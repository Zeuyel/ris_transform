TY  - JOUR
AU  - Karimian, M.
AU  - Beigy, H.
TI  - CPT4: Continual Prompted Transformer for Test Time Training
PY  - 2025
T2  - Information Sciences
VL  - 700
C7  - 121841
DO  - 10.1016/j.ins.2024.121841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214289896&doi=10.1016%2fj.ins.2024.121841&partnerID=40&md5=fc033d9fbc6ce0fa044a290b67383cd5
AB  - Adapting machine learning models to non-stationary environments is challenging due to evolving domain shifts. Test-time adaptation (TTA) methods address this challenge by employing pre-trained models on source data to predict on unlabeled target data with different domains and adapt the model. However, real-world scenarios frequently encounter continual shifts in target data domains during testing, leading to complexities in ongoing adaptation and error propagation. While earlier TTA methods for image classification tasks mainly focused on convolutional-based models, this paper introduces a transformer-based approach to address TTA challenges, particularly in non-stationary environments. We propose a method, Continual Prompted Transformer for Test-Time Training (CPT4), that enhances the Vision Transformer (ViT) model by incorporating shared prompts (small learnable parameters) and a batch normalization module, aiming to mitigate catastrophic forgetting and handle domain shifts effectively. The prompt pool retains information from prior tasks, while the batch normalization module transfers source data statistics to test time. This work contributes to utilizing small learnable parameters for continual learning in TTA scenarios without access to source data or target labels. Comprehensive experiments using continual image classification benchmarks with non-stationary environments demonstrate CPT4's substantial performance improvement over the original ViT model in a continual test-time training scenario across different adaptation strategies. © 2025 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Karimian2025CPT4
ER  -

TY  - JOUR
AU  - Hassan Anik, B.M.T.
AU  - Abdel-Aty, M.
AU  - Islam, Z.
TI  - Can we realize seamless traffic safety at smart intersections by predicting and preventing impending crashes?
PY  - 2025
T2  - Accident Analysis and Prevention
VL  - 211
C7  - 107908
DO  - 10.1016/j.aap.2024.107908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213567305&doi=10.1016%2fj.aap.2024.107908&partnerID=40&md5=8f9fe32797ab8c8bf5baa2fcf8de0054
AB  - Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties. We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Hassan Anik2025Can
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Fanfan, P.
AU  - Zhang, Y.
AU  - Chen, T.
AU  - Du, H.
TI  - Integrating deep learning model and virtual reality technology for motion prediction in emergencies
PY  - 2025
T2  - Safety Science
VL  - 183
C7  - 106721
DO  - 10.1016/j.ssci.2024.106721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209638207&doi=10.1016%2fj.ssci.2024.106721&partnerID=40&md5=9fad0df6800f70cbb6492593415226cd
AB  - Predicting the evacuation behavior of pedestrians in emergencies is essential for ensuring public safety. Existing deep learning-based prediction models generally focus on crowd trajectories extrapolation in conventional scenarios but ignore the effect of emergencies on human behavior. Their performance has not been rigorously validated during emergency events such as fires and floodwaters. In this paper, we implement a combined solution involving a transformer-based network and virtual reality (VR) modeling. The proposed virtual reality-trained neural network incorporates diverse cues from human poses, moving paths, scenes, and emergency events to predict future trajectories. The virtual reality modeling creates diverse evacuation scenarios to enhance prediction performance. Moreover, based on the pretraining of our constructed VR dataset, the designed model can be applied to real-world human behavior prediction. The experimental results demonstrate our model's superior accuracy in various scenarios, particularly for emergency evacuations, showcasing its ability to capture the dynamics of human behavior in safety-critical environments. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:2; zdy:None; 
LB  - Li2025Integrating
ER  -

TY  - JOUR
AU  - Jia, R.
AU  - Gao, K.
AU  - Liu, Y.
AU  - Yu, B.
AU  - Ma, X.
AU  - Ma, Z.
TI  - i-CLTP: Integrated contrastive learning with transformer framework for traffic state prediction and network-wide analysis
PY  - 2025
T2  - Transportation Research Part C: Emerging Technologies
VL  - 171
C7  - 104979
DO  - 10.1016/j.trc.2024.104979
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212880422&doi=10.1016%2fj.trc.2024.104979&partnerID=40&md5=272ed4d7ffd74ab4a467140fa99ecb68
AB  - Traffic state predictions are critical for the traffic management and control of transport systems. This study introduces an innovative contrastive learning framework coupled with a transformer architecture for spatiotemporal traffic state prediction, designed to capture the spatio-temporal heterogeneity inherent in traffic. The transformer structure functions as the upper level of the prediction framework to minimize the prediction errors between the input and predicted output. Based on the self-supervised contrastive learning, the lower level in the framework is proposed to discern the spatio-temporal heterogeneity and embed the latent characteristic of traffic flow by regenerating the augmentation features. Then, a soft clustering problem is applied between the upper level and lower level to category the types of traffic flow characteristics by minimizing the joint loss across each cluster. Subsequently, the proposed model is evaluated through a real-world highway traffic flow dataset for bench marking against several latest existing models. The experimental results affirm that the proposed model considerably enhances traffic state prediction accuracy. In terms of precision metrics, the model records a Mean Absolute Error of 13.31 and a Mean Absolute Percentage Error of 7.85%, reflecting marked improvements of 2.0% and 14.5% respectively over the latest and most competitive baseline model. Furthermore, the analysis reveals that capacity of the proposed method to learn the cluster patterns of spatio-temporal traffic dynamics reflected by calibrated fundamental diagrams. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; 
LB  - Jia2025i-CLTP
ER  -

TY  - JOUR
AU  - Di Rocco, J.
AU  - Nguyen, P.T.
AU  - Di Sipio, C.
AU  - Rubei, R.
AU  - Di Ruscio, D.
AU  - Di Penta, M.
TI  - DeepMig: A transformer-based approach to support coupled library and code migrations
PY  - 2025
T2  - Information and Software Technology
VL  - 177
C7  - 107588
DO  - 10.1016/j.infsof.2024.107588
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205990085&doi=10.1016%2fj.infsof.2024.107588&partnerID=40&md5=3b7f11f7bd4909535b956a5643722acd
AB  - Context: While working on software projects, developers often replace third-party libraries (TPLs) with different ones offering similar functionalities. However, choosing a suitable TPL to migrate to is a complex task. As TPLs provide developers with Application Programming Interfaces (APIs) to allow for the invocation of their functionalities after adopting a new TPL, projects need to be migrated by the methods containing the affected API calls. Altogether, the coupled migration of TPLs and code is a strenuous process, requiring massive development effort. Most of the existing approaches either deal with library or API call migration but usually fail to solve both problems coherently simultaneously. Objective: This paper presents DeepMig, a novel approach to the coupled migration of TPLs and API calls. We aim to support developers in managing their projects, at the library and API level, allowing them to increase their productivity. Methods: DeepMig is based on a transformer architecture, accepts a set of libraries to predict a new set of libraries. Then, it looks for the changed API calls and recommends a migration plan for the affected methods. We evaluate DeepMig using datasets of Java projects collected from the Maven Central Repository, ensuring an assessment based on real-world dependency configurations. Results: Our evaluation reveals promising outcomes: DeepMig recommends both libraries and code; by several projects, it retrieves a perfect match for the recommended items, obtaining an accuracy of 1.0. Moreover, being fed with proper training data, DeepMig provides comparable code migration steps of a static API migrator, a baseline for the code migration task. Conclusion: We conclude that DeepMig is capable of recommending both TPL and API migration, providing developers with a practical tool to migrate the entire project. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Di Rocco2025DeepMig
ER  -

TY  - JOUR
AU  - Xu, Z.
AU  - Gan, S.
AU  - Hua, X.
AU  - Xiong, Y.
TI  - Can the sentiment of the official media predict the return volatility of the Chinese crude oil futures?
PY  - 2024
T2  - Energy Economics
VL  - 140
C7  - 107967
DO  - 10.1016/j.eneco.2024.107967
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207084196&doi=10.1016%2fj.eneco.2024.107967&partnerID=40&md5=f0d8399b5e0100870eacbaa90649f89d
AB  - This study investigates whether the sentiment of Chinese official media towards crude oil influences price volatility of the Chinese crude oil futures (SC). By leveraging textual analysis through Bidirectional Encoder Representations from Transformers (BERT), we quantify the sentiment of oil-related articles published by the primary official media in China. Our main finding, building on both in-sample and out-of-sample analyses, robustly reveals that this sentiment significantly forecasts the one-day-ahead intraday return volatility of SC. Moreover, we extend the analysis to different time horizons (i.e., one-week and one-month-ahead) and find the prominent forecasting power of the official media sentiment as well. We also find that the official media sentiment fails to forecast the price volatility of WTI oil futures, implying that the official media sentiment contains some unique Chinese information. Overall, our study contributes to the existing literature on predicting the return volatility of the Chinese crude oil futures, and offers fresh insights into an essential yet underexplored sentiment, i.e., official media sentiment. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Xu2024Can
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Wang, L.
AU  - An, W.
TI  - Probability density prediction for carbon allowance prices based on TS2Vec and distribution Transformer
PY  - 2024
T2  - Energy Economics
VL  - 140
C7  - 107986
DO  - 10.1016/j.eneco.2024.107986
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208476352&doi=10.1016%2fj.eneco.2024.107986&partnerID=40&md5=bf36cda489f98a54ab43b2b92856de9b
AB  - Carbon allowance price is an important tool to reduce carbon emissions and achieve carbon neutrality. It is necessary to establish a predictive model to provide accurate and reliable information to managers and participants in the carbon trading market. Therefore, a novel probability density prediction model, called TS2Vec-based distribution Transformer (TDT), is proposed. TDT consists of two stages: contrastive unsupervised pre-training and supervised training. In the contrastive unsupervised training stage, time series to vector (TS2Vec) is used to represent the dynamic trends and unique features of the data. Then, these representations are fed into the distribution Transformer (DT) to fit the hypothetical probability distribution. Experimental results show that the prediction results of the proposed TDT are more accurate and reliable than other benchmark models. In addition, our research indicates reliable probability density predictions provide enterprises with opportunities to control carbon emission costs and increase economic returns, thereby improving the competitiveness of enterprises and promoting carbon emission reduction. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Wang2024Probability
ER  -

TY  - JOUR
AU  - Anik, B.M.T.H.
AU  - Islam, Z.
AU  - Abdel-Aty, M.
TI  - A time-embedded attention-based transformer for crash likelihood prediction at intersections using connected vehicle data
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 169
C7  - 104831
DO  - 10.1016/j.trc.2024.104831
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203499233&doi=10.1016%2fj.trc.2024.104831&partnerID=40&md5=be69b28e1263912944caeaf3b7fb15ce
AB  - The real-time crash likelihood prediction model is an essential component of the proactive traffic safety management system. Over the years, numerous studies have attempted to construct a crash likelihood prediction model in order to enhance traffic safety, but mostly on freeways. In the majority of the existing studies, researchers have primarily used a deep learning-based framework to identify crash potential. Lately, Transformers have emerged as a potential deep neural network that fundamentally operates through attention-based mechanisms. Transformers exhibit distinct functional benefits over established deep learning models like Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs), and Convolutional Neural Networks (CNNs). First, they employ attention mechanisms to accurately weigh the significance of different parts of input data, a dynamic functionality that is not available in RNNs, LSTMs, and CNNs. Second, they are well-equipped to handle dependencies over long-range data sequences, a feat RNNs typically struggle with. Lastly, unlike RNNs, LSTMs, and CNNs, which process data in sequence, Transformers can parallelly process data elements during training and inference, thereby enhancing their efficiency. Apprehending the immense possibility of Transformers, this paper proposes inTersection-Transformer (inTformer), a time-embedded attention-based Transformer model that can effectively predict intersection crash likelihood in real-time. The inTformer is basically a binary prediction model that predicts the occurrence or non-occurrence of crashes at intersections in the near future (i.e., next 15 min). The proposed model was developed by employing traffic data extracted from connected vehicles. Acknowledging the complex traffic operation mechanism at intersection, this study developed zone-specific models by dividing the intersection region into two distinct zones: within-intersection and approach zones, each representing the intricate flow of traffic unique to the type of intersection (i.e., three-legged and four-legged intersections). In the ‘within-intersection’ zone, the inTformer models attained a sensitivity of up to 73%, while in the ‘approach’ zone, the sensitivity peaked at 74%. Moreover, benchmarking the optimal zone-specific inTformer models against earlier studies on crash likelihood prediction at intersections and several established deep learning models trained on the same connected vehicle dataset confirmed the superiority of the proposed inTformer. Further, to quantify the impact of features on crash likelihood at intersections, the SHAP (SHapley Additive exPlanations) method was applied on the best performing inTformer models. The most critical predictors were average and maximum approach speeds, average and maximum control delays, average and maximum travel times, split failure percentage and count, and percent arrival on green. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; 
LB  - Anik2024time-embedded
ER  -

TY  - JOUR
AU  - Peters, H.
AU  - Bayer, J.B.
AU  - Matz, S.C.
AU  - Chi, Y.
AU  - Vaid, S.S.
AU  - Harari, G.M.
TI  - Social media use is predictable from app sequences: Using LSTM and transformer neural networks to model habitual behavior
PY  - 2024
T2  - Computers in Human Behavior
VL  - 161
C7  - 108381
DO  - 10.1016/j.chb.2024.108381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200976669&doi=10.1016%2fj.chb.2024.108381&partnerID=40&md5=29ff138630f4caa7ac3376a28fc7ad7b
AB  - The present paper introduces a novel approach to studying social media habits through predictive modeling of sequential smartphone user behaviors. While much of the literature on media and technology habits has relied on self-report questionnaires and simple behavioral frequency measures, we examine an important yet understudied aspect of media and technology habits: their embeddedness in repetitive behavioral sequences. Leveraging Long Short-Term Memory (LSTM) and transformer neural networks, we show that (i) social media use is predictable at the within and between-person level and that (ii) there are robust individual differences in the predictability of social media use. We examine the performance of several modeling approaches, including (i) global models trained on the pooled data from all participants, (ii) idiographic person-specific models, and (iii) global models fine-tuned on person-specific data. Neither person-specific modeling nor fine-tuning on person-specific data substantially outperformed the global models, indicating that the global models were able to represent a variety of idiosyncratic behavioral patterns. Additionally, our analyses reveal that individual differences in the predictability of social media use were not substantially related to differences in the frequency of smartphone use in general or the frequency of social media use, indicating that our approach captures an aspect of habits that is distinct from behavioral frequency. Implications for habit modeling and theoretical development are discussed. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Peters2024Social
ER  -

TY  - JOUR
AU  - Gong, Y.
AU  - Cosma, G.
AU  - Finke, A.
TI  - VITR: Augmenting Vision Transformers with Relation-Focused Learning for Cross-modal Information Retrieval
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 9
C7  - 220
DO  - 10.1145/3686805
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210317345&doi=10.1145%2f3686805&partnerID=40&md5=587d2687bb03a1fc4f8f4a361168a059
AB  - The relations expressed in user queries are vital for cross-modal information retrieval. Relation-focused cross-modal retrieval aims to retrieve information that corresponds to these relations, enabling effective retrieval across different modalities. Pre-Trained networks, such as Contrastive Language-Image Pre-Training networks, have gained significant attention and acclaim for their exceptional performance in various cross-modal learning tasks. However, the Vision Transformer (ViT) used in these networks is limited in its ability to focus on image region relations. Specifically, ViT is trained to match images with relevant descriptions at the global level, without considering the alignment between image regions and descriptions. This article introduces VITR, a novel network that enhances ViT by extracting and reasoning about image region relations based on a local encoder. VITR is comprised of two key components. Firstly, it extends the capabilities of ViT-based cross-modal networks by enabling them to extract and reason with region relations present in images. Secondly, VITR incorporates a fusion module that combines the reasoned results with global knowledge to predict similarity scores between images and descriptions. The proposed VITR network was evaluated through experiments on the tasks of relation-focused cross-modal information retrieval. The results derived from the analysis of the Flickr30K, MS-COCO, RefCOCOg, and CLEVR datasets demonstrated that the proposed VITR network consistently outperforms state-of-The-Art networks in image-To-Text and text-To-image retrieval. © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Gong2024VITR
ER  -

TY  - JOUR
AU  - Kumar, R.
AU  - Mendes-Moreira, J.
AU  - Chandra, J.
TI  - Spatio-Temporal Parallel Transformer Based Model for Traffic Prediction
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 9
C7  - 213
DO  - 10.1145/3679017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210313256&doi=10.1145%2f3679017&partnerID=40&md5=5128289e3a2caebb12224eb7ad4e3fa5
AB  - Traffic forecasting problems involve jointly modeling the non-linear spatio-Temporal dependencies at different scales. While graph neural network models have been effectively used to capture the non-linear spatial dependencies, capturing the dynamic spatial dependencies between the locations remains a major challenge. The errors in capturing such dependencies propagate in modeling the temporal dependencies between the locations, thereby severely affecting the performance of long-Term predictions. While transformer-based mechanisms have been recently proposed for capturing the dynamic spatial dependencies, these methods are susceptible to fluctuations in data brought on by unforeseen events like traffic congestion and accidents. To mitigate these issues we propose an improvised spatio-Temporal parallel transformer (STPT) based model for traffic prediction that uses multiple adjacency graphs passed through a pair of coupled graph transformer-convolution network units, operating in parallel, to generate more noise-resilient embeddings. We conduct extensive experiments on 4 real-world traffic datasets and compare the performance of STPT with several state-of-The-Art baselines, in terms of measures like RMSE, MAE, and MAPE. We find that using STPT improves the performance by around as compared to the baselines. We also investigate the applicability of the model on other spatio-Temporal data in other domains. We use a Covid-19 dataset to predict the number of future occurrences in different regions from a given set of historical occurrences. The results demonstrate the superiority of our model for such datasets.  © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Kumar2024Spatio-Temporal
ER  -

TY  - JOUR
AU  - Nishikawa, K.
AU  - Koshiba, H.
TI  - Exploring the applicability of large language models to citation context analysis
PY  - 2024
T2  - Scientometrics
VL  - 129
IS  - 11
SP  - 6751
EP  - 6777
DO  - 10.1007/s11192-024-05142-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204707155&doi=10.1007%2fs11192-024-05142-9&partnerID=40&md5=31dab229843be0f8c95d75c9edf83af7
AB  - Unlike traditional citation analysis, which assumes that all citations in a paper are equivalent, citation context analysis considers the contextual information of individual citations. However, citation context analysis requires creating a large amount of data through annotation, which hinders its widespread use. This study explored the applicability of Large Language Models (LLM)—particularly Generative Pre-trained Transformer (GPT)—to citation context analysis by comparing LLM and human annotation results. The results showed that LLM annotation is as good as or better than human annotation in terms of consistency but poor in terms of its predictive performance. Thus, having LLM immediately replace human annotators in citation context analysis is inappropriate. However, the annotation results obtained by LLM can be used as reference information when narrowing the annotation results obtained by multiple human annotators down to one; alternatively, the LLM can be used as an annotator when it is difficult to prepare sufficient human annotators. This study provides basic findings important for the future development of citation context analysis. © Akadémiai Kiadó, Budapest, Hungary 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Nishikawa2024Exploring
ER  -

TY  - JOUR
AU  - Pourbehzadi, M.
AU  - Javidi, G.
AU  - Howell, C.J.
AU  - Kamar, E.
AU  - Sheybani, E.
TI  - Enhanced (cyber) situational awareness: Using interpretable principal component analysis (iPCA) to automate vulnerability severity scoring
PY  - 2024
T2  - Decision Support Systems
VL  - 186
C7  - 114308
DO  - 10.1016/j.dss.2024.114308
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203133481&doi=10.1016%2fj.dss.2024.114308&partnerID=40&md5=931bc984689f65da24ec09990f4428cf
AB  - The Common Vulnerability Scoring System (CVSS) is widely used in the cybersecurity industry to assess the severity of vulnerabilities. However, manual assessments and human error can lead to delays and inconsistencies. This study employs situational awareness theory to develop an automated decision support system, integrating perception, comprehension, and projection components to enhance effectiveness. Specifically, an interpretable principal component analysis (iPCA) combined with machine learning is utilized to forecast CVSS scores using text descriptions from the Common Vulnerabilities and Exposures (CVE) database. Different forecasting approaches, including traditional machine learning models, Long-Short Term Memory Neural Networks, and Transformer architectures (ChatGPT) are compared to determine the best performance. The results show that iPCA combined with support vector regression achieves a high performance (R2 = 98%) in predicting CVSS scores using CVE text descriptions. The results indicate that the variability, length, and details in the vulnerability description contribute to the performance of the transformer model. These findings are consistent across vulnerability descriptions from six companies between 2017 and 2019. The study's outcomes have the potential to enhance organizations' security posture, improving situational awareness and enabling better managerial decision-making in cybersecurity. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Pourbehzadi2024Enhanced
ER  -

TY  - JOUR
AU  - Zou, J.
AU  - Sun, A.
AU  - Long, C.
AU  - Kanoulas, E.
TI  - Knowledge-Enhanced Conversational Recommendation via Transformer-Based Sequential Modeling
PY  - 2024
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 6
C7  - 162
DO  - 10.1145/3677376
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208364514&doi=10.1145%2f3677376&partnerID=40&md5=f35159b0f131527029df81886810cbb7
AB  - In conversational recommender systems (CRSs), conversations usually involve a set of items and item-related entities or attributes, e.g., director is a related entity of a movie. These items and item-related entities are often mentioned along the development of a dialog, leading to potential sequential dependencies among them. However, most of existing CRSs neglect these potential sequential dependencies7. In this article, we first propose a Transformer-based sequential conversational recommendation method, named TSCR, to model the sequential dependencies in the conversations to improve CRS. In TSCR, we represent conversations by items and the item-related entities, and construct user sequences to discover user preferences by considering both the mentioned items and item-related entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Meanwhile, in certain domains, knowledge graphs formed by the items and their related entities are readily available, which provide various different kinds of associations among them. Given that TSCR does not benefit from such knowledge graphs, we then propose a knowledge graph enhanced version of TSCR, called TSCRKG. In specific, we leverage the knowledge graph to offline initialize our model TSCRKG, and augment the user sequence of conversations (i.e., sequence of the mentioned items and item-related entities in the conversation) with multi-hop paths in the knowledge graph. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines, and the enhanced version TSCRKG further improves recommendation performance on top of TSCR.  © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Zou2024Knowledge-Enhanced
ER  -

TY  - JOUR
AU  - Orozco López, E.
AU  - Kaplan, D.
AU  - Linhoss, A.
TI  - Interpretable Transformer Neural Network Prediction of Diverse Environmental Time Series Using Weather Forecasts
PY  - 2024
T2  - Water Resources Research
VL  - 60
IS  - 10
C7  - e2023WR036337
DO  - 10.1029/2023WR036337
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207874231&doi=10.1029%2f2023WR036337&partnerID=40&md5=54582e33ee92e990d57a408a94b20731
AB  - Transformer neural networks (TNNs) have caused a paradigm shift in deep learning domains like natural language processing, gathering immense interest due to their versatility in other fields such as time series forecasting (TSF). Most current TSF applications of TNNs use only historic observations to predict future events, ignoring information available in weather forecasts to inform better predictions, and with little attention given to the interpretability of the model's use of explanatory inputs. This work explores the potential for TNNs to perform TSF across multiple environmental variables (streamflow, stage, water temperature, and salinity) in two ecologically important regions: the Peace River watershed (Florida) and the northern Gulf of Mexico (Louisiana). The TNN was tested and its prediction uncertainty quantified for each response variable from one-to fourteen-day-ahead forecasts using past observations and spatially distributed weather forecasts. A sensitivity analysis (SA) was performed on the trained TNNs' attention weights to identify the relative influence of each input variable on each response variable across prediction windows. Overall model performance ranged from good to very good (0.78 < NSE < 0.99 for all variables and forecast horizons). Through the SA, we found that the TNN was able to learn the physical patterns behind the data, adapt the use of input variables to each forecast, and increasingly use weather forecast information as prediction windows increased. The TNN's excellent performance and flexibility, along with the intuitive interpretability highlighting the logic behind the models' forecasting decision-making process, provide evidence for the applicability of this architecture to other TSF variables and locations. © 2024. The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; 
LB  - Orozco López2024Interpretable
ER  -

TY  - JOUR
AU  - Zheng, W.
AU  - Li, C.
AU  - Deng, Z.
TI  - Hotel demand forecasting with multi-scale spatiotemporal features
PY  - 2024
T2  - International Journal of Hospitality Management
VL  - 123
C7  - 103895
DO  - 10.1016/j.ijhm.2024.103895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202801983&doi=10.1016%2fj.ijhm.2024.103895&partnerID=40&md5=6edfb7f63ffab0d47b43ff7ac7844abb
AB  - Accurate demand forecasting is critical to hotel revenue management and related decision-making. Considering the heterogeneity and dynamics of spatial effects across different time scales, this study introduces a novel model which can deeply extract these features to improve the forecasting performance of hotel demand. Specifically, the model constructs input variables with different periodicities and then integrates a Transformer neural network and long short-term memory to extract multi-scale and dynamic spatiotemporal features to generate accurate forecasts. The effectiveness of the model is verified through an empirical case in Xiamen, China. Results suggest our model significantly outperforms benchmarks in terms of accuracy and robustness. The findings extend the application of spatial-temporal modeling in hotel demand forecasting. Hotel managers can use our forecasts to optimize operations, improve revenues, and control risks. The extracted spatiotemporal features can also help managers examine cooperation and competition relationships with neighbor hotels. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Zheng2024Hotel
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Wang, J.
AU  - Wang, J.
AU  - Guan, Q.
TI  - Predicting air quality using a multi-scale spatiotemporal graph attention network
PY  - 2024
T2  - Information Sciences
VL  - 680
C7  - 121072
DO  - 10.1016/j.ins.2024.121072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198004548&doi=10.1016%2fj.ins.2024.121072&partnerID=40&md5=5ce16a899a8ecb53d36568e9808e84ef
AB  - As urbanization accelerates, air quality has become a pressing concern. Accurate air quality prediction is essential for informed governmental decision-making and for protecting public health. Variations in air quality are influenced by complex multi-scale spatiotemporal processes. Existing research primarily relies on capturing single spatiotemporal features of air quality to predict changes. Meanwhile, when constructing spatiotemporal dynamic graphs, the inherent characteristics of the input data and the comprehensive effects of both global and local influences are not fully considered. To address these problems, we propose a graph-attention-based approach, named Multi-scale Spatiotemporal Graph Attention Network (MSTGAN). MSTGAN addresses the intricate spatiotemporal patterns of air quality across various scales through three key components: (1) a multistation transformer to model the temporal patterns of air quality at individual monitoring stations; (2) a bilinear spatiotemporal attention mechanism to capture the spatiotemporal dynamic global dependencies among all stations in a region; and (3) a set of spatiotemporal dependence graph-coupled Chebyshev graph convolution gate recurrent units to extract and aggregate the local spatiotemporal features of interrelated stations. Experiments conducted on three real-world datasets demonstrated that MSTGAN achieved significant improvements of 4.2%, 3.9%, and 7.8% in the mean absolute error, root mean square error, and R2 evaluation metrics, respectively, compared to seven state-of-the-art time-series forecasting methods. This code is publicly available at https://github.com/HPSCIL/MSTGAN-airquality-prediction. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024Predicting
ER  -

TY  - JOUR
AU  - Yu, C.
AU  - Lin, H.
AU  - Dong, W.
AU  - Fang, S.
AU  - Yuan, Q.
AU  - Yang, C.
TI  - TripChain2RecDeepSurv: A novel framework to predict transit users’ lifecycle behavior status transitions for user management
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 167
C7  - 104818
DO  - 10.1016/j.trc.2024.104818
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201774077&doi=10.1016%2fj.trc.2024.104818&partnerID=40&md5=68021bbad0388d80fff895c976818611
AB  - Transit users’ lifecycle behavior pattern transition reflects the continuous and multi-phase changes in how frequently and regularly users utilize public transit over their lifetime. Predicting transit users’ lifecycle behavior pattern transition is vital for enhancing the efficiency and responsiveness of transportation systems. Thus, this study incorporates lifecycle analysis in predicting long-term sequential behavioral pattern transition processes to go beyond just examining user churning at a single point in time. Specifically, this study proposes the TripChain2RecDeepSurv, a novel model that pioneers the individual-level analysis of lifecycle behavior status transitions (LBST) within public transit systems. The TripChain2RecDeepSurv is composed of (1) the TripChain2Vec module for encoding transit users’ trip chains; (2) the self-attention Transformer module for exploring the latent features related to spatiotemporal patterns; (3) the recurrent deep survival analysis module for predicting LBSTs. We demonstrate TripChain2RecDeepSurv's predictive performance for empirical analysis by employing Shenzhen Bus data. Our model achieves a 74.39% accuracy rate in churn determination and over 80% accuracy in status sequence identification on the churn path. In addition, our findings highlight the segmented nature of Kaplan-Meier curves and identify the optimal intervention time against the user churning process. Meanwhile, the proposed model provides individual-level heterogeneity analysis, which emphasizes the significance of customizing user engagement strategies, advocating for interventions that extend users’ engagement in patterns with high-frequency transit usage to curb the transition to less frequent travel usage. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; 
LB  - Yu2024TripChain2RecDeepSurv
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Yu, Y.
AU  - Zhang, T.
AU  - Song, K.
AU  - Wang, Y.
AU  - Gao, S.
TI  - Improved dendritic learning: Activation function analysis
PY  - 2024
T2  - Information Sciences
VL  - 679
C7  - 121034
DO  - 10.1016/j.ins.2024.121034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196773201&doi=10.1016%2fj.ins.2024.121034&partnerID=40&md5=568396940fcbd6c34c6a376ed7be38e1
AB  - This study conducted a thorough evaluation of an improved dendritic learning (DL) framework, focusing specifically on its application in power load forecasting. The objective was to optimise the activation functions within the synapses and somas of DL to enhance their adaptability across diverse real-world scenarios. Through a rigorous analysis involving 25 experiments across five activation functions (sigmoid, hyperbolic tangent (tanh), rectified linear unit (ReLU), leaky ReLU, and exponential linear unit (ELU)), we elucidated their impacts on both regression and classification performance. Notably, the leaky ReLU–tanh combination demonstrated exceptional mean performance and effectiveness across 14 benchmark datasets from the University of California Irvine Machine Learning Repository, surpassing alternative combinations. When applied to power load forecasting, this combination outperformed other models, particularly transformer and LSTM. These findings underscore the significant advantages of the leaky ReLU–tanh-based DL framework in accurately predicting electricity load in smart grids, as evidenced by the lowest mean absolute error (39.27), root mean squared error (29.13), and mean absolute percentage error (2.84). © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2024Improved
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Ren, M.
AU  - Wang, Z.
AU  - Li, G.
TI  - MEMF: Multi-entity multimodal fusion framework for sales prediction in live streaming commerce
PY  - 2024
T2  - Decision Support Systems
VL  - 184
C7  - 114277
DO  - 10.1016/j.dss.2024.114277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197270719&doi=10.1016%2fj.dss.2024.114277&partnerID=40&md5=94f1408b74744fce523e837f1033ac36
AB  - Live streaming commerce thrives with a rich tapestry of multimodal information that intertwines with various entities, including the anchor, the commodities, and the live streaming environment. Despite the wealth of data at hand, the synthesis and analysis of this information to predict sales remains a significant challenge. This study introduces a framework for multi-entity multimodal fusion, which is characterized by the effective synthesis of multimodal data and its prioritization of entity-level fusion, thereby providing a comprehensive feature representation for improving predictive performance. In addressing the multimodal data associated with a diverse range of products, our framework improves the Transformer architecture to initially capture the intra-product modal features and subsequently integrate the inter-product features. Data experiments are conducted on a real-world dataset from Taobao Live. The framework outperforms both traditional machine learning methods and state-of-the-art multimodal fusion methods, which affirms its value as a robust decision-support tool for sales prediction, enabling more accurate pre-event predictions and strategic planning. We also examine the impact of different types of information in accurate sales prediction. It is found that harnessing a comprehensive suite of data leads to optimal performance across all evaluation metrics. Commodity-related data is primary factor in determining the prediction accuracy, followed by video data and streaming room-related data, providing insights regarding the resource allocation for collecting and analyzing multimodal data from live streaming platforms. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Xu2024MEMF
ER  -

TY  - JOUR
AU  - Hu, S.
AU  - Chen, J.
AU  - Zhang, W.
AU  - Liu, G.
AU  - Chang, X.
TI  - Graph transformer embedded deep learning for short-term passenger flow prediction in urban rail transit systems: A multi-gate mixture-of-experts model
PY  - 2024
T2  - Information Sciences
VL  - 679
C7  - 121095
DO  - 10.1016/j.ins.2024.121095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196797751&doi=10.1016%2fj.ins.2024.121095&partnerID=40&md5=cb934481b7bdeccbf0cc7b51b23d1cfd
AB  - Urban rail transit (URT) plays a crucial role in mitigating urban traffic congestion by offering faster and higher-quality travel services. Short-term passenger flow predictions have practical significance for metro management and operation. However, the complex spatiotemporal characteristics and the relationship between entry and exit passenger flows make it challenging to detect the dynamic evolution patterns. This study proposes a Spatio-Temporal Graph Transformer (STGT) under the multi-task learning framework, utilizing Graph Transformer network and gated residual units to select and aggregate features. To account for the correlation between entry and exit passenger flow prediction tasks, the STGT model integrates a Multi-gate Mixture-of-Experts (MMoE) approach, which combines different expert networks for diverse input and explicitly learns to model passenger flow relationships in various scenarios. Metro-related characteristics such as weather conditions, train operation characteristics, and accessibility of nearby bus stops are incorporated to enhance prediction accuracy. Experimental evaluations are conducted using real-world historical passenger travel records from the Beijing subway. The results demonstrate the superior robustness and advantages of the STGT-MMoE model over basic and advanced benchmarks for passenger flow prediction tasks. These findings provide compelling evidence to address the challenges of short-term inflow and outflow prediction in urban rail transit systems. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Hu2024Graph
ER  -

TY  - JOUR
AU  - Lee, D.-G.
AU  - Ahn, K.-H.
TI  - Improving medium-range streamflow forecasts over South Korea with a dual-encoder transformer model
PY  - 2024
T2  - Journal of Environmental Management
VL  - 368
C7  - 122114
DO  - 10.1016/j.jenvman.2024.122114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200636905&doi=10.1016%2fj.jenvman.2024.122114&partnerID=40&md5=4e98e3564a81e34e923941e4000e8d6c
AB  - Accurate and reliable hydrological forecasts play a pivotal role in ensuring water security, facilitating flood preparedness, and supporting agriculture activities. This study investigates the potential of hydrological forecasting in South Korea, focusing on medium-range lead times ranging from 1 to 10 days. The methodology involves leveraging a Transformer neural network, a model entirely based on attention mechanisms. Specifically, our study introduces the Dualformer, a dual-encoder-based transformer model capable of accommodating two distinct datasets: historical and forecast meteorological data. The performance of this proposed model, along with its variants designed to test specific structural aspects, is evaluated in predicting daily streamflow across 473 grid cells covering extensive regions within the study area. Furthermore, the proposed model is assessed against the performance of a recently developed approach aiming for the same objective. These models are trained using historical meteorological variables and geographic characteristics, alongside the Global Ensemble Forecast System, version 12 (GEFSv12) reforecasts, in addition to historical runoff. The results indicate that our proposed model performs competitively, especially for relatively short lead times while effectively managing information from two distinct data sources. For instance, the mean Nash-Sutcliffe efficiency for 473 grids is 0.664 for the first one-day lead when using the Dualformer, whereas the benchmark model achieves a score of 0.535. Additionally, we observe an additional enhancement in Dualformer's performance when utilizing a larger dataset. Finally, we conclude this paper with a discussion regarding potential improvements to the forecast model through the incorporation of additional input and modeling structures. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; 
LB  - Lee2024Improving
ER  -

TY  - JOUR
AU  - Janssens, B.
AU  - Schetgen, L.
AU  - Bogaert, M.
AU  - Meire, M.
AU  - Van den Poel, D.
TI  - 360 Degrees rumor detection: When explanations got some explaining to do
PY  - 2024
T2  - European Journal of Operational Research
VL  - 317
IS  - 2
SP  - 366
EP  - 381
DO  - 10.1016/j.ejor.2023.06.024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163863220&doi=10.1016%2fj.ejor.2023.06.024&partnerID=40&md5=a0fa02043541c9833815686aa590ee2a
AB  - Unverified rumor detection recently received considerable academic attention due to the societal impact resulting from this potential misinformation. Previous work in this area mainly focused on textual features using a limited number of data sets and candidate algorithms, and completely disregarded model explainability. This study aims to come up with a more comprehensive social media rumor detection methodology. First, we investigate which machine or deep learning algorithm is best suited to classify tweets into rumors and non-rumors using both textual and structured features. Next, we interpret these rumor detection models with the LIME method and assess the quality of the explanations via fidelity and stability. To ensure the robustness of our methodology, it is benchmarked across the well-known PHEME data sets and two novel data sets, which are made publicly available. The results indicate that machine learners perform best on small data sets, while transformer architectures show the highest predictive accuracy for larger data sets. Unfortunately, these high accuracy transformer models are incompatible with LIME, which results in low fidelity. Moreover, our study shows that all LIME explanations are unstable across folds. Based on these results, we argue to evaluate explanation quality using fidelity and stability before explanation deployment. Our results further demonstrate that apparent model-agnostic explanations such as LIME do not seem to be completely model-agnostic and should be used with caution. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Janssens2024360
ER  -

TY  - JOUR
AU  - Peng, Z.
AU  - Rong, Y.
AU  - Zhu, T.
TI  - Transformer-based choice model: A tool for assortment optimization evaluation
PY  - 2024
T2  - Naval Research Logistics
VL  - 71
IS  - 6
SP  - 854
EP  - 877
DO  - 10.1002/nav.22183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189067701&doi=10.1002%2fnav.22183&partnerID=40&md5=ef556e64837f96e490c9923c87cd86a5
AB  - Assessing the efficacy of algorithms plays a pivotal role in advancing various fields, both in theory and practice. Unlike the predictive models, due to the intricate relationship between decisions and the underlying data-generating processes, the evaluation of decision algorithms cannot directly rely on real data. Hence, a simulator becomes indispensable for appraising decision algorithm effectiveness. In this paper, we aim to leverage assortment decisions, a widely used application in revenue management, to illustrate the utilization of a machine learning-based simulation. The process can be summarised as: we utilize the modified Transformer-based choice model, acting as a simulator, to generate a synthetic dataset that mimics consumer purchasing behavior. After training the MNL, DeepFM, and DeepFM-a models, all of which can swiftly provide assortment decisions in real-time, we utilize the simulator to evaluate the revenue generated by each assortment prescribed by different choice models. This approach mitigates the challenge of validating decision models that alter real-world observed data. To show the benefit of such a simulation approach, we have conducted various numerical studies. These studies aim to examine the impact of outside option attractiveness, data size, the number of features, and cardinality. Admittedly, due to the close alignment between the simulator and complex consumer purchase choice datasets, some numerical observations may be challenging to explain. Nevertheless, by employing the simulator, we are able to contrast the differences between the MNL and DeepFM/DeepFM-a models, shedding light on their respective model misspecifications. © 2024 Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Peng2024Transformer-based
ER  -

TY  - JOUR
AU  - Mu, L.
AU  - Bi, S.
AU  - Ding, X.
AU  - Xu, Y.
TI  - Transformer-based ozone multivariate prediction considering interpretable and priori knowledge: A case study of Beijing, China
PY  - 2024
T2  - Journal of Environmental Management
VL  - 366
C7  - 121883
DO  - 10.1016/j.jenvman.2024.121883
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199144663&doi=10.1016%2fj.jenvman.2024.121883&partnerID=40&md5=431cd657b062fe1c517282dd5b58dad7
AB  - Ozone pollution is the focus of current environmental governance in China and high-quality prediction of ozone concentration is the prerequisite to effective policymaking. The studied ozone pollution time series exhibits distinct seasonality and secular trends and is associated with various factors. This study developed an interpretable hybrid model by combining STL decomposition and the Transformer (STL-Transformer) with the prior information of ozone time series and global multi-source information as prediction basis. The STL decomposition decomposes ozone time series into trend, seasonal, and remainder components. Then, the three components, along with other air quality and meteorological data, are integrated into the input sequence of the Transformer. The experiment results show that the STL-Transformer outperforms the other five state-of-the-art models, including the standard Transformer. Specially, the univariate forecasting for ozone relies on mimicking the patterns and trends that have occurred in the past. In contrast, multivariate forecasting can effectively capture complex relationships and dependencies involving multiple variables. The method successfully grasps the prior and global multi-source information and simultaneously improves the interpretability of ozone prediction with high precision. This study provides new insights for air pollution forecasting and has reliable theoretical value and practical significance for environmental governance. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; 
LB  - Mu2024Transformer-based
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Liu, W.
AU  - Yang, H.
TI  - Deep causal inference for understanding the impact of meteorological variations on traffic
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 165
C7  - 104744
DO  - 10.1016/j.trc.2024.104744
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198394744&doi=10.1016%2fj.trc.2024.104744&partnerID=40&md5=dad7b7fe48aa17b32d73a96609944082
AB  - Understanding the causal impact of meteorological variations on traffic conditions (e.g., traffic flow and speed) is crucial for effective traffic prediction and management, as well as the mitigation of adverse weather effects on traffic. However, many existing studies focused on establishing associations between meteorological situations and traffic, rather than delving into causal relationships, especially with deep learning techniques. Consequently, the ability to identify specific meteorological conditions that significantly contribute to traffic congestion or delays is still limited. To address this issue, this study proposes the Meteorological-Traffic Causal Inference Variational Auto-Encoder Model (MT-CIVAE) to estimate the causal impact of fine-grained meteorological variations (e.g., rain and temperature) on traffic. Specifically, MT-CIVAE is based on the Variational Auto-Encoder and consists of an encoder to recover the distribution of latent confounders and a decoder to estimate the conditional probabilities of treatments. Transformer encoder layers are incorporated to analyze the spatial and temporal correlations of historical traffic data to further enhance the inference capability. To evaluate the effectiveness of the proposed approach for causal inference, real-world traffic flow and speed datasets collected from California, along with corresponding fine-grained meteorological datasets, are employed. The counterfactual analysis is conducted using artificially generated meteorological conditions as treatments, which allows for the simulation of hypothetical meteorological scenarios and the evaluation of their potential impact on traffic conditions. This study develops deep learning methods for assessing the causal impact of meteorological variations on traffic dynamics, offering explanations and insights that can assist transportation institutions in guiding post-meteorology traffic management strategies. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; 
LB  - Li2024Deep
ER  -

TY  - JOUR
AU  - Sun, J.
AU  - Zhai, J.
TI  - MCNet: Multivariate long-term time series forecasting with local and global context modeling
PY  - 2024
T2  - Information Sciences
VL  - 676
C7  - 120864
DO  - 10.1016/j.ins.2024.120864
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195031425&doi=10.1016%2fj.ins.2024.120864&partnerID=40&md5=4f52ef4ed4ca6022e00f624793070fc9
AB  - Time series data typically exhibit various intra-sequence and inter-sequence correlations, resulting in intricate, intertwined dependencies, which pose challenges for accurately predicting future long-term trends. Previous studies have not fully considered the two correlations, and they also still face challenges of excessive time and memory complexity when dealing with long-term predictions. To address these challenges and establish high-precision prediction models, we propose MCNet that consists of a local branch and a global branch. The local branch aims at capturing short-term variations of intra-sequences, as well as capturing inter-sequence correlations. The global branch models long-term dependencies within sequences. Specifically, the local branch consists only of MLP module, which effectively captures short-term variations of intra-sequences by independently modeling the temporal information within and between patches of the most recent time series. Subsequently, inter-sequence dependencies are captured through the channel interaction module, which further explores more key information to improve the performance of MCNet. Meanwhile, global branch models long-term dependencies within the time series through structured global convolution. Experimental results on multiple popular long-term time series forecasting benchmarks demonstrate that MCNet outperforms state-of-the-art methods, yielding a relative improvement of 12% for multivariate time series while also being more efficient. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Sun2024MCNet
ER  -

TY  - JOUR
AU  - Mena, G.
AU  - Coussement, K.
AU  - De Bock, K.W.
AU  - De Caigny, A.
AU  - Lessmann, S.
TI  - Exploiting time-varying RFM measures for customer churn prediction with deep neural networks
PY  - 2024
T2  - Annals of Operations Research
VL  - 339
IS  - 1-2
SP  - 765
EP  - 787
DO  - 10.1007/s10479-023-05259-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150436491&doi=10.1007%2fs10479-023-05259-9&partnerID=40&md5=9d2ff25f3729b6123263555a3e266049
AB  - Deep neural network (DNN) architectures such as recurrent neural networks and transformers display outstanding performance in modeling sequential unstructured data. However, little is known about their merit to model customer churn with time-varying data. The paper provides a comprehensive evaluation of the ability of recurrent neural networks and transformers for customer churn prediction (CCP) using time-varying behavioral features in the form of recency, frequency, and monetary value (RFM). RFM variables are the backbone of CCP and, more generally, customer behavior forecasting. We examine alternative strategies for integrating time-varying and non-variant customer features in one network architecture. In this scope, we also assess hybrid approaches that incorporate the outputs of DNNs in conventional CCP models. Using a comprehensive panel data set from a large financial services company, we find recurrent neural networks to outperform transformer architectures when focusing on time-varying RFM features. This finding is confirmed when time-invariant customer features are included, independent of the specific form of feature integration. Finally, we find no statistical evidence that hybrid approaches (based on regularized logistic regression and extreme gradient boosting) improve predictive performance—highlighting that DNNs and especially recurrent neural networks are suitable standalone classifiers for CCP using time-varying RFM measures. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Mena2024Exploiting
ER  -

TY  - JOUR
AU  - Zhang, G.P.
AU  - Xia, Y.
AU  - Xie, M.
TI  - Intermittent demand forecasting with transformer neural networks
PY  - 2024
T2  - Annals of Operations Research
VL  - 339
IS  - 1-2
SP  - 1051
EP  - 1072
DO  - 10.1007/s10479-023-05447-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162732740&doi=10.1007%2fs10479-023-05447-7&partnerID=40&md5=901011c95349939dc6fbb5ce1fb51a0c
AB  - Intermittent demand forecasting is an important yet challenging task in many organizations. While prior research has been focused on traditional methods such as Croston’s method and its variants, limited research has been conducted using advanced machine learning or deep learning methods. In this study, we introduce Transformer, a recently developed deep learning approach, to forecast intermittent demand. Its effectiveness is empirically tested with a dataset of 925 intermittent demand items from an airline spare parts provider and compared with that of two traditional methods such as Croston’s and the Syntetos–Boylan approximation as well as several popular neural network architectures including feedforward neural networks, recurrent neural networks, and long short-term memory. Our results based on six different forecasting performance measures show that Transformer performs very well against other methods in a variety of settings. We also examine how data sparsity impacts model performance and find that different models perform similarly when sparsity is low. Although the performance of all models generally gets worse as the sparsity level increases, the advantage of Transformer over other models increases with sparsity. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Zhang2024Intermittent
ER  -

TY  - JOUR
AU  - Zhuo, X.
AU  - Qian, S.
AU  - Hu, J.
AU  - Dai, F.
AU  - Lin, K.
AU  - Wu, G.
TI  - Multi-Hop Multi-View Memory Transformer for Session-Based Recommendation
PY  - 2024
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 6
C7  - 144
DO  - 10.1145/3663760
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202975023&doi=10.1145%2f3663760&partnerID=40&md5=8002ba0e5a391d07f3d42d7f91db7725
AB  - A Session-Based Recommendation (SBR) seeks to predict users' future item preferences by analyzing their interactions with previously clicked items. In recent approaches, Graph Neural Networks (GNNs) have been commonly applied to capture item relations within a session to infer user intentions. However, these GNN-based methods typically struggle with feature ambiguity between the sequential session information and the item conversion within an item graph, which may impede the model's ability to accurately infer user intentions. In this article, we propose a novel Multi-hop Multi-view Memory Transformer (M3T) to effectively integrate the sequence-view information and relation conversion (graph-view information) of items in a session. First, we propose a Multi-view Memory Transformer (M2T) module to concurrently obtain multi-view information of items. Then, a set of trainable memory matrices are employed to store sharable item features, which mitigates cross-view item feature ambiguity. To comprehensively capture latent user intentions, an M3T framework is designed to integrate user intentions across different hops of an item graph. Specifically, a k-order power method is proposed to manage the item graph to alleviate the over-smoothing problem when obtaining high-order relations of items. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our method.  © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Zhuo2024Multi-Hop
ER  -

TY  - JOUR
AU  - Bao, H.-W.-S.
TI  - The Fill-Mask Association Test (FMAT): Measuring Propositions in Natural Language
PY  - 2024
T2  - Journal of Personality and Social Psychology
VL  - 127
IS  - 3
SP  - 537
EP  - 561
DO  - 10.1037/pspa0000396
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191325590&doi=10.1037%2fpspa0000396&partnerID=40&md5=eaeb7f726d2c3f0675090162ce267b23
AB  - Recent advances in large language models are enabling the computational intelligent analysis of psychology in natural language. Here, the Fill-Mask Association Test (FMAT) is introduced as a novel and integrative method leveraging Masked Language Models to study and measure psychology from a propositional perspective at the societal level. The FMAT uses Bidirectional Encoder Representations from Transformers (BERT) models to compute semantic probabilities of option words filling in the masked blank of a designed query (i.e., a clozelike contextualized sentence). The current research presents 15 studies that establish the reliability and validity of the FMAT in predicting factual associations (Studies 1A–1C), measuring attitudes/ biases (Studies 2A–2D), capturing social stereotypes (Studies 3A–3D), and retrospectively delineating lay perceptions of sociocultural changes over time (Studies 4A–4D). Empirically, the FMAT replicated seminal findings previously obtained with human participants (e.g., the Implicit Association Test) and other big-data text-analytic methods (e.g., word frequency analysis, the Word Embedding Association Test), demonstrating robustness across 12 BERT model variants and diverse training text corpora. Theoretically, the current findings substantiate the propositional (vs. associative) perspective on how semantic associations are represented in natural language. Methodologically, the FMAT allows for more fine-grained language-based psychological measurement, with an R package developed to streamline its workflow for use on broader research questions. © 2024 American Psychological Association
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:4; ZUFE:1A; zdy:4; 
LB  - Bao2024Fill-Mask
ER  -

TY  - JOUR
AU  - Paeedeh, N.
AU  - Pratama, M.
AU  - Wibirama, S.
AU  - Mayer, W.
AU  - Cao, Z.
AU  - Kowalczyk, R.
TI  - Few-shot class incremental learning via robust transformer approach
PY  - 2024
T2  - Information Sciences
VL  - 675
C7  - 120751
DO  - 10.1016/j.ins.2024.120751
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193934831&doi=10.1016%2fj.ins.2024.120751&partnerID=40&md5=80eb993f004590655574aa86322be9b7
AB  - Few-Shot Class-Incremental Learning (FSCIL)presents an extension of the Class Incremental Learning (CIL)problem where a model is faced with the problem of data scarcity while addressing the Catastrophic Forgetting (CF)problem. This problem remains an open problem because all recent works are built upon the Convolutional Neural Networks (CNNs)performing sub-optimally compared to the transformer approaches. Our paper presents Robust Transformer Approach (ROBUSTA)built upon the Compact Convolutional Transformer (CCT). The issue of overfitting due to few samples is overcome with the notion of the stochastic classifier, where the classifier's weights are sampled from a distribution with mean and variance vectors, thus increasing the likelihood of correct classifications, and the batch-norm layer to stabilize the training process. The issue of CFis dealt with the idea of delta parameters, small task-specific trainable parameters while keeping the backbone networks frozen. A non-parametric approach is developed to infer the delta parameters for the model's predictions. The prototype rectification approach is applied to avoid biased prototype calculations due to the issue of data scarcity. The advantage of ROBUSTAis demonstrated through a series of experiments in the benchmark problems where it is capable of outperforming prior arts with big margins without any data augmentation protocols. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Paeedeh2024Few-shot
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Xu, Y.
AU  - Law, R.
AU  - Wang, S.
TI  - Enhancing tourism demand forecasting with a transformer-based framework
PY  - 2024
T2  - Annals of Tourism Research
VL  - 107
C7  - 103791
DO  - 10.1016/j.annals.2024.103791
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194049607&doi=10.1016%2fj.annals.2024.103791&partnerID=40&md5=47e181c735e846b4769df9ada547c475
AB  - This study introduces an innovative framework that harnesses the most recent transformer architecture to enhance tourism demand forecasting. The proposed transformer-based model integrates the tree-structured parzen estimator for hyperparameter optimization, a robust time series decomposition approach, and a temporal fusion transformer for multivariate time series prediction. Our novel approach initially employs the decomposition method to decompose the data series to effectively mitigate the influence of outliers. The temporal fusion transformer is subsequently utilized for forecasting, and its hyperparameters are meticulously fine-tuned by a Bayesian-based algorithm, culminating in a more efficient and precise model for tourism demand forecasting. Our model surpasses existing state-of-the-art methodologies in terms of forecasting accuracy and robustness. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Li2024Enhancing
ER  -

TY  - JOUR
AU  - Qin, Y.
AU  - Ju, W.
AU  - Wu, H.
AU  - Luo, X.
AU  - Zhang, M.
TI  - Learning Graph ODE for Continuous-Time Sequential Recommendation
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 7
SP  - 3224
EP  - 3236
DO  - 10.1109/TKDE.2024.3349397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181576796&doi=10.1109%2fTKDE.2024.3349397&partnerID=40&md5=65b8961219d46a6e2fbb3575cd3dfb1a
AB  - Sequential recommendation aims at understanding user preference by capturing successive behavior correlations, which are usually represented as the item purchasing sequences based on their past interactions. Existing efforts generally predict the next item via modeling the sequential patterns. Despite effectiveness, there exist two natural deficiencies: (i) user preference is dynamic in nature, and the evolution of collaborative signals is often ignored; and (ii) the observed interactions are often irregularly-sampled, while existing methods model item transitions assuming uniform intervals. Thus, how to effectively model and predict the underlying dynamics for user preference becomes a critical research problem. To tackle the above challenges, in this paper, we focus on continuous-time sequential recommendation and propose a principled graph ordinary differential equation framework named GDERec. Technically, GDERec is characterized by an autoregressive graph ordinary differential equation consisting of two components, which are parameterized by two tailored graph neural networks (GNNs) respectively to capture user preference from the perspective of hybrid dynamical systems. On the one hand, we introduce a novel ordinary differential equation based GNN to implicitly model the temporal evolution of the user-item interaction graph. On the other hand, an attention-based GNN is proposed to explicitly incorporate collaborative attention to interaction signals when the interaction graph evolves over time. The two customized GNNs are trained alternately in an autoregressive manner to track the evolution of the underlying system from irregular observations, and thus learn effective representations of users and items beneficial to the sequential recommendation. Extensive experiments on five benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:A期刊; FMS:B; 
LB  - Qin2024Learning
ER  -

TY  - JOUR
AU  - Lin, J.
AU  - Michailidis, G.
TI  - A multi-task encoder-dual-decoder framework for mixed frequency data prediction
PY  - 2024
T2  - International Journal of Forecasting
VL  - 40
IS  - 3
SP  - 942
EP  - 957
DO  - 10.1016/j.ijforecast.2023.08.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172869064&doi=10.1016%2fj.ijforecast.2023.08.003&partnerID=40&md5=0cf86c642377ed476d5556438512d939
AB  - Mixed-frequency data prediction tasks are pertinent in various application domains, in which one leverages progressively available high-frequency data to forecast/nowcast the low-frequency ones. Existing methods in the literature tailored to such tasks are mostly linear in nature; depending on the specific formulation, they largely rely on the assumption that the (latent) processes that govern the dynamics of the high- and low-frequency blocks of variables evolve at the same frequency, either the low or the high one. This paper develops a neural network-based multi-task shared-encoder-dual-decoder framework for joint multi-horizon prediction of both the low- and high-frequency blocks of variables, wherein the encoder/decoder modules can be either long short-term memory or transformer ones. It addresses forecast/nowcast tasks in a unified manner, leveraging the encoder–decoder structure that can naturally accommodate the mixed-frequency nature of the data. The proposed framework exhibited competitive performance when assessed on both synthetic data experiments and two real datasets of US macroeconomic indicators and electricity data. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Lin2024multi-task
ER  -

TY  - JOUR
AU  - Zhuo, X.
AU  - Wu, G.
AU  - Zhang, Z.
AU  - Wu, X.
TI  - Geometric-Contextual Mutual Infomax Path Aggregation for Relation Reasoning on Knowledge Graph
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 7
SP  - 3076
EP  - 3090
DO  - 10.1109/TKDE.2024.3360258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184314522&doi=10.1109%2fTKDE.2024.3360258&partnerID=40&md5=255a893844a6b62b54a74f2bcaa70083
AB  - Relation reasoning in Knowledge Graph Completion (KGC) aims at predicting missing relations between entities. Recently, effective KGC methods have usually focused on exploring the path pattern between entities, such as reward-based path walking and path context mining, to complete target relations. However, these methods typically suffer from two challenges: 1) They have difficulty in handling the individual representation limitation of candidate paths when there are no paths that directly represent latent relations between entities; 2) They overlook the biases of path context induction, which leads to unreasonable information interfering with the model's reasoning. To manage these challenges, a Geometric-Contextual Mutual Infomax (GCMI) path aggregator is proposed for relation reasoning. First, we design an attentive path aggregator with a shared Transformer encoder to capture the contexts from several candidate paths parallelly and integrate these contexts to sufficiently represent the latent relations of each entity pair for reasoning. Then, the GCMI modules are proposed to constrain the local and global biases of path context induction in the Transformer encoder and the path aggregator, respectively, by a straightforward geometric rule. Extensive experiments on 32 real-world relation reasoning tasks demonstrate that our method significantly outperforms 8 state-of-the-art baselines in terms of AP and AUC. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Zhuo2024Geometric-Contextual
ER  -

TY  - JOUR
AU  - Yu, X.
AU  - Qin, C.
AU  - Shen, D.
AU  - Ma, H.
AU  - Zhang, L.
AU  - Zhang, X.
AU  - Zhu, H.
AU  - Xiong, H.
TI  - RDGT: Enhancing Group Cognitive Diagnosis With Relation-Guided Dual-Side Graph Transformer
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 7
SP  - 3429
EP  - 3442
DO  - 10.1109/TKDE.2024.3352640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182917696&doi=10.1109%2fTKDE.2024.3352640&partnerID=40&md5=9d673f532bbc4267a2fe1ec884027ac6
AB  - Cognitive diagnosis has been widely recognized as a crucial task in the field of computational education, which is capable of learning the knowledge profiles of students and predicting their future exercise performance. Indeed, considerable research efforts have been made in this direction over the past decades. However, most of the existing studies only focus on individual-level diagnostic modeling, while the group-level cognitive diagnosis still lacks an in-depth exploration, which is more compatible with realistic collaborative learning environments. To this end, in this paper, we propose a Relation-guided Dual-side Graph Transformer (RDGT) model for achieving effective group-level cognitive diagnosis. Specifically, we first construct the dual-side relation graphs (i.e., student-side and exercise-side) from the group-student-exercise heterogeneous interaction data for explicitly modeling associations between students and exercises, respectively. In particular, the edge weight between two nodes is defined based on the similarity of corresponding student-exercise interactions. Then, we introduce two relation-guided graph transformers to learn the representations of students and exercises by integrating the whole graph information, including both nodes and edge weights. Meanwhile, the inter-group information has been incorporated into the student-side relation graph to further enhance the representations of students. Along this line, we design a cognitive diagnosis module for learning the groups' proficiency in specific knowledge concepts, which includes an attention-based aggregation strategy to obtain the final group representation and a hybrid loss for optimizing the performance prediction of both group and student. Finally, extensive experiments on 5 real-world datasets clearly demonstrate the effectiveness of our model as well as some interesting findings (e.g., the representative groups and potential collaborations among students). © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:A期刊; FMS:B; 
LB  - Yu2024RDGT
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Zhang, D.
AU  - Liu, G.
AU  - Huang, L.
AU  - Qin, K.
TI  - Enhancing relation extraction using multi-task learning with SDP evidence
PY  - 2024
T2  - Information Sciences
VL  - 670
C7  - 120610
DO  - 10.1016/j.ins.2024.120610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190323295&doi=10.1016%2fj.ins.2024.120610&partnerID=40&md5=be97f12aec05468038c2b64b0d98dfa2
AB  - Relation extraction (RE) is a crucial subtask of information extraction, which involves recognizing the relation between entity pairs in a sentence. Previous studies have extensively employed syntactic information, notably the shortest dependency path (SDP), to collect word evidence, termed SDP evidence, which gives clues about the given entity pair, thus improving RE. Nevertheless, prevalent transformer-based techniques lack syntactic information and cannot effectively model essential syntactic clues to support relations. This study exerts multi-task learning to address these issues by imbibing an SDP token position prediction task into the RE task. To this end, we introduce SGA, an SDP evidence guiding approach that transfers the SDP evidence into two novel supervisory signal labels: SDP tokens label and SDP matrix label. The former guides the attention modules to assign high attention weights to SDP token positions, emphasizing relational clues. In the meantime, the latter supervises SGA to predict a parameterized asymmetric product matrix among the SDP tokens for RE. Experimental outcomes demonstrate the model's enhanced ability to leverage SDP information, thereby directing attention modules and predicted matrix labels to focus on SDP evidence. Consequently, our proposed approach surpasses existing publicly available optimal baselines across four RE datasets: SemEval2010-Task8, KBP37, NYT, and WebNLG.1 © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2024Enhancing
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Li, W.
AU  - Hu, C.
AU  - Xie, T.
AU  - Jiang, Y.
AU  - Li, R.
AU  - Soomro, S.-E.-E.
AU  - Xu, Y.
TI  - Research on runoff process vectorization and integration of deep learning algorithms for flood forecasting
PY  - 2024
T2  - Journal of Environmental Management
VL  - 362
C7  - 121260
DO  - 10.1016/j.jenvman.2024.121260
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194955730&doi=10.1016%2fj.jenvman.2024.121260&partnerID=40&md5=518394fde1d199c10f3aad1a0a29c2a6
AB  - Accurate multi-step ahead flood forecasting is crucial for flood prevention and mitigation efforts as well as optimizing water resource management. In this study, we propose a Runoff Process Vectorization (RPV) method and integrate it with three Deep Learning (DL) models, namely Long Short-Term Memory (LSTM), Temporal Convolutional Network (TCN), and Transformer, to develop a series of RPV-DL flood forecasting models, namely RPV-LSTM, RPV-TCN, and RPV-Transformer models. The models are evaluated using observed flood runoff data from nine typical basins in the middle Yellow River region. The key findings are as follows: Under the same lead time conditions, the RPV-DL models outperform the DL models in terms of Nash-Sutcliffe efficiency coefficient, root mean square error, and relative error for peak flows in the nine typical basins of the middle Yellow River region. Based on the comprehensive evaluation results of the train and test periods, the RPV-DL model outperforms the DL model by an average of 2.82%–22.21% in terms of NSE across nine basins, with RMSE and RE reductions of 10.86–28.81% and 36.14%–51.35%, respectively. The vectorization method significantly improves the accuracy of DL flood forecasting, and the RPV-DL models exhibit better predictive performance, particularly when the lead time is 4h–6h. When the lead time is 4–6h, the percentage improvement in NSE is 9.77%, 15.07%, and 17.94%. The RPV-TCN model shows superior performance in overcoming forecast errors among the nine basins. The research findings provide scientific evidence for flood prevention and mitigation efforts in river basins. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:B; 
LB  - Liu2024Research
ER  -

TY  - JOUR
AU  - Xiao, J.
AU  - Long, B.
TI  - A multi-channel spatial-temporal transformer model for traffic flow forecasting
PY  - 2024
T2  - Information Sciences
VL  - 671
C7  - 120648
DO  - 10.1016/j.ins.2024.120648
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191339568&doi=10.1016%2fj.ins.2024.120648&partnerID=40&md5=83208979d22afe239f676c8c3019f41b
AB  - Traffic flow forecasting is a crucial task in transportation management and planning. The main challenges for traffic flow forecasting are that (1) as the length of prediction time increases, the accuracy of prediction will decrease; (2) the predicted results greatly rely on the extraction of temporal and spatial dependencies from the road networks. To overcome the challenges mentioned above, we propose a multi-channel spatial-temporal transformer model for traffic flow forecasting, which improves the accuracy of the prediction by fusing results from different channels of traffic data. Our approach leverages graph convolutional network to extract spatial features from each channel while using a transformer-based architecture to capture temporal dependencies across channels. We introduce an adaptive adjacency matrix to overcome limitations in feature extraction from fixed topological structures. Experimental results on six real-world datasets demonstrate that introducing a multi-channel mechanism into the temporal model enhances performance and our proposed model outperforms state-of-the-art models in terms of accuracy. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Xiao2024multi-channel
ER  -

TY  - JOUR
AU  - Benrachou, D.E.
AU  - Glaser, S.
AU  - Elhenawy, M.
AU  - Rakotonirainy, A.
TI  - Improving Efficiency and Generalisability of Motion Predictions with Deep Multi-Agent Learning and Multi-Head Attention
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 5356
EP  - 5373
DO  - 10.1109/TITS.2023.3339640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181804783&doi=10.1109%2fTITS.2023.3339640&partnerID=40&md5=ad3f40a3bf0efa8c2abf6074da9c0e64
AB  - Automated Vehicles (AVs) have been receiving increasing attention as a potential highly mechanised, intelligent, self-regulating futuristic mode of transport. AVs are predicted to address limitations and human factors associated with traditional modes of transportation. Beyond the typical operations of AVs which can perform rudimentary tasks, the intelligent embedded program fit in to process challenging scenarios and deep multi-dimensional/ agent intents and interaction of the roadway is the grey area yet to be explored to design an exclusive encoding of social functionality and operation in order to address human factors causing road crashes. The aim of this study is to design a data-driven prediction framework for AVs that utilises multiple inputs to prove a multimodal, probabilistic estimate of the future intentions and trajectories of surrounding vehicles in freeway operation. Our proposed framework is a deep multi-agent learning-based system designed to effectively capture social interactions between vehicles without relying on map information. Our approach excels in capturing the high-level behaviours of multiple vehicles and generating a multi-modal trajectory forecast. It employs a multi-headed neural architecture to learn from social interactions between vehicle pairs and generates diverse trajectories proportional to predicted target intents, thus enabling feature fusion. Additionally, a multi-head self-attention mechanism is incorporated for prediction refinement. We achieved a good prediction performance with a lower prediction error in real traffic data at highways. Evaluation of the proposed framework using the NGSIM (US-101 and I-80) and HighD datasets shows satisfactory prediction performance for long-term trajectory prediction of multiple surrounding vehicles. Additionally, the proposed framework has higher prediction accuracy and generalisability than state-of-the-art approaches. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Benrachou2024Improving
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - He, S.
AU  - Liu, H.
AU  - Chen, J.
AU  - Dong, H.
TI  - WindTrans: Transformer-Based Wind Speed Forecasting Method for High-Speed Railway
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 4947
EP  - 4963
DO  - 10.1109/TITS.2023.3337150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182947459&doi=10.1109%2fTITS.2023.3337150&partnerID=40&md5=6804eb6652caa4cbc75449a2b213244c
AB  - Wind speed forecasting provides the upcoming wind information and is important to the safe operation of High-Speed Railway (HSR). However, it remains a challenge due to the stochastic and highly varying characteristics of wind. In this paper, we propose a novel Transformer-based method for short-term wind speed forecasting, named WindTrans. Two major cruxes are addressed. First, the task is performed on fine-grained wind speed gathered from multiple sensors. These data present dynamic intra-series and inter-series correlations, which are hard for previous methods to recover. We advance a Transformer-based deep learning model, which has two distinctive characteristics: (1) a graph encoder, which captures the dynamic spatial correlation among wind speeds at different locations, and (2) a temporal decoder to model long sequence wind speed time series, which is resistant to noise in time series. Second, wind speed patterns gradually evolve in long-term periods, thus deactivating prediction models trained on historical data. To tackle this bottleneck, we put forward an experience replay-based scheme to renew the model regularly. To ensure that the renewed model still dominates historical wind patterns, we store and replay only a small portion of historical data named episodic memory. A simple but efficient strategy is designed to constitute episodic memory and thus relieve the computation burden. Experiments conducted on two real-world datasets demonstrate the superiority of our method over existing approaches. Particularly, WindTrans surpasses state-of-the-art methods by up to 36.7%, 29.3% and 13.3% improvement in MAPE measure for 1 hour ahead prediction on 10-minute, 5-minute, and 1-minute-based tasks, respectively. Furthermore, via our continual learning scheme, the model retains competitive performance with only 6.9% datum stored and retrained on. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Liu2024WindTrans
ER  -

TY  - JOUR
AU  - Zhu, W.
AU  - Xi, Z.
AU  - Hu, C.
AU  - Zhao, B.
AU  - Niu, Y.
TI  - Passenger Comfort Quantification for Automated Vehicle Based on Stacking of Psychophysics Mechanism and Encoder-Transformer Model
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 5211
EP  - 5224
DO  - 10.1109/TITS.2023.3337775
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180348108&doi=10.1109%2fTITS.2023.3337775&partnerID=40&md5=f05f4293f228366611ac11d9cde5813e
AB  - Passenger comfort is a crucial aspect that influences humans' acceptance of automated vehicles. The passenger comfort score (PCS) is closely related to the passengers' psychological states, however, comfort quantification methods based on the passengers' psychophysics mechanism are rare. This research pioneers a passenger comfort quantification model (PCQM) specifically designed for automated vehicles, demonstrating the model's ability to accurately quantify subjective PCS under urban LCS. Three significant contributions form the basis of this study: 1) A dataset dedicated to comfort quantification is collected. A novel PCQM based on ensemble learning of psychophysics mechanism based sub-model and encoder-transformer based sub-model is proposed. The psychophysics mechanism model is derived from Stevens' power law. 2) As a subjective indicator, the self-reported score (SRS), which is the indicator of PCS contains considerable noise. The PCQM addresses the issue of substantial noise prevalent in the subjective SRS by incorporating a semi-supervised learning strategy, which enhances data consistency and suppresses noise. 3) The efficacy of the proposed PCQM is corroborated via deployment on an automated vehicle, where the model's real-time predictions strongly align with SRS from onboard passengers. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhu2024Passenger
ER  -

TY  - JOUR
AU  - Bai, S.
AU  - Yang, L.
AU  - Liu, Y.
AU  - Yu, H.
TI  - DMF-Net: A Dual-Encoding Multi-Scale Fusion Network for Pavement Crack Detection
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 5981
EP  - 5996
DO  - 10.1109/TITS.2023.3331769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184801141&doi=10.1109%2fTITS.2023.3331769&partnerID=40&md5=a435187e7d113592a7a554868f908009
AB  - Currently, cracks are the most common defect in pavement diseases. Long-term non-maintenance can lead to crack lengthening and expansion, causing serious traffic accidents, as well as shortening the service life of pavement cracks. Therefore, it is of utmost importance to maintain cracks at an early stage. Due to the effect of some challenging factors, such as various shape information of the cracks, complex textured backgrounds, light shadows, similar texture objects, micro cracks and other factors, accurate crack detection still faces a certain challenges. To solve the above problems, a dual-encoding multi-scale fusion network based on the combination of convolutional neural network (CNN) and transformer network is proposed, named DMF-Net. To obtain stronger feature representations, a dual-encoding path is built to acquire global context features and local detail information simultaneously, where global context features are extracted based on the transformer branch, and the local detail features are extracted based on the CNN branch to detect tiny details of the cracks. Meanwhile, an interactive attention learning (IAL) module is introduced to effectively fuse the global features from the transformer branch and the local detail information from the CNN branch, achieving mutual communication and learning of different feature information. In addition, to enrich the feature representation ability, an attention-based feature enhancement (AFE) module is introduced to acquire more global contexts. Furthermore, faced with the crack detection task with class imbalance issue, a triple attention module (TAM) is built to emphasize the micro cracks. Finally, in the segmentation prediction stage, the deep supervision mechanism is also introduced to accelerate the convergence speed of the model, and serve effective multi-scale feature fusion. Compared with the current mainstream segmentation models, excellent performance has been obtained, which could provide a feasible scheme for the early maintenance of pavement cracks. The source code about proposed DMF-Net is available at https://github.com/Bsl1/DMFNet.git. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; FMS:B; 
LB  - Bai2024DMF-Net
ER  -

TY  - JOUR
AU  - Huang, S.
AU  - Liu, Y.
AU  - Cui, H.
AU  - Zhang, F.
AU  - Li, J.
AU  - Zhang, X.
AU  - Zhang, M.
AU  - Zhang, C.
TI  - MEAformer: An all-MLP transformer with temporal external attention for long-term time series forecasting
PY  - 2024
T2  - Information Sciences
VL  - 669
C7  - 120605
DO  - 10.1016/j.ins.2024.120605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190243936&doi=10.1016%2fj.ins.2024.120605&partnerID=40&md5=bb25f17f4de6888dd0e4c1d735f69544
AB  - Transformer-based models have significantly improved performance in Long-term Time Series Forecasting (LTSF). These models employ various self-attention mechanisms to discover long-term dependencies. However, the computational efficiency is hampered by the inherent permutation invariance of self-attention, and they primarily focus on relationships within the sequence while neglecting potential relationships between different sample sequences. This limits the ability and flexibility of self-attention in LTSF. In addition, the Transformer's decoder outputs sequences in an autoregressive manner, leading to slow inference speed and error accumulation effects, especially for LTSF. Regarding the issues with Transformer-based models for LTSF, we propose a model better suited for LTSF, named MEAformer. MEAformer adopts a fully connected Multi-Layer Perceptron (MLP) architecture consisting of two types of layers: encoder layers and MLP layers. Unlike most encoder layers in Transformer-based models, the MEAformer replaces self-attention with temporal external attention. Temporal external attention explores potential relationships between different sample sequences in the training dataset. Compared to the quadratic complexity of self-attention mechanisms, temporal external attention has efficient linear complexity. Encoder layers can be stacked multiple times to capture time-dependent relationships at different scales. Furthermore, the MEAformer replaces the intricate decoder layers of the original model with more straightforward MLP layers. This modification aims to enhance inference speed and facilitate single-pass sequence generation, effectively mitigating the problem of error accumulation effects. Regarding long-term forecasting, MEAformer achieves state-of-the-art performance on six benchmark datasets, covering five real-world domains: energy, transportation, economy, weather, and disease. Code is available at: https://github.com/huangsiyuan924/MEAformer. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2024MEAformer
ER  -

TY  - JOUR
AU  - Bian, M.
AU  - Ren, Y.
AU  - He, G.
AU  - Feng, G.
AU  - Zhang, X.
TI  - VMMP: Verifiable privacy-preserving multi-modal multi-task prediction
PY  - 2024
T2  - Information Sciences
VL  - 669
C7  - 120547
DO  - 10.1016/j.ins.2024.120547
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189608457&doi=10.1016%2fj.ins.2024.120547&partnerID=40&md5=db12f5869e8c14caefc5773fcf81d24c
AB  - Transformer is emerging as a promising model with intrinsic traits in various multi-modal applications. Edge computing has provided an efficient platform for computationally-weak clients, but this entails risks to confidential data and proprietary models. Prior works on the privacy-preserving transformer-based inference only process a single modal data and protect confidential data or model parameters, or approximate non-linear functions with utility degradation. To mitigate the aforementioned issues, we propose the first verifiable outsourcing framework for multi-modal multi-task prediction (VMMP) via the additive secret sharing technique in an edge computing paradigm, which not only ensures the confidentiality of local data and model parameters but also guarantees the verifiability of prediction results. The security analysis and computational consumption reveal that VMMP can save the time costs of clients by 87%, 30%, and 40% compared to the original model on three types of cross-modal tasks and achieves significant time cost savings on the client side compared to the previous works in a secure manner. To evaluate the effective utility, VMMP is examined on three public datasets across visual and language modalities. Extensive evaluations indicate that VMMP outperforms the related works without utility degradation. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Bian2024VMMP
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, H.
AU  - Deng, F.
AU  - Liang, J.
AU  - Yang, J.
TI  - Stochastic Non-Autoregressive Transformer-Based Multi-Modal Pedestrian Trajectory Prediction for Intelligent Vehicles
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3561
EP  - 3574
DO  - 10.1109/TITS.2023.3342040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181818146&doi=10.1109%2fTITS.2023.3342040&partnerID=40&md5=adf2a2e89976d4ceca7e95593c36ede9
AB  - Pedestrian trajectory prediction, which aims at predicting the future positions of all pedestrians in a crowd scene given their past trajectories, is the cornerstone of autonomous driving and intelligent transportation systems. Accurate prediction and fast inference are both indispensable for real-world applications. In this paper, we propose a stochastic non-autoregressive Transformer-based multi-modal trajectory prediction model to address the two challenges. Specifically, a novel graph attention module dedicated to joint learning of social and temporal interaction is proposed to explore the complex interaction among pedestrians while integrating sparse attention mechanism, pedestrian identity, and temporal order contained in the trajectory data. By doing so, the interaction across temporal and social dimensions can be simultaneously processed to extract abundant context features for prediction. Besides, to accelerate inference speed, we put forward a stochastic non-autoregressive Transformer model with multi-modal prediction capability where each future trajectory can be inferred in a parallel fashion, therefore, resulting in diverse trajectory predictions and less computational cost. Extensive experiments and ablation studies are performed to evaluate our approach. The empirical results demonstrate that the proposed model not only produces high prediction accuracy but also infers with fast speed. The code of the proposed method will be publicly available at https://github.com/xbchen82/SNARTF. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2024Stochastic
ER  -

TY  - JOUR
AU  - Govers, W.
AU  - Yurtman, A.
AU  - Aslandere, T.
AU  - Eikelenberg, N.
AU  - Meert, W.
AU  - Davis, J.
TI  - Time-Shifted Transformers for Driver Identification Using Vehicle Data
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3767
EP  - 3776
DO  - 10.1109/TITS.2023.3326652
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181563911&doi=10.1109%2fTITS.2023.3326652&partnerID=40&md5=e8d6a36fe55a89ded82f5194f2ab9f67
AB  - A modern vehicle contains a large number of electronic control units and sensors that are connected to cloud environments. These electronic units generate a huge amount of data that can be leveraged to identify the current driver and adapt to their behavior. For example, driver identification can improve the accuracy of range estimation in battery electric vehicles. This study focuses on identifying drivers based on their behaviour by using multivariate time series data acquired by the sensors available in the vehicle. We propose two different classifiers: one based on Bi-directional stacked Long Short-Term Memory with Attention mechanism (BiLSTM-A) and another based on a Modified Time Series Transformer (MTST). We perform driver identification in two different ways: 1) by applying a classifier on a single time segment; and 2) by using our proposed time-shift ensembles to combine predictions made from multiple time segments. We experimentally evaluate the proposed techniques on a publicly available dataset that comprises 10 drivers. By using all appropriate features, the proposed BiLSTM-A and MTST classifiers identify the driver with an accuracy of 55% and 73%, respectively, from a single time segment of 60 seconds duration. Time-shift ensembles increase the accuracy substantially, to 92% for BiLSTM-A and 97% for MTST when a 460-second time period is used for each prediction. We conclude that the proposed MTST classifier outperforms BiLSTM-A and existing classifiers in the driver identification task, and time-shift ensembles substantially improve the accuracy.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Govers2024Time-Shifted
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Zhang, J.
AU  - Yang, L.
AU  - Wang, C.
AU  - Gao, Z.
TI  - COV-STFormer for Short-Term Passenger Flow Prediction during COVID-19 in Urban Rail Transit Systems
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3793
EP  - 3811
DO  - 10.1109/TITS.2023.3323379
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174831981&doi=10.1109%2fTITS.2023.3323379&partnerID=40&md5=c6cbb160c59d7278ad2cb36ab2255dc6
AB  - Accurate passenger flow prediction of urban rail transit systems (URT) is essential for improving the performance of intelligent transportation systems, especially during the epidemic. How to dynamically model the complex spatiotemporal dependencies of passenger flow is the main issue in achieving accurate passenger flow prediction during the epidemic. To solve this issue, this paper proposes a brand-new transformer-based architecture called COVID-19 Spatial-Temporal Transformer Network (COV-STFormer) under the encoder-decoder framework specifically for COVID-19. Concretely, a modified self-Attention mechanism named Causal-Convolution ProbSparse Self-Attention (CPSA) is developed to model the complex temporal dependencies of passenger flow. A novel Adaptive Multi-Graph Convolution Network (AMGCN) is introduced to capture the complex and dynamic spatial dependencies by leveraging multiple graphs in a self-Adaptive manner. Additionally, the Multi-source Data Fusion block fuses the passenger flow data, COVID-19 confirmed case data, and the relevant social media data to study the impact of COVID-19 to passenger flow. Experiments on real-world passenger flow datasets demonstrate the superiority of COV-STFormer over the other thirteen state-of-The-Art methods. Several ablation studies are carried out to verify the effectiveness and reliability of our model structure. Results can provide critical insights for the operation of URT systems.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2024COV-STFormer
ER  -

TY  - JOUR
AU  - Yang, J.
AU  - Chu, D.
AU  - Yin, J.
AU  - Pi, D.
AU  - Wang, J.
AU  - Lu, L.
TI  - Distributed Model Predictive Control for Heterogeneous Platoon with Leading Human-Driven Vehicle Acceleration Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3944
EP  - 3959
DO  - 10.1109/TITS.2023.3330941
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177997556&doi=10.1109%2fTITS.2023.3330941&partnerID=40&md5=1ff75152736f61504d5122f9418bcf93
AB  - Heterogeneous vehicle platoons, consisting of a human-driven vehicle (HDV) as the leader and connected automated vehicles (CAVs) as followers, present a promising solution to address various challenges arising from fully autonomous driving. In this paper, we propose a novel LSTM-based distributed model predictive control (DMPC) platooning method. Initially, we develop and train a vehicle acceleration prediction model based on a long short-Term memory (LSTM) network using real-world driving data. Subsequently, the predicted acceleration sequence of the leading HDV is integrated into the DMPC-based platoon control model for the following CAVs. To validate the effectiveness of our method, we conduct simulation experiments using real-world driving data. The results demonstrate that, with a time headway of 1 s, the maximum speed error and maximum spacing error of the heterogeneous vehicle platoon using the proposed LSTM-based DMPC are reduced by at least 5.8% and 5.9%, respectively, compared to the traditional DMPC method. Furthermore, the LSTM-based DMPC outperforms the Transformer-based DMPC method, resulting in a 1.0% reduction in maximum speed error and a 0.7% reduction in maximum spacing error. The proposed method effectively dampens oscillation caused by the leading HDV and enhances tracking accuracy.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2024Distributed
ER  -

TY  - JOUR
AU  - Shi, C.
AU  - Ren, P.
AU  - Fu, D.
AU  - Xin, X.
AU  - Yang, S.
AU  - Cai, F.
AU  - Ren, Z.
AU  - Chen, Z.
TI  - Diversifying Sequential Recommendation with Retrospective and Prospective Transformers
PY  - 2024
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 5
C7  - 132
DO  - 10.1145/3653016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195044918&doi=10.1145%2f3653016&partnerID=40&md5=84698a0b5729805ae7f001191a5a74fa
AB  - Previous studies on sequential recommendation (SR) have predominantly concentrated on optimizing recommendation accuracy. However, there remains a significant gap in enhancing recommendation diversity, particularly for short interaction sequences. The limited availability of interaction information in short sequences hampers the recommender's ability to comprehensively model users' intents, consequently affecting both the diversity and accuracy of recommendation. In light of the above challenge, we propose reTrospective and pRospective Transformers for dIversified sEquential Recommendation (TRIER). The TRIER addresses the issue of insufficient information in short interaction sequences by first retrospectively learning to predict users' potential historical interactions, thereby introducing additional information and expanding short interaction sequences, and then capturing users' potential intents from multiple augmented sequences. Finally, the TRIER learns to generate diverse recommendation lists by covering as many potential intents as possible.To evaluate the effectiveness of TRIER, we conduct extensive experiments on three benchmark datasets. The experimental results demonstrate that TRIER significantly outperforms state-of-the-art methods, exhibiting diversity improvement of up to 11.36% in terms of intra-list distance (ILD@5) on the Steam dataset, 3.43% ILD@5 on the Yelp dataset and 3.77% in terms of category coverage (CC@5) on the Beauty dataset. As for accuracy, on the Yelp dataset, we observe notable improvement of 7.62% and 8.63% in HR@5 and NDCG@5, respectively. Moreover, we found that TRIER reveals more significant accuracy and diversity improvement for short interaction sequences.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Shi2024Diversifying
ER  -

TY  - JOUR
AU  - Ouyang, J.
AU  - Yu, M.
AU  - Yu, W.
AU  - Qin, Z.
AU  - Regan, A.C.
AU  - Wu, D.
TI  - TPGraph: A Spatial-Temporal Graph Learning Framework for Accurate Traffic Prediction on Arterial Roads
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3911
EP  - 3926
DO  - 10.1109/TITS.2023.3334558
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181577965&doi=10.1109%2fTITS.2023.3334558&partnerID=40&md5=4c280e5135012b3bb6cc723af6bb8cdb
AB  - The accurate prediction of traffic conditions, including speed, flow, and travel time, poses a critical challenge in urbanization that significantly impacts car owners and road administrators. However, in certain scenarios with restricted road data availability (e.g. lack of traffic light status and signal control strategies, cooperation between road administrators and third parties, etc.), it is imperative to make effective use of basic road information (e.g. historical traffic data and road connectivity) to improve both prediction accuracy and scalability on various arterial road networks against state-of-art deep learning models. In this paper, we propose a spatial-temporal learning framework TPGraph for an accurate prediction of arterial roads' traffic data by effectively utilizing upstream and downstream road information. TPGraph is composed of three major parts: 1) A multi-scale temporal feature fusion module that utilizes a multi-head attention mechanism to integrate recently-periodic features, daily-periodic features, and weekly-periodic features; 2) A multi-graph convolution module that employs graph fusion and graph convolution networks to capture richer spatial semantics, and 3) A dynamic spatial-temporal prediction module that leverages a spatial-temporal transformer for single or multiple traffic-state predictions. Our proposed framework, TPGraph, leverages just multi-scale historical traffic conditions and readily accessible spatial factors as input to generate accurate predictions of future traffic conditions. We mainly evaluate the performance of our approach through multi-step prediction experiments conducted at hourly intervals, forecasting travel time or travel speed for each road at 15 mins, 30 mins, and 1 hour. Furthermore, we conduct extensive experiments on real-world arterial road datasets to demonstrate the superior predictive performance of TPGraph compared to existing methods. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Ouyang2024TPGraph
ER  -

TY  - JOUR
AU  - Pu, Y.
AU  - Liu, F.
AU  - Shi, R.
AU  - Yuan, H.
AU  - Chen, R.
AU  - Peng, T.
AU  - Wu, W.
TI  - ELAKT: Enhancing Locality for Attentive Knowledge Tracing
PY  - 2024
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 4
C7  - 112
DO  - 10.1145/3652601
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193526605&doi=10.1145%2f3652601&partnerID=40&md5=6ecfaa047c840db40785ab65645fa456
AB  - Knowledge tracing models based on deep learning can achieve impressive predictive performance by leveraging attention mechanisms. However, there still exist two challenges in attentive knowledge tracing (AKT): First, the mechanism of classical models of AKT demonstrates relatively low attention when processing exercise sequences with shifting knowledge concepts (KC), making it difficult to capture the comprehensive state of knowledge across sequences. Second, classical models do not consider stochastic behaviors, which negatively affects models of AKT in terms of capturing anomalous knowledge states. This article proposes a model of AKT, called Enhancing Locality for Attentive Knowledge Tracing (ELAKT), that is a variant of the deep KT model. The proposed model leverages the encoder module of the transformer to aggregate knowledge embedding generated by both exercises and responses over all timesteps. In addition, it uses causal convolutions to aggregate and smooth the states of local knowledge. The ELAKT model uses the states of comprehensive KCs to introduce a prediction correction module to forecast the future responses of students to deal with noise caused by stochastic behaviors. The results of experiments demonstrated that the ELAKT model consistently outperforms state-of-the-art baseline KT models.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Pu2024ELAKT
ER  -

TY  - JOUR
AU  - Dong, N.
AU  - Chen, S.
AU  - Wu, Y.
AU  - Feng, Y.
AU  - Liu, X.
TI  - An enhanced motion planning approach by integrating driving heterogeneity and long-term trajectory prediction for automated driving systems: A highway merging case study
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 161
C7  - 104554
DO  - 10.1016/j.trc.2024.104554
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187196616&doi=10.1016%2fj.trc.2024.104554&partnerID=40&md5=02e77161ff28a03154b8f4dc5981a38c
AB  - Navigating automated driving systems (ADSs) through complex driving environments is difficult. Predicting the driving behavior of surrounding human-driven vehicles (HDVs) is a critical component of an ADS. This paper proposes an enhanced motion-planning approach for an ADS in a highway-merging scenario. This method utilizes the results of two aspects: the driving behavior and long-term trajectory of surrounding HDVs, which are coupled using a hierarchical model that is used for the motion planning of an ADS to improve driving safety. An unsupervised clustering algorithm is utilized to classify HDV drivers into two categories: aggressive and normal, as part of predicting their driving behaviors. Subsequently, a logistic regression model is employed for driving style prediction. For trajectory prediction, a transformer-based model that concentrated parallelization computations on longer sequence predictions via a self-attention mechanism is developed. Based on the predicted driving styles and trajectories of the surrounding HDVs, an intelligent decision-making strategy is utilized for ADS motion planning. Finally, real-world traffic data collected from drones on a highway ramp in Xi'an is used as a case study to train and evaluate the proposed model. The results demonstrate that the proposed approach can predict HDVs merging trajectories with a mean squared error (MSE) smaller than 0.125 at 30 s away from the merging point, outperforming existing approaches in terms of predictable duration and accuracy. Furthermore, it exhibited safety improvements by adjusting the ADS motion state in advance with good predictive power for the surrounding HDVs’ motion. For both normal and aggressive driving styles, the ADS trajectories reached optimal safety at a prediction horizon of at least 10 s and over 6.67 s, respectively, when evaluating both time-to-collision (TTC) and deceleration rate to avoid a crash (DRAC) metrics. This indicates that our proposed procedures have improved safety for AVs with long-term predictive capabilities (i.e., over 6 s) for surrounding HDVs. Interestingly, the safety performance does not continue to improve with the increase in prediction horizon once the optimal safety performance (highest TTC and lowest DRAC) has been achieved for both normal and aggressive styles. This suggests that an excessively long prediction horizon (e.g., 30 s) is not always beneficial for safety performance of ADS in our case study. When ADS encounter aggressive HDVs, having a predicted surrounding HDV trajectory can extremely reduce crash risk and maintain a safe situation. This demonstrates that planning ADS trajectories with HDV predictions has significant effects on safety, especially for aggressive driving styles as compared to normal driving styles. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - FMS:B; 
LB  - Dong2024enhanced
ER  -

TY  - JOUR
AU  - Pölz, A.
AU  - Blaschke, A.P.
AU  - Komma, J.
AU  - Farnleitner, A.H.
AU  - Derx, J.
TI  - Transformer Versus LSTM: A Comparison of Deep Learning Models for Karst Spring Discharge Forecasting
PY  - 2024
T2  - Water Resources Research
VL  - 60
IS  - 4
C7  - e2022WR032602
DO  - 10.1029/2022WR032602
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190245322&doi=10.1029%2f2022WR032602&partnerID=40&md5=3dfe8b6247023bf46dfb6b6e6cabf74f
AB  - Karst springs are essential drinking water resources, however, modeling them poses challenges due to complex subsurface flow processes. Deep learning models can capture complex relationships due to their ability to learn non-linear patterns. This study evaluates the performance of the Transformer in forecasting spring discharges for up to 4 days. We compare it to the Long Short-Term Memory (LSTM) Neural Network and a common baseline model on a well-studied Austrian karst spring (LKAS2) with an extensive hourly database. We evaluated the models for two further karst springs with diverse discharge characteristics for comparing the performances based on four metrics. In the discharge-based scenario, the Transformer performed significantly better than the LSTM for the spring with the longest response times (9% mean difference across metrics), while it performed poorer for the spring with the shortest response time (4% difference). Moreover, the Transformer better predicted the shape of the discharge during snowmelt. Both models performed well across all lead times and springs with 0.64–0.92 for the Nash–Sutcliffe efficiency and 10.8%–28.7% for the symmetric mean absolute percentage error for the LKAS2 spring. The temporal information, rainfall and electrical conductivity were the controlling input variables for the non-discharge based scenario. The uncertainty analysis revealed that the prediction intervals are smallest in winter and autumn and highest during snowmelt. Our results thus suggest that the Transformer is a promising model to support the drinking water abstraction management, and can have advantages due to its attention mechanism particularly for longer response times. © 2024. The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - FMS:B; 
LB  - Pölz2024Transformer
ER  -

TY  - JOUR
AU  - Guo, M.
AU  - Janson, B.
AU  - Peng, Y.
TI  - A spatiotemporal deep learning approach for pedestrian crash risk prediction based on POI trip characteristics and pedestrian exposure intensity
PY  - 2024
T2  - Accident Analysis and Prevention
VL  - 198
C7  - 107493
DO  - 10.1016/j.aap.2024.107493
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185306410&doi=10.1016%2fj.aap.2024.107493&partnerID=40&md5=373ef853b8d813b65307ebba6832c765
AB  - Pedestrians represent a population of vulnerable road users who are directly exposed to complex traffic conditions, thereby increasing their risk of injury or fatality. This study first constructed a multidimensional indicator to quantify pedestrian exposure, considering factors such as Point of Interest (POI) attributes, POI intensity, traffic volume, and pedestrian walkability. Following risk interpolation and feature engineering, a comprehensive data source for risk prediction was formed. Finally, based on risk factors, the VT-NET deep learning network model was proposed, integrating the algorithmic characteristics of the VGG16 deep convolutional neural network and the Transformer deep learning network. The model involved training non-temporal features and temporal features separately. The training dataset incorporated features such as weather conditions, exposure intensity, socioeconomic factors, and the built environment. By employing different training methods for different types of causative feature variables, the VT-NET model analyzed changes in risk features and separately trained temporal and non-temporal risk variables. It was used to generate spatiotemporal grid-level predictions of crash risk across four spatiotemporal scales. The performance of the VT-NET model was assessed, revealing its efficacy in predicting pedestrian crash risks across the study area. The results indicated that areas with concentrated crash risks are primarily located in the city center and persist for several hours. These high-risk areas dissipate during the late night and early morning hours. High-risk areas were also found to cluster in the city center; this clustering behavior was more prominent during weekends compared to weekdays and coincided with commercial zones, public spaces, and educational and medical facilities. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Guo2024spatiotemporal
ER  -

TY  - JOUR
AU  - Hajek, P.
AU  - Henriques, R.
TI  - Predicting M&A targets using news sentiment and topic detection
PY  - 2024
T2  - Technological Forecasting and Social Change
VL  - 201
C7  - 123270
DO  - 10.1016/j.techfore.2024.123270
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184992612&doi=10.1016%2fj.techfore.2024.123270&partnerID=40&md5=d75fb6ebe27dc33b8e19bae930d1d93f
AB  - This paper uses news sentiment and topics to discuss the challenges and opportunities of predicting mergers and acquisition (M&A) targets. We explore the effect of investor sentiment on identifying M&As targets and how company-specific news articles can be used as a source of sentiment and topics to obtain richer information on various corporate events. We propose a framework incorporating news sentiment and topics into the M&A target prediction model, utilising state-of-the-art transformer-based sentiment analysis and topic modelling approaches. We evaluate the textual features' predictive power using a real-world dataset of US and UK target and non-target companies from 2020 to 2021, with several experiments conducted to reveal the contribution of sentiment and thematic focus of news to M&A target prediction. A profit-based objective function is proposed to overcome the inherent class imbalance problem in the dataset. Our findings suggest that news-based prediction models outperform traditional statistical and single machine learning methods, indicating the need for more robust and less prone to overfitting ensemble learning methods. Additionally, our study provides evidence for the positive effect of news-based negative sentiment on the likelihood of M&A. Our research has important implications for investors and analysts who seek to identify investment opportunities. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Hajek2024Predicting
ER  -

TY  - JOUR
AU  - Acciaio, B.
AU  - Kratsios, A.
AU  - Pammer, G.
TI  - Designing universal causal deep learning models: The geometric (Hyper)transformer
PY  - 2024
T2  - Mathematical Finance
VL  - 34
IS  - 2
SP  - 671
EP  - 735
DO  - 10.1111/mafi.12389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148992813&doi=10.1111%2fmafi.12389&partnerID=40&md5=674180fb95770929f0face01c7a095b1
AB  - Several problems in stochastic analysis are defined through their geometry, and preserving that geometric structure is essential to generating meaningful predictions. Nevertheless, how to design principled deep learning (DL) models capable of encoding these geometric structures remains largely unknown. We address this open problem by introducing a universal causal geometric DL framework in which the user specifies a suitable pair of metric spaces (Formula presented.) and (Formula presented.) and our framework returns a DL model capable of causally approximating any “regular” map sending time series in (Formula presented.) to time series in (Formula presented.) while respecting their forward flow of information throughout time. Suitable geometries on (Formula presented.) include various (adapted) Wasserstein spaces arising in optimal stopping problems, a variety of statistical manifolds describing the conditional distribution of continuous-time finite state Markov chains, and all Fréchet spaces admitting a Schauder basis, for example, as in classical finance. Suitable spaces (Formula presented.) are compact subsets of any Euclidean space. Our results all quantitatively express the number of parameters needed for our DL model to achieve a given approximation error as a function of the target map's regularity and the geometric structure both of (Formula presented.) and of (Formula presented.). Even when omitting any temporal structure, our universal approximation theorems are the first guarantees that Hölder functions, defined between such (Formula presented.) and (Formula presented.) can be approximated by DL models. © 2023 The Authors. Mathematical Finance published by Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Acciaio2024Designing
ER  -

TY  - JOUR
AU  - Han, Y.
TI  - Generation-based Multi-view Contrast for Self-supervised Graph Representation Learning
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 5
C7  - 130
DO  - 10.1145/3645095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189451786&doi=10.1145%2f3645095&partnerID=40&md5=18a8906d4406dc60d92390016df6d348
AB  - Graph contrastive learning has made remarkable achievements in the self-supervised representation learning of graph-structured data. By employing perturbation function (i.e., perturbation on the nodes or edges of graph), most graph contrastive learning methods construct contrastive samples on the original graph. However, the perturbation-based data augmentation methods randomly change the inherent information (e.g., attributes or structures) of the graph. Therefore, after nodes embedding on the perturbed graph, we cannot guarantee the validity of the contrastive samples as well as the learned performance of graph contrastive learning. To this end, in this article, we propose a novel generation-based multi-view contrastive learning framework (GMVC) for self-supervised graph representation learning, which generates the contrastive samples based on our generator rather than perturbation function. Specifically, after nodes embedding on the original graph we first employ random walk in the neighborhood to develop multiple relevant node sequences for each anchor node. We then utilize the transformer to generate the representations of relevant contrastive samples of anchor node based on the features and structures of the sampled node sequences. Finally, by maximizing the consistency between the anchor view and the generated views, we force the model to effectively encode graph information into nodes embeddings. We perform extensive experiments of node classification and link prediction tasks on eight benchmark datasets, which verify the effectiveness of our generation-based multi-view graph contrastive learning method.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Han2024Generation-based
ER  -

TY  - JOUR
AU  - Walschot, M.
AU  - Katz, D.
TI  - Desalination and transboundary water governance in conflict settings
PY  - 2024
T2  - Journal of Environmental Management
VL  - 355
C7  - 120509
DO  - 10.1016/j.jenvman.2024.120509
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187203696&doi=10.1016%2fj.jenvman.2024.120509&partnerID=40&md5=13e782584119b3cb954d1c377e2e91e8
AB  - Desalination can reduce both water scarcity and variability in supplies, two factors identified as drivers of transboundary water conflict. As such, some have predicted that increasing development of desalination capacity may reduce conflict over shared waters. Others have claimed that desalination may become a source of new conflicts. Additionally, desalination may open up new avenues for cooperation, but also may allow for unilateral action by parties, thereby decreasing cooperation. This study looks at the impact of the introduction of desalination on hydro-political relations in two protracted conflict settings: the island of Cyprus and the Arab-Israeli conflict. Using both quantitative and qualitative assessments, we find that desalination has fundamentally altered hydro-political relations, but find no consistent trends in terms of levels of conflict and cooperation. These findings suggest that the influence of desalination on hydro-political relations is likely to be a function of, rather than a transformer of, the larger geopolitical context. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; 
LB  - Walschot2024Desalination
ER  -

TY  - JOUR
AU  - Sang, W.
AU  - Zhang, H.
AU  - Kang, X.
AU  - Nie, P.
AU  - Meng, X.
AU  - Boulet, B.
AU  - Sun, P.
TI  - Dynamic multi-granularity spatial-temporal graph attention network for traffic forecasting
PY  - 2024
T2  - Information Sciences
VL  - 662
C7  - 120230
DO  - 10.1016/j.ins.2024.120230
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183973074&doi=10.1016%2fj.ins.2024.120230&partnerID=40&md5=8c852012ed38bc76e4ff18bb64ad34bd
AB  - Traffic forecasting, as the cornerstone of the development of intelligent transportation systems, plays a crucial role in facilitating accurate control and management of urban traffic. By treating sensors as nodes in a road network, recent research on modeling complex spatial-temporal graph structures has achieved notable advancements in traffic forecasting. However, limited by the increasing number of sensors and recorded data points, most of the recent studies on spatial-temporal graph neural network (STGNN) research concentrate on aggregating short-term (e.g. recent one-hour) traffic history to predict future data. Furthermore, almost all previous STGNNs neglect to incorporate the cyclical patterns that appear in the traffic historical data. For example, the cyclical patterns of traffic on the same day or hour of each week can help improve the accuracy of future traffic predictions. In this paper, we propose a novel Dynamic Multi-Granularity Spatial-Temporal Graph Attention Network (DmgSTGAT) framework for traffic forecasting, which leverages multi-granularity spatial-temporal correlations across different time-scales and variables to efficiently consider cyclical patterns in traffic data. We also design effective temporal encoding and transformer encoding layers to produce meaningful multi-granularity sensor-level, day-level, hour-level, and point-level representations. The multi-granularity spatial-temporal graph attention network can use the produced representations to extract useful but sparsely distributed patterns accurately, which also avoids the influence of extra noise from the long-term history. Experimental results on four real-world traffic datasets show that DmgSTGAT can achieve state-of-the-art performance with the help of multi-granularity cyclical patterns compared with various recent baselines. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Sang2024Dynamic
ER  -

TY  - JOUR
AU  - Huang, T.
AU  - Fu, R.
AU  - Sun, Q.
AU  - Deng, Z.
AU  - Liu, Z.
AU  - Jin, L.
AU  - Khajepour, A.
TI  - Driver lane change intention prediction based on topological graph constructed by driver behaviors and traffic context for human-machine co-driving system
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 160
C7  - 104497
DO  - 10.1016/j.trc.2024.104497
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184153071&doi=10.1016%2fj.trc.2024.104497&partnerID=40&md5=6727e804187bf25150f6f32abeff25c9
AB  - Driver lane change intention (DLCI) predicting has become an essential research for the development of human–machine co-driving system. This work makes an attempt to predict the DLCI, which is the result of complex interaction between human drivers and driving scene. While few works have explored the relationship between driver behavior features and key features of driving scene when predicting the DLCI. To solve this gap, we developed a DLCI prediction method based on topological graph constructed by driver behaviors and traffic context. However, challenges trend on the heels of that because of some unavoidable features that are irrelevant to the DLCI prediction in the topological graph, the difficulty of capturing global dependencies in the driver's head pose sequence, the dynamics of the relationship between different categories, and insufficient of the DLCI dataset. Therefore, we designed a DLCI predicting model based on dynamic graph convolution network with semantic attention module (DGCN-SAM) and self-supervised guided learning based on the understanding of topological graph (SGL-UTG). Specifically, an invert residual module with anthropomorphic attention mechanism (IRM-AAM) was designed to extract important features in topological graphs. The Transformer with multi-head self-attention was used to capture the global dependences of driver's head pose sequence. DGCN-SAM was developed to model the relationship between different categories or nodes in the graph. And SGL-UTG was proposed to improve the generalization performance and prevent overfitting in the absence of sufficient DLCI data. The experimental results demonstrate that the proposed method can predict the DLCI in real-time with high accuracy. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:B; 
LB  - Huang2024Driver
ER  -

TY  - JOUR
AU  - Yu, C.
AU  - Yan, G.
AU  - Yu, C.
AU  - Liu, X.
AU  - Mi, X.
TI  - MRIformer: A multi-resolution interactive transformer for wind speed multi-step prediction
PY  - 2024
T2  - Information Sciences
VL  - 661
C7  - 120150
DO  - 10.1016/j.ins.2024.120150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184143353&doi=10.1016%2fj.ins.2024.120150&partnerID=40&md5=867638330524054881240af333625cda
AB  - Wind speed prediction is crucial for managing energy consumption in wind farms. Traditional wind speed prediction techniques often overlook two essential characteristics of wind speed data: (a) the downsampled wind speed data can retain cyclic and trend information, which is valuable for the model. (b) Multi-resolution speed data exhibited distinct patterns, enabling the model to extract insights from various perspectives. Considering the above two characteristics, this paper presents a novel approach called the Multi-Resolution Interactive transformer (MRIformer), which consists of the ASI block and the MRI block. The ASI block utilizes two different attention mechanisms to extract temporal information and enhance interactive learning among subsequences while downsampling wind speed data. The MRI block utilizes a tree structure to stack multiple layers of ASI blocks, enabling the analysis of wind speed data at various resolutions. By incorporating residual connections and multi-head attention, the MRI block effectively fuses data with different resolutions. Comparative experiments on three real-world datasets led to the following conclusions. (a) MRIformer exceeded 14 state-of-the-art baselines on all datasets and achieved a performance improvement of over 7.5%. (b) The effectiveness of the designed structure is demonstrated through component replacement and ablation experiments. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:B; 
LB  - Yu2024MRIformer
ER  -

TY  - JOUR
AU  - Lin, Y.
TI  - Progressive neural network for multi-horizon time series forecasting
PY  - 2024
T2  - Information Sciences
VL  - 661
C7  - 120112
DO  - 10.1016/j.ins.2024.120112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183576871&doi=10.1016%2fj.ins.2024.120112&partnerID=40&md5=e9c7b194665ffbf8344b6f6cef242c12
AB  - In this paper, we introduce ProNet, an novel deep learning approach designed for multi-horizon time series forecasting, adaptively blending autoregressive (AR) and non-autoregressive (NAR) strategies. Our method involves dividing the forecasting horizon into segments, predicting the most crucial steps in each segment non-autoregressively, and the remaining steps autoregressively. The segmentation process relies on latent variables, which effectively capture the significance of individual time steps through variational inference. In comparison to AR models, ProNet showcases remarkable advantages, requiring fewer AR iterations, resulting in faster prediction speed, and mitigating error accumulation. On the other hand, when compared to NAR models, ProNet takes into account the interdependency of predictions in the output space, leading to improved forecasting accuracy. Our comprehensive evaluation, encompassing four large datasets, and an ablation study, demonstrate the effectiveness of ProNet, highlighting its superior performance in terms of accuracy and prediction speed, outperforming state-of-the-art AR and NAR forecasting models. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Lin2024Progressive
ER  -

TY  - JOUR
AU  - Chen, D.
AU  - Hu, N.
AU  - Liang, P.
AU  - Swink, M.
TI  - Understanding the impact of trade policy effect uncertainty on firm-level innovation investment
PY  - 2024
T2  - Journal of Operations Management
VL  - 70
IS  - 2
SP  - 316
EP  - 340
DO  - 10.1002/joom.1285
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178390274&doi=10.1002%2fjoom.1285&partnerID=40&md5=a7bf3ab0152b3f4a71c626f5dca30d43
AB  - Drawing on real options and resource dependence theories, this study examines how firms adjust their innovation investments to address trade policy effect uncertainty (TPEU), a type of firm-specific, perceived environmental uncertainty capturing managers' difficulty in predicting the impacts of potential policy changes on business operations. To develop a context-dependent, time-varying measure of TPEU, we apply bidirectional encoder representations from transformers, an advanced deep learning technique. We analyze the texts of mandatory management discussion and analysis sections of annual reports from 3181 publicly listed Chinese firms. Our sample comprises 22,669 firm-year observations spanning the years 2007 to 2019. The econometric analyses show that firms experiencing higher TPEU will reduce innovation investments. This effect is stronger for firms facing lower competition, involving more foreign sales, and not owned by the state. These findings provide clarity on previously inconclusive results by showcasing the significant influence of policy effect uncertainty, as opposed to policy state uncertainty, on firms' decisions regarding innovation investments. Additionally, these findings underscore the importance of resource dependence factors as crucial contextual factors in this decision-making process. © 2023 Association for Supply Chain Management, Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - FMS:A; AJG:5; ZUFE:TOP; zdy:5; 
LB  - Chen2024Understanding
ER  -

TY  - JOUR
AU  - Pu, B.
AU  - Liu, J.
AU  - Kang, Y.
AU  - Chen, J.
AU  - Yu, P.S.
TI  - MVSTT: A Multiview Spatial-Temporal Transformer Network for Traffic-Flow Forecasting
PY  - 2024
T2  - IEEE Transactions on Cybernetics
VL  - 54
IS  - 3
SP  - 1582
EP  - 1595
DO  - 10.1109/TCYB.2022.3223918
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144768753&doi=10.1109%2fTCYB.2022.3223918&partnerID=40&md5=d61a0231ea5ee5661dd965abd3bee2a8
AB  - Accurate traffic-flow prediction remains a critical challenge due to complicated spatial dependencies, temporal factors, and unpredictable events. Most existing approaches focus on single- or dual-view learning and thus face limitations in systematically learning complex spatial-temporal features. In this work, we propose a novel multiview spatial-temporal transformer (MVSTT) network that can effectively learn complex spatial-temporal domain correlations and potential patterns from multiple views. First, we examine a temporal view and design a short-range gated convolution component from a short-term subview, and a long-range gated convolution component from a long-term subview. These two components effectively aggregate knowledge of the temporal domain at multiple granularities and mine patterns of node evolution across time steps. Meanwhile, in the spatial view, we design a dual-graph spatial learning module that captures fixed and dynamic spatial dependencies of nodes, as well as the evolution patterns of edges, from the static and dynamic graph subviews, respectively. In addition, we further design a spatial-temporal transformer to mine different levels of spatial-temporal features through multiview knowledge fusion. Extensive experiments on four real-world traffic datasets show that our method consistently outperforms the state-of-the-art baseline. The code of MVSTT is available at https://github.com/JianSoL/MVSTT.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; FMS:B; AJG:3; zdy:3; 
LB  - Pu2024MVSTT
ER  -

TY  - JOUR
AU  - Vuong, T.
AU  - Ruotsalo, T.
TI  - Predicting Representations of Information Needs from Digital Activity Context
PY  - 2024
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 4
C7  - 95
DO  - 10.1145/3639819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193535810&doi=10.1145%2f3639819&partnerID=40&md5=839d30be3866597f23394789f5fd8282
AB  - Information retrieval systems often consider search-session and immediately preceding web-browsing history as the context for predicting users' present information needs. However, such context is only available when a user's information needs originate from web context or when users have issued preceding queries in the search session. Here, we study the effect of more extensive context information recorded from users' everyday digital activities by monitoring all information interacted with and communicated using personal computers. Twenty individuals were recruited for 14 days of 24/7 continuous monitoring of their digital activities, including screen contents, clicks, and operating system logs on Web and non-Web applications. Using this data, a transformer architecture is applied to model the digital activity context and predict representations of personalized information needs. Subsequently, the representations of information needs are used for query prediction, query auto-completion, selected search result prediction, and Web search re-ranking. The predictions of the models are evaluated against the ground truth data obtained from the activity recordings. The results reveal that the models accurately predict representations of information needs improving over the conventional search session and web-browsing contexts. The results indicate that the present practice for utilizing users' contextual information is limited and can be significantly extended to achieve improved search interaction support and performance. © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:A期刊; FMS:B; 
LB  - Vuong2024Predicting
ER  -

TY  - JOUR
AU  - Long, C.
AU  - Yuan, H.
AU  - Fang, J.
AU  - Xian, X.
AU  - Liu, G.
AU  - Sheng, V.S.
AU  - Zhao, P.
TI  - Learning Global and Multi-granularity Local Representation with MLP for Sequential Recommendation
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 4
C7  - 87
DO  - 10.1145/3638562
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185802415&doi=10.1145%2f3638562&partnerID=40&md5=b066481b8e2ca586ee7f1cc203cd8a43
AB  - Sequential recommendation aims to predict the next item of interest to users based on their historical behavior data. Usually, users' global and local preferences jointly affect the final recommendation result in different ways. Most existing works use transformers to globally model sequences, which makes them face the dilemma of quadratic computational complexity when dealing with long sequences. Moreover, the scope setting of the user's local preference is usually static and single, and cannot cover richer multi-level local semantics. To this end, we proposed a parallel architecture for capturing global representation and Multi-granularity Local dependencies with MLP for sequential Recommendation (MLM4Rec). For global representation, we utilize modified MLP-Mixer to capture global information of user sequences due to its simplicity and efficiency. For local representation, we incorporate convolution into MLP and propose a multi-granularity local awareness mechanism for capturing richer local semantic information. Moreover, we introduced a weight pooling method to adaptively fuse local-global representations instead of directly concatenation. Our model has the advantages of low complexity and high efficiency thanks to its simple MLP structure. Experimental results on three public datasets demonstrate the effectiveness of our proposed model. Our code is available here. Copyright © 2024 held by the owner/author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Long2024Learning
ER  -

TY  - JOUR
AU  - Wang, Q.
AU  - Cao, X.
AU  - Wang, J.
AU  - Zhang, W.
TI  - Knowledge-Aware Collaborative Filtering With Pre-Trained Language Model for Personalized Review-Based Rating Prediction
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 3
SP  - 1170
EP  - 1182
DO  - 10.1109/TKDE.2023.3301884
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167819218&doi=10.1109%2fTKDE.2023.3301884&partnerID=40&md5=05c99653ec921ee3fbd9631c06e0b39c
AB  - Personalized review-based rating prediction aims at leveraging existing reviews to model user interests and item characteristics for rating prediction. Most of the existing studies mainly encounter two issues. First, the rich knowledge contained in the fine-grained aspects of each review and the knowledge graph is rarely considered to complement the pure text for better modeling user-item interactions. Second, the power of pre-trained language models is not carefully studied for personalized review-based rating prediction. To address these issues, we propose an approach named Knowledge-aware Collaborative Filtering with Pre-trained Language Model (KCF-PLM). For the first issue, to utilize rich knowledge, KCF-PLM develops a transformer network to model the interactions of the extracted aspects w.r.t. a user-item pair. For the second issue, to better represent users and items, KCF-PLM takes all the historical reviews of a user or an item as input to pre-trained language models. Moreover, KCF-PLM integrates the transformer network and the pre-trained language models through representation propagation on the knowledge graph and user-item guided attention of the aspect representations. Thus KCF-PLM combines review text, aspect, knowledge graph, and pre-trained language models together for review-based rating prediction. We conduct comprehensive experiments on several public datasets, demonstrating the effectiveness of KCF-PLM.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:A期刊; FMS:B; 
LB  - Wang2024Knowledge-Aware
ER  -

TY  - JOUR
AU  - Tufano, R.
AU  - Dabic, O.
AU  - Mastropaolo, A.
AU  - Ciniselli, M.
AU  - Bavota, G.
TI  - Code Review Automation: Strengths and Weaknesses of the State of the Art
PY  - 2024
T2  - IEEE Transactions on Software Engineering
VL  - 50
IS  - 2
SP  - 338
EP  - 353
DO  - 10.1109/TSE.2023.3348172
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181565883&doi=10.1109%2fTSE.2023.3348172&partnerID=40&md5=13391e83302cf2a373ff6293d05a7c05
AB  - The automation of code review has been tackled by several researchers with the goal of reducing its cost. The adoption of deep learning in software engineering pushed the automation to new boundaries, with techniques imitating developers in generative tasks, such as commenting on a code change as a reviewer would do or addressing a reviewer's comment by modifying code. The performance of these techniques is usually assessed through quantitative metrics, e.g., the percentage of instances in the test set for which correct predictions are generated, leaving many open questions on the techniques' capabilities. For example, knowing that an approach is able to correctly address a reviewer's comment in 10% of cases is of little value without knowing what was asked by the reviewer: What if in all successful cases the code change required to address the comment was just the removal of an empty line? In this paper we aim at characterizing the cases in which three code review automation techniques tend to succeed or fail in the two above-described tasks. The study has a strong qualitative focus, with ∼105 man-hours of manual inspection invested in manually analyzing correct and wrong predictions generated by the three techniques, for a total of 2,291 inspected predictions. The output of this analysis are two taxonomies reporting, for each of the two tasks, the types of code changes on which the experimented techniques tend to succeed or to fail, pointing to areas for future work. A result of our manual analysis was also the identification of several issues in the datasets used to train and test the experimented techniques. Finally, we assess the importance of researching in techniques specialized for code review automation by comparing their performance with ChatGPT, a general purpose large language model, finding that ChatGPT struggles in commenting code as a human reviewer would do. © 1976-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:A期刊; FMS:B; 
LB  - Tufano2024Code
ER  -

TY  - JOUR
AU  - Gao, J.
AU  - Yu, B.
AU  - Chen, Y.
AU  - Bao, S.
AU  - Gao, K.
AU  - Zhang, L.
TI  - An ADAS with better driver satisfaction under rear-end near-crash scenarios: A spatio-temporal graph transformer-based prediction framework of evasive behavior and collision risk
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 159
C7  - 104491
DO  - 10.1016/j.trc.2024.104491
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183451684&doi=10.1016%2fj.trc.2024.104491&partnerID=40&md5=dbd33f8e7ef5e2c907e305ec42f9faff
AB  - Current advanced driver assistance systems (ADASs) do not consider drivers’ preferences of evasive behavior types and risk levels under rear-end near-crash scenarios, which undermines driver satisfaction, trust, and use of ADASs. Additionally, spatio-temporal interactions between vehicles are not fully involved in current evasive behavior prediction models, and the influence of evasive behavior is ignored while predicting collision risk. To address these issues, this study aims to propose an ADAS with better driver satisfaction under rear-end near-crash scenarios by establishing a spatio-temporal graph transformer-based prediction framework of evasive behavior and collision risk. A total of 822 evasive events are extracted from 108,000 real vehicle trajectories on highways, and variables from three sources (i.e., road environment features, evading vehicle features, and interactive behavior features) are used to construct rear-end near-crash scenario knowledge graphs (RNSKGs). By utilizing RNSKGs embedding and multi-head self-attention mechanism, spatio-temporal graph transformer networks can effectively capture the spatio-temporal interactions between vehicles. The results show that the prediction accuracy of evasive behavior (i.e., braking-only or braking and steering) and collision risk (lower, medium, or higher risk) is 96.34% and 92.12%, respectively, superior to other commonly-used methods. After including the selected evasive behavior in predicting collision risk, the overall accuracy increases by 10.91%. Then, an autonomous evasive takeover system (AET) based on the prediction framework is developed, and its effectiveness and satisfaction are verified by driving simulation experiments. According to the self-reported data of participants, the safety, comfort, usability, and acceptability of AET proposed in this study all significantly outperform existing autonomous takeover systems (i.e., autonomous emergency braking and autonomous emergency steering). The findings of this study might contribute to the optimization of ADASs, the enhancement of mutual understanding between ADASs and human drivers, and the improvement of active driving safety. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - FMS:B; 
LB  - Gao2024ADAS
ER  -

TY  - JOUR
AU  - Wei, S.
AU  - Lv, J.
AU  - Guo, Y.
AU  - Yang, Q.
AU  - Chen, X.
AU  - Zhao, Y.
AU  - Li, Q.
AU  - Zhuang, F.
AU  - Kou, G.
TI  - Combining intra-risk and contagion risk for enterprise bankruptcy prediction using graph neural networks
PY  - 2024
T2  - Information Sciences
VL  - 659
C7  - 120081
DO  - 10.1016/j.ins.2023.120081
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182456555&doi=10.1016%2fj.ins.2023.120081&partnerID=40&md5=581c064d5eb1e75ac21981408a3c8969
AB  - Predicting the bankruptcy risk of small and medium-sized enterprises (SMEs) is crucial for making decisions about loans. Existing studies in both finance and AI research fields, however, tend to only consider either the intra-risk or contagion risk of enterprises, ignoring their interactions and combinatorial effects. This study for the first time considers both types of risk and their joint effects in bankruptcy prediction. Specifically, we first propose an enterprise intra-risk encoder based on statistically significant enterprise risk indicators for its intra-risk learning. Then, we propose an enterprise contagion risk encoder based on an enterprise knowledge graph for its contagion risk embedding. In particular, the contagion risk encoder includes both the newly proposed Heterogeneous Hyper-Graph Neural Networks (HHGNN) and Hierarchical Graph Transformer Networks (HGTN). Using these two types of encoders, we design a unified framework to simultaneously capture intra-risk and contagion risk for bankruptcy prediction. To evaluate the model, we collect real-world multi-sources data on SMEs and build a novel benchmark dataset called SMEsD. We provide open access to the dataset, which is expected to further promote research on financial risk analysis. Experiments on SMEsD against twelve state-of-the-art baselines demonstrate the effectiveness of the proposed model for bankruptcy prediction. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Wei2024Combining
ER  -

TY  - JOUR
AU  - Tipirneni, S.
AU  - Zhu, M.
AU  - Reddy, C.K.
TI  - StructCoder: Structure-Aware Transformer for Code Generation
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 3
C7  - 70
DO  - 10.1145/3636430
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182592552&doi=10.1145%2f3636430&partnerID=40&md5=83d3c6b1e1501d6e397d1f403653db6e
AB  - There has been a recent surge of interest in automating software engineering tasks using deep learning. This article addresses the problem of code generation, in which the goal is to generate target code given source code in a different language or a natural language description. Most state-of-the-art deep learning models for code generation use training strategies primarily designed for natural language. However, understanding and generating code requires a more rigorous comprehension of the code syntax and semantics. With this motivation, we develop an encoder-decoder Transformer model in which both the encoder and decoder are explicitly trained to recognize the syntax and dataflow in the source and target codes, respectively. We not only make the encoder structure aware by leveraging the source code's syntax tree and dataflow graph, but we also support the decoder in preserving the syntax and dataflow of the target code by introducing two novel auxiliary tasks: Abstract Syntax Tree (AST) path prediction and dataflow prediction. To the best of our knowledge, this is the first work to introduce a structure-aware Transformer decoder that models both syntax and dataflow to enhance the quality of generated code. The proposed StructCoder model achieves state-of-the-art performance on code translation and text-to-code generation tasks in the CodeXGLUE benchmark and improves over baselines of similar size on the APPS code generation benchmark. Our code is publicly available at https://github.com/reddy-lab-code-research/StructCoder/.  © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Tipirneni2024StructCoder
ER  -

TY  - JOUR
AU  - Vairetti, C.
AU  - Aránguiz, I.
AU  - Maldonado, S.
AU  - Karmy, J.P.
AU  - Leal, A.
TI  - Analytics-driven complaint prioritisation via deep learning and multicriteria decision-making
PY  - 2024
T2  - European Journal of Operational Research
VL  - 312
IS  - 3
SP  - 1108
EP  - 1118
DO  - 10.1016/j.ejor.2023.08.027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171162315&doi=10.1016%2fj.ejor.2023.08.027&partnerID=40&md5=50533b37c9e380abca955c4b4a5c1fe3
AB  - Complaint analysis is an essential business analytics application because complaints have a strong influence on customer satisfaction (CSAT). However, the process of categorising and prioritising complaints manually can be extremely time consuming for large companies. In this paper, we propose a framework for automatic complaint labelling and prioritisation using text analytics and operational research techniques. The labelling step of the training set is performed using a simple weighting approach from the multiple-criteria decision-making (MCDM) literature, while transformer-based deep learning (DL) techniques are used for text classification. We define two priority classes, namely, urgent complaints and other claims, and develop a system for automatic complaint categorisation. Our experimental results show that excellent predictive performance can be achieved with state-of-the-art text classification models. In particular, BETO, a bidirectional encoder representations from transformers (BERT) model trained on a large Spanish corpus, reaches an accuracy (ACCU) and area under the curve (AUC) of 92.1% and 0.9785, respectively. This positive result translates into a successful complaint prioritisation scheme, which improves CSAT and reduces the churn rate. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Vairetti2024Analytics-driven
ER  -

TY  - JOUR
AU  - Bernabe, P.
AU  - Gotlieb, A.
AU  - Legeard, B.
AU  - Marijan, D.
AU  - Sem-Jacobsen, F.O.
AU  - Spieker, H.
TI  - Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 2
SP  - 1166
EP  - 1177
DO  - 10.1109/TITS.2023.3322690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174799109&doi=10.1109%2fTITS.2023.3322690&partnerID=40&md5=7932ecfa3f3fe064a584b286e9a54436
AB  - In maritime traffic surveillance, detecting illegal activities, such as illegal fishing or transshipment of illicit products is a crucial task of the coastal administration. In the open sea, one has to rely on Automatic Identification System (AIS) message transmitted by on-board transponders, which are captured by surveillance satellites. However, insincere vessels often intentionally shut down their AIS transponders to hide illegal activities. In the open sea, it is very challenging to differentiate intentional AIS shutdowns from missing reception due to protocol limitations, bad weather conditions or restricting satellite positions. This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models. Using historical data, the trained model predicts if a message should be received in the upcoming minute or not. Afterwards, the model reports on detected anomalies by comparing the prediction with what actually happens. Our method can process AIS messages in real-time, in particular, more than 500 Millions AIS messages per month, corresponding to the trajectories of more than 60 000 ships. The method is evaluated on 1-year of real-world data coming from four Norwegian surveillance satellites. Using related research results, we validated our method by rediscovering already detected intentional AIS shutdowns.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Bernabe2024Detecting
ER  -

TY  - JOUR
AU  - Pugoy, R.A.
AU  - Kao, H.-Y.
TI  - NEAR: Non-Supervised Explainability Architecture for Accurate Review-Based Collaborative Filtering
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 2
SP  - 750
EP  - 765
DO  - 10.1109/TKDE.2022.3226189
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144056063&doi=10.1109%2fTKDE.2022.3226189&partnerID=40&md5=ac4113543c833ff37040791633bec419
AB  - There is a critical issue in explainable recommender systems that compounds the challenges of explainability yet is rarely tackled: the lack of ground-truth explanation texts for training. It is unrealistic to expect every user-item pair in a dataset to have a corresponding target explanation. Hence, we pioneer the first non-supervised explainability architecture for review-based collaborative filtering (called NEAR) as our novel contribution to the theory of explanation construction in recommender systems. While maintaining excellent recommendation performance, our approach reformulates explainability as a non-supervised (i.e., unsupervised and self-supervised) explanation generation task. We formally define two explanation types, both of which NEAR can produce. An invariant explanation, fixed for all users, is based on the unsupervised extractive summary of an item's reviews via embedding clustering. Meanwhile, a variant explanation, personalized for a specific user, is a sentence-level text generated by our customized Transformer conditioned on every user-item-rating tuple and artificial ground-truth (self-supervised label) from one of the invariant explanation's sentences. Our empirical evaluation illustrates that NEAR's rating prediction accuracy is better than the other state-of-the-art baselines. Moreover, experiments and assessments show that NEAR-generated variant explanations are more personalized and distinct than those from other Transformer-based models, and our invariant explanations are preferred over those from other contemporary models in real life.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Pugoy2024NEAR
ER  -

TY  - JOUR
AU  - Ouyang, N.
AU  - Ao, L.
AU  - Cai, Q.
AU  - Wan, W.
AU  - Ren, X.
AU  - He, X.
AU  - Sheng, K.
TI  - Graph Transformer-Based Dynamic Edge Interaction Encoding for Traffic Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3513325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213062416&doi=10.1109%2fTITS.2024.3513325&partnerID=40&md5=be7449d020af8e15f696c32e0ef70f8b
AB  - Traffic prediction is an essential function of intelligent transportation system for traffic control and autonomous driving. Most existing methods encode traffic spatial and temporal data separately, and then design a feature fusion module to correlate spatial and temporal features. However, spatial information is often static, and repetitive static spatial encoding leads to waste of resources, especially in large-scale traffic network prediction. In this paper, we propose a dynamic edge interaction encoding method for spatio-temporal features based on inverse Transformer (iTransformer) and Graph Transformer, named iTPGT-former. The dynamic edge interaction process is designed to embed dynamic temporal features into static edges via a convolutional embedding module. To enhance the Graph Transformer, a relative position encoding strategy based on the self-attentive score of the positive definite kernel (PDK) on graphs and a method for graph substructure encoding (GSE) via enumeration of paths are introduced. In the experimental and discussion session, the iTPGT-former is considered for accuracy, parameters, inference speed, and rich ablation experiments are provided based on six publicly available traffic datasets. The results show that iTPGT-former outperforms the baseline model in both traffic flow and traffic speed prediction. The maximum improvement is achieved in the METR-LA 60-min speed prediction task, with 15.2% reduction in Mean Absolute Percentage Error (MAPE). In addition, the inference of iTPGT-former is significantly faster than the GCN-based method. Our implementation of the iTPGT-former is available at https://github.com/ouyangnann/iTPGTN-former. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Ouyang2024Graph
ER  -

TY  - JOUR
AU  - Orfanoudakis, S.
AU  - Diaz-Londono, C.
AU  - Yilmaz, Y.E.
AU  - Palensky, P.
AU  - Vergara, P.P.
TI  - EV2Gym: A Flexible V2G Simulator for EV Smart Charging Research and Benchmarking
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3510945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212602311&doi=10.1109%2fTITS.2024.3510945&partnerID=40&md5=70772c4f6d178e08164a80f2d74f22ff
AB  - As electric vehicle (EV) numbers rise, concerns about the capacity of current charging and power grid infrastructure grow, necessitating the development of smart charging solutions. While many smart charging simulators have been developed in recent years, only a few support the development of Reinforcement Learning (RL) algorithms in the form of a Gym environment, and those that do usually lack depth in modeling Vehicle-to-Grid (V2G) scenarios. To address the aforementioned issues, this paper introduces EV2Gym, a realistic simulator platform for the development and assessment of small and large-scale smart charging algorithms within a standardized platform. The proposed simulator is populated with comprehensive EV, charging station, power transformer, and EV behavior models validated using real data. EV2Gym has a highly customizable interface empowering users to choose from pre-designed case studies or craft their own customized scenarios to suit their specific requirements. Moreover, it incorporates a diverse array of RL, mathematical programming, and heuristic algorithms to speed up the development and benchmarking of new solutions. By offering a unified and standardized platform, EV2Gym aims to provide researchers and practitioners with a robust environment for advancing and assessing smart charging algorithms.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Orfanoudakis2024EV2Gym
ER  -

TY  - JOUR
AU  - Yan, W.
AU  - Ma, H.
AU  - Yang, Z.
TI  - Segmented Sequence Prediction using Variable-Order Markov Model Ensemble
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
DO  - 10.1109/TKDE.2024.3522975
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213447578&doi=10.1109%2fTKDE.2024.3522975&partnerID=40&md5=48c4f80445faea3f7e8edf5acd527263
AB  - In recent years, sequence prediction, particularly in natural language processing tasks, has made significant progress due to advanced neural network architectures like Transformer and enhanced computing power. However, challenges persist in modeling and analyzing certain types of sequence data, such as human daily activities and competitive ball games. These segmented sequence data are characterized by short length, varying local dependencies, and coarse-grained unit states. These characteristics limit the effectiveness of conventional probabilistic graphical models and attention-based or recurrent neural networks in modeling and analyzing segmented sequence data. To address this gap, we introduce a novel generative model for segmented sequences, employing an ensemble of multiple variable-order Markov models (VOMMs) to flexibly represent state transition dependencies. Our approach integrates probabilistic graphical models with neural networks, surpassing the representation capabilities of single high-order or variable-order Markov models. Compared to end-to-end deep learning models, our method offers improved interpretability and reduces overfitting in short segments. We demonstrate the efficacy of our proposed method in two tasks: predicting tennis shot types and forecasting daily action sequences. These applications highlight the broad applicability of our segmented sequence modeling approach across diverse domains. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Yan2024Segmented
ER  -

TY  - JOUR
AU  - Lee, K.
AU  - Seo, H.
AU  - Kim, S.
AU  - An, B.S.
AU  - Park, S.
AU  - Jeon, Y.
AU  - Lee, E.C.
TI  - Quality-Based rPPG Compensation With Temporal Difference Transformer for Camera-Based Driver Monitoring
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3504605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214291447&doi=10.1109%2fTITS.2024.3504605&partnerID=40&md5=3eae991b4988f05c4ddf907d3a219769
AB  - Remote photoplethysmography (rPPG) is a method for monitoring pulse signal by utilizing a camera sensor to capture a facial video including variations in blood flow beneath the skin. Recently, rPPG advancements have enabled the measurement of an individual’s heart rate with a Root Mean Square Error (RMSE) of approximately 1.0 in controlled indoor environments. However, when applied in car dataset including driving environments, the RMSE of rPPG measurements significantly increases to over 9.07. This limitation, caused by motion-related artifacts and fluctuations in ambient illumination, becomes particularly noticeable while driving, resulting in a Percentage of Time that Error is less than 6 beats per minute (PTE6) of up to 65.1%. To address these limitations, we focus on the assessment of rPPG noise, with an emphasis on evaluating noise components within facial video and quantifying quality of the rPPG measurement. In this paper, we propose a deep learning framework that infers rPPG signal and quality based on video vision transformer. the proposed method demonstrates that the top 10% quality measurements yield PTE6 of 91.98% and 99.59% in driving and garage environments, respectively. Additionally, we introduce a quality-based rPPG compensation method that improves accuracy in driving environments by predicting rPPG quality based on noise assessment. This compensation method demonstrates superior accuracy compared to the current state-of-the-art, achieving a PTE6 of 68.24% in driving scenarios. © 2024 IEEE. All rights reserved, including rights for text and data mining, and training of artificial intelligence.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Lee2024Quality-Based
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Chen, X.
AU  - Yang, J.
TI  - Edge-Enhanced Heterogeneous Graph Transformer With Priority-Based Feature Aggregation for Multi-Agent Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3509954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212754368&doi=10.1109%2fTITS.2024.3509954&partnerID=40&md5=db106f3ae35001a206f5140104f795f5
AB  - Trajectory prediction, which aims to predict the future positions of all agents in a crowd scene, given their past trajectories, plays a vital role in improving the safety of autonomous driving vehicles. For heterogeneous agents, it is imperative to account for the gap in feature distribution differences between agents in different categories. Besides, exploring the reference relationship between the future motions of agents is crucial yet overlooked in previous trajectory prediction methods. To tackle these challenges, we propose an edge-enhanced heterogeneous graph Transformer with priority-based feature aggregation for multi-modal trajectory prediction. Specifically, a new edge-enhanced heterogeneous interaction module that carries relative position information via edges is proposed to explore the complex interaction among agents. Additionally, we propose the concept of priority during the decoding phase and the corresponding measuring method, based on which a priority-based feature aggregation module is presented to enable referencing between agents, allowing for a more reasonable trajectory generation process. Additionally, we design an effective feature fusion method based on state refinement LSTM so that temporal and social features can be well integrated while accounting for their roles in trajectory prediction. Extensive experimental results on public datasets demonstrate that our approach outperforms the state-of-the-art baseline methods, confirming the effectiveness of our proposed method. The source code of our EPHGT model will be publicly released at https://github.com/xbchen82/EPHGT. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024Edge-Enhanced
ER  -

TY  - JOUR
AU  - Xing, Y.
AU  - Yang, S.
AU  - Wang, S.
AU  - Zhang, S.
AU  - Liang, G.
AU  - Zhang, X.
AU  - Zhang, Y.
TI  - MS-DETR: Multispectral Pedestrian Detection Transformer With Loosely Coupled Fusion and Modality-Balanced Optimization
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 20628
EP  - 20642
DO  - 10.1109/TITS.2024.3450584
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210918883&doi=10.1109%2fTITS.2024.3450584&partnerID=40&md5=2e39702428fa2c56183318049f842c78
AB  - Multispectral pedestrian detection is an important task for many around-the-clock applications, since the visible and thermal modalities can provide complementary information especially under low light conditions. Due to the presence of two modalities, misalignment and modality imbalance are the most significant issues in multispectral pedestrian detection. In this paper, we propose MultiSpectral pedestrian DEtection TRansformer (MS-DETR) to fix above issues. MS-DETR consists of two modality-specific backbones and Transformer encoders, followed by a multi-modal Transformer decoder, and the visible and thermal features are fused in the multi-modal Transformer decoder. To well resist the misalignment between multi-modal images, we design a loosely coupled fusion strategy by sparsely sampling some keypoints from multi-modal features independently and fusing them with adaptively learned attention weights. Moreover, based on the insight that not only different modalities, but also different pedestrian instances tend to have different confidence scores to final detection, we further propose an instance-aware modality-balanced optimization strategy, which preserves visible and thermal decoder branches and aligns their predicted slots through an instance-wise dynamic loss. Our end-to-end MS-DETR shows superior performance on the challenging KAIST, CVC-14 and LLVIP benchmark datasets. The source code is available at https://github.com/YinghuiXing/MS-DETR. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Xing2024MS-DETR
ER  -

TY  - JOUR
AU  - Ren, R.
AU  - Shi, P.
AU  - Jia, P.
AU  - Kim, J.
TI  - An Unsupervised Learning Approach for Pavement Distress Diagnosis via Siamese Networks
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3500030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210935529&doi=10.1109%2fTITS.2024.3500030&partnerID=40&md5=9714fcc7b16d1d99ed4806c573ee2591
AB  - Accurate, automated diagnosis of pavement distress is essential for effective roadway maintenance but presents considerable challenges. Supervised learning methods are constrained by limited labeled data, while existing unsupervised representation learning approaches are difficult to capture the fine-grained details needed for precise pixel-level segmentation in pavement images with similar backgrounds. To address these limitations, we propose a novel unsupervised approach for pavement distress segmentation that employs a new pretext task within Siamese networks. Our method integrates an explicit prediction head and a high-dimensional cross-entropy loss, enabling implicit class labeling and enhancing fine-grained recognition of distress patterns. Additionally, vision transformers are employed to leverage self-attention mechanisms, facilitating accurate segmentation of foreground distress regions. Experimental results demonstrate that our approach outperforms existing unsupervised representation learning and anomaly detection methods. Notably, when used to pre-train backbone networks such as ResNet-50, our method yields higher accuracy and faster convergence on downstream supervised tasks compared to pre-training on the labeled ImageNet dataset. The proposed method holds promise for advancing pavement maintenance decision-making and enhancing the performance of traditional supervised deep learning models.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Ren2024Unsupervised
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Yang, J.
AU  - Wu, X.
AU  - Zhou, W.
AU  - Wang, Y.
TI  - ETR: Enhancing Taillight Recognition via Transformer-Based Video Classification
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3509394
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212131845&doi=10.1109%2fTITS.2024.3509394&partnerID=40&md5=3db36f3ab1a33360b38eb77982db7009
AB  - In autonomous driving, efficiently and accurately recognizing taillight states using dashcams is essential for interpreting other vehicles' intentions. Recent video-based taillight recognition methods outperform earlier image-based approaches. However, they face challenges in efficiently integrating spatiotemporal information and managing high computational costs. In this paper, we introduce ETR, an accurate and efficient Transformer-based video classification model designed to enhance taillight recognition. Specifically, we first design a lightweight backbone to extract temporal and spatial features from videos and generate queries with prior information. Next, we develop a hierarchical progressive Transformer decoder that integrates feature maps from different levels of the backbone to enhance the model's global information. Finally, we employ a classification head to predict the taillight state of the video. Additionally, we introduce a public dataset, ETR-Taillights, to address the current lack of open datasets for vehicle taillight recognition. The dataset contains 28,799 dashcam video clips, making it the largest public taillight recognition dataset. Experiments show that our method achieves a 91.69% F-measure on the ETR-Taillights dataset, surpassing the latest taillight recognition methods, VIF by 6.94% and CNN-LSTM by 10.82%. Additionally, it achieves an inference speed of 45.06 FPS, being 3.6 times faster than VIF. Furthermore, we conduct real-world road tests to demonstrate our method's robustness and effectiveness in practical scenarios. Our model and dataset are available at https://github.com/yang590/ vehicle-taillight.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024ETR
ER  -

TY  - JOUR
AU  - Gan, J.
AU  - Yang, Q.
AU  - Zhang, D.
AU  - Li, L.
AU  - Qu, X.
AU  - Ran, B.
TI  - A Novel Voronoi-Based Spatio-Temporal Graph Convolutional Network for Traffic Crash Prediction Considering Geographical Spatial Distributions
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 21723
EP  - 21736
DO  - 10.1109/TITS.2024.3452275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210928952&doi=10.1109%2fTITS.2024.3452275&partnerID=40&md5=432249850475a596e4059279fd33c9d3
AB  - Accurately predicting the probability of crashes is crucial for preventing traffic crashes and mitigating their impacts. However, the imbalance in crash data, irregular road network structures, and heterogeneity in multi-source data pose significant challenges. To address these issues, this study introduces a spatio-temporal graph convolutional network traffic crash prediction model based on Voronoi diagrams that considers geographical spatial distribution. Initially, this study introduces a spatial partitioning method based on Voronoi diagrams, grounded on the geographic spatial distribution characteristics of traffic crashes. It constructs a novel graph structure with spatial units within Voronoi diagrams as nodes and the shared length of different road types between units as edges. This graph structure integrates the spatial distribution characteristics of crashes with the graph structure, substantially contributing to addressing the zero-inflation problem inherent in spatial units constructed on a grid basis. Subsequently, the study employs a GCN (Graph Convolutional Network) and Transformer encoder to build the VSTGCN (Voronoi-Based Spatio-Temporal Graph Convolutional Network) crash prediction model, evaluating its effectiveness using real data from New York City. Comparisons with eight baseline models demonstrate that VSTGCN outperforms them in all evaluation metrics. Moreover, the paper conducts model ablation studies from different perspectives, such as feature modules and graph structure composition, revealing that the chosen spatial, temporal, and spatio-temporal features significantly influence the model's predictive performance, with spatial features having the most substantial impact. Finally, the novel graph structure based on Voronoi diagrams proposed in this study shows a clear advantage in model effectiveness compared to traditional graph structures. This research can effectively handle complex crash data structures and accurately predict crash probabilities, providing a reliable basis for developing measures to prevent crashes and alleviate their impacts. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Gan2024Novel
ER  -

TY  - JOUR
AU  - Wang, S.
AU  - Yang, Q.
AU  - Ruan, S.
AU  - Long, C.
AU  - Yuan, Y.
AU  - Li, Q.
AU  - Yuan, Z.
AU  - Bao, J.
AU  - Zheng, Y.
TI  - Spatial Meta Learning With Comprehensive Prior Knowledge Injection for Service Time Prediction
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
DO  - 10.1109/TKDE.2024.3512582
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211975200&doi=10.1109%2fTKDE.2024.3512582&partnerID=40&md5=dafe55a252d5ab4594dffd426113e139
AB  - Intelligent logistics relies on accurately predicting the service time, which is a part of time cost in the last-mile delivery. However, service time prediction (STP) is non-trivial given complex delivery circumstances, location heterogeneity, and skewed observations in space, which are not well-handled by existing solutions. In our prior work, we treat STP at each location as a learning task to keep the location heterogeneity, propose a prior knowledge-enhanced meta-learning to tackle skewed observations, and introduce a Transformer-based representation module to encode complex delivery circumstances. Maintaining the design principles of prior work, in this extended paper, we propose MetaSTP+. In addition to fusing the prior knowledge after the meta-learning process, MetaSTP+ also injects the prior knowledge before and during the meta-learning process to better tackle skewed observations. More specifically, MetaSTP+ completes the support set of tasks with scarce samples from other tasks based on prior knowledge and is equipped with a prior knowledge-aware historical observation encoding module to achieve those purposes accordingly. Experiments show MetaSTP+ outperforms the best baseline by 11.2% and 8.4% on two real-world datasets. Finally, an intelligent waybill assignment system based on MetaSTP+ is deployed in JD Logistics.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Wang2024Spatial
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Yang, J.
AU  - Wu, X.
AU  - Zhou, W.
AU  - Wang, Y.
TI  - TrVLR: A Transformer-Based Vehicle Light Recognition Method in Vehicle Inspection
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 19995
EP  - 20005
DO  - 10.1109/TITS.2024.3447586
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210990315&doi=10.1109%2fTITS.2024.3447586&partnerID=40&md5=8cf7d8200a9490410fe3ac38317c5328
AB  - Vehicle light inspection is a crucial aspect of vehicle inspection, as vehicle lights play a vital role in understanding vehicle behavior. Due to diverse ambient illumination, non-uniform vehicle light standards, and complex light states, existing vehicle light recognition methods perform poorly, especially in turn signals. To realize intelligent vehicle light inspection, an accurate and real-time intelligent vehicle light recognition method is urgently needed. To address this issue, we propose a Transformer-based vehicle light recognition method, TrVLR, which effectively models sequential information and global relationships of the vehicle light image sequence, resulting in precise recognition. Specifically, we first utilize a convolutional neural network (CNN) backbone to extract features from vehicle light area video. Then, we adopt a Transformer encoder to encapsulate the long sequential information of the entire video. Next, a Transformer decoder is used to contextualize each image throughout the video and output the classification information of each image. Finally, we predict the state of the lights in each image by feed-forward networks (FFNs). Experiments demonstrate that our method obtains state-of-the-art results in headlights, taillights, and turn signals with F-measures of 93.34%, 91.64%, and 88.17%, respectively. Notably, TrVLR surpasses CNN-LSTM by 7.01% in turn signal recognition. Our method has been successfully applied to intelligent vehicle light inspection, and the video demo is shown at https://www.youtube.com/watch?v=p8E78Pwkcxo. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024TrVLR
ER  -

TY  - JOUR
AU  - Cheng, J.
AU  - Li, K.
AU  - Liang, Y.
AU  - Sun, L.
AU  - Yan, J.
AU  - Wu, Y.
TI  - Rethinking Urban Mobility Prediction: A Multivariate Time Series Forecasting Approach
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3498054
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210991851&doi=10.1109%2fTITS.2024.3498054&partnerID=40&md5=7c7552078f2f94fa5f33bd2ab983d999
AB  - Long-term urban mobility predictions play a crucial role in the effective management of urban facilities and services. Conventionally, urban mobility data has been structured as spatiotemporal videos, treating longitude and latitude grids as fundamental pixels. Consequently, video prediction methods, relying on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), have been instrumental in this domain. In our research, we introduce a fresh perspective on urban mobility prediction. Instead of oversimplifying urban mobility data as traditional video data, we regard it as a complex multivariate time series. This perspective involves treating the time-varying values of each grid in each channel as individual time series. To tackle the prediction of these time series, we present the Super-Multivariate Urban Mobility Transformer (SUMformer), which utilizes a specially designed attention mechanism to calculate temporal and cross-variable correlations and reduce computational costs stemming from a large number of time series. SUMformer also employs low-frequency filters to extract essential information for long-term predictions. Furthermore, SUMformer is structured with a temporal patch merge mechanism, forming a hierarchical framework that enables the capture of multi-scale correlations. Consequently, it excels in urban mobility pattern modeling and long-term prediction, outperforming current state-of-the-art methods across five real-world datasets. The code is available at: https://github.com/Chengyui/SUMformer.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Cheng2024Rethinking
ER  -

TY  - JOUR
AU  - Tao, W.
AU  - Liu, H.
AU  - Xu, J.
AU  - Dai, Q.
AU  - Zhou, J.
AU  - Wen, H.
AU  - Chen, Z.
TI  - Collaboration or Competition: An Infomax-Based Period-Aware Transformer for Ticket-Grabbing Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 19757
EP  - 19769
DO  - 10.1109/TITS.2024.3450610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210972779&doi=10.1109%2fTITS.2024.3450610&partnerID=40&md5=304c70a2c70ffda27288ebe253991c9b
AB  - Helping users to grab train tickets during a travel peak is a very important service provided by many mainstream online travel platforms (OTPs), e.g., booking.com, Ctrip.com, and Alibaba Fliggy, which greatly enriches the experience for platform users. To optimize such train ticket-grabbing service, a vital accompanying task is to predict the train ticket-grabbing success rates for users during their train ticket-grabbing process to help them make decisions. Although many endeavours have been made towards the traffic prediction problem, none of them was dedicated to solving the ticket-grabbing issue. That is, prior methods ignored the unique properties exhibited in the ticket-grabbing scenario, such as the specific spatial relationship between stations and trains, the collaboration and competition relationships between different routes, and the temporal periodic pattern in ticket-grabbing. In this paper, we propose a novel Infomax-based Period-aware Transformer (IPT) tailored for predicting the success rate of train ticket-grabbing that will be displayed on OTPs, which is to our best knowledge the first attempt along this line. IPT contains three modules: i) a multi-view node embedding module, which serves to model the special spatial relationships between stations and trains by employing the intra- and inter-graph aggregation layers; ii) an infomax-based graph representation learning module, which aims to learn a high-level node embedding by training a discriminator to distinguish different types of edges in the route graph; iii) a period-aware Transformer module, which intends to discover the ticket-grabbing temporal periodic dependencies by designing a periodic activation function. Extensive offline and online evaluations on a real-world dataset show that IPT substantially outperforms state-of-the-art baselines. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Tao2024Collaboration
ER  -

TY  - JOUR
AU  - Lang, B.
AU  - Li, X.
AU  - Chuah, M.C.
TI  - BEV-TP: End-to-End Visual Perception and Trajectory Prediction for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 18537
EP  - 18546
DO  - 10.1109/TITS.2024.3433591
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208807362&doi=10.1109%2fTITS.2024.3433591&partnerID=40&md5=e7ccd7f03435c65940470b0342f9f833
AB  - For autonomous vehicles (AVs), the ability for effective end-to-end perception and future trajectory prediction is critical in planning a safe automatic maneuver. In the current AVs systems, perception and prediction are two separate modules. The prediction module receives only a restricted amount of information from the perception module. Furthermore, perception errors will propagate into the prediction module, ultimately having a negative impact on the accuracy of the prediction results. In this paper, we present a novel framework termed BEV-TP, a visual context-guided center-based transformer network for joint 3D perception and trajectory prediction. BEV-TP exploits visual information from consecutive multi-view images and context information from HD semantic maps, to predict better objects’ centers whose locations are then used to query visual features and context features via the attention mechanism. Generated agent queries and map queries facilitate learning of the transformer module for further feature aggregation. Finally, multiple regression heads are used to perform 3D bounding box detection and future velocity prediction. This center-based approach achieves a differentiable, simple, and efficient E2E trajectory prediction framework. Extensive experiments conducted on the nuScenes dataset demonstrate the effectiveness of BEV-TP over traditional pipelines with sequential paradigms. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Lang2024BEV-TP
ER  -

TY  - JOUR
AU  - Shi, F.
AU  - Li, D.
AU  - Wang, X.
AU  - Li, B.
AU  - Wu, X.
TI  - TGformer: A Graph Transformer Framework for Knowledge Graph Embedding
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
DO  - 10.1109/TKDE.2024.3486747
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208930487&doi=10.1109%2fTKDE.2024.3486747&partnerID=40&md5=9efbf4ecc1b3a60bd18525f6c3458c8c
AB  - Knowledge graph embedding is efficient method for reasoning over known facts and inferring missing links. Existing methods are mainly triplet-based or graph-based. Triplet-based approaches learn the embedding of missing entities by a single triple only. They ignore the fact that the knowledge graph is essentially a graph structure. Graph-based methods consider graph structure information but ignore the contextual information of nodes in the knowledge graph, making them unable to discern valuable entity (relation) information. In response to the above limitations, we propose a general graph transformer framework for knowledge graph embedding (TGformer). It is the first to use a graph transformer to build knowledge embeddings with triplet-level and graph-level structural features in the static and temporal knowledge graph. Specifically, a context-level subgraph is constructed for each predicted triplet, which models the relation between triplets with the same entity. Afterward, we design a knowledge graph transformer network (KGTN) to fully explore multi-structural features in knowledge graphs, including triplet-level and graph-level, boosting the model to understand entities (relations) in different contexts. Finally, semantic matching is adopted to select the entity with the highest score. Experimental results on several public knowledge graph datasets show that our method can achieve state-of-the-art performance in link prediction.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Shi2024TGformer
ER  -

TY  - JOUR
AU  - Hong, S.
AU  - Choi, Y.
AU  - Jeon, J.-J.
TI  - Interpretable water level forecaster with spatiotemporal causal attention mechanisms
PY  - 2024
T2  - International Journal of Forecasting
DO  - 10.1016/j.ijforecast.2024.10.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210076987&doi=10.1016%2fj.ijforecast.2024.10.003&partnerID=40&md5=5efc4aa5215cdf570da9c48e22b02515
AB  - Accurate forecasting of river water levels is vital for effectively managing traffic flow and mitigating the risks associated with natural disasters. This task presents challenges due to the intricate factors influencing the flow of a river. Recent advances in machine learning have introduced numerous effective forecasting methods. However, these methods lack interpretability due to their complex structure, resulting in limited reliability. Addressing this issue, this study proposes a deep learning model that quantifies interpretability, with an emphasis on water level forecasting. This model focuses on generating quantitative interpretability measurements, which align with the common knowledge embedded in the input data. This is facilitated by the utilization of a transformer architecture that is purposefully designed with masking, incorporating a multi-layer network that captures spatiotemporal causation. We perform a comparative analysis on the Han River dataset obtained from Seoul, South Korea, from 2016 to 2021. The results illustrate that our approach offers enhanced interpretability consistent with common knowledge, outperforming competing methods. The approach also enhances robustness against distribution shift. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Hong2024Interpretable
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Huang, A.
AU  - Luo, Q.
AU  - Guan, W.
TI  - Local-Perception-Enhanced Spatial-Temporal Evolving Graph Transformer Network: Citywide Demand Prediction of Taxi and Ride-Hailing
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 17105
EP  - 17121
DO  - 10.1109/TITS.2024.3450846
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209990432&doi=10.1109%2fTITS.2024.3450846&partnerID=40&md5=38ef45a7da1d1bdd508fd8347414617d
AB  - Accurate prediction of demand for traditional taxi and ride-hailing services is crucial for addressing supply-demand imbalances. However, recent studies based on global adaptive graphs, local spatial-temporal graphs, and self-attention mechanisms struggle to effectively capture the dynamic and intricate relations in demand. Moreover, existing dynamic graph generators face challenges in efficiently producing high-quality graphs to learn the diverse interactions among zones along time axis and their shared patterns spanning various time scales. To solve these challenges, we propose a novel Local-Perception-Enhanced Spatial-Temporal Evolving Graph Transformer Network (LPE-STGTN), aimed at improving the effectiveness and efficiency of extracting intricate local dependencies in taxi demand. Specifically, we elaborately design a spatial-temporal evolving graph generator to absorb shared and diversified inter-zone relations across different temporal periodicities and specific interactions among zones within each time step. Furthermore, an attention free transformer with local context (AFT-local) is introduced to effectively learn the correlations between adjacent time steps. Extensive experiments on three taxi datasets of New York and Beijing are carried out to evaluate the superior performance of our model. Compared with the most competitive baseline, our model achieves a balance between effectiveness and efficiency on three datasets, with average training time reduction of 70.66% and average performance improvement of 1.96%.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2024Local-Perception-Enhanced
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Wang, B.
AU  - Zhao, Y.
AU  - Yuan, Y.
AU  - Zhou, T.
AU  - Li, Z.
TI  - Collaborative Multimodal Fusion Network for Multiagent Perception
PY  - 2024
T2  - IEEE Transactions on Cybernetics
DO  - 10.1109/TCYB.2024.3491756
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209947163&doi=10.1109%2fTCYB.2024.3491756&partnerID=40&md5=8b9b1b556991f70e61e805891ad184da
AB  - With the increasing popularity of autonomous driving systems and their applications in complex transportation scenarios, collaborative perception among multiple intelligent agents has become an important research direction. Existing single-agent multimodal fusion approaches are limited by their inability to leverage additional sensory data from nearby agents. In this article, we present the collaborative multimodal fusion network (CMMFNet) for distributed perception in multiagent systems. CMMFNet first extracts modality-specific features from LiDAR point clouds and camera images for each agent using dual-stream neural networks. To overcome the ambiguity in-depth prediction, we introduce a collaborative depth supervision module that projects dense fused point clouds onto image planes to generate more accurate depth ground truths. We then present modality-aware fusion strategies to aggregate homogeneous features across agents while preserving their distinctive properties. To align heterogeneous LiDAR and camera features, we introduce a modality consistency learning method. Finally, a transformer-based fusion module dynamically captures cross-modal correlations to produce a unified representation. Comprehensive evaluations on two extensive multiagent perception datasets, OPV2V and V2XSet, affirm the superiority of CMMFNet in detection performance, establishing a new benchmark in the field.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; AJG:3; zdy:3; 
LB  - Zhang2024Collaborative
ER  -

TY  - JOUR
AU  - Dong, Y.
AU  - Pan, Y.
AU  - Wang, D.
AU  - Chen, A.
TI  - Traffic Load Simulation for Long-Span Bridges Using a Transformer Model Incorporating In-Lane Transverse Vehicle Movements
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 15600
EP  - 15613
DO  - 10.1109/TITS.2024.3452106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209389559&doi=10.1109%2fTITS.2024.3452106&partnerID=40&md5=fed3d4a97fd68abf708acb408e5475ae
AB  - Traffic load simulation (TLS) is critical for the design and assessment of long-span bridges. Traditional methods, such as Monte-Carlo sampling and Cellular Automaton, rely on actual traffic data for load generation and evolution. However, they often overlook in-lane transverse movements, which are vital for precise bridge component assessment. This paper presents a TLS framework that incorporates in-lane transverse movements for long-span bridges. We select eight parameters as input features for a Transformer-based deep learning model, designed to predict both longitudinal and transverse vehicle speeds. The TLS process begins with spatial-temporal traffic load monitoring on the target bridge. Monte-Carlo sampling generates vehicle data, and the trained Transformer model simulates traffic evolution. A case study on a 1490-meter main-span suspension bridge illustrates the proposed method. Traffic trajectories were captured using a multi-vision system and reconstructed to minimize errors. The Transformer model was trained with optimized hyperparameters, enabling the completion of TLS on the entire bridge deck. We also compare the performance of other deep learning models, evaluate the accuracy of transverse distribution in TLS, and discuss its potential applications in future bridge assessments. The proposed TLS method enhances current practices by accurately simulating transverse vehicle positions on bridge decks, thereby improving the fidelity of microscopic traffic simulations and enabling more precise fatigue damage assessments of bridge components.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Dong2024Traffic
ER  -

TY  - JOUR
AU  - Kong, L.
AU  - Li, W.
AU  - Yang, H.
AU  - Zhang, Y.
AU  - Guan, J.
AU  - Zhou, S.
TI  - CausalFormer: An Interpretable Transformer for Temporal Causal Discovery
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
DO  - 10.1109/TKDE.2024.3484461
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207459156&doi=10.1109%2fTKDE.2024.3484461&partnerID=40&md5=df32960e417e3180a80de34210ce7238
AB  - Temporal causal discovery is a crucial task aimed at uncovering the causal relations within time series data. The latest temporal causal discovery methods usually train deep learning models on prediction tasks to uncover the causality between time series. They capture causal relations by analyzing the parameters of some components of the trained models, e.g., attention weights and convolution weights. However, this is an incomplete mapping process from the model parameters to the causality and fails to investigate the other components, e.g., fully connected layers and activation functions, that are also significant for causal discovery. To facilitate the utilization of the whole deep learning models in temporal causal discovery, we proposed an interpretable transformer-based causal discovery model termed CausalFormer, which consists of the causality-aware transformer and the decomposition-based causality detector. The causality-aware transformer learns the causal representation of time series data using a prediction task with the designed multi-kernel causal convolution which aggregates each input time series along the temporal dimension under the temporal priority constraint. Then, the decomposition-based causality detector interprets the global structure of the trained causality-aware transformer with the proposed regression relevance propagation to identify potential causal relations and finally construct the causal graph. Experiments on synthetic, simulated, and real datasets demonstrate the state-of-the-art performance of CausalFormer on discovering temporal causality. Our code is available at https://github.com/lingbai-kong/CausalFormer. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Kong2024CausalFormer
ER  -

TY  - JOUR
AU  - She, Y.
AU  - Li, P.
AU  - Wei, M.
AU  - Liang, D.
AU  - Chen, Y.
AU  - Xie, H.
AU  - Lee Wang, F.
TI  - eViTBins: Edge-Enhanced Vision-Transformer Bins for Monocular Depth Estimation on Edge Devices
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 20320
EP  - 20334
DO  - 10.1109/TITS.2024.3480114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207947117&doi=10.1109%2fTITS.2024.3480114&partnerID=40&md5=5268849ebf939e5490798c7c9defb23a
AB  - Monocular depth estimation (MDE) remains a fundamental yet not well-solved problem in computer vision. Current wisdom of MDE often achieves blurred or even indistinct depth boundaries, degenerating the quality of vision-based intelligent transportation systems. This paper presents an edge-enhanced vision transformer bins network for monocular depth estimation, termed eViTBins. eViTBins has three core modules to predict monocular depth maps with exceptional smoothness, accuracy, and fidelity to scene structures and object edges. First, a multi-scale feature fusion module is proposed to circumvent the loss of depth information at various levels during depth regression. Second, an image-guided edge-enhancement module is proposed to accurately infer depth values around image boundaries. Third, a vision transformer-based depth discretization module is introduced to comprehend the global depth distribution. Meanwhile, unlike most MDE models that rely on high-performance GPUs, eViTBins is optimized for seamless deployment on edge devices, such as NVIDIA Jetson Nano and Google Coral SBC, making it ideal for real-time intelligent transportation systems applications. Extensive experimental evaluations corroborate the superiority of eViTBins over competing methods, notably in terms of preserving depth edges and global depth representations.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - She2024eViTBins
ER  -

TY  - JOUR
AU  - Zheng, X.
AU  - Bagloee, S.A.
AU  - Sarvi, M.
TI  - TRECK: Long-Term Traffic Forecasting with Contrastive Representation Learning
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 16964
EP  - 16977
DO  - 10.1109/TITS.2024.3421328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208705660&doi=10.1109%2fTITS.2024.3421328&partnerID=40&md5=5b8cc29a97b55aed0d5debb079db0762
AB  - Recent research mainly applies deep learning (DL) methods to short-term traffic forecasting. However, there is a growing interest in long-term forecasting, which allows action optimization at more steps in the future. Motivated by the encouraging success of contrastive representation learning, we propose a powerful and light framework, namely, Traffic Representation Extraction with Contrastive learning frameworK (TRECK), to improve traffic forecasting performance, especially for longer prediction terms. TRECK i) learns disentangled seasonal representations with contrastive learning, ii) enhances the learning of event data with entity embedding and iii) improves generalization and encourages obtaining more effective representations for the forecasting task through multi-task learning. TRECK can be directly applied to typical sequence-to-sequence DL prediction models. We evaluate TRECK when integrated with vanilla base models (RNN and BiLSTM) on large-size and real-world datasets. Experimental results show that TRECK can considerably boost the performance of base models and offer them the capability of handling increasing forecasting horizons. With TRECK, even a naive model like RNN can outperform state-of-the-art Transformer-based and GNN-based methods. Moreover, while avoiding any laborious feature design, the representations extracted by TRECK are more desirable than hand-crafted time features, yielding an 18.69% lower average MAE. Further analysis highlights its efficacy in diverse traffic conditions and in generating prediction intervals. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zheng2024TRECK
ER  -

TY  - JOUR
AU  - Nguyen, T.T.
AU  - Nguyen, T.T.
AU  - Weidlich, M.
AU  - Jo, J.
AU  - Nguyen, Q.V.H.
AU  - Yin, H.
AU  - Liew, A.W.-C.
TI  - Handling Low Homophily in Recommender Systems with Partitioned Graph Transformer
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
DO  - 10.1109/TKDE.2024.3485880
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208390157&doi=10.1109%2fTKDE.2024.3485880&partnerID=40&md5=303f14c3664eaf14ea69f337d26ed864
AB  - Modern recommender systems derive predictions from an interaction graph that links users and items. To this end, many of today's state-of-the-art systems use graph neural networks (GNNs) to learn effective representations of these graphs under the assumption of homophily, i.e., the idea that similar users will sit close to each other in the graph. However, recent studies have revealed that real-world recommendation graphs are often heterophilous, i.e., dissimilar users will also often sit close to each other. One of the reasons for this heterophilia is shilling attacks that obscure the inherent characteristics of the graph and make the derived recommendations less accurate as a consequence. Hence, to cope with low homophily in recommender systems, we propose a recommendation model called PGT4Rec that is based on a Partitioned Graph Transformer. The model integrates label information into the learning process, which allows discriminative neighbourhoods of users to be generated. As such, the framework can both detect shilling attacks and predict user ratings for items. Extensive experiments on real and synthetic datasets show PGT4Rec as not only providing superior performance in these two tasks but also significant robustness to a range of adversarial conditions.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Nguyen2024Handling
ER  -

TY  - JOUR
AU  - Zhao, J.
AU  - Zhuo, F.
AU  - Sun, Q.
AU  - Li, Q.
AU  - Hua, Y.
AU  - Zhao, J.
TI  - DSFormer-LRTC: Dynamic Spatial Transformer for Traffic Forecasting With Low-Rank Tensor Compression
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 16323
EP  - 16335
DO  - 10.1109/TITS.2024.3436523
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204807390&doi=10.1109%2fTITS.2024.3436523&partnerID=40&md5=12701bfe51d531b26ee1e48ebfd48f02
AB  - Traffic flow forecasting is challenging due to the intricate spatio-temporal correlations in traffic patterns. Previous works captured spatial dependencies based on graph neural networks and used fixed graph construction methods to characterize spatial relationships, which limits the ability of models to capture dynamic and long-range spatial dependencies. Meanwhile, prior studies did not consider the issue of a large number of redundant parameters in traffic prediction models, which not only increases the storage cost of the model but also reduces its generalization ability. To address the above challenges, we propose a Dynamic Spatial Transformer for Traffic Forecasting with Low-Rank Tensor Compression (DSFormer-LRTC). Specifically, we constructed a global spatial Transformer to capture remote spatial dependencies, and a distance-based mask matrix is used in local spatial Transformer to enhance the adjacent spatial influence. To reduce the complexity of the model, the model adopts a design that separates temporal and spatial. Meanwhile, we introduce low-rank tensor decomposition to reconstruct the parameter matrix in Transformer module to compress the proposed model. Experimental results show that DSFormer-LRTC achieves state-of-the-art performance on four real-world datasets. The experimental analysis of attention matrix also proves that the model can learn dynamic and distant spatial features. Finally, the compressed model parameters reduce the original parameter size by two-thirds, while significantly outperforming the baseline model in terms of computational efficiency.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhao2024DSFormer-LRTC
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Wang, S.
AU  - Zhu, J.
AU  - Xie, X.
AU  - Zhang, L.
TI  - Domain Adaptation Transformer for Unsupervised Driving-Scene Segmentation in Adverse Conditions
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 21129
EP  - 21141
DO  - 10.1109/TITS.2024.3461468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206256633&doi=10.1109%2fTITS.2024.3461468&partnerID=40&md5=6e319c7bf64b908829a1241c6728e9a8
AB  - Semantic segmentation in driving scenarios is important for modern autonomous driving technology. While the existing methods have shown promising results in segmenting normal-condition images, their performance in adverse scenes remains unsatisfactory due to limited visual field and lack of annotation. To address this issue, we propose an unsupervised domain adaptation semantic segmentation method with the transformer architecture, namely ACSegFormer, for driving-scene adverse conditions, aiming at mining image features in visually restricted scenes. Three effective training strategies are proposed in ACSegFormer to learn the latent image context relations and to reduce the gaps between different domains: an entropy-based pseudo label correction scheme that refines the target domain predictions with the normal reference predictions, an optimal transport-based inter-domain alignment module that performs domain alignment on the outputs of transformer encoder, and a masked context learning module that enhances the model's ability to perceive the missing information of target domain image. Our ACSegFormer has no additional training parameters on top of the existing transformer segmentation framework, which can be easily used for self-training-based unsupervised domain adaptation approaches. The experimental results show that our ACSegFormer achieves state-of-the-art performance on driving-scene segmentation benchmarks in adverse conditions, including Dark Zurich and ACDC. Codes and models are available at https://github.com/wenyyu/ACSegFormer. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Liu2024Domain
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Zhang, Y.-F.
AU  - Zhang, Z.
AU  - Wen, Q.
AU  - Wang, L.
TI  - LogoRA: Local-Global Representation Alignment for Robust Time Series Classification
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 12
SP  - 8718
EP  - 8729
DO  - 10.1109/TKDE.2024.3459908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204247974&doi=10.1109%2fTKDE.2024.3459908&partnerID=40&md5=4cd846fc8537f8cce5c856ea91371429
AB  - Unsupervised domain adaptation (UDA) of time series aims to teach models to identify consistent patterns across various temporal scenarios, disregarding domain-specific differences, which can maintain their predictive accuracy and effectively adapt to new domains. However, existing UDA methods struggle to adequately extract and align both global and local features in time series data. To address this issue, we propose the Local-Global Representation Alignment framework (LogoRA), which employs a two-branch encoder-comprising a multi-scale convolutional branch and a patching transformer branch. The encoder enables the extraction of both local and global representations from time series. A fusion module is then introduced to integrate these representations, enhancing domain-invariant feature alignment from multi-scale perspectives. To achieve effective alignment, LogoRA employs strategies like invariant feature learning on the source domain, utilizing triplet loss for fine alignment and dynamic time warping-based feature alignment. Additionally, it reduces source-target domain gaps through adversarial training and per-class prototype alignment. Our evaluations on four time-series datasets demonstrate that LogoRA outperforms strong baselines by up to 12.52%, showcasing its superiority in time series UDA tasks.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Zhang2024LogoRA
ER  -

TY  - JOUR
AU  - Cao, H.
AU  - Chen, G.
AU  - Zhao, H.
AU  - Jiang, D.
AU  - Zhang, X.
AU  - Tian, Q.
AU  - Knoll, A.
TI  - SDPT: Semantic-Aware Dimension-Pooling Transformer for Image Segmentation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 15934
EP  - 15946
DO  - 10.1109/TITS.2024.3417813
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203146661&doi=10.1109%2fTITS.2024.3417813&partnerID=40&md5=7214e77593b55b9c92ca2ba67dd56709
AB  - Image segmentation plays a critical role in autonomous driving by providing vehicles with a detailed and accurate understanding of their surroundings. Transformers have recently shown encouraging results in image segmentation. However, transformer-based models are challenging to strike a better balance between performance and efficiency. The computational complexity of the transformer-based models is quadratic with the number of inputs, which severely hinders their application in dense prediction tasks. In this paper, we present the semantic-aware dimension-pooling transformer (SDPT) to mitigate the conflict between accuracy and efficiency. The proposed model comprises an efficient transformer encoder for generating hierarchical features and a semantic-balanced decoder for predicting semantic masks. In the encoder, a dimension-pooling mechanism is used in the multi-head self-attention (MHSA) to reduce the computational cost, and a parallel depth-wise convolution is used to capture local semantics. Simultaneously, we further apply this dimension-pooling attention (DPA) to the decoder as a refinement module to integrate multi-level features. With such a simple yet powerful encoder-decoder framework, we empirically demonstrate that the proposed SDPT achieves excellent performance and efficiency on various popular benchmarks, including ADE20K, Cityscapes, and COCO-Stuff. For example, our SDPT achieves 48.6% mIOU on the ADE20K dataset, which outperforms the current methods with fewer computational costs. The codes can be found at https://github.com/HuCaoFighting/SDPT.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Cao2024SDPT
ER  -

TY  - JOUR
AU  - Paltenghi, M.
AU  - Pandita, R.
AU  - Henley, A.Z.
AU  - Ziegler, A.
TI  - Follow-Up Attention: An Empirical Study of Developer and Neural Model Code Exploration
PY  - 2024
T2  - IEEE Transactions on Software Engineering
VL  - 50
IS  - 10
SP  - 2568
EP  - 2582
DO  - 10.1109/TSE.2024.3445338
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201757668&doi=10.1109%2fTSE.2024.3445338&partnerID=40&md5=69ceca00c920953c22da0d44f7d5ea84
AB  - Recent neural models of code, such as OpenAI Codex and AlphaCode, have demonstrated remarkable proficiency at code generation due to the underlying attention mechanism. However, it often remains unclear how the models actually process code, and to what extent their reasoning and the way their attention mechanism scans the code matches the patterns of developers. A poor understanding of the model reasoning process limits the way in which current neural models are leveraged today, so far mostly for their raw prediction. To fill this gap, this work studies how the processed attention signal of three open large language models - CodeGen, InCoder and GPT-J - agrees with how developers look at and explore code when each answers the same sensemaking questions about code. Furthermore, we contribute an open-source eye-tracking dataset comprising 92 manually-labeled sessions from 25 developers engaged in sensemaking tasks. We empirically evaluate five heuristics that do not use the attention and ten attention-based post-processing approaches of the attention signal of CodeGen against our ground truth of developers exploring code, including the novel concept of follow-up attention which exhibits the highest agreement between model and human attention. Our follow-up attention method can predict the next line a developer will look at with 47% accuracy. This outperforms the baseline prediction accuracy of 42.3%, which uses the session history of other developers to recommend the next line. These results demonstrate the potential of leveraging the attention signal of pre-trained models for effective code exploration. © 1976-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Paltenghi2024Follow-Up
ER  -

TY  - JOUR
AU  - Li, T.-B.
AU  - Liu, A.-A.
AU  - Song, D.
AU  - Li, W.-H.
AU  - Zhang, J.
AU  - Wei, Z.-Q.
AU  - Su, Y.-T.
TI  - Multi-Task Spatial-Temporal Transformer for Multi-Variable Meteorological Forecasting
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 12
SP  - 8876
EP  - 8888
DO  - 10.1109/TKDE.2024.3432599
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199524783&doi=10.1109%2fTKDE.2024.3432599&partnerID=40&md5=afaf30c4991aa6205e4ff63c14906f17
AB  - This study delves into multi-variable meteorological spatial-temporal prediction, focusing on the simultaneous forecasting of key meteorological parameters such as temperature, wind speed, and atmospheric pressure. The core challenge of this task lies in identifying commonalities across different variables while capturing their unique features and the interactions among them. To address this, we propose a novel multi-task learning framework tailored for multi-variable meteorological forecasting. Our framework integrates a convolutional variable-specific visual representation module and a variable-interactive spatial-temporal inference module. The former extracts distinct variable information independently for each variable, while the latter employs a tri-level attention mechanism across space, time, and variables to uncover both commonalities and interactions among the variables. An adaptive multi-loss optimization strategy and a local information aggregation module are introduced to balance task optimization complexities and enhance representation stability. Comprehensive experiments across various meteorological prediction tasks confirm the effectiveness of our methods, showcasing superior performance over existing approaches. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Li2024Multi-Task
ER  -

TY  - JOUR
AU  - Tran, T.V.T.
AU  - Hy, T.S.
TI  - Protein Design by Directed Evolution Guided by Large Language Models
PY  - 2024
T2  - IEEE Transactions on Evolutionary Computation
SP  - 1
EP  - 1
DO  - 10.1109/TEVC.2024.3439690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200825151&doi=10.1109%2fTEVC.2024.3439690&partnerID=40&md5=bdac6ac3c132fb7d3f5f62c01058878a
AB  - Directed evolution, a strategy for protein engineering, optimizes protein properties (i.e., fitness) by a rigorous and resource-intensive process of screening or selecting among a vast range of mutations. By conducting an in silico screening of sequence properties, machine learning-guided directed evolution (MLDE) can expedite the optimization process and alleviate the experimental workload. In this work, we propose a general MLDE framework in which we apply recent advancements of Deep Learning in protein representation learning and protein property prediction to accelerate the searching and optimization processes. In particular, we introduce an optimization pipeline that utilizes Large Language Models (LLMs) to pinpoint the mutation hotspots in the sequence and then suggest replacements to improve the overall fitness. Our experiments have shown the superior efficiency and efficacy of our proposed framework in the conditional protein generation, in comparision with other state-of-the-art baseline algorithms. We expect this work will shed a new light on not only protein engineering but also on solving combinatorial problems using data-driven methods. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; AJG:4; zdy:4; 
LB  - Tran2024Protein
ER  -

TY  - JOUR
AU  - Ye, M.
AU  - Yu, Y.
AU  - Shen, Z.
AU  - Yu, W.
AU  - Zeng, Q.
TI  - Cross-Feature Interactive Tabular Data Modeling With Multiplex Graph Neural Networks
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 12
SP  - 7851
EP  - 7864
DO  - 10.1109/TKDE.2024.3440654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200798036&doi=10.1109%2fTKDE.2024.3440654&partnerID=40&md5=0eb7ad6ff9f4b2ba43ecc19e6b259135
AB  - The rising popularity of tabular data in data science applications has led to a surge of interest in utilizing deep neural networks (DNNs) to address tabular problems. Existing deep neural network methods are not effective in handling two fundamental challenges that are inherent in tabular data: permutation invariance (where the labels remain unchanged regardless of element order) and local dependency (where predictive labels are solely determined by local features). Furthermore, given the inherent heterogeneity among elements in tabular data, effectively capturing heterogeneous feature interactions remains unresolved. In this paper, we propose a novel Multiplex Cross-Feature Interaction Network (MPCFIN) by explicitly and systematically modeling feature relations with interactive graph neural networks. Specifically, MPCFIN first learns the most relevant features associated with individual features, and merges them to form cross-feature embedding. Subsequently, we design a multiplex graph neural network to learn enhanced representation for each sample. Comprehensive experiments on seven datasets demonstrate that MPCFIN exhibits superior performance over deep neural network methods in modeling the tabular data, showcasing consistent interpretability in its cross-feature embedding module for medical diagnosis applications. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Ye2024Cross-Feature
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Liu, C.
TI  - Real-Time Pavement Damage Detection With Damage Shape Adaptation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 18954
EP  - 18963
DO  - 10.1109/TITS.2024.3416508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197590813&doi=10.1109%2fTITS.2024.3416508&partnerID=40&md5=71d8296607b63b305cd340da03347e06
AB  - Intelligent detection of pavement damage is crucial to road maintenance. Timely identification of cracks and potholes helps prolong the road service life. Current detection models fail to balance accuracy and speed. In this study, we propose a fast damage detection algorithm named FPDDN to achieve real-time and high-accuracy pavement damage detection. FPDDN integrates the deformable transformer, D2f block, and SFB module to predict pavement damage of different sizes in multiple branches. The deformable transformer allows the FPDDN to exhibit adaptability to geometric variations in road defects, thereby improving the detection accuracy of irregular defects such as cracks. D2f block is mainly used to lightweight the network and increase the inference speed. The SFB module can significantly decrease the loss of information during downsampling of small-sized objects. This integration enhances the model's ability to extract global damage features, reduces the loss of information on small-scale defects, and improves the synergy between deep and shallow feature layers. The model's performance was evaluated using the RDD2022 dataset, focusing on inference speed and detection accuracy. When compared to state-of-the-art models such as YOLO v8, FPDDN has a parameter count that is only one-fifth of that of YOLO v8x, yet it surpasses YOLO v8x in detection accuracy. The FPDDN achieved an F1 score of 0.601 and a mAP50 of 0.610 on the RDD2022 dataset, outperforming the compared models. Additionally, the algorithm achieved a balance between accuracy and speed with an inference speed of 1.8ms for pavement damage detection.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2024Real-Time
ER  -

TY  - JOUR
AU  - Gonsior, J.
AU  - Falkenberg, C.
AU  - Magino, S.
AU  - Reusch, A.
AU  - Hartmann, C.
AU  - Thiele, M.
AU  - Lehner, W.
TI  - Comparing and Improving Active Learning Uncertainty Measures for Transformer Models by Discarding Outliers
PY  - 2024
T2  - Information Systems Frontiers
DO  - 10.1007/s10796-024-10503-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197103717&doi=10.1007%2fs10796-024-10503-z&partnerID=40&md5=9a5f6909b7df4e90853d8fc70580bbc2
AB  - Despite achieving state-of-the-art results in nearly all Natural Language Processing applications, fine-tuning Transformer-encoder based language models still requires a significant amount of labeled data to achieve satisfying work. A well known technique to reduce the amount of human effort in acquiring a labeled dataset is Active Learning (AL): an iterative process in which only the minimal amount of samples is labeled. AL strategies require access to a quantified confidence measure of the model predictions. A common choice is the softmax activation function for the final Neural Network layer. In this paper, we compare eight alternatives on seven datasets and show that the softmax function provides misleading probabilities. Our finding is that most of the methods primarily identify hard-to-learn-from samples (commonly called outliers), resulting in worse than random performance, instead of samples, which actually reduce the uncertainty of the learned language model. As a solution, this paper proposes Uncertainty-Clipping, a heuristic to systematically exclude samples, which results in improvements for most methods compared to the softmax function. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Gonsior2024Comparing
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Huang, B.
AU  - Jia, B.
AU  - Gao, Y.
AU  - Qiao, J.
TI  - MAS-DSO: Advancing Direct Sparse Odometry With Multi-Attention Saliency
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 17468
EP  - 17481
DO  - 10.1109/TITS.2024.3414171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197643507&doi=10.1109%2fTITS.2024.3414171&partnerID=40&md5=6f7876b1146e26ecc718c53f7ba2e142
AB  - Visual odometry (VO) is a critical component of simultaneous localization and mapping (SLAM) with extensive applications in robot navigation and beyond. However, prevalent VO methods often underperform in intricate environments with dynamic textures, insufficient lighting, and rapid rotational movements, primarily due to constrained feature selection and inadequate image structure comprehension. To address these challenges, this paper proposes a novel VO framework, termed Multi-Attention Saliency Direct Sparse Odometry (MAS-DSO). Specifically, MAS-DSO significantly bolsters performance and robustness through accurate recognition of visually salient regions and deep understanding of image structures. With regard to the problem of limited feature selection, we propose a Saliency Transformer Generative Adversarial Network (STRGAN) based on a multi-attention mechanism, narrowing the feature selection scope and enhancing its accuracy. Addressing the issue of limited understanding of image structure, we introduce a robust method for gradient computation to accurately determine the gradient values of features. Building on this, we have designed a dynamic gradient weight adjustment strategy that takes into account both the gradient magnitude and local image structure, thereby achieving precise gradient weight distribution. Comprehensive quantitative evaluations on the ICL-NUIM and TUM monoVO datasets reveal that MAS-DSO not only outperforms SalientDSO, DSO, and ORB-SLAM in performance metrics but also significantly surpasses other methods in saliency prediction performance and mapping quality. In conclusion, MAS-DSO not only augments feature selection efficiency but also enhances the processing prowess for diverse images in complex settings.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Li2024MAS-DSO
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Wang, Z.
AU  - Du, B.
AU  - Wu, J.
AU  - Zhang, X.
AU  - Meng, E.
TI  - Deep Session Heterogeneity-Aware Network for Click Through Rate Prediction
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 12
SP  - 7927
EP  - 7939
DO  - 10.1109/TKDE.2024.3421594
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197541228&doi=10.1109%2fTKDE.2024.3421594&partnerID=40&md5=4bb64f8feca8c521798141a7eff41e4a
AB  - CTR (Click-Through Rate) prediction plays an essential role in online advertising systems. Most existing works attempt to capture users' interests from sessions by assuming that behaviors within a session are homogeneous. However, user interest may change frequently. Thus it is hard to guarantee that behaviors in a session are homogeneous, resulting in users' interests extracted from sessions being biased. In this paper, we propose a model named Deep Session Heterogeneity-aware Network (DSHN) by learning the relationships of behaviors within sessions and the relevance between the session and target item to alleviate the influence of irrelevant or heterogeneous sessions. We design a heterogeneity-aware mechanism to learn the heterogeneity of items within a session. Then we further design two modules: the Session Heterogeneity Learning module and the Relevance Inference module. The Session Heterogeneity Learning module weighs each session by summarizing the variation of session interest with and without any behavior. The relevance Inference module learns the relevance between the target item and each session in a similar way by learning session interest with and without the target item. Extensive experiments on four datasets demonstrate that our proposed DSHN achieves better results compared to the state-of-the-art. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Zhang2024Deep
ER  -

TY  - JOUR
AU  - Zhu, A.
AU  - Xiao, Y.
AU  - Liu, C.
AU  - Tan, M.
AU  - Cao, Z.
TI  - Lightweight LiDAR-Camera Alignment With Homogeneous Local-Global Aware Representation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 15922
EP  - 15933
DO  - 10.1109/TITS.2024.3409397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196087930&doi=10.1109%2fTITS.2024.3409397&partnerID=40&md5=0d95bcdb53cfa3af582d578338454f00
AB  - In this paper, a novel LiDAR-Camera Alignment (LCA) method using homogeneous local-global spatial aware representation is proposed. Compared with the state-of-the-art methods (e.g., LCCNet), our proposition holds 2 main superiorities. First, homogeneous multi-modality representation learned with a uniform CNN model is applied along the iterative prediction stages, instead of the state-of-the-art heterogeneous counterparts extracted from the separated modality-wise CNN models within each stage. In this way, the model size can be significantly decreased (e.g., 12.39M (ours) vs. 333.75M (LCCNet)). Meanwhile, within our proposition the interaction between LiDAR and camera data is built during feature learning to better exploit the descriptive clues, which has not been well concerned by the existing approaches. Secondly, we propose to equip the learned LCA representation with local-global spatial aware capacity via encoding CNN’s local convolutional features with Transformer’s non-local self-attention manner. Accordingly, the local fine details and global spatial context can be jointly captured by the encoded local features. And, they will be jointly used for LCA. On the other hand, the existing methods generally choose to reveal the global spatial property via intuitively concatenating the local features. Additionally at the initial LCA stage, LiDAR is roughly aligned with camera by our pre-alignment method, according to the point distribution characteristics of its 2D projection version with the initial extrinsic parameters. Although its structure is simple, it can essentially alleviate LCA’s difficulty for the consequent stages. To better optimize LCA, a novel loss function that builds the correlation between translation and rotation loss items is also proposed. The experiments on KITTI data verifies the superiority of our proposition both on effectiveness and efficiency. The source code will be released at https://github.com/Zaf233/Light-weight-LCA upon acceptance. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhu2024Lightweight
ER  -

TY  - JOUR
AU  - Han, L.
AU  - Ye, H.-J.
AU  - Zhan, D.-C.
TI  - The Capacity and Robustness Trade-Off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 11
SP  - 7129
EP  - 7142
DO  - 10.1109/TKDE.2024.3400008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193234295&doi=10.1109%2fTKDE.2024.3400008&partnerID=40&md5=56b9a4293d759c437505adeeaf60024a
AB  - Multivariate time series data comprises various channels of variables. The multivariate forecasting models need to capture the relationship between the channels to accurately predict future values. However, recently, there has been an emergence of methods that employ the Channel Independent (CI) strategy. These methods view multivariate time series data as separate univariate time series and disregard the correlation between channels. Surprisingly, our empirical results have shown that models trained with the CI strategy outperform those trained with the Channel Dependent (CD) strategy, usually by a significant margin. Nevertheless, the reasons behind this phenomenon have not yet been thoroughly explored in the literature. This paper provides comprehensive empirical and theoretical analyses of the characteristics of multivariate time series datasets and the CI/CD strategy. Our results conclude that the CD approach has higher capacity but often lacks robustness to accurately predict distributionally drifted time series. In contrast, the CI approach trades capacity for robust prediction. Practical measures inspired by these analyses are proposed to address the capacity and robustness dilemma, including a modified CD method called Predict Residuals with Regularization (PRReg) that can surpass the CI strategy. We hope our findings can raise awareness among researchers about the characteristics of multivariate time series and inspire the construction of better forecasting models.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:A期刊; FMS:B; 
LB  - Han2024Capacity
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Fu, M.
AU  - Song, W.
AU  - Yang, Y.
AU  - Alahi, A.
TI  - Dynamic Voxels Based on Ego-Conditioned Prediction: An Integrated Spatio-Temporal Framework for Motion Planning
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 10
SP  - 14973
EP  - 14985
DO  - 10.1109/TITS.2024.3398008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194083536&doi=10.1109%2fTITS.2024.3398008&partnerID=40&md5=d00fc0d75f9cbbcbbdea0f5e25d24901
AB  - Prediction is a vital component of motion planning for autonomous vehicles (AVs). By reasoning about the possible behavior of other target agents, the ego vehicle (EV) can navigate safely, efficiently, and politely. However, most of the existing work overlooks the interdependencies of the prediction and planning module, only connecting them in a sequential pipeline or underexploring the prediction results in the planning module. In this work, we propose a framework that integrates the prediction and planning module with three highlights. First, we propose an ego-conditioned model for causal prediction, with the introduced edge-featured graph transformer model, the impact the ego future maneuver poses to the target vehicles is demonstrated. Second, we develop a motion planner based on 'dynamic voxels' in the spatio-temporal domain, enabling the time-to-collision criterion evaluation and the optimal trajectory generation in continuous space. Third, the prediction and planning modules are coupled in a closed-loop and efficient form. Specifically, taking each maneuver as a cluster, representative trajectory primitives are generated for conditional prediction, and conversely, prediction results are used to score the primitives as guidance, which alleviates the duplicated callback of the prediction module. The simulations are conducted in overtaking, merging, unprotected left turns, and also scenarios with imperfect social behaviors. The comparison studies demonstrate the better safety assurance and efficiency of the proposed model, and the ablation experiments further reveal the effectiveness of the new ideas. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2024Dynamic
ER  -

TY  - JOUR
AU  - Du, J.
AU  - Ma, L.
AU  - Li, J.
AU  - Qin, N.
AU  - Zelek, J.
AU  - Guan, H.
AU  - Li, J.
TI  - RdmkNet & Toronto-RDMK: Large-Scale Datasets for Road Marking Classification and Segmentation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 10
SP  - 13467
EP  - 13482
DO  - 10.1109/TITS.2024.3394481
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192987732&doi=10.1109%2fTITS.2024.3394481&partnerID=40&md5=f6b264f9836e40a0fef5f643ff40a966
AB  - Effective road marking classification and segmentation play a pivotal role in advancing vehicle-to-everything (V2X) applications and refining road inventory databases. However, the irregular data formats and unordered permutation modes of 3D point clouds, along with the limited availability of large-scale datasets with point-level annotations, remain significant obstacles to designing deep learning-based networks with superior performance. To address these challenges, this paper proposes a novel multi-level feature optimization network structure, named MFPNet, and introduces two point cloud benchmarks, RdmkNet and Toronto-Rdmk, for road marking classification and segmentation in intricate urban environments. MFPNet is composed of three integral modules. First, the M-transformer module, consisting of three transformers obtained from different channels, fully captures rich point cloud background information and long-distance dependencies between objects. Then, the feature pooling aggregation module uses parallel structured pooling attention mechanisms to aggregate features captured by the M-transformer module, while the prediction refinement module further enhances the acquisition of semantic features. Comparative studies indicate that MFPNet can be embedded into general deep learning networks without changing their original network structures, significantly improving the accuracy of multiple baseline networks. Furthermore, extensive experiments demonstrate that the two newly-developed point cloud datasets are meaningful for road marking classification and segmentation tasks, contributing to the development of autonomous driving.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Du2024RdmkNet
ER  -

TY  - JOUR
AU  - Xu, Q.
AU  - Pang, Y.
AU  - Zhou, X.
AU  - Liu, Y.
TI  - PIGAT: Physics-Informed Graph Attention Transformer for Air Traffic State Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 12561
EP  - 12577
DO  - 10.1109/TITS.2024.3386128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190773704&doi=10.1109%2fTITS.2024.3386128&partnerID=40&md5=8b7a553d5510977517db4ffd795cb500
AB  - Efficient and resilient traffic management relies on accurate prediction of air traffic states. However, the complex spatial-temporal dependencies of air traffic networks make this task challenging. To address this issue, we propose a novel deep learning framework, named Physics-Informed Graph Attention Transformer (PIGAT), which leverages real-world data and knowledge to predict essential air traffic state parameters. Our approach utilizes fine-grained traffic state detection to extract critical features from aviation databases. The model employs GAT-based spatial learning blocks with temporal Transformers to capture the dynamic spatial-temporal dependencies of data. A dynamic graph generator layer is also utilized to update the airport network's topological structure adaptively, strengthening the model prediction's effectiveness. Furthermore, the fluid queuing-theoretic PDEs are incorporated into the loss function, enhancing the model's interpretability and reliability. Our framework is evaluated on real-world air traffic datasets from 36 major airport hubs within the US. Experimental results demonstrate that our proposed framework efficiently makes accurate predictions and outperforms eight baselines. In conclusion, our proposed framework has the potential to be applied in real-time decision-making systems for air traffic management and provides promising directions for future research. The code for our project is available at: https://github.com/ymlasu/para-atm-collection/tree/master/air-traffic-prediction/PIGAT.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2024PIGAT
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Li, B.
AU  - Wang, X.
AU  - Sammut, C.
AU  - Yao, L.
TI  - Attention-Aware Social Graph Transformer Networks for Stochastic Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 11
SP  - 5633
EP  - 5646
DO  - 10.1109/TKDE.2024.3390765
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190774864&doi=10.1109%2fTKDE.2024.3390765&partnerID=40&md5=00f3dc739b1adb9ec716400cd3ec9e5f
AB  - Trajectory prediction is fundamental to various intelligent technologies, such as autonomous driving and robotics. The motion prediction of pedestrians and vehicles helps emergency braking, reduces collisions, and improves traffic safety. Current trajectory prediction research faces problems of complex social interactions, high dynamics and multi-modality. Especially, it still has limitations in long-time prediction. We propose Attention-aware Social Graph Transformer Networks for multi-modal trajectory prediction. We combine Graph Convolutional Networks and Transformer Networks by generating stable resolution pseudo-images from Spatio-temporal graphs through a designed stacking and interception method. Furthermore, we design the attention-aware module to handle social interaction information in scenarios involving mixed pedestrian-vehicle traffic. Thus, we maintain the advantages of the Graph and Transformer, i.e., the ability to aggregate information over an arbitrary number of neighbors and the ability to perform complex time-dependent data processing. We conduct experiments on datasets involving pedestrian, vehicle, and mixed trajectories, respectively. Our results demonstrate that our model minimizes displacement errors across various metrics and significantly reduces the likelihood of collisions. It is worth noting that our model effectively reduces the final displacement error, illustrating the ability of our model to predict for a long time.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:A期刊; FMS:B; 
LB  - Liu2024Attention-Aware
ER  -

TY  - JOUR
AU  - Liu, D.
AU  - Wang, Y.
AU  - Liu, C.
AU  - Yuan, X.
AU  - Wang, K.
AU  - Yang, C.
TI  - Scope-Free Global Multi-Condition-Aware Industrial Missing Data Imputation Framework via Diffusion Transformer
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 11
SP  - 6977
EP  - 6988
DO  - 10.1109/TKDE.2024.3392897
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191355452&doi=10.1109%2fTKDE.2024.3392897&partnerID=40&md5=789f0811e199ce2c080d03c50fbce95b
AB  - Missing data is a common phenomenon in the industrial field. The recovery of missing data is crucial to enhance the reliability of subsequent data-driven monitoring and control of industrial processes. Most existing methods are limited by the confined scope of feature extraction, which makes it impossible to rely on global information to impute missing data. In addition, they usually assume that industrial data is a uniform distribution across all working conditions, ignoring the differences in data evolution patterns across different conditions. To address these issues, this paper proposes an innovative scope-free global multi-condition-aware imputation framework based on diffusion transformer (SGMCAI-DiT). First, it extends the diffusion model by introducing conditional probability to capture the condition distribution of the entire data. Then, a noise prediction model is designed based on a novel double-weighted attention mechanism (DW-SA) to broaden the horizons of feature extraction. By discerning the inter-conditional interactions and the intra-conditional local information, the missing data imputation performance can be improved. Finally, the effectiveness and suitability of the proposed SGMCAI-DiT are verified on four real datasets sourced from industrial processes and two public non-industrial datasets. Extensive experimental results demonstrate that the proposed method outperforms several state-of-the-art methods in different missing data scenarios.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:A期刊; FMS:B; 
LB  - Liu2024Scope-Free
ER  -

TY  - JOUR
AU  - Lim, S.
AU  - El-Basyouny, K.
AU  - Yang, Y.H.
TI  - PU-Ray: Domain-Independent Point Cloud Upsampling via Ray Marching on Neural Implicit Surface
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 10
SP  - 14600
EP  - 14610
DO  - 10.1109/TITS.2024.3388276
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191344426&doi=10.1109%2fTITS.2024.3388276&partnerID=40&md5=545190812f640dc3c170202fb7e577db
AB  - While recent advancements in deep-learning point cloud upsampling methods have improved the input to intelligent transportation systems, they still suffer from issues of domain dependency between synthetic and real-scanned point clouds. This paper addresses the above issues by proposing a new ray-based upsampling approach with an arbitrary rate, where a depth prediction is made for each query ray and its corresponding patch. Our novel method simulates the sphere-tracing ray marching algorithm on the neural implicit surface defined with an unsigned distance function (UDF) to achieve more precise and stable ray-depth predictions by training a point-transformer-based network. The rule-based mid-point query sampling method generates more evenly distributed points without requiring an end-to-end model trained using a nearest-neighbor-based reconstruction loss function, which may bias towards the training dataset. Self-supervised learning becomes possible with accurate ground truths within the input point cloud. The results demonstrate the method's versatility across domains and training scenarios with limited computational resources and training data. Comprehensive analyses of synthetic and real-scanned applications provide empirical evidence for the significance of the upsampling task across the computer vision and graphics domains to real-world applications of ITS.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Lim2024PU-Ray
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, S.
AU  - Li, J.
AU  - Yang, J.
TI  - Pedestrian Crossing Intention Prediction Based on Cross-Modal Transformer and Uncertainty-Aware Multi-Task Learning for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 12538
EP  - 12549
DO  - 10.1109/TITS.2024.3386689
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191291992&doi=10.1109%2fTITS.2024.3386689&partnerID=40&md5=6dfda09332c3c4e5f3f31ed8aab97e8e
AB  - Accurate prediction of whether pedestrians will cross the street is prevalently recognized as an indispensable function of autonomous driving systems, especially in urban environments. How to utilize the complementary information present in different types of data (or modalities) is one of the major challenges. This paper makes the first attempt to develop a cross-modal transformer-based crossing intention prediction model merely using bounding boxes and ego-vehicle speed as input features. The cross-modal transformer can leverage self-attention and cross-modal attention to mine the modality-specific and complementary correlation. A bottleneck feature fusion is presented to obtain the compressed feature representation. To facilitate the network training, we further put forward a novel uncertainty-aware multi-task learning method that jointly predicts the future bounding box as well as crossing action such that the commonalities and differences across two tasks can be exploited. To evaluate the proposed method, extensive comparative experiments and ablation studies are performed on two benchmark datasets. The results demonstrate that by only using the bounding box and ego-vehicle speed as input features, our model is on a par with other state-of-the-art approaches that rely on more inputs, and even achieves superior performance in most cases. The source code will be released at https://github.com/xbchen82/PedCMT.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2024Pedestrian
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Wei, Z.
AU  - He, H.
AU  - Wei, H.
AU  - Li, S.
AU  - Gao, F.
TI  - Ensembled Traffic-Aware Transformer-Based Predictive Energy Management for Electrified Vehicles
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 12333
EP  - 12346
DO  - 10.1109/TITS.2024.3375331
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188932247&doi=10.1109%2fTITS.2024.3375331&partnerID=40&md5=62da0869b0d47990368fd96261d5f06b
AB  - The predictive energy management strategy (PEMS) offers potential advantages in enhancing the driving economy of electrified vehicles using vehicle speed prediction. However, realizing accurate predictions in practical contexts remains a challenge. Departing from conventional PEMS that rely on historical speed or static traffic data, we introduce a real-time traffic-aware PEMS for improved performance. To better understand the interplay between the host vehicle and its surrounding traffic, we use a Transformer network as the predictor that employs the speeds and relative distances of the surrounding six vehicles to forecast future speed sequences for the host vehicle. To augment this data-driven approach, we develop a dual-predictor strategy based on the deep ensemble technique. This strategy measures the Transformer's output uncertainty to gauge prediction reliability and introduce an automated threshold mechanism. Based on this threshold and real-time uncertainties, the strategy chooses between the Transformer and an exponential predictor to achieve improved prediction outcomes. A reinforcement learning method is integrated as the PEMS optimizer. For validation, we generate training data with traffic information based on the next generation simulation (NGSIM) dataset and create a test scenario in the SUMO simulator. The results confirm that speed predictions based on real-time traffic data surpass traditional PEMS, either directly inputting traffic data or excluding it. The Transformer predictor significantly outperforms the state-of-the-art predictor. Importantly, our dual-predictor design amplifies prediction accuracy by 27.2% against the standard single-network predictor under non-training conditions. Overall, our PEMS enhances driving economy by 11.1% relative to traffic-unaware models and 8.0% over non-Transformer schemes.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Wu2024Ensembled
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Alam, S.
AU  - Cai, Q.
AU  - Delahaye, D.
TI  - Text-Enriched Air Traffic Flow Modeling and Prediction Using Transformers
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7963
EP  - 7976
DO  - 10.1109/TITS.2024.3379210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189817261&doi=10.1109%2fTITS.2024.3379210&partnerID=40&md5=58fdfa28a7bd37fef3ecb8d31c88f2b1
AB  - The air traffic control paradigm is shifting from sector-based operations to flow-centric approaches to overcome sectors' geographical limits. Modeling and predicting intersecting air traffic flows can assist controllers in flow coordination under the flow-centric paradigm. This paper proposes a flow-centric framework- TEMPT: Text-Enriched air traffic flow Modeling and Prediction using Transformers- to identify, represent, and predict intersecting flows in the airspace. Firstly, nominal flow intersections (NFI) are identified through hierarchical clustering of flight trajectory intersections. A flow pattern consistency-based graph analytics approach is proposed to determine the number of NFIs. Secondly, in contrast to the traditional traffic flow feature representation, i.e., numerical time series of flights, this paper proposes a text-enriched flow feature representation to intuitively describe the 'flow of flights' in the airspace. More specifically, air traffic flow features are described by a 'text paragraph' composed of the time and flight sequences transiting through the NFIs. Finally, a transformer neural network model is adopted to learn the text-enriched flow features and predict the future traffic demand at the NFIs during future time windows. An experimental study was carried out in French airspace to validate the efficacy of TEMPT using one-month ADS-B data in December 2019. Prediction results show that TEMPT outperforms the competitive air traffic flow modeling and prediction approaches: time-series-based Transformers, Long Short-term Memory (LSTM), and Graph Convolutional Networks (GCN), as well as aerodynamic trajectory simulation-based prediction and the historical average.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Ma2024Text-Enriched
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Wang, Z.
AU  - Ning, N.
AU  - Jin, Z.
AU  - Lu, N.
AU  - Shen, X.
TI  - I2T: From Intention Decoupling to Vehicular Trajectory Prediction Based on Prioriformer Networks
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 9411
EP  - 9426
DO  - 10.1109/TITS.2024.3375900
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188951414&doi=10.1109%2fTITS.2024.3375900&partnerID=40&md5=e0bd04232279d6820803d3a2256f8dec
AB  - A reliable driving trajectory prediction of surrounding vehicles is an essential reference for decision-making and safe driving of an autonomous vehicle. Although predicting short-Term trajectories can be well achieved, it is still very challenging for long-Term prediction of trajectories since the prediction space grows exponentially. In this paper, we propose a novel architecture for trajectory prediction from factored intention estimation (I2T), which decouples the trajectory prediction space into a high-level space for intention estimation and a low-level space for motion prediction. The long-Term dependencies between intention cues and future motions during driving are naturally extended to the internal sharing mechanism of I2T, leading to improved performance. Furthermore, we design a Prioriformer model to serve as the backbone network for I2T so that it can accurately capture the long-Term dependency couplings related to the task of intention estimation or motion prediction. Prioriformer model adopts a personalized normalization method, which facilitates learning latent representations of long-Term features and avoids getting stuck on local optimum. A designed multi-scale fusion encoder extracts features from various receptive fields and then learns richer information from the representation subspaces. An efficient non-Autoregressive decoder reduces the pressure in long-Term prediction of trajectories while avoiding cumulative errors. Experiments on three real-world motion datasets show that I2T can significantly outperform the state-of-The-Art.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024I2T
ER  -

TY  - JOUR
AU  - Yan, X.
AU  - Gan, X.
AU  - Tang, J.
AU  - Zhang, D.
AU  - Wang, R.
TI  - ProSTformer: Progressive Space-Time Self-Attention Model for Short-Term Traffic Flow Forecasting
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 10802
EP  - 10816
DO  - 10.1109/TITS.2024.3367754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188012766&doi=10.1109%2fTITS.2024.3367754&partnerID=40&md5=1d45801dc725abc72fa10071ad67b52c
AB  - Traffic flow forecasting is essential and challenging to intelligent city management and public safety. In this paper, we attempt to use a pure self-attention method in traffic flow forecasting. However, when dealing with input sequences, including large-scale regions' historical records, it is difficult for the self-attention mechanism to focus on the most relevant ones for forecasting. To address this issue, we design a progressive space-time self-attention mechanism named ProSTformer, which can reduce self-attention computation times from thousands to tens. Our design is based on two pieces of prior knowledge in the traffic flow forecasting literature: (i) spatiotemporal dependencies can be factorized into spatial and temporal dependencies; (ii) adjacent regions have more influences than distant regions, and temporal characteristics of closeness, period and trend are more important than crossed relations between them. Our ProSTformer has two characteristics. First, each block in ProSTformer highlights the unique dependencies, ProSTformer progressively focuses on spatial dependencies from local to global regions, on temporal dependencies from closeness, period and trend to crossed relations between them, and on external dependencies such as weather conditions, temperature and day-of-week. Second, we use the Tensor Rearranging technique to force the model to compute self-attention only to adjacent regions and to the unique temporal characteristic. Then, we use the Patch Merging technique to greatly reduce self-attention computation times to distant regions and crossed temporal relations. We evaluate ProSTformer on two traffic datasets and find that it performs better than sixteen baseline models. The code is available at https://github.com/yanxiao1930/ProSTformer_code/tree/main.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Yan2024ProSTformer
ER  -

TY  - JOUR
AU  - Cao, J.
AU  - Di, X.
AU  - Liu, X.
AU  - Li, J.
AU  - Li, Z.
AU  - Zhao, L.
AU  - Hawbani, A.
AU  - Guizani, M.
TI  - Anomaly Detection for In-Vehicle Network Using Self-Supervised Learning With Vehicle-Cloud Collaboration Update
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7454
EP  - 7466
DO  - 10.1109/TITS.2024.3351438
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189500252&doi=10.1109%2fTITS.2024.3351438&partnerID=40&md5=477c087183ee969409c4b9bf7d38a224
AB  - With the increasing communications between the In-Vehicle Networks (IVNs) and external networks, security has become a stringent problem. In addition, the controller area network bus in IVN lacks security mechanisms by design, which is vulnerable to various attacks. Thus, it is important to detect IVN anomalies for complete vehicular security. However, current studies are constrained by either requiring labeled data or failing to accurately detect message-level anomalies without labeled data. In addition, the concept drift of existing methods has become a challenge over time. To address these problems, this paper proposes an IVN anomaly detection method based on Self-supervised Learning (IVNSL), which is capable of detecting message-level anomalies without labels. The essential idea of IVNSL is to make the message prediction model learn the distribution of normal messages in sequences using message sequences with noise. Furthermore, to accurately detect anomalies, a Message Prediction Model based on Hierarchical transformers (MPMHit) is proposed, which captures the spatial features of the message and the dependencies between messages. Meanwhile, to solve the concept drift over time, this paper proposes an online update mechanism for MPMHit based on vehicle-cloud collaboration. We conduct an extensive experimental evaluation on the car hacking dataset, resulting to an F1-score average and average false positive rates of IVNSL being 2.282% higher and 1.595% lower than the best baseline method. The average detection speed of each message is as fast as 0.1075 ms.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Cao2024Anomaly
ER  -

TY  - JOUR
AU  - Feng, R.
AU  - Li, Z.
AU  - Liu, B.
AU  - Ding, Y.
TI  - A Joint Spatiotemporal Prediction and Image Confirmation Model for Vehicle Trajectory Concatenation With Low Detection Rates
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 11701
EP  - 11715
DO  - 10.1109/TITS.2024.3373774
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188531914&doi=10.1109%2fTITS.2024.3373774&partnerID=40&md5=1b8a5aa1c990ecce2d1f949bbbeaba2a
AB  - Ensuring the quality of trajectories is of utmost importance in traffic flow analysis. Traditional approaches rely on reconstructing nearly complete trajectories and subsequently denoising them. However, low detection rates often pose challenges and result in failed trajectory construction. To overcome this issue, this paper presents a trajectory concatenation method that combines NS Transformer prediction and Siamese-VGG16 similarity confirmation, specifically designed to address low detection rates. The employed transformer model can withstand missing values, efficiently extracting internal associations among multiple traffic parameters in conditions of sparse data. Furthermore, a lightweight image feature similarity verification step is integrated after trajectory prediction to find the most similar target to the image in the predicted spatiotemporal domain. Additionally, a lightweight image feature similarity verification step is integrated after trajectory prediction to identify the most similar targets within the predicted spatiotemporal domain. Experimental results demonstrate the efficacy of the proposed method, successfully connecting over 80% of fragmented tracks and yielding significant maintenance of MOTA above 0.74 under low detection accuracy.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Feng2024Joint
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Zhang, X.
AU  - Luo, Y.
AU  - Hao, Q.
AU  - Su, J.
AU  - Cai, G.
TI  - Guard-Net: Lightweight Stereo Matching Network via Global and Uncertainty-Aware Refinement for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10260
EP  - 10273
DO  - 10.1109/TITS.2024.3357841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187288268&doi=10.1109%2fTITS.2024.3357841&partnerID=40&md5=ae5c417da1e8dccb62c604af4fd44006
AB  - Stereo matching is a prominent research area in autonomous driving and computer vision. Despite significant progress made by learning-based methods, accurately predicting disparities in hazardous regions, which is crucial for ensuring safe vehicle operation, remains challenging. The limitations of methods based on Convolutional Neural Networks (CNNs) are most noticeable in textureless regions and repetitive patterns, leading to unreliable predictions. Furthermore, calculating disparities for boundaries and thin structures, where the disparity jump phenomenon is prominent remains difficult. To address these issues, we propose a lightweight stereo matching architecture that focuses on obtaining real-Time and high-precision disparity maps in hazardous areas. We exploit an efficient global enhanced path to provide global representations in ill-posed regions, where CNN-based approaches often struggle. Second, our model integrates local and global features to generate more reliable cost volume. Finally, our innovative uncertainty-Aware module refines disparity, making full use of high-frequency detailed information and uncertainty attention, effectively preserving complex structures. Comprehensive experimental studies on SceneFlow demonstrate our method outperforms state-of-The-Art methods, achieving an End-Point Error (EPE) of 0.47 with only 3.60M parameters. The effectiveness of our method speed-Accuracy trade-off is further confirmed by competitive results obtained from the KITTI 2012 and KITTI 2015 experiments. Code is available at: https://github.com/YJLCV/Guard-Net.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Liu2024Guard-Net
ER  -

TY  - JOUR
AU  - Deng, J.
AU  - Chen, X.
AU  - Jiang, R.
AU  - Yang, Y.
AU  - Song, X.
AU  - Tsang, I.W.
TI  - Disentangling Structured Components: Towards Adaptive, Interpretable and Scalable Time Series Forecasting
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 8
SP  - 3783
EP  - 3800
DO  - 10.1109/TKDE.2024.3371931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187014950&doi=10.1109%2fTKDE.2024.3371931&partnerID=40&md5=3e6617d9885f5f26c2a9e7cef0ad1d23
AB  - Multivariate time-series (MTS) forecasting is a paramount and fundamental problem in many real-world applications. The core issue in MTS forecasting is how to effectively model complex spatial-temporal patterns. In this paper, we develop a adaptive, interpretable and scalable forecasting framework, which seeks to individually model each component of the spatial-temporal patterns. We name this framework SCNN, as an acronym of Structured Component-based Neural Network. SCNN works with a pre-defined generative process of MTS, which arithmetically characterizes the latent structure of the spatial-temporal patterns. In line with its reverse process, SCNN decouples MTS data into structured and heterogeneous components and then respectively extrapolates the evolution of these components, the dynamics of which are more traceable and predictable than the original MTS. Extensive experiments are conducted to demonstrate that SCNN can achieve superior performance over state-of-the-art models on three real-world datasets. Additionally, we examine SCNN with different configurations and perform in-depth analyses of the properties of SCNN.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:A期刊; FMS:B; 
LB  - Deng2024Disentangling
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Li, J.
AU  - Hu, Y.
AU  - Chen, H.
TI  - A Battery Prognostics and Health Management Technique Based on Knee Critical Interval and Linear Complexity Self-Attention Transformer in Electric Vehicles
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10216
EP  - 10230
DO  - 10.1109/TITS.2024.3355436
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186073730&doi=10.1109%2fTITS.2024.3355436&partnerID=40&md5=b75d9b34de91b6fe8cd8e837502623f0
AB  - Accurately estimating the remaining useful life (RUL) of lithium-ion batteries is crucial for the safe and reliable operation of batteries in electric vehicles. Due to the slow aging process and complex chemical reactions of batteries, it is challenging to obtain the complete battery lifecycle data to predict the RUL. To embrace these challenges, we propose an intelligent Transformer network with the improved self-attention mechanism based on data of the key interval area. Firstly, the knee-point and knee-onset in the capacity decay curve of the battery are identified by the Bacon-Watts model. The feature data that does not meet the minimum aging period between the knee-point and knee-onset in the aging curve is eliminated to ensure the accuracy and quickness of the prediction. Secondly, the denoising autoencoder (DAE) is used to mine the correlation between the aging characteristics in this interval and the low-dimensional hidden feature of battery aging is reconstructed. Finally, the Transformer network with improved multi-head self-attention mechanism is taken to capture the dependencies between features at different positions. A feed-forward neural network is employed to determine the weights of the features at the different sample time, which are then used in conjunction with fully connected layers and a prediction layer to estimate the remaining lifespan of lithium batteries. The proposed method is validated using the CALCE battery dataset. Simulation results show that the method achieves accurate and fast health prognosis with an average error of 0.0091 for the accuracy metric RE when only key feature interval data are used. There is also a significant advantage in computation time compared to other state-of-the-art algorithms, and our method can provide more accurate and faster health prognosis of batteries.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Ma2024Battery
ER  -

TY  - JOUR
AU  - Xu, L.
AU  - Tang, H.
AU  - Li, H.
AU  - Li, X.
AU  - Gulliver, T.A.
AU  - Le, K.N.
TI  - Secrecy Performance Intelligent Prediction for Mobile Vehicular Networks: An DI-CNN Approach
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7363
EP  - 7373
DO  - 10.1109/TITS.2024.3352668
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187271499&doi=10.1109%2fTITS.2024.3352668&partnerID=40&md5=a5b250f22c11fba2ddeba5c5e7189e58
AB  - The rapid expansion of Internet of Vehicles (IoV) networks has facilitated high throughput and reliable vehicular communications. Mobile vehicular networks face the challenges: diversification of network equipment, user mobility, and the broadcast nature of wireless channels, so physical layer security modeling of IoV communication systems has become important. The complexity of wireless communication channels makes real-time prediction of secrecy performance challenging. This paper presents an analysis of secrecy performance for mobile vehicular networks. To ensure data secure transmission, we have employed the decode-and-forward (DF) relaying scheme. The signal-to-noise ratio (SNR) of the effective end-to-end link is employed to obtain the mathematical expression results, which can evaluate the secrecy performance. The theoretical secrecy performance is confirmed via simulation. Then, we design a dense-inception convolution neural network (DI-CNN) model, and propose a DI-CNN-based intelligent prediction algorithm.Transformer, ShuffleNetV2, RegNet and YOLOv5 methods are employed to analyze the performance of DI-CNN algorithm. It is shown that the DI-CNN approach has a prediction accuracy that is 48.8% better than Transformer.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2024Secrecy
ER  -

TY  - JOUR
AU  - Zhao, J.
AU  - Dong, Z.
AU  - Yao, X.
AU  - Xi, X.
TI  - Optimizing collaboration decisions in technological innovation through machine learning: identify trend and partners in collaboration-knowledge interdependent networks
PY  - 2024
T2  - Annals of Operations Research
DO  - 10.1007/s10479-024-05867-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185259238&doi=10.1007%2fs10479-024-05867-z&partnerID=40&md5=51a83173cda7ad256e63bf7c43fc413e
AB  - Technological innovation, which is exemplified by the convergence of diverse knowledge domains and collaborative efforts across industries, has emerged as the primary catalyst for organizations seeking to enhance their business operations and attain competitive advantages. Consequently, optimizing decision-making processes is imperative for organizations to adeptly forecast technological convergence trends and strategically identify suitable collaboration partners. Since a firm is embedded in both a collaboration network and a knowledge network, it is necessary to consider a dual network structure and the interdependence of the two subnetworks in terms of technological convergence. Regrettably, limited attention has been given to this aspect and the evolving nature of knowledge networks in the existing studies. To address these issues, this study proposes an innovative research framework for technological convergence, combining a dynamic link prediction model using a transformer with the theory of interdependent networks, which enhances predictive algorithms regarding the convergence of new technologies and simultaneously identifies potential collaborative partners. Patent data from the medical device field are collected to conduct experiments. The results indicate that the proposed approach yields a 15% improvement in the area under the curve (AUC) metric over that of the recurrent neural network (RNN)-based dynamic model and a gain of more than 25% compared to the machine learning-based static model. Our study has important theoretical and practical implications for improving business operations and innovation strategies. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Zhao2024Optimizing
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Geng, M.
AU  - Chen, Y.
AU  - Cai, Z.
AU  - Zhu, Z.
AU  - Chen, X.M.
TI  - Demand forecasting and predictability identification of ride-sourcing via bidirectional spatial-temporal transformer neural processes
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 158
C7  - 104427
DO  - 10.1016/j.trc.2023.104427
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183580342&doi=10.1016%2fj.trc.2023.104427&partnerID=40&md5=ff0509e5851a2e77ff0a00095d113383
AB  - Understanding the spatial–temporal stochasticity in shared mobility is crucial for ride-sourcing demand forecasting, supply–demand management, and vehicle dispatch optimization. In contrast to conventional deep learning methods that typically provide point predictions or deterministic predictions, this paper introduces the bidirectional spatial–temporal Transformer neural processes (Bi-STTNP) prediction model, which stands out from conventional deep learning methods by providing probabilistic predictions and uncertainty estimations for ride-sourcing demand. Bi-STTNP captures the multivariate spatial–temporal Gaussian distribution of demand, offering not only demand expectations but also comprehensive uncertainty representations. We propose a predictability identification process based on predictive distributions to assess varying predictability across time slots and regions, improving interpretability. Our model, consisting of the bidirectional supply–demand attention module and spatial–temporal Transformer module, maintains interpretability while ensuring accurate demand expectation predictions. Extensive experiments on a real-world dataset of 15 million ride-sourcing orders in Hangzhou, China, demonstrate that Bi-STTNP outperforms baseline models in predicting demand expectation and quantifying demand uncertainty. Furthermore, we compute loose spatial–temporal predictability lower bounds and categorize regions by predictability, providing insights for optimizing passenger pricing strategies, driver incentives, and vehicle dispatching in ride-sourcing platforms. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; 
LB  - Li2024Demand
ER  -

TY  - JOUR
AU  - Yang, H.
AU  - Yan, C.
AU  - Chen, Z.
AU  - Wang, P.
TI  - A K-Shape Clustering Based Transformer-Decoder Model for Predicting Multi-Step Potentials of Urban Mobility Field
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10298
EP  - 10312
DO  - 10.1109/TITS.2024.3355211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184306462&doi=10.1109%2fTITS.2024.3355211&partnerID=40&md5=308b975049d821b9b49eb4089a2a5af0
AB  - Identifying and predicting the travel hotspots in urban areas can provide crucial support for building intelligent transportation systems. In this study, we propose to use the potentials of urban mobility field to identify the travel hotspots and develop a K-shape clustering transformer-decoder (KSC-TD) model to predict multi-step potentials. In the KSC-TD model, the K-shape clustering method is used to cluster the grids with similar potential time series, whereas the transformer-decoder model is trained for each cluster of grids by integrating the multi-head masked attention mechanism and the scheduled sampling strategy. The developed KSC-TD model is validated using the license plate recognition (LPR) data of Changsha (a major southern city of China). Results indicate that the proposed KSC-TD model outperforms nine benchmark models in predicting the multi-step potentials of urban mobility field, offering a new and effective approach for anticipating urban travel hotspots.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2024K-Shape
ER  -

TY  - JOUR
AU  - Jiao, Y.
AU  - Miao, M.
AU  - Yin, Z.
AU  - Lei, C.
AU  - Zhu, X.
AU  - Zhao, X.
AU  - Nie, L.
AU  - Tao, B.
TI  - A Hierarchical Hybrid Learning Framework for Multi-Agent Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10344
EP  - 10354
DO  - 10.1109/TITS.2024.3357479
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184832024&doi=10.1109%2fTITS.2024.3357479&partnerID=40&md5=dbc6fe17d3607b45ac121efee642d9e4
AB  - Accurate trajectory prediction for neighboring agents is crucial for autonomous vehicles navigating complex scenes. Recent deep learning (DL) methods excel in encoding complex interactions but often generate invalid predictions due to difficulties in modeling transient and contingency interactions. This paper proposes a hierarchical hybrid framework that combines DL and reinforcement learning (RL) for multi-Agent trajectory prediction, capturing multi-scale interactions that shape future motion. In the DL stage, Transformer-style graph neural network (GNN) is employed to encode heterogeneous interactions at intermediate and global scales, predicting multi-modal intentions as key future positions for agents. In the RL stage, we divide the scene into local scenes based on DL predictions. A Transformer-based Proximal Policy Optimization (PPO) model, incorporated with vehicle kinematics, generates future trajectories in the form of motion planning shaped by microscopic interactions and guided by a multi-objective reward for balanced agent-centric accuracy and scene-wise compatibility. Experimental results on the Argoverse benchmark and driver-in-loop simulations demonstrate that our framework enhances trajectory prediction feasibility and plausibility in interactive scenes.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Jiao2024Hierarchical
ER  -

TY  - JOUR
AU  - Kim, S.
AU  - Yun, S.-B.
AU  - Bae, H.-O.
AU  - Lee, M.
AU  - Hong, Y.
TI  - Physics-informed convolutional transformer for predicting volatility surface
PY  - 2024
T2  - Quantitative Finance
VL  - 24
IS  - 2
SP  - 203
EP  - 220
DO  - 10.1080/14697688.2023.2294799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184242176&doi=10.1080%2f14697688.2023.2294799&partnerID=40&md5=91ee6f08a942455f97ecef18f3dd6a5d
AB  - Predicting volatility is important for asset predicting, option pricing and hedging strategies because it cannot be directly observed in the financial market. The dynamics of the volatility surface is difficult to estimate. In this paper, we establish a novel architecture based on physics-informed neural networks and convolutional transformers. The performance of the new architecture is directly compared to other well-known deep-learning architectures, such as standard physics-informed neural networks, convolutional long-short term memory (ConvLSTM), and self-attention ConvLSTM. Numerical evidence indicates that the proposed physics-informed convolutional transformer network achieves a superior performance than other methods. © 2024 Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Kim2024Physics-informed
ER  -

TY  - JOUR
AU  - Masafu, C.
AU  - Williams, R.
TI  - Satellite Video Remote Sensing for Flood Model Validation
PY  - 2024
T2  - Water Resources Research
VL  - 60
IS  - 1
C7  - e2023WR034545
DO  - 10.1029/2023WR034545
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182173672&doi=10.1029%2f2023WR034545&partnerID=40&md5=c0ba583747c3db6833669acae7beeda4
AB  - Satellite-based optical video sensors are poised as the next frontier in remote sensing. Satellite video offers the unique advantage of capturing the transient dynamics of floods with the potential to supply hitherto unavailable data for the assessment of hydraulic models. A prerequisite for the successful application of hydraulic models is their proper calibration and validation. In this investigation, we validate 2D flood model predictions using satellite video-derived flood extents and velocities. Hydraulic simulations of a flood event with a 5-year return period (discharge of 722 m3 s−1) were conducted using Hydrologic Engineering Center—River Analysis System 2D in the Darling River at Tilpa, Australia. To extract flood extents from satellite video of the studied flood event, we use a hybrid transformer-encoder, convolutional neural network (CNN)-decoder deep neural network. We evaluate the influence of test-time augmentation (TTA)—the application of transformations on test satellite video image ensembles, during deep neural network inference. We employ Large Scale Particle Image Velocimetry (LSPIV) for non-contact-based river surface velocity estimation from sequential satellite video frames. When validating hydraulic model simulations using deep neural network segmented flood extents, critical success index peaked at 94% with an average relative improvement of 9.5% when TTA was implemented. We show that TTA offers significant value in deep neural network-based image segmentation, compensating for aleatoric uncertainties. The correlations between model predictions and LSPIV velocities were reasonable and averaged 0.78. Overall, our investigation demonstrates the potential of optical space-based video sensors for validating flood models and studying flood dynamics. © 2024. The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - FMS:B; 
LB  - Masafu2024Satellite
ER  -

TY  - JOUR
AU  - Yuan, K.
AU  - Huang, Y.
AU  - Yang, S.
AU  - Wu, M.
AU  - Cao, D.
AU  - Chen, Q.
AU  - Chen, H.
TI  - Evolutionary Decision-Making and Planning for Autonomous Driving: A Hybrid Augmented Intelligence Framework
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7339
EP  - 7351
DO  - 10.1109/TITS.2023.3349198
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182935151&doi=10.1109%2fTITS.2023.3349198&partnerID=40&md5=eb551b617b833772911b4a495fb84f76
AB  - Recently, thanks to the introduction of human feedback, Chat Generative Pre-trained Transformer (ChatGPT) has achieved remarkable success in the language processing field. Analogically, human drivers are expected to have great potential in improving the performance of autonomous driving under real-world traffic. Therefore, this study proposes a novel framework for evolutionary decision-making and planning by developing a hybrid augmented intelligence (HAI) method to introduce human feedback into the learning process. In the framework, a decision-making scheme based on interactive reinforcement learning (Int-RL) is first developed. Specifically, a human driver evaluates the learning level of the ego vehicle in real-time and intervenes to assist the learning of the vehicle with a conditional sampling mechanism, which encourages the vehicle to pursue human preferences and punishes the bad experience of conflicts with the human. Then, the longitudinal and lateral motion planning tasks are performed utilizing model predictive control (MPC), respectively. The multiple constraints from the vehicle's physical limitation and driving task requirements are elaborated. Finally, a safety guarantee mechanism is proposed to ensure the safety of the HAI system. Specifically, a safe driving envelope is established, and a safe exploration/exploitation logic based on the trial-and-error on the desired decision is designed. Simulation with a high-fidelity vehicle model is conducted, and results show the proposed framework can realize an efficient, reliable, and safe evolution to pursue higher traffic efficiency of the ego vehicle in both multi-lane and congested ramp scenarios.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Yuan2024Evolutionary
ER  -

TY  - JOUR
AU  - Yao, Z.
AU  - Li, X.
AU  - Lang, B.
AU  - Chuah, M.C.
TI  - Goal-LBP: Goal-Based Local Behavior Guided Trajectory Prediction for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6770
EP  - 6779
DO  - 10.1109/TITS.2023.3342706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181568438&doi=10.1109%2fTITS.2023.3342706&partnerID=40&md5=71f60b210641c17f63d709a43fe751ea
AB  - In recent years, the design of models for performing the trajectory prediction task, one of the critical tasks in autonomous driving, has received great attention from researchers. However, accurately predicting future locations is challenging due to the difficulty of learning accurate intentions and modeling multimodality. Historical paths at a certain location can help predict the future trajectory of an agent currently located in that position and address these limitations. In this work, we propose a goal-based local behavior guided model, Goal-LBP, using such information (referred to as local behavior data) to generate potential goals and guide the prediction of trajectories conditioned on such goals. Goal-LBP uses Transformer encoders to extract homogeneous features and attention mechanism to represent the heterogeneous interactions and subsequently uses an encoder-decoder Gated Recurrent Unit (GRU) model to generate predictions. We evaluate our Goal-LBP using two large-scale real-world autonomous driving datasets, namely nuScenes and Argoverse. Our results show that compared to several SOTA models, Goal-LBP achieves the best ADE/FDE performance and it ranked #2 on the leaderboard of the nuScenes trajectory benchmark in June 2023. In addition, we also demonstrate that our local behavior estimator block can be easily added to two existing SOTA methods, namely AgentFormer and LaPred. Adding this LBE block improves the original AgentFormer and LaPred performance by at least 10%.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Yao2024Goal-LBP
ER  -

TY  - JOUR
AU  - Yang, B.
AU  - Fan, F.
AU  - Ni, R.
AU  - Wang, H.
AU  - Jafaripournimchahi, A.
AU  - Hu, H.
TI  - A Multi-Task Learning Network With a Collision-Aware Graph Transformer for Traffic-Agents Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6677
EP  - 6690
DO  - 10.1109/TITS.2023.3345296
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181564597&doi=10.1109%2fTITS.2023.3345296&partnerID=40&md5=501be9deca17a129ec60a314ea72145f
AB  - It is critical for autonomous vehicles to accurately forecast the future trajectories of surrounding agents to avoid collisions. However, capturing the complex interactions between agents in complex urban scenes is challenging. As a result, complex interactions may impair trajectory prediction accuracy. A trajectory prediction network with an enhanced Graph Transformer (TP-EGT) is proposed to forecast the future trajectories of traffic-agents. A collision-aware Graph Transformer is introduced to capture the complex social interactions between traffic-agents. Following that, an additional interaction prediction task that could predict the interaction probabilities between agents is proposed to mitigate the over-smoothing issue of the Graph Transformer via a multi-task learning strategy. Afterward, the trajectory prediction performance is improved with additional interaction probabilities, which are beneficial for the decision-making and planning modules of autonomous vehicles. Quantitative and qualitative evaluations of TP-EGT on the ETH/UCY and ApolloScape databases demonstrate that the trajectory prediction accuracy of TP-EGT is comparable to the state-of-the-art baseline methods, and the predicted interaction probabilities can help autonomous vehicles comprehend the complex traffic scenes. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2024Multi-Task
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liu, F.
AU  - Xing, L.
AU  - Yuan, C.
AU  - Wu, D.
TI  - A Deep Learning Framework to Explore Influences of Data Noises on Lane-Changing Intention Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6514
EP  - 6526
DO  - 10.1109/TITS.2023.3344647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181570513&doi=10.1109%2fTITS.2023.3344647&partnerID=40&md5=d24193829067799f826a23e8a1e86a5c
AB  - The accuracy of the data is crucial to the real-time prediction of autonomous driving. Due to factors such as weather and the accuracy of data collection equipment, there frequently exist noises in the data collected in real time. Therefore, it is necessary to perform analysis on acquired kinematic features related to driving behavior prediction. This study proposes a novel deep learning framework to explore influences of data noises on lane-changing intention prediction. Kinematic features including the longitudinal distance difference, velocity and acceleration, lateral velocity and acceleration of the vehicles are first extracted from the HighD. Then, the anti-interference performance of deep learning models such as transformer is tested. By comparing dataset with and without noises, we develop an evaluation method containing several predictive performance metrics and statistical measures. The results show that: (1) the longitudinal acceleration of the vehicle has the lowest sensitivity to noise, and the lateral velocity has the weakest anti-interference and the highest sensitivity. (2) The Bi-LSTM model with multi-head attention mechanism performs well in reducing the sensitivity of longitudinal acceleration and prediction accuracy. This study provides valuable information for data acquisition and model selection of real-time driving intention prediction. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; FMS:B; 
LB  - Li2024Deep
ER  -

TY  - JOUR
AU  - Kong, X.
AU  - Shen, Z.
AU  - Wang, K.
AU  - Shen, G.
AU  - Fu, Y.
TI  - Exploring Bus Stop Mobility Pattern: A Multi-Pattern Deep Learning Prediction Framework
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6604
EP  - 6616
DO  - 10.1109/TITS.2023.3345872
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182381068&doi=10.1109%2fTITS.2023.3345872&partnerID=40&md5=6994dd19745ba804e7fb0d49d969d863
AB  - The spatio-temporal prediction task in the transportation network is the core of the solutions for various traffic problems. On one hand, the mobility pattern in traffic can be reflected in the travel behavior of the crowd. In most traffic prediction tasks, the importance of the mobility pattern is often overlooked. On the other hand, traffic prediction also has a variety of predicting scenarios, including short-term and long-term prediction, and relevant research cannot solve the problems under the two scenarios at the same time. In view of the problem of existing work, we propose a multi-pattern traffic prediction framework, MPGNNFormer. First, we construct a new bus stop distance network to model the relationships between stops. Then, we use a graph neural network-based deep clustering method to extract the bus stop mobility pattern. Finally, we design a transformer-based spatio-temporal prediction model (STGNNFormer) to predict bus stop flow by taking full advantage of time dependency and space dependency. After that, we conduct a series of experiments to evaluate and test them on the real bus dataset, including analyzing mobility patterns and comparing prediction results. The experimental results prove that MPGNNFormer can improve the calculation efficiency in the prediction scene while ensuring prediction accuracy in the stop-flow prediction of the transportation network. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; FMS:B; 
LB  - Kong2024Exploring
ER  -

TY  - JOUR
AU  - Du, H.
AU  - Yuan, H.
AU  - Zhao, P.
AU  - Wang, D.
AU  - Sheng, V.S.
AU  - Liu, Y.
AU  - Liu, G.
AU  - Zhao, L.
TI  - Feature-Aware Contrastive Learning With Bidirectional Transformers for Sequential Recommendation
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 12
SP  - 8192
EP  - 8205
DO  - 10.1109/TKDE.2023.3343345
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181563688&doi=10.1109%2fTKDE.2023.3343345&partnerID=40&md5=a980c0e49c3e5203ccec6f6c536d2ee7
AB  - Contrastive learning with Transformer-based sequence encoder has gained predominance for sequential recommendation due to its ability to mitigate the data noise and the data sparsity issue. However, existing contrastive learning approaches for sequential recommendation still suffer from two limitations. First, they mainly center on left-to-right unidirectional Transformers as base encoders, which are suboptimal for sequential recommendation because user behaviors may not be a rigid left-to-right sequence. Second, they devise contrastive learning objectives only from the sequence level, neglecting the rich self-supervision signals from the feature level. To address these limitations, we propose a novel framework called Feature-aware Contrastive Learning with bidirectional Transformers for sequential Recommendation (FCLRec) to effectively leverage feature information for sequential recommendation. Specifically, we first augment bidirectional Transformers with a novel feature-aware self-attention module that is able to simultaneously model the complex relationships between sequences and features. Next, we propose a novel feature-aware contrastive learning objective that generates a collection of positive samples via three types of augmentations from three different levels. Finally, we adopt feature prediction as an auxiliary task to strengthen the connections between items and features. Our experimental results on four public benchmark datasets show that FCLRec outperforms the state-of-the-art methods for sequential recommendation. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Du2024Feature-Aware
ER  -

TY  - JOUR
AU  - Zheng, H.
AU  - Wang, Z.
AU  - Zheng, C.
AU  - Wang, Y.
AU  - Fan, X.
AU  - Cong, W.
AU  - Hu, M.
TI  - A graph multi-attention network for predicting airport delays
PY  - 2024
T2  - Transportation Research Part E: Logistics and Transportation Review
VL  - 181
C7  - 103375
DO  - 10.1016/j.tre.2023.103375
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179132119&doi=10.1016%2fj.tre.2023.103375&partnerID=40&md5=d2c4c0c0ad6a3ee6059d1c0e65a959e4
AB  - Predicting airport delays is of great importance for aviation operations, from the development of effective air traffic management strategies to the reallocation of airline resources. In this paper, the long-term prediction of the next 24 h of network-wide delays is investigated. The sensitivity to error propagation over long time periods as well as dynamic spatial correlations and non-linear temporal correlations of the aviation network are considered. An external impact modeling module is introduced to account for the influence of weather on flight delay patterns. A Spatial-Temporal Gated Multi-Attention Graph Network (STGMAGNet) considering external impact to predict airport delays is then developed. We validate our model on a flight delays dataset collected from the Bureau of Transportation Statistics of US, covering January 1, 2019, to December 31, 2019. In long-term (input-24-predict-24 setting) forecasting, STGMAGNet provides state-of-the-art accuracy, with a MAE reduction of at least 21% averaged in arrival delay prediction, 18% averaged MAE reduction in departure delay prediction compared to MLP, LSTM, Seq2Seq and Transformer. Our model can enable aviation management to shift from a reactive to proactive approach, thus enhancing its operational efficiency and overall performance. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - FMS:B; 
LB  - Zheng2024graph
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Xing, W.
AU  - Jiao, H.
AU  - Yang, Z.
AU  - Li, Y.
TI  - Deep bi-directional information-empowered ship trajectory prediction for maritime autonomous surface ships
PY  - 2024
T2  - Transportation Research Part E: Logistics and Transportation Review
VL  - 181
C7  - 103367
DO  - 10.1016/j.tre.2023.103367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178995898&doi=10.1016%2fj.tre.2023.103367&partnerID=40&md5=b7280559e50dcd0f6ce8fdb85ac3286f
AB  - It is critical to have accurate ship trajectory prediction for collision avoidance and intelligent traffic management of manned ships and emerging Maritime Autonomous Surface Ships (MASS). Deep learning methods for accurate prediction based on AIS data have emerged as a contemporary maritime transportation research focus. However, concerns about its accuracy and computational efficiency widely exist across both academic and industrial sectors, necessitating the discovery of new solutions. This paper aims to develop a new prediction approach called Deep Bi-Directional Information-Empowered (DBDIE) by utilising integrated multiple networks and an attention mechanism to address the above issues. The new DBDIE model extracts valuable features by fusing the Bi-directional Long Short-Term Memory (Bi-LSTM) and the Bi-directional Gated Recurrent Unit (Bi-GRU) neural networks. Additionally, the weights of the two bi-directional units are optimised using an attention mechanism, and the final prediction results are obtained through a weight self-adjustment mechanism. The effectiveness of the proposed model is verified through comprehensive comparisons with state-of-the-art deep learning methods, including Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), Bi-LSTM, Bi-GRU, Sequence to Sequence (Seq2Seq), and Transformer neural networks. The experimental results demonstrate that the new DBDIE model achieves the most satisfactory prediction outcomes than all other classical methods, providing a new solution to improving the accuracy and effectiveness of predicting ship trajectories, which becomes increasingly important in the era of the safe navigation of mixed manned ships and MASS. As a result, the findings can aid the development and implementation of proactive preventive measures to avoid collisions, enhance maritime traffic management efficiency, and ensure maritime safety. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - FMS:B; 
LB  - Li2024Deep
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Zhang, J.
AU  - Yang, L.
AU  - Gao, Z.
TI  - Network-wide short-term inflow prediction of the multi-traffic modes system: An adaptive multi-graph convolution and attention mechanism based multitask-learning model
PY  - 2024
T2  - Transportation Research Part C: Emerging Technologies
VL  - 158
C7  - 104428
DO  - 10.1016/j.trc.2023.104428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178430237&doi=10.1016%2fj.trc.2023.104428&partnerID=40&md5=12ef9995359108864eee568a0719b1aa
AB  - Network-wide short-term inflow prediction is important in efficiently managing the urban transportation system. Nowadays, all kinds of traffic modes gradually become interconnected and form a complex multi-traffic modes system, while extensive studies focus on the single-traffic mode and ignore the correlations among different traffic modes. There exist some challenges for short-term inflow prediction of multi-traffic modes: (1) the interaction mechanism among multi-traffic modes is difficult to learn and few studies explore the mechanism, (2) the data of multi-traffic modes are usually heterogenous due to the different spatial units of different traffic modes, and (3) it is challenging to extract the complex and dynamic features of the multi-traffic modes and most existing methods apply static spatiotemporal correlations among multi-traffic modes, while the genuine correlations among different traffic modes might be missing. To tackle these challenges, this study proposed a multitask-learning-based model called MultiMode-former (M2-former) with the encoder-decoder structure for network-wide short-term inflow prediction of the multi-traffic modes system. Specifically, the encoder is designed to learn and capture the complex and dynamic spatiotemporal correlations of multi-traffic modes, and the decoder is designed to extract the features of the target traffic mode and share knowledge among multi-traffic modes. Extensive experiments are conducted based on the real-world multi-traffic modes system data of Beijing, China. Results prove the superiority of the M2-former. In addition, the spatial and temporal information interaction mechanisms among multi-traffic modes are also explored. This paper can provide a reliable method and critical insights for the management and understanding of a multi-traffic modes system. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; 
LB  - Yang2024Network-wide
ER  -

TY  - JOUR
AU  - Xue, H.
AU  - Salim, F.D.
TI  - PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 11
SP  - 6851
EP  - 6864
DO  - 10.1109/TKDE.2023.3342137
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180312993&doi=10.1109%2fTKDE.2023.3342137&partnerID=40&md5=bca373a2d2f15c16341915fc006b2915
AB  - This paper presents a new perspective on time series forecasting. In existing time series forecasting methods, the models take a sequence of numerical values as input and yield numerical values as output. The existing SOTA models are largely based on the Transformer architecture, modified with multiple encoding mechanisms to incorporate the context and semantics around the historical data. Inspired by the successes of pre-trained language foundation models, we pose a question about whether these models can also be adapted to solve time-series forecasting. Thus, we propose a new forecasting paradigm: prompt-based time series forecasting (PromptCast). In this novel task, the numerical input and output are transformed into prompts and the forecasting task is framed in a sentence-to-sentence manner, making it possible to directly apply language models for forecasting purposes. To support and facilitate the research of this task, we also present a large-scale dataset (PISA) that includes three real-world forecasting scenarios. We evaluate different SOTA numerical-based forecasting methods and language generation models. The benchmark results with various forecasting settings demonstrate the proposed PromptCast with language generation models is a promising research direction. Additionally, in comparison to conventional numerical-based forecasting, PromptCast shows a much better generalization ability under the zero-shot setting.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:A期刊; FMS:B; 
LB  - Xue2024PromptCast
ER  -

TY  - JOUR
AU  - Hou, J.
AU  - Dong, Z.
AU  - Zhou, J.
AU  - Liu, Z.
TI  - Discovering Predictable Latent Factors for Time Series Forecasting
PY  - 2024
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 36
IS  - 10
SP  - 5106
EP  - 5119
DO  - 10.1109/TKDE.2023.3335240
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178060240&doi=10.1109%2fTKDE.2023.3335240&partnerID=40&md5=10cb4e92cfdab0b280a199732131c27a
AB  - Modern temporal modeling methods, such as Transformer and its variants, have demonstrated remarkable capabilities in handling sequential data from specific domains like language and vision. Though achieving high performance with large-scale data, they often have redundant or unexplainable structures. When encountering some real-world datasets with limited observable variables that can be affected by many unknown factors, these methods may struggle to identify meaningful patterns and dependencies inherent in data, and thus, the modeling becomes unstable and unpredictable. To tackle this critical issue, in this article, we develop a novel algorithmic framework for inferring latent factors implied by the observed temporal data. The inferred factors are used to form multiple predictable and independent signal components that enable not only the reconstruction of future time series for accurate prediction but also sparse relation reasoning for long-term efficiency. To achieve this, we introduce three characteristics, i.e., predictability, sufficiency, and identifiability, and model these characteristics of latent factors via powerful deep latent dynamics models to infer the predictable signal components. Empirical results on multiple real datasets show the efficiency of our method for different kinds of time series forecasting tasks. Statistical analyses validate the predictability and interpretability of the learned latent factors.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:A期刊; FMS:B; 
LB  - Hou2024Discovering
ER  -

TY  - JOUR
AU  - Bi, J.-W.
AU  - Han, T.-Y.
AU  - Yao, Y.
AU  - Yang, T.
TI  - Tourism demand forecasting under conceptual drift during COVID-19: an ensemble deep learning model
PY  - 2024
T2  - Current Issues in Tourism
VL  - 27
IS  - 23
SP  - 4084
EP  - 4103
DO  - 10.1080/13683500.2023.2273922
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174680503&doi=10.1080%2f13683500.2023.2273922&partnerID=40&md5=01664e8792149d36468628e90d796a01
AB  - To address the issue of tourism demand forecasting in the context of concept drift, a new ensemble deep learning model based on transformer is proposed, which includes three parts: data processing, base predictor pool construction, base predictor selection and combination. In the first part, the relevant data are collected and converted into the input form required by transformer. In the second part, a base predictor pool containing multiple predictors is constructed, where each predictor can capture a specific concept from historical data. In the final part, a predictor selection algorithm is proposed to select ‘effective predictors’ from the base predictor pool. These effective predictors are further integrated to generate the final forecasts. The proposed model is applied to the forecast of tourist volume of two attractions in China. The results show that the proposed model outperforms the benchmark models in the context of concept drift, benchmarked against eight models. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Bi2024Tourism
ER  -

TY  - JOUR
AU  - Hu, H.-X.
AU  - Hu, Q.
AU  - Tan, G.
AU  - Zhang, Y.
AU  - Lin, Z.-Z.
TI  - A Multi-Layer Model Based on Transformer and Deep Learning for Traffic Flow Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 1
SP  - 443
EP  - 451
DO  - 10.1109/TITS.2023.3311397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173022416&doi=10.1109%2fTITS.2023.3311397&partnerID=40&md5=2193eef445c09e882e9c6aa16133ae31
AB  - Using traffic data to accurately predict the traffic flow at a certain time in the future can alleviate problems such as traffic congestion, which plays an important role in the healthy transportation and economic development of cities. However, current traffic flow prediction models rely on human experience and only consider the advantages of single machine learning model. Therefore, in this work, we propose a multi-layer model based on transformer and deep learning for traffic flow prediction (MTDLTFP). The MTDLTFP model first draws on the idea of transformer model, which uses multiple encoders and decoders to perform feature extraction on the initial traffic data without human experience. In addition, in the prediction stage, the MTDLTFP model using deep learning technology, which input the hidden features into the convolutional neural network (CNN) and multi-layer feedforward neural network (MFNN) to obtain the prediction score respectively. The CNN model can captures the correlation information between the hidden features, and the MFNN can captures the nonlinear relationship between the features. Finally, we use a linear model to combine the two prediction scores, which can make the final prediction value take into account the common advantages of both models. Multiple experimental results on two real datasets demonstrate the effectiveness of the MTDLTFP model. The experimental results on the WorkDay dataset are as follows, with the RMSE value of 0.191, MAE value of 0.165. The experimental results on the HoliDay dataset are as follows, with RMSE value of 0.227, MAE value of 0.192.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Hu2024Multi-Layer
ER  -

TY  - JOUR
AU  - Guan, Z.
AU  - Chen, Y.
AU  - Zhao, Y.
AU  - Zhang, S.
AU  - Jin, H.
AU  - Yang, L.
AU  - Yan, W.
AU  - Zheng, S.
AU  - Lu, P.
AU  - Yang, Q.
TI  - STFS-urban: Spatio-temporal flood simulation model for urban areas
PY  - 2024
T2  - Journal of Environmental Management
VL  - 349
C7  - 119289
DO  - 10.1016/j.jenvman.2023.119289
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174739948&doi=10.1016%2fj.jenvman.2023.119289&partnerID=40&md5=882f66a7fec8e98e3cb193f7e39cb532
AB  - Amidst escalating urbanization and increasing extreme climatic events, strengthening flood resilience strategies in global cities has become imperative. This study introduces an innovative spatiotemporal urban flood simulation model that seamlessly integrates diverse refined and multi-spatiotemporal scales, ranging from 7.5 to 60 min and 100–2000 m, respectively. The model comprises multi-scale radar rainfall inversion (MRI), fine-grained coupled flood simulation model (FGCFS), and transformer-CNN flood prediction (TCFP) modules. Employing the Nanjing urban area as a case study, the model's efficacy is subjected to rigorous assessment. The advantages derived from integrated refinement coupling and boundary conditions through FGCFS and TCFP are accentuated. Impressively, the results underscore the robust performance of radar rainfall inversion across most scales, revealing a correlation coefficient surpassing 0.8 and a root-mean-square error of under 5.2 mm. FGCFS achieves optimal simulated water depth changes at 7.5 min × 500 m resolution, with the Nash efficiency coefficient exceeding 0.69 (0.94 at YS observation point and 0.89 at SXM observation point), alongside percentage deviations below 12.89 (3.59 at SXM observation point and 2.42 at XJL observation point). TCFP's learning proficiency is showcased through error convergence to 0.002 m after twenty iterations, particularly suitable for resolutions below 4 m. Notably, both FGCFS and TCFP demonstrate efficient utilization of resources, enabling streamlined simulations across varying data resolutions. Consequently, our study propels a sophisticated framework harmonizing multi-scale data integration, refinement coupling, and dynamic allocation. Our work extends beyond practical solutions, offering a glimpse into the future of flood simulation modeling, and reaffirming its pivotal role within the realm of environmental research and management. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:B; 
LB  - Guan2024STFS-urban
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Yu, X.
AU  - Chen, J.
AU  - He, B.-G.
AU  - Wang, W.
AU  - Rawat, D.B.
AU  - Lyu, Z.
TI  - PGA-Net: Polynomial Global Attention Network With Mean Curvature Loss for Lane Detection
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 1
SP  - 417
EP  - 429
DO  - 10.1109/TITS.2023.3309948
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171751626&doi=10.1109%2fTITS.2023.3309948&partnerID=40&md5=dbe0ceabe447ea1d651c62720fa8ef89
AB  - Lane detection is an important task in the field of automatic driving. Since lane lines usually have complex topologies and exist in various complex scenes (e.g., damaged lanes, severe occlusion, etc.), lane detection remains challenging. In this work, we propose a Polynomial Global Attention Network (PGA-Net) for lane detection, which is an end-to-end model for mining global road information and predicting lanes shape parameter formulas simultaneously. We model lane shape with cubic polynomial function and use the transformer-based DETR model to introduce the context information of lanes and roads to better regress the lane parameters. For polynomial curve modeling, we propose Mean Curvature Loss (MCL) to constrain the curvature of the predicted lanes, thereby enhancing the quality of curve lanes prediction. In addition, we design an improved supervision strategy to eliminate information bias between our parametric prediction methods and the labeling methods of lane datasets. Our method achieves state-of-the-art performance on two popular benchmarks (TuSimple and LLAMAS) and a most challenging benchmark (CULane), while exhibiting accelerated speed (>140fps on 3090 GPU, 28.9% improvement in average) and lightweight model size (<3M, an averaged 83.7% reduction). Our code is available at https://github.com/qklee-lz/PGA-Net.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Li2024PGA-Net
ER  -

TY  - JOUR
AU  - Beyer Díaz, S.
AU  - Coussement, K.
AU  - De Caigny, A.
AU  - Pérez, L.F.
AU  - Creemers, S.
TI  - Do the US president's tweets better predict oil prices? An empirical examination using long short-term memory networks
PY  - 2024
T2  - International Journal of Production Research
VL  - 62
IS  - 6
SP  - 2158
EP  - 2175
DO  - 10.1080/00207543.2023.2217286
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161382629&doi=10.1080%2f00207543.2023.2217286&partnerID=40&md5=7898c98102b8161138dacb570d959f4b
AB  - The price of oil is highly complex to predict as it is impacted by global demand and supply, geopolitical events, and market sentiment. The accuracy of such predictions, however, has far-reaching implications for supply chain performance, portfolio management, and expected stock market returns. This paper contributes to the oil price prediction literature by evaluating the predictive impact of the US President's communication on Twitter, while benchmarking various Natural Language Processing (NLP) techniques, including Term Frequency-Inverse Document Frequency (TF-IDF), Word2Vec, Doc2Vec, Global Vectors for Word Representation (GloVe), and Bidirectional Encoder Representations from Transformers (BERT). These techniques are combined with a deep neural network Long Short-Term Memory (LSTM) architecture using a five-day lag for both the oil price and the textual Twitter data. The data was collected during the term of US President Donald Trump, resulting in 1449 days of crude oil price prediction and a total of 16,457 tweets. The study is validated for Brent and West Texas Intermediate blends, using the daily price of a barrel of crude oil as the target variable. The results confirm that including the US President's tweets significantly increases the predictive power of oil price prediction models, and that an LSTM architecture with BERT as NLP technique has the best performance. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Beyer Díaz2024Do
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Tan, G.
AU  - Zhong, R.
AU  - Li, Y.
AU  - Gou, C.
TI  - PIT: Progressive Interaction Transformer for Pedestrian Crossing Intention Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 12
SP  - 14213
EP  - 14225
DO  - 10.1109/TITS.2023.3309309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171738492&doi=10.1109%2fTITS.2023.3309309&partnerID=40&md5=09e675fd943691c4a89ff64a2d26a4bf
AB  - For autonomous driving, one of the major challenges is to predict pedestrian crossing intention in ego-view. Pedestrian intention depends not only on their intrinsic goals but also on the stimulation of surrounding traffic elements. Considering the influence of other traffic elements on pedestrian intention, recent work introduced more traffic element information into the model to successfully improve performance. However, it is still difficult to effectively capture and fully exploit the potential dynamic spatio-temporal interactions among the target pedestrian and its surrounding traffic elements for accurate reasoning. In this work, inspired by neuroscience that human drivers tend to make continuous sensory-motor driving decisions by progressive visual stimulation, we propose a model termed Progressive Interaction Transformer (PIT) for pedestrian crossing intention prediction. Local pedestrian, global environment, and ego-vehicle motion are considered simultaneously in the proposed PIT. In particular, the temporal fusion block and self-attention mechanism are introduced to jointly and progressively model the dynamic spatio-temporal interactions among the three parties, allowing it to capture richer information and make prediction in a similar way to human drivers. Experimental results demonstrate that PIT achieves higher performance compared with other state-of-the-arts and preserves real-time inference. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2023PIT
ER  -

TY  - JOUR
AU  - Liang, M.
AU  - Zhu, X.
AU  - Zhou, H.
AU  - Qin, J.
AU  - Yin, X.-C.
TI  - HFENet: Hybrid Feature Enhancement Network for Detecting Texts in Scenes and Traffic Panels
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 12
C7  - 3305686
SP  - 14200
EP  - 14212
DO  - 10.1109/TITS.2023.3305686
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168667093&doi=10.1109%2fTITS.2023.3305686&partnerID=40&md5=ef6bd6f4d981109d0ace7f795c187e70
AB  - Text detection in complex scene images is a challenging task for intelligent transportation. Existing scene text detection methods often adopt multi-scale feature learning strategies to extract informative feature representations for covering objects of various sizes. However, the sampling operation inherent in multi-scale feature generation can easily impair high-frequency details (e.g., textures and boundaries), which are critical for text detection. In this work, we propose an innovative Hybrid Feature Enhancement Network (dubbed HFENet) to explicitly improve the quality of high-frequency information for detecting texts in scenes and traffic panels. To be concrete, we propose a simple yet effective self-guided feature enhancement module (SFEM) for globally lifting feature representations to highly discriminative and high-frequency abundant ones. Notably, our SFEM is pluggable and will be removed after training without introducing extra computational costs. In addition, due to the challenge and importance of accurately predicting boundaries for text detection, we propose a novel boundary enhancement module (BEM) to explicitly strengthen local feature representations in the guidance of boundary annotation for accurate localization. Extensive experiments on multiple publicly available datasets (i.e., MSRA-TD500, CTW1500, Total-Text, Traffic Guide Panel Dataset, Chinese Road Plate Dataset, and ASAYAR_TXT) verify the state-of-the-art performance of our method.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Liang2023HFENet
ER  -

TY  - JOUR
AU  - Hernandez, I.
AU  - Nie, W.
TI  - The AI-IP: Minimizing the guesswork of personality scale item development through artificial intelligence
PY  - 2023
T2  - Personnel Psychology
VL  - 76
IS  - 4
SP  - 1011
EP  - 1035
DO  - 10.1111/peps.12543
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140015986&doi=10.1111%2fpeps.12543&partnerID=40&md5=534080dc0524434579dc6e975b1fbd26
AB  - We propose a framework for integrating various modern natural language processing (NLP) models to assist researchers with developing valid psychological scales. Transformer-based deep neural networks offer state-of-the-art performance on various natural language tasks. This project adapts the transformer model GPT-2 to learn the structure of personality items, and generate the largest openly available pool of personality items, consisting of one million new items. We then use that artificial intelligence-based item pool (AI-IP) to provide a subset of potential scale items for measuring a desired construct. To better recommend construct-related items, we train a paired neural network-based classification BERT model to predict the observed correlation between personality items using only their text. We also demonstrate how zero-shot models can help balance desired content domains within the scale. In combination with the AI-IP, these models narrow the large item pool to items most correlated with a set of initial items. We demonstrate the ability of this multimodel framework to develop longer cohesive scales from a small set of construct-relevant items. We found reliability, validity, and fit equivalent for AI-assisted scales compared to scales developed and optimized by traditional methods. By leveraging neural networks’ ability to generate text relevant to a given topic and infer semantic similarity, this project demonstrates how to support creative and open-ended elements of the scale development process to increase the likelihood of one's initial scale being valid, and minimize the need to modify and revalidate the scale. © 2022 The Authors. Personnel Psychology published by Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - FMS:A; AJG:5; ZUFE:1A; zdy:5; 
LB  - Hernandez2023AI-IP
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Li, J.
AU  - Gao, G.
AU  - Lu, H.
AU  - Yang, J.
AU  - Yue, D.
TI  - Lightweight Real-Time Semantic Segmentation Network With Efficient Transformer and CNN
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 12
SP  - 15897
EP  - 15906
DO  - 10.1109/TITS.2023.3248089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149404169&doi=10.1109%2fTITS.2023.3248089&partnerID=40&md5=62da41f719c7d50b318de26b9da2e0f7
AB  - In the past decade, convolutional neural networks (CNNs) have shown prominence for semantic segmentation. Although CNN models have very impressive performance, the ability to capture global representation is still insufficient, which results in suboptimal results. Recently, Transformer achieved huge success in NLP tasks, demonstrating its advantages in modeling long-range dependency. Recently, Transformer has also attracted tremendous attention from computer vision researchers who reformulate the image processing tasks as a sequence-to-sequence prediction but resulted in deteriorating local feature details. In this work, we propose a lightweight real-time semantic segmentation network called LETNet. LETNet combines a U-shaped CNN with Transformer effectively in a capsule embedding style to compensate for respective deficiencies. Meanwhile, the elaborately designed Lightweight Dilated Bottleneck (LDB) module and Feature Enhancement (FE) module cultivate a positive impact on training from scratch simultaneously. Extensive experiments performed on challenging datasets demonstrate that LETNet achieves superior performances in accuracy and efficiency balance. Specifically, It only contains 0.95M parameters and 13.6G FLOPs but yields 72.8% mIoU at 120 FPS on the Cityscapes test set and 70.5% mIoU at 250 FPS on the CamVid test dataset using a single RTX 3090 GPU. Source code will be available at https://github.com/IVIPLab/LETNet.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 47
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2023Lightweight
ER  -

TY  - JOUR
AU  - Huang, W.
AU  - Gao, T.
AU  - Hao, Y.
AU  - Wang, X.
TI  - Transformer-based forecasting for intraday trading in the Shanghai crude oil market: Analyzing open-high-low-close prices
PY  - 2023
T2  - Energy Economics
VL  - 127
C7  - 107106
DO  - 10.1016/j.eneco.2023.107106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174439649&doi=10.1016%2fj.eneco.2023.107106&partnerID=40&md5=ce6ad980c9198f83c300fc8222bdecdb
AB  - The Shanghai crude oil futures market exudes distinct speculative attributes, underscoring the pivotal significance of precise price forecasts. Accurate forecasting of Shanghai crude oil futures prices assumes vital importance for investors to optimize their portfolios profitably, for producers to mitigate production risks in the crude oil spot market, and for providing cogent decision-making support to government entities. This study implements a groundbreaking unbiased structural forecasting for Shanghai crude oil futures' open-high-low-close (OHLC) prices leveraging the Transformer framework coupled with the model-driven and penalty term-based loss function designs. Based on OHLC forecasts, this study devises three intraday trading strategies. Notably, our results evince that the forecasting accuracy of the Transformer outperforms the Naïve method, vector autoregression (VAR) and vector error correction model (VECM), multiple linear regression (MLR), support vector regression (SVR), and long short-term memory (LSTM) neural network when applied to different temporal granularities of Shanghai crude oil futures OHLC data. Furthermore, the three proposed intraday trading strategies exhibit higher annualized return rates and Sharpe ratios, alongside lower maximum drawdowns and standard deviations of returns in comparison to the conventional close-to-close strategy relying solely on the close price. Remarkably, the forecasting process and intraday trading strategies explicated in this study can equally apply to other futures products in the energy sector, including electricity, coal, and natural gas. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Huang2023Transformer-based
ER  -

TY  - JOUR
AU  - Li, G.
AU  - Zhong, S.
AU  - Deng, X.
AU  - Xiang, L.
AU  - Gary Chan, S.-H.
AU  - Li, R.
AU  - Liu, Y.
AU  - Zhang, M.
AU  - Hung, C.-C.
AU  - Peng, W.-C.
TI  - A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 11
SP  - 10967
EP  - 10980
DO  - 10.1109/TKDE.2022.3233086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147217804&doi=10.1109%2fTKDE.2022.3233086&partnerID=40&md5=d5cb2579192f9e85577009896e534c7e
AB  - We study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency between regions. Given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t-1, we predict the traffic at time t for any region. Prior arts in the area often considered the spatial and temporal dependencies in a decoupled manner, or were rather computationally intensive in training with a large number of hyper-parameters which needed tuning. We propose ST-TIS, a novel, lightweight and accurate Spatial-Temporal Transformer with information fusion and region sampling for traffic forecasting. ST-TIS extends the canonical Transformer with information fusion and region sampling. The information fusion module captures the complex spatial-temporal dependency between regions. The region sampling module is to improve the efficiency and prediction accuracy, cutting the computation complexity for dependency learning from O(n2) to O(nn), where n is the number of regions. With far fewer parameters than state-of-the-art deep learning models, ST-TIS's offline training is significantly faster in terms of tuning and computation (with a reduction of up to 90% on training time and network parameters). Notwithstanding such training efficiency, extensive experiments show that ST-TIS is substantially more accurate in online prediction than state-of-the-art approaches (with an average improvement of 9.5% on RMSE, and 12.4% on MAPE compared to STDN and DSAN). © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:A期刊; FMS:B; 
LB  - Li2023Lightweight
ER  -

TY  - JOUR
AU  - Wu, B.
AU  - Shi, T.
AU  - Zhong, L.
AU  - Zhang, Y.
AU  - Ye, Y.
TI  - Graph-coupled time interval network for sequential recommendation
PY  - 2023
T2  - Information Sciences
VL  - 648
C7  - 119510
DO  - 10.1016/j.ins.2023.119510
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168761802&doi=10.1016%2fj.ins.2023.119510&partnerID=40&md5=90f5df62f4e31fb246f0aec349044acd
AB  - Modeling the dynamics of sequential patterns (i.e., sequential recommendation) has obtained great attention, where the key problem is how to infer the next interesting item according to users' historical actions. Owing to high efficiency and accuracy, several Transformer-like frameworks have successfully achieved this task without adopting complicated recurrent or convolutional operations. Nevertheless, they focus only on the user-item bipartite graph and forgo other auxiliary information, which is non-trivial to attain satisfactory performance especially under long-tail distribution scenarios. In modeling short-term user interests, they fail to capture the time intervals between the recent actions and the target timestamp, which may result in the suboptimal performance. To settle such two problems, we propose a novel architecture for the task of sequential recommendation, namely graph-coupled time interval network (GCTN). Specifically, by means of item category information, we devise a category-aware graph propagation module to better learn user and item embeddings. Furthermore, we design a time-aware self-attention mechanism, which explicitly captures the effect of the time interval between two actions for next item prediction. To integrate these two parts into an organic whole, we introduce a personalized gating strategy to differentiate the importance of each part under the special context. Extensive experiments demonstrate the effectiveness and efficiency of GCTN over recent state-of-the-art methods on four real-world datasets, seamlessly combining the advantages of graph neural networks and Transformers. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:B; 
LB  - Wu2023Graph-coupled
ER  -

TY  - JOUR
AU  - Ma, T.
AU  - Wang, W.
AU  - Chen, Y.
TI  - Attention is all you need: An interpretable transformer-based asset allocation approach
PY  - 2023
T2  - International Review of Financial Analysis
VL  - 90
C7  - 102876
DO  - 10.1016/j.irfa.2023.102876
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166905036&doi=10.1016%2fj.irfa.2023.102876&partnerID=40&md5=d3377944a8159ee3d788e046d8056c1b
AB  - Deep learning technology is rapidly adopted in financial market settings. Using a large data set from the Chinese stock market, we propose a return-risk trade-off strategy via a new transformer model. The empirical findings show that these updates, such as the self-attention mechanism in technology, can improve the use of time-series information related to returns and volatility, increase predictability, and capture more economic gains than other nonlinear models, such as LSTM. Our model employs Shapley additive explanations (SHAP) to measure the “economic feature importance” and tabulates the different important features in the prediction process. Finally, we document several economic explanations for the TF model. This paper sheds light on the burgeoning field on asset allocation in the age of big data. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Ma2023Attention
ER  -

TY  - JOUR
AU  - Sun, X.
AU  - Zhou, J.
AU  - Liu, L.
AU  - Wu, Z.
TI  - CasTformer: A novel cascade transformer towards predicting information diffusion
PY  - 2023
T2  - Information Sciences
VL  - 648
C7  - 119531
DO  - 10.1016/j.ins.2023.119531
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168768594&doi=10.1016%2fj.ins.2023.119531&partnerID=40&md5=2ec403404e1ee73cb22391e5259e1827
AB  - Predicting information diffusion cascade is an essential task in social networks. We mainly focus on predicting the size of the information cascade. The relationships inside a cascade are diverse, including global and relative spatio-temporal relationships, as well as interpersonal influence relationships. These complex relationships between nodes play a crucial role in cascade prediction, but they have not been thoroughly investigated. The Transformer's global receptive field can assist in capturing the relationships between two arbitrary nodes. However, using Transformer directly for a cascade is insufficient without considering its temporal and structural characteristics. In this paper, we propose a novel cascade Transformer for the first time, called CasTformer, specifically designed for cascade size prediction. CasTformer utilizes a global spatio-temporal positional encoding and relative relationship bias matrices on the self-attention mechanism to capture diverse cascade relationships. Moreover, self-knowledge distillation is employed for obtaining a better cascade representation to enhance prediction performance. We use four datasets with nearly millions of cascade samples to validate our model and it achieves training in 3 hours. Experimental results show that it outperforms state-of-the-art methods by an average of 11.9%, 6.1%, and 9.6% on MSLE, MAPE, and R2, respectively. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Sun2023CasTformer
ER  -

TY  - JOUR
AU  - Geng, M.
AU  - Chen, Y.
AU  - Xia, Y.
AU  - Chen, X.M.
TI  - Dynamic-learning spatial-temporal Transformer network for vehicular trajectory prediction at urban intersections
PY  - 2023
T2  - Transportation Research Part C: Emerging Technologies
VL  - 156
C7  - 104330
DO  - 10.1016/j.trc.2023.104330
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170639772&doi=10.1016%2fj.trc.2023.104330&partnerID=40&md5=9a0f9a81c8b1822fce71db996cdc7344
AB  - Forecasting vehicles' future motion is crucial for real-world applications such as the navigation of autonomous vehicles and feasibility of safety systems based on the Internet of Vehicles (IoV). Vehicular trajectory prediction at urban intersections remains challenging due to the difficulty in modeling temporal dependencies and spatial interactions among traffic agents. This paper proposes a dynamic-learning spatial-temporal Transformer network (DSTTN) with domain adaptation training methods based on two modules for two-dimensional vehicular trajectory prediction at urban intersections. The first module is trajectory maneuver characterization (TMC) which captures latent driving maneuver features and divides trajectory data into different categories with different distributions, which can be regarded as different domains in transfer learning (TL). The second module is trajectory distribution matching (TDM) which adopts a novel spatial-temporal Transformer network with distribution matching loss to dynamically learn domain-invariant maneuvers and achieve accurate trajectory prediction. Experiments and ablation studies collected at two unsignalized urban intersections of the inD dataset first validate the interpretability, transferability, and high prediction accuracy of the proposed DSTTN. The results show that the TMC module has maneuver-representational ability. The proposed STTN achieves good and stable prediction accuracy compared with other baselines, including the state-of-the-art deep learning model, while DSTTN with the TMC and TDM modules further improves accuracy. Additional experiments have been conducted under 70 randomly-selected urban intersection scenarios of the Waymo dataset to validate the good prediction accuracy of the proposed method. The formulation of DSTTN offers new ideas for dividing trajectory data into different domains and general domain adaptation to vehicle trajectory prediction under urban road environments. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - FMS:B; 
LB  - Geng2023Dynamic-learning
ER  -

TY  - JOUR
AU  - Zhu, Z.
AU  - Tong, H.
AU  - Wang, Y.
AU  - Li, Y.
TI  - BL-GAN: Semi-Supervised Bug Localization via Generative Adversarial Network
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 11
SP  - 11112
EP  - 11125
DO  - 10.1109/TKDE.2022.3225329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144084847&doi=10.1109%2fTKDE.2022.3225329&partnerID=40&md5=1b5b996afcde95f5d1205ef303335788
AB  - Various automated bug localization technologies have recently emerged that require adequate bug-fix records available to train a predictive model. However, many projects in practice might not provide these necessities, especially for new projects in the first release, due to the expensive human effort for constructing a large amount of bug-fix records. Aiming to capture the potential relevance distribution between the bug report and code file from a limited number of available bug-fix records, we present the first semi-supervised bug localization model named BL-GAN in this paper. For this purpose, the promising Generative Adversarial Network is introduced in BL-GAN, in which synthetic bug-fix records close to the real ones are constructed by searching the project directory tree to generate file paths instead of traversing the contents of all code files. For processing bug reports, the proposed BL-GAN adopts an attention-based Transformer architecture to capture semantic and sequence information. In order to capture the proprietary structural information in code files, BL-GAN incorporates a novel multilayer Graph Convolutional Network to process the source code in a graphical view. Extensive experiments on large-scale real-world datasets reveal that our model BL-GAN significantly outperforms the state-of-the-art on all evaluation measures.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Zhu2023BL-GAN
ER  -

TY  - JOUR
AU  - Tong, J.
AU  - Xie, L.
AU  - Yang, W.
AU  - Zhang, K.
AU  - Zhao, J.
TI  - Enhancing time series forecasting: A hierarchical transformer with probabilistic decomposition representation
PY  - 2023
T2  - Information Sciences
VL  - 647
C7  - 119410
DO  - 10.1016/j.ins.2023.119410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169560816&doi=10.1016%2fj.ins.2023.119410&partnerID=40&md5=bfcc66d7c4128b9c879a55f60538ed00
AB  - Time series forecasting is crucial for several fields, such as disaster warning, weather prediction, and energy consumption. Transformer-based models are considered to have revolutionized the field of time series forecasting. However, the autoregressive form of the Transformer gives rise to cumulative errors in the inference stage. Furthermore, the complex temporal pattern of the time series leads to increased difficulty for the models in mining reliable temporal dependencies. In this paper, we propose a hierarchical Transformer with probabilistic decomposition representation, which provides a flexible framework for hierarchical and decomposable forecasts for time series. The hierarchical mechanism utilizes the forecasting results of the Transformer as conditional information for the generative model, performing sequence-level forecasts to approximate the ground truth, which can mitigate the cumulative error of the autoregressive Transformer. In addition, the conditional generative model encodes historical and predictive information into the latent space and reconstructs typical patterns from the latent space, including seasonality and trend terms. The process provides a flexible framework for the separation of complex patterns through the interaction of information in the latent space. Extensive experiments on several datasets demonstrate the effectiveness and robustness of the model, indicating that it compares favorably with the state of the art. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; FMS:B; 
LB  - Tong2023Enhancing
ER  -

TY  - JOUR
AU  - Tian, R.
AU  - Wang, C.
AU  - Hu, J.
AU  - Ma, Z.
TI  - Multi-scale spatial-temporal aware transformer for traffic prediction
PY  - 2023
T2  - Information Sciences
VL  - 648
C7  - 119557
DO  - 10.1016/j.ins.2023.119557
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169003980&doi=10.1016%2fj.ins.2023.119557&partnerID=40&md5=2e119029da31b9cc765d44e837ce7924
AB  - Traffic prediction is an important part of smart city management. Accurate traffic prediction can be deployed in urban applications such as congestion alerting and route planning, thus providing sustainable services to the public or relevant departments. Although some improvements have been made in existing traffic prediction methods, there are challenges due to the following: (1) Time series has multi-scale nature, that is, from different scale time ranges, traffic flow changes show different trends; (2) Spatial heterogeneity, meaning that traffic conditions in similar functional areas are usually similar. This task remains difficult. To address the above challenges, we propose a new spatial-temporal prediction method, namely Multi-Scale Spatial-Temporal Aware Transformer (MSSTAT), which is a Transformer architecture with multi-scale characteristics. Specifically, compared to the input of encoder, the input of different decoder layers has different scale information, MSSTAT synchronizes model the connection between time steps and scale information by a kind of Parallel Cross Multi-Head Attention, which gives each time step several times the perceived field while also being able to weaken the impact brought by anomaly point. In addition, to add connections between regions with similar functions, we map the traffic data of each node as a probability distribution and then measure the similarity between the nodes by the Wasserstein Distance, which leads to our proposed spatial-temporal aware adjacency matrix. Experimental results on four traffic flow datasets show that MSSTAT outperforms the state-of-the-art baseline. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; FMS:B; 
LB  - Tian2023Multi-scale
ER  -

TY  - JOUR
AU  - Geng, M.
AU  - Cai, Z.
AU  - Zhu, Y.
AU  - Chen, X.
AU  - Lee, D.-H.
TI  - Multimodal Vehicular Trajectory Prediction With Inverse Reinforcement Learning and Risk Aversion at Urban Unsignalized Intersections
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 11
SP  - 12227
EP  - 12240
DO  - 10.1109/TITS.2023.3285891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163502848&doi=10.1109%2fTITS.2023.3285891&partnerID=40&md5=50c4be9c2fcea48823d72ff98b2f4172
AB  - Understanding human drivers' intentions and predicting their future motions are significant to connected and autonomous vehicles and traffic safety and surveillance systems. Predicting multimodal vehicular trajectories at urban unsignalized intersections remains challenging due to dynamic traffic flow and uncertainty of human drivers' maneuvers. In this paper, we propose a comprehensive trajectory prediction framework that combines a multimodal trajectory generation network with inverse reinforcement learning (IRL) and risk aversion (RA) modules. Specifically, we first construct a multimodal spatial-temporal Transformer network (mmSTTN) to generate multiple trajectory candidates, using trajectory coordinates as inputs. Accounting for spatio-temporal features, we formulate the IRL reward function for evaluating all candidate trajectories. The optimal trajectory is then selected based on the computed rewards, a process that mimics human drivers' decision-making. We further develop the RA module based on the driving risk field for optimal risk-averse trajectory prediction. We conduct experiments and ablation studies using the inD dataset at an urban unsignalized intersection, demonstrating impressive human trajectory alignment, prediction accuracy, and the ability to generate risk-averse trajectories. Our proposed framework reduces prediction errors and driving risks by 25% and 30% compared to baseline methods. Results validate vehicles' human-like risk-averse diverging-and-concentrating behavior as they traverse the intersection. The proposed framework presents a novel approach for forecasting multimodal vehicular trajectories by imitating human drivers and incorporating physics-based risk information derived from the driving field. This research offers a promising direction for enhancing the safety and efficiency of connected and autonomous vehicles navigating urban environments. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; FMS:B; 
LB  - Geng2023Multimodal
ER  -

TY  - JOUR
AU  - Fu, M.
AU  - Nguyen, V.
AU  - Tantithamthavorn, C.(k).
AU  - Le, T.
AU  - Phung, D.
TI  - VulExplainer: A Transformer-Based Hierarchical Distillation for Explaining Vulnerability Types
PY  - 2023
T2  - IEEE Transactions on Software Engineering
VL  - 49
IS  - 10
SP  - 4550
EP  - 4565
DO  - 10.1109/TSE.2023.3305244
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168263380&doi=10.1109%2fTSE.2023.3305244&partnerID=40&md5=915c3a0a9c829c9a2c0c80dd0a28f186
AB  - Deep learning-based vulnerability prediction approaches are proposed to help under-resourced security practitioners to detect vulnerable functions. However, security practitioners still do not know what type of vulnerabilities correspond to a given prediction (aka CWE-ID). Thus, a novel approach to explain the type of vulnerabilities for a given prediction is imperative. In this paper, we propose VulExplainer, an approach to explain the type of vulnerabilities. We represent VulExplainer as a vulnerability classification task. However, vulnerabilities have diverse characteristics (i.e., CWE-IDs) and the number of labeled samples in each CWE-ID is highly imbalanced (known as a highly imbalanced multi-class classification problem), which often lead to inaccurate predictions. Thus, we introduce a Transformer-based hierarchical distillation for software vulnerability classification in order to address the highly imbalanced types of software vulnerabilities. Specifically, we split a complex label distribution into sub-distributions based on CWE abstract types (i.e., categorizations that group similar CWE-IDs). Thus, similar CWE-IDs can be grouped and each group will have a more balanced label distribution. We learn TextCNN teachers on each of the simplified distributions respectively, however, they only perform well in their group. Thus, we build a transformer student model to generalize the performance of TextCNN teachers through our hierarchical knowledge distillation framework. Through an extensive evaluation using the real-world 8,636 vulnerabilities, our approach outperforms all of the baselines by 5%-29%. The results also demonstrate that our approach can be applied to Transformer-based architectures such as CodeBERT, GraphCodeBERT, and CodeGPT. Moreover, our method maintains compatibility with any Transformer-based model without requiring any architectural modifications but only adds a special distillation token to the input. These results highlight our significant contributions towards the fundamental and practical problem of explaining software vulnerability.  © 1976-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:A期刊; FMS:B; 
LB  - Fu2023VulExplainer
ER  -

TY  - JOUR
AU  - Jiayi, X.I.E.
AU  - Chen, Z.
TI  - Hierarchical Transformer with Spatio-temporal Context Aggregation for Next Point-of-interest Recommendation
PY  - 2023
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 2
C7  - 37
DO  - 10.1145/3597930
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181535550&doi=10.1145%2f3597930&partnerID=40&md5=30d851067f7fdb7ad81556dc4124616f
AB  - Next point-of-interest (POI) recommendation is a critical task in location-based social networks, yet remains challenging due to a high degree of variation and personalization exhibited in user movements. In this work, we explore the latent hierarchical structure composed of multi-granularity short-term structural patterns in user check-in sequences. We propose a Spatio-Temporal context AggRegated Hierarchical Transformer (STAR-HiT) for next POI recommendation, which employs stacked hierarchical encoders to recursively encode the spatio-temporal context and explicitly locate subsequences of different granularities. More specifically, in each encoder, the global attention layer captures the spatio-temporal context of the sequence, while the local attention layer performed within each subsequence enhances subsequence modeling using the local context. The sequence partition layer infers positions and lengths of subsequences from the global context adaptively, such that semantics in subsequences can be well preserved. Finally, the subsequence aggregation layer fuses representations within each subsequence to form the corresponding subsequence representation, thereby generating a new sequence of higher-level granularity. The stacking of hierarchical encoders captures the latent hierarchical structure of the check-in sequence, which is used to predict the next visiting POI. Extensive experiments on three public datasets demonstrate that the proposed model achieves superior performance while providing explanations for recommendations. © 2023 Association for Computing Machinery. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:A期刊; FMS:B; 
LB  - Jiayi2023Hierarchical
ER  -

TY  - JOUR
AU  - Xie, P.
AU  - Ma, M.
AU  - Li, T.
AU  - Ji, S.
AU  - Du, S.
AU  - Yu, Z.
AU  - Zhang, J.
TI  - Spatio-Temporal Dynamic Graph Relation Learning for Urban Metro Flow Prediction
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 10
SP  - 9973
EP  - 9984
DO  - 10.1109/TKDE.2023.3269771
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159688094&doi=10.1109%2fTKDE.2023.3269771&partnerID=40&md5=9dbfafd8ee6fa5758e990381e3747389
AB  - Urban metro flow prediction is of great value for metro operation scheduling, passenger flow management and personal travel planning. However, the problem is challenging. First, different metro stations, e.g. transfer stations and non-transfer stations have unique traffic patterns. Second, it is difficult to model complex spatio-temporal dynamic relation of metro stations. To address these challenges, we develop a spatio-temporal dynamic graph relational learning model (STDGRL) to predict urban metro station flow. First, we propose a spatio-temporal node embedding representation module to capture the traffic patterns of different stations. Second, we employ a dynamic graph relationship learning module to learn dynamic spatial relationships between metro stations without a predefined graph adjacency matrix. Finally, we provide a transformer-based long-term relationship prediction module for long-term metro flow prediction. Extensive experiments are conducted based on metro data in four cities, China, with experimental results demonstrating the advantages of our method compared over 14 baselines for urban metro flow prediction. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:A期刊; FMS:B; 
LB  - Xie2023Spatio-Temporal
ER  -

TY  - JOUR
AU  - Arashpour, M.
TI  - AI explainability framework for environmental management research
PY  - 2023
T2  - Journal of Environmental Management
VL  - 342
C7  - 118149
DO  - 10.1016/j.jenvman.2023.118149
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159040416&doi=10.1016%2fj.jenvman.2023.118149&partnerID=40&md5=60429c48d758c929025db8c21c2159af
AB  - Deep learning networks powered by AI are essential predictive tools relying on image data availability and processing hardware advancements. However, little attention has been paid to explainable AI (XAI) in application fields, including environmental management. This study develops an explainability framework with a triadic structure to focus on input, AI model and output. The framework provides three main contributions. (1) A context-based augmentation of input data to maximize generalizability and minimize overfitting. (2) A direct monitoring of AI model layers and parameters to use leaner (lighter) networks suitable for edge device deployment, (3) An output explanation procedure focusing on interpretability and robustness of predictive decisions by AI networks. These contributions significantly advance state of the art in XAI for environmental management research, offering implications for improved understanding and utilization of AI networks in this field. © 2023 The Author
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - FMS:B; 
LB  - Arashpour2023AI
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Zhang, C.
AU  - Song, X.
AU  - Dong, Z.
AU  - Zhu, H.
AU  - Li, W.
TI  - Contextualized Knowledge Graph Embedding for Explainable Talent Training Course Recommendation
PY  - 2023
T2  - ACM Transactions on Information Systems
VL  - 42
IS  - 2
C7  - 33
DO  - 10.1145/3597022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165636537&doi=10.1145%2f3597022&partnerID=40&md5=203a3b2760ce14aae74a718a7b0e1c9a
AB  - Learning and development, or L&D, plays an important role in talent management, which aims to improve the knowledge and capabilities of employees through a variety of performance-oriented training activities. Recently, with the rapid development of enterprise management information systems, many research efforts and industrial practices have been devoted to building personalized employee training course recommender systems. Nevertheless, a widespread challenge is how to provide explainable recommendations with the consideration of different learning motivations from talents. To this end, we propose CKGE, a contextualized knowledge graph (KG) embedding approach for developing an explainable training course recommender system. A novel perspective of CKGE is to integrate both the contextualized neighbor semantics and high-order connections as motivation-aware information for learning effective representations of talents and courses. Specifically, in CKGE, for each entity pair (i.e., the talent-course pair), we first construct a meta-graph, including the neighbors of each entity and the meta-paths between entities as motivation-aware information. Then, we develop a novel KG-based Transformer, which can serialize entities and paths in the meta-graph as a sequential input, with the specially designed relational attention and structural encoding mechanisms to better model the global dependence of KG structured data. Meanwhile, the local path mask prediction can effectively reveal the importance of different paths. As a result, CKGE not only can make precise predictions but also can discriminate the saliencies of meta-paths in characterizing corresponding preferences. Extensive experiments on real-world and public datasets clearly validate the effectiveness and interpretability of CKGE compared with state-of-the-art baselines. © 2023 Association for Computing Machinery. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:A期刊; FMS:B; 
LB  - Yang2023Contextualized
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Wu, D.
AU  - Boulet, B.
TI  - MetaProbformer for Charging Load Probabilistic Forecasting of Electric Vehicle Charging Stations
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 10
SP  - 10445
EP  - 10455
DO  - 10.1109/TITS.2023.3276947
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161066186&doi=10.1109%2fTITS.2023.3276947&partnerID=40&md5=ba14cb69d5a8b5a9c6a52ceb08286c02
AB  - The penetration of electric vehicles (EV) has been increasing rapidly in recent years. Electric vehicle charging load poses a huge demand on the power grids. The forecasting for electric vehicle charging load, especially for the charging load of EV charging stations, is of significant importance for the safe operation of power grids. However, most of the existing forecasting methods fail to capture the long-term dependencies efficiently and assume the availability of a large amount of training data. Hence, they cannot address newly built charging stations with scarce historical charging load data. Meanwhile, most of the methods focus on point forecasting, which lacks risk consideration. In this work, we aim to leverage the benefits of Transformer-based models for EV charging forecasting. Specifically, we propos Probformer, a Transformer-based forecasting model for charging load forecasting. To enable Probformer to adapt fast to unseen environments, we further extend it to MetaProbformer, a meta-learning-based forecasting framework. Extensive experiments have been done on real-world datasets for both point forecasting and probabilistic forecasting. Experimental results show that our methods can consistently outperform baseline methods by a large margin.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2023MetaProbformer
ER  -

TY  - JOUR
AU  - Zou, G.
AU  - Lai, Z.
AU  - Ma, C.
AU  - Tu, M.
AU  - Fan, J.
AU  - Li, Y.
TI  - When Will We Arrive? A Novel Multi-Task Spatio-Temporal Attention Network Based on Individual Preference for Estimating Travel Time
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 10
SP  - 11438
EP  - 11452
DO  - 10.1109/TITS.2023.3276916
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161042931&doi=10.1109%2fTITS.2023.3276916&partnerID=40&md5=13272680512ccadefa90a7d5fc2c368d
AB  - Predicting how long a trip will take may allow travelers plan ahead, save money, and avoid traffic congestion. The journey time estimation model should take into account three crucial factors: (1) individual travel preference, (2) dynamic spatio-temporal correlations, and (3) the association between long-term speed forecast and travel time estimate. In order to overcome these challenges, this study proposes a unique parallel architecture called the multi-task spatio-temporal attention network (MT-STAN) to estimate journey times. To extract the dynamic spatio-temporal correlations of the road network, we first develop a traffic speed prediction model based on spatio-temporal block and bridge transformer networks, combining the road, timestamp, and traffic speed information into hidden states. Second, we offer a personalized model for estimating journey times that makes use of cross-network, holistic attention, and semantic transformer. In this approach, travel preferences extraction through cross-network, holistic attention permits correlations between the dynamic road network's hidden states and individual journey characteristics, which are subsequently transformed into global semantics by the semantic transformer; preferences and semantics are integrated during the estimate phase. Finally, a multi-task learning component is included, which combines both traffic speed prediction and individual journey time estimate, via the sharing of underlying network parameters and the improvement of the contextual semantic knowledge of the latter job. Evaluation experiments are carried out using a highway dataset collected in Yinchuan City, Ningxia Province, China. The proposed prediction model outperforms state-of-the-art baseline approaches in experiments.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; FMS:B; 
LB  - Zou2023When
ER  -

TY  - JOUR
AU  - Geng, M.
AU  - Li, J.
AU  - Li, C.
AU  - Xie, N.
AU  - Chen, X.
AU  - Lee, D.-H.
TI  - Adaptive and Simultaneous Trajectory Prediction for Heterogeneous Agents via Transferable Hierarchical Transformer Network
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 10
SP  - 11479
EP  - 11492
DO  - 10.1109/TITS.2023.3276946
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162731101&doi=10.1109%2fTITS.2023.3276946&partnerID=40&md5=b37544a19e59c5aaeae5b7465313d513
AB  - Simultaneously and accurately predicting trajectories of multiple heterogeneous agents is crucial for intelligent transportation systems (ITS) applications, e.g., connected and autonomous vehicles. Existing model-based and data-driven methods can achieve good prediction accuracy, but most of them neglect the domain shift issue and prevalent imperfect data problems, i.e., few-shot learning and zero-shot learning issues. To address these issues, we propose a multi-source transfer learning (TL) framework, transferable hierarchical Siamese Transformer network (T-HSTN), for trajectory prediction of multiple heterogeneous agents, e.g., vehicles, bicycles, and pedestrians, at urban unsignalized intersections under small data conditions. Specifically, by extending the self-attention mechanism and exploring feature representations of traffic scenes, a Transformer-based network that hierarchically extracts temporal/spatial features and map features is introduced as the basic prediction model. Moreover, a TL framework with adaptive learning and feature alignment modules is built to explore the feature representations of unfixed traffic scenes and align both statistical and deep features to learn domain-invariant knowledge. More challenging trajectory prediction experiments are designed, corresponding to newly-built or badly-instrumented intersections under real-world scenarios. Experimental results verify the proposed method's high accuracy, transferability, and generability. Our work fills the gap in solutions and benchmarks for TL tasks in trajectory prediction for heterogeneous agents. The conducted TL experiments provide a more practical setting of considering imperfect data problems in trajectory prediction. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Geng2023Adaptive
ER  -

TY  - JOUR
AU  - Geng, M.
AU  - Li, J.
AU  - Xia, Y.
AU  - Chen, X.M.
TI  - A physics-informed Transformer model for vehicle trajectory prediction on highways
PY  - 2023
T2  - Transportation Research Part C: Emerging Technologies
VL  - 154
C7  - 104272
DO  - 10.1016/j.trc.2023.104272
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167436609&doi=10.1016%2fj.trc.2023.104272&partnerID=40&md5=b215311774672aefa3899233b1fa17fd
AB  - Autonomous Vehicles (AVs) have made remarkable developments and are anticipated to replace human drivers. In transitioning from human-driven vehicles to fully AVs, one crucial task is to predict the trajectories of the subject vehicle and its surrounding vehicles in real time. Most existing methods of vehicle trajectory prediction on highways are based on physical models or purely data-driven models. However, they either yield unsatisfactory prediction performance or lack model interpretability and physical implications. This paper proposes a Physics-Informed Deep Learning framework that fully leverages the advantages of data-driven and physics-based models to go beyond the existing models. We use the Transformer neural network architecture with self-attention as Physics-Uninformed Neural Network (PUNN) and Intelligent Driver Model (IDM) as physical model to construct of Physics-Informed Transformer-Intelligent Driver Model (PIT-IDM). Extensive experiments have been conducted on two datasets with different traffic environments, i.e., Next Generation SIMulation (NGSIM) data in the US and the Ubiquitous Traffic Eyes (UTE) data in China, to verify model accuracy and efficiency. Compared with the three kinds of baselines by relative and absolute measures of effectiveness, the best performing PIT-IDM reduces longitudinal trajectory prediction errors for long horizons by 5%-50%, some even reduced up to 70%. Extensive empirical analyses have been carried out to verify its excellent spatio-temporal transferability and explore the physics-informed mechanism underlying this deep learning method. The training and inference time analysis indicates that although it takes longer to train PIT-IDM, it requires fewer calls and accumulates fewer errors with less computation time in real-world applications. The overall results further validate the efficacy of this Physics-Informed Deep Learning framework in enhancing model accuracy, interpretability, and transferability. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - FMS:B; 
LB  - Geng2023physics-informed
ER  -

TY  - JOUR
AU  - Li, R.
AU  - Zhang, F.
AU  - Li, T.
AU  - Zhang, N.
AU  - Zhang, T.
TI  - DMGAN: Dynamic Multi-Hop Graph Attention Network for Traffic Forecasting
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 9
SP  - 9088
EP  - 9101
DO  - 10.1109/TKDE.2022.3221316
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141640181&doi=10.1109%2fTKDE.2022.3221316&partnerID=40&md5=c312dc7b8c90d9e7693d09725b9827f2
AB  - In the intelligent transportation system, traffic forecasting, which is generally characterized as a graph spatial-temporal prediction task, plays a crucial role. It is challenging to generate reliable forecast results due to the complexity of traffic topological information and the inherent uncertainty of road traffic circumstances. Existing works generally focus on modeling spatial dependency on static graph structures, but ignore dynamic relations between road segments and cannot extract long-range traffic dependencies in spatial-temporal domains. To bridge the above gaps, we present a novel framework, called Dynamic Multi-Hop Graph Attention Network (DMGAN). Specifically, we leverage dynamic graph modeling to capture time-varying relations across road sections and introduce the multi-hop operation in each message propagation layer to extract long-range spatial dependency. Meanwhile, we develop a fusion-attention module, preserving both local and global hidden layer outputs of the encoder, to capture both long- and short-term temporal dependencies jointly. In this way, our method can fully model complex time-varying traffic topology information and capture the internal patterns of traffic series by integrating dynamic graph structure and temporal attention component. DGMAN achieves state-of-the-art performance in three metrics, as demonstrated by experimental findings on four real-world public traffic datasets, METR-LA, PEMS-BAY, PEMS03, and PEMS07.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:A期刊; FMS:B; 
LB  - Li2023DMGAN
ER  -

TY  - JOUR
AU  - Xiao, M.
AU  - Qiao, Z.
AU  - Fu, Y.
AU  - Dong, H.
AU  - Du, Y.
AU  - Wang, P.
AU  - Xiong, H.
AU  - Zhou, Y.
TI  - Hierarchical Interdisciplinary Topic Detection Model for Research Proposal Classification
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 9
SP  - 9685
EP  - 9699
DO  - 10.1109/TKDE.2023.3248608
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149419699&doi=10.1109%2fTKDE.2023.3248608&partnerID=40&md5=3ca018483ff00bc96c93b10fa597794c
AB  - The peer merit review of research proposals has been the major mechanism to decide grant awards. However, research proposals have become increasingly interdisciplinary. It has been a longstanding challenge to assign interdisciplinary proposals to appropriate reviewers so proposals are fairly evaluated. One of the critical steps in reviewer assignment is to generate accurate interdisciplinary topic labels for proposal-reviewer matching. Existing systems mainly collect topic labels manually generated by principle investigators. However, such human-reported labels can be non-accurate, incomplete, labor intensive, and time costly. What role can AI play in developing a fair and precise proposal reviewer assignment system? In this study, we collaborate with the National Science Foundation of China to address the task of automated interdisciplinary topic path detection. For this purpose, we develop a deep Hierarchical Interdisciplinary Research Proposal Classification Network (HIRPCN). Specifically, we first propose a hierarchical transformer to extract the textual semantic information of proposals. We then design an interdisciplinary graph and leverage GNNs to learn representations of each discipline in order to extract interdisciplinary knowledge. After extracting the semantic and interdisciplinary knowledge, we design a level-wise prediction component to fuse the two types of knowledge representations and detect interdisciplinary topic paths for each proposal. We conduct extensive experiments and expert evaluations on three real-world datasets to demonstrate the effectiveness of our proposed model.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:A期刊; FMS:B; 
LB  - Xiao2023Hierarchical
ER  -

TY  - JOUR
AU  - Wen, Y.
AU  - Li, Z.
AU  - Wang, X.
AU  - Xu, W.
TI  - Traffic demand prediction based on spatial-temporal guided multi graph Sandwich-Transformer
PY  - 2023
T2  - Information Sciences
VL  - 643
C7  - 119269
DO  - 10.1016/j.ins.2023.119269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161063770&doi=10.1016%2fj.ins.2023.119269&partnerID=40&md5=4d92f86652d54757fa543ee3a27aeaa5
AB  - The ability of spatial-temporal traffic demand prediction is crucial for urban computing, traffic management and future autonomous driving. In this paper, a novel Spatial-Temporal Guided Multi-graph Sandwich-Transformer (STGMT) is suggested to address the ubiquitous spatial-temporal heterogeneity in traffic demand forecasting. Compared to the original Transformer, we employ Time to Vector (Time2Vec) and Node to Vector (Node2Vec) in the embedding layer to obtain universal representations for temporal nodes and spatial nodes, respectively, which are then combined to form Spatial-Temporal Embedding (STE) blocks. The STE guides the attention mechanism, maintaining a unique parameter space for spatial-temporal nodes and enabling the learning of node-specific patterns. In STGMT, we develop Multi-head Temporal Attention (MTA) and Multi-head Temporal Interactive Attention (MTIA) for extracting temporal features, while Multi-head Spatial Attention (MSA) is employed for extracting spatial features. Furthermore, MSA incorporates both the accessibility graph determined by road topology and the similarity graph determined by specific traffic events to characterize the pairwise relationships among spatial nodes. Various attentions and feed-forward layers are rearranged and combined to form the Sandwich-Transformer. Extensive experiments are conducted on public datasets of node-level tasks of two different types (highway and urban) and indicate that the STGMT outperforms state-of-the-art models. The proposed STGMT effectively addresses the ubiquitous spatial-temporal heterogeneity challenge in traffic demand forecasting, thereby enhancing the accuracy of traffic demand prediction and offering valuable guidance for traffic planning and operations. Our code and data are open source at https://github.com/YanJieWen/STGMT-Tensorflow-implementation. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Wen2023Traffic
ER  -

TY  - JOUR
AU  - Zhong, X.
AU  - Yan, X.
AU  - Yang, Z.
AU  - Huang, W.
AU  - Jiang, K.
AU  - Liu, R.W.
AU  - Wang, Z.
TI  - Visual Exposes You: Pedestrian Trajectory Prediction Meets Visual Intention
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 9
SP  - 9390
EP  - 9400
DO  - 10.1109/TITS.2023.3266762
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153503280&doi=10.1109%2fTITS.2023.3266762&partnerID=40&md5=45c3ecc3e9831fe2cc293c09ee919a70
AB  - Pedestrian trajectory prediction in multiple scenarios is of immense importance in autonomous driving and disentanglement of human behavior but is limited in catching human intention and initiative. Most previous works tend to predict the trajectory using only 2D coordinates, which generally cause two common problems: a) Overlooking the subjective initiative, including sudden swerve and erratic movement; b) A potential challenge called abnormal collision caused by unlabeled pedestrians on dataset is not being identified and resolved, which would ruin the model prediction. To break those limitations, we introduce visual localization and orientation as Visual Intention Knowledge to help the trajectory prediction, which is learned directly from visual scenarios. It benefits to comprehend human intention and formulates decision-making processes. Moreover, by learning from the visual information and decision-making policy, we construct the Visual Intention Knowledge associated spatio-temporal Transformer (VIKT) to predict human trajectory by combining the intention knowledge with the novel Transformer. Extensive experimental results demonstrate that our VIKT model could achieve competitive performance by the Visual Intention Knowledge through optimizing the model prediction compared with state-of-the-art methods in terms of prediction accuracy on ETH/UCY and SDD benchmarks.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Zhong2023Visual
ER  -

TY  - JOUR
AU  - Wong, C.
AU  - Xia, B.
AU  - Peng, Q.
AU  - Yuan, W.
AU  - You, X.
TI  - MSN: Multi-Style Network for Trajectory Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 9
SP  - 9751
EP  - 9766
DO  - 10.1109/TITS.2023.3274777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161609901&doi=10.1109%2fTITS.2023.3274777&partnerID=40&md5=220e0827f0fb24f0e26a2208719fc31d
AB  - Trajectory prediction aims to forecast agents' possible future locations considering their observations along with the video context. It is strongly needed by many autonomous platforms like tracking, detection, robot navigation, and self-driving cars. Whether it is agents' internal personality factors, interactive behaviors with the neighborhood, or the influence of surroundings, they all impact agents' future planning. However, many previous methods model and predict agents' behaviors with the same strategy or feature distribution, making them challenging to make predictions with sufficient style differences. This paper proposes the Multi-Style Network (MSN), which utilizes style proposal and stylized prediction using two sub-networks, to provide multi-style predictions in a novel categorical way adaptively. The proposed network contains a series of style channels, and each channel is bound to a unique and specific behavior style. We use agents' end-point plannings and their interaction context as the basis for the behavior classification, so as to adaptively learn multiple diverse behavior styles through these channels. Then, we assume that the target agents may plan their future behaviors according to each of these categorized styles, thus utilizing different style channels to make predictions with significant style differences in parallel. Experiments show that the proposed MSN outperforms current state-of-the-art methods up to 10% quantitatively on two widely used datasets, and presents better multi-style characteristics qualitatively.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; FMS:B; 
LB  - Wong2023MSN
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Zhang, J.
AU  - Yang, L.
AU  - Yang, Y.
AU  - Li, X.
AU  - Gao, Z.
TI  - Short-term passenger flow prediction for multi-traffic modes: A Transformer and residual network based multi-task learning method
PY  - 2023
T2  - Information Sciences
VL  - 642
C7  - 119144
DO  - 10.1016/j.ins.2023.119144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160005776&doi=10.1016%2fj.ins.2023.119144&partnerID=40&md5=34bfa51bb722ea24119fac423e7a22cb
AB  - Managing multiple traffic modes cooperatively is becoming increasingly important owing to the diversity of passenger demands. Short-term passenger flow predictions for multi-traffic modes can be applied to the management of the multi-traffic modes system. However, this is challenging because the spatiotemporal features of multi-traffic modes are complex. Moreover, the passenger flows of the multi-traffic modes differentiated and fluctuated significantly. To address these issues, this study proposes a multitask learning-based model, called Res-Transformer, for short-term inflow prediction of multi-traffic modes. The Res-Transformer consists of two parts: (1) modified Transformer layers comprising the Conv-Transformer layer and the multi-head attention mechanism, which helps extract the spatiotemporal features of multi-traffic modes, and (2) the structure of the residual network, which is utilized to obtain correlations among multi-traffic modes and prevent gradient vanishing and explosion. The proposed model was evaluated using two large-scale real-world datasets from Beijing, China. One was a traffic hub, and the other was a residential area. The results not only demonstrate the effectiveness and robustness of the Res-Transformer but also prove the benefits of considering multi-traffic modes jointly. This study provides critical insights into short-term inflow prediction of the multi-traffic modes system. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2023Short-term
ER  -

TY  - JOUR
AU  - Kong, L.
AU  - Ojha, V.
AU  - Gao, R.
AU  - Suganthan, P.N.
AU  - Snášel, V.
TI  - Low-rank and global-representation-key-based attention for graph transformer
PY  - 2023
T2  - Information Sciences
VL  - 642
C7  - 119108
DO  - 10.1016/j.ins.2023.119108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159566842&doi=10.1016%2fj.ins.2023.119108&partnerID=40&md5=f8b8a585a314d02d0724a1ec5ec7fa02
AB  - Transformer architectures have been applied to graph-specific data such as protein structure and shopper lists, and they perform accurately on graph/node classification and prediction tasks. Researchers have proved that the attention matrix in Transformers has low-rank properties, and the self-attention plays a scoring role in the aggregation function of the Transformers. However, it can not solve the issues such as heterophily and over-smoothing. The low-rank properties and the limitations of Transformers inspire this work to propose a Global Representation (GR) based attention mechanism to alleviate the two heterophily and over-smoothing issues. First, this GR-based model integrates geometric information of the nodes of interest that conveys the structural properties of the graph. Unlike a typical Transformer where a node feature forms a Key, we propose to use GR to construct the Key, which discovers the relation between the nodes and the structural representation of the graph. Next, we present various compositions of GR emanating from nodes of interest and α-hop neighbors. Then, we explore this attention property with an extensive experimental test to assess the performance and the possible direction of improvements for future works. Additionally, we provide mathematical proof showing the efficient feature update in our proposed method. Finally, we verify and validate the performance of the model on eight benchmark datasets that show the effectiveness of the proposed method. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Kong2023Low-rank
ER  -

TY  - JOUR
AU  - Tang, C.
AU  - Hu, Q.
AU  - Zhou, G.
AU  - Yao, J.
AU  - Zhang, J.
AU  - Huang, Y.
AU  - Ye, Q.
TI  - Transformer Sub-Patch Matching for High-Performance Visual Object Tracking
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 8
SP  - 8121
EP  - 8135
DO  - 10.1109/TITS.2023.3264664
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153373340&doi=10.1109%2fTITS.2023.3264664&partnerID=40&md5=ba9e8c6583023e3122a2051079af6f26
AB  - Visual tracking is a core component of intelligent transportation systems, especially for unmanned driving and road surveillance. Numerous convolutional neural network (CNN) trackers have achieved unprecedented performance. However, CNN features with regular spatial context relationships experience difficulty matching the rigid target templates when dramatic deformation and occlusion occur. In this paper, we propose a novel full Transformer Sub-patch Matching network for tracking (TSMtrack), which decomposes the tracked object into sub-patches, and interlaced matches the extracted sub-patches by leveraging the attention mechanism born with the Transformer. Roots in Transformer architecture, TSMtrack consists of image patch decomposition, sub-patch matching, and position prediction. Specifically, TSMtrack converts the whole frame into sub-patches and extracts the sub-patch features independently. By sub-patch matching and FFN-like prediction, TSMtrack enables independent similarity measurement between sub-patch features in an interlaced and iterative fashion. With a full Transformer pipeline implemented, we achieve a high-quality trade-off between tracking speed performance. Experiments on nine benchmarks demonstrate the effectiveness of our Transformer sub-patch matching framework. In particular, it realizes an AO of 75.6 on GOT-10K and SR of 57.9 on WebUAV-3M with 48 FPS on GPU RTX-2060s.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Tang2023Transformer
ER  -

TY  - JOUR
AU  - Bapaume, T.
AU  - Côme, E.
AU  - Ameli, M.
AU  - Roos, J.
AU  - Oukhellou, L.
TI  - Forecasting passenger flows and headway at train level for a public transport line: Focus on atypical situations
PY  - 2023
T2  - Transportation Research Part C: Emerging Technologies
VL  - 153
C7  - 104195
DO  - 10.1016/j.trc.2023.104195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163215000&doi=10.1016%2fj.trc.2023.104195&partnerID=40&md5=0a717b535d45ecb8c5d2bd56948ea39e
AB  - This paper proposes a computer vision framework based on deep learning approaches for the real-time prediction of passenger loads and train headways in a metro line in an urban transit network. The short-term prediction problem is formulated as an image completion task. The train journeys on the metro line are represented as images, with the pixels denoting the train data, including the departure location, time, and load. Metro line applicative constraints, e.g., irregular time sampling of trains and univariate space, are considered in the images. Several deep learning-based architectures are investigated, including two new architectures based on transformers. Finally, an in-depth analysis and comparison of the models is performed based on a real test case of Paris metro line 9, for which a large database was collected over three years. This allowed us to include numerous instances with atypical transport system performance indicators (e.g., strikes, lockdowns, and disruptions) and to design a methodology (based on a latent space representation of the dataset) to identify and label interesting test cases. We evaluate and demonstrate the robustness of the proposed approaches numerically and study their limits for passenger loads and headways in atypical scenarios. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; 
LB  - Bapaume2023Forecasting
ER  -

TY  - JOUR
AU  - Gomes, L.
AU  - da Silva Torres, R.
AU  - Côrtes, M.L.
TI  - BERT- and TF-IDF-based feature extraction for long-lived bug prediction in FLOSS: A comparative study
PY  - 2023
T2  - Information and Software Technology
VL  - 160
C7  - 107217
DO  - 10.1016/j.infsof.2023.107217
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152939913&doi=10.1016%2fj.infsof.2023.107217&partnerID=40&md5=938e8ab6fdc27e7fe4fe0274662aa1a2
AB  - Context: The correct prediction of long-lived bugs could help maintenance teams to build their plan and to fix more bugs that often adversely affect software quality and disturb the user experience across versions in Free/Libre Open-Source Software (FLOSS). Machine Learning and Text Mining methods have been applied to solve many real-world prediction problems, including bug report handling. Objective: Our research aims to compare the accuracy of ML classifiers on long-lived bug prediction in FLOSS using Bidirectional Encoder Representations from Transformers (BERT)- and Term Frequency - Inverse Document Frequency (TF-IDF)-based feature extraction. Besides that, we aim to investigate BERT variants on the same task. Method: We collected bug reports from six popular FLOSS and used the Machine Learning classifiers to predict long-lived bugs. Furthermore, we compare different feature extractors, based on BERT and TF-IDF methods, in long-lived bug prediction. Results: We found that long-lived bug prediction using BERT-based feature extraction systematically outperformed the TF-IDF. The SVM and Random Forest outperformed other classifiers in almost all datasets using BERT. Furthermore, smaller BERT architectures show themselves as competitive. Conclusion: Our results demonstrated a promising avenue to predict long-lived bugs based on BERT contextual embedding features and fine-tuning procedures. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:B期刊; FMS:B; 
LB  - Gomes2023BERT
ER  -

TY  - JOUR
AU  - Lin, Z.
AU  - Zang, S.
AU  - Wang, R.
AU  - Sun, Z.
AU  - Senthilnath, J.
AU  - Xu, C.
AU  - Kwoh, C.K.
TI  - Attention Over Self-Attention: Intention-Aware Re-Ranking With Dynamic Transformer Encoders for Recommendation
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 8
SP  - 7782
EP  - 7795
DO  - 10.1109/TKDE.2022.3208633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139473253&doi=10.1109%2fTKDE.2022.3208633&partnerID=40&md5=007c2a6ff05ab612006d714f19179004
AB  - Re-ranking models refine item recommendation lists generated by the prior global ranking model, which have demonstrated their effectiveness in improving the recommendation quality. However, most existing re-ranking solutions only learn from implicit feedback with a shared prediction model, which regrettably ignore inter-item relationships under diverse user intentions. In this paper, we propose a novel Intention-aware Re-ranking Model with Dynamic Transformer Encoder (RAISE), aiming to perform user-specific prediction for each individual user based on her intentions. Specifically, we first propose to mine latent user intentions from text reviews with an intention discovering module (IDM). By differentiating the importance of review information with a co-attention network, the latent user intention can be explicitly modeled for each user-item pair. We then introduce a dynamic transformer encoder (DTE) to capture user-specific inter-item relationships among item candidates by seamlessly accommodating the learned latent user intentions via IDM. As such, one can not only achieve more personalized recommendations but also obtain corresponding explanations by constructing RAISE upon existing recommendation engines. Empirical study on four public datasets shows the superiority of our proposed RAISE, with up to 13.95%, 9.60%, and 13.03% relative improvements evaluated by Precision@5, MAP@5, and NDCG@5 respectively.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:A期刊; FMS:B; 
LB  - Lin2023Attention
ER  -

TY  - JOUR
AU  - Deng, J.
AU  - Chen, X.
AU  - Jiang, R.
AU  - Song, X.
AU  - Tsang, I.W.
TI  - A Multi-View Multi-Task Learning Framework for Multi-Variate Time Series Forecasting
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 8
SP  - 7665
EP  - 7680
DO  - 10.1109/TKDE.2022.3218803
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141598882&doi=10.1109%2fTKDE.2022.3218803&partnerID=40&md5=845356357cf485662a5d8851c974025b
AB  - Multi-variate time series (MTS) data is a ubiquitous class of data abstraction in the real world. Any instance of MTS is generated from a hybrid dynamical system and their specific dynamics are usually unknown. The hybrid nature of such a dynamical system is a result of complex external attributes, such as geographic location and time of day, each of which can be categorized into either spatial attributes or temporal attributes. Therefore, there are two fundamental views which can be used to analyze MTS data, namely the spatial view and the temporal view. Moreover, from each of these two views, we can partition the set of data samples of MTS into disjoint forecasting tasks in accordance with their associated attribute values. Then, samples of the same task will manifest similar forthcoming pattern, which is less sophisticated to be predicted in comparison with the original single-view setting. Considering this insight, we propose a novel multi-view multi-task (MVMT) learning framework for MTS forecasting. Instead of being explicitly presented in most scenarios, MVMT information is deeply concealed in the MTS data, which severely hinders the model from capturing it naturally. To this end, we develop two kinds of basic operations, namely task-wise affine transformation and task-wise normalization, respectively. Applying these two operations with prior knowledge on the spatial and temporal view allows the model to adaptively extract MVMT information while predicting. Extensive experiments on three datasets are conducted to illustrate that canonical architectures can be greatly enhanced by the MVMT learning framework in terms of both effectiveness and efficiency. In addition, we design rich case studies to reveal the properties of representations produced at different phases in the entire prediction procedure.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:A期刊; FMS:B; 
LB  - Deng2023Multi-View
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Zhao, X.
AU  - Zhang, X.
AU  - Paliwal, M.
TI  - Real-Time Forecasting of Dockless Scooter-Sharing Demand: A Spatio-Temporal Multi-Graph Transformer Approach
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 8
SP  - 8507
EP  - 8518
DO  - 10.1109/TITS.2023.3239309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148438643&doi=10.1109%2fTITS.2023.3239309&partnerID=40&md5=d71ae67d54e2e88adf57ede9b55ab40b
AB  - Accurately forecasting the real-time travel demand for dockless scooter-sharing is crucial for the planning and operations of transportation systems. Deep learning models provide researchers with powerful tools to achieve this task, but research in this area is still lacking. This paper thus proposes a novel deep learning architecture named Spatio-Temporal Multi-Graph Transformer (STMGT) to forecast the real-time spatiotemporal dockless scooter-sharing demand. The proposed model uses a graph convolutional network (GCN) based on adjacency graph, functional similarity graph, demographic similarity graph, and transportation supply similarity graph to attach spatial dependency to temporal input (i.e., historical demand). The output of GCN is subsequently processed with weather condition information by the Transformer to capture temporal dependency. Then, a convolutional layer is used to generate the final prediction. The proposed model is evaluated for two real-world case studies in Washington, D.C. and Austin, TX, respectively, and the results show that for both case studies, STMGT significantly outperforms all the selected benchmark models, and the most important model component is the weather information. The proposed model can help micromobility operators develop optimal vehicle rebalancing schemes and guide cities to better manage dockless scooter-sharing operations.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2023Real-Time
ER  -

TY  - JOUR
AU  - Fang, Y.
AU  - Zhao, X.
AU  - Chen, Y.
AU  - Xiao, W.
AU  - De Rijke, M.
TI  - PF-HIN:Pre-Training for Heterogeneous Information Networks
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 8
SP  - 8372
EP  - 8385
DO  - 10.1109/TKDE.2022.3206597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139385999&doi=10.1109%2fTKDE.2022.3206597&partnerID=40&md5=676c38b733409cd7b95323c657ebdbba
AB  - In network representation learning we learn how to represent heterogeneous information networks in a low-dimensional space so as to facilitate effective search, classification, and prediction solutions. Previous network representation learning methods typically require sufficient task-specific labeled data to address domain-specific problems. The trained model usually cannot be transferred to out-of-domain datasets. We propose a self-supervised pre-training and fine-tuning framework, PF-HIN, to capture the features of a heterogeneous information network. Unlike traditional network representation learning models that have to train the entire model all over again for every downstream task and dataset, PF-HIN only needs to fine-tune the model and a small number of extra task-specific parameters, thus improving model efficiency and effectiveness. During pre-training, we first transform the neighborhood of a given node into a sequence. PF-HIN is pre-trained based on two self-supervised tasks, masked node modeling and adjacent node prediction. We adopt deep bi-directional transformer encoders to train the model, and leverage factorized embedding parameterization and cross-layer parameter sharing to reduce the parameters. In the fine-tuning stage, we choose four benchmark downstream tasks, i.e., link prediction, similarity search, node classification, and node clustering. PF-HIN outperforms state-of-the-art alternatives on each of these tasks, on four datasets.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:A期刊; FMS:B; 
LB  - Fang2023PF-HIN:Pre-Training
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Jiao, H.
AU  - Yang, Z.
TI  - AIS data-driven ship trajectory prediction modelling and analysis based on machine learning and deep learning methods
PY  - 2023
T2  - Transportation Research Part E: Logistics and Transportation Review
VL  - 175
C7  - 103152
DO  - 10.1016/j.tre.2023.103152
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161305189&doi=10.1016%2fj.tre.2023.103152&partnerID=40&md5=4bf2088136aa1d336ba5052083c1cdd8
AB  - Maritime transport faces new safety challenges in an increasingly complex traffic environment caused by large-scale and high-speed ships, particularly with the introduction of intelligent and autonomous ships. It is evident that Automatic Identification System (AIS) data-driven ship trajectory prediction can effectively aid in identifying abnormal ship behaviours and reducing maritime risks such as collision, stranding, and contact. Furthermore, trajectory prediction is widely recognised as one of the critical technologies for realising safe autonomous navigation. The prediction methods and their performance are the key factors for future safe and automatic shipping. Currently, ship trajectory prediction lacks the real performance measurement and analysis of different algorithms, including classical machine learning and emerging deep learning methods. This paper aims to systematically analyse the performance of ship trajectory prediction methods and pioneer experimental tests to reveal their advantages and disadvantages as well as fitness in different scenarios involving complicated systems. To do so, five machine learning methods (i.e., Kalman Filter (KF), Support Vector Progression (SVR), Back Propagation network (BP), Gaussian Process Regression (GPR), and Random Forest (RF)) and seven deep learning methods (i.e., Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gate Recurrent Unit (GRU), Bi-directional Long Short-Term Memory (Bi-LSTM), Sequence to Sequence (Seq2seq), Bi-directional Gate Recurrent Unit (Bi-GRU), and Transformer) are first extracted from the state-of-the-art literature review and then employed to implement the trajectory prediction and compare their prediction performance in the real world. Three AIS datasets are collected from the waters of representative traffic features, including a normal channel (i.e., the Chengshan Jiao Promontory), complex traffic (i.e., the Zhoushan Archipelago), and a port area (i.e., Caofeidian port). They are selected to test and analyse the performance of all twelve methods based on six evaluation indexes and explore the characteristics and effectiveness of the twelve trajectory prediction methods in detail. The experimental results provide a novel perspective, comparison, and benchmark for ship trajectory prediction research, which not only demonstrates the fitness of each method in different maritime traffic scenarios, but also makes significant contributions to maritime safety and autonomous shipping development. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 64
C2  - FMS:B; 
LB  - Li2023AIS
ER  -

TY  - JOUR
AU  - Korangi, K.
AU  - Mues, C.
AU  - Bravo, C.
TI  - A transformer-based model for default prediction in mid-cap corporate markets
PY  - 2023
T2  - European Journal of Operational Research
VL  - 308
IS  - 1
SP  - 306
EP  - 320
DO  - 10.1016/j.ejor.2022.10.032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143550150&doi=10.1016%2fj.ejor.2022.10.032&partnerID=40&md5=bf3c81e595f7896a3367391bc7df9610
AB  - In this paper, we study mid-cap companies, i.e. publicly traded companies with less than US$10 billion in market capitalisation. Using a large dataset of US mid-cap companies observed over 30 years, we look to predict the default probability term structure over the short to medium term and understand which data sources (i.e. fundamental, market or pricing data) contribute most to the default risk. Whereas existing methods typically require that data from different time periods are first aggregated and turned into cross-sectional features, we frame the problem as a multi-label panel data classification problem. To tackle it, we then employ transformer models, a state-of-the-art deep learning model emanating from the natural language processing domain. To make this approach suitable to the given credit risk setting, we use a loss function for multi-label classification, to deal with the term structure, and propose a multi-channel architecture with differential training that allows the model to use all input data efficiently. Our results show that the proposed deep learning architecture produces superior performance, resulting in a sizeable improvement in AUC (Area Under the receiver operating characteristic Curve) over traditional models. In order to interpret the model, we also demonstrate how to produce an importance ranking for the different data sources and their temporal relationships, using a Shapley approach for feature groups. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Korangi2023transformer-based
ER  -

TY  - JOUR
AU  - Jiang, Y.
AU  - Meng, R.
AU  - Huang, Y.
AU  - Lu, W.
AU  - Liu, J.
TI  - Generating keyphrases for readers: A controllable keyphrase generation framework
PY  - 2023
T2  - Journal of the Association for Information Science and Technology
VL  - 74
IS  - 7
SP  - 759
EP  - 774
DO  - 10.1002/asi.24749
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152078043&doi=10.1002%2fasi.24749&partnerID=40&md5=01cd8026a771549625906f2186732770
AB  - With the wide application of keyphrases in many Information Retrieval (IR) and Natural Language Processing (NLP) tasks, automatic keyphrase prediction has been emerging. However, these statistically important phrases are contributing increasingly less to the related tasks because the end-to-end learning mechanism enables models to learn the important semantic information of the text directly. Similarly, keyphrases are of little help for readers to quickly grasp the paper's main idea because the relationship between the keyphrase and the paper is not explicit to readers. Therefore, we propose to generate keyphrases with specific functions for readers to bridge the semantic gap between them and the information producers, and verify the effectiveness of the keyphrase function for assisting users’ comprehension with a user experiment. A controllable keyphrase generation framework (the CKPG) that uses the keyphrase function as a control code to generate categorized keyphrases is proposed and implemented based on Transformer, BART, and T5, respectively. For the Computer Science domain, the Macro-avgs of (Formula presented.), (Formula presented.), and (Formula presented.) on the Paper with Code dataset are up to 0.680, 0.535, and 0.558, respectively. Our experimental results indicate the effectiveness of the CKPG models. © 2023 Association for Information Science and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:A; 
LB  - Jiang2023Generating
ER  -

TY  - JOUR
AU  - Rao, Z.
AU  - Wang, H.
AU  - Chen, L.
AU  - Lian, Y.
AU  - Zhong, Y.
AU  - Liu, Z.
AU  - Cai, Y.
TI  - Monocular Road Scene Bird's Eye View Prediction via Big Kernel-Size Encoder and Spatial-Channel Transform Module
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 7
SP  - 7138
EP  - 7148
DO  - 10.1109/TITS.2023.3253554
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151547733&doi=10.1109%2fTITS.2023.3253554&partnerID=40&md5=21bfeb21344c9ba7692b071db485ee9d
AB  - A detailed representation of the surrounding road scene is crucial for an autonomous driving system. sethlcolor yellow The camera-based Bird's Eye View map has been a popular solution to present the surrounding information, due to its low cost and rich spatial context information. Most of the existing methods predict the BEV map based on the depth-estimation or the trivial homography method, which may cause the error propagation and the absence of content. To overcome these drawbacks, we propose a novel end-to-end framework that employs the front monocular image to predict the road layout and vehicle occupancy. In particular, to capture the long-range feature, we redesign a CNN encoder with a large kernel size to extract the image features. For reducing the big difference between the front image features and the top-down features, we propose a novel Spatial-Channel projection module to convert the front map into the top-down space. Additionally, concerning the correlation between front view and top-down view, we propose the Dual Cross-view Transformer module to refine the top-down view feature maps and strengthen the transformation. Extensive evaluations on the KITTI and Argoverse datasets present that the proposed model achieves the state-of-the-art results for both datasets. Furthermore, the proposed model runs in 37 FPS on a single GPU, demonstrating the generation of a real-time BEV map. The code will be published at https://github.com/raozhongyu/BEV-LKA.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Rao2023Monocular
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zheng, X.
AU  - Sun, K.
AU  - Liu, W.
AU  - Zhang, Y.
TI  - Self-supervised vision transformer-based few-shot learning for facial expression recognition
PY  - 2023
T2  - Information Sciences
VL  - 634
SP  - 206
EP  - 226
DO  - 10.1016/j.ins.2023.03.105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150792082&doi=10.1016%2fj.ins.2023.03.105&partnerID=40&md5=dfe0f6b2a1670261a57bd9211daefc6e
AB  - Facial expression recognition (FER) is embedded in many real-world human-computer interaction tasks, such as online learning, depression recognition and remote diagnosis. However, FER is often hindered by privacy concerns and low recognition accuracy due to inadequate data transfer restrictions on public clouds, insufficient quantities of effective labeled samples and class imbalance. To address the above challenges, we have developed an automatic privacy-preserving learning state recognition system for supervising the quality of online teaching with the cooperation of edge servers and cloud servers to reduce the risk of privacy exposure. In particular, we propose few-shot facial expression recognition with a self-supervised vision transformer (SSF-ViT) by integrating self-supervised learning (SSL) and few-shot learning (FSL) to train a deep learning model with fewer labeled samples. Specifically, a vision transformer (ViT) is jointly pretrained with four self-supervised pretext tasks, including image denoising and reconstruction, image rotation prediction, jigsaw puzzle and masked patch prediction, to obtain a pretrained ViT encoder. Then, the pretrained ViT encoder is used on a lab-controlled labeled FER dataset to extract the spatiotemporal features and implement the FER task to fine-tune the parameters. Finally, we construct prototypes to verify the few-shot classification method for specific expression recognition. Support and query sets are divided in the wild FER dataset, and few-shot classification episodes are constructed. The fine-tuned ViT encoder is used as the feature extractor to build the prototype for each support set category, and the expression classification results are obtained by computing the Euclidean distance between the query samples and the prototypes. The extensive experimental results show that SSF-ViT can achieve recognition accuracies of 74.95%, 66.04%, 63.69% and 90.98% on the FER2013, AffectNet, SFEW 2.0 and RAF-DB datasets, respectively. In addition, SSF-ViT can improve the recognition performance of specific expression categories on these datasets. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2023Self-supervised
ER  -

TY  - JOUR
AU  - Shi, C.
AU  - Cai, B.
AU  - Zhao, Y.
AU  - Gao, L.
AU  - Sood, K.
AU  - Xiang, Y.
TI  - CoSS: Leveraging Statement Semantics for Code Summarization
PY  - 2023
T2  - IEEE Transactions on Software Engineering
VL  - 49
IS  - 6
SP  - 3472
EP  - 3486
DO  - 10.1109/TSE.2023.3256362
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151331220&doi=10.1109%2fTSE.2023.3256362&partnerID=40&md5=f688da43a2e74f73561d98236d57f320
AB  - Automated code summarization tools allow generating descriptions for code snippets in natural language, which benefits software development and maintenance. Recent studies demonstrate that the quality of generated summaries can be improved by using additional code representations beyond token sequences. The majority of contemporary approaches mainly focus on extracting code syntactic and structural information from abstract syntax trees (ASTs). However, from the view of macro-structures, it is challenging to identify and capture semantically meaningful features due to fine-grained syntactic nodes involved in ASTs. To fill this gap, we investigate how to learn more code semantics and control flow features from the perspective of code statements. Accordingly, we propose a novel model entitled CoSS for code summarization. CoSS adopts a Transformer-based encoder and a graph attention network-based encoder to capture token-level and statement-level semantics from code token sequence and control flow graph, respectively. Then, after receiving two-level embeddings from encoders, a joint decoder with a multi-head attention mechanism predicts output sequences verbatim. Performance evaluations on Java, Python, and Solidity datasets validate that CoSS outperforms nine state-of-the-art (SOTA) neural code summarization models in effectiveness and is competitive in execution efficiency. Further, the ablation study reveals the contribution of each model component.  © 1976-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:A期刊; FMS:B; 
LB  - Shi2023CoSS
ER  -

TY  - JOUR
AU  - Gao, K.
AU  - Li, X.
AU  - Chen, B.
AU  - Hu, L.
AU  - Liu, J.
AU  - Du, R.
AU  - Li, Y.
TI  - Dual Transformer Based Prediction for Lane Change Intentions and Trajectories in Mixed Traffic Environment
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 6
SP  - 6203
EP  - 6216
DO  - 10.1109/TITS.2023.3248842
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149836203&doi=10.1109%2fTITS.2023.3248842&partnerID=40&md5=396e9d843bf4169358237730e2244516
AB  - In a mixed traffic environment of human and autonomous driving, it is crucial for an autonomous vehicle to predict the lane change intentions and trajectories of vehicles that pose a risk to it. However, due to the uncertainty of human intentions, accurately predicting lane change intentions and trajectories is a great challenge. Therefore, this paper aims to establish the connection between intentions and trajectories and propose a dual Transformer model for the target vehicle. The dual Transformer model contains a lane change intention prediction model and a trajectory prediction model. The lane change intention prediction model is able to extract social correlations in terms of vehicle states and outputs an intention probability vector. The trajectory prediction model fuses the intention probability vector, which enables it to obtain prior knowledge. For the intention prediction model, the accuracy can be improved by designing the multi-head attention. For the trajectory prediction model, the performance can be optimized by incorporating intention probability vectors and adding the LSTM. Verified on NGSIM and highD datasets, the experimental results show that this model has encouraging accuracy. Compared with the model without intention probability vectors, the impact of the model on NGSIM dataset and highD dataset in RMSE is improved by 57.27% and 58.70% respectively. Compared with two existed models, evaluation metrics of the intention prediction can be improved by 7.40-10.09% on NGSIM dataset and 2.17-2.69% on highD dataset within advanced prediction time 1s. This method provides the insights for designing advanced perceptual systems for autonomous vehicles.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 56
C2  - CCF:B期刊; FMS:B; 
LB  - Gao2023Dual
ER  -

TY  - JOUR
AU  - Moulouel, K.
AU  - Chibani, A.
AU  - Amirat, Y.
TI  - Ontology-based hybrid commonsense reasoning framework for handling context abnormalities in uncertain and partially observable environments
PY  - 2023
T2  - Information Sciences
VL  - 631
SP  - 468
EP  - 486
DO  - 10.1016/j.ins.2023.02.078
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150367886&doi=10.1016%2fj.ins.2023.02.078&partnerID=40&md5=b983e69d4c2b5db89e9f77a12288602e
AB  - Ambient intelligence (AmI) systems aim to provide users with context-aware assistance services intended to improve the quality of their lives in terms of autonomy, safety, and well-being. Taking the uncertainty and partial observability of these environments into account is of major importance for context recognition and, more specifically, to detect and solve context abnormalities such as those related to the user's behavior or those related to context attribute prediction. In this paper, an ontology-based framework integrating machine learning and probabilistic planning within commonsense reasoning is proposed to recognize the user's context and abnormalities associated with it. The reasoning is performed using event calculus in answer set programming (ECASP); ECASP allows for abductive and temporal reasoning, which results in an eXplainable AI (XAI) approach. A context ontology is proposed to axiomatize the reasoning and introduce the notion of probabilistic fluents into the EC formalism in order to perform probabilistic reasoning. The reasoning incorporates probabilistic planning based on a partially observable Markov decision process (POMDP) to solve knowledge incompleteness. To evaluate the proposed framework, real-life scenarios, based on the Orange4Home and SIMADL public datasets are implemented and discussed. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Moulouel2023Ontology-based
ER  -

TY  - JOUR
AU  - Yu, L.
AU  - Sun, L.
AU  - Du, B.
AU  - Liu, C.
AU  - Lv, W.
AU  - Xiong, H.
TI  - Heterogeneous Graph Representation Learning With Relation Awareness
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 6
SP  - 5935
EP  - 5947
DO  - 10.1109/TKDE.2022.3160208
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126648622&doi=10.1109%2fTKDE.2022.3160208&partnerID=40&md5=4a6132ea03543206c07e430305230b02
AB  - Representation learning on heterogeneous graphs aims to obtain meaningful node representations to facilitate various downstream tasks, such as node classification and link prediction. Existing heterogeneous graph learning methods are primarily developed by following the propagation mechanism of node representations. There are few efforts on studying the role of relations for improving the learning of more fine-grained node representations. Indeed, it is important to collaboratively learn the semantic representations of relations and discern node representations with respect to different relation types. To this end, in this paper, we propose a Relation-aware Heterogeneous Graph Neural Network, namely R-HGNN, to learn node representations on heterogeneous graphs at a fine-grained level by considering relation-aware characteristics. Specifically, a dedicated graph convolution component is first designed to learn unique node representations from each relation-specific graph separately. Then, a cross-relation message passing module is developed to improve the interactions of node representations across different relations. Also, the relation representations are learned in a layer-wise manner to capture relation semantics, which are used to guide the node representation learning process. Moreover, a semantic fusing module is presented to aggregate relation-aware node representations into a compact representation with the learned relation representations. Finally, we conduct extensive experiments on a variety of graph learning tasks, and experimental results demonstrate that our approach consistently outperforms existing methods among all the tasks. © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - CCF:A期刊; FMS:B; 
LB  - Yu2023Heterogeneous
ER  -

TY  - JOUR
AU  - Lei, Y.
AU  - Li, Y.
TI  - A novel scheme of domain transfer in document-level cross-domain sentiment classification
PY  - 2023
T2  - Journal of Information Science
VL  - 49
IS  - 3
SP  - 567
EP  - 581
DO  - 10.1177/01655515211012329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105788933&doi=10.1177%2f01655515211012329&partnerID=40&md5=25f77d32ba735227de9b2c10dc2c6277
AB  - The sentiment classification aims to learn sentiment features from the annotated corpus and automatically predict the sentiment polarity of new sentiment text. However, people have different ways of expressing feelings in different domains. Thus, there are important differences in the characteristics of sentimental distribution across different domains. At the same time, in certain specific domains, due to the high cost of corpus collection, there is no annotated corpus available for the classification of sentiment. Therefore, it is necessary to leverage or reuse existing annotated corpus for training. In this article, we proposed a new algorithm for extracting central sentiment sentences in product reviews, and improved the pre-trained language model Bidirectional Encoder Representations from Transformers (BERT) to achieve the domain transfer for cross-domain sentiment classification. We used various pre-training language models to prove the effectiveness of the newly proposed joint algorithm for text-ranking and emotional words extraction, and utilised Amazon product reviews data set to demonstrate the effectiveness of our proposed domain-transfer framework. The experimental results of 12 different cross-domain pairs showed that the new cross-domain classification method was significantly better than several popular cross-domain sentiment classification methods. © The Author(s) 2021.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Lei2023novel
ER  -

TY  - JOUR
AU  - Xia, L.
AU  - Huang, C.
AU  - Xu, Y.
AU  - Pei, J.
TI  - Multi-Behavior Sequential Recommendation With Temporal Graph Transformer
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 6
SP  - 6099
EP  - 6112
DO  - 10.1109/TKDE.2022.3175094
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132509784&doi=10.1109%2fTKDE.2022.3175094&partnerID=40&md5=c41be6a89b65aa8708a1b8dc7e33c288
AB  - Modeling time-evolving preferences of users with their sequential item interactions, has attracted increasing attention in many online applications. Hence, sequential recommender systems have been developed to learn the dynamic user interests from the historical interactions for suggesting items. However, the interaction pattern encoding functions in most existing sequential recommender systems have focused on single type of user-item interactions. In many real-life online platforms, user-item interactive behaviors are often multi-typed (e.g., click, add-to-favorite, purchase) with complex cross-type behavior inter-dependencies. Learning from informative representations of users and items based on their multi-typed interaction data, is of great importance to accurately characterize the time-evolving user preference. In this work, we tackle the dynamic user-item relation learning with the awareness of multi-behavior interactive patterns. Towards this end, we propose a new Temporal Graph Transformer (TGT) recommendation framework to jointly capture dynamic short-term and long-range user-item interactive patterns, by exploring the evolving correlations across different types of behaviors. The new TGT method endows the sequential recommendation architecture to distill dedicated knowledge for type-specific behavior relational context and the implicit behavior dependencies. Experiments on the real-world datasets indicate that our method TGT consistently outperforms various state-of-the-art recommendation methods. Our model implementation codes are available at https://github.com/akaxlh/TGT.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:A期刊; FMS:B; 
LB  - Xia2023Multi-Behavior
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Wang, S.
AU  - Lin, M.
AU  - Xu, Z.
AU  - Guo, W.
TI  - Learning speaker-independent multimodal representation for sentiment analysis
PY  - 2023
T2  - Information Sciences
VL  - 628
SP  - 208
EP  - 225
DO  - 10.1016/j.ins.2023.01.116
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147197890&doi=10.1016%2fj.ins.2023.01.116&partnerID=40&md5=bfdbc53d355943644d9db6a719c5d904
AB  - Multimodal sentiment analysis is an actively growing research area that utilizes language, acoustic and visual signals to predict sentiment inclination. Compared to language, acoustic and visual features carry a more evident personal style which may degrade the model generalization capability. The issue will be exacerbated in a speaker-independent setting, where the model will encounter samples from unseen speakers during the testing stage. To mitigate personal style's impact, we propose a framework named SIMR for learning speaker-independent multimodal representation. This framework separates the nonverbal inputs into style encoding and content representation with the aid of informative cross-modal correlations. Besides, in terms of integrating cross-modal complementary information, the classical transformer-based approaches are inherently inclined to discover compatible cross-modal interactions but ignore incompatible ones. In contrast, we suggest simultaneously locating both through an enhanced cross-modal transformer module. Experimental results show that the proposed model achieves state-of-the-art performance on several datasets. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2023Learning
ER  -

TY  - JOUR
AU  - Ma, M.
AU  - Ren, P.
AU  - Chen, Z.
AU  - Ren, Z.
AU  - Liang, H.
AU  - Ma, J.
AU  - De Rijke, M.
TI  - Improving Transformer-based Sequential Recommenders through Preference Editing
PY  - 2023
T2  - ACM Transactions on Information Systems
VL  - 41
IS  - 3
C7  - 71
DO  - 10.1145/3564282
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159360887&doi=10.1145%2f3564282&partnerID=40&md5=00313813964ae8e974cccefd8919f954
AB  - One of the key challenges in sequential recommendation is how to extract and represent user preferences. Traditional methods rely solely on predicting the next item. But user behavior may be driven by complex preferences. Therefore, these methods cannot make accurate recommendations when the available information user behavior is limited. To explore multiple user preferences, we propose a transformer-based sequential recommendation model, named MrTransformer (Multi-preference Transformer). For training MrTransformer, we devise a preference-editing-based self-supervised learning (SSL) mechanism that explores extra supervision signals based on relations with other sequences. The idea is to force the sequential recommendation model to discriminate between common and unique preferences in different sequences of interactions. By doing so, the sequential recommendation model is able to disentangle user preferences into multiple independent preference representations so as to improve user preference extraction and representation.We carry out extensive experiments on five benchmark datasets. MrTransformer with preference editing significantly outperforms state-of-the-art sequential recommendation methods in terms of Recall, MRR, and NDCG. We find that long sequences of interactions from which user preferences are harder to extract and represent benefit most from preference editing.  © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:A期刊; FMS:B; 
LB  - Ma2023Improving
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Zhang, Y.
AU  - Li, X.
AU  - Zhang, Y.
AU  - Yin, B.
TI  - Hypergraph Transformer Neural Networks
PY  - 2023
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 17
IS  - 5
C7  - 63
DO  - 10.1145/3565028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153856470&doi=10.1145%2f3565028&partnerID=40&md5=f55f2a30b340243f4d1697253e15938e
AB  - Graph neural networks (GNNs) have been widely used for graph structure learning and achieved excellent performance in tasks such as node classification and link prediction. Real-world graph networks imply complex and various semantic information and are often referred to as heterogeneous information networks (HINs). Previous GNNs have laboriously modeled heterogeneous graph networks with pairwise relations, in which the semantic information representation for learning is incomplete and severely hinders node embedded learning. Therefore, the conventional graph structure cannot satisfy the demand for information discovery in HINs. In this article, we propose an end-to-end hypergraph transformer neural network (HGTN) that exploits the communication abilities between different types of nodes and hyperedges to learn higher-order relations and discover semantic information. Specifically, attention mechanisms weigh the importance of semantic information hidden in original HINs to generate useful meta-paths. Meanwhile, our method develops a multi-scale attention module to aggregate node embeddings in higher-order neighborhoods. We evaluate the proposed model with node classification tasks on six datasets: DBLP, ACM, IBDM, Reuters, STUD-BJUT, and Citeseer. Experiments on a large number of benchmarks show the advantages of HGTN.  © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; FMS:B; 
LB  - Li2023Hypergraph
ER  -

TY  - JOUR
AU  - Borchert, P.
AU  - Coussement, K.
AU  - De Caigny, A.
AU  - De Weerdt, J.
TI  - Extending business failure prediction models with textual website content using deep learning
PY  - 2023
T2  - European Journal of Operational Research
VL  - 306
IS  - 1
SP  - 348
EP  - 357
DO  - 10.1016/j.ejor.2022.06.060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134723297&doi=10.1016%2fj.ejor.2022.06.060&partnerID=40&md5=250b32572ff3788bb3de6b809ddc99e8
AB  - Business failure prediction (BFP) is an important instrument in assessing the risk of corporate failure. While a large body of research has focused on BFP, recent research in operations research and analytics acknowledges the beneficial effect of incorporating textual data for predictive modelling. However, extant BFP research that incorporates textual company information is very scarce. Based on a dataset containing 13,571 European companies provided by the largest European data aggregator, this study investigates the added value of extending traditional BFP models with textual website content. We further benchmark various feature extraction techniques in natural language processing (i.e. the vector-space approach, neural networks-based approaches and transformers) and assess the best way of representing and integrating textual website features for BFP modelling. The results confirm that including textual website data improves BFP predictive performance, and that textual features extracted by transformers add the most value to the BFP models in this benchmark setting. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Borchert2023Extending
ER  -

TY  - JOUR
AU  - Xiong, J.
AU  - Yu, L.
AU  - Niu, X.
AU  - Leng, Y.
TI  - XRR: Extreme multi-label text classification with candidate retrieving and deep ranking
PY  - 2023
T2  - Information Sciences
VL  - 622
SP  - 115
EP  - 132
DO  - 10.1016/j.ins.2022.11.158
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145556608&doi=10.1016%2fj.ins.2022.11.158&partnerID=40&md5=8b0396990d98095b3739121c47d76747
AB  - Extreme Multi-label Text Classification (XMTC) is a key task of finding the most relevant labels from a large label set for a document. Although some deep learning-based methods have shown great success in XMTC, they still suffer from the following drawbacks. First, although several methods have improved the precision by clustering labels and combining several sub-models to train and predict for one dataset, they were not ideal in terms of computational efficiency. Second, most of those methods need a low dimensional bottleneck layer before the output layer to compress the feature representations to fit the GPU memory, which results in information loss of original features. In this paper, we proposed a novel two-stage XMTC framework with candidate Retrieving and deep Ranking (XRR) to address those drawbacks. In the retrieving stage, we designed two retrieval strategies, including an aligning Point Mutual Information (aPMI) method, and a Unified Label-Semantic Embedding (ULSE) method, to extract hundreds of candidates from massive labels. In the ranking stage, we presented a deep ranking model using a pre-trained transformer to distinguish the true labels from candidates. Extensive experiments show that XRR outperforms the state-of-the-art methods on five widely used multi-label datasets. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; FMS:B; 
LB  - Xiong2023XRR
ER  -

TY  - JOUR
AU  - Huo, G.
AU  - Zhang, Y.
AU  - Wang, B.
AU  - Gao, J.
AU  - Hu, Y.
AU  - Yin, B.
TI  - Hierarchical Spatio-Temporal Graph Convolutional Networks and Transformer Network for Traffic Flow Forecasting
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 3855
EP  - 3867
DO  - 10.1109/TITS.2023.3234512
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147217824&doi=10.1109%2fTITS.2023.3234512&partnerID=40&md5=e85eb12ef4f4506bd1e2e3088c2643b8
AB  - Graph convolutional networks (GCN) have been applied in the traffic flow forecasting tasks with the graph capability in describing the irregular topology structures of road networks. However, GCN based traffic flow forecasting methods often fail to simultaneously capture the short-term and long-term temporal relations carried by the traffic flow data, and also suffer the over-smoothing problem. To overcome the problems, we propose a hierarchical traffic flow forecasting network by merging newly designed the long-term temporal Transformer network (LTT) and the spatio-temporal graph convolutional networks (STGC). Specifically, LTT aims to learn the long-term temporal relations among the traffic flow data, while the STGC module aims to capture the short-term temporal relations and spatial relations among the traffic flow data, respectively, via cascading between the one-dimensional convolution and the graph convolution. In addition, an attention fusion mechanism is proposed to combine the long-term with the short-term temporal relations as the input of the graph convolution layer in STGC, in order to mitigate the over-smoothing problem of GCN. Experimental results on three public traffic flow datasets prove the effectiveness and robustness of the proposed method.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - CCF:B期刊; FMS:B; 
LB  - Huo2023Hierarchical
ER  -

TY  - JOUR
AU  - Ramana, K.
AU  - Srivastava, G.
AU  - Kumar, M.R.
AU  - Gadekallu, T.R.
AU  - Lin, J.C.-W.
AU  - Alazab, M.
AU  - Iwendi, C.
TI  - A Vision Transformer Approach for Traffic Congestion Prediction in Urban Areas
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 3922
EP  - 3934
DO  - 10.1109/TITS.2022.3233801
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147207357&doi=10.1109%2fTITS.2022.3233801&partnerID=40&md5=94be37b2d56c9d28d4b3a8cee1695e22
AB  - Traffic problems continue to deteriorate because of increasing population in urban areas that rely on many modes of transportation, the transportation infrastructure has achieved considerable strides in the last several decades. This has led to an increase in congestion control difficulties, which directly affect citizens through air pollution, fuel consumption, traffic law breaches, noise pollution, accidents, and loss of time. Traffic prediction is an essential aspect of an intelligent transportation system in smart cities because it helps reduce overall traffic congestion. This article aims to design and enforce a traffic prediction scheme that is efficient and accurate in forecasting traffic flow. Available traffic flow prediction methods are still unsuitable for real-world applications. This fact motivated us to work on a traffic flow forecasting issue using Vision Transformers (VTs). In this work, VTs were used in conjunction with Convolutional neural networks (CNN) to predict traffic congestion in urban spaces on a city-wide scale. In our proposed architecture, a traffic image is fed to a CNN, which generates feature maps. These feature maps are then fed to the VT, which employs the dual techniques of tokenization and projection. Tokenization is used to convert features into tokens containing Vision information, which are then sent to projection, where they are transformed into feature maps and ultimately delivered to LSTM. The experimental results demonstrate that the vision transformer prediction method based on Spatio-temporal characteristics is an excellent way of predicting traffic flow, particularly during anomalous traffic situations. The proposed technology surpasses traditional methods in terms of precision, accuracy and recall and aids in energy conservation. Through rerouting, the proposed work will benefit travellers and reduce fuel use.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 54
C2  - CCF:B期刊; FMS:B; 
LB  - Ramana2023Vision
ER  -

TY  - JOUR
AU  - Yang, C.
AU  - Pei, Z.
TI  - Long-Short Term Spatio-Temporal Aggregation for Trajectory Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 4114
EP  - 4126
DO  - 10.1109/TITS.2023.3234962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147298679&doi=10.1109%2fTITS.2023.3234962&partnerID=40&md5=59ee2340b46a1ad25d6a5e09e7f8ac22
AB  - Pedestrian trajectory prediction in crowd scenes plays a significant role in intelligent transportation systems. The main challenges are manifested in learning motion patterns and addressing future uncertainty. Typically, trajectory prediction is considered in two dimensions, including temporal dynamics modeling and social interactions capturing. For temporal dependencies, although existing models based on recurrent neural networks (RNNs) or convolutional neural networks (CNNs) achieve high performance on short-term prediction, they still suffer from limited scalability for long sequences. For social interactions, previous graph-based methods only consider fixed features but ignore dynamic interactions between pedestrians. Considering that the transformer network has a strong capability of capturing spatial and long-term temporal dynamics, we propose Long-Short Term Spatio-Temporal Aggregation (LSSTA) network for human trajectory prediction. First, a modern variant of graph neural networks, named spatial encoder, is presented to characterize spatial interactions between pedestrians. Second, LSSTA utilizes a transformer network to handle long-term temporal dependencies and aggregates the spatial and temporal features with a temporal convolution network (TCN). Thus, TCN is combined with the transformer to form a long-short term temporal dependency encoder. Additionally, multi-modal prediction is an efficient way to address future uncertainty. Existing auto-encoder modules are extended with static scene information and future ground truth for multi-modal trajectory prediction. Experimental results on complex scenes demonstrate the superior performance of our method in comparison to existing approaches.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2023Long-Short
ER  -

TY  - JOUR
AU  - Kothari, P.
AU  - Alahi, A.
TI  - Safety-Compliant Generative Adversarial Networks for Human Trajectory Forecasting
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 4251
EP  - 4261
DO  - 10.1109/TITS.2022.3233906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147260526&doi=10.1109%2fTITS.2022.3233906&partnerID=40&md5=a7dc9d6f3e73cedf432b05bd4d0bd63c
AB  - Human trajectory forecasting in crowds presents the challenges of modelling social interactions and outputting collision-free multimodal distribution. Following the success of Social Generative Adversarial Networks (SGAN), recent works propose various GAN-based designs to better model human motion in crowds. Despite superior performance in reducing distance-based metrics, current networks fail to output socially acceptable trajectories, as evidenced by high collisions in model predictions. To counter this, we introduce SGANv2: an improved safety-compliant SGAN architecture equipped with spatio-temporal interaction modelling and a transformer-based discriminator. The spatio-temporal modelling ability helps to learn the human social interactions better while the transformer-based discriminator design improves temporal sequence modelling. Additionally, SGANv2 utilizes the learned discriminator even at test-time via a collaborative sampling strategy that not only refines the colliding trajectories but also prevents mode collapse, a common phenomenon in GAN training. Through extensive experimentation on multiple real-world and synthetic datasets, we demonstrate the efficacy of SGANv2 to provide socially-compliant multimodal trajectories.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; FMS:B; 
LB  - Kothari2023Safety-Compliant
ER  -

TY  - JOUR
AU  - Han, C.
AU  - Ma, T.
AU  - Gu, L.
AU  - Cao, J.
AU  - Shi, X.
AU  - Huang, W.
AU  - Tong, Z.
TI  - Asphalt Pavement Health Prediction Based on Improved Transformer Network
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 4482
EP  - 4493
DO  - 10.1109/TITS.2022.3229326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147208715&doi=10.1109%2fTITS.2022.3229326&partnerID=40&md5=bced7dc4381d53610d58cd7a5a82f320
AB  - Neural network-based models have been implemented to predict various health indicators of asphalt pavement using pavement historical detection data. Unfortunately, their accuracy and reliability are not acceptable owing to their shallow architecture. To solve the issue, this study proposed an improved Transformer network to predict asphalt pavement health, called the Transformer with forward and reversed time series (Transformer FRTS). In terms of the input data, Transformer FRTS uses a new data form, so-called the random difference time series, to reduce the time dependency of the network prediction. In terms of the network architecture, the proposed network uses its encoder and decoder to obtain the data association from the forward and reverse time series. In addition, Transformer FRTS uses a post-processing decision criterion to improve the accuracy and reliability of prediction. The numerical experiment using the detection data from RIOHTrack full-scale track demonstrates that the proposed network has state-of-the-practice performance in asphalt pavement health prediction.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:B期刊; FMS:B; 
LB  - Han2023Asphalt
ER  -

TY  - JOUR
AU  - Cui, J.
AU  - Chen, Z.
AU  - Zhou, A.
AU  - Wang, J.
AU  - Zhang, W.
TI  - Fine-Grained Interaction Modeling with Multi-Relational Transformer for Knowledge Tracing
PY  - 2023
T2  - ACM Transactions on Information Systems
VL  - 41
IS  - 4
C7  - 104
DO  - 10.1145/3580595
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172418631&doi=10.1145%2f3580595&partnerID=40&md5=eed805af088566ee93a38905a1111d14
AB  - Knowledge tracing, the goal of which is predicting students' future performance given their past question response sequences to trace their knowledge states, is pivotal for computer-Aided education and intelligent tutoring systems. Although many technical efforts have been devoted to modeling students based on their question-response sequences, fine-grained interaction modeling between question-response pairs within each sequence is underexplored. This causes question-response representations less contextualized and further limits student modeling. To address this issue, we first conduct a data analysis and reveal the existence of complex cross effects between different question-response pairs within a sequence. Consequently, we propose MRT-KT, a multi-relational transformer for knowledge tracing, to enable fine-grained interaction modeling between question-response pairs. It introduces a novel relation encoding scheme based on knowledge concepts and student performance. Comprehensive experimental results show that MRT-KT outperforms state-of-The-Art knowledge tracing methods on four widely-used datasets, validating the effectiveness of considering fine-grained interaction for knowledge tracing.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:A期刊; FMS:B; 
LB  - Cui2023Fine-Grained
ER  -

TY  - JOUR
AU  - Leonhardt, J.
AU  - Rudra, K.
AU  - Anand, A.
TI  - Extractive Explanations for Interpretable Text Ranking
PY  - 2023
T2  - ACM Transactions on Information Systems
VL  - 41
IS  - 4
C7  - 88
DO  - 10.1145/3576924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172691686&doi=10.1145%2f3576924&partnerID=40&md5=63fc2be6478748a262f4465202234e36
AB  - Neural document ranking models perform impressively well due to superior language understanding gained from pre-Training tasks. However, due to their complexity and large number of parameters these (typically transformer-based) models are often non-interpretable in that ranking decisions can not be clearly attributed to specific parts of the input documents.In this article, we propose ranking models that are inherently interpretable by generating explanations as a by-product of the prediction decision. We introduce the Select-And-Rank paradigm for document ranking, where we first output an explanation as a selected subset of sentences in a document. Thereafter, we solely use the explanation or selection to make the prediction, making explanations first-class citizens in the ranking process. Technically, we treat sentence selection as a latent variable trained jointly with the ranker from the final output. To that end, we propose an end-To-end training technique for Select-And-Rank models utilizing reparameterizable subset sampling using the Gumbel-max trick.We conduct extensive experiments to demonstrate that our approach is competitive to state-of-The-Art methods. Our approach is broadly applicable to numerous ranking tasks and furthers the goal of building models that are interpretable by design. Finally, we present real-world applications that benefit from our sentence selection method. © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:A期刊; FMS:B; 
LB  - Leonhardt2023Extractive
ER  -

TY  - JOUR
AU  - Abuhassan, M.
AU  - Anwar, T.
AU  - Fuller-Tyszkiewicz, M.
AU  - Jarman, H.K.
AU  - Shatte, A.
AU  - Liu, C.
AU  - Sukunesan, S.
TI  - Classification of Twitter users with eating disorder engagement: Learning from the biographies
PY  - 2023
T2  - Computers in Human Behavior
VL  - 140
C7  - 107519
DO  - 10.1016/j.chb.2022.107519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142339269&doi=10.1016%2fj.chb.2022.107519&partnerID=40&md5=0691a995b87f851466a5a8798a99b68b
AB  - Individuals with an Eating Disorder (ED) are typically reluctant to seek help via traditional means (e.g., psychologists). However, recent evidence suggests that many individuals seek assistance via social media for weight and diet related concerns. Sophisticated approaches are needed to better distinguish those who may be in need of help for an ED from those who are simply commenting on ED in online social environments. In order to facilitate effective communication between individuals with or at-risk of an ED and healthcare professionals, this research exploits a deep learning model to differentiate the users with ED engagement (e.g., ED sufferers, healthcare professionals or communicators) over social media. For this purpose, a collection of Twitter data is compiled using Twitter application programming interface (API) on the Australian Research Data Commons (ARDC) Nectar research cloud. After collecting 1,400,000 Twitter biographies in total, a subset of 4000 biographies are annotated manually. This annotation enables the differentiation of users engaged with ED-focused language on social media into five categories: ED-user, healthcare professional, communicator, healthcare professional-communicator, and other. Based on these annotated categories, a predictive deep learning model based on bidirectional encoder representations from transformers (BERT) and long short-term memory (LSTM) is developed. The model achieves an F1 score of 98.19% and an accuracy of 98.37%. It demonstrates the viability of detecting the individuals with possible ED risk and distinguishes them from other categories using their biography data. We further conducted a network analysis for investigating the communication network between these categories. Our analysis shows that ED-users are more secretive and self-protective, whereas the healthcare professionals and communicators frequently interact with each other and a wide range of other people. To the best of our knowledge, our research is the first of its kind for identifying the different user categories engaged with ED-focused communications on social media. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Abuhassan2023Classification
ER  -

TY  - JOUR
AU  - Jiang, X.
AU  - Yu, Z.
AU  - Hai, C.
AU  - Liu, H.
AU  - Wu, X.
AU  - Ward, T.
TI  - DNformer: Temporal Link Prediction with Transfer Learning in Dynamic Networks
PY  - 2023
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 17
IS  - 3
C7  - 3551892
DO  - 10.1145/3551892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152615977&doi=10.1145%2f3551892&partnerID=40&md5=930627c1f6ef52369dc968fe7811967a
AB  - Temporal link prediction (TLP) is among the most important graph learning tasks, capable of predicting dynamic, time-varying links within networks. The key problem of TLP is how to explore potential link-evolving tendency from the increasing number of links over time. There exist three major challenges toward solving this problem: temporal nonlinear sparsity, weak serial correlation, and discontinuous structural dynamics. In this article, we propose a novel transfer learning model, called DNformer, to predict temporal link sequence in dynamic networks. The structural dynamic evolution is sequenced into consecutive links one by one over time to inhibit temporal nonlinear sparsity. The self-attention of the model is used to capture the serial correlation between the input and output link sequences. Moreover, our structural encoding is designed to obtain changing structures from the consecutive links and to learn the mapping between link sequences. This structural encoding consists of two parts: the node clustering encoding of each link and the link similarity encoding between links. These encodings enable the model to perceive the importance and correlation of links. Furthermore, we introduce a measurement of structural similarity in the loss function for the structural differences of link sequences. The experimental results demonstrate that our model outperforms other state-of-the-art TLP methods such as Transformer, TGAT, and EvolveGCN. It achieves the three highest AUC and four highest precision scores in five different representative dynamic networks problems.  © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Jiang2023DNformer
ER  -

TY  - JOUR
AU  - Xu, M.
AU  - Di, Y.
AU  - Yang, H.
AU  - Chen, X.
AU  - Zhu, Z.
TI  - Multi-task supply-demand prediction and reliability analysis for docked bike-sharing systems via transformer-encoder-based neural processes
PY  - 2023
T2  - Transportation Research Part C: Emerging Technologies
VL  - 147
C7  - 104015
DO  - 10.1016/j.trc.2023.104015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146281201&doi=10.1016%2fj.trc.2023.104015&partnerID=40&md5=095bdbfa2e58764e0f553039f83f030d
AB  - With the rise of sharing economy, bike-sharing systems (BSSs) have gained heated attention, and their operations require accurate prediction of bike usage. Although many deep learning methods have been exploited to predict bike usage, they generally provide point predictions of average bike usage, neglecting the stochasticity in BSSs. Due to the analytically explainable properties and linear computational costs with respect to data size, neural processes (NPs) have recently attracted increasing interest. An NP model learns a Gaussian process (GP) by mapping the input–output observations to a probabilistic distribution over functions. Each function is a distribution of the outputs given an input, conditioned on the arbitrary size of observed data. NPs provide probabilistic confidence in predicted results, which overcomes the point prediction issue faced by other models and provides insights for operational strategies in stochastic scenarios. This paper originally proposes a transformer-encoder-based NP (TENP) model to fit the distribution of bike usage in BSSs. To the best of our knowledge, this work is among the first to incorporate transformer encoders into NPs, enhancing the capability of extracting relevant information in a targeted manner. Based on the Citi Bike datasets in New York City, the TENP method is adopted in a multi-task learning task that simultaneously fits the number of pickups and returns. The proposed TENP model outperforms the conventional NP method and its extensions and prevalent machine learning models in terms of prediction accuracy. Armed with the probabilistic confidence provided by the TENP, reliability analysis is conducted, and thoughtful guidance is provided for bike-sharing operations, such as dynamic bike rebalancing. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - FMS:B; 
LB  - Xu2023Multi-task
ER  -

TY  - JOUR
AU  - Guo, D.
AU  - Wu, E.Q.
AU  - Wu, Y.
AU  - Zhang, J.
AU  - Law, R.
AU  - Lin, Y.
TI  - FlightBERT: Binary Encoding Representation for Flight Trajectory Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 2
SP  - 1828
EP  - 1842
DO  - 10.1109/TITS.2022.3219923
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141552554&doi=10.1109%2fTITS.2022.3219923&partnerID=40&md5=7a60b102d715b0e1853d8ef64fb7949c
AB  - Flight Trajectory Prediction (TP) is an essential task in Air Traffic Control (ATC). Currently, the TP task is usually achieved by regression approaches, which concatenates several scalar attributes of the observation into a low-dimensional vector as the inputs. However, it is difficult to accurately model aircraft motion patterns using low-dimensional features in complex and time-varying ATC environments. To improve the performance of the TP task, in this paper, a novel framework, called FlightBERT, is proposed based on Binary Encoding (BE) representation, which enables us to tackle the TP task as a multi binary classification problem. Specifically, the scalar attributes of the flight trajectory are encoded into binary codes and transformed into a high-dimensional representation by the attribute embedding module. Considering the prior knowledge among flight attributes, an Attribute Correlation Attention (ACoAtt) block is designed to explicitly capture the correlations among the specific attributes. A stacked Transformer block is applied to serve as the backbone network, which is followed by the predictor to generate the outputs. Considering the nature of flight trajectory, a hybrid constrained loss, i.e., combining the mean square error loss with the binary cross-entropy loss, is innovatively designed to optimize the proposed framework. The proposed method is validated on a large-scale dataset, which is collected from the real-world ATC environment. The experimental results demonstrate that the proposed method outperforms other baselines by quantitative and qualitative evaluations. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; FMS:B; 
LB  - Guo2023FlightBERT
ER  -

TY  - JOUR
AU  - Jia, S.
AU  - Pei, X.
AU  - Yao, W.
AU  - Wong, S.C.
TI  - Self-Supervised Depth Estimation Leveraging Global Perception and Geometric Smoothness
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 2
SP  - 1502
EP  - 1517
DO  - 10.1109/TITS.2022.3219604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141633662&doi=10.1109%2fTITS.2022.3219604&partnerID=40&md5=090ae2892d4c4a1d69f8bcd4b3c9cca0
AB  - Self-supervised depth estimation has drawn much attention in recent years as it does not require labeled data but image sequences. Moreover, it can be conveniently used in various applications, such as autonomous driving, robotics, realistic navigation, and smart cities. However, extracting global contextual information from images and predicting a geometrically natural depth map remain challenging. In this paper, we present DLNet for pixel-wise depth estimation, which simultaneously extracts global and local features with the aid of our depth Linformer block. This block consists of the Linformer and innovative soft split multi-layer perceptron blocks. Moreover, a three-dimensional geometry smoothness loss is proposed to predict a geometrically natural depth map by imposing the second-order smoothness constraint on the predicted three-dimensional point clouds, thereby realizing improved performance as a byproduct. Finally, we explore the multi-scale prediction strategy and propose the maximum margin dual-scale prediction strategy for further performance improvement. In experiments on the KITTI and Make3D benchmarks, the proposed DLNet achieves performance competitive to those of the state-of-the-art methods, reducing time and space complexities by more than 62% and 56% at a resolution of 416 × 128 , respectively. Extensive testing on various real-world situations further demonstrates the strong practicality and generalization capability of the proposed model. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Jia2023Self-Supervised
ER  -

TY  - JOUR
AU  - Chi, J.
AU  - Qu, Y.
AU  - Liu, T.
AU  - Zheng, Q.
AU  - Yin, H.
TI  - SeqTrans: Automatic Vulnerability Fix Via Sequence to Sequence Learning
PY  - 2023
T2  - IEEE Transactions on Software Engineering
VL  - 49
IS  - 2
SP  - 564
EP  - 585
DO  - 10.1109/TSE.2022.3156637
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126293988&doi=10.1109%2fTSE.2022.3156637&partnerID=40&md5=d33f94d2bdbfca3e7c99a43c3a7b0430
AB  - Software vulnerabilities are now reported unprecedentedly due to the recent development of automated vulnerability hunting tools. However, fixing vulnerabilities still mainly depends on programmers' manual efforts. Developers need to deeply understand the vulnerability and affect the system's functions as little as possible. In this paper, with the advancement of Neural Machine Translation (NMT) techniques, we provide a novel approach called SeqTrans to exploit historical vulnerability fixes to provide suggestions and automatically fix the source code. To capture the contextual information around the vulnerable code, we propose to leverage data-flow dependencies to construct code sequences and feed them into the state-of-the-art transformer model. The fine-tuning strategy has been introduced to overcome the small sample size problem. We evaluate SeqTrans on a dataset containing 1,282 commits that fix 624 CVEs in 205 Java projects. Results show that the accuracy of SeqTrans outperforms the latest techniques and achieves 23.3% in statement-level fix and 25.3% in CVE-level fix. In the meantime, we look deep inside the result and observe that the NMT model performs very well in certain kinds of vulnerabilities like CWE-287 (Improper Authentication) and CWE-863 (Incorrect Authorization). © 1976-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:A期刊; FMS:B; 
LB  - Chi2023SeqTrans
ER  -

TY  - JOUR
AU  - Xue, Z.
AU  - Zhiqiang, Z.
AU  - Zhengyin, H.
TI  - Exploring interdisciplinarity of science projects based on the text mining
PY  - 2023
T2  - Journal of Information Science
DO  - 10.1177/01655515231182075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164513536&doi=10.1177%2f01655515231182075&partnerID=40&md5=11c537b2e384104cb9ed874df4cb23a9
AB  - Interdisciplinary research has gradually become one of the main driving forces to promote original innovation of scientific research, and how to measure the interdisciplinarity of science project is becoming an important topic in the science foundation managements. Existing researches mainly using methods, such as academic degree or institutional discipline or discipline category mapping of journals, to measure the interdisciplinarity. This study proposes an approach to mine and capture the different or complementary characteristics of interdisciplinarity of projects by combining text mining and machine learning methods. First, we construct the classification system and extract a raw paper and its discipline matrix according to the discipline category of journals where the references were published in. Second, we cut the matrix to summarise the distribution of key disciplines in each paper and extract the text features in the abstract and title to form a training set. Finally, we compare and analyse the classification effects of Naive Bayesian Model, Support Vector Machine and Bidirectional Encoder Representations from Transformers (BERT) model. Then, the model evaluation indicators show that the best classification effect was achieved by the BERT model. Therefore, the deep pre-trained linguistic model BERT is chosen to predict the discipline distribution of each project. In addition, the different aspects of interdisciplinarity are measured using network coherence and discipline diversity indicators. Besides, experts are invited to evaluate and interpret the results. This proposed approach could be applied to deeply understand the discipline integration from a new perspective. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Xue2023Exploring
ER  -

TY  - JOUR
AU  - Hu, S.
AU  - Xiong, C.
TI  - High-dimensional population inflow time series forecasting via an interpretable hierarchical transformer
PY  - 2023
T2  - Transportation Research Part C: Emerging Technologies
VL  - 146
C7  - 103962
DO  - 10.1016/j.trc.2022.103962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143712055&doi=10.1016%2fj.trc.2022.103962&partnerID=40&md5=b9f61596408221587702565a0f9d1d26
AB  - Mobile device location data (MDLD) are emerging data sources in the transportation domain that contain large-scale, fine-grained information on population inflow. However, limited studies have built forecasting models based on large-scale MDLD-based population inflow time series. This task is challenging due to complex nonlinear temporal dynamics, high-dimensional time series structure (i.e. multiple time series with multi-shape inputs and outputs), and non-negligible impacts from various external factors. To address these challenges, this study introduces a deep learning framework, the Interpretable Hierarchical Transformer (IHTF), for nationwide county-level population inflow time series forecasting and interpretation. A variety of cutting-edge deep learning techniques are fused, including the variable selection network to incorporate external effects, the gated residual network to handle nonlinearity, and the transformer architecture to learn temporal dynamics. Different interior parameters, such as variable selection weight and temporal attention weight, are extracted to explain patterns learned by the framework. Numerical experiments show that IHTF outperforms extensive baseline models in forecasting accuracy. In addition, feature importance generated by IHTF is similar to the tree-based model, LightGBM, but exhibits a more even distribution, among which point-of-interests (POIs) count, county location, median household income, and percentage of accommodation and food services are the most important static variables. Moreover, attention weight demonstrates that IHTF can automatically learn the seasonality from time series. Taken together, this framework can serve as a reliable travel demand forecasting component in the transportation planning process that allows modeling the travel demand continuously instead of by snapshot. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - FMS:B; 
LB  - Hu2023High-dimensional
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Yang, J.
AU  - Dai, T.
AU  - Xiao, Y.
TI  - A predictive model based on user awareness and multi-type rumors forwarding dynamics
PY  - 2023
T2  - Information Sciences
VL  - 619
SP  - 795
EP  - 816
DO  - 10.1016/j.ins.2022.11.072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142876393&doi=10.1016%2fj.ins.2022.11.072&partnerID=40&md5=00111d86b15defd3863166b93b1359c6
AB  - Previous models for predicting rumor-forwarding trends were primarily focused on feature generation and model prediction in two independent directions: message text and user association features. However, the abstraction of user awareness, text contextual feature extraction limitation, and inefficiency of traditional hyperparameter search methods still pose numerous challenges. This study proposes a rumor-forwarding trend prediction model that combines user awareness and multi-type rumor to address such challenges. First, considering the abstraction of user awareness under multi-type rumors, we extract features by cascading user behavior, historical activities, interactions, and activity levels and by fusing features using a two-layer fully connected network to effectively quantify the relevant features of user awareness. Second, considering the limitations of traditional text representation in semantic context understanding, we use the Bidirectional Encoder Representation from Transformers (BERT) pre-training model to characterize the text in the topic, obtain text representation sequence with contextual relationships, and propose an Improved Cuckoo Search (ICS) method that optimizes the hyperparameters of the temporal convolutional network (TCN) model. Finally, an Improved Cuckoo Search-TCN-based rumor-forwarding trend prediction model is constructed based on user awareness features and text representation sequences to predict the rumor-forwarding trend. Certain rumors with a large potential impact range can be monitored at the early dissemination stage. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Li2023predictive
ER  -

TY  - JOUR
AU  - Liu, L.
AU  - Racz, D.
AU  - Vaillancourt, K.
AU  - Michelman, J.
AU  - Barnes, M.
AU  - Mellem, S.
AU  - Eastham, P.
AU  - Green, B.
AU  - Armstrong, C.
AU  - Bal, R.
AU  - O'Banion, S.
AU  - Guo, F.
TI  - Smartphone-based hard-braking event detection at scale for road safety services
PY  - 2023
T2  - Transportation Research Part C: Emerging Technologies
VL  - 146
C7  - 103949
DO  - 10.1016/j.trc.2022.103949
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144024612&doi=10.1016%2fj.trc.2022.103949&partnerID=40&md5=8e97573e5e4e7b74f240b9107fbc8ac4
AB  - Road crashes are the sixth leading cause of lost disability-adjusted life-years (DALYs) worldwide. One major challenge in traffic safety research is the sparsity of crashes, which makes it difficult to achieve a fine-grain understanding of crash causations and predict future crash risk in a timely manner. Hard-braking events have been widely used as a safety surrogate due to their relatively high prevalence and ease of detection with embedded vehicle sensors. As an alternative to using sensors fixed in vehicles, this paper presents a scalable approach for detecting hard-braking events using the kinematics data collected from smartphone sensors. We train a Transformer-based machine learning model for hard-braking event detection using concurrent sensor readings from smartphones and vehicle sensors from drivers who connect their phone to the vehicle while navigating in Google Maps. The detection model shows superior performance with a 0.83 Area under the Precision–Recall Curve (PR-AUC), which is 3.8×better than a GPS speed-based heuristic model, and 166.6×better than an accelerometer-based heuristic model. The detected hard-braking events are strongly correlated with crashes from publicly available datasets, supporting their use as a safety surrogate. In addition, we conduct model fairness and selection bias evaluation to ensure that the safety benefits are equally shared. The developed methodology can benefit many safety applications such as identifying safety hot spots at road network level, evaluating the safety of new user interfaces, as well as using routing to improve traffic safety. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - FMS:B; 
LB  - Liu2023Smartphone-based
ER  -

TY  - JOUR
AU  - Cheng, L.
AU  - Jia, W.
AU  - Yang, W.
TI  - Capture Salient Historical Information: A Fast and Accurate Non-autoregressive Model for Multi-turn Spoken Language Understanding
PY  - 2022
T2  - ACM Transactions on Information Systems
VL  - 41
IS  - 2
C7  - 41
DO  - 10.1145/3545800
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143432685&doi=10.1145%2f3545800&partnerID=40&md5=bf6c108820a37bfee3d2f1f662c20642
AB  - Spoken Language Understanding (SLU), a core component of the task-oriented dialogue system, expects a shorter inference facing the impatience of human users. Existing work increases inference speed by designing non-autoregressive models for single-turn SLU tasks but fails to apply to multi-turn SLU in confronting the dialogue history. The intuitive idea is to concatenate all historical utterances and utilize the non-autoregressive models directly. However, this approach seriously misses the salient historical information and suffers from the uncoordinated-slot problems. To overcome those shortcomings, we propose a novel model for multi-turn SLU named Salient History Attention with Layer-Refined Transformer (SHA-LRT), which comprises a SHA module, a Layer-Refined Mechanism (LRM), and a Slot Label Generation (SLG) task. SHA captures salient historical information for the current dialogue from both historical utterances and results via a well-designed history-attention mechanism. LRM predicts preliminary SLU results from Transformer's middle states and utilizes them to guide the final prediction, and SLG obtains the sequential dependency information for the non-autoregressive encoder. Experiments on public datasets indicate that our model significantly improves multi-turn SLU performance (17.5% on Overall) with accelerating (nearly 15 times) the inference process over the state-of-the-art baseline as well as effective on the single-turn SLU tasks.  © 2022 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:A期刊; FMS:B; 
LB  - Cheng2022Capture
ER  -

TY  - JOUR
AU  - Sprangers, O.
AU  - Schelter, S.
AU  - de Rijke, M.
TI  - Parameter-efficient deep probabilistic forecasting
PY  - 2023
T2  - International Journal of Forecasting
VL  - 39
IS  - 1
SP  - 332
EP  - 345
DO  - 10.1016/j.ijforecast.2021.11.011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122963685&doi=10.1016%2fj.ijforecast.2021.11.011&partnerID=40&md5=0aeadf8b24a7988f76aba0e848968f3c
AB  - Probabilistic time series forecasting is crucial in many application domains, such as retail, ecommerce, finance, and biology. With the increasing availability of large volumes of data, a number of neural architectures have been proposed for this problem. In particular, Transformer-based methods achieve state-of-the-art performance on real-world benchmarks. However, these methods require a large number of parameters to be learned, which imposes high memory requirements on the computational resources for training such models. To address this problem, we introduce a novel bidirectional temporal convolutional network that requires an order of magnitude fewer parameters than a common Transformer-based approach. Our model combines two temporal convolutional networks: the first network encodes future covariates of the time series, whereas the second network encodes past observations and covariates. We jointly estimate the parameters of an output distribution via these two networks. Experiments on four real-world datasets show that our method performs on par with four state-of-the-art probabilistic forecasting methods, including a Transformer-based approach and WaveNet, on two point metrics (sMAPE and NRMSE) as well as on a set of range metrics (quantile loss percentiles) in the majority of cases. We also demonstrate that our method requires significantly fewer parameters than Transformer-based methods, which means that the model can be trained faster with significantly lower memory requirements, which as a consequence reduces the infrastructure cost for deploying these models. © 2021 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Sprangers2023Parameter-efficient
ER  -

TY  - JOUR
AU  - Ciniselli, M.
AU  - Cooper, N.
AU  - Pascarella, L.
AU  - Mastropaolo, A.
AU  - Aghajani, E.
AU  - Poshyvanyk, D.
AU  - Di Penta, M.
AU  - Bavota, G.
TI  - An Empirical Study on the Usage of Transformer Models for Code Completion
PY  - 2022
T2  - IEEE Transactions on Software Engineering
VL  - 48
IS  - 12
SP  - 4818
EP  - 4837
DO  - 10.1109/TSE.2021.3128234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145349356&doi=10.1109%2fTSE.2021.3128234&partnerID=40&md5=07328f166363007a0e8b14a1e3bcec1a
AB  - Code completion aims at speeding up code writing by predicting the next code token(s) the developer is likely to write. Works in this field focused on improving the accuracy of the generated predictions, with substantial leaps forward made possible by deep learning (DL) models. However, code completion techniques are mostly evaluated in the scenario of predicting the next token to type, with few exceptions pushing the boundaries to the prediction of an entire code statement. Thus, little is known about the performance of state-of-the-art code completion approaches in more challenging scenarios in which, for example, an entire code block must be generated. We present a large-scale study exploring the capabilities of state-of-the-art Transformer-based models in supporting code completion at different granularity levels, including single tokens, one or multiple entire statements, up to entire code blocks (e.g., the iterated block of a for loop). We experimented with several variants of two recently proposed Transformer-based models, namely RoBERTa and the Text-To-Text Transfer Transformer (T5), for the task of code completion. The achieved results show that Transformer-based models, and in particular the T5, represent a viable solution for code completion, with perfect predictions ranging from ∼29%, obtained when asking the model to guess entire blocks, up to ∼69%, reached in the simpler scenario of few tokens masked from the same code statement.  © 1976-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 41
C2  - CCF:A期刊; FMS:B; 
LB  - Ciniselli2022Empirical
ER  -

TY  - JOUR
AU  - Du, W.
AU  - Chen, S.
AU  - Li, H.
AU  - Li, Z.
AU  - Cao, X.
AU  - Lv, Y.
TI  - Airport Capacity Prediction With Multisource Features: A Temporal Deep Learning Approach
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 1
SP  - 615
EP  - 630
DO  - 10.1109/TITS.2022.3213029
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140720706&doi=10.1109%2fTITS.2022.3213029&partnerID=40&md5=be17508f2cca3af3224ec0c7fef28964
AB  - Accurate airport capacity estimation is crucial for the secure and orderly operation of the aviation system. However, such estimation is a non-trivial task as capacity depends on various meteorological and operational features. The complex coupling characteristics among these multi-source features have proved to be challenging for most of the traditional regression models. Recently, enhanced by its excellent ability to mine nonlinear relationships, the machine learning methods trigger widely applications. However, due to the imbalance of features scatter and the neglect of temporal dependences in aviation systems, existing machine learning methods for airport capacity prediction still have room for improvement. In light of these, this paper presents a novel airport capacity prediction method based on the multi-channel fusion Transformer model (MF-Transformer). Besides the commonly used aviation features, we unprecedentedly harness the power of the high-dimensional meteorological feature for accurate prediction. As to the model, we construct a multi-channel feature fusion structure, which includes a three-channel network for multi-source features extraction and an attention-based feature fusion module between channels. In each channel, the Transformer-based model is utilized to capture the temporal dependences of features. We conduct experiments on the capacity prediction tasks of the Beijing Capital International Airport which is the largest airport in China and verify that the proposed MF-Transformer outperforms benchmarks under different prediction horizons.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; FMS:B; 
LB  - Du2023Airport
ER  -

TY  - JOUR
AU  - Lian, J.
AU  - Yu, F.
AU  - Li, L.
AU  - Zhou, Y.
TI  - Causal Temporal-Spatial Pedestrian Trajectory Prediction With Goal Point Estimation and Contextual Interaction
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 24499
EP  - 24509
DO  - 10.1109/TITS.2022.3204342
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139395100&doi=10.1109%2fTITS.2022.3204342&partnerID=40&md5=6a123ad332d18f5959ba0b0304ea6007
AB  - Forecasting pedestrian trajectories in complex dynamic environments is highly critical for the application of autonomous vehicles and robots. Accordingly, this paper proposes a novel pedestrian trajectory prediction model called CTSGI, which, utilizes self-attention mechanism to construct an interactive graph between pedestrians and their neighbors based on their spatial relationship, to model the crowd's interaction. At the same time, it uses self-attention to extract the temporal dependence for a single pedestrian. In order to effectively model the interaction between the pedestrian and the context, such as where a pedestrian can walk or approach, the semantic segmentation of background image is utilized. CTSGI estimates the goal points of pedestrian and their neighbors to assist in predicting the future trajectory. In addition, the causal structure model is used to analyze the confounding factors existing in the encoding stage, and Do-calculus is introduced for eliminating the confounding impact to improve the prediction performance. Moreover, extensive experiments are conducted for the proposed model on ETH and UCY datasets, and clearly, the experimental results reveal that the model reported herein outperforms the comparative state-of-the-art methods by 27.59% in Average Displacement Error (ADE) and 8.33% in Final Displacement Error (FDE). Furthermore, visualization of attention indicates that our model can capture the interaction between some specific pedestrian and their neighbors better. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Lian2022Causal
ER  -

TY  - JOUR
AU  - Fang, Y.
AU  - Zhao, F.
AU  - Qin, Y.
AU  - Luo, H.
AU  - Wang, C.
TI  - Learning All Dynamics: Traffic Forecasting via Locality-Aware Spatio-Temporal Joint Transformer
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 23433
EP  - 23446
DO  - 10.1109/TITS.2022.3197640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136843712&doi=10.1109%2fTITS.2022.3197640&partnerID=40&md5=6390ad15b2da537012124db43c4a9fe8
AB  - Forecasting traffic flow and speed in the urban is important for many applications, ranging from the intelligent navigation of map applications to congestion relief of city management systems. Therefore, mining the complex spatio-temporal correlations in the traffic data to accurately predict traffic is essential for the community. However, previous studies that combined the graph convolution network or self-attention mechanism with deep time series models (e.g., the recurrent neural network) can only capture spatial dependencies in each time slot and temporal dependencies in each sensor, ignoring the spatial and temporal correlations across different time slots and sensors. Besides, the state-of-the-art Transformer architecture used in previous methods is insensitive to local spatio-temporal contexts, which is hard to suit with traffic forecasting. To solve the above two issues, we propose a novel deep learning model for traffic forecasting, named Locality-aware spatio-temporal joint Transformer (Lastjormer), which elaborately designs a spatio-temporal joint attention in the Transformer architecture to capture all dynamic dependencies in the traffic data. Specifically, our model utilizes the dot-product self-attention on sensors across many time slots to extract correlations among them and introduces the linear and convolution self-attention mechanism to reduce the computation needs and incorporate local spatio-temporal information. Experiments on three real-world traffic datasets, England, METR-LA, and PEMS-BAY, demonstrate that our Lastjormer achieves state-of-the-art performances on a variety of challenging traffic forecasting benchmarks.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - CCF:B期刊; FMS:B; 
LB  - Fang2022Learning
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Zhang, Y.
AU  - Fortino, G.
AU  - Guan, Q.
AU  - Liu, J.
AU  - Song, J.
TI  - Software Escalation Prediction Based on Deep Learning in the Cognitive Internet of Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 25408
EP  - 25418
DO  - 10.1109/TITS.2022.3140903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123778689&doi=10.1109%2fTITS.2022.3140903&partnerID=40&md5=0b664f65aebf23445012c85e34e04696
AB  - In the Cognitive Internet of Vehicles (CIoV), vehicles, road side units (RSU) and other key nodes have been equipped with more and more software to support intelligent transportation system (ITS), vehicle automatic control and intelligent road information services. Additionally, technological innovation forces the software in the CIoV to update and upgrade in time. However, escalation is critical to the safety, stability, and maintenance cost of transportation systems. It can be assumed that when the intelligent services supporting CIoV can realize self-perception and escalation, the cognitive ability and coordination ability of the entire CIoV will be greatly improved. To address this, we first propose a deep learning-based method for Software Escalation Prediction (SEP) in CIoV. Specifically, the pretraining mechanism of transformers in the field of natural language processing is combined with software upgrade-related events to dynamically model software sequence activities. To capture the event association in the software activities, we use graph modeling software's state log and utilize a graph neural network (GNN) to learn the complex life activity rule of software. Finally, the above characteristics are deeply integrated. The proposed method has a 6%-8% improvement over the RoBERTa methods.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2022Software
ER  -

TY  - JOUR
AU  - Hou, L.
AU  - Li, S.E.
AU  - Yang, B.
AU  - Wang, Z.
AU  - Nakano, K.
TI  - Structural Transformer Improves Speed-Accuracy Trade-Off in Interactive Trajectory Prediction of Multiple Surrounding Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 24778
EP  - 24790
DO  - 10.1109/TITS.2022.3193665
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135762964&doi=10.1109%2fTITS.2022.3193665&partnerID=40&md5=70861e8e99e113c5c20932e975740c58
AB  - Fast and accurate long-term trajectory prediction of surrounding vehicles (SVs) is critical to autonomous driving systems. In high-density traffic flows, strongly correlated vehicle behaviors require considering the interactions among multiple SVs when predicting their future trajectories. However, existing interactive prediction methods, most based on Long Short-Term Memory (LSTM), are suffering from slow prediction because they analyze SVs one by one and analyze trajectory sequence node by node. This paper presents a fast interactive trajectory prediction method called Structural Transformer which learns both spatial and temporal dependencies among multiple SVs in parallel. Specifically, our model first removes the internal states and loops of LSTM and replaces with a weighted self-reference mapping to realize parallel computation. Then, it embeds the relative spatial information of multiple SVs into trajectory states and reorganizes the self-reference mapping with neighbor-only interaction masks to achieve interactive prediction. Results on the NGSIM dataset show satisfyingly speed and accuracy performance on long-term trajectory prediction of multiple SVs. The longitudinal and lateral errors are reduced to 2.67m and 0.25m over 5s time horizon. The computational time of each step is only 12ms on a 2080ti GPU, which is over 4 times faster than the Structural LSTM.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; FMS:B; 
LB  - Hou2022Structural
ER  -

TY  - JOUR
AU  - Sutopo, R.
AU  - Lim, J.M.-Y.
AU  - Baskaran, V.M.
TI  - Efficient Long-Term Dependencies Learning for Passenger Flow Prediction with Selective Feedback Mechanism
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 24020
EP  - 24030
DO  - 10.1109/TITS.2022.3199748
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137895363&doi=10.1109%2fTITS.2022.3199748&partnerID=40&md5=71a65ac8dcc996bf9c839cb4ef743af6
AB  - With the rapid growth of worldwide urbanization, the increasing demand for public transportation is indispensable. To improve the service quality, predicting the flow of passengers is important for the transport operators. Information on density of passengers can be used as early warnings of overcrowding and to determine if additional fleet is required. However, passenger flow forecasting is a challenging task, as it is affected by many complex factors such as spatial dependencies, temporal dependencies, and external influences. Furthermore, the ability to learn the long-term dependency of the data is also crucial, as the distant past flow information contributes to the flow over time. Most of the existing studies struggle to solve this issue, especially to learn the long-term dependency of the data, as they rely heavily on the raw handcrafted features and require high memory bandwidth to compute. To address these issues, we propose a Selective Feedback Transformer (SFT) capable of learning long-term dependency efficiently, where the selective feedback mechanism only computes the important feedback from the dominant query-key pairs in the memory. Experimental results demonstrate that the proposed model outperforms all the benchmarked methods by 27%-37% in terms of RMSE and 36%-50% in terms of MAE. Additionally, when the proposed model is tested with shallowed model (less number of decoding layer), it exhibits a substantial improvement of 14%-57% in the training time and 15%-46% in the inference time, with minimal impact on the accuracies.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Sutopo2022Efficient
ER  -

TY  - JOUR
AU  - Sun, G.
AU  - Qi, H.
AU  - Shen, Y.
AU  - Yin, B.
TI  - TCSA-Net: A Temporal-Context-Based Self-Attention Network for Next Location Prediction
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 20735
EP  - 20745
DO  - 10.1109/TITS.2022.3181339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132756661&doi=10.1109%2fTITS.2022.3181339&partnerID=40&md5=57dcf3006b1df39d7f7294c194139b60
AB  - Next location prediction aims to find the location that the user will visit next. It plays a fundamental role for location-based applications. However, the heterogeneity and sparsity of the trajectory data pose great challenges to the task. Recently, RNN-based methods have shown promising performance in learining the spatio-temporal characteristics of the trajectory. While the effectiveness of location prediction has been improved, the computational efficiency and the long-term preferences still leave space for further research. The self-attention mechanism is viewed as a promising solution for parallel computation and exploiting sequential regularities from sparse data. But the huge memory cost and the neglect of temporal information make it infeasible to directly modeling human mobility regularities. In this paper, we propose a temporal-context-based self-attention network named TCSA-Net, which can simultaneously exploit long- and short-term mvoement preferences from sparse and long trajectories. In particular, we design a novel two-stage self-attention architecture that can learn long-term dependency under constrained memory budget. Further, we propose a multi-modal embedding layer to model two complementary temporal contexts and provide more abundant temporal and sequential information. Extensive experiments on two real-life datasets show that the TCSA-Net significantly outperforms the state-of-the-art methods in terms of standard evaluation metrics.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Sun2022TCSA-Net
ER  -

TY  - JOUR
AU  - Zhang, K.
AU  - Feng, X.
AU  - Wu, L.
AU  - He, Z.
TI  - Trajectory Prediction for Autonomous Driving Using Spatial-Temporal Graph Attention Transformer
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 22343
EP  - 22353
DO  - 10.1109/TITS.2022.3164450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129406845&doi=10.1109%2fTITS.2022.3164450&partnerID=40&md5=e4e4dfd52591f047bf796065c1461af6
AB  - For autonomous vehicles driving on roads, future trajectories of surrounding traffic agents (e.g., vehicles, bicycles, pedestrians) are essential information. The prediction of future trajectories is challenging as the motion of traffic agents is constantly affected by spatial-temporal interactions from agents and road infrastructure. To take those interactions into account, this study proposes a Graph Attention Transformer (Gatformer) in which a traffic scene is represented by a sparse graph. To maintain the spatial and temporal information of traffic agents in a traffic scene, Convolutional Neural Networks (CNNs) are utilized to extract spatial features and a position encoder is proposed to encode the spatial features and the corresponding temporal features. Based on the encoded features, a Graph Attention Network (GAT) block is employed to model the agent-agent and agent-infrastructure interactions with the help of attention mechanisms. Finally, a Transformer network is introduced to predict trajectories for multiple agents simultaneously. Experiments are conducted over the Lyft dataset and state-of-the-art methods are introduced for comparison. The results show that the proposed Gatformer could make more accurate predictions while requiring less inference time than its counterparts.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 62
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2022Trajectory
ER  -

TY  - JOUR
AU  - Xu, S.
AU  - Zhang, C.
AU  - Hong, D.
TI  - BERT-based NLP techniques for classification and severity modeling in basic warranty data study
PY  - 2022
T2  - Insurance: Mathematics and Economics
VL  - 107
SP  - 57
EP  - 67
DO  - 10.1016/j.insmatheco.2022.07.013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135392813&doi=10.1016%2fj.insmatheco.2022.07.013&partnerID=40&md5=d92d7a32fc355a2e38078244b845d58c
AB  - This paper is to explore data-driven models based on a newly developed natural language processing (NLP) tool called Bidirectional Encoder Representations from Transformer (BERT) to incorporate textural data information for group classification and loss amount prediction on truck's basic warranty claims. In group classification modeling, multiple-class logistic regression is compared with BERT-based back-propagation neural networks (NN). In group loss severity modeling, direct NN regression is compared with BERT-based NN regression prediction. Furthermore, based on the results from a so-called optimal bin-width algorithm, the severity distribution is fitted in Gamma and its parameters are then estimated using maximum likelihood estimation (MLE). The data experiments show that the BERT framework for NLP improves the classification of the warranty claims as well as the loss severity prediction both in accuracy and stability. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Xu2022BERT-based
ER  -

TY  - JOUR
AU  - Xie, Y.
AU  - Niu, J.
AU  - Zhang, Y.
AU  - Ren, F.
TI  - Multisize Patched Spatial-Temporal Transformer Network for Short- and Long-Term Crowd Flow Prediction
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 21548
EP  - 21568
DO  - 10.1109/TITS.2022.3186707
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134304842&doi=10.1109%2fTITS.2022.3186707&partnerID=40&md5=d29cb1218f5ec508825de01b6cb60a43
AB  - The prediction of urban crowds is crucial not only to traffic management but also to studies on the city-level social phenomena, such as energy consumption, urban growth, city planning, and epidemic prevention. The challenges of accurately predicting crowd flow come from the non-linear spatial-temporal dependence of crowd flow data, periodic laws, such as daily and weekly periodicity, and external factors, such as weather and holidays. It is even more challenging for most existing short-term prediction models to make an accurate long-term prediction. In this paper, we propose a novel patched Transformer-based sequence-to-sequence model, called MultiSize Patched Spatial-Temporal Transformer Network (MSP-STTN), to incorporate rich and unified context modeling via a self-attention mechanism and global memory learning via a cross-attention mechanism for short- and long-term grid-based crowd flow prediction. In particular, a multisize patched spatial-temporal self-attention Transformer is designed to capture cross-space-time and cross-size contextual dependence of crowd data. The same structured cross-attention Transformer is developed to adaptively learn a global memory for long-term prediction in a responding-to-a-query style without error accumulation. In addition, a categorized space-time expectation is proposed as a unified regional encoding with temporal and external factors and is used as a base prediction for stable training. Furthermore, auxiliary tasks are introduced for promoting feature encoding and leveraging feature consistency to assist in the main prediction task. The experimental results reveal that MSP-STTN is competitive with the state of the art for one-step and multi-step short-term prediction within several hours and achieves practical long-term crowd flow prediction within one day on real-world grid-based crowd data sets TaxiBJ, BikeNYC, and CrowdDensityBJ. Our code and data are available at https://github.com/xieyulai/MSP-STTN. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - CCF:B期刊; FMS:B; 
LB  - Xie2022Multisize
ER  -

TY  - JOUR
AU  - Yan, H.
AU  - Ma, X.
AU  - Pu, Z.
TI  - Learning Dynamic and Hierarchical Traffic Spatiotemporal Features with Transformer
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 22386
EP  - 22399
DO  - 10.1109/TITS.2021.3102983
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113308926&doi=10.1109%2fTITS.2021.3102983&partnerID=40&md5=522c9bc398a5cde89af88b3b9c8101e2
AB  - Traffic forecasting has attracted considerable attention due to its importance in proactive urban traffic control and management. Scholars and engineers have exerted considerable efforts in improving the performance of traffic forecasting algorithms in terms of accuracy, reliability, and efficiency. Spatial feature representation of traffic flow is a core component that greatly influences traffic forecasting performance. In previous studies, several spatial attributes of traffic flow are ignored due to the following issues: a) traffic flow propagation does not comply with the road network, b) the spatial pattern of traffic flow varies over time, and c) single adjacent matrix cannot handle the complex and hierarchical urban traffic flow. To address the abovementioned issues, this study proposes a novel traffic forecasting algorithm called traffic transformer, which achieves great success in natural language processing. The multihead attention mechanism and stacking layers enable the transformer to learn dynamic and hierarchical features in sequential data. Two components, namely, global encoder and global-local decoder, are proposed to extract and fuse the spatial patterns globally and locally. Experimental results indicate that the proposed traffic transformer outperforms state-of-the-art methods. The learned dynamic and hierarchical features of traffic flow can help achieve a better understanding of spatial dependency of traffic flow for effective and efficient traffic control and management strategies.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 125
C2  - CCF:B期刊; FMS:B; 
LB  - Yan2022Learning
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, H.
AU  - Zhao, F.
AU  - Hu, Y.
AU  - Tan, C.
AU  - Yang, J.
TI  - Intention-Aware Vehicle Trajectory Prediction Based on Spatial-Temporal Dynamic Attention Network for Internet of Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
SP  - 19471
EP  - 19483
DO  - 10.1109/TITS.2022.3170551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129432452&doi=10.1109%2fTITS.2022.3170551&partnerID=40&md5=de48ab115b1b3760ee0888cb31e1895a
AB  - Vehicle trajectory prediction is a keystone for the application of the internet of vehicles (IoV). With the help of deep learning and big data, it is possible to understand the between-vehicle interaction pattern hidden in the complex traffic environment. In this paper, we propose a novel spatial-temporal dynamic attention network for vehicle trajectory prediction, which can comprehensively capture temporal and social patterns in a hierarchical manner. The social relation between vehicles is captured at each timestamp and thus retains the dynamic variation of interaction. The temporal correlation in terms of individual motion state as well as social interaction is captured by different sequential models. Furthermore, a driving intention-specific feature fusion mechanism is proposed such that the extracted temporal and social features can be integrated adaptively for the maneuver-based multi-modal trajectory prediction. Experimental results on two real-world datasets show that compared with the state-of-the-art algorithms, our proposal achieves comparable prediction performance for short-term prediction, however, works much better for long-term prediction. Additionally, various ablation analysis is provided to evaluate the effectiveness of our proposed network components. The code will be available at https://xbchen82.github.io/resource/.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 89
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2022Intention-Aware
ER  -

TY  - JOUR
AU  - Kriebel, J.
AU  - Stitz, L.
TI  - Credit default prediction from user-generated text in peer-to-peer lending using deep learning
PY  - 2022
T2  - European Journal of Operational Research
VL  - 302
IS  - 1
SP  - 309
EP  - 323
DO  - 10.1016/j.ejor.2021.12.024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123016411&doi=10.1016%2fj.ejor.2021.12.024&partnerID=40&md5=83a66e0239624d936757e138fadbb49a
AB  - Digital technologies produce vast amounts of unstructured data that can be stored and accessed by traditional banks and fintech companies. We employ deep learning and several other techniques to extract credit-relevant information from user-generated text on Lending Club. Our results show that even short pieces of user-generated text can improve credit default predictions significantly. The importance of text is further supported by an information fusion analysis. Compared with other approaches that use text, deep learning outperforms them in almost all cases. However, machine learning models combined with word frequencies or topic models also extract substantial credit-relevant information. A comparison of six deep neural network architectures, including state-of-the-art transformer models, finds that the architectures mostly provide similar performance. This means that simpler methods (such as average embedding neural networks) offer performance comparable to more complex methods (such as the transformer networks BERT and RoBERTa) in this credit scoring setting. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 46
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Kriebel2022Credit
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Wan, Y.
AU  - Qin, J.
AU  - Fu, W.
AU  - Kang, Y.
TI  - A Deep RL-Based Algorithm for Coordinated Charging of Electric Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
SP  - 18774
EP  - 18784
DO  - 10.1109/TITS.2022.3170000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129441475&doi=10.1109%2fTITS.2022.3170000&partnerID=40&md5=c7f57e67f67cce8e34aae1e38d285188
AB  - The development of electric vehicle (EV) industry is facing a series of issues, among which the efficient charging of multiple EVs needs solving desperately. This paper investigates the coordinated charging of multiple EVs with the aim of reducing the charging cost, ensuring a high battery state of charge (SoC), and avoiding the transformer overload. To this end, we first formulate the EV coordinated charging problem with the above multiple objectives as a Markov Decision Process (MDP) and then propose a multi-agent deep reinforcement learning (DRL)-based algorithm. In the proposed algorithm, a novel interaction model, i.e., communication neural network (CommNet) model, is adopted to realize the distributed computation of global information (namely the electricity price, the transformer load, and the total charging cost of multiple EVs). Moreover, different from the most existing works which make specific constraints on the size, the location, or the topology of the distribution network, what we need in the proposed method is only the transformer load. Besides, due to the use of long and short-term memory (LSTM) for price prediction, the proposed algorithm can flexibly deal with various uncertain price mechanisms. Finally, simulations are presented to verify the effectiveness and practicability of the proposed algorithm in a residential charging area.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2022Deep
ER  -

TY  - JOUR
AU  - Zhang, K.
AU  - Li, L.
TI  - Explainable multimodal trajectory prediction using attention models
PY  - 2022
T2  - Transportation Research Part C: Emerging Technologies
VL  - 143
C7  - 103829
DO  - 10.1016/j.trc.2022.103829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135521155&doi=10.1016%2fj.trc.2022.103829&partnerID=40&md5=edf38f99a8b9dad490053173e2aa3146
AB  - Automated vehicles are expected to navigate complex urban environments safely along with several non-cooperating agents. Therefore, accurate trajectory prediction is crucial for safe navigation and receives much interest. However, most existing studies mainly focus on models' prediction accuracy rather than their explainability. In this paper, we propose a Multimodal Trajectory Prediction Transformer (MTPT) model to retrieve the influencing factors of prediction and help understand the intrinsic mechanism of prediction. Especially in the MTPT model, we use a modified Swin Transformer with multiple prediction heads to carry out multimodal trajectory prediction. Numerical experiments confirm the MTPT model can capture the most critical input factors with the help of the attention method and thus improve prediction accuracy. The proposed model obtains state-of-the-art results even with limited training data. Moreover, the identified input factors are also in agreement with the human driving experience. This agreement indicates that the proposed model appropriately learns how to predict. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - FMS:B; 
LB  - Zhang2022Explainable
ER  -

TY  - JOUR
AU  - Latifi, S.
AU  - Jannach, D.
AU  - Ferraro, A.
TI  - Sequential recommendation: A study on transformers, nearest neighbors and sampled metrics
PY  - 2022
T2  - Information Sciences
VL  - 609
SP  - 660
EP  - 678
DO  - 10.1016/j.ins.2022.07.079
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134888073&doi=10.1016%2fj.ins.2022.07.079&partnerID=40&md5=c72309eccbc12981d0be587c95ea7bea
AB  - Sequential recommendation problems have received increased research interest in recent years. In such scenarios, the task is to suggest items to users to consume next, given their past interaction history, e.g., the next movie to watch or the next item to place in the shopping cart. A number of machine learning models were proposed recently for the task of sequential recommendation, with the latest ones based on deep learning techniques, in particular on Transformers. Given the often surprisingly competitive performance of simpler nearest-neighbor methods for the related problem of session-based recommendation, we investigate the use of nearest-neighbor methods for sequential recommendation problems. Our analysis on four datasets shows that nearest-neighbor methods achieve comparable or better performance than the recent Transformer-based BERT4REC method on two of them. However, the deep learning method outperforms the simple methods for the two larger datasets, confirming previous hypotheses that neural methods work best when more data is available. As a further result of our experiments, we found additional evidence that sampled metrics must be used with care, as they may not be predictive of an algorithm ranking that would be observed with the non-sampled, full evaluation. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; FMS:B; 
LB  - Latifi2022Sequential
ER  -

TY  - JOUR
AU  - Abdelraouf, A.
AU  - Abdel-Aty, M.
AU  - Wu, Y.
TI  - Using Vision Transformers for Spatial-Context-Aware Rain and Road Surface Condition Detection on Freeways
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
SP  - 18546
EP  - 18556
DO  - 10.1109/TITS.2022.3150715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125353337&doi=10.1109%2fTITS.2022.3150715&partnerID=40&md5=30f9b01002133721f58d893cf71913c6
AB  - Inclement weather conditions, particularly heavy rain and the consequent wet road surface, have an unfavorable effect on driving conditions, traffic infrastructure, and operational plans. To mitigate the potentially detrimental ramifications of turbulent weather, it must be continuously monitored in real time and with high geospatial granularity. Traditionally, road weather conditions are monitored using weather forecasts or Roadside Weather Information Systems (RWIS). However, these methods are either ill-equipped or too expensive to provide the required fine-grained observations. Alternatively, roadside traffic CCTV cameras are ubiquitously deployed on US freeways and can serve as inexpensive sensors to surveil weather. In this paper, a novel vision-based methodology is proposed to detect rain and road surface conditions from roadside traffic cameras. Vision Transformers were utilized for image-based classification. They demonstrated superior results compared to convolution-based approaches. Furthermore, the geographical distribution of roadside cameras was leveraged to add spatial context awareness to the detection model. A Spatial Self-Attention network was proposed to model the relationship between the detection results of adjacent images as a sequence-to-sequence detection task. The results indicate that the addition of the sequential detection module improved the accuracy of the stand-alone Vision Transformer as measured by the F1-score. The boost in performance enhanced the F1-scores of the stand-alone Vision Transformer by 5.61% and 5.97% for the rain and road surface condition detection tasks, respectively, raising the total F1-score to 96.71% and 98.07%. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - CCF:B期刊; FMS:B; 
LB  - Abdelraouf2022Using
ER  -

TY  - JOUR
AU  - Bittar, T.
AU  - Carpentier, P.
AU  - Chancelier, J.-P.
AU  - Lonchampt, J.
TI  - A decomposition method by interaction prediction for the optimization of maintenance scheduling
PY  - 2022
T2  - Annals of Operations Research
VL  - 316
IS  - 1
SP  - 229
EP  - 267
DO  - 10.1007/s10479-021-04460-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122866825&doi=10.1007%2fs10479-021-04460-y&partnerID=40&md5=9ff0bd3e93aecd4e3f33f1b70f98eec4
AB  - Optimizing maintenance scheduling is a major issue to improve the performance of hydropower plants. We study a system of several physical components of the same family: either a set of turbines, a set of transformers or a set of generators. The components share a common stock of spare parts and experience random failures that occur according to known failure distributions. We seek a deterministic preventive maintenance strategy that minimizes an expected cost depending on maintenance and forced outages of the system. The Auxiliary Problem Principle is used to decompose the original large-scale optimization problem into a sequence of independent subproblems of smaller dimension while ensuring their coordination. Each subproblem consists in optimizing the maintenance on a single component. Decomposition-coordination techniques are based on variational techniques but the maintenance optimization problem is a mixed-integer problem. Therefore, we relax the dynamics and the cost functions of the system. The resulting algorithm iteratively solves the subproblems on the relaxed system with a blackbox method and coordinates the components. Relaxation parameters have an important influence on the optimization and must be appropriately chosen. An admissible maintenance strategy is then derived from the resolution of the relaxed problem. We apply the decomposition algorithm on a system with 80 components. It outperforms the reference blackbox method applied directly on the original problem. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Bittar2022decomposition
ER  -

TY  - JOUR
AU  - Guo, H.
AU  - Keyvan-Ekbatani, M.
AU  - Xie, K.
TI  - Lane change detection and prediction using real-world connected vehicle data
PY  - 2022
T2  - Transportation Research Part C: Emerging Technologies
VL  - 142
C7  - 103785
DO  - 10.1016/j.trc.2022.103785
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134331760&doi=10.1016%2fj.trc.2022.103785&partnerID=40&md5=a8bc51d3936cb94bc69acd4983550cc6
AB  - Prediction of lane changes (LCs) provides critical information to enhance traffic safety and efficiency in a connected and automated driving environment. It is essential to precisely detect LCs from driving data to lay the groundwork for LC prediction. This study aims to develop LC detection and prediction models using large-scale real-world data collected by connected vehicles (CVs). At first, an autoencoder was used to detect LCs, and proved to be more precise and robust than conventional methods. Next, a transformer-based LC prediction model was developed, which concentrated computation power on key information via an attention mechanism. It outperformed the baseline models in terms of accuracy and computational efficiency. The prediction horizon was also analyzed and LC could be accurately predicted up to two seconds in advance. At last, the transformer model was implemented for real-time prediction and demonstrated a great potential for practical applications. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - FMS:B; 
LB  - Guo2022Lane
ER  -

TY  - JOUR
AU  - Zhang, F.
AU  - Yu, X.
AU  - Keung, J.
AU  - Li, F.
AU  - Xie, Z.
AU  - Yang, Z.
AU  - Ma, C.
AU  - Zhang, Z.
TI  - Improving Stack Overflow question title generation with copying enhanced CodeBERT model and bi-modal information
PY  - 2022
T2  - Information and Software Technology
VL  - 148
C7  - 106922
DO  - 10.1016/j.infsof.2022.106922
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129387733&doi=10.1016%2fj.infsof.2022.106922&partnerID=40&md5=e90c3528ae58e4ceba29cae65f7891b8
AB  - Context: Stack Overflow is very helpful for software developers who are seeking answers to programming problems. Previous studies have shown that a growing number of questions are of low quality and thus obtain less attention from potential answerers. Gao et al. proposed an LSTM-based model (i.e., BiLSTM-CC) to automatically generate question titles from the code snippets to improve the question quality. However, only using the code snippets in the question body cannot provide sufficient information for title generation, and LSTMs cannot capture the long-range dependencies between tokens. Objective: This paper proposes CCBERT, a deep learning based novel model to enhance the performance of question title generation by making full use of the bi-modal information of the entire question body. Method: CCBERT follows the encoder–decoder paradigm and uses CodeBERT to encode the question body into hidden representations, a stacked Transformer decoder to generate predicted tokens, and an additional copy attention layer to refine the output distribution. Both the encoder and decoder perform the multi-head self-attention operation to better capture the long-range dependencies. This paper builds a dataset containing around 200,000 high-quality questions filtered from the data officially published by Stack Overflow to verify the effectiveness of the CCBERT model. Results: CCBERT outperforms all the baseline models on the dataset. Experiments on both code-only and low-resource datasets show the superiority of CCBERT with less performance degradation. The human evaluation also shows the excellent performance of CCBERT concerning both readability and correlation criteria. Conclusion: CCBERT is capable of automatically capturing the bi-modal semantic information from the entire question body and parsing the long-range dependencies to achieve better performance. Therefore, CCBERT is an effective approach for generating Stack Overflow question titles. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2022Improving
ER  -

TY  - JOUR
AU  - Zhang, M.
AU  - Ge, S.
TI  - Vision and Trajectory-Based Dynamic Collision Prewarning Mechanism for Tower Cranes
PY  - 2022
T2  - Journal of Construction Engineering and Management
VL  - 148
IS  - 7
C7  - 04022057
DO  - 10.1061/(ASCE)CO.1943-7862.0002309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130309441&doi=10.1061%2f%28ASCE%29CO.1943-7862.0002309&partnerID=40&md5=93072f24eb92e0c4d91d48580fc06f60
AB  - Tower cranes are very common at construction sites. As workers focus most of their attention on their own tasks, their ability to detect changes in the surrounding environment is reduced, and it is difficult to avoid the collision risk of heavy falling objects. To solve this problem, this study establishes a dynamic collision prewarning mechanism for tower crane construction based on vision and trajectory analysis by tracking and predicting the trajectories of loads and workers. Specifically, the proposed dynamic collision prewarning mechanism consists of three parts. First, Fairmultiple object tracking (FairMOT), a multiple object tracking algorithm based on deep learning, is used to detect and track workers and loads, and time-series data of their positions are obtained. Then a trajectory prediction model based on a transformer is applied to predict the trajectories of objects in the future (10 s) based on the historical data. Finally, safety rules are established by considering the locations, speeds, shapes, and sizes of loads and workers and their trajectories over a period of time. Risk levels for each worker are assigned to reduce the risk of collisions between workers and loads. Finally, the performance of the models is evaluated at a construction site. FairMOT has good tracking performance and can continuously track objects with short occlusion (2 s). Transformer-based trajectory prediction model has higher accuracy than other methods [e.g., social generative adversarial network (GAN), social long short-term memory (LSTM)]. The results of the study show that the proposed method can accurately predict the unsafe approach of workers and loads. The safety prewarning mechanism proposed in this study can help improve the safety of tower crane construction.  © 2022 American Society of Civil Engineers.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - FMS:B; 
LB  - Zhang2022Vision
ER  -

TY  - JOUR
AU  - Tipirneni, S.
AU  - Reddy, C.K.
TI  - Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series
PY  - 2022
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 16
IS  - 6
C7  - 105
DO  - 10.1145/3516367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141150179&doi=10.1145%2f3516367&partnerID=40&md5=48d2524eb134572c41e98fb0a637a63f
AB  - Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at https://github.com/sindhura97/STraTS. © 2022 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 49
C2  - CCF:B期刊; FMS:B; 
LB  - Tipirneni2022Self-Supervised
ER  -

TY  - JOUR
AU  - Zhang, M.
AU  - Wu, S.
AU  - Gao, M.
AU  - Jiang, X.
AU  - Xu, K.
AU  - Wang, L.
TI  - Personalized Graph Neural Networks With Attention Mechanism for Session-Aware Recommendation
PY  - 2022
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 34
IS  - 8
SP  - 3946
EP  - 3957
DO  - 10.1109/TKDE.2020.3031329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095986918&doi=10.1109%2fTKDE.2020.3031329&partnerID=40&md5=29c8c0fe9807286d6724e7a1801c07ee
AB  - The problem of session-aware recommendation aims to predict users' next click based on their current session and historical sessions. Existing session-aware recommendation methods have defects in capturing complex item transition relationships. Other than that, most of them fail to explicitly distinguish the effects of different historical sessions on the current session. To this end, we propose a novel method, named Personalized Graph Neural Networks with Attention Mechanism (A-PGNN) for brevity. A-PGNN mainly consists of two components: one is Personalized Graph Neural Network (PGNN), which is used to extract the personalized structural information in each user behavior graph, compared with the traditional Graph Neural Network (GNN) model, which considers the role of the user when the node embedding is updated. The other is Dot-Product Attention mechanism, which draws on the Transformer net to explicitly model the effect of historical sessions on the current session. Extensive experiments conducted on two real-world data sets show that A-PGNN evidently outperforms the state-of-the-art personalized session-aware recommendation methods.  © 1989-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 77
C2  - CCF:A期刊; FMS:B; 
LB  - Zhang2022Personalized
ER  -

TY  - JOUR
AU  - Colasanto, F.
AU  - Grilli, L.
AU  - Santoro, D.
AU  - Villani, G.
TI  - AlBERTino for stock price prediction: a Gibbs sampling approach
PY  - 2022
T2  - Information Sciences
VL  - 597
SP  - 341
EP  - 357
DO  - 10.1016/j.ins.2022.03.051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126917852&doi=10.1016%2fj.ins.2022.03.051&partnerID=40&md5=d27998ccfe54d02247aebb87e06a8658
AB  - BERT (Bidirectional Encoder Representations from Transformers) is one of the most popular models in Natural Language Processing (NLP) for Sentiment Analysis. The main goal is to classify sentences (or entire texts) and to obtain a score in relation to their polarity: positive, negative or neutral. Recently, a Transformer-based architecture, the fine-tuned AlBERTo (Polignano et al. (2019)), has been introduced to determine a sentiment score in the financial sector through a specialized corpus of sentences. In this paper, we use the sentiment (polarity) score to improve the stocks forecasting. We apply the BERT model to determine the score associated to various events (both positive and negative) that have affected some stocks in the market. The sentences used to determine the scores are newspaper articles published on MilanoFinanza. We compute both the average sentiment score and the polarity, and we use a Monte Carlo method to generate (starting from the day the article was released) a series of possible paths for the next trading days, exploiting the Bayesian inference to determine a new series of bounded drift and volatility values on the basis of the score; thus, returning an exact “directed” price as a result. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; FMS:B; 
LB  - Colasanto2022AlBERTino
ER  -

TY  - JOUR
AU  - Zhang, W.
AU  - Chen, Z.
AU  - Zha, H.
AU  - Wang, J.
TI  - Learning from Substitutable and Complementary Relations for Graph-based Sequential Product Recommendation
PY  - 2022
T2  - ACM Transactions on Information Systems
VL  - 40
IS  - 2
C7  - 3464302
DO  - 10.1145/3464302
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124071771&doi=10.1145%2f3464302&partnerID=40&md5=4ac6dfb860ed58541c73c305993c5fba
AB  - Sequential product recommendation, aiming at predicting the products that a target user will interact with soon, has become a hotspot topic. Most of the sequential recommendation models focus on learning from users' interacted product sequences in a purely data-driven manner. However, they largely overlook the knowledgeable substitutable and complementary relations between products. To address this issue, we propose a novel Substitutable and Complementary Graph-based Sequential Product Recommendation model, namely, SCG-SPRe. The innovations of SCG-SPRe lie in its two main modules: (1) The module of interactive graph neural networks jointly encodes the high-order product correlations in the substitutable graph and the complementary graph into two types of relation-specific product representations. (2) The module of kernel-enhanced transformer networks adaptively fuses multiple temporal kernels to characterize the unique temporal patterns between a candidate product to be recommended and any interacted product in a target behavior sequence. Thanks to the seamless integration of the two modules, SCG-SPRe obtains candidate-dependent user representations for different candidate products to compute the corresponding ranking scores. We conduct extensive experiments on three public datasets, demonstrating SCG-SPRe is superior to competitive sequential recommendation baselines and validating the benefits of explicitly modeling the product-product relations.  © 2021 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:A期刊; FMS:B; 
LB  - Zhang2022Learning
ER  -

TY  - JOUR
AU  - Huang, F.
AU  - Yi, P.
AU  - Wang, J.
AU  - Li, M.
AU  - Peng, J.
AU  - Xiong, X.
TI  - A dynamical spatial-temporal graph neural network for traffic demand prediction
PY  - 2022
T2  - Information Sciences
VL  - 594
SP  - 286
EP  - 304
DO  - 10.1016/j.ins.2022.02.031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125283635&doi=10.1016%2fj.ins.2022.02.031&partnerID=40&md5=fc98108695adc286c0e6d587a89892a9
AB  - Traffic demand prediction is significant and practical in the resource scheduling of transportation application systems. Meanwhile, it remains a challenging topic due to the complexities of contextual effects and the highly dynamic nature of demand. Many works based on graph neural network (GNN) have recently been proposed to cope with this task. However, most previous studies treat the spatial dependence as a static graph, and their inference mechanism lacks interpretability. To address the issues, a Dynamical Spatial-Temporal Graph Neural Network model (DSTGNN) is proposed in this paper. DSTGNN has two critical phases: (1) Creating a spatial dependence graph. To capture the dynamical relationship, we propose building a spatial graph based on the stability of node's spatial dependence. (2) Inferring intensity. We model the changing demand process using the inhomogeneous Poisson process, which addresses the interpretability issue, and build a spatial-temporal embedding network to infer the intensity. Specifically, the spatial-temporal embedding network integrates the diffusion convolution neural network (DCNN) and a modified transformer. Extensive experiments are carried out on two real data sets, and the experimental results demonstrate that the performance of DSTGNN outperforms the state-of-the-art models on traffic demand prediction. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 77
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2022dynamical
ER  -

TY  - JOUR
AU  - Cantini, R.
AU  - Marozzo, F.
AU  - Bruno, G.
AU  - Trunfio, P.
TI  - Learning Sentence-to-Hashtags Semantic Mapping for Hashtag Recommendation on Microblogs
PY  - 2022
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 16
IS  - 2
C7  - 32
DO  - 10.1145/3466876
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114988746&doi=10.1145%2f3466876&partnerID=40&md5=a402694ecfd00ce39fa4f688514f43da
AB  - The growing use of microblogging platforms is generating a huge amount of posts that need effective methods to be classified and searched. In Twitter and other social media platforms, hashtags are exploited by users to facilitate the search, categorization, and spread of posts. Choosing the appropriate hashtags for a post is not always easy for users, and therefore posts are often published without hashtags or with hashtags not well defined. To deal with this issue, we propose a new model, called HASHET (HAshtag recommendation using Sentence-to-Hashtag Embedding Translation), aimed at suggesting a relevant set of hashtags for a given post. HASHET is based on two independent latent spaces for embedding the text of a post and the hashtags it contains. A mapping process based on a multi-layer perceptron is then used for learning a translation from the semantic features of the text to the latent representation of its hashtags. We evaluated the effectiveness of two language representation models for sentence embedding and tested different search strategies for semantic expansion, finding out that the combined use of BERT (Bidirectional Encoder Representation from Transformer) and a global expansion strategy leads to the best recommendation results. HASHET has been evaluated on two real-world case studies related to the 2016 United States presidential election and COVID-19 pandemic. The results reveal the effectiveness of HASHET in predicting one or more correct hashtags, with an average F-score up to 0.82 and a recommendation hit-rate up to 0.92. Our approach has been compared to the most relevant techniques used in the literature (generative models, unsupervised models, and attention-based supervised models) by achieving up to 15% improvement in F-score for the hashtag recommendation task and 9% for the topic discovery task. © 2021 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; FMS:B; 
LB  - Cantini2022Learning
ER  -

TY  - JOUR
AU  - Shao, T.
AU  - Cai, F.
AU  - Chen, W.
AU  - Chen, H.
TI  - Self-supervised clarification question generation for ambiguous multi-turn conversation
PY  - 2022
T2  - Information Sciences
VL  - 587
SP  - 626
EP  - 641
DO  - 10.1016/j.ins.2021.12.040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121925778&doi=10.1016%2fj.ins.2021.12.040&partnerID=40&md5=7ed9ea2d87e44fb0ae3b4c4d0777a62a
AB  - Clarification Question Generation (CQG) aims to automatically generate clarification questions to avoid misunderstanding. In this paper, we focus on generating clarification questions in the scenario of ambiguous multi-turn conversation, which can be well applied to the interactive systems, e.g., dialogue systems and conversational recommendation systems. As a novel direction, limited manual-annotated samples are available for CQG. Moreover, existing approaches mainly ignore the representation of ambiguous semantics and cannot deal with the Out-of-Vocabulary (OOV) problem in a good manner. To address the above issues, we propose a Self-supervised Hierarchical Pointer-generator model (SHiP) for this task. In detail, similar to the backbone Coarse-to-fine process of CQG, we first formulate two self-supervised learning pretext tasks, i.e., Dialogue History Prediction and Entity Name Prediction. Then, we incorporate a hierarchical Transformer mechanism and a pointer-generator mechanism to understand the ambiguous multi-turn conversations and solve the OOV problem. Finally, we propose an end-to-end co-training paradigm to train the pretext tasks and downstream tasks. We quantify the improvements of SHiP against the competitive baselines on a publicly available dataset CLAQUA, showing a general improvement of 6.75% and 3.91% over state-of-the-art baseline in terms of BLEU and ROUGE-L, respectively. © 2021 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; FMS:B; 
LB  - Shao2022Self-supervised
ER  -

TY  - JOUR
AU  - Sun, R.
AU  - An, L.
AU  - Li, G.
AU  - Yu, C.
TI  - Predicting social media rumours in the context of public health emergencies
PY  - 2022
T2  - Journal of Information Science
DO  - 10.1177/01655515221137879
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142854837&doi=10.1177%2f01655515221137879&partnerID=40&md5=a1523905782f7a382764e7b04e24cc7d
AB  - The spread of rumours on social media in the context of public health emergencies often distorts perceptions of public events and obstructs crisis management. Microblog entries about 28 rumour cases are collected on Sina Weibo during the COVID-19 outbreak. The Modality–Agency–Interactivity–Navigability model is used to identify the key factors of rumour prediction. To investigate the relationship among information modality, information content, information source and rumour identification, the binary logistic regression model is established based on the features of users and microblog entries. In addition, we propose a multi-feature rumour prediction model based on the Bidirectional Encoder Representations from Transformers (BERT) and Extreme Gradient Boosting (XGBoost) models. The proposed rumour prediction model has the best performance compared with other models. The feature importance is then calculated by the SHapley Additive exPlanations (SHAP), which can also explain the XGBoost results. It is shown that the likelihood that microblog entries are rumours decreases as the values of variables such as user influence and the positive sentiment of comments rise. Microblog entries posted on Thursdays or at noon are more probably to be rumours than those posted at other time. The proposed model can assist emergency management departments in establishing a feasible rumour prediction mechanism to guide public opinion against rumours. © The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Sun2022Predicting
ER  -

TY  - JOUR
AU  - Mustar, A.
AU  - Lamprier, S.
AU  - Piwowarski, B.
TI  - On the Study of Transformers for Query Suggestion
PY  - 2022
T2  - ACM Transactions on Information Systems
VL  - 40
IS  - 1
C7  - 18
DO  - 10.1145/3470562
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123915257&doi=10.1145%2f3470562&partnerID=40&md5=fbd7f4e9a65c6fca3a969596f8af4918
AB  - When conducting a search task, users may find it difficult to articulate their need, even more so when the task is complex. To help them complete their search, search engine usually provide query suggestions. A good query suggestion system requires to model user behavior during the search session. In this article, we study multiple Transformer architectures applied to the query suggestion task and compare them with recurrent neural network (RNN)-based models. We experiment Transformer models with different tokenizers, with different Encoders (large pretrained models or fully trained ones), and with two kinds of architectures (flat or hierarchic). We study the performance and the behaviors of these various models, and observe that Transformer-based models outperform RNN-based ones. We show that while the hierarchical architectures exhibit very good performances for query suggestion, the flat models are more suitable for complex and long search tasks. Finally, we investigate the flat models behavior and demonstrate that they indeed learn to recover the hierarchy of a search session. © 2021 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:A期刊; FMS:B; 
LB  - Mustar2022On
ER  -

TY  - JOUR
AU  - Stevenson, M.
AU  - Mues, C.
AU  - Bravo, C.
TI  - The value of text for small business default prediction: A Deep Learning approach
PY  - 2021
T2  - European Journal of Operational Research
VL  - 295
IS  - 2
SP  - 758
EP  - 771
DO  - 10.1016/j.ejor.2021.03.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103544993&doi=10.1016%2fj.ejor.2021.03.008&partnerID=40&md5=672fbd733353a8b301ba93614f30a408
AB  - Compared to consumer lending, Micro, Small and Medium Enterprise (mSME) credit risk modelling is particularly challenging, as, often, the same sources of information are not available. Therefore, it is standard policy for a loan officer to provide a textual loan assessment to mitigate limited data availability. In turn, this statement is analysed by a credit expert alongside any available standard credit data. In our paper, we exploit recent advances from the field of Deep Learning and Natural Language Processing (NLP), including the BERT (Bidirectional Encoder Representations from Transformers) model, to extract information from 60,000 textual assessments provided by a lender. We consider the performance in terms of the AUC (Area Under the receiver operating characteristic Curve) and Brier Score metrics and find that the text alone is surprisingly effective for predicting default. However, when combined with traditional data, it yields no additional predictive capability, with performance dependent on the text's length. Our proposed Deep Learning model does, however, appear to be robust to the quality of the text and therefore suitable for partly automating the mSME lending process. We also demonstrate how the content of loan assessments influences performance, leading us to a series of recommendations on a new strategy for collecting future mSME loan assessments. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 56
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Stevenson2021value
ER  -

TY  - JOUR
AU  - Pamuksuz, U.
AU  - Yun, J.T.
AU  - Humphreys, A.
TI  - A Brand-New Look at You: Predicting Brand Personality in Social Media Networks with Machine Learning
PY  - 2021
T2  - Journal of Interactive Marketing
VL  - 56
SP  - 55
EP  - 69
DO  - 10.1016/j.intmar.2021.05.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110120421&doi=10.1016%2fj.intmar.2021.05.001&partnerID=40&md5=2b4b64f0510709deb3c6ba221d4cfc13
AB  - Tools for analyzing social media text data to gain marketing insight have recently emerged. While a wealth of research has focused on automated human personality assessment, little research has focused on advancing methods for obtaining brand personality from social media content. Brand personality is a nuanced aspect of brands that has a consistent set of traits aside from its functional benefits. In this study, we introduce a novel, automated, and generalizable data analytics approach to extract near real-time estimates of brand personalities in social media networks. This method can be used to track attempts to change brand personality over time, measure brand personality of competitors, and assess congruence in brand personality. Applied to consumer data, firms can assess how consumers perceive brand personality and study the effects of brand–consumer congruence in personality. Our approach develops a novel hybrid machine learning algorithmic design (LDA2Vec), which bypasses often extensive manual coding tasks, thus providing an adaptable and scalable tool that can be used for a range of management studies. Our approach enhances the theoretical understanding of channeled and perceived brand personality as it is represented in social media networks and provides practitioners with the ability to foster branding strategies by using big data resources. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Pamuksuz2021Brand-New
ER  -

TY  - JOUR
AU  - Puranam, D.
AU  - Kadiyali, V.
AU  - Narayan, V.
TI  - The impact of increase in minimum wages on consumer perceptions of service: a transformer model of online restaurant reviews
PY  - 2021
T2  - Marketing Science
VL  - 40
IS  - 5
SP  - 985
EP  - 1004
DO  - 10.1287/mksc.2021.1294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118220280&doi=10.1287%2fmksc.2021.1294&partnerID=40&md5=162ae33122d2e30988c252ade6470a07
AB  - We study the impact of a mandated increase in minimum wages on consumer perceptions of multiple dimensions of service quality in the restaurant industry. When faced with higher minimum wages, firms might reduce the number of employees, resulting in poorer consumer service. Alternatively, higher-paid workers might be more motivated to improve consumer service. Using a combination of human annotation and several transformer models, we estimate the incidence of discussion of several service quality attributes (and their valence) in a textual data set of 97,242 online reviews of 1,752 restaurants posted over two years. We exploit a natural experiment in the County of Santa Clara, California, wherein only the city of San Jose legislated a 25% minimum wage increase in 2013. By comparing restaurant reviews in San Jose with those of synthetic controls, we find an improvement in the perceived service quality of San Jose restaurants. Specifically, we find reduced negative discussion of the courtesy and friendliness of workers. This decrease is present in independent restaurants and not in chains. This finding appears to be consistent with agency theory–based predictions of greater incentives to improve service in independent restaurants. We discuss alternative mechanisms for our results. We also discuss implications for consumers, restaurants, and policy makers. © 2021 INFORMS.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - FMS:A; AJG:5; ZUFE:TOP; zdy:5; 
LB  - Puranam2021impact
ER  -

TY  - JOUR
AU  - Lu, Y.
AU  - Luo, J.
AU  - Xiao, Y.
AU  - Zhu, H.
TI  - Text representation model of scientific papers based on fusing multi-viewpoint information and its quality assessment
PY  - 2021
T2  - Scientometrics
VL  - 126
IS  - 8
SP  - 6937
EP  - 6963
DO  - 10.1007/s11192-021-04028-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108666731&doi=10.1007%2fs11192-021-04028-4&partnerID=40&md5=983a6c7b160bf1560f5a1f7c249ee2b5
AB  - Text representation is the preliminary work for in-depth analysis and mining of information in scientific papers. It directly affects the effects of downstream tasks such as, scientific papers classification, clustering, and similarity calculation. However, recent researches mainly considered citation network and partial structural information, which is insufficient when representing scientific papers. Therefore, in order to improve the performance of text representation model, this paper proposed MV-HATrans, a text representation model that combines multi-viewpoint information, such as the semantic information of knowledge graph and structural information. This model extracts word information from three aspects, including contextual content, part of speech, and word meaning of WordNet. Based on combination of hierarchical attention mechanism and transformer, the model achieves the full text representation of scientific papers. Finally, this paper uses the binary experimental dataset AAPR, which indicates whether scientific papers are accepted or not, and applies the proposed model of text representation to achieve the goal of automatic quality assessment. Results show that in the quality classification of scientific papers, adopting part-of-speech information and semantic information based on WordNet definitions can effectively achieve the accuracy of prediction as 70.14%. Among all the structural modules, authors and abstracts contributes the most to the quality classification of scientific papers, especially authors as 9.51%. © 2021, Akadémiai Kiadó, Budapest, Hungary.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Lu2021Text
ER  -

TY  - JOUR
AU  - Lim, B.
AU  - Arık, S.Ö.
AU  - Loeff, N.
AU  - Pfister, T.
TI  - Temporal Fusion Transformers for interpretable multi-horizon time series forecasting
PY  - 2021
T2  - International Journal of Forecasting
VL  - 37
IS  - 4
SP  - 1748
EP  - 1764
DO  - 10.1016/j.ijforecast.2021.03.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107952273&doi=10.1016%2fj.ijforecast.2021.03.012&partnerID=40&md5=acb2f4682854c52ef442cc80bd9123b9
AB  - Multi-horizon forecasting often contains a complex mix of inputs – including static (i.e. time-invariant) covariates, known future inputs, and other exogenous time series that are only observed in the past – without any prior information on how they interact with the target. Several deep learning methods have been proposed, but they are typically ‘black-box’ models that do not shed light on how they use the full range of inputs present in practical scenarios. In this paper, we introduce the Temporal Fusion Transformer (TFT) – a novel attention-based architecture that combines high-performance multi-horizon forecasting with interpretable insights into temporal dynamics. To learn temporal relationships at different scales, TFT uses recurrent layers for local processing and interpretable self-attention layers for long-term dependencies. TFT utilizes specialized components to select relevant features and a series of gating layers to suppress unnecessary components, enabling high performance in a wide range of scenarios. On a variety of real-world datasets, we demonstrate significant performance improvements over existing benchmarks, and highlight three practical interpretability use cases of TFT. © 2021 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 848
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Lim2021Temporal
ER  -

TY  - JOUR
AU  - Lee, W.
AU  - Shi, Y.
AU  - Sun, H.
AU  - Cheng, L.
AU  - Zhang, K.
AU  - Wang, X.
AU  - Chen, Z.
TI  - MSIPA: Multi-Scale Interval Pattern-Aware Network for ICU Transfer Prediction
PY  - 2021
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 16
IS  - 1
C7  - 3458284
DO  - 10.1145/3458284
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111168496&doi=10.1145%2f3458284&partnerID=40&md5=6f83d0754be368697289639223ab8dc9
AB  - Accurate prediction of patients' ICU transfer events is of great significance for improving ICU treatment efficiency. ICU transition prediction task based on Electronic Health Records (EHR) is a temporal mining task like many other health informatics mining tasks. In the EHR-based temporal mining task, existing approaches are usually unable to mine and exploit patterns used to improve model performance. This article proposes a network based on Interval Pattern-Aware, Multi-Scale Interval Pattern-Aware (MSIPA) network. MSIPA mines different interval patterns in temporal EHR data according to the short, medium, and long intervals. MSIPA utilizes the Scaled Dot-Product Attention mechanism to query the contexts corresponding to the three scale patterns. Furthermore, Transformer will use all three types of contextual information simultaneously for ICU transfer prediction. Extensive experiments on real-world data demonstrate that an MSIPA network outperforms state-of-The-Art methods. © 2021 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Lee2021MSIPA
ER  -

TY  - JOUR
AU  - Anukoolthamchote, P.C.
AU  - Assané, D.
AU  - Konan, D.E.
TI  - Net electricity load profiles: Shape and variability considering customer-mix at transformers on the island of Oahu, Hawai'i
PY  - 2020
T2  - Energy Policy
VL  - 147
C7  - 111732
DO  - 10.1016/j.enpol.2020.111732
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089953172&doi=10.1016%2fj.enpol.2020.111732&partnerID=40&md5=394e367eb74e2a11540ef7b46ef28355
AB  - This paper uses data provided by Hawaiian Electric Company (HECO) for the period from September 2010 to May 2014. The study explores the effect of customer mix of each distributed transformer on the shape of load profiles along with their variability. Results suggest that in a more residential-concentrated area, net load generally has two peaks — morning and night, while a more commercial-or industrial-concentrated area exhibits one midday peak. The shape of a given areas’ load profile is mostly influenced by its customer-mix and the time-of-day, while its load volatility is largely the result of weather patterns and the level of PV penetration. Since solar power typically exhibits different generation characteristics from power produced by other conventional sources, more precise solar forecasts enable electric system operators to better manage electricity generation with fluctuating solar output. © 2020 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Anukoolthamchote2020Net
ER  -

TY  - JOUR
AU  - Tófoli, M.F.
AU  - Soler, E.M.
AU  - Balbo, A.R.
AU  - Baptista, E.C.
AU  - Nepomuceno, L.
TI  - Interior/exterior-point methods with inertia correction strategy for solving optimal reactive power flow problems with discrete variables
PY  - 2020
T2  - Annals of Operations Research
VL  - 286
IS  - 1-2
SP  - 243
EP  - 263
DO  - 10.1007/s10479-018-3012-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052641341&doi=10.1007%2fs10479-018-3012-y&partnerID=40&md5=bfbc6591ed2f6c6a84c8661cd3f7f631
AB  - Interior/exterior-point methods have been widely used for solving Optimal Reactive Power Flow problems (ORPF). However, the utilization of such methods becomes difficult when transformer taps and/or capacitor/reactor banks are more rigorously represented in the problem formulation by means of discrete control variables. This work investigates the solution of the ORPF problem when transformer tap ratios are modeled as discrete variables. The solution method proposed handles discrete variables by means of sinusoidal penalty function, while the penalized problems are solved by an exterior-point method. An inertia correction strategy is proposed in order to assure that only local minima are obtained for the penalized problems. New search directions are also investigated that combine predictor and corrector directions. Numerical simulations are performed involving the IEEE 14, 30 and 57 bus systems. The results show the efficiency of the proposed inertia correction strategy and also reveals that the proposed exterior-point method outperforms traditional interior-point methods in terms of the number of iterations and computation times. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Tófoli2020Interior/exterior-point
ER  -

TY  - JOUR
AU  - Alletto, S.
AU  - Abati, D.
AU  - Calderara, S.
AU  - Cucchiara, R.
AU  - Rigazio, L.
TI  - Self-Supervised Optical Flow Estimation by Projective Bootstrap
PY  - 2019
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 20
IS  - 9
C7  - 8506466
SP  - 3294
EP  - 3302
DO  - 10.1109/TITS.2018.2873980
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055709752&doi=10.1109%2fTITS.2018.2873980&partnerID=40&md5=07220224952912e0afa84681fe76fa48
AB  - Dense optical flow estimation is complex and time consuming, with state-of-the-art methods relying either on large synthetic data sets or on pipelines requiring up to a few minutes per frame pair. In this paper, we address the problem of optical flow estimation in the automotive scenario in a self-supervised manner. We argue that optical flow can be cast as a geometrical warping between two successive video frames and devise a deep architecture to estimate such transformation in two stages. First, a dense pixel-level flow is computed with a projective bootstrap on rigid surfaces. We show how such global transformation can be approximated with a homography and extend spatial transformer layers so that they can be employed to compute the flow field implied by such transformation. Subsequently, we refine the prediction by feeding a second, deeper network that accounts for moving objects. A final reconstruction loss compares the warping of frame Xt with the subsequent frame Xt+1 and guides both estimates. The model has the speed advantages of end-to-end deep architectures while achieving competitive performances, both outperforming recent unsupervised methods and showing good generalization capabilities on new automotive data sets. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Alletto2019Self-Supervised
ER  -

TY  - JOUR
AU  - Bell, C.D.
AU  - Tague, C.L.
AU  - McMillan, S.K.
TI  - Modeling Runoff and Nitrogen Loads From a Watershed at Different Levels of Impervious Surface Coverage and Connectivity to Storm Water Control Measures
PY  - 2019
T2  - Water Resources Research
VL  - 55
IS  - 4
SP  - 2690
EP  - 2707
DO  - 10.1029/2018WR023006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063769268&doi=10.1029%2f2018WR023006&partnerID=40&md5=7a51cce2f129f95ccb014edfef665bba
AB  - Urban development of watersheds increases runoff and nitrogen loads by adding urban impervious surfaces and increasing the hydrologic connectivity of these surfaces to streams. Storm water control measures (SCMs) are designed to disrupt this connectivity by retaining water in biologically active depressions where nitrogen retention, transformation, and removal occur. This work applies a mechanistic, spatially distributed, hydroecological model (RHESSys) to a suburban watershed in Charlotte, NC, with 15% total imperviousness (TI) and 33% watershed area mitigated by SCMs. We developed emergent relationships between watershed-scale predictors (TI and connectivity to SCMs) and water and nitrogen response variables (storm water runoff ratios and nitrogen load by species). Results showed that annual runoff ratios were insensitive to increases in connectivity to SCMs (varying by ~1% of rainfall) because SCMs did not substantially increase evaporation but that runoff ratios increased by an average 0.2% per 1% increase in TI due to decreases in transpiration in the watershed. Generally, nitrate loads increased with TI but decreased as more surfaces were mitigated by SCMs. However, these nitrate reductions corresponded to increased export of dissolved organic nitrogen and ammonium. Together, these results indicate that SCMs act as both removers and transformers of nitrogen at the watershed scale. SCMs showed a net assimilation of nitrogen in warm months and net release in cool months, which offset the timing of nitrogen export relative to inputs. This work highlights that using a hydroecological, process-based model reveals both the emergent relationships between watershed condition and response and the processes controlling those relationships. ©2019. American Geophysical Union. All Rights Reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - FMS:B; 
LB  - Bell2019Modeling
ER  -

TY  - JOUR
AU  - Whitfield Aslund, M.L.
AU  - Ollson, C.A.
AU  - Knopper, L.D.
TI  - Projected contributions of future wind farm development to community noise and annoyance levels in ontario, canada
PY  - 2013
T2  - Energy Policy
VL  - 62
SP  - 44
EP  - 50
DO  - 10.1016/j.enpol.2013.07.070
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884989814&doi=10.1016%2fj.enpol.2013.07.070&partnerID=40&md5=6fc04fc32dce694dc3ab351995dff6a5
AB  - Wind turbines produce sound during their operation; therefore, jurisdictions around the world have developed regulations regarding the placement of electricity generating wind farms with the intent of preventing unacceptable levels of 'community noise' in their vicinity. However, as survey results indicate that the relationship between wind turbine noise and annoyance may differ from noise-annoyance relationships for other common noise sources (e.g., rail, traffic), there are concerns that the application of general noise guidelines for wind turbines may lead to unacceptably high levels of annoyance in communities. In this study, previously published survey results that quantified wind turbine noise and self-reported annoyance were applied to the predicted noise levels (from turbines and transformers) for over 8000 receptors in the vicinity of 13 planned wind power developments in the province of Ontario, Canada. The results of this analysis indicate that the current wind turbine noise restrictions in Ontario will limit community exposure to wind turbine related noise such that levels of annoyance are unlikely to exceed previously established background levels of noise-related annoyance from other common noise sources. This provides valuable context that should be considered by policy-makers when evaluating the potential impacts of wind turbine noise on the community. © 2013 Elsevier Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - FMS:B; AJG:2; zdy:2; 
LB  - Whitfield Aslund2013Projected
ER  -

TY  - JOUR
AU  - Sultana, S.
AU  - Chen, Z.
TI  - Modeling flood induced interdependencies among hydroelectricity generating infrastructures
PY  - 2009
T2  - Journal of Environmental Management
VL  - 90
IS  - 11
SP  - 3272
EP  - 3282
DO  - 10.1016/j.jenvman.2009.05.019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-69249229504&doi=10.1016%2fj.jenvman.2009.05.019&partnerID=40&md5=b23a0e3a5b8718eaddf9f3735830aa0c
AB  - This paper presents a new kind of integrated modeling method for simulating the vulnerability of a critical infrastructure for a hazard and the subsequent interdependencies among the interconnected infrastructures. The developed method has been applied to a case study of a network of hydroelectricity generating infrastructures, e.g., water storage concrete gravity dam, penstock, power plant and transformer substation. The modeling approach is based on the fragility curves development with Monte Carlo simulation based structural-hydraulic modeling, flood frequency analysis, stochastic Petri net (SPN) modeling, and Markov Chain analysis. A certain flood level probability can be predicted from flood frequency analysis, and the most probable damage condition for this hazard can be simulated from the developed fragility curves of the dam. Consequently, the resulting interactions among the adjacent infrastructures can be quantified with SPN analysis; corresponding Markov Chain analysis simulates the long term probability matrix of infrastructure failures. The obtained results are quite convincing to prove the novel contribution of this research to the field of infrastructure interdependency analysis which might serve as a decision making tool for flood related emergency response and management. © 2009 Elsevier Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - FMS:B; 
LB  - Sultana2009Modeling
ER  -

TY  - JOUR
AU  - Hong, Y.
AU  - Meeker, W.Q.
AU  - McCalley, J.D.
TI  - Prediction of remaining life of power transformers based on left truncated and right censored lifetime data
PY  - 2009
T2  - Annals of Applied Statistics
VL  - 3
IS  - 2
SP  - 857
EP  - 879
DO  - 10.1214/00-AOAS231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954789389&doi=10.1214%2f00-AOAS231&partnerID=40&md5=c041b3abdc53d68fe8c6dddd27791a7b
AB  - Prediction of the remaining life of high-voltage power transformers is an important issue for energy companies because of the need for planning maintenance and capital expenditures. Lifetime data for such transformers are complicated because transformer lifetimes can extend over many decades and transformer designs and manufacturing practices have evolved. We were asked to develop statistically-based predictions for the lifetimes of an energy company's fleet of high-voltage transmission and distribution transformers. The company's data records begin in 1980, providing information on installation and failure dates of transformers. Although the dataset contains many units that were installed before 1980, there is no information about units that were installed and failed before 1980. Thus, the data are left truncated and right censored. We use a parametric lifetime model to describe the lifetime distribution of individual transformers. We develop a statistical procedure, based on age-adjusted life distributions, for computing a prediction interval for remaining life for individual transformers now in service. We then extend these ideas to provide predictions and prediction intervals for the cumulative number of failures, over a range of time, for the overall fleet of transformers. © Institute of Mathematical Statistics, 2009.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 131
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Hong2009Prediction
ER  -

TY  - JOUR
AU  - Barrios, E.
TI  - Soil biota, ecosystem services and land productivity
PY  - 2007
T2  - Ecological Economics
VL  - 64
IS  - 2
SP  - 269
EP  - 285
DO  - 10.1016/j.ecolecon.2007.03.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-36549064652&doi=10.1016%2fj.ecolecon.2007.03.004&partnerID=40&md5=be13442afa1ff3720627db3fe90bd659
AB  - The soil environment is likely the most complex biological community. Soil organisms are extremely diverse and contribute to a wide range of ecosystem services that are essential to the sustainable function of natural and managed ecosystems. The soil organism community can have direct and indirect impacts on land productivity. Direct impacts are those where specific organisms affect crop yield immediately. Indirect effects include those provided by soil organisms participating in carbon and nutrient cycles, soil structure modification and food web interactions that generate ecosystem services that ultimately affect productivity. Recognizing the great biological and functional diversity in the soil and the complexity of ecological interactions it becomes necessary to focus in this paper on soil biota that have a strong linkage to functions which underpin 'soil based' ecosystem services. Selected organisms from different functional groups (i.e. microsymbionts, decomposers, elemental transformers, soil ecosystem engineers, soil-borne pest and diseases, and microregulators) are used to illustrate the linkages of soil biota and ecosystem services essential to life on earth as well as with those associated with the provision of goods and the regulation of ecosystem processes. These services are not only essential to ecosystem function but also a critical resource for the sustainable management of agricultural ecosystems. Research opportunities and gaps related to methodological, experimental and conceptual approaches that may be helpful to address the challenge of linking soil biodiversity and function to the provision of ecosystem services and land productivity are discussed. These include: 1) integration of spatial variability research in soil ecology and a focus on 'hot spots' of biological activity, 2) using a selective functional group approach to study soil biota and function, 3) combining new and existing methodological approaches that link selected soil organisms, the temporal and spatial dynamics of their function, and their contribution to the provision of selected 'soil based' ecosystem services, 4) using understanding about hierarchical relationships to manage soil biota and function in cropping systems, 5) using local knowledge about plants as indicators of soil quality, remote sensing and GIS technologies, and plant-soil biota interactions to help understand the impacts of soil biota at landscape scale, and 6) developing land quality monitoring systems that inform land users about their land's ecosystem service performance, improve capacities to predict and adapt to environmental changes, and support policy and decision-making. © 2007 Elsevier B.V. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 684
C2  - FMS:A; AJG:3; zdy:3; 
LB  - Barrios2007Soil
ER  -

TY  - JOUR
AU  - Pedregal, D.J.
AU  - Young, P.C.
TI  - Modulated cycles, an approach to modelling periodic components from rapidly sampled data
PY  - 2006
T2  - International Journal of Forecasting
VL  - 22
IS  - 1
SP  - 181
EP  - 194
DO  - 10.1016/j.ijforecast.2005.03.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-31744433149&doi=10.1016%2fj.ijforecast.2005.03.001&partnerID=40&md5=0adfec3cdd8c61004d461f9d1f9fe2a7
AB  - Unobserved components models provide a natural framework for the estimation and forecasting of periodic components embedded in the time series, such as business cycles or seasonality. However, periodic behaviour can be complicated to analyse when dealing with rapidly sampled data of the kind encountered in electricity demand forecast problems. Data of this nature tend to show a multiplicity of superimposed periodic patterns, including annual, weekly and daily cycles. In this paper, we present a new seasonal component model based on modulated periodic components, which is capable of replicating multiplicative periodic components in an efficient manner, in the sense that the number of parameters in the model is much lower than in a standard unobserved components model without modulation. The model performance compares favourably with respect to standard techniques on a rolling forecasting exercise based on actual hourly electricity load demand data at a certain transformer in the UK. © 2005 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - FMS:B; AJG:3; zdy:3; 
LB  - Pedregal2006Modulated
ER  -

TY  - JOUR
AU  - Anderson, M.R.
AU  - Pankow, J.F.
TI  - A Case Study of a Chemical Spill: Polychlorinated Biphenyls (PCBs): 3. PCB Sorption and Retardation in Soil Underlying the Site
PY  - 1986
T2  - Water Resources Research
VL  - 22
IS  - 7
SP  - 1051
EP  - 1057
DO  - 10.1029/WR022i007p01051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0022751604&doi=10.1029%2fWR022i007p01051&partnerID=40&md5=447e39b5a045c83dfa53cfce7854c59e
AB  - Condie silt from near a polychlorinated biphenyls (PCBs) and chlorinated benzenes spill site was studied with respect to the sorption and predicted retardation of these compounds. The soil organic carbon fraction (foc) of the silt was measured to be 0.0036 ± 0.00088. The sorption partition coefficient (Kp′ milliliters/gram) values were: 2,2′,5,5′‐tefrachlorobiphenyl (4‐PCB), 5000; 2,2′,4,5,5′‐pentachlorobiphenyl (5‐PCB), 9400; and 2,2′,4,4′,5,5′‐hexachlorobiphenyl (6‐PCB), 26,000. The direct measurement of the Kp values allowed an improved estimation of sorption over that possible with the measured foc and the available literature Koc data. Mean transport retardation factors (R) for 4‐PCB, 5‐PCB, and 6‐PCB in saturated silt were calculated to be 2.7 E + 04, 5.0 E + 04, and 1.4 E + 05, respectively. This implies that dissolved PCBs will move only very slowly through unfractured Condie silt. Since the Kp values of the PCBs were not affected when 20 mg/L of 1,2,4‐trichlorobenzene was added to the aqueous phase, PCB transport at the site will not be accelerated by the presence of the chlorinated benzenes. Therefore if fractures are not present in the silt in its middle and lower levels, then there is little chance that the PCBs pose a threat to the underlying Regina aquifer system. R values predicted for 1,2,4‐trichlorobenzene and 1,2,4,5‐tetrachlorobenzene were 120 and 600, respectively; they may also not pose an immediate threat to the underlying aquifer if fractures are absent. Copyright 1986 by the American Geophysical Union.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - FMS:B; 
LB  - Anderson1986Case
ER  -
