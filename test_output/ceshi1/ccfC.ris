TY  - JOUR
AU  - Acharyya, S.
AU  - Pervin, N.
TI  - Enhancing cross-domain recommendations: Leveraging personality-based transfer learning with probabilistic matrix factorization
PY  - 2025
T2  - Expert Systems with Applications
VL  - 263
C7  - 125667
DO  - 10.1016/j.eswa.2024.125667
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208967782&doi=10.1016%2fj.eswa.2024.125667&partnerID=40&md5=b65d39c34833fc7c5ccb6923623cff84
AB  - The conventional method of computing personality scores through extensive questionnaire-based surveys poses practical challenges in real-world scenarios. An alternate route is to predict personality scores from user reviews by analysing various linguistic features such as writing style, word choices, and specific phrases. However, the reviews are domain-dependent and classification models trained on one domain cannot be readily applied to other domains. To mitigate this challenge, we propose a cross-domain recommendation framework called PEMF-CD which leverages a novel mixing strategy to integrate user reviews from multiple domains with common joint embedding space and predict user personality scores using a transformer model. By capturing the underlying semantics and latent representations within the textual data, the transformer architecture can effectively model the linguistic cues to infer users’ personality traits, and the learning is transferred across domains. To further enhance the recommendation process, our model integrates personality-wise and rating pattern-based similarities of users into a probabilistic matrix factorization method that fosters user neighbourhoods based on similarity scores among users. Comprehensive experiments were conducted using five real-world datasets from TripAdvisor and Amazon with varied numbers of users, items, and reviews of up to 44,187, 26,386, and 426,791, respectively. The performance has been benchmarked against thirteen baseline algorithms and the experimental results demonstrate a significant improvements of up to 24.72%, 64.28%, 48.79%, and 61% in RMSE, and 55.9%, 76.7%, 67.6%, and 71.5% in MAE for a 90:10 train–test split with Digital Music, Fashion, Magazine Subscriptions and Video Games datasets from Amazon, respectively. Similar results have been observed for the 80:20 train–test split. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Acharyya2025Enhancing
ER  -

TY  - JOUR
AU  - Dong, Y.
AU  - Han, C.
AU  - Zhao, C.
AU  - Madan, A.
AU  - Mohanty, L.
AU  - Yang, Y.
TI  - Multi-Context enhanced Lane-Changing prediction using a heterogeneous Graph Neural Network
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125902
DO  - 10.1016/j.eswa.2024.125902
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210122528&doi=10.1016%2fj.eswa.2024.125902&partnerID=40&md5=3887b8906ab1c551f70c3670c3d5b8c9
AB  - Lane-changing Prediction (LCP) is crucial in defining vehicle movement in Microscopic Traffic Load Simulation (MTLS), impacting the distribution of traffic load on bridge decks. Despite their simplicity, existing physics-based approaches are subjective and deterministic, resulting in low fidelity in reflecting real-world scenarios. Current data-driven methods attempt to address this but only consider the trajectories of the subject vehicle and adjacent vehicles, neglecting other relevant contexts and thus compromising prediction accuracy. This study introduces LaneMCGNN, a multi-context enhanced graph neural network model for lane-changing prediction. The model integrates contextual features from spatial-temporal trajectories, vehicle types, and semantic maps, employing multi-attention mechanisms and Transformer modules to enhance feature extraction from these contexts. A lightweight Convolutional Neural Network (CNN) is utilized for efficient feature extraction from semantic maps of bridge decks. Trained and evaluated on an open-access dataset, our model achieves an accuracy of 98.928%, an F1-score of 0.989, and an Area Under Curve (AUC) of 0.999. Comparative discussions and ablation tests underscore the superiority of our model and the importance of incorporating multiple contexts. The proposed model can significantly enhance MTLS by improving the prediction of lane-keeping and lane-changing behaviors of vehicles, thereby increasing the precision of performance assessment for bridge components. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Dong2025Multi-Context
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Yang, S.
AU  - Zhao, H.
AU  - Chen, Y.
TI  - A crisis event classification method based on a multimodal multilayer graph model
PY  - 2025
T2  - Neurocomputing
VL  - 621
C7  - 129271
DO  - 10.1016/j.neucom.2024.129271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214299110&doi=10.1016%2fj.neucom.2024.129271&partnerID=40&md5=5c55737b0747147064c0fcbcd195a01b
AB  - Quickly obtaining and classifying relevant information about crisis events via social media platforms, such as Twitter and Weibo, plays a critical role in the subsequent rescue operations and post-disaster reconstruction. Current crisis event classification technologies are unable to comprehensively acquire data and are not applicable to a wide range of scenarios. To address this issue, this paper proposes a crisis event prediction method based on a multi-information multimodal deep graph model. Exploring multimodal graph information innovatively and deeply enhances the effectiveness and broadens the applicability of predicting crisis events. First, Bi-LSTM and a GCN structure based on word graphs are used to obtain the sentence and grammatical information of the text, constructing a text feature vector. The image feature vector is constructed by combining a CNN and a Transformer. Second, a graph of the text group and a graph of the image group are constructed on the basis of cosine similarity, and a multilayer structure combining autoencoders and a GCN is used to mine the integrated information of the data. Finally, multimodal feature vectors are converted into a multimodal semantic network, and a multilayer GCN structure with an attention mechanism is employed for crisis event classification prediction. The experimental results on the CrisisMMD dataset and its generated datasets demonstrate that the proposed model outperforms the current state-of-the-art models. © 2025 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2025crisis
ER  -

TY  - JOUR
AU  - Hosseinimanesh, G.
AU  - Alsheghri, A.
AU  - Keren, J.
AU  - Cheriet, F.
AU  - Guibault, F.
TI  - Personalized dental crown design: A point-to-mesh completion network
PY  - 2025
T2  - Medical Image Analysis
VL  - 101
C7  - 103439
DO  - 10.1016/j.media.2024.103439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212544114&doi=10.1016%2fj.media.2024.103439&partnerID=40&md5=03b98f5e73d601f5ac9fce1360fa7722
AB  - Designing dental crowns with computer-aided design software in dental laboratories is complex and time-consuming. Using real clinical datasets, we developed an end-to-end deep learning model that automatically generates personalized dental crown meshes. The input context includes the prepared tooth, its adjacent teeth, and the two closest teeth in the opposing jaw. The training set contains this context, the ground truth crown, and the extracted margin line. Our model consists of two components: First, a feature extractor converts the input point cloud into a set of local feature vectors, which are then fed into a transformer-based model to predict the geometric features of the crown. Second, a point-to-mesh module generates a dense array of points with normal vectors, and a differentiable Poisson surface reconstruction method produces an accurate crown mesh. Training is conducted with three losses: (1) a customized margin line loss; (2) a contrastive-based Chamfer distance loss; and (3) a mean square error (MSE) loss to control mesh quality. We compare our method with our previously published method, Dental Mesh Completion (DMC). Extensive testing confirms our method's superiority, achieving a 12.32% reduction in Chamfer distance and a 46.43% reduction in MSE compared to DMC. Margin line loss improves Chamfer distance by 5.59%. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hosseinimanesh2025Personalized
ER  -

TY  - JOUR
AU  - Fu, S.
AU  - Jia, Y.
AU  - Lin, L.
AU  - Suo, S.
AU  - Guo, F.
AU  - Zhang, S.
AU  - Liu, Y.
TI  - PSTFormer: A novel parallel spatial-temporal transformer for remaining useful life prediction of aeroengine
PY  - 2025
T2  - Expert Systems with Applications
VL  - 265
C7  - 125995
DO  - 10.1016/j.eswa.2024.125995
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211327421&doi=10.1016%2fj.eswa.2024.125995&partnerID=40&md5=d026b7d1465ccac8e96ec26118bd0b5a
AB  - One of the significant tasks in aeroengine remaining useful life (RUL) prediction is to address both temporal dependencies and spatial dependencies in multivariate time series (MTS) monitoring data. However, it is difficult for traditional transformer-based methods simultaneously extract both temporal and spatial dependencies due to their mutual interference, limiting the further improvement of prediction performance. To address these issues, this paper proposes a novel Parallel Spatial-Temporal Transformer (PSTFormer) for aeroengine RUL prediction with multi-sensor monitoring data. First, a novel parallel spatial–temporal attention mechanism (PSTAM) is designed, which consists of a temporal attention module (TAM) and a spatial attention module (SAM), to simultaneously capture temporal and spatial dependencies from MTS data. TAM employs multiscale convolution to learn the temporal dependencies at different time scales, while SAM adopts a self-attention mechanism to learn the spatial dependencies among different sensor parameter. Parallel connection between TAM and SAM can effectively avoid the mutual interference between temporal and spatial dependencies, improving the modeling ability of complex spatiotemporal relationships. Second, a task-guided spatiotemporal feature fusion (TG-STFF) module is designed, which adaptively fuses temporal and spatial features according to downstream task. Specifically, based on the RUL prediction characteristic, TG-STFF converts spatial features into attention weights and fuses them with temporal features to extract more representative degradation features. Finally, the effectiveness of PSTFormer is validated by a series of experimental comparisons on the public C-MAPSS dataset. Compared with SOTA methods, PSTFormer exhibits more outstanding prediction performance, and it can effectively address the aforementioned challenges in RUL prediction tasks. Therfore, the development of PSTFormer provides an innovative and effective method for aeroengine RUL prediction, significantly enhancing the efficiency and safety of aeroengine maintenance and operation. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Fu2025PSTFormer
ER  -

TY  - JOUR
AU  - Andreopoulos, W.B.
AU  - Lopez, D.
AU  - Rojas, C.
AU  - Bhandare, V.P.
TI  - Finding BERT errors by clustering activation vectors
PY  - 2025
T2  - Future Generation Computer Systems
VL  - 166
C7  - 107601
DO  - 10.1016/j.future.2024.107601
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212039029&doi=10.1016%2fj.future.2024.107601&partnerID=40&md5=337222a2b50141490ecfaf3a2eb8274b
AB  - The non-linear nature of deep neural networks makes it difficult to interpret the reason behind their output, thus reducing verifiability of the system where these models are applied. Understanding the patterns between activation vectors and predictions could give insight as to erroneous classifications and how to identify them. This paper explains a systematic approach to identifying the clusters with the most misclassifications or false label annotations. For this research, we extracted the activation vectors from a deep learning model, DNABERT, and visualized them using t-SNE to decode the reason behind the results that are produced. We applied K-means in a hierarchical fashion on the activation vectors for a set of training instances. We analyzed cluster mean activation vectors to find any patterns in the errors across K-means clusters. The cluster analysis revealed that the predictions were uniform, or nearly 100 percent the same, in clusters of similar activation vectors. It was found that two clusters containing most of their objects belonging to the same true class tend to be closer together than clusters of opposite classes. The means of objects of the same true label are closer if two clusters have the same predicted labels rather than opposite predicted labels, showing that the activation vectors reflect both predicted and true classes. We did a similar analysis for all 26 organisms in the dataset, showing the Euclidean distance can be used for identifying clusters with many errors. We propose a heuristic to find the clusters with a high number of misclassifications or incorrect label annotations using the vector analysis between clusters. This can aid in identifying misclassifications of DNA sequences or problems with sequence tagging. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Andreopoulos2025Finding
ER  -

TY  - JOUR
AU  - Xia, Z.
AU  - Zhao, Y.
AU  - Gu, J.
AU  - Wang, W.
AU  - Zhang, W.
AU  - Huang, Z.
TI  - FC-DETR: High-precision end-to-end surface defect detector based on foreground supervision and cascade refined hybrid matching
PY  - 2025
T2  - Expert Systems with Applications
VL  - 266
C7  - 126142
DO  - 10.1016/j.eswa.2024.126142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212132805&doi=10.1016%2fj.eswa.2024.126142&partnerID=40&md5=fce8225ee4913faa047f96a36fa970e5
AB  - Surface defect detection plays a vital role in modern industry product quality control. However, due to the large variation in the shape and scale of defects, achieving accurate detection is a great challenge. Existing CNN-based detection methods perform well in local modeling, but it is difficult to extract accurate features when dealing with defects with significant changes in shape and scale. To overcome these challenges, this paper leverages the long-range dependency modeling advantages of the Transformer architecture and proposes an innovative end-to-end detection network named FC-DETR. Firstly, a foreground supervision module (FSM) is introduced to enhance the focus on foreground defect features and reduce the computational of the encoder. Secondly, a cascade refined hybrid matching (CRHM) strategy is proposed to increase the number of positive samples during training and avoid NMS post-processing in predicting. Thirdly, the IA-BCELoss is introduced as the classification loss function, coupling classification scores with the IoU of predicted and ground truth boxes to obtain high-quality detection boxes. Finally, the effectiveness and advancement of the proposed method are validated on three public defect detection datasets: NEU-DET, GC10-DET, and PCB defect dataset. The experimental results show that the mAP50 of the proposed method on NEU-DET, GC10-DET, and PCB datasets is 83.7%, 83.6%, and 98.7%, respectively. Compared with the CNN-based detection method, it is significantly improved. Ablation experiments further verify the effectiveness of the proposed modules. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Xia2025FC-DETR
ER  -

TY  - JOUR
AU  - Du, P.
AU  - Ye, Y.
AU  - Wu, H.
AU  - Wang, J.
TI  - Study on deterministic and interval forecasting of electricity load based on multi-objective whale optimization algorithm and transformer model
PY  - 2025
T2  - Expert Systems with Applications
VL  - 268
C7  - 126361
DO  - 10.1016/j.eswa.2024.126361
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214295661&doi=10.1016%2fj.eswa.2024.126361&partnerID=40&md5=5df4944ccac357f3e118ce4de01a6f43
AB  - Scientific and accurate electricity load forecasting is crucial for realizing effective power dispatch and ensuring the security, reliability and economy of power system operation. To this end, this research proposes a hybrid framework using data processing and analysis methods, deep learning and a multi-objective optimization algorithm. The framework includes four modules: data processing and mining module, optimization module, forecasting module, and evaluation module. Specifically, in the data processing and mining module, a longitudinal data selection method is used to extract sequence similarity features, while distribution functions are applied to capture the statistical properties of the data. In the optimization module, the multi-objective whale optimization algorithm is adopted to fine-tune the hyperparameters of the Transformer model to construct an optimized Transformer model. In the forecasting module, deterministic and uncertainty predictions of the developed model and comparison methods are carried out using two electricity load datasets to get the final predicted values. Furthermore, in the evaluation module, several deterministic prediction evaluation metrics and three uncertainty evaluation metrics are introduced to evaluate the prediction abilities of the methods. Ultimately, the numerical results display that compared with the optimal benchmark model, the developed model using two datasets can enhance the improvement percentage of mean absolute percentage error by 35.9327% and 23.7584%, respectively, which demonstrates its higher prediction performance than benchmark models, improves the prediction accuracy of electricity load, and provides valuable insights and references for other energy prediction fields. © 2025 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Du2025Study
ER  -

TY  - JOUR
AU  - He, C.
AU  - Yang, C.
AU  - Zhang, H.
AU  - Long, Y.
AU  - Zhao, X.
TI  - DTI-MPFM: A multi-perspective fusion model for predicting potential drug–target interactions
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125740
DO  - 10.1016/j.eswa.2024.125740
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210123875&doi=10.1016%2fj.eswa.2024.125740&partnerID=40&md5=0c4f11447d14efe8dd78963e9c597e59
AB  - The prediction of potential drug–target interactions (DTIs) is the use of computational methods to estimate the likelihood of binding between drug molecules and biological targets (such as proteins, enzymes, ion channels, etc.). Existing methods typically use the chemical structure and molecular properties of drugs, as well as the sequence and three-dimensional structural features of proteins. These features are converted into low-dimensional dense vectors using deep learning methods (e.g. GCN and word2vec) and then fed into a fully connected neural network to predict the probability of interaction between drug molecules and biological targets. However, these methods struggle to simultaneously capture local and global drug–target features, and cannot exploit the complex topological relationships in drug–target interaction networks. This study proposes a multi-perspective fusion model for predicting potential drug–target interactions (DTI-MPFM). First, a multimodal drug–target knowledge graph (BBDKG) is constructed and complex topological information is extracted using Rescal. Next, the SMILES (Simplified Molecular Input Line Entry System) of drugs and protein sequences are re-encoded using a character dictionary encoding method. CNN and Transformer are then used to extract local and global features respectively. Finally, in order to obtain high-order interaction information between sparse characteristics and determine the likelihood of drug–target binding, linear fusion is employed. According to experimental results, DTI-MPFM performs more than 1% better than baseline models on the BBDKG dataset across a number of parameters. Source code and datasets are available at https://github.com/pole-min/DTI-MPFM. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - He2025DTI-MPFM
ER  -

TY  - JOUR
AU  - Dong, H.
AU  - Wu, J.
AU  - Xing, C.
AU  - Xi, H.
AU  - Cui, H.
AU  - Zhu, J.
TI  - Treasure in the background: Improve saliency object detection by self-supervised contrast learning
PY  - 2025
T2  - Expert Systems with Applications
VL  - 267
C7  - 126244
DO  - 10.1016/j.eswa.2024.126244
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213222149&doi=10.1016%2fj.eswa.2024.126244&partnerID=40&md5=1baed278f67f867d8c839544fba210c1
AB  - Salient object detection (SOD) is a critical task in computer vision, aimed at identifying visually striking regions within images. Existing SOD methods predict saliency maps in a supervised manner that heavily relies on labels. These methods have the following challenges: (1) Poor boundary detection when the salient objects closely resemble the backgrounds; (2) High false positives caused by more focus on objects and less on the surroundings. Therefore, it is crucial to develop better solutions to improve the comprehensiveness and precision of SOD results. Inspired by findings from a pilot study, which revealed that supervised learning tends to focus on prominent regions but neglects background information around objects, while self-supervised learning captures more comprehensive details, we introduce self-supervised contrast learning into the SOD framework. We design image-level contrast learning and pixel-level contrast learning for the SOD models with Token to Token Vision Transformer (T2T) and Vision Graph Neural Network (ViG) backbone. In fact, our approach is backbone-agnostic and can be applied as a plugin to any model. We conduct comprehensive comparison and ablation experiments on both RGB natural image datasets and medical image datasets to evaluate our method, the experimental results demonstrate that our method outperforms state-of-the-art methods consistently. Most importantly, our method not only provides a new perspective for the SOD task but also shows a new paradigm for other dense prediction tasks. Code is available at https://github.com/msctransu/SCL_SOD.git. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Dong2025Treasure
ER  -

TY  - JOUR
AU  - Aghaomidi, P.
AU  - Mirzaei, F.
AU  - Bahmani, Z.
TI  - MSLSNet: A combination of multi-task self-supervised learning and Swin transformer network for face and keypoint detection in thermal images
PY  - 2025
T2  - Expert Systems with Applications
VL  - 268
C7  - 126238
DO  - 10.1016/j.eswa.2024.126238
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213551642&doi=10.1016%2fj.eswa.2024.126238&partnerID=40&md5=ca06b1c3a54d82f2b723ef11694113ce
AB  - Accurate tracking in thermal images is critical for applications such as surveillance, authentication, and healthcare diagnostics, which rely on reliable face and facial keypoint detection. However, the scarcity of annotated thermal datasets poses a major challenge, reducing detection performance. Therefore, we introduced a multi-task self-supervised learning approach with a hybrid model, combining convolutional neural networks and transformers, tailored to enhance feature extraction in thermal images, even with limited data. Our convolutional-based model employed four pretext tasks—gender and subject classification, rotation prediction, and image inpainting. These tasks enabled learning intricate facial structures without face and keypoint annotations, generalizing effectively to diverse and unseen data. For face detection, we pretrained the model on these tasks and used fully connected. For keypoint detection, we used the pretrained model alongside a Swin transformer in a parallel configuration where these models worked simultaneously to leverage local and global features for improved accuracy. Fully connected layers were used to capture spatial relationships for accurate feature mapping in keypoint detection. By combining convolutional networks for local features and transformers for global context, the models demonstrated strong generalization. The models achieved an intersection over union (IoU) of 0.92 for face detection and a normalized mean error of 1.36 for keypoint detection, representing a 35.24 % improvement over the best-reported results. Additionally, our face detection algorithm identified 80 % of faces with a high IoU (>0.9), compared to 20 % by prior methods on a Thermal dataset. These results highlight the robustness of our approach, making it suitable for real-world applications. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Aghaomidi2025MSLSNet
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - He, W.
AU  - Cui, L.
AU  - Xu, Y.
AU  - Guo, W.
AU  - Feng, Z.
TI  - A capsule-based reinforcement learning framework for supply–demand matching in mobile crowdsourcing
PY  - 2025
T2  - Expert Systems with Applications
VL  - 267
C7  - 126203
DO  - 10.1016/j.eswa.2024.126203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213080552&doi=10.1016%2fj.eswa.2024.126203&partnerID=40&md5=f4f4cab127284805dd415ddb76409894
AB  - Mobile crowdsourcing services such as taxi and food delivery are playing an increasingly indispensable role in people's daily lives. Due to the complexity and dynamism in mobile scenarios, it is difficult to predict the trajectories and behavioral patterns of service providers and requesters in different regions at different times for effective scheduling in crowdsourcing platforms. The imbalance between supply and demand in different sub-regions has affected the sustainable operation of crowdsourcing services. To address this issue, we propose a capsule-based actor–critic reinforcement learning framework to achieve balanced supply and demand of mobile crowdsourcing services across multiple sub-regions. The framework includes a capsule network-based actor–critic reinforcement learning model and a willingness prediction model, which can continuously adjust the distribution between the supply and demand of mobile crowdsourcing services while taking into account the participants’ daily trajectory preferences, thus improving the experience and satisfaction of mobile crowdsourcing participants and facilitating the sustainable operation of the platform. The proposed framework has been validated on several real-world mobile crowdsourcing datasets for its effectiveness. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2025capsule-based
ER  -

TY  - JOUR
AU  - Gou, Z.
AU  - Long, Y.
AU  - Sun, J.
AU  - Gao, K.
TI  - TG-ERC: Utilizing three generation models to handle emotion recognition in conversation tasks
PY  - 2025
T2  - Expert Systems with Applications
VL  - 268
C7  - 126269
DO  - 10.1016/j.eswa.2024.126269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213278018&doi=10.1016%2fj.eswa.2024.126269&partnerID=40&md5=d720e56c47ffa36b2a8491562afcbd9c
AB  - The ongoing advancement of intelligent dialogue systems has led to the widespread utilization of emotion recognition in various domains including healthcare, education and human resources, particularly in dialogue settings, garnering significant interest from researchers. However, existing models are unable to fully exploit the potential correlation between topic and emotion. Furthermore, it has been demonstrated that merely relying on a single generative model to understand the context content is insufficient. This paper introduces a novel framework, TG-ERC, which combines three distinct generative models to enhance emotion recognition in conversation. These models are utilized to extract topic, emotion, and external knowledge information from utterances. Initially, a pre-trained language model and a topic detection layer are employed to derive topic representation. Subsequently, this representation is fed into a conditional variational autoencoder to capture latent variables associated with emotion. Finally, the emotion recognition utilizing Transformer architecture and incorporating common sense knowledge is developed to predict emotions by integrating knowledge, emotion, and topic information. Experimental results on DailyDialog, MELD, IEMOCAP, and EmoryNLP datasets demonstrate that the proposed method outperforms baselines. The TG-ERC code is publicly available further exploration. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Gou2025TG-ERC
ER  -

TY  - JOUR
AU  - Haridasan, V.
AU  - Hariharanath, K.
AU  - Muthukumaran, K.
TI  - Gazelle optimization and conditional variational auto encoder for telecom user service recommendation based on churn analysis
PY  - 2025
T2  - Expert Systems with Applications
VL  - 267
C7  - 126199
DO  - 10.1016/j.eswa.2024.126199
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213083714&doi=10.1016%2fj.eswa.2024.126199&partnerID=40&md5=55164210464430ff041ddee5be48a7c4
AB  - Customer churn analysis in telecommunication industry is a very essential factor to be achieved and it makes direct impact to retaining customers and generating income. Various current approaches are utilized to enhancing the customer experience in telecommunication-network service with churn analysis. But those approaches has lots of challenges such as acquisition cost will be high within the networks and also the satisfaction level of recommending the network for the customers was not in a rapid-flow. To-overcome these concerns, Conditional Variational Auto Encoder (CVAE) is developed to enhance the customer experience in telecommunication-network by predicting the churn-customers. The text's was gathered and pre-processed using tokenization, stemming, stop word removal, spell correction, handling negation, character normalization and lemmatization. Subsequently, Contrastive information extraction with Generation Transformer(CGT) is used to extract features. Appropriate Features are chosen by using t-DSNE (t-Distributed Stochastic Neighbor Embedding). Optimal number of components are selected using GOA. Finally, CVAE is used for predicting churn customers and recommend the high priority network to the user. From the experiment analysis, the proposed approach attains an accuracy of 97.2%, a precision value of up to 94.5%, and a specificity range of 98.1% for service recommendation. Whereas accuracy of 96.45, precision of 93.5% and specificity of 96% is achieved for churn prediction. Thus, the suggested-method is the better choice for enhancing the customer experience in telecommunications-network. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Haridasan2025Gazelle
ER  -

TY  - JOUR
AU  - Benarfa, G.
AU  - Amamou, A.
AU  - Kelouwani, S.
AU  - Hébert, M.
AU  - Zeghmi, L.
AU  - Jemei, S.
TI  - Online health-aware energy management strategy of a fuel cell hybrid autonomous mobile robot under startup–shutdown condition
PY  - 2025
T2  - Expert Systems with Applications
VL  - 266
C7  - 125943
DO  - 10.1016/j.eswa.2024.125943
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211600395&doi=10.1016%2fj.eswa.2024.125943&partnerID=40&md5=a3b6b4c61ca218f28eee84079fec5e03
AB  - In the age of Industry 4.0, the automation of industrial processes is essential for enhancing efficiency, productivity, and flexibility. Autonomous mobile robots are pivotal in this transformation, particularly in material handling and logistics operations within complex industrial environments. Fuel cell hybrid autonomous mobile robots, a type of autonomous mobile robot that functions with hybridization of battery and fuel cell, offer significant advantages in operational efficiency and sustainability. However, the commercialization of these vehicles is impeded by the limited lifespan of fuel cells and the adverse effects of frequent startup–shutdown cycles, which lead to significant fuel cell degradation and reduced operational efficiency. This study addresses these challenges by presenting an innovative, health-aware energy management strategy tailored for fuel cell hybrid autonomous mobile robots. The proposed strategy aims to balance hydrogen consumption with fuel cell degradation through a comprehensive two-step approach. First, the offline module employs digital modeling combined with a Markov Decision Process to generate long-term power profiles. This step includes the use of Dynamic Programming to optimize power distribution, ensuring an efficient energy management strategy. Additionally, a transformer neural network is trained on this optimized data to accurately predict the fuel cell's power output. In the online step, a Model Predictive Control technique is utilized to dynamically track the fuel cell's power output based on real-time predictions from the trained transformer model. This enables the system to adapt to changing operational conditions, maintaining optimal performance and extending the fuel cell's lifespan. Our comparative analysis, based on simulations and experimental tests conducted in a controlled laboratory environment, demonstrates that this approach enhances both fuel cell lifespan and hydrogen efficiency. Specifically, our strategy extends the fuel cell's operational life by 9.5% and achieves a hydrogen consumption of 15.83 g over a 600-s operational cycle, compared to benchmark methods. The novelty of this research lies in its integration of advanced predictive models and control techniques, which collectively optimize the operational efficiency and durability of fuel cell hybrid autonomous mobile robots. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Benarfa2025Online
ER  -

TY  - JOUR
AU  - Zhang, R.
AU  - Li, G.
AU  - Qu, S.
AU  - Wang, J.
AU  - Peng, J.
TI  - Mamba-GIE: A visual state space models-based generalized image extrapolation method via dual-level adaptive feature fusion
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125961
DO  - 10.1016/j.eswa.2024.125961
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211023332&doi=10.1016%2fj.eswa.2024.125961&partnerID=40&md5=999dc1a334aa4faa10f8c262144d01a8
AB  - Generalized Image Extrapolation is an image generation sub-task and a challenging ill-posed problem. This task intends to predict unknown regions based on the center area. Unfortunately, existing methods encounter the triple dilemma: (1) Convolutional Neural Networks (CNNs)-based methods can precisely extract local details but underperform in capturing global semantic information due to inductive bias, resulting in a lack of consistency in the image structure and layout. (2) Vision Transformer (ViT)-based methods, although superior to global information extraction, are not sufficiently fine-grained in detail and texture generation, and (3) ViT-based approaches rely on the self-attention mechanism, which leads to a tremendous computational burden in processing images and makes model training inefficient. We propose a novel model named Mamba-GIE, designed to effectively balance information of different granularities and address the unresolved challenges in GIE tasks. At the macro level, Mamba-GIE adopts a U-shaped encoder–decoder architecture, with its core basic block being the improved Hybrid State Space Models (Hybrid-SSMs). Specifically, within the basic blocks, the input feature map is processed via two parallel branches: (1) Extracting global information via the Mamba branch and (2) Handling local details using the CNNs branch. At the micro level, we introduce the dual-level adaptive feature fusion mechanism to achieve adaptive feature fusion in intra- and inter-Hybrid-SSMs blocks. Extensive experiments on three public datasets demonstrate that our approach outperforms existing GIE methods in most evaluation metrics and image generation quality. Comprehensive ablation studies and resource consumption assessments further reveal the efficiency and effectiveness of Mamba-GIE. Code: https://github.com/zrymsm/Mamba-GIE. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2025Mamba-GIE
ER  -

TY  - JOUR
AU  - Yu, C.
AU  - Li, Y.
AU  - Zhai, G.
TI  - Time-frequency attention mechanism-based model for enhancing wind speed prediction accuracy
PY  - 2025
T2  - Expert Systems with Applications
VL  - 265
C7  - 126038
DO  - 10.1016/j.eswa.2024.126038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211376900&doi=10.1016%2fj.eswa.2024.126038&partnerID=40&md5=a0ff583d2f1ef2d096e59361562f3d55
AB  - Wind energy constitutes a substantial renewable energy source, and its efficient exploitation depends significantly on precise wind speed forecasting. However, achieving accurate predictions in this area is challenging. Taking into account the consistent physical information contained within the time and frequency domain of a time signal, a novel time–frequency attention block and model is proposed. The pivotal component, denoted as the time–frequency attention (TFA) block, normalizes the time series of wind speed, utilizes the discrete cosine transform to obtain frequency domain information, and subsequently maps the time–frequency data to a high-dimensional space, employing an attention mechanism for adaptive fusion. After residual connections and multi-layer stacking, the predictive values are obtained by connecting with fully connected layers. Experimental results demonstrate that, compared to state-of-the-art models such as the Transformer and TimesNet, the TFA model exhibits favorable predictive performance. While hyperparameters do exert some influence on the predictive performance of the TFA model, its overall performance remains stable and consistently optimal. Regarding the operational mechanism of the model, visualization of the intermediate outputs confirms the TFA model's exceptional ability to capture temporal and frequency domain fluctuations, as well as mean features. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yu2025Time-frequency
ER  -

TY  - JOUR
AU  - Fofanah, A.J.
AU  - Chen, D.
AU  - Wen, L.
AU  - Zhang, S.
TI  - CHAMFormer: Dual heterogeneous three-stages coupling and multivariate feature-aware learning network for traffic flow forecasting
PY  - 2025
T2  - Expert Systems with Applications
VL  - 266
C7  - 126085
DO  - 10.1016/j.eswa.2024.126085
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211740274&doi=10.1016%2fj.eswa.2024.126085&partnerID=40&md5=ff248c72b43c9364a6d2a83df4cd12af
AB  - Accurate traffic flow prediction is essential for intelligent transportation systems and urban planning. Traditional approaches that combine Transformer models with Graph Convolutional Networks (GCNs) or Convolutional Neural Networks (CNNs) often struggle to effectively integrate features with varying degrees of connectivity. As a result, graph-based problems do not fully utilise the capabilities of GCNs, while time-series problems fail to entirely leverage CNNs. To overcome these challenges, we introduce the Dual Heterogeneous Three-Stage Coupling and Multivariate Feature-Aware Learning Network (CHAMFormer). This architecture comprises three main components, each focusing on a distinct innovation: capturing fine-grained, short-range traffic patterns to manage immediate interactions and local bottlenecks; integrating mid-range spatial and temporal features to understand broader traffic interactions and ripple effects; and analysing complex, long-term traffic dynamics to anticipate and manage large-scale events and network behaviours across the entire system. These modules enhance GCN performance, enabling them to function more effectively alongside Transformers and Graph Neural Networks (GNNs). The CHAMFormer model incorporates a three-stage self-attention mechanism with a Skip-Connection method to improve the capture of detailed information without significantly increasing computational costs. By connecting low-level, intermediate-level, and high-level feature extractions, this model adapts well to changing traffic patterns, thereby enhancing multi-feature awareness and prediction accuracy. Extensive experiments using seven public datasets, both with and without predefined graph structures, and in multivariate and univariate scenarios demonstrate that CHAMFormer improves prediction accuracy by at least 10%–15%. To validate our proposed model, we also tested CHAMFormer in the energy domain, where it effectively handles time-series problems. Additionally, a sensitivity analysis confirms the model's predictability and interpretability, providing valuable insights for transportation policy and infrastructure development. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Fofanah2025CHAMFormer
ER  -

TY  - JOUR
AU  - Liu, P.
AU  - Zhang, Z.
AU  - Meng, Z.
AU  - Gao, N.
TI  - Transformer-based monocular depth estimation with hybrid attention fusion and progressive regression
PY  - 2025
T2  - Neurocomputing
VL  - 620
C7  - 129268
DO  - 10.1016/j.neucom.2024.129268
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213291692&doi=10.1016%2fj.neucom.2024.129268&partnerID=40&md5=b21a1e62f7f6f8af6d6b70b201693aba
AB  - Monocular depth estimation has gained prominence due to its versatile applications and minimal system requirements, despite the inherent challenges posed by its ill-posed nature. Recent advancements in Transformer techniques have significantly propelled this field forward. This paper introduces a novel Transformer-based encoder-decoder network to enhance monocular depth estimation, presenting two key improvements compared to prior approaches. Firstly, a hybrid attention fusion module is designed in the decoding stage for feature fusion. This module employs a parallel hybrid structure design to fully leverage the complementary advantages of Transformers and convolution methods, effectively capturing both local contextual and global consistency of depth maps. Additionally, to mitigate fine-grained depth loss during decoder upsampling, a deep progressive regression module is proposed. This module gradually predicts depth maps of varying resolutions by enhancing interactions between adjacent prediction branches. Experimental results on challenging indoor and outdoor benchmark datasets affirm the superior performance of the proposed method, showing that it effectively addresses some of the limitations of existing approaches. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2025Transformer-based
ER  -

TY  - JOUR
AU  - Nam, K.
AU  - Kim, J.
AU  - Kim, H.
AU  - Chung, M.
TI  - SA-DETR: Saliency Attention-based DETR for salient object detection
PY  - 2025
T2  - Pattern Analysis and Applications
VL  - 28
IS  - 1
C7  - 5
DO  - 10.1007/s10044-024-01379-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211108891&doi=10.1007%2fs10044-024-01379-5&partnerID=40&md5=bef4704c0c950021fcdf7ec04d132df2
AB  - Researches on the Salient Object Detection (SOD) task have made many advances based on deep learning methods. However, most methods have focused on predicting a fine mask rather than finding the most salient objects. Most datasets for the SOD task also focus on evaluating pixel-wise accuracy rather than “saliency”. In this study, we used the Salient Objects in Clutter (SOC) dataset to conduct research that focuses more on the saliency of objects. We propose a architecture that extends the cross-attention mechanism of Transformer to the DETR architecture to learn the relationship between the global image semantics and the objects. We extended module with Saliency Attention (SA) to the network, namely SA-DETR, to detect salient objects based on object-level saliency. Our proposed method with cross- and saliency-attentions shows superior results in detecting salient objects among multiple objects compared to other methods. We demonstrate the effectiveness of our proposed method by showing that it outperforms the state-of-the-art performance of the existing SOD method by 4.7% and 0.2% in MAE and mean E-measure, respectively. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Nam2025SA-DETR
ER  -

TY  - JOUR
AU  - Ranjan, S.
AU  - Singh, S.K.
TI  - Overcoming catastrophic forgetting in molecular property prediction using continual learning of sequential episodes
PY  - 2025
T2  - Expert Systems with Applications
VL  - 267
C7  - 125997
DO  - 10.1016/j.eswa.2024.125997
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212829330&doi=10.1016%2fj.eswa.2024.125997&partnerID=40&md5=9a5709a0e3561d16bd0cbf97036725aa
AB  - Continual Learning requires Large Language Models (LLM) to adapt to new episodes and data over time without forgetting the knowledge acquired from previous episodes. This dynamic approach to learning is crucial in molecular property prediction, where data is not static but arrives in streams. LLMs are prone to Catastrophic Forgetting (CF), where learning new information leads to erosion of previously acquired knowledge. This is particularly problematic in scenarios where the chemical, genomic, and proteomic data distribution shifts or new episodes differ significantly from prior ones. In response to the above issue, this work proposes a Multi-task Learner with Online Elastic Weight Consolidation and LLMs (Bidirectional Encoder Representation of Transformer (BERT) and Bidirectional Autoregressive Transformers (BART)) called Bidirectional Multi-Task Learner Elastic Weight Consolidation (B-MTLEWC). Two molecular datasets used for sequential learning of episodes are trained for 2000 epochs, which generated acceptable results on the B-MTLEWC model (1. Blood Brain Barrier Peptides (BBBP): Accuracy 89.16% and 88.81% and 2. Bitter: Accuracy 85.82% and 87.06% on unmasked and masked sets, respectively). The B-MTLEWC model is evaluated against BERT and BART across twelve augmented test datasets spanning three distinct episodes, focusing on knowledge retention from previous episodes. The model shows a maximum performance drop of only 1% in accuracy and Area Under the Curve, and in some cases, its performance remained consistent, demonstrating effective mitigation of CF. The empirical analysis combined with various explainability techniques highlighted significant performance improvements in sequential learning of episodes compared to State-of-the-Art methods, hence addressing the stability-plasticity trade-off. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ranjan2025Overcoming
ER  -

TY  - JOUR
AU  - Zou, W.
AU  - Sun, X.
AU  - Wu, W.
AU  - Lu, Q.
AU  - Zhao, X.
AU  - Bo, Q.
AU  - Yan, J.
TI  - TCMT: Target-oriented Cross Modal Transformer for Multimodal Aspect-Based Sentiment Analysis
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125818
DO  - 10.1016/j.eswa.2024.125818
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210275165&doi=10.1016%2fj.eswa.2024.125818&partnerID=40&md5=fb2b57744b7b6664db5c599b21d31439
AB  - Multimodal Aspect-Based Sentiment Analysis (MABSA) technology aims to utilize both textual and visual modalities to achieve Multimodal Aspect Term Extraction (MATE) and Multimodal Aspect Sentiment Classification (MASC) in tweets. Current research has overlooked the impact of noise from irrelevant regions in images on model performance. Additionally, there has been insufficient utilization of the textual information contained within images and the syntactic features of sentences. In this paper, we propose a Target-oriented Cross Modal Transformer (TCMT) for MABSA. The model consists of a textual auxiliary module, a visual auxiliary module, and a main module: the textual aspect-sentiment extraction module, the visual aspect-sentiment prediction module, and the textual-visual alignment cross-modal module. In the textual auxiliary module, we utilize syntactic features to assist the model in identifying the boundaries of multi-word aspect terms and employ Optical Character Recognition (OCR) technology to capture textual information contained within images. In the visual auxiliary module, we employ Adjective-Noun Pairs (ANPs) detection for supervised training of images. Additionally, we have improved the cross-modal Transformer structure by designing a GCN-based Transformer in the textual auxiliary module to learn syntactic graphs, and a CNN-based Transformer in the visual auxiliary module to focus more on important information in images. In the cross-modal MABSA module, we design a target-oriented interaction component to facilitate modal interaction learning and mitigate the impact of image noise, along with an alignment auxiliary component to optimize modal alignment training. We conducted extensive experiments on two publicly available benchmark datasets. The results demonstrate that the performance of the TCMT model is significantly superior to that of the baseline model, achieving state-of-the-art results. Both the textual auxiliary module and the visual auxiliary module effectively assist the cross-modal MABSA module in completing the task more efficiently. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zou2025TCMT
ER  -

TY  - JOUR
AU  - Wu, G.
AU  - Hu, L.
AU  - Hu, Y.
AU  - Xing, Y.
AU  - Wang, F.
TI  - User intention prediction for trigger-action programming rule using multi-view representation learning
PY  - 2025
T2  - Expert Systems with Applications
VL  - 267
C7  - 126198
DO  - 10.1016/j.eswa.2024.126198
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212929822&doi=10.1016%2fj.eswa.2024.126198&partnerID=40&md5=79f9df416e85c842453507a1d37dd753
AB  - Trigger-action programming (TAP) allows users to create rules for automating smart devices and Internet services, such as “If a person is leaving, then turn off the air conditioner”. User intention, as the internal driving force behind rule creation, plays a crucial role in understanding user demands. While existing research can easily identify users’ explicit demands, such as turning off the air conditioner, it often fails to recognize implicit intentions, such as energy saving. Predicting user intention presents several challenges, including (1) contextual dependencies between triggers and actions that lead to different intentions when users combine various functions, (2) identifying user intention in short function description texts, and (3) entities with similar functions that do not reflect user intentions due to a lack of domain-specific knowledge. To address these challenges, we propose a multi-view representation learning-based framework, MvTAP, jointly in (1) user view, (2) developer view, and (3) knowledge view. In MvTAP, we first design different methods to learn the representation of the three views, respectively. We then propose a transformer-based method to fuse the representations of these views. User intention prediction is formulated as a multi-label classification task. The effectiveness of MvTAP is validated using a real-world IFTTT dataset. Experimental results show that the proposed framework can effectively predict user intentions in TAP rules. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wu2025User
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Lu, Y.
AU  - Bai, J.
AU  - Campello, V.M.
AU  - Feng, F.
AU  - Lekadir, K.
TI  - Segment Anything Model for fetal head-pubic symphysis segmentation in intrapartum ultrasound image analysis
PY  - 2025
T2  - Expert Systems with Applications
VL  - 263
C7  - 125699
DO  - 10.1016/j.eswa.2024.125699
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208916846&doi=10.1016%2fj.eswa.2024.125699&partnerID=40&md5=96ed4e93811ed66da0eb9fcab3da23e1
AB  - The Angle of Progression (AoP), determined by the contour delineations of the pubic symphysis and fetal head (PSFH) in intrapartum ultrasound (US) images, is crucial for predicting delivery mode and significantly influences labor outcomes. However, automating AoP measurement based on PSFH segmentation remains challenging due to poor foreground-background contrast, blurred boundaries, and anatomical variability in shapes, sizes, and positions during labor. We propose a novel Segment Anything Model (SAM) framework, AoP-SAM, designed to enhance the PSFH segmentation, AoP measurement and outcome prediction, tackling the challenges of small target segmentation and accurate boundary segmentation. It synergistically combines CNNs and Transformers within a cooperative encoder to process complex spatial relationships and contextual information to segment the PSFH. In this encoder, we devise a multi-scale CNN branch to capture intrinsic local details, which compensates for the defects of the Transformer branch in extracting local features. Further, a cross-branch attention module is applied to improve prediction by fostering the effective information exchange and integration between two branches. Evaluations on the benchmark dataset demonstrate that our method achieves state-of-the-art (SOTA) performance. Specifically, in the PSFH segmentation task, the AoP measurement task, and the AoP classification task, we achieved a DSC of 0.8745 on the PS structure, a ΔAoP of 7.6743°, and an F1-score of 0.7719, respectively. Compared to the second-ranking method, these results represent improvements of 2.5%, 6.3%, and 1.1%. Our study presents a framework for intrapartum biometry, offering significant advancements in labor monitoring and delivery mode prediction in clinical settings. Future efforts will focus on optimizing AoP-SAM for resource-constrained environments, highlighting its potential for lightweight adaptation. https://github.com/maskoffs/AoP-SAM. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhou2025Segment
ER  -

TY  - JOUR
AU  - Liu, L.
AU  - Wu, M.
AU  - Lv, Q.
AU  - Liu, H.
AU  - Wang, Y.
TI  - CCNN-former: Combining convolutional neural network and Transformer for image-based traffic time series prediction
PY  - 2025
T2  - Expert Systems with Applications
VL  - 268
C7  - 126146
DO  - 10.1016/j.eswa.2024.126146
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213501700&doi=10.1016%2fj.eswa.2024.126146&partnerID=40&md5=13786df29cdcb3118135d988a42f11d6
AB  - Traffic time series prediction is crucial to the development of urban intelligent transportation systems (ITS). Traditional prediction models are mainly designed to extract the spatio-temporal features based on historical traffic flow in the form of time series, ignoring the learning of the implicit periodic patterns hidden in the flow. In addition, most of the models solely employ the historical traffic flow with no more than 12 time steps for prediction. Such short-term input struggles to contain rich, continuous and diverse periodic patterns, limiting their performance. To this end, we propose a model of combining convolutional neural network (CNN) and Transformer (CCNN-Former) tailored for image-based traffic time series prediction. Specifically, we first propose a data conversion module that converts the long-term time series traffic flow into a new representation of image with fixed resolution, ensuring that both short- and long-term information is contained in an image. Then, CNN and Transformer are utilized to learn the image-based features from local and global perspectives, respectively. The core of CCNN-Former is to creatively propose a new long-term time series data imaging strategy and use a computer vision method to extract rich short- and long-term image-based features, achieving the goal of improving prediction performance while maintaining high efficiency. Extensive experiments are conducted on two real-world datasets to demonstrate the superiority of CCNN-Former compared with seven competitive baselines. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2025CCNN-former
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Zhang, X.
AU  - Zhu, L.
AU  - Zhang, Y.
AU  - Cao, J.
AU  - Ling, W.-K.
TI  - Enhancing 3D video watching experiences: Tackling compression and 3D warping distortions in synthesized view with perceptual guidance
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125853
DO  - 10.1016/j.eswa.2024.125853
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210286571&doi=10.1016%2fj.eswa.2024.125853&partnerID=40&md5=47fe48ebe5a891d7e2c12f3a37e7f7c7
AB  - In 3D video systems, synthesized videos are typically rendered using view synthesis technology, mainly Depth Image Based Rendering (DIBR) technology, and suffer from both compression and 3D warping artifacts, which may degrade the perceptual quality of 3D video. Taking into account human perceptual characteristics towards synthesized views, wherein individuals readily discern DIBR distortion, such as cracks and irregular stretching, more attention should be paid to addressing DIBR distortion for Synthesized View Quality Enhancement (SVQE). In this paper, we propose a Distortion Map-guided Asymmetrical encoder–decoder restoration Network for SVQE, termed DMANet, which prioritizes human perceptual factors while maintaining a delicate balance between effectiveness and efficiency. Specifically, to consider the perceptual characteristics, a distortion-aware module is introduced by embedding the predicted DIBR distortion into the restoration network through multi-scale feature embedding, and collaborates with the DIBR distortion prediction loss to focus more on the DIBR-distorted regions. Meanwhile, to promote the efficiency of the U-shape network, an asymmetrical encoder–decoder restoration network is proposed, where the encoder progressively integrates both transformer and CNN modules for facilitating local–global feature extraction, while the decoder is configured with only the CNN module. Furthermore, hybrid transformer-based modules incorporate channel attention interaction and convolutional filters to fully exploit the channel-wise global modeling ability of self-attention while preserving local details. Substantial experimental results show that the proposed DMANet can outperform SOTA SVQE methods and is comparable to SOTA image restoration methods with fewer model parameters, flops, and shorter running time. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2025Enhancing
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Chen, Y.
AU  - Wang, T.
AU  - Xie, C.-Z.T.
AU  - Tian, Y.
TI  - Mixture of Spatial–Temporal Graph Transformer Networks for urban congestion prediction using multimodal transportation data
PY  - 2025
T2  - Expert Systems with Applications
VL  - 268
C7  - 126108
DO  - 10.1016/j.eswa.2024.126108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214101847&doi=10.1016%2fj.eswa.2024.126108&partnerID=40&md5=8f74a205db56ad10054ee538358c9baa
AB  - Urban traffic congestion significantly affects economic productivity, environmental sustainability, and quality of life. Traditional traffic congestion prediction models, which are primarily based on single-mode data, often fail to capture the intricate interactions and dependencies present in multimodal urban transportation systems. In this paper, we propose a novel Mixture of Spatial–Temporal Graph Transformer Networks (MoSTGTN) for urban congestion prediction using multimodal transportation data. Our approach integrates a pattern-aware dynamic graph neural network for analyzing grid-based traffic big data, a dynamic spatial–temporal graph transformer to learn the distinct features of each traffic modality, and a mixture of experts framework to capture both intra-modality characteristics and inter-modality interactions. Real-world multimodal transportation data from Tianjin, China, including taxi and shared bicycle data, is used to validate the proposed model. The MoSTGTN model consistently outperforms state-of-the-art baseline models across multiple metrics, as well as in various traffic regions, time periods, and directions. The robustness of the model is further confirmed through extensive variance analysis. Our key findings highlight the critical role of inter-modal interactions and underscore the significant contribution of shared bicycle data in improving urban traffic congestion prediction accuracy, especially in high-density traffic areas. © 2025 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2025Mixture
ER  -

TY  - JOUR
AU  - Cao, Y.
AU  - Liao, Y.
AU  - Liu, Z.
AU  - Ma, X.
AU  - Liu, X.
TI  - SWAformer: A novel shifted window attention Transformer model for accurate power distribution prediction
PY  - 2025
T2  - Expert Systems with Applications
VL  - 265
C7  - 126058
DO  - 10.1016/j.eswa.2024.126058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211176371&doi=10.1016%2fj.eswa.2024.126058&partnerID=40&md5=76b247c12124e81963186358a8f92c65
AB  - In recent years, deep learning models have been increasingly applied to power distribution prediction due to the success of time series prediction methods. These models extract features from the data and capture the overall trend, leading to more accurate predictions than traditional approaches. Global information refers to the overall trend or pattern across the entire dataset, while local information pertains to specific variations or changes within smaller regions of the data. However, focusing solely on global information while neglecting these local variations can reduce prediction accuracy and increase model complexity. To address these challenges, we propose a novel Shifted Window Attention Transformer model that enhances local information learning by iteratively computing self-attention within regions of varying window sizes. Additionally, patch relative position encoding is incorporated to better preserve spatiotemporal information. The model operates in a bottom-up manner, where the cascaded input data progressively extract features from local to global levels. This approach efficiently integrates both global and local information, resulting in improved performance. The effectiveness of our model was demonstrated on widely used public datasets, where it achieved superior prediction results for power distribution tasks. By optimizing grid operators’ decisions, our approach enhances the accuracy and efficiency of power distribution and supports the advancement and modernization of power systems. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Cao2025SWAformer
ER  -

TY  - JOUR
AU  - Bell-Navas, A.
AU  - Groun, N.
AU  - Villalba-Orero, M.
AU  - Lara-Pezzi, E.
AU  - Garicano-Mena, J.
AU  - Le Clainche, S.
TI  - Automatic Cardiac Pathology Recognition in Echocardiography Images using Higher Order Dynamic Mode Decomposition and a Vision Transformer for Small Datasets
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125849
DO  - 10.1016/j.eswa.2024.125849
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210541449&doi=10.1016%2fj.eswa.2024.125849&partnerID=40&md5=cdd83db3e7acb52feebbbe789aeb4581
AB  - Heart diseases are the main international cause of human defunction. According to the WHO, nearly 18 million people decease each year because of heart diseases. Also considering the increase of medical data, much pressure is put on the health industry to develop systems for early and accurate heart disease recognition. In this work, an automatic cardiac pathology recognition system based on a novel deep learning framework is proposed, which analyses in real-time echocardiography video sequences. The system works in two stages. The first one transforms the data included in a database of echocardiography sequences into a machine learning-compatible collection of annotated images which can be used in the training phase of any kind of machine learning-based framework, including deep learning. This includes the use of the Higher Order Dynamic Mode Decomposition (HODMD) algorithm, for the first time to the authors’ knowledge, for both data augmentation and feature extraction in the medical field. The second stage is focused on building and training a Vision Transformer (ViT), barely explored in the related literature. The ViT is adapted for an effective training from scratch, even with small datasets. The designed neural network analyses images from an echocardiography sequence to predict the heart state. The results obtained show the efficacy of the HODMD algorithm and the superiority of the proposed system, even outperforming pretrained Convolutional Neural Networks (CNNs), which are so far the method of choice in the literature. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Bell-Navas2025Automatic
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Zhuang, M.
AU  - Wang, J.
AU  - Zhou, J.
TI  - Leveraging multi-time-span sequences and feature correlations for improved stock trend prediction
PY  - 2025
T2  - Neurocomputing
VL  - 620
C7  - 129218
DO  - 10.1016/j.neucom.2024.129218
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213080195&doi=10.1016%2fj.neucom.2024.129218&partnerID=40&md5=1e1fb694287d40fc591ecbc66b1f7038
AB  - Accurate stock trend prediction is critical for informed investment decisions and the stability of financial markets. However, existing methodologies often overlook fine-grained stock price volatility and fail to incorporate a comprehensive spectrum of technical indicators, inadequately capturing the complex interrelationships fundamental to technical analysis. This paper proposes MSFCE, a novel framework for stock market trend prediction that enhances feature correlations across multi-time-span sequences. Specifically, MSFCE designs a multi-scale feature encoder to capture both intraday and daily features, which are processed through a Transformer-based dimensionally adaptive encoder. Furthermore, the framework leverages higher-order interactions among technical indicators via a graph attention network, dynamically modeling their interdependencies to improve prediction robustness in dynamic markets. Extensive experiments on the SSE50 and CSI300 datasets demonstrate that MSFCE significantly outperforms existing state-of-the-art methods, consistently exhibiting superior performance across multiple test periods and market conditions. Its strong prediction accuracy and risk management suggest practical applicability in trading strategies, yielding significant excess returns in empirical backtests. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2025Leveraging
ER  -

TY  - JOUR
AU  - Sun, C.
AU  - Chen, J.
AU  - Zhao, Y.
AU  - Han, H.
AU  - Jing, R.
AU  - Tan, G.
AU  - Wu, D.
TI  - Appformer: A novel framework for mobile app usage prediction leveraging progressive multi-modal data fusion and feature extraction
PY  - 2025
T2  - Expert Systems with Applications
VL  - 265
C7  - 125903
DO  - 10.1016/j.eswa.2024.125903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211033353&doi=10.1016%2fj.eswa.2024.125903&partnerID=40&md5=6d645449874b955fa6469a86b662247d
AB  - This article presents Appformer, a novel mobile application prediction framework inspired by the efficiency of Transformer-like architectures in processing sequential data through self-attention mechanisms. Combining a Multi-Modal Data Progressive Fusion Module with a sophisticated Feature Extraction Module, Appformer leverages the synergies of multi-modal data fusion and data mining techniques while maintaining user privacy. The framework employs Points of Interest (POIs) associated with base stations, optimizing them through comprehensive comparative experiments to identify the most effective clustering method. These refined inputs are seamlessly integrated into the initial phases of cross-modal data fusion, where temporal units are encoded via word embeddings and subsequently merged in later stages. The Feature Extraction Module, employing Transformer-like architectures specialized for time series analysis, adeptly distils comprehensive features. It meticulously fine-tunes the outputs from the fusion module, facilitating the extraction of high-caliber, multi-modal features, thus guaranteeing a robust and efficient extraction process. Extensive experimental validation confirms Appformer's effectiveness, attaining state-of-the-art (SOTA) metrics in mobile app usage prediction, thereby signifying a notable progression in this field. The implementation is available at https://github.com/SunChuike/Appformer-ESWA. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Sun2025Appformer
ER  -

TY  - JOUR
AU  - Quang Tran, V.
AU  - Byeon, H.
TI  - Explainable hybrid tabular Variational Autoencoder and feature Tokenizer Transformer for depression prediction
PY  - 2025
T2  - Expert Systems with Applications
VL  - 265
C7  - 126084
DO  - 10.1016/j.eswa.2024.126084
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211192610&doi=10.1016%2fj.eswa.2024.126084&partnerID=40&md5=d117712d631d02a1ec0a18f8bd3b7f89
AB  - Recent advancements in machine learning and deep learning have significantly improved the diagnosis, detection, prediction, and prognosis of depressive disorders. However, these methodologies have issues related to generalizability, transparency, data scarcity, privacy concerns, and class imbalance. This study develops a robust and interpretable model for predicting depression in South Korea, addressing these limitations. We employed a hybrid deep learning approach that integrates the Feature Tokenizer Transformer model, specifically designed for tabular data, to effectively tokenize and process categorical and numerical features, alongside synthetic data generated by the tabular variational autoencoder (TVAE). TVAE is an adaptation of variational autoencoders that uses a specialized loss function for tabular data. generated high-quality synthetic data from the Korea National Health and Nutrition Examination Survey (KNHANES) dataset. The efficacy of the TVAE-generated data was validated using non-parametric statistical tests, achieving 86.30% on the Kolmogorov-Smirnov test and 76.65% on the Chi-squared test. Performance evaluation metrics, such as accuracy, recall, F1-score, and AUC, demonstrated our model's effectiveness, yielding an accuracy 0.7783, a recall score of 0.5310, an F1-score of 0.4657, and an AUC of 0.6822, outperforming state-of-the-art models. Additionally, SHapley Additive exPlanations analysis was incorporated to explain feature importance, offering valuable insights for healthcare professionals. This research highlights the potential of deep learning and synthetic data generation techniques to enhance depression prediction, addressing critical challenges such as generalizability, class imbalance, data privacy, and interpretability over existing models. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Quang Tran2025Explainable
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Xie, L.
AU  - Wang, X.
AU  - Pan, H.
AU  - Wang, Z.
TI  - A twin disentanglement Transformer Network with Hierarchical-Level Feature Reconstruction for robust multimodal emotion recognition
PY  - 2025
T2  - Expert Systems with Applications
VL  - 264
C7  - 125822
DO  - 10.1016/j.eswa.2024.125822
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210528891&doi=10.1016%2fj.eswa.2024.125822&partnerID=40&md5=59a05e927fe33ba8b467a2b00f5800f2
AB  - In real-world human–computer interaction, the performance of multimodal emotion recognition models is inevitably affected by random modality feature missing. Thus, robust multimodal emotion recognition methods have attracted increasing attention. However, existing robust multimodal emotion recognition methods generally ignore the distributional gap between modalities. To address this issue, we propose a Twin Disentanglement Transformer Network with Hierarchical-Level Feature Reconstruction (TDTN-HLFR), which aims to enhance model robustness by reconstructing missing features from modality-common and modality-specific perspectives. The network comprises two primary learning processes: disentanglement learning and reconstruction learning. The former learns to efficiently decouple the original multimodal features into modality-specific and modality-common representations through a Disentanglement Transformer Network (DTN). Based on the former, the latter developed the TDTN-HLFR, which learns to reconstruct missing features from modality-common and modality-specific perspectives. In doing this, the TDTN-HLFR mitigates the impact of the distributional gap on the reconstruction of missing features. Extensive experiments are conducted on two multimodal continuous emotion recognition datasets: The Remote Collaborative and Affective (RECOLA) and the Ulm-Trier Social Stress Test (ULM-TSST) datasets. In terms of combined Concordance Correlation Coefficient (CCC) for valence and arousal prediction, our method delivers 0.0852 absolute increases on the RECOLA dataset and 0.0207 on the ULM-TSST dataset compared with the best baseline in the complete modality feature setting while delivering 0.0692 absolute increases on the RECOLA dataset and 0.0347 on the ULM-TSST dataset compared with the best baseline in the incomplete modality feature setting. These results demonstrate the potential of the TDTN-HLFR in real-world human–computer interaction scenarios. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2025twin
ER  -

TY  - JOUR
AU  - Yang, M.
AU  - Guo, Y.
AU  - Wang, B.
AU  - Wang, Z.
AU  - Chai, R.
TI  - A day-ahead wind speed correction method: Enhancing wind speed forecasting accuracy using a strategy combining dynamic feature weighting with multi-source information and dynamic matching with improved similarity function
PY  - 2025
T2  - Expert Systems with Applications
VL  - 263
C7  - 125724
DO  - 10.1016/j.eswa.2024.125724
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208655221&doi=10.1016%2fj.eswa.2024.125724&partnerID=40&md5=15085525a9a4bfe87413c7bc03129305
AB  - Forecasting error of day-ahead wind speed (WS) seriously affects wind power integration and power system security and stability. In this regard, this paper fully considers the spatiotemporal correlation of wind farms (WFs) in different geographical locations, and proposes a day-ahead WS combined correction method that integrates multi-source station dynamic information weighting. Different from the previous WS correction methods, this paper fully considers the dynamic correlation of WS between the WFs, introduces an improved weighted similarity function to screen and dynamically weight the information of WFs with dynamic correlation, and introduces the dynamic weighting feature into the WS correction process. A combined decomposition mechanism is proposed, which combines sequential variational mode decomposition (SVMD) and feature mode decomposition (FMD) models to extract the most relevant trend components and non-stationary components of forecasted and measured WS. A combined correction model is introduced, and a combined architecture of Non-stationary Transformer combined with bidirectional long short-term memory network (Ns-Transformer-BILSTM) is used to correct the stationary WS component. A dynamic matching mechanism of fluctuation components considering improved similarity is proposed for the correction of non-stationary components. The proposed method is applied to several regional WFs in China. The experimental results show that the average correction of NRMSE, NMAE and R can reach 2.4 % ∼ 3.7 %, 2.0 % ∼ 3.0 % and 3.3 % ∼ 9.7 %, respectively. The NRMSE and NMAE corresponding to the corrected WS of certain individual WFs can be reduced by 10 % and 9 %, respectively, and R can be increased by 33 %. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yang2025day-ahead
ER  -

TY  - JOUR
AU  - Guo, W.
AU  - Ren, Z.
AU  - Du, W.
AU  - Weng, T.
TI  - TFT-MPIR: An end-to-end multi-period inventory replenishment strategy based on temporal fusion transformer
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125464
DO  - 10.1016/j.eswa.2024.125464
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205904134&doi=10.1016%2fj.eswa.2024.125464&partnerID=40&md5=bc950de025f9c2ef513578270302d8f2
AB  - The inherent uncertainty associated with demand and vendor lead time significantly complicates replenishment strategies, which is challenge in the dynamic realm of e-commerce platforms. An end-to-end multi-period inventory replenishment strategy based on temporal fusion transformer (TFT-MPIR) is tailored for an integrated inventory replenishment decision-making process, and takes into account stochastic demand, vendor lead time, as well as linear transportation costs. TFT-MPIR which is fundamentally trained on an extensive amount of historical data, utilizes deep learning to directly calculate replenishment orders based on contextual and historical insights, deviating from the conventional two-step Predict-Then-Optimize (PTO) approach. The TFT-MPIR neural network framework designed with the concept of modularity enables an in-depth understanding and optimization of its structure and parameters. Specifically, the demand forecasting module utilizes temporal fusion transformer for advanced multi-quantile forecasting, generating comprehensive demand projections that significantly improve the accuracy of subsequent replenishment decisions. Numerical experiments incorporate authentic historical data from a prominent beverage supplier. Compared to the optimal solution (OPT) for inventory costs, TFT-MPIR exhibits a variance of 15.8%, markedly surpassing other integrated inventory strategies namely (t, R, S), PTO, and E2E-Multi-layer perceptron(E2E-MLP), which demonstrate divergences of 34.8%, 24.1%, and 22.3% respectively from OPT. Furthermore, TFT-MPIR framework achieves a cost reduction of 8.3% relative to the conventional PTO, and 19% in comparison to the (t, R, S). The robustness and scalability of the TFT-MPIR are substantiated through the adjustment of the ratio between unit stockout cost and unit transportation cost, coupled with sensitivity analysis. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Guo2025TFT-MPIR
ER  -

TY  - JOUR
AU  - Song, L.
AU  - Wang, Y.
AU  - Shi, L.
AU  - Yu, J.
AU  - Li, F.
AU  - Xiang, S.
TI  - Transformer with token attention and attribute prediction for image captioning
PY  - 2025
T2  - Pattern Recognition Letters
VL  - 188
SP  - 74
EP  - 80
DO  - 10.1016/j.patrec.2024.11.022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211998129&doi=10.1016%2fj.patrec.2024.11.022&partnerID=40&md5=766273a2dcd5d84c0393b1b8f73246d6
AB  - Recently, Vision Transformers (ViTs) have become the mainstream models in image captioning tasks. ViTs take all image tokens as inputs to extract visual features, which may cause concerns about worthless tokens, and meanwhile lead to a huge amount of computation. This paper proposes a novel token reduction module to remedy this drawback. Specifically, the module employs ViTs to embed the input tokens, and adaptively learns informative visual tokens in way of token attention on the channel-spatial granularity. Furthermore, an attribute prediction module is designed to strengthen the relationship between vision and language. Technically, the attribute prediction is achieved via a classifier in form of Multi-Layer Perceptron (MLP). Both the visual representations and attribute representations are obtained by Transformers, which are then combined as the input of the Transformer decoder for caption generation. All of the modules are constructed in an encoder–decoder framework and support the end-to-end learning. Experiment results have shown that our approach can effectively reduce the computational cost of ViTs while maintaining comparable performance on the MS COCO and NoCaps datasets. For example, by pruning more than 70% of the input tokens, our approach greatly reduces GFLOPs by 41% ∼ 47%, while preserving its accuracy of a 142.1 CIDEr score on the MS COCO dataset. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Song2025Transformer
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Song, W.
AU  - Wu, Q.
AU  - Sun, W.
AU  - Li, Q.
AU  - Jia, L.
TI  - A novel local enhanced channel self-attention based on Transformer for industrial remaining useful life prediction
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 141
C7  - 109815
DO  - 10.1016/j.engappai.2024.109815
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211974310&doi=10.1016%2fj.engappai.2024.109815&partnerID=40&md5=91243a6f87b24090f7fc6f5c3ef41b90
AB  - Remaining useful life (RUL) prediction is a foundational technique for predictive maintenance (PdM) and is critical to ensuring the reliability and safety of complex industrial machines. Recently, while advanced deep learning architectures like recurrent neural network (RNN), convolutional neural network (CNN) and self-attention (SA) have been widely used for RUL prediction, existing methods still face difficulties in simultaneously processing global long-term dependencies and local contextual information of sequence units as well as the spatial correlations of industrial multi-sensors. In this article, we propose local enhanced channel self-attention based on Transformer (LECformer), a novel deep RUL prediction method to overcome these issues. LECformer can more effectively capture the long-term dependencies by Transformer architecture compared with RNN/CNN-based methods. Moreover, LECformer proposes a novel local enhanced channel self-attention (LECSA) mechanism to replace the traditional SA of vanilla Transformer, which can adaptively extract both long-term dependencies and local contextual information, while dynamically weighting the importance of different channels to improve predictive performance. Two widely used turbofan engine datasets and a bearing dataset are applied to validate the effectiveness of the proposed method. Experimental results show that the LECformer significantly outperforms the state-of-the-art RUL prediction methods. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2025novel
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Fu, R.
AU  - Xing, T.
AU  - Yu, Z.
AU  - Yin, F.
TI  - A user behavior-aware multi-task learning model for enhanced short video recommendation
PY  - 2025
T2  - Neurocomputing
VL  - 617
C7  - 129076
DO  - 10.1016/j.neucom.2024.129076
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210734280&doi=10.1016%2fj.neucom.2024.129076&partnerID=40&md5=9063d1c19676873a971ab1043bd5f14c
AB  - In the rapidly evolving landscape of digital media consumption, accurately predicting user preferences and behaviors is critical for the effectiveness of recommendation systems, especially for short video content. Traditional recommendation methods often ignore the association between multiple user behavior types and struggle with dynamically adapting to user behavior changes, leading to suboptimal personalization and user engagement. To address these issues, this paper introduces a user behavior-aware multi-task learning model for enhanced short video recommendation (UBA-SVR) by leveraging insights into dynamic user interactions. In our approach, we construct a user behavior-aware transformer to comprehensively capture users’ dynamic interests and generate the fusion feature representation. Subsequently, we introduce a hierarchical knowledge extraction framework to process features in multi-stage and adopt a task-aware attention mechanism within the tower network structure to facilitate effective information sharing and differentiation among tasks. Furthermore, we employ a dynamic joint loss optimization strategy to adaptively adjust the loss weights for different tasks to promote collaborative enhancement. Extensive experiments on two real-world datasets demonstrate that the proposed method achieves significant improvements in multiple prediction tasks simultaneously. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2025user
ER  -

TY  - JOUR
AU  - Tian, X.
AU  - Huang, S.
AU  - Xiao, J.
AU  - Wang, H.
AU  - Liu, Y.
TI  - SDVS-Net: A spatial dilated convolution and variable self-attention network for multivariate long-term time series forecasting
PY  - 2025
T2  - Neurocomputing
VL  - 619
C7  - 129148
DO  - 10.1016/j.neucom.2024.129148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212191339&doi=10.1016%2fj.neucom.2024.129148&partnerID=40&md5=41be1f39ea4513b0cca25abc41788e58
AB  - Multivariate long-term time series data exhibit complex time and spatial (variable) characteristics. Transformer-based methods have achieved some success in multivariate long-term time series forecasting (MTSF) tasks. However, the embedding strategy of transformers tends to amalgamate variables, leading to the loss of variable dependency features. Additionally, these methods overly emphasize the extraction of time features, neglecting to explore the complex dependencies among variables. Therefore, MTSF poses an important and challenging problem in time series analysis. This paper proposes a spatial dilated convolution and variable self-attention network for MTSF, called SDVS-Net. SDVS-Net thoroughly considers multivariate long-term time series’ time and spatial (variable) features. Spatial dilated convolution (SDC) is employed to extract local features among variables to fully exploit the local dependencies among variables. To further capture the global dependencies among variables, Multivariate multi-head attention (MMA) is introduced, utilizing multi-head mechanisms to supplement the dependencies of each variable at different times. Time multilayer perceptron(TMP) with enhanced features from hidden layers is employed to extract features from the time dimension further. Finally, a single-layer feedforward neural network (FNN) outputs the prediction series. The experimental results on six benchmark datasets from different real-world domains demonstrate that, compared to state-of-the-art methods, SDVS-Net achieves higher prediction accuracy in MTSF problems. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tian2025SDVS-Net
ER  -

TY  - JOUR
AU  - Huang, S.
AU  - Hong, Z.
AU  - Wu, B.
AU  - Liang, J.
AU  - Huang, Q.
TI  - Spatio-temporal collaborative multiple-stream transformer network for liver lesion classification on multiple-sequence magnetic resonance imaging
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 142
C7  - 109933
DO  - 10.1016/j.engappai.2024.109933
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213837931&doi=10.1016%2fj.engappai.2024.109933&partnerID=40&md5=a6cb65e8c4f10d95e68f76adbd9a920b
AB  - Accurate identification of focal liver lesions is essential for determining the appropriate therapeutic approach in clinical practice. Magnetic resonance imaging (MRI) is a valuable technology for precise classification, revealing diverse physical and biological details of lesions. However, due to the wide variety and morphological variability of the lesions, unsystematic mixing analysis of multiple-sequences MRI may cause aliasing of lesion information, obscuring the inter-tissue relationships between various imaging sequences and impeding a comprehensive diagnosis. In this paper, we proposed a Spatio-Temporal Collaborative Multiple-Stream Transformer Network that simultaneously considers spatial contrast and temporal variations to obtain detailed information on anatomical structures and tissue dynamics, effectively organizing and utilizing multiple-sequence MRI for analysis. Specifically, multiple-sequence MRI is first grouped into multiple streams based on MRI diagnostic characteristics. To reduce the interference of redundancy across multiple streams, we design a bottleneck bridge structure for spatial information aggregation. Additionally, we adopt a bidirectional Long Short-Term Memory to simulate radiologists observing the vascular morphology and hemodynamics in lesion sites from contrast-enhanced sequences. Experiments conducted on public MRI dataset, which includes seven categories of focal liver lesions from 498 patients, demonstrate that our framework achieves state-of-the-art performance, with an accuracy of 85.6%, a precision of 87.4%, a recall of 84.2%, an F1-score of 85.3%, and an Area Under the Curve of 97.1%. The experimental results indicate that the network performs well in predicting focal liver lesions, advancing the application of precision medicine. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Huang2025Spatio-temporal
ER  -

TY  - JOUR
AU  - Strem, N.
AU  - Dhami, D.S.
AU  - Schmidt, B.
AU  - Klöpper, B.
AU  - Kersting, K.
TI  - APT: Alarm Prediction Transformer
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125521
DO  - 10.1016/j.eswa.2024.125521
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206903947&doi=10.1016%2fj.eswa.2024.125521&partnerID=40&md5=5a5bc7a06e4da26cd9bca362da7dba86
AB  - Distributed control systems (DCS) are essential to operate complex industrial processes. A major part of a DCS is the alarm system, which helps plant operators to keep the processes stable and safe. Alarms are defined as threshold values on individual signals taking into account minimum reaction time of the human operator. In reality, however, alarms are often noisy and overwhelming, and thus can be easily overlooked by the operators. Early alarm prediction can give the operator more time to react and introduce corrective actions to avoid downtime and negative impact on human safety and the environment. In this context, we introduce Alarm Prediction Transformer (APT), a multimodal Transformer-based machine learning model for early alarm prediction based on the combination of recent events and signal data. Specifically, we propose two novel fusion strategies and three methods of label encoding with various levels of granularity. Given a window of several minutes of event logs and signal data, our model predicts whether an alarm is going to be triggered after a few minutes and, if yes, it also predicts its location. Our experiments on two novel real industrial plant data sets and a simulated data set show that the model is capable of predicting alarms with the given horizon and that our proposed fusion technique combining inputs from different modalities, i. e. events and signals, yields more accurate results than any of the modalities alone or conventional fusion techniques. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Strem2025APT
ER  -

TY  - JOUR
AU  - Shu, X.
AU  - Li, H.
AU  - Wen, W.
AU  - Qiao, R.
AU  - Li, N.
AU  - Ruan, W.
AU  - Su, H.
AU  - Wang, B.
AU  - Chen, S.
AU  - Zhou, J.
TI  - Precise occlusion-aware and feature-level reconstruction for occluded person re-identification
PY  - 2025
T2  - Neurocomputing
VL  - 616
C7  - 128919
DO  - 10.1016/j.neucom.2024.128919
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209995499&doi=10.1016%2fj.neucom.2024.128919&partnerID=40&md5=cbc605ecb3092880f9d46570936f20d4
AB  - Occluded person re-IDentification (re-ID) is a challenging task in surveillance scenarios that remains unresolved. To address it, existing methods primarily rely on auxiliary models, e.g. pose estimation, to explore visible parts by detecting human keypoints. However, these approaches inevitably encounter two issues: domain gap and information asymmetry. The former arises from pre-training auxiliary models on different domains, while the latter indicates that the occluded query has asymmetric valid cues compared to the holistic visible gallery. In this paper, we propose a novel Precise Occlusion-aware and Feature-level Reconstruction (POFR) network for occluded re-ID. POFR addresses the occlusion issue from two viewpoints: perceiving the occlusions other than visible human bodies and reconstructing the occluded parts at the feature level. The first perspective is achieved through occlusion-driven contrastive learning (OCL). OCL incorporates an occlusion generator capable of generating object and person-specific occlusions. Unlike previous coarse occlusions, our generator leverages segmented pedestrians and obstacles to generate realistic occlusions which are then used for contrastive learning. The second perspective is implemented through an occlusion-guided feature reconstruction (OFR) module. OFR initially learns an occlusion predictor to estimate the occlusion mask, which is subsequently utilized to recover features corresponding to the occluded regions. Benefiting from the occlusion generator, the occlusion predictor can be effectively supervised with the precise occlusion masks, thereby mitigating the domain gap problem. Additionally, the recovered features alleviate information asymmetry when matching an occluded query and a holistic gallery. Extensive experiments conducted on occluded, partial, and holistic datasets demonstrate the superior performance of our POFR over state-of-the-art methods. The source code will be made publicly available upon paper acceptance. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Shu2025Precise
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Ren, X.
AU  - Li, J.
AU  - Chen, X.
AU  - Zhu, X.
TI  - Prediction of circRNA-drug sensitivity using random auto-encoders and multi-layer heterogeneous graph transformers
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 3
C7  - 238
DO  - 10.1007/s10489-024-05859-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213727175&doi=10.1007%2fs10489-024-05859-3&partnerID=40&md5=a744ef4c75d6fdc3100a735100342c3e
AB  - A growing evidence has demonstrated that the expression of circRNAs have significant impact on cell sensitivity to drugs, thereby affecting drug efficacy. Several computational methods have been developed to identify potential circRNA-drug sensitivity associations based on graph auto-encoder and multi-modal information of circRNA and drugs. However, multi-modal information may still lead to a local embedding representation space. And the graph auto-encoder is easy to neglect the global information of the whole graph. Thus, the predictive performance of existing methods is still not satisfactory and needs improvement. In this study, we introduce a model named MHGTCDA for forecasting potential circRNA-drug sensitivity associations using adaptive random auto-encoders (RAEs) and multi-layer Heterogeneous Graph Transformers (MHGT). Firstly, random auto-encoders are used to encode the circRNAs and drugs, respectively. Secondly, MHGT framework is used to obtain context representation of the nodes, which directly utilizes the edge information of the bipartite graph composed of circRNA-drug pairs, thereby reducing information loss. Then, the concatenated embedding matrices of circRNAs and drugs from MHGT are decoded through inner product to obtain the predicted circRNA-drug sensitivity associations. Extensive cross-validation experiments demonstrate that MHGTCDA outperforms nine other state-of-the-art methods. Case studies further illustrate the excellent predictive ability of the proposed method. These results highlight the potential of MHGTCDA as a valuable method for predicting circRNA-drug sensitivity associations, offering significant benefits to drug development. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2025Prediction
ER  -

TY  - JOUR
AU  - Wu, Q.
AU  - Liu, Y.
AU  - Chen, S.
AU  - Xu, W.
AU  - Wu, Y.
AU  - Zhu, X.
AU  - Yue, Y.
TI  - Attention holistic processing multi-channel graph transformer with graph residual connections for predicting lncRNA–Protein interactions
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 310
C7  - 112957
DO  - 10.1016/j.knosys.2025.112957
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214304780&doi=10.1016%2fj.knosys.2025.112957&partnerID=40&md5=c1f6c9514ee0423540556745f7b88a0b
AB  - Understanding the interactions between long non-coding RNAs (lncRNAs) and proteins is crucial for elucidating complex regulatory mechanisms within cells. Recent advances in graph-neural-network prediction methods have been significant. However, they still insufficiently address the sparsity of data in predicting associations between lncRNAs and proteins, and often overlook the importance of weighting multilevel representations during the encoding process of lncRNAs and proteins. Moreover, the high complexity of encoding networks can lead to model instability. We introduce a novel approach called the Graph residual connection attention Holistic processing multiple Channels graph Transformer (GHCT) for predicting interactions between lncRNAs and proteins. This model leverages identity feature matrices for adaptive encoding and employs deep graph residual modules to resolve issues of model instability. The GHCT captures complex feature representations and long-distance dependencies through holistic attentional processing. It also utilises this graph multichannel attention mechanism to capture cross-channel graph aggregation information and effectively capture and integrate information from different data channels. Finally, matrix multiplication is used for decoding and prediction. We conducted extensive experiments on three widely used datasets, including sparse datasets, in which our GHCT model achieved area under the curve (AUC) scores of 0.9775, 0.9746, and 0.9808, significantly outperforming other state-of-the-art models. Moreover, we conducted ten repeated experiments on imbalanced and noisy datasets, the results of which demonstrated the excellent generalisation and noise resistance capabilities of our model. Our case studies have also shown that our method can discover new lncRNA–protein interactions, providing valuable insights for predicting the interactions between lncRNAs and proteins. © 2025 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Wu2025Attention
ER  -

TY  - JOUR
AU  - Gao, R.
AU  - Wang, J.
AU  - Yu, Y.
AU  - Wu, J.
AU  - Zhang, L.
TI  - Enhanced graph diffusion learning with dynamic transformer for anomaly detection in multivariate time series
PY  - 2025
T2  - Neurocomputing
VL  - 619
C7  - 129168
DO  - 10.1016/j.neucom.2024.129168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212553210&doi=10.1016%2fj.neucom.2024.129168&partnerID=40&md5=ce1e0590e4142c3c3370f94e33b28c04
AB  - In recent years, deep learning-based multivariate time series anomaly detection methods have significantly improved detection performance by accurately modeling the spatiotemporal correlations in sensor data. However, they still face the following challenges: the complexity of signals acquired from sensors makes it difficult to capture the true hidden spatial relationships between sensors. Local features and global correlations of time series data are ignored in capturing accurately the temporal correlations of multivariate time series. To address these problems, we propose a Graph Diffusion Transformed Spatiotemporal model(GDTS) for multivariate time series anomaly detection. Specifically, we first extend a newly developed diffusion probability model to spatial correlation modeling of sensors, which results in a new graph diffusion network. During the diffusion process, we design a novel L2 regularized weighted dot product diffusion function with energy constraints to guide information propagation for accurately capturing the hidden spatial dependencies between sensors. Moreover, we develop a variant of the transformer model with a hybrid sampling strategy to capture the local features and global correlations of time series, which comprehensively describes the temporal correlation of time series data. Subsequently, the multivariate time series features are jointly optimized at the spatio-temporal level for prediction. Finally, the threshold method is used to measure the deviation between the actual observed value and the predicted value to accomplish anomaly detection. Extensive experiments on real-world publicly available datasets demonstrate that GDTS significantly outperforms several state-of-the-art methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Gao2025Enhanced
ER  -

TY  - JOUR
AU  - Yan, X.
AU  - Zhang, X.
AU  - Xia, S.
TI  - Multi-View topology assisted dynamic graph learning for fMRI-based Alzheimer's disease identification
PY  - 2025
T2  - Neurocomputing
VL  - 618
C7  - 129025
DO  - 10.1016/j.neucom.2024.129025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211499673&doi=10.1016%2fj.neucom.2024.129025&partnerID=40&md5=8f17ca15a06f3f43928743ec14d19286
AB  - Resting-state functional magnetic resonance imaging (rs-fMRI) provides a non-invasive technology that helps identify abnormal connections in the brain by tracking changes in blood flow components. Functional connectivity networks (FCNs) derived from fMRI data are commonly used for identifying brain disorders such as Alzheimer's disease (AD). Unfortunately, most existing AD identification models rely solely on static single-view FCN (e.g., Pearson correlation, PC), neglecting the temporal information and complex topological structures present in fMRI data. Additionally, the imbalance of training data significantly hampers the generalization ability of the model. To this end, we propose a multi-view topology assisted dynamic graph learning (MTDGL) framework for fMRI analysis and AD automated identification, with a three-pipeline fMRI feature extraction structure composed of a spatiotemporal branch, a topological branch and a raw information branch. At the outset, we adopt a category balancing strategy for the training data to enhance the representation ability of the model. In the spatiotemporal branch, we employ a spatiotemporal attention graph isomorphism network (STAGIN) to capture latent dynamic representations in fMRI data. In the topological branch, we integrate topological information extracted from multiple views (i.e., PC, mutual information, MI). In the raw information branch, we extract the fine-grained information in the raw signal and adaptively fuse them with the dynamic representations for the final AD classification task. This can overcome the limitations of single-view methods in describing topological structures. In the feature fusion stage, the relevant features are first integrated, and then the original signal features are merged into these integrated relevant features through the Transformer model to achieve deep fusion between the two main information streams. The experimental results on the ADNI dataset demonstrate that the proposed MTDGL achieves an accuracy of 92.43% in AD recognition, outperforming several state-of-the-art approaches. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yan2025Multi-View
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Zhao, Y.
AU  - Xu, Y.
TI  - TransformerLSR: Attentive joint model of longitudinal data, survival, and recurrent events with concurrent latent structure
PY  - 2025
T2  - Artificial Intelligence in Medicine
VL  - 160
C7  - 103056
DO  - 10.1016/j.artmed.2024.103056
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212409707&doi=10.1016%2fj.artmed.2024.103056&partnerID=40&md5=98d0ef2d449415c2b4552abc1d467b74
AB  - In applications such as biomedical studies, epidemiology, and social sciences, recurrent events often co-occur with longitudinal measurements and a terminal event, such as death. Therefore, jointly modeling longitudinal measurements, recurrent events, and survival data while accounting for their dependencies is critical. While joint models for the three components exist in statistical literature, many of these approaches are limited by heavy parametric assumptions and scalability issues. Recently, incorporating deep learning techniques into joint modeling has shown promising results. However, current methods only address joint modeling of longitudinal measurements at regularly-spaced observation times and survival events, neglecting recurrent events. In this paper, we develop TransformerLSR, a flexible transformer-based deep modeling and inference framework to jointly model all three components simultaneously. TransformerLSR integrates deep temporal point processes into the joint modeling framework, treating recurrent and terminal events as two competing processes dependent on past longitudinal measurements and recurrent event times. Additionally, TransformerLSR introduces a novel trajectory representation and model architecture to potentially incorporate a priori knowledge of known latent structures among concurrent longitudinal variables. We demonstrate the effectiveness and necessity of TransformerLSR through simulation studies and analyzing a real-world medical dataset on patients after kidney transplantation. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2025TransformerLSR
ER  -

TY  - JOUR
AU  - Thibeault, S.
AU  - Roy-Beaudry, M.
AU  - Parent, S.
AU  - Kadoury, S.
TI  - Prediction of the upright articulated spine shape in the operating room using conditioned neural kernel fields
PY  - 2025
T2  - Medical Image Analysis
VL  - 100
C7  - 103400
DO  - 10.1016/j.media.2024.103400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210538490&doi=10.1016%2fj.media.2024.103400&partnerID=40&md5=6dd2cf04bc279389c5cf3396b3f349c1
AB  - Anterior vertebral tethering (AVT) is a non-invasive spine surgery technique, treating severe spine deformations and preserving lower back mobility. However, patient positioning and surgical strategies greatly influences postoperative results. Predicting the upright geometry from pediatric spines is needed to optimize patient positioning in the operating room (OR) and improve surgical outcomes, but remains a complex task due to immature bone properties. We propose a framework used in the OR predicting the upright spine geometry at the first visit following surgery in idiopathic scoliosis patients. The approach first creates a 3D model of the spine while the patient is on the operating table. For this, multiview Transformers that combine images from different viewpoints are used to generate the intraoperative pose. The postoperative upright shape is then predicted on-the-fly using implicit neural fields, which are trained from geometries at different time points and conditioned with surgical parameters. A Signed Distance Function for shape constellations is used to handle the variability in spine appearance, capturing a disentangled latent domain of the articulation vectors, with separate encoding vectors representing both articulation and shape parameters. A regularization criterion based on a pre-trained group-wise trajectory of spine transformations generates complete spine models. A training set of 652 patients with 3D models was used to train the model, tested on a distinct cohort of 83 surgical patients. The framework based on neural kernels predicted upright 3D geometries with a mean 3D error of 1.3±0.5mm in landmarks points, and IoU of 95.9% in vertebral shapes when compared to actual postop models, falling within the acceptable margins of error below 2 mm. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Thibeault2025Prediction
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Zhang, Y.
AU  - Kampffmeyer, M.
AU  - Pan, Y.
AU  - Zhang, C.
AU  - Sun, S.
AU  - Chang, H.
AU  - Zhao, X.
TI  - HierGAT: hierarchical spatial-temporal network with graph and transformer for video HOI detection
PY  - 2025
T2  - Multimedia Systems
VL  - 31
IS  - 1
C7  - 13
DO  - 10.1007/s00530-024-01604-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212107805&doi=10.1007%2fs00530-024-01604-5&partnerID=40&md5=f5001b622891ac955dafe1771e08a6a6
AB  - Different from traditional video-based HOI detection, which is confined to segment labeling only, the task of joint segmentation and labeling for video HOI requires predicting human sub-activity and object affordance labels while delineating their segment boundaries. Previous methods mainly rely on frame-level and segment-level features to predict segmentation boundaries and labels. However, recognizing the significance of inter-frame and long-term temporal information is imperative. Therefore, to address this task and delve deeper into the temporal dynamics of human–object interactions, we propose a novel Hierarchical spatial-temporal network with Graph And Transformer (HierGAT). This framework integrates two branches: a temporal-enhanced recurrent graph network (TRGN) and parallel transformer encoders (PTE), aimed at extracting hierarchical temporal features from video data. We first augment the temporal aspect of the recurrent graph network by incorporating inter-frame interactions to capture spatial-temporal information within and across frames. Considering the auxiliary role of adjacent frames, we also propose a grouped fusion mechanism to fuse the obtained interaction information. The parallel transformer encoders branch consists of two parallel transformer encoders to extract spatial and long-term temporal information in the video. By leveraging the outputs from these branches, our model fully exploits spatial-temporal information to predict segmentation boundaries and labels. Experimental results across three datasets demonstrate the effectiveness of our approach. All the codes and data can be found at https://github.com/wjx1198/HierGAT. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2025HierGAT
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Lei, F.
AU  - Wang, B.
AU  - Zhang, Q.
AU  - Zhen, X.
AU  - Zhang, L.
TI  - De-noising mask transformer for referring image segmentation
PY  - 2025
T2  - Image and Vision Computing
VL  - 154
C7  - 105356
DO  - 10.1016/j.imavis.2024.105356
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211112052&doi=10.1016%2fj.imavis.2024.105356&partnerID=40&md5=57ebb1d27e229df30418206b1469d475
AB  - Referring Image Segmentation (RIS) is a challenging computer vision task that involves identifying and segmenting specific objects in an image based on a natural language description. Unlike conventional segmentation methodologies, RIS needs to bridge the gap between visual and linguistic modalities to exert the semantic information provided by natural language. Most existing RIS approaches are confronted with the common issue that the intermediate predicted target region also participates in the later feature generation and parameter updating. Then the wrong prediction, especially occurs in the early training stage, will bring the gradient misleading and ultimately affect the training stability. To tackle this issue, we propose de-noising mask (DNM) transformer to fuse the cross-modal integration, a novel framework to replace the cross-attention by DNM-attention in traditional transformer. Furthermore, two kinds of DNM-attention, named mask-DNM and cluster-DNM, are proposed, where noisy ground truth information is adopted to guide the attention mechanism to produce accurate object queries, i.e., de-nosing query. Thus, DNM-attention leverages noisy ground truth information to guide the attention mechanism to produce additional de-nosing queries, which effectively avoids the gradient misleading. Experimental results show that the DNM transformer improves the performance of RIS and outperforms most existing RIS approaches on three benchmarks. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2025De-noising
ER  -

TY  - JOUR
AU  - Jiang, H.
AU  - Liu, D.
AU  - Ding, X.
AU  - Chen, Y.
AU  - Li, H.
TI  - TCM: An efficient lightweight MLP-based network with affine transformation for long-term time series forecasting
PY  - 2025
T2  - Neurocomputing
VL  - 617
C7  - 128960
DO  - 10.1016/j.neucom.2024.128960
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210114480&doi=10.1016%2fj.neucom.2024.128960&partnerID=40&md5=586374be4950b040733b0221e280420b
AB  - Time series forecasting (TSF) involves extracting underlying patterns from past information to predict future sequences over a specific period. Extending the prediction length of time series and improving the prediction accuracy have always been challenging tasks. Autoregressive prediction methods based on Markov chains tend to accumulate errors over time. Although Transformer-based methods with various self-attention mechanisms have shown some improvements, they require higher memory and computational resources. In this work, we present an effective MLP-based TSF framework named TCM, which models the sequence and channel dependencies separately using Token MLP and Channel MLP. Additionally, we employ the Affine Transformation to replace layer normalization or batch normalization, leading to substantial enhancements in both accuracy and inference speed. Compared to current state-of-the-art long-term time series forecasting models, TCM achieves 6.0% relative improvement on seven real-world datasets, including electricity, weather, and illness domains. The TCM model, characterized by its efficiency and lightweight architecture, also makes it suitable for scenarios with high real-time requirements. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jiang2025TCM
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Guo, L.
AU  - Wang, G.
AU  - Yu, J.
AU  - Zheng, X.
AU  - Mei, Y.
AU  - Han, B.
TI  - A dual-level graph attention network and transformer for enhanced trajectory prediction under road network constraints
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125510
DO  - 10.1016/j.eswa.2024.125510
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206507982&doi=10.1016%2fj.eswa.2024.125510&partnerID=40&md5=655485a587154a66d604223af2dc6e23
AB  - Predicting vehicle future trajectories enables various Location-Based Services (LBS), including traffic flow monitoring, vehicle route planning, etc. Vehicles are constrained to predefined road networks. Their traveling behaviors are influenced by both their own attributes and road network characteristics hidden in other vehicles’ travel histories. Most of the existing methods fail to sufficiently leverage such collaborative trajectory data under road network constraints. This paper proposes a novel model, called HGT-RN (Hierarchical Graph Attention Network and Transformer Networks for Enhanced Trajectory Prediction under Road Network Constraints), which exploits all vehicles’ trajectories and integrates road network constraints. Specifically, HGT-RN creates a dual-level Graph Attention Network (GAT) based on global traffic flow and local individual trajectory graph to learn trajectory embeddings: (i) Weighted-directional global traffic flow graph and Weighted-Directional GAT to learn the global-level trajectory embedding by aggregating the neighbors’ embeddings based on the spatial transitional relationships among road intersections over all vehicles’ trajectories, considering the preference of current trajectory; and (ii) Local individual trajectory graph attention network to learn the local-level trajectory embedding by modeling the transitions within the current trajectory at each intersection. When incorporating the trajectory embeddings into a transformer model for future trajectory prediction, a road network topology-aware loss function is designed to improve accuracy. Extensive experiments conducted on three city-scale real-world taxi trajectory datasets demonstrate that HGT-RN significantly outperforms existing baseline models. The code is available at https://github.com/zjy9826/HGT-RN. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2025dual-level
ER  -

TY  - JOUR
AU  - Gao, H.
AU  - Guo, Q.
AU  - Zhang, Z.
AU  - Li, Y.
TI  - An integrated feature extraction framework of linear multi-layer perceptron to reduce computation complexity for remaining useful life prediction
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 141
C7  - 109846
DO  - 10.1016/j.engappai.2024.109846
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211967819&doi=10.1016%2fj.engappai.2024.109846&partnerID=40&md5=bce6a69db0f08cecc0c06f118d920519
AB  - Recently, there has been a growth in deep learning-based solutions for RUL prediction, although these increasingly complex models have significantly improved prediction performance, these studies typically overlook the computational and storage resources required for model deployment. Thus, we attempt to construct a lightweight model based on a simple linear multi-layer perceptron (MLP) that achieves prediction performance comparable to complex models, while ensuring easier deployment on resource-constrained edge devices. Firstly, a feature reconstruction method based on unsupervised clustering is proposed, which uses the K-means algorithm to perform unsupervised clustering on the variable operating condition data, and then standardization is conducted according to the mean and variance of each class, so as to separate the degradation features from the operating condition. Then, we propose a time-series linear extractor (TiLE) architecture for extracting degradation features from multi-sensor data. This lightweight framework achieves the advantage of linear computational scalability, which improves the inference efficiency of the model. The feature recalibration mechanism of TiLE is designed to reduce the interference of random factors, which is conducive to improving the prediction accuracy. Experimental results on the NASA turbine engine dataset show that the TiLE-based model outperforms state-of-the-art methods while achieving superior computational complexity and inference efficiency. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Gao2025integrated
ER  -

TY  - JOUR
AU  - Alfarisy, G.A.F.
AU  - Malik, O.A.
AU  - Hong, O.W.
TI  - Towards Unsupervised Domain-Specific Open-World Recognition
PY  - 2025
T2  - Neurocomputing
VL  - 619
C7  - 129141
DO  - 10.1016/j.neucom.2024.129141
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212229266&doi=10.1016%2fj.neucom.2024.129141&partnerID=40&md5=241a4be224ebbd8899b964356df80b3c
AB  - Open-World Recognition (OWR) is an emerging study that constructs machine-learning models to recognize unknown classes and learn them continually. The classical formalization of OWR relies on three main components: classifier, unknown identification, and continual learning. However, for a model that operates on domain-specific tasks, training rejected unknown classes directly will harm the models in terms of effectivity and efficiency (i.e., a waste collector robot will learn unnecessary classes and will collect novel non-waste objects). Filtering these novel objects manually requires human-in-the-loop which is costly and unable to learn on the job. Therefore, in this study, we introduce and formalize Unsupervised Domain-specific Open-world Recognition (UDOR) that has the potential framework to achieve a fully automated agent in an open-world environment. In addition, we formalize the specific component in UDOR called novelty manager to assist the model to learn on the job. Furthermore, we propose a unified model using Continual Multi-Channel Contrastive Prototype Networks (CMCCPN), Automated Machine learning (AutoML), and class discovery with Hierarchical DBSCAN (HDBSCAN) or First Integer Neighbor Clustering Hierarchy (FINCH) as a step towards UDOR. Our experimentation results suggest that CMCCPN produced the highest performance, AutoML provides almost exemplary capability in differentiating novel classes, and Vision Transformer with HDBSCAN or FINCH shows a good technique to be investigated in discovering classes with a small number of classes. Our source code is available at https://github.com/gusti-alfarisy/udor. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Alfarisy2025Towards
ER  -

TY  - JOUR
AU  - Le, V.-T.
AU  - Jin, H.
AU  - Kim, Y.-G.
TI  - HSTforU: anomaly detection in aerial and ground-based videos with hierarchical spatio-temporal transformer for U-net
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 4
C7  - 261
DO  - 10.1007/s10489-024-06042-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214099011&doi=10.1007%2fs10489-024-06042-4&partnerID=40&md5=a471c40db6ac373d8383bc65430236eb
AB  - Anomaly detection is to identify abnormal events against normal ones within surveillance videos mainly collected in ground-based settings. Recently, the demand for processing drone-collected data is rapidly growing with the expanding range of drone applications. However, as most aerial videos collected by flying drones contain dynamic backgrounds and others, it is necessary to deal with their spatio-temporal features in detecting anomalies. This study presents a transformer-based video anomaly detection method whereby we investigate a challenging aerial dataset and three benchmark ground-based datasets. A multi-stage transformer is leveraged as an encoder to generate multi-scale feature maps, which are then conveyed to a hierarchical spatio-temporal transformer, that is linked to a decoder and used to capture spatial and temporal information by utilizing a joint attention mechanism. Extensive evaluations including several ablation studies suggest that this network outperforms the state-of-the-art methods. We expect the proposed transformer for U-net can find diverse applications in the video processing area. Code and pre-trained models are publicly available at https://github.com/vt-le/HSTforU. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Le2025HSTforU
ER  -

TY  - JOUR
AU  - Fu, C.
AU  - Su, Y.
AU  - Su, K.
AU  - Liu, Y.
AU  - Shi, J.
AU  - Wu, B.
AU  - Liu, C.
AU  - Ishi, C.T.
AU  - Ishiguro, H.
TI  - HAM-GNN: A hierarchical attention-based multi-dimensional edge graph neural network for dialogue act classification
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125459
DO  - 10.1016/j.eswa.2024.125459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205595921&doi=10.1016%2fj.eswa.2024.125459&partnerID=40&md5=1999a1df6069276615d348ea4a21e688
AB  - Dialogue act (DA) analysis is crucial for developing natural conversational systems and dialogue generation. Modelling DA labels at the utterance-level requires contextual and speaker-aware understanding, especially for conversational agents handling Japanese dialogues. In this study, we propose a Hierarchical Attention-based Multi-dimensional Edge Graph Neural Network (HAM-GNN) to effectively model DA labels by capturing speaker interconnections and contextual semantics. Specifically, long short-term memory networks (LSTMs) first encode contextual information within a dialogue window. We then construct a context graph by aggregating neighbouring utterances and apply a graph attention network (GAT) to model speaker interactions with multi-dimensional edges. To prevent incorrect edge definitions from completely deactivating connections during training, we initialize soft edges for nominally unconnected nodes with a small non-zero value. Moreover, to avoid loss of contextual information from localized graph construction, we utilize a convolutional Transformer (Conformer) to build residual connections. Subsequently, a gated graph convolutional network (GatedGCN) selects salient utterances for DA classification. Finally, multi-level representations are merged and fed to dense layers for classification. We evaluate our HAM-GNN model on the Japanese DA dataset (JPS-DA) and the English Switchboard DA dataset (SWDA). Results show our method outperforms baselines on JPS-DA and achieves competitive performance on SWDA. The graph-based architecture effectively encodes utterance semantics and speaker relationships for DA prediction in conversational systems. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Fu2025HAM-GNN
ER  -

TY  - JOUR
AU  - Xue, Q.
AU  - Ma, J.
AU  - Zhao, X.
AU  - Liu, R.
AU  - Li, H.
AU  - Zhu, X.
TI  - Informer-FDR: A short-term vehicle speed prediction model in car-following scenario based on traffic environment
PY  - 2025
T2  - Expert Systems with Applications
VL  - 262
C7  - 125655
DO  - 10.1016/j.eswa.2024.125655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208111035&doi=10.1016%2fj.eswa.2024.125655&partnerID=40&md5=d77e7d2a8db5fea65b32ff6877a6ca30
AB  - Drivers’ car-following behaviors on urban roads are influenced by various factors, including pedestrians, cyclists, adjacent vehicles, and roadside parking. However, few models consider these factors’ influence on drivers’ speed selections during car-following, limiting the human-like driving capability of advanced driver assistance systems (ADAS). This paper proposes a vehicle speed prediction model in car-following scenario that considers the influences of the traffic environment. The vehicle speed is predicted using Informer-FDR (Informer with fusion features, dilated causal convolution, and residual connection), which adopts an improved encoder-decoder structure based on the Informer model. Fusing features of traffic environment characteristics and vehicle dynamics parameters enables the dynamic interaction characteristics between drivers and the traffic environment and potential traffic conflicts to be effectively reflected, which enhances the model's understanding of the complex driving environment. Moreover, the high computational complexity is reduced by using the ProbSparse self-attention mechanism, which will help to address the difficulty of applying Transformer class models to on-board platforms. Totally 3,980 car-following cases were extracted from naturalistic driving data (NDD), vehicle dynamics parameters and traffic environment characteristics in the car-following scenarios were obtained through target detection and ranging algorithm. The optimal feature set was mined using the combined feature selection method. The dilated causal convolution and average pooling layer are introduced to expand the receptive field of the model, enhance global feature extraction, and ensure the causality of temporal predictions. Furthermore, the residual connection was added to the encoder, realizing the direct deep transfer of cross-layer information. Verifications on the test set show that Informer-FDR has the lowest MAE (0.583), MSE (2.942), RMSE (1.715), and the highest speed prediction accuracy (97.76%), spacing gap accuracy (94.27%), acceleration accuracy (95.35%), which outperforms other baseline models in terms of prediction performance. The ablation study confirms the importance of the improved distilling layer module, residual connection module, and fusion features for predictive performance improvement. Additionally, the road-type experiment reveals performance differences of the model on different road types, emphasizing the importance of incorporating traffic environment on urban road. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Xue2025Informer-FDR
ER  -

TY  - JOUR
AU  - Yu, R.
AU  - Chen, M.
AU  - Liu, B.
TI  - A triple-phase boost transformer for industrial equipment fault prediction
PY  - 2025
T2  - Neurocomputing
VL  - 619
C7  - 129137
DO  - 10.1016/j.neucom.2024.129137
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211697114&doi=10.1016%2fj.neucom.2024.129137&partnerID=40&md5=4960ade7aa8b2dd322ff8e8dce0918b1
AB  - To address the critical demand for predictive maintenance (PdM) in the industrial scene, our proposed solution is the triple-phase boost transformer (THOR) model. This model achieves accurate time-series multi-label classification and provides an end-to-end solution that includes unsupervised anomaly detection for fault prediction. To further enhance the model's ability to detect anomalies, we have implemented a min–max loss training approach. This approach amplifies the discrepancy between normal and abnormal patterns, enabling the identification of more obscure anomalies. Additionally, THOR incorporates the use of Discrete Wavelet Transformation (DWT) and designs a DWT attention mechanism for developing frequency-enhanced transformers. This advancement lends greater power to both anomaly detection and capturing temporal signatures for fault prediction. In our real-world case analysis, the effectiveness of the proposed method is verified. With our approach, we achieved precision rates of at least 97.44%, rates of 92.77%, and F1-scores of 0.95 or above, surpassing the performance of other existing fault prediction models in multi-class fault prediction. Therefore, our THOR model offers a valuable solution to the limitations faced by current fault prediction models. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yu2025triple-phase
ER  -

TY  - JOUR
AU  - Ruiz-Santaquiteria, J.
AU  - Pedraza, A.
AU  - Deniz, O.
AU  - Bueno, G.
TI  - DT4PEIS: detection transformers for parasitic egg instance segmentation
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 4
C7  - 271
DO  - 10.1007/s10489-024-06199-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214094518&doi=10.1007%2fs10489-024-06199-y&partnerID=40&md5=d06e9d5b71935fd680f0ff44becadf80
AB  - Parasitic infections pose a significant health risk in many regions worldwide, requiring rapid and reliable diagnostic methods to identify and treat affected individuals. Recent advancements in deep learning have significantly improved the accuracy and efficiency of microscopic image analysis workflows, enabling its application in various domains such as medical diagnostics and microbiology. This work presents DT4PEIS, a novel two-stage architecture for the instance segmentation of parasite eggs in microscopic images. The first stage is a DEtection TRansformer (DETR) based architecture, which predicts the bounding boxes and class labels of the detected eggs. Then, the predicted bounding boxes are used as prompts to guide the segmentation process in the second stage, which is based on the Segment Anything Model (SAM) architecture. We evaluate the performance of the proposed method on the Chula-ParasiteEgg-11 dataset. Our results show that the proposed method outperforms the other architectures in terms of segmentation mean Average Precision (mAP), providing a more detailed and accurate representation of the detected eggs. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Ruiz-Santaquiteria2025DT4PEIS
ER  -

TY  - JOUR
AU  - Xia, H.
AU  - Meng, T.
TI  - Unsupervised model-guided online transfer learning framework for multiple fault detection of satellite control system
PY  - 2025
T2  - Neurocomputing
VL  - 618
C7  - 129149
DO  - 10.1016/j.neucom.2024.129149
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211581405&doi=10.1016%2fj.neucom.2024.129149&partnerID=40&md5=fc07879da8392af2fede3b70de23ca4a
AB  - Satellite in-orbit fault detection is critical for satellite reliability and safety. Although fault detection has been extensively studied from signal processing to data-driven methods, there has been less discussion on the problem of fault detection when multiple faults coexist. To address this challenge, this paper proposes a novel unsupervised model-guided online transfer learning method. The method utilizes model-guided to reduce the influence of the control algorithm on the control system. Then, a complexity analyzer is designed to select an appropriate prediction model for each satellite component. Finally, an adaptive threshold setting method based on Wasserstein distance optimization and online transfer learning is combined to achieve accurate detection of each fault when multiple faults coexist. Simulation experiments on multiple fault datasets of six components of a satellite control system, including fault detection accuracy experiments, ablation experiments, and comparison experiments, show that the method is more effective when multiple faults coexist compared to other four advanced fault detection methods. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xia2025Unsupervised
ER  -

TY  - JOUR
AU  - Ma, S.
AU  - Chen, C.
AU  - Zhang, L.
AU  - Yang, X.
AU  - Zhang, J.
AU  - Zhao, X.
TI  - AMTrack:Transformer tracking via action information and mix-frequency features
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125451
DO  - 10.1016/j.eswa.2024.125451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205568519&doi=10.1016%2fj.eswa.2024.125451&partnerID=40&md5=86fd73d0300af9d051c5b9c84e9755db
AB  - Nowadays, Transformer-based visual tracking algorithms have been developing quickly because of the self-attention mechanism of Transformer, which has the capability to model global information. Although the self-attention mechanism in Transformer can effectively capture long-range dependencies in feature space, they only use flattened two-dimensional features and are unable to capture long-range temporal dependencies. Furthermore, since the self-attention in Transformer functions as a low-pass filter, it picks up on low-frequency features of the target while ignoring high-frequency features. This research suggests a Transformer tracker based on action information and mix-frequency features (AMTrack) to address these problems. Specifically, to address the lack of temporal remote dependencies, we introduce the target action aware module and the target action offset module. The target action aware module sets up several pathways to extract spatio-temporal, channel, and motion feature independently. In contrast, the target action offset module computes the target's offset information by computing relative feature maps. Furthermore, in order to address the imbalance between high and low frequency features, we propose a mix-frequency attention and multi-frequency self-attention convolutional block. The mix-frequency attention uses high-frequency features within partitioned local windows as input for the high-frequency branch and average-pooled low-frequency features as the input for the low-frequency branch, calculating attention scores in both branches respectively. The multi-frequency self-attention convolutional block uses self-attention to capture low-frequency features and convolution to capture high-frequency features. Extensive experiments are carried out on eight challenging tracking datasets (e.g., OTB100 (Object Tracking Benchmark 100), NFS (Need For Speed), UAV123 (Unmanned Aerial Vehicles 123), TC128 (Temple Color 128), VOT2018 (Visual Object Tracking 2018), LaSOT (Large-scale Single Object Tracking), TrackingNet (Tracking Network), GOT-10k (Generic Object Tracking-10k)), and the experimental results show that our tracker achieves excellent tracking performance when compared with several state-of-the-art tracking algorithms. The experimental results show that on LaSOT, the success rates AUC (Area Under Curve), PNorm, and P reach 65.8%, 69.2%, and 68.0%, respectively, where the AUC value is 2.1% higher than the baseline algorithm TrDiMP (Transformer Discriminative Model Prediction). On other datasets, our tracker also achieves excellent tracking performance. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ma2025AMTrack:Transformer
ER  -

TY  - JOUR
AU  - Xia, H.
AU  - Chen, X.
AU  - Chen, B.
AU  - Hu, Y.
TI  - Dynamic synchronous graph transformer network for region-level air-quality forecasting
PY  - 2025
T2  - Neurocomputing
VL  - 616
C7  - 128924
DO  - 10.1016/j.neucom.2024.128924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209874945&doi=10.1016%2fj.neucom.2024.128924&partnerID=40&md5=00751a004d8d2c291b38bbc4dc96e467
AB  - Accurate forecasting of air quality aids in mitigating air pollution, enhancing the well-being of residents, and supporting the city's sustainable growth. Recent works have utilized graph neural network for spatial dependency modeling in air-quality forecasting task. However, many existing methods rely on separate components to individually capture temporal and spatial correlations, which makes it difficult to synchronously capture the multiscale spatiotemporal correlation (MSTCs) from the spatiotemporal graph. This paper proposed a dynamic synchronous graph transformer (DSGT) based on the Encoder-Decoder structure to forecast air quality of urban regions. It captures time-varying observed station readings through dynamic graph convolution operations and can learn the influence of auxiliary features. We designed a multiscale dynamic synchronous graph constructing way to construct graphs which can effectively encode the MSTCs. There is a multiscale spatiotemporal synchronous graph convolution component in DSGT for extracting multiscale spatiotemporal representation from the constructed graphs. The synchronous graph attention mechanism and temporal attention mechanism were designed to integrated into Encoder-Decoder structure to focus the long-term influence of auxiliary features and the short-term influence of multiscale spatiotemporal representation. Via extensive experiments on two real-world datasets, it is demonstrated that the proposed model outperforms existing methods in both short- and long-term forecasting. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xia2025Dynamic
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Yang, X.
AU  - Wang, X.
AU  - Fu, W.
AU  - Zhong, B.
AU  - Zhang, J.
TI  - SAM-Assisted Temporal-Location Enhanced Transformer Segmentation for Object Tracking with Online Motion Inference
PY  - 2025
T2  - Neurocomputing
VL  - 617
C7  - 128914
DO  - 10.1016/j.neucom.2024.128914
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210416059&doi=10.1016%2fj.neucom.2024.128914&partnerID=40&md5=16adafc69f87d0aae17647c9c4d9fc2c
AB  - Current transformer-based trackers typically represent targets using bounding boxes. However, bounding boxes do not accurately describe the target and uncontrollably contain most background pixels. This paper proposes a Segment Anything Model (SAM)-Assisted Temporal-Location Enhanced Transformer Segmentation for Object Tracking with Online Motion Inference. First, a novel transformer-based temporal-location enhanced segmentation method is proposed. The target temporal features are clustered into foreground–background tokens utilizing a mask to capture discriminative information distribution. Then, the suitable positional prompts are learned in the proposed mask prediction head to establish the mapping between target features and localization, which enhances the specific foreground weights for precise mask generation. Second, a temporal-based motion inference module is proposed. It fully utilizes the target temporal state to construct an online displacement model inferring motion relationships of the target between frames and providing robust position prompts for the segmentation process. We also introduce SAM for initial mask generation. Precise pixel-level object tracking is achieved by combining segmentation and localization within a unified process. Experimental results demonstrate that the proposed method yields competitive performance compared to existing approaches. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2025SAM-Assisted
ER  -

TY  - JOUR
AU  - Wang, B.
AU  - Yang, M.
AU  - Cao, P.
AU  - Liu, Y.
TI  - A novel embedded cross framework for high-resolution salient object detection
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 4
C7  - 277
DO  - 10.1007/s10489-024-06073-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214195924&doi=10.1007%2fs10489-024-06073-x&partnerID=40&md5=441f9d3820bffa4c69f78590fa5acd3e
AB  - Salient object detection (SOD) is a fundamental research topic in computer vision and has attracted significant interest from various fields, it has revealed two issues while driving the rapid development of salient detection. (1) The salient regions in high-resolution images exhibit significant differences in location, structure, and edge details, which makes them difficult to recognize and depict. (2) The traditional salient detection architecture is insensitive to detecting targets in high-resolution feature spaces, which leads to incomplete saliency predictions. To address these limitations, this paper proposes a novel embedded cross framework with a dual-path transformer (ECF-DT) for high-resolution SOD. The framework consists of a dual-path transformer and a unit fusion module for partitioning the salient targets. Specifically, we first design a cross network as a baseline model for salient object detection. Then, the dual-path transformer is embedded into the cross network with the objective of integrating fine-grained visual contextual information and target details while suppressing the disparity of the feature space. To generate more robust feature representations, we also introduce a unit fusion module, which highlights the positive information in the feature channels and encourages saliency prediction. Extensive experiments are conducted on nine benchmark databases, and the performance of the ECF-DT is compared with that of other existing state-of-the-art methods. The results indicate that our method outperforms its competitors and accurately detects the targets in high-resolution images with large objects, cluttered backgrounds, and complex scenes. It achieves MAEs of 0.017, 0.026, and 0.031 on three high-resolution public databases. Moreover, it reaches S-measure rates of 0.909, 0.876, 0.936, 0.854, 0.929, and 0.826 on six low-resolution public databases. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2025novel
ER  -

TY  - JOUR
AU  - Wen, M.
AU  - Chen, Z.
AU  - Xiong, Y.
AU  - Zhang, Y.
TI  - LGAT: A novel model for multivariate time series anomaly detection with improved anomaly transformer and learning graph structures
PY  - 2025
T2  - Neurocomputing
VL  - 617
C7  - 129024
DO  - 10.1016/j.neucom.2024.129024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210545520&doi=10.1016%2fj.neucom.2024.129024&partnerID=40&md5=13a38b3b0035e415c3e3da947f3af177
AB  - Time series anomaly detection involves identifying data points in continuously collected datasets that deviate from normal patterns. Given that real-world systems often consist of multiple variables, detecting anomalies in multivariate datasets has become a key focus of current research. This challenge has wide-ranging applications across various industries for system maintenance, such as in water treatment and distribution networks, transportation, and autonomous vehicles, thus driving active research in the field of time series anomaly detection. However, traditional methods primarily address this issue by predicting and reconstructing input time steps, but they still suffer from problems of overgeneralization and inconsistency in providing high performance for reasoning about complex dynamics. In response, we propose a novel unsupervised model called LGAT, which can automatically learn graph structures and leverage an enhanced Anomaly Transformer architecture to capture temporal dependencies. Moreover, the model features a new encoder–decoder architecture designed to enhance context extraction capabilities. In particular, the model calculates anomaly scores for multivariate time series anomaly detection by combining the reconstruction of input time series with the model's computed prior associations and sequential correlations. This model captures inter-variable relationships and exhibit stronger context extraction abilities, making it more sensitive to anomaly detection. Extensive experiments on six common anomaly detection benchmarks further demonstrate the superiority of our approach over other state-of-the-art methods, with an improvement of approximately 1.2% across various metrics. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wen2025LGAT
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Kong, F.
AU  - Feng, S.
AU  - Wang, M.
AU  - Yang, X.
AU  - Zhao, H.
AU  - Wang, D.
AU  - Zhang, Y.
TI  - Is Mamba effective for time series forecasting?
PY  - 2025
T2  - Neurocomputing
VL  - 619
C7  - 129178
DO  - 10.1016/j.neucom.2024.129178
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212178664&doi=10.1016%2fj.neucom.2024.129178&partnerID=40&md5=7d39048882f2f49ad084ab92e968211a
AB  - In the realm of time series forecasting (TSF), it is imperative for models to adeptly discern and distill hidden patterns within historical time series data to forecast future states. Transformer-based models exhibit formidable efficacy in TSF, primarily attributed to their advantage in apprehending these patterns. However, the quadratic complexity of the Transformer leads to low computational efficiency and high costs, which somewhat hinders the deployment of the TSF model in real-world scenarios. Recently, Mamba, a selective state space model, has gained traction due to its ability to process dependencies in sequences while maintaining near-linear complexity. For TSF tasks, these characteristics enable Mamba to comprehend hidden patterns as the Transformer and reduce computational overhead compared to the Transformer. Therefore, we propose a Mamba-based model named Simple-Mamba (S-Mamba) for TSF. Specifically, we tokenize the time points of each variate autonomously via a linear layer. A bidirectional Mamba layer is utilized to extract inter-variate correlations and a Feed-Forward Network is set to learn temporal dependencies. Finally, the generation of forecast outcomes through a linear mapping layer. Experiments on thirteen public datasets prove that S-Mamba maintains low computational overhead and achieves leading performance. Furthermore, we conduct extensive experiments to explore Mamba's potential in TSF tasks. Our code is available at https://github.com/wzhwzhwzh0921/S-D-Mamba. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2025Is
ER  -

TY  - JOUR
AU  - Shah, S.T.U.
AU  - Khan, F.
AU  - Yamani, S.
AU  - Alturki, R.
AU  - Gazzawe, F.
AU  - Razzak, M.I.
TI  - DSRS: DELIGHT sequential recommender system
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 142
C7  - 109936
DO  - 10.1016/j.engappai.2024.109936
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213866376&doi=10.1016%2fj.engappai.2024.109936&partnerID=40&md5=502ab20d6e7cee68620076f97b6800c2
AB  - Sequential recommendation is becoming more critical in a variety of e-commerce platforms. The aim of sequential recommender systems is to model the dynamic preferences of users based on their previous actions and predict what they will do next. The collected user activity logs on real-world platforms could be quite long. This wealth of information provides options to follow users’ actual interests. Prior efforts primarily aimed at providing recommendations following recent behaviors. Meanwhile, the entire sequential data may not be used efficiently since early actions may influence users’ decisions at present. Furthermore, scanning the whole behavior sequence while doing inference for every user is unbearable due to the need for prompt reaction time in real-world applications. To this end, we propose the DELIGHT Sequential Recommender System (DSRS), which takes the above properties into account to recommend the next item the user might be interested in. DSRS divides the entire user behavior sequence into long- and short-term segments and models them through independent networks before integrating their learned representations. In particular, the first network learns user long-term, whereas the second one learns short-term preferences and then combines them for an efficient joint recommendation. Experimental findings across four datasets show that our model outperforms other state-of-the-art sequential models in apprehending long-term dependence. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Shah2025DSRS
ER  -

TY  - JOUR
AU  - Jin, L.
AU  - Zhou, G.
AU  - Liu, Z.
AU  - Yu, Y.
AU  - Zhang, T.
AU  - Yang, M.
AU  - Zhou, J.
TI  - IRPE: Instance-level reconstruction-based 6D pose estimator
PY  - 2025
T2  - Image and Vision Computing
VL  - 154
C7  - 105340
DO  - 10.1016/j.imavis.2024.105340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211050757&doi=10.1016%2fj.imavis.2024.105340&partnerID=40&md5=caf4506c7e8e3858962dcbe0094c4c8c
AB  - The estimation of an object's 6D pose is a fundamental task in modern commercial and industrial applications. Vision-based pose estimation has gained popularity due to its cost-effectiveness and ease of setup in the field. However, this type of estimation tends to be less robust compared to other methods due to its sensitivity to the operating environment. For instance, in robot manipulation applications, heavy occlusion and clutter are common, posing significant challenges. For safety and robustness in industrial environments, depth information is often leveraged instead of relying solely on RGB images. Nevertheless, even with depth information, 6D pose estimation in such scenarios still remains challenging. In this paper, we introduce a novel 6D pose estimation method that promotes the network's learning of high-level object features through self-supervised learning and instance reconstruction. The feature representation of the reconstructed instance is subsequently utilized in direct 6D pose regression via a multi-task learning scheme. As a result, the proposed method can differentiate and retrieve each object instance from a scene that is heavily occluded and cluttered, thereby surpassing conventional pose estimators in such scenarios. Additionally, due to the standardized prediction of reconstructed image, our estimator exhibits robustness performance against variations in lighting conditions and color drift. This is a significant improvement over traditional methods that depend on pixel-level sparse or dense features. We demonstrate that our method achieves state-of-the-art performance (e.g., 85.4% on LM-O) on the most commonly used benchmarks with respect to the ADD(-S) metric. Lastly, we present a CLIP dataset that emulates intense occlusion scenarios of industrial environment and conduct a real-world experiment for manipulation applications to verify the effectiveness and robustness of our proposed method. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jin2025IRPE
ER  -

TY  - JOUR
AU  - Yin, L.
AU  - Zheng, D.
TI  - Hybrid modeling with data enhanced driven learning algorithm for smart generation control in multi-area integrated energy systems with high proportion renewable energy
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125530
DO  - 10.1016/j.eswa.2024.125530
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205959582&doi=10.1016%2fj.eswa.2024.125530&partnerID=40&md5=6173a544d48b0aae57e60725b9cbd987
AB  - Multi-area integrated energy systems (MA-IES) with a high proportion of renewable energy have become a trend in social development. The access to a large number of distributed energy sources makes the safe, stable, and economic operation of MA-IES suffer serious challenges. To reduce the frequency deviation and area control error (ACE) of MA-IES and to improve the economy of operation, this study proposed a hybrid modeling with data enhanced driven learning algorithm, which combines model-driven and data-driven algorithms, named combined proportion-integral-derivative and deep reinforcement learning (CPIDDRL). Firstly, the frequency deviation signals are collected and judged, and the smaller frequency deviation signals, which are sent to the model-driven part, are regulated by proportion-integral-derivative (PID) controllers. Then, the ACE and large frequency deviation signals are collected and transmitted to the data-driven part, and the Transformer deep learning network is applied to predict the multi-feature timeseries, which are applied to strategy selection for state-action-reward-state-action reinforcement learning. Finally, the model-driven part and data-driven part work together to generate adjustment commands every 4 s. The control effects of CPIDDRL, PID, Q-learning, and sliding model control algorithms are compared in two and four areas integrated energy systems. The results show that, compared to the comparison algorithms, the CPIDDRL reduces the mean values of frequency deviation and ACEs by at least 46.78% and 6.83%, respectively, and the total generation cost by at least 8.20%. CPIDDRL has practical significance in improving system stability, enhancing renewable energy integration capabilities, and promoting the development of smart grids. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yin2025Hybrid
ER  -

TY  - JOUR
AU  - Özen, S.
AU  - Yazıcı, A.
AU  - Atalay, V.
TI  - Hybrid deep learning models with data fusion approach for electricity load forecasting
PY  - 2025
T2  - Expert Systems
VL  - 42
IS  - 2
C7  - e13741
DO  - 10.1111/exsy.13741
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205322836&doi=10.1111%2fexsy.13741&partnerID=40&md5=561e3786377324e21040d7cec04f57f4
AB  - This study explores the application of deep learning in forecasting electricity consumption. Initially, we assess the performance of standard neural networks, such as convolutional neural networks (CNN) and long short-term memory (LSTM), along with basic methods like ARIMA and random forest, on a univariate electricity consumption data set. Subsequently, we develop hybrid models for a comprehensive multivariate data set created by merging weather and electricity data. These hybrid models demonstrate superior performance compared to individual models on the univariate data set. Our main contribution is the introduction of a novel hybrid data fusion model. This model integrates a single-model approach for univariate data, a hybrid model for multivariate data, and a linear regression model that processes the outputs from both. Our hybrid fusion model achieved an RMSE value of 0.0871 on the Chicago data set, outperforming other models such as Random Forest (0.2351), ARIMA (0.2184), CNN (0.1802), LSTM + LSTM (0.1496), and CNN + LSTM (0.1587). Additionally, our model surpassed the performance of our base transformer model. Furthermore, combining the best-performing transformer model, with a Gaussian Process model resulted in further improvement in performance. The Transformer + Gaussian model achieved an RMSE of 0.0768, compared with 0.0781 for the single transformer model. Similar trends were observed in the Pittsburgh and IHEC data sets. © 2024 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Özen2025Hybrid
ER  -

TY  - JOUR
AU  - Xu, T.
AU  - Zhang, Y.
AU  - Song, X.
AU  - Wu, X.-J.
TI  - Towards fine-grained adaptive video captioning via Quality-Aware Recurrent Feedback Network
PY  - 2025
T2  - Expert Systems with Applications
VL  - 261
C7  - 125480
DO  - 10.1016/j.eswa.2024.125480
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205431943&doi=10.1016%2fj.eswa.2024.125480&partnerID=40&md5=b29bb9f4242ab0d8ab23daf6bfec1e3e
AB  - To achieve accurate video captioning, most existing solutions focus on employing auxiliary features to provide complementary generation clues, such as detected target regions, audio speech signals, and in-plane text. However, beyond introducing external information, the potential of using the generated captions has been overlooked. We argue that the intrinsic value lies in the caption text, which can faithfully reflect the video content. To this end, we propose to reuse the captions via a Quality-Aware Recurrent Feedback Network (QARFNet), a model that progressively exploits the supportive power between video features and the generated captions. Specifically, inspired by the backtracking AdaBoost algorithm, we propose to build a recurrent loop structure that recycles the obtained linguistic predictions to refine the input visual features. Referring to the greedy selective nature of the AdaBoost algorithm, we set a quality-aware gate to assess the necessity of forwarding the next loop, lessening the complexity. After the refinement loop, if the confidence score remains below the predefined threshold, we select the output with the highest confidence score to advance the subsequent transformer decoder. To facilitate feedback in each loop, a Multi-level Update Module is constructed before fusing linguistic predictions with video features. This involves extracting nouns and verbs from linguistic predictions to lighten relevant video tokens, achieving self-interactions across recurrent loops. By merging the coarse-grained and gradually refined linguistic prediction features, the video tokens are semantically closer to the desired textual representation. To alleviate the increased calculation caused by the loops, we employ a flat transformer encoder to decrease the complexity. The experimental results on several benchmark datasets confirm the effectiveness of our approach, with superior performance compared to the state-of-the-art. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Xu2025Towards
ER  -

TY  - JOUR
AU  - Xia, J.
AU  - He, L.
AU  - Gao, X.
AU  - Hu, B.
TI  - Blind image quality assessment for in-the-wild images by integrating distorted patch selection and multi-scale-and-granularity fusion
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 309
C7  - 112772
DO  - 10.1016/j.knosys.2024.112772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210529002&doi=10.1016%2fj.knosys.2024.112772&partnerID=40&md5=d687aed3e3ab1b35f0e0846f5c0f58f9
AB  - Images taken in natural environments often exhibit complicated distortions, posing significant challenges for assessing their quality. Although current methods prioritize the perception of image contents and distortions, few explicitly investigate local distortions, a crucial factor affecting human visual perception. To mitigate this, this paper proposes a novel blind image quality assessment (IQA) method for in-the-wild images, termed DPSF, which integrates Distorted Patch Selection and multi-scale and multi-granularity feature Fusion. Specifically, it is first explained that the distributions of the mean subtracted contrast normalized coefficients of distorted patches differ from those of undistorted patches. Building upon this, an effective strategy for distorted patch selection is devised. Subsequently, a hybrid Transformer-convolutional neural network (CNN) module is proposed to exploit the benefits of both Transformer and CNN for distortion perception, in which the long-range dependencies of the selected patches are considered. Finally, an effective fusion module is employed for image quality evaluation, amalgamating finer and richer semantic and distortion features from multiple scales and granularities. Experimental results on five authentic IQA databases demonstrate that the proposed method yields more precise quality predictions compared with the state-of-the-art methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Xia2025Blind
ER  -

TY  - JOUR
AU  - Zhang, C.
AU  - Tian, Y.-X.
AU  - Hu, A.-Y.
TI  - Utilizing textual data from online reviews for daily tourism demand forecasting: A deep learning approach leveraging word embedding techniques
PY  - 2025
T2  - Expert Systems with Applications
VL  - 260
C7  - 125439
DO  - 10.1016/j.eswa.2024.125439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205319019&doi=10.1016%2fj.eswa.2024.125439&partnerID=40&md5=d1ff9f46b2e323c0aebb8f624f96d52e
AB  - Accurately estimating daily tourism volumes is crucial for optimizing operational strategies and enhancing visitor experiences at tourist destinations. In this study, we leverage historical tourism volume data, search engine data, and online review data (including textual review contents) to forecast daily tourism demand. We develop a deep learning framework that includes a feature selection module to select search engine indices, a word embedding module to transform review texts into numerical predictors, and an extreme learning machine (ELM) enhanced with the whale optimization algorithm (WOA) for predictive modeling. Based on different word embedding techniques, we investigated two specific forecasting methods: one based on term frequency-inverse document frequency (TF-IDF) and Transformer, and the other based on the standard pre-trained bidirectional encoder representations from Transformers (BERT). These two methods enhance predictive accuracy while ensuring fast training and inference speeds, making it suitable for the high-frequency daily tourism forecasting task. Experimental results demonstrate that the two methods significantly outperform traditional approaches that rely solely on numerical data sources, achieving lower prediction errors and faster inference speeds compared to established benchmark methods, highlighting their potential to contribute to advancements in tourism prediction methodologies. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2025Utilizing
ER  -

TY  - JOUR
AU  - Strem, N.
AU  - Dhami, D.S.
AU  - Schmidt, B.
AU  - Kersting, K.
TI  - Multimodal transformer for early alarm prediction
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109643
DO  - 10.1016/j.engappai.2024.109643
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210539712&doi=10.1016%2fj.engappai.2024.109643&partnerID=40&md5=49648dc608dcc89a1c9e235b24944da2
AB  - Alarms are an essential part of distributed control systems designed to help plant operators keep the processes stable and safe. In reality, however, alarms are often noisy and thus can be easily overlooked. Early alarm prediction can give the operator more time to assess the situation and introduce corrective actions to avoid downtime and negative impact on human safety and environment. Existing studies on alarm prediction typically rely on signals directly coupled with these alarms. However, using more sources of information could benefit early prediction by letting the model learn characteristic patterns in the interactions of signals and events. Meanwhile, multimodal deep learning has recently seen impressive developments. Combination (or fusion) of modalities has been shown to be a key success factor, yet choosing the best fusion method for a given task introduces a new degree of complexity, in addition to existing architectural choices and hyperparameter tuning. This is one of the reasons why real-world problems are still typically tackled with unimodal approaches. To bridge this gap, we introduce a multimodal Transformer model for early alarm prediction based on a combination of recent events and signal data. The model learns the optimal representation of data from multiple fusion strategies automatically. The model is validated on real-world industrial data. We show that our model is capable of predicting alarms with the given horizon and that the proposed multimodal fusion method yields state-of-the-art predictive performance while eliminating the need to choose among conventional fusion techniques, thus reducing tuning costs and training time. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Strem2025Multimodal
ER  -

TY  - JOUR
AU  - Zhang, W.
AU  - Xie, R.
AU  - Li, J.
AU  - Wang, L.
AU  - Li, X.
AU  - Peng, P.
TI  - Predicting the number of COVID-19 imported cases based on cross-modal transformer: A case study in China
PY  - 2025
T2  - Expert Systems with Applications
VL  - 260
C7  - 125483
DO  - 10.1016/j.eswa.2024.125483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205366004&doi=10.1016%2fj.eswa.2024.125483&partnerID=40&md5=7f43f498f6fee309396b85e1ddc5c735
AB  - With the global outbreak of COVID-19, an increasing number of countries have made imported epidemic control a priority, imposing restriction measures to prevent the spread of the virus caused by imported cases. To control the imported epidemic, it is necessary to accurately predict the number of imported cases from different source countries. This paper proposes a novel time series prediction approach called PNICA (Prediction on Number of Imported CAses) that uses deep learning to predict the number of COVID-19 imported cases. On the one hand, the proposed PNICA approach adopts a multi-modal learning strategy to fuse three sources of data: flight data, the epidemic data, and the data of historical imported cases. On the other hand, the proposed PNICA approach extends the traditional transformer model with cross-modal attention to learn the interactions between different data modalities to improve prediction accuracy. We use China as the target country and collect the number of imported cases from four source countries—Japan, USA, Russia, and the UK—as well as the epidemic data and flight data from May to November 2020. Experiments on the collected data demonstrate that the proposed PNICA approach outperforms the baseline methods in predicting the number of imported cases. The ablation study shows that both the multi-modal learning strategy and cross-modal attention can significantly improve prediction performance. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2025Predicting
ER  -

TY  - JOUR
AU  - Verma, S.
AU  - Kumar, A.
AU  - Sharan, A.
TI  - WRGAT-PTBERT: weighted relational graph attention network over post-trained BERT for aspect based sentiment analysis
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 2
C7  - 181
DO  - 10.1007/s10489-024-06011-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212435422&doi=10.1007%2fs10489-024-06011-x&partnerID=40&md5=fade88df959cd1cb3c11b0cdbeff8a79
AB  - Aspect-based sentiment analysis (ABSA) focused on forecasting the sentiment orientation of a given aspect target within the input. Existing methods employ neural networks and attention mechanisms to encode input and discern aspect-context relationships. Bidirectional Encoder Representation from Transformer(BERT) has become the standard contextual encoding method in the textual domain. Researchers have ventured into utilizing graph attention networks(GAT) to incorporate syntactic information into the task, yielding cutting-edge results. However, current approaches overlook the potential advantages of considering word dependency relations. This work proposes a hybrid model combining contextual information obtained from a post-trained BERT with syntactic information from a relational GAT (RGAT) for the ABSA task. Our approach leverages dependency relation information effectively to improve ABSA performance in terms of accuracy and F1-score, as demonstrated through experiments on SemEval-14 Restaurant and Laptop, MAMS, and ACL-14 Twitter datasets. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Verma2025WRGAT-PTBERT
ER  -

TY  - JOUR
AU  - Zhou, H.
AU  - Mao, Y.
AU  - Li, X.
AU  - Rong, Y.
AU  - Chen, L.
AU  - Yin, C.
TI  - TKSTAGNet: A Top-K Spatio-Temporal Attention Gating Network for air pollution prediction
PY  - 2025
T2  - Expert Systems with Applications
VL  - 260
C7  - 125409
DO  - 10.1016/j.eswa.2024.125409
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204697107&doi=10.1016%2fj.eswa.2024.125409&partnerID=40&md5=60768965d35ab9c38c2b779ceadb1b3f
AB  - Accurate air pollution prediction is of great significance for human health, travel, and environmental management. As an emerging artificial intelligence technology, Transformer has already shown tremendous potential in air pollution prediction. Unfortunately, existing Transformer-based methods are challenging to accurately predict air pollution due to two limitations: (1) they neglect irrelevant spatial and temporal neighbors (e.g., neighboring sensors and timesteps) when modeling spatio-temporal correlations, and (2) they lack an adaptive mechanism to mine different effects caused by various external factors (e.g., meteorological conditions). Jointly taking these limitations into account, we propose a novel Transformer-based architecture for air pollution prediction, named Top-K Spatio-Temporal Attention Gating Network (TKSTAGNet). In this architecture, to effectively extract spatio-temporal correlations, we first design a TopKpooling Spatial Attention (TopK-SA) and a TopKpooling Temporal Attention (TopK-TA). In TopK-SA, the TopKpooling mechanism is introduced into spatial attention to filter out irrelevant spatial neighbors, accurately capturing spatial dependencies. In TopK-TA, the TopKpooling mechanism is integrated with temporal attention to identify and exclude irrelevant temporal neighbors, precisely extracting temporal dependencies. To adaptively fuse various external factors, a gating fusion module is then proposed. We conduct experiments on three real-world air pollution datasets from urban regions in Beijing, Shanghai, and Chongqing, respectively. Experimental results demonstrate that TKSTAGNet outperforms state-of-the-art baselines in prediction precision and fitting the variation trends of air pollution. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhou2025TKSTAGNet
ER  -

TY  - JOUR
AU  - Dai, J.
AU  - Li, H.
AU  - Jiang, S.
AU  - Yang, H.
TI  - An efficient object tracking based on multi-head cross-attention transformer
PY  - 2025
T2  - Expert Systems
VL  - 42
IS  - 2
C7  - e13650
DO  - 10.1111/exsy.13650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197467033&doi=10.1111%2fexsy.13650&partnerID=40&md5=d8ca1b6c433e59b3e3872adfef3f2f17
AB  - Object tracking is an essential component of computer vision and plays a significant role in various practical applications. Recently, transformer-based trackers have become the predominant method for tracking due to their robustness and efficiency. However, existing transformer-based trackers typically focus solely on the template features, neglecting the interactions between the search features and the template features during the tracking process. To address this issue, this article introduces a multi-head cross-attention transformer for visual tracking (MCTT), which effectively enhance the interaction between the template branch and the search branch, enabling the tracker to prioritize discriminative feature. Additionally, an auxiliary segmentation mask head has been designed to produce a pixel-level feature representation, enhancing and tracking accuracy by predicting a set of binary masks. Comprehensive experiments have been performed on benchmark datasets, such as LaSOT, GOT-10k, UAV123 and TrackingNet using various advanced methods, demonstrating that our approach achieves promising tracking performance. MCTT achieves an AO score of 72.8 on the GOT-10k. © 2024 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Dai2025efficient
ER  -

TY  - JOUR
AU  - Gao, F.
AU  - Leng, J.
AU  - Gan, J.
AU  - Gao, X.
TI  - Ranking-based adaptive query generation for DETRs in crowded pedestrian detection
PY  - 2025
T2  - Neurocomputing
VL  - 612
C7  - 128710
DO  - 10.1016/j.neucom.2024.128710
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206108079&doi=10.1016%2fj.neucom.2024.128710&partnerID=40&md5=00459cd3361997e23124237832cf8c6d
AB  - Variants of DEtection TRansformer (DETRs) have shown promising performance in crowded pedestrian detection. However, we observe that DETRs are sensitive to the hyper-parameter (the number of queries). Adjusting this hyper-parameter is crucial for achieving competitive performance across different crowded pedestrian datasets. Existing query generation methods are limited to generate a fixed number of queries based on this hyper-parameter, which often leads to missed detections and incorrect detections due to the varied number and density of pedestrians in crowded scenes. To address this challenge, we propose an adaptive query generation method called Ranking-based Adaptive Query Generation (RAQG). RAQG comprises three components: a ranking prediction head, a query supplementer, and Soft Gradient L1 Loss (SGL1). Specifically, we leverage the ranking of the lowest confidence score positive training sample to generate queries adaptively. The ranking prediction head predicts this ranking, which guides our query generation. Additionally, to refine the query generation process, we introduce a query supplementer that adjusts the number of queries based on the predicted ranking. Furthermore, we introduce SGL1, a novel loss function for training the ranking prediction head over a wide regression range. Our method is designed to be lightweight and universal, suitable for integration into any DETRs framework for crowded pedestrian detection. Experimental results on Crowdhuman and Citypersons datasets demonstrate that our RAQG method can generate queries adaptively and achieves competitive results. Notably, our approach achieves a state-of-the-art 39.4% MR on Crowdhuman. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Gao2025Ranking-based
ER  -

TY  - JOUR
AU  - Kang, J.
AU  - Heo, B.
AU  - Choe, J.
TI  - Improving ViT interpretability with patch-level mask prediction
PY  - 2025
T2  - Pattern Recognition Letters
VL  - 187
SP  - 73
EP  - 79
DO  - 10.1016/j.patrec.2024.11.018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210118225&doi=10.1016%2fj.patrec.2024.11.018&partnerID=40&md5=fd2ec0958fedd6c31163dde44de0cc8d
AB  - Vision Transformers (ViTs) have demonstrated remarkable performances on various computer vision tasks. Attention scores are often used to explain the decision-making process of ViTs, showing which tokens are more important than others. However, the attention scores have several limitations as an explanation for ViT, such as conflicting with other explainable methods or highlighting unrelated tokens. In order to address this limitation, we propose a novel method for generating a visual explanation map from ViTs. Unlike previous approaches that rely on attention scores, our method leverages ViT features and conducts a single forward pass through our Patch-level Mask prediction (PM) module. Our visual explanation map provides class-dependent and probabilistic interpretation that can identify crucial regions of model decisions. Experimental results demonstrate that our approach outperforms previous techniques in both classification and interpretability aspects. Additionally, it can be applied to the weakly-supervised object localization (WSOL) tasks using pseudo mask labels. Our method requires no extra parameters and necessitates minimal locality supervision, utilizing less than 1% of the ImageNet-1k training dataset. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Kang2025Improving
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Xie, Z.
AU  - Chiu, D.K.W.
AU  - Ho, K.K.W.
TI  - Multimodal market information fusion for stock price trend prediction in the pharmaceutical sector: Multimodal market information fusion for stock price trend prediction in the pharmaceutical sector: H. Wang et al.
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 1
C7  - 77
DO  - 10.1007/s10489-024-05894-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211359278&doi=10.1007%2fs10489-024-05894-0&partnerID=40&md5=b67a2603d642cfae0b689d17ff5be733
AB  - With the evolution of China's market economy, the securities market is increasingly anchoring a pivotal role in the nation's economic landscape. Consequently, stock trend forecasting has garnered heightened attention among scholars and practitioners. This research pioneers the use of multimodal information to predict stock market fluctuations. Based on our experimental results, LSTM + Transformer performs better in handling multimodal data for stock movement prediction tasks regarding accuracy, F1-score, precision, and recall. Additionally, we employed the Granger causality test and Impulse response test to investigate the causal relationships between sentiment and stock trends, as well as the interplay between COVID-related indicators and stock trajectories. We identified discernible causal links between sentiments, COVID indicators, and stock trends for select pharmaceutical stocks. Our findings can provide valuable guidance for investors and market regulators, especially within the pharmaceutical industry. Understanding investor sentiment and the impact of the pandemic on severity can assist in effective stock commentary management and improve investment strategies. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2025Multimodal
ER  -

TY  - JOUR
AU  - Zhuang, J.
AU  - Li, J.
AU  - Shi, C.
AU  - Lin, X.
AU  - Fu, Y.-G.
TI  - Enhanced Graph Transformer: Multi-scale attention with Heterophilous Curriculum Augmentation
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 309
C7  - 112874
DO  - 10.1016/j.knosys.2024.112874
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212546469&doi=10.1016%2fj.knosys.2024.112874&partnerID=40&md5=b6980f3f2d408e2de79173f0e92166a3
AB  - Graph representation learning is a crucial area in machine learning, with widespread applications in social networks, recommendation systems, and traffic flow prediction. Recently, Graph Transformers have emerged as powerful tools for this purpose, garnering significant attention. In this work, we observe a fundamental issue of previous Graph Transformers that they overlook the scale-related information gap and often employ an identical attention computation method for different-scale node interactions, leading to suboptimality of model performance. To address this, we propose a Multi-Scale Attention Graph Transformer (MSA-GT) that enables each node to conduct adaptive interactions conditioned on different scales from both local and global perspectives. Specifically, MSA-GT guides several attention mechanisms to focus on individual scales and then perform customized combinations via an attention-based fusion module, thereby obtaining much more semantically fine-grained node representations. Despite the potential of the above design, we still observe over-fitting to some extent, which is a typical challenge for training Graph Transformers. We propose two additional technical components to prevent over-fitting and improve the performance further. We first introduce a path-based pruning strategy to reduce ineffective attention interactions, facilitating more accurate relevant node selection. Additionally, we propose a Heterophilous Curriculum Augmentation (HCA) module, which gradually increases the training difficulty, forming a weak-to-strong regularization schema and therefore enhancing the model's generalization ability step-by-step. Extensive experiments show that our method outperforms many state-of-the-art methods on eight public graph benchmarks, proving its effectiveness. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Zhuang2025Enhanced
ER  -

TY  - JOUR
AU  - dos Santos, P.H.
AU  - de Carvalho Santos, V.
AU  - da Silva Luz, E.J.
TI  - Towards robust ferrous scrap material classification with deep learning and conformal prediction
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 140
C7  - 109724
DO  - 10.1016/j.engappai.2024.109724
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210276754&doi=10.1016%2fj.engappai.2024.109724&partnerID=40&md5=9196b6a9a073e640133e1ba886c1f100
AB  - The classification of ferrous scrap materials is a well-explored problem in the literature, recognized for its significance in the steel production industry. While deep learning models are effective for this task, their deployment in industrial settings requires addressing model uncertainties and ensuring proper calibration. This study proposes adapting split conformal prediction to quantify uncertainties and facilitate model calibration. The results indicate that the Hierarchical Vision Transformer using Shifted Windows (Swin) models, particularly Swin V2, serves as the most reliable backbone for this task. Although the performance of Swin models is comparable to other evaluated models, Swin V2 demonstrates superior confidence, achieving 95.51% accuracy and the lowest conformal prediction threshold. The method is rigorously evaluated on a real-world dataset comprising 8,147 images across nine classes of ferrous scrap widely used in the Brazilian steel industry. Explainability methods corroborate the results of conformal prediction, enhancing transparency and trust in model predictions, and thereby facilitating industrial adoption. This approach bridges the gap between advanced deep learning and practical application in ferrous scrap classification, underscoring the importance of model calibration in industrial deployment. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - dos Santos2025Towards
ER  -

TY  - JOUR
AU  - He, L.
AU  - Zhao, J.
AU  - Zhang, J.
AU  - Jiang, J.
AU  - Qi, S.
AU  - Wang, Z.
AU  - Wu, D.
TI  - LMTformer: facial depression recognition with lightweight multi-scale transformer from videos
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 2
C7  - 195
DO  - 10.1007/s10489-024-05908-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212670079&doi=10.1007%2fs10489-024-05908-x&partnerID=40&md5=29bbc489380227e80c8ab6a3aa87b5a9
AB  - Depression will become the most common mental disorder worldwide by 2030. A number of models based on deep learning are proposed to help the clinicians to assess the severity of depression. However, two issues remain unresolved: (1) few studies have not considered to encode multi-scale facial behaviors. (2) the current studies have the high computational complexity to hinder the proposed architecture in clinical application. To mitigate the above issues, an end-to-end, lightweight, multi-scale transformer based architecture, termed LMTformer, for sequential video-based depression analysis (SVDA), is proposed. In LMTformer, which consists of the three models: coarse-grained feature extraction (CFE) block, light multi-scale transformer (LMST), final Beck Depression Inventory–II (BDI–II) predictor (FBP). In CFE, coarse-grained features are extracted for LMST. In LMST, a multi-scale transformer is proposed to model the potential local and global features at the different receptive field. In addition, multi-scale global feature aggregation (MSGFA) is also proposed to model the global features. For FBP, two fully connected layers are used. Our novel architecture LMTformer is evaluated on the AVEC2013/AVEC2014 depression databases, and the former dataset with a root mean square error (RMSE) of 7.75 and a mean absolute error (MAE) of 6.12 for AVEC2013, and a RMSE of 7.97 and a MAE of 6.05 for AVEC2014. On the LMVD dataset, we obtain the best performances with F1-score of 82.74%. Additionally, the model represents the excellent computational complexity while only need 0.95M parameters and 1.1G floating-point operations per second (FLOPs). Code will be available at: https://github.com/helang818/LMTformer/. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - He2025LMTformer
ER  -

TY  - JOUR
AU  - Zhu, J.
AU  - Liu, D.
AU  - Chen, H.
AU  - Liu, J.
AU  - Tao, Z.
TI  - DTSFormer: Decoupled temporal-spatial diffusion transformer for enhanced long-term time series forecasting
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 309
C7  - 112828
DO  - 10.1016/j.knosys.2024.112828
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212829863&doi=10.1016%2fj.knosys.2024.112828&partnerID=40&md5=5b8df04c849250e8a2ce7ed1590c231b
AB  - Transformer-based models have significantly advanced long-term time series forecasting by leveraging self-attention mechanisms to capture long-term dependencies. However, these models face high computational costs, slow inference speeds, and limitations in utilizing information from longer lookback windows. Additionally, existing methods often neglect implicit spatial dependencies between variables, and struggle with semantic misalignment and insufficient diffusion of spatial information. To address these challenges, we propose DTSFormer, a Decoupled Temporal-Spatial Diffusion Transformer designed specifically for long-term time series forecasting: (1) DTSFormer effectively integrates temporal features with implicit spatial attributes, ensuring comprehensive utilization of both temporal and spatial information. (2) DTSFormer introduce a Mix-hop Diffusion layer to effectively propagate and aggregate spatial information while preserving the original graph structure, significantly improving the accuracy of spatial information dissemination. (3) we develop a cross-diffusion attention mechanism based on the Expectation-Maximization algorithm, which integrates graph structure information with varying semantics under a seasonal trend decomposition framework. This approach enhances the fusion of semantic information from different graph structures and reduces computational complexity. Our extensive experiments on multiple benchmark datasets across different domains demonstrate that DTSFormer consistently achieves state-of-the-art performance in both accuracy and efficiency. These results validate DTSFormer as a robust and scalable solution for advanced long-term time series forecasting tasks. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Zhu2025DTSFormer
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Liu, P.
AU  - Pan, Y.
AU  - Yu, J.
AU  - Liu, W.
AU  - Chen, H.
AU  - Luo, Y.
AU  - Wang, H.
TI  - Text-dominant multimodal perception network for sentiment analysis based on cross-modal semantic enhancements
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 2
C7  - 188
DO  - 10.1007/s10489-024-06150-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212785907&doi=10.1007%2fs10489-024-06150-1&partnerID=40&md5=82c7618add20fd8873db6e7b27df96eb
AB  - Abstract: Multimodal sentiment analysis (MSA) aims to discern the emotional information expressed by users in the multimodal data they upload on various social media platforms. In most previous studies, these modalities (audio A, visual V, and text T) were typically treated equally, overlooking the lower representation quality inherent in audio and visual modalities. This oversight often results in inaccurate interaction information when audio or visual modalities are used as the primary input, thereby negatively impacting the model’s sentiment predictions. In this paper, we propose a text-dominant multimodal perception network with cross-modal transformer-based semantic enhancement. The network comprises primarily a text-dominant multimodal perception (TDMP) module and a cross-modal transformer-based semantic enhancement (TSE) module. TDMP leverages the text modality to dominate intermodal interactions, extracting high correlation and differentiation features from each modality, thereby obtaining more accurate representations for each modality. The TSE module uses a transformer architecture to convert the audio and visual modality features into text features. By applying KL divergence constraints, it ensures that the translated modality representations capture as much emotional information as possible while maintaining high similarity to the original text modality representations. This enhances the original text modality semantics while mitigating the negative impact of the input. Extensive experiments on the CMU-MOSI and CMU-MOSEI datasets demonstrate the effectiveness of our proposed model. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2025Text-dominant
ER  -

TY  - JOUR
AU  - Su, G.
AU  - Guan, Y.
TI  - MSDformer: an autocorrelation transformer with multiscale decomposition for long-term multivariate time series forecasting
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 2
C7  - 179
DO  - 10.1007/s10489-024-06105-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212304512&doi=10.1007%2fs10489-024-06105-6&partnerID=40&md5=04e2337a1680d9d3048c56463d4d0b00
AB  - Abstract: The improvement of performance and efficiency in long-term time series forecasting is significant for practical applications. However, while enhancing overall performance, existing time series forecasting methods often exhibit unsatisfactory capabilities in the restoration of details and prediction efficiency. To address these issues, an autocorrelation Transformer with multiscale decomposition (MSDformer) is proposed for long-term multivariate time series forecasting. Specifically, a multiscale decomposition (MSDecomp) module is designed, which identifies the temporal repeating patterns in time series with different scales to retain more historical details while extracting trend components. An Encoder layer is proposed based on the MSDecomp module and Auto-Correlation mechanism, which discovers the similarity of subsequences in a periodic manner and effectively captures the seasonal components to improve the degree of restoration of prediction details while extracting the residual trend components. Finally, unlike the traditional Transformer structure, the decoder structure is replaced by the proposed Autoregressive module to simplify the output mode of the decoder and enhance linear information. Compared to other advanced and representative models on six real-world datasets, the experimental results demonstrate that the MSDformer has a relative performance improvement of an average of 8.1%. MSDformer also has lower memory usage and temporal consumption, making it more advantageous for long-term time series forecasting. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Su2025MSDformer
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Song, B.
AU  - Zhang, Z.
AU  - Zhang, Y.
TI  - Multimodal sentiment analysis based on multi-stage graph fusion networks under random missing modality conditions
PY  - 2025
T2  - IET Image Processing
VL  - 19
IS  - 1
C7  - e13310
DO  - 10.1049/ipr2.13310
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212474117&doi=10.1049%2fipr2.13310&partnerID=40&md5=48ec503c41d7e6c321b2b4db118f8b8b
AB  - The primary challenge of the multimodal sentiment analysis (MSA) task is the modal fusion, and the lack of modalities may exist in the fusion process, which leads to poor prediction results. Most of the previous research on multimodal fusion is single-stage fusion, disregarding how various modality subsets interact, as well as rarely considering relative position relationship of modality sequences, causing the fragmentation of context info. Considering the aforementioned issues, this study introduces an MSA method based on the multi-stage graph fusion network (MSGFN) under random missing modality conditions to improve the robustness of the model to MSA under the random missing modality conditions. Firstly, for each modality, its inter-modal and intra-modal multi-head attention are used to learn robust representation of the modality sequence. Meanwhile, the relative position encoding (RPE) is introduced into mechanism of attention that enables model to perceive and learn the relative position before and after the modality sequence when calculating attention, thereby better understanding the contextual info of the sequence. After that, the transformer encoder receives the learned modality features and uses the pre-trained model to supervise the reconstruction of the missing modality information. Finally, the feature representations of different modalities have effectively fused using multi-stage graph fusion network, and the output is used for the ultimate sentiment classification. Wide experiments are conducted on two publicly available datasets, CMU-MOSI and IEMOCAP, and the findings indicate that the proposed method can better handle the challenges caused by modality fusion and modality missing compared with several baseline methods. © 2024 The Author(s). IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2025Multimodal
ER  -

TY  - JOUR
AU  - Huang, B.
AU  - Li, X.
AU  - Hu, C.
AU  - Li, H.
TI  - Stochastic human motion prediction using a quantized conditional diffusion model
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 309
C7  - 112823
DO  - 10.1016/j.knosys.2024.112823
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211388938&doi=10.1016%2fj.knosys.2024.112823&partnerID=40&md5=80230a8150fdcd81320b3efd82708c33
AB  - Human motion prediction is a fundamental task in computer vision, aiming to forecast future human poses based on observed motion sequences. Existing deterministic methods generate a single future motion sequence, neglecting the inherent stochasticity and diversity of human behaviors. To address this limitation, we propose a novel two-stage stochastic human motion prediction framework, termed the Quantized Conditional Diffusion Model (QCDM), which combines a Discrete Motion Quantization Module and a Conditional Motion Generation Module. Specifically, we first design a discrete motion quantization module that leverages Graph Convolutional Networks (GCNs) and one-dimensional temporal convolutions to encode motion sequences into continuous latent representations. These representations are then quantized into discrete latent variables using a learnable codebook. A decoder reconstructs the motion sequence from these discrete variables, preserving key motion patterns while eliminating redundancies. Next, we develop a conditional motion generation module that integrates GCNs and Transformers for denoising spatio-temporal features. The diffusion process iteratively refines noisy motion data by reversing a gradual noising procedure, modeling the distribution of plausible future motions. Action category information and observed historical motion segments are incorporated as conditions into the denoising process, enabling controllable generation of specific motions. Additionally, we introduce a diversity enhancement strategy by penalizing overly similar samples. This encourages the model to explore a wider range of plausible motions and thereby improving the diversity and richness of the prediction results. Extensive experiments demonstrate that the QCDM framework outperforms state-of-the-art methods in stochastic human motion prediction tasks, offering both accuracy and diversity in generated motion sequences. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Huang2025Stochastic
ER  -

TY  - JOUR
AU  - Han, X.
AU  - Oishi, N.
AU  - Tian, Y.
AU  - Ucurum, E.
AU  - Young, R.
AU  - Chatwin, C.
AU  - Birch, P.
TI  - ETTrack: enhanced temporal motion predictor for multi-object tracking
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 1
C7  - 33
DO  - 10.1007/s10489-024-05866-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210361920&doi=10.1007%2fs10489-024-05866-4&partnerID=40&md5=71e7dc346b2a4bc186d132dd6c77cfba
AB  - Many Multi-Object Tracking (MOT) approaches exploit motion information to associate all the detected objects across frames. However, traditional tracking-by-detection (TBD) methods, relying on the Kalman Filter, often work well in linear motion scenarios but struggle to accurately predict the locations of objects undergoing complex and non-linear movements. To overcome these limitations, we propose ETTrack, a novel motion prediction method with an enhanced temporal motion predictor. Specifically, the motion predictor integrates a transformer model and a Temporal Convolutional Network (TCN) to capture both long-term and short-term motion patterns, and it predicts the future motion of individual objects based on the historical motion information. Additionally, we propose a novel Momentum Correction Loss function that provides additional information regarding the motion direction of objects during training. This allows the motion predictor to rapidly adapt to sudden motion variations and more accurately predict future motion. Our experimental results demonstrate that ETTrack achieves a competitive performance compared with state-of-the-art trackers on DanceTrack and SportsMOT, scoring 56.4% and 74.4% in HOTA metrics, respectively. Our work provides a robust solution for MOT in complex dynamic environments, which enhances the non-linear motion prediction capabilities of tracking algorithms. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Han2025ETTrack
ER  -

TY  - JOUR
AU  - Rajendran, M.
AU  - Hong, B.
TI  - Autoregressive multimodal transformer for zero-shot sales forecasting of fashion products with exogenous data: Autoregressive multimodal transformer..: M. Rajendran and B. Hong
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 2
C7  - 108
DO  - 10.1007/s10489-024-05972-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211330925&doi=10.1007%2fs10489-024-05972-3&partnerID=40&md5=42a0f9acf749d5912d0b5eddfbca4600
AB  - Predicting future sales volumes of fashion industry products is challenging due to rapid market changes and limited historical sales data for recent products. As traditional forecasting methods and machine learning models often fail to address this problem, we propose a novel autoregressive multimodal transformer architecture to anticipate the sales volume of brand-new apparel items by capturing trends among interrelated attributes. In this paper, we utilize authentic data from a fashion company that includes a limited amount of historical time-series sales data and several influencing factors like product image, textual descriptions, and temporal attributes. To mitigate the data inadequacies, we investigate the impact of integrating exogenous knowledge from an e-tailer site filtered with fashion apparel products. Also, we found that employing the zero-shot forecasting approach further aids in forecasting with minimal time-series sales data. Our approach achieves the values of 1.546 and 16.42 in terms of MAE and WAPE, respectively, by leveraging exogenous data compared to existing benchmark models. This study demonstrates the potential of our autoregressive multimodal transformer to predict sales volumes with more precision, and it highlights the importance of incorporating the zero-shot forecasting approach in the dynamic fashion industry. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Rajendran2025Autoregressive
ER  -

TY  - JOUR
AU  - Cheng, F.
AU  - Peng, G.
AU  - Li, J.
AU  - Zhao, B.
AU  - Pan, J.-S.
AU  - Li, H.
TI  - A Transformer-based network with adaptive spatial prior for visual tracking
PY  - 2025
T2  - Neurocomputing
VL  - 614
C7  - 128821
DO  - 10.1016/j.neucom.2024.128821
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208760742&doi=10.1016%2fj.neucom.2024.128821&partnerID=40&md5=800898d92150246ee407c6b60eec6529
AB  - Single object tracking (SOT) in complex scenes presents significant challenges in computer vision. In recent years, transformer has shown its demonstrated efficacy in visual object tracking tasks, due to its capacity to capture the long-range dependencies between image pixels. However, two limitations hinder the performance improvement of transformer-based trackers. Firstly, transformer splits and partitions the image into a sequence of patches, which disrupts the internal structural information of the object. Secondly, transformer-based trackers encode the target template and search region together, potentially leading to confusion between the target and background during feature interaction. To address the above issues, we propose a fully transformer-based tracking framework via learning structural prior information, called SPformer. In other words, a self-attention spatial-prior generative network is established for simulating the spatial associations between features. Moreover, the cross-attention structural prior extractors based on Gaussian and arbitrary distributions are developed to seek the semantic interaction features between the object template and the search region, effectively mitigating feature confusion. Extensive experiments on eight prevailing benchmarks demonstrate that SPformer outperforms existing state-of-art (SOAT) trackers. We further analyze the effectiveness of the two proposed prior modules and validate their application in target tracking models. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cheng2025Transformer-based
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Gao, H.
AU  - Sun, W.
AU  - Song, W.
AU  - Li, Q.
TI  - Multivariate time series generation based on dual-channel Transformer conditional GAN for industrial remaining useful life prediction
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 308
C7  - 112749
DO  - 10.1016/j.knosys.2024.112749
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209894525&doi=10.1016%2fj.knosys.2024.112749&partnerID=40&md5=b4fe83fd1744fb89c1f2bc59f002a810
AB  - Remaining useful life (RUL) prediction is a key enabler of predictive maintenance. While deep learning based prediction methods have made great progress, the data imbalance issue caused by limited run-to-failure data severely undermines their performance. Some recent works employ generative adversarial network (GAN) to tackle this issue. However, most GAN-based generative methods have difficulties in simultaneously extracting correlations of different time steps and sensors. In this paper, we propose dual-channel Transformer conditional GAN (DCTC-GAN), a novel multivariate time series (MTS) generation framework, to generate high-quality MTS to enhance deep learning based RUL prediction models. We design a novel dual-channel Transformer architecture to construct the generator and discriminator, which consists of a temporal encoder and a spatial encoder that work in parallel to automatically pay different attention to different time steps and sensors. Based on this, DCTC-GAN can directly extract the long-distance temporal relations of different time steps while capturing the spatial correlations of different sensors to synthesize high-quality MTS data. Experimental analysis on widely used turbofan engine dataset and FEMTO bearing dataset demonstrates that our DCTC-GAN significantly enhances the performance of existing deep learning models for RUL prediction, without changing its structure, and exceeds the capabilities of current representative generative methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Zhang2025Multivariate
ER  -

TY  - JOUR
AU  - Ranganatha, H.R.
AU  - Syed Mustafa, A.
TI  - Enhancing fraud detection efficiency in mobile transactions through the integration of bidirectional 3d Quasi-Recurrent Neural network and blockchain technologies
PY  - 2025
T2  - Expert Systems with Applications
VL  - 260
C7  - 125179
DO  - 10.1016/j.eswa.2024.125179
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203871141&doi=10.1016%2fj.eswa.2024.125179&partnerID=40&md5=837192236058682c012d32909753d1d7
AB  - Cases of financial fraud are increasing despite recent technical breakthroughs. It is tough to find authentic financial transaction data due to privacy issues and a lack of inter-organization synergy. However, for technologies based on data, such as machine learning to function accurately inside practical systems, they require actual data. This manuscript proposes a Fraud Detection (FD) Efficiency in Mobile Transactions through the Integration of Bidirectional 3D Quasi-Recurrent Neural Networks and Proof of Voting consensus Blockchain Technologies (Bi-3DQRNN-PoV-FD-MT). A dataset of Bitcoin transactions is employed in the suggested model. The banking sector's Bitcoin transactions serve as the foundation for this dataset. Then the data balancing is performed using a Self-Adaptive Synthetic Over-Sampling Technique (SASOS). Then, the proposed framework utilizes the Bi-3DQRNN to determine if the information is fraudulent or not. Moreover, an intelligent Enhanced Artificial Gorilla Troops (EAGTO) Optimization algorithm is introduced to tune the weights of the model parameters. A blockchain-based proof of Voting (PoV) consensus algorithm is integrated with the proposed model for forecasting upcoming transactions. The developed scheme is instigated in Python and the performance provides 12.09%, 8.91%, and 6.92% higher accuracy compared with existing techniques like K-nearest neighbor- Distributed Blockchain Consortium (KNN-DBC), Decision tree-Ethereum blockchain-enabled smart contract (DT-EBSC) and Heterogeneous Graph Transformer Networks-Ethereum smart contract (HGTN-ESC). © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ranganatha2025Enhancing
ER  -

TY  - JOUR
AU  - Paulraj, S.
AU  - Vairavasundaram, S.
TI  - Transformer-enabled weakly supervised abnormal event detection in intelligent video surveillance systems
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109496
DO  - 10.1016/j.engappai.2024.109496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207004215&doi=10.1016%2fj.engappai.2024.109496&partnerID=40&md5=260bde2f5fbd33ac8661c066e8082cd0
AB  - Video Anomaly Detection (VAD) for weakly supervised data operates with limited video-level annotations. It also holds the practical significance to play a pivotal role in surveillance and security applications like public safety, patient monitoring, autonomous vehicles, etc. Moreover, VAD extends its utility to various industrial settings, where it is instrumental in safeguarding workers' safety, enabling real-time production quality monitoring, and predictive maintenance. These diverse applications highlight the versatility of VAD and its potential to transform processes across various industries, making it an essential tool along with traditional surveillance applications. The majority of the existing studies have been focused on mitigating critical aspects of VAD, such as reducing false alarm rates and misdetection. These challenges can be effectively addressed by capturing the intricate spatiotemporal pattern within video data. Therefore, the proposed work named Swin Transformer-based Hybrid Temporal Adaptive Module (ST-HTAM) Abnormal Event Detection introduces an intuitive temporal module along with leveraging the strengths of the Swin (Shifted window-based) Transformers for spatial analysis. The novel aspect of this work lies in the hybridization of global self-attention and Convolutional-Long Short Term Memory (C-LSTM) Networks are renowned for capturing both global and local temporal dependencies. By extracting these spatial and temporal components, the proposed method, ST-HTAM, offers a comprehensive understanding of anomalous events. Altogether, it enhances the accuracy and robustness of Weakly Supervised VAD (WS-VAD). Finally, an anomaly scoring mechanism is employed in the classification step to facilitate effective anomaly detection from test video data. The proposed system is tailored to operate in real-time and highlights the dual focus on sophisticated Artificial Intelligence (AI) techniques and their impactful use cases across diverse domains. Comprehensive experiments are conducted on benchmark datasets that clearly show the substantial superiority of the ST-HTAM over state-of-the-art approaches. Code is available at https://github.com/Shalmiyapaulraj78/STHTAM-VAD. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Paulraj2025Transformer-enabled
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Keles, E.
AU  - Durak, G.
AU  - Taktak, Y.
AU  - Susladkar, O.
AU  - Gorade, V.
AU  - Jha, D.
AU  - Ormeci, A.C.
AU  - Medetalibeyoglu, A.
AU  - Yao, L.
AU  - Wang, B.
AU  - Isler, I.S.
AU  - Peng, L.
AU  - Pan, H.
AU  - Vendrami, C.L.
AU  - Bourhani, A.
AU  - Velichko, Y.
AU  - Gong, B.
AU  - Spampinato, C.
AU  - Pyrros, A.
AU  - Tiwari, P.
AU  - Klatte, D.C.F.
AU  - Engels, M.
AU  - Hoogenboom, S.
AU  - Bolan, C.W.
AU  - Agarunov, E.
AU  - Harfouch, N.
AU  - Huang, C.
AU  - Bruno, M.J.
AU  - Schoots, I.
AU  - Keswani, R.N.
AU  - Miller, F.H.
AU  - Gonda, T.
AU  - Yazici, C.
AU  - Tirkes, T.
AU  - Turkbey, B.
AU  - Wallace, M.B.
AU  - Bagci, U.
TI  - Large-scale multi-center CT and MRI segmentation of pancreas with deep learning
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103382
DO  - 10.1016/j.media.2024.103382
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208758378&doi=10.1016%2fj.media.2024.103382&partnerID=40&md5=e2809fe3372eaa50be1240330f336470
AB  - Automated volumetric segmentation of the pancreas on cross-sectional imaging is needed for diagnosis and follow-up of pancreatic diseases. While CT-based pancreatic segmentation is more established, MRI-based segmentation methods are understudied, largely due to a lack of publicly available datasets, benchmarking research efforts, and domain-specific deep learning methods. In this retrospective study, we collected a large dataset (767 scans from 499 participants) of T1-weighted (T1 W) and T2-weighted (T2 W) abdominal MRI series from five centers between March 2004 and November 2022. We also collected CT scans of 1,350 patients from publicly available sources for benchmarking purposes. We introduced a new pancreas segmentation method, called PanSegNet, combining the strengths of nnUNet and a Transformer network with a new linear attention module enabling volumetric computation. We tested PanSegNet's accuracy in cross-modality (a total of 2,117 scans) and cross-center settings with Dice and Hausdorff distance (HD95) evaluation metrics. We used Cohen's kappa statistics for intra and inter-rater agreement evaluation and paired t-tests for volume and Dice comparisons, respectively. For segmentation accuracy, we achieved Dice coefficients of 88.3% (±7.2%, at case level) with CT, 85.0% (±7.9%) with T1 W MRI, and 86.3% (±6.4%) with T2 W MRI. There was a high correlation for pancreas volume prediction with R2 of 0.91, 0.84, and 0.85 for CT, T1 W, and T2 W, respectively. We found moderate inter-observer (0.624 and 0.638 for T1 W and T2 W MRI, respectively) and high intra-observer agreement scores. All MRI data is made available at https://osf.io/kysnj/. Our source code is available at https://github.com/NUBagciLab/PaNSegNet. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhang2025Large-scale
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Wang, Z.
AU  - Dong, X.
AU  - Du, J.
TI  - OnsitNet: A memory-capable online time series forecasting model incorporating a self-attention mechanism
PY  - 2025
T2  - Expert Systems with Applications
VL  - 259
C7  - 125231
DO  - 10.1016/j.eswa.2024.125231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203015786&doi=10.1016%2fj.eswa.2024.125231&partnerID=40&md5=66cfc3c84fb26fe7f2f9b8cd06924690
AB  - Traditional time series (TS) forecasting models are based on fixed, static datasets and lack scalability when faced with the continuous influx of data in real-world scenarios. Real-time online learning of data streams is crucial for improving forecasting efficiency. However, few studies focus on online TS forecasting, and existing approaches have several limitations. Most current online TS forecasting models merely train on data streams and are ineffective in handling concept drift scenarios. Furthermore, they often fail to adequately consider dependencies between variables and do not leverage the robust modeling capabilities of offline models. Therefore, we propose an innovative online learning method called OnsitNet. It consists of multiple learning modules that progressively expand the receptive field of convolutional kernels within the learning modules using an exponentially growing dilation factor, aiding in the capture of multi-scale data features. Within the learning modules, we propose an online learning strategy focusing on memorizing concept drift scenarios, with a fast learner, memorizer, and Pearson trigger. The Pearson trigger activates dynamic interaction between the fast learner and memorizer by detecting new data patterns, facilitating online rapid learning of data streams. To capture the dependencies between variables, we propose a new model, SITransformer, which is a streamlined version of the offline model ITransformer. Unlike the traditional Transformer, it reverses the roles of the feed-forward network and the attention mechanism. This inverted architecture is more effective at learning the correlations between variables. Experimental results on five real-world datasets show OnsitNet achieves lower online prediction errors, enabling timely and effective forecasting of future trends in TS data. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2025OnsitNet
ER  -

TY  - JOUR
AU  - Zheng, R.
AU  - Ren, Y.
AU  - Zhou, Q.
AU  - Ye, Y.
AU  - Zeng, H.
TI  - Cross transformer for LiDAR-based loop closure detection
PY  - 2025
T2  - Machine Vision and Applications
VL  - 36
IS  - 1
C7  - 2
DO  - 10.1007/s00138-024-01629-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208754447&doi=10.1007%2fs00138-024-01629-w&partnerID=40&md5=8998d28c696b854fd8cbec51ac597aeb
AB  - Loop closure detection, also known as place recognition, a key component of simultaneous localization and mapping (SLAM) systems, aims to recognize previously visited locations and reduce the accumulated drift error caused by odometry. Current vision-based methods are susceptible to variations in illumination and perspective, limiting their generalization ability and robustness. Thus, in this paper, we propose CrossT-Net (Cross Transformer Net), a novel cross-attention based loop closure detection network for LiDAR. CrossT-Net directly estimates the similarity between two frames by leveraging multi-class information maps, including range, intensity, and normal maps, to comprehensively characterize environmental features. A Siamese Encoder Net with shared parameters extracts frame features, and a Cross Transformer module captures intra-frame context and inter-frame correlations through self-attention and cross-attention mechanisms. In the final stage, an Overlap Estimation Module predicts the point cloud overlap between two frames. Experimental results on several benchmark datasets demonstrate that our proposed method outperforms existing methods in precision and recall, and exhibits strong generalization performance in different road environments. The implementation of our approach is available at: https://github.com/Bryan-ZhengRui/CrossT-Net_Pytorch. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zheng2025Cross
ER  -

TY  - JOUR
AU  - Chen, Q.
AU  - Wang, L.
AU  - Zhang, Z.
AU  - Wang, X.
AU  - Liu, W.
AU  - Xia, B.
AU  - Ding, H.
AU  - Zhang, J.
AU  - Xu, S.
AU  - Wang, X.
TI  - Dual-path aggregation transformer network for super-resolution with images occlusions and variability
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109535
DO  - 10.1016/j.engappai.2024.109535
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207579082&doi=10.1016%2fj.engappai.2024.109535&partnerID=40&md5=cd360777e061f60001a5d840c8002074
AB  - While Transformer-based approaches have recently achieved notable success in super-resolution, their extensive computational requirements impede widespread practical adoption. High-resolution meteorological satellite cloud imagery is essential for weather analysis and forecasting. Enhancing image resolution through super-resolution techniques facilitates the accurate identification and localization of geographic features by meteorological systems. However, current super-resolution methods fail to restore the intricacies of cloud formations and complex regions fully. This research introduces a novel dual-path aggregation Transformer network (DPAT) tailored to enhance the super-resolution of meteorological satellite cloud images. The DPAT network adeptly captures cloud imagery's subtle details and textures, effectively addressing occlusions and the variability inherent in satellite imagery. It bolsters the model's ability to manage the complex attributes of cloud images through the introduction of the Dual-path Aggregation Self-Attention (DASA) mechanism and the Multi-scale Feature Aggregation Block (MFAB), thereby enhancing performance in processing intricate cloud features. The DASA mechanism synthesizes features across spatial, depth, and channel dimensions via a dual-path approach, thoroughly exploiting feature correlations. The MFAB, designed to supplant the multilayer perceptron, incorporates shift convolution and a multi-scale interaction block to augment feature information, compensating for the deficiency in local information absorption due to fixed receptive fields. Experimental outcomes indicate that DPAT delivers superior super-resolution outcomes. With a parameter count of only 32% of the Enhanced Deep Residual Network (EDSR) or 77% of the Image Restoration using Shift Window Transformer (SwinIR), DPAT matches SwinIR's performance on the satellite cloud dataset. Moreover, DPAT balances accuracy and parameter economy across various datasets. This technology is expected to improve image super-resolution capabilities in multiple fields such as human action recognition and industrial recognition, and indirectly improve the accuracy of image perception tasks. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chen2025Dual-path
ER  -

TY  - JOUR
AU  - Weng, S.
AU  - Zhang, Q.
AU  - Han, K.
AU  - Pan, M.
AU  - Tan, Y.
AU  - Chen, Q.
AU  - Wu, F.
AU  - Wang, C.
AU  - Zheng, L.
AU  - Lei, Y.
AU  - Sha, W.
TI  - Reference-based image super-resolution of hyperspectral and red-green-blue image for determination of wheat kernel quality using deep learning networks
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109513
DO  - 10.1016/j.engappai.2024.109513
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207057436&doi=10.1016%2fj.engappai.2024.109513&partnerID=40&md5=b4d24779ad8ed301cf13e7f0c2445841
AB  - In the process of cultivation and harvest, wheat kernel quality is highly susceptible to various factors, such as disease, mildew, atrophy and impurities, and detection of kernel quality is essential to avoid hazard proliferation, facilitate product grading, and ensure food safety. Possessing abundant image and spectral characteristics, hyperspectral imaging (HSI) has gained impressive achievements in kernel quality analysis, but its low spatial resolution limits its detection accuracy. In this study, reference-based image super-resolution (RefSR) of HSI and Red-Green-Blue image was adopted to improve resolution to determine wheat kernel quality using deep learning networks. Firstly, RefSR was conducted by the improved transformer network with dual-branch feature extraction and weighted fusion operation and achieved excellent RefSR with significant resolution improvement, peak signal to noise ratio of 35.521 and structural similarity index of 0.97, outweighing the existing state-of-the-art networks. Then, the reflectance images (RIs) of effective wavelengths (EWs) from generated HSI images were combined with the residual network with a spatial, channel attention and multi-scale residual to determine wheat kernel quality. Precise analysis was achieved with the accuracy in calibration, validation and prediction sets of 100.00%, 95.26% and 92.78%. RefSR provides a novel and efficient approach for obtaining HSI images of high spatial resolution and facilitates the application of HSI in analysis of crop kernels. RIs of several sporadic EWs can be easily acquired and processed, achieving field and rapid kernel detection. Therefore, the proposed method furnishes the efficient, accurate and applicable determination of wheat kernel quality. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Weng2025Reference-based
ER  -

TY  - JOUR
AU  - Yan, L.
AU  - Wen, H.
AU  - Wang, Z.
AU  - Jin, Y.
AU  - Guo, J.
AU  - Liu, Y.
AU  - Fan, S.
TI  - Prediction and evaluation of key parameters in coalbed methane pre-extraction based on transformer and inversion model
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109661
DO  - 10.1016/j.engappai.2024.109661
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208916996&doi=10.1016%2fj.engappai.2024.109661&partnerID=40&md5=788bc043c169f0e3a1caad937c0fdcc1
AB  - Accurate parameter prediction in the coalbed methane (CBM) pre-extraction process is crucial for formulating effective control measures and preventing CBM-related accidents. Traditional prediction methods rely on feature extraction or complex physical model parameter calculations, which require extensive manual intervention and have limited practical applicability. Additionally, simple neural network methods are prone to overfitting and gradient vanishing when handling parameters, and they lack the capability to dynamically monitor gas pressure during extraction, leading to inefficient and blind extraction operations. This study proposes a CBM pre-extraction parameter and completion time prediction method based on the Transformer model. By integrating autoregressive models and wavelet denoising techniques, the approach effectively captures temporal features and long-term dependencies in CBM data. Experimental results demonstrate that the proposed model outperforms traditional methods in short-, medium-, and long-term predictions, with a median R2 value of 0.99072, and 76% of the training results exceeding 0.9. Furthermore, a CBM pressure inversion model was developed, combining dimensional analysis and physical similarity principles with the Transformer model, enabling the dynamic detection of high- and low-pressure regions in coal seams. In single borehole compliance time predictions, the median compliance time for the first stage is 4 days, with an average of 49 days and a maximum of 277 days, providing adjustment guidance for boreholes with extended compliance times. The proposed model significantly improves prediction accuracy and stability, offering critical support for developing scientifically sustainable pre-extraction plans and advancing intelligent CBM management. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yan2025Prediction
ER  -

TY  - JOUR
AU  - Jin, Z.
AU  - Fu, X.
AU  - Xiang, L.
AU  - Zhu, G.
AU  - Hu, A.
TI  - Informer learning framework based on secondary decomposition for multi-step forecast of ultra-short term wind speed
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109702
DO  - 10.1016/j.engappai.2024.109702
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209557349&doi=10.1016%2fj.engappai.2024.109702&partnerID=40&md5=fa8043469ecdde124d6fa82b72b47e81
AB  - Accurate and dependable wind speed prediction holds paramount importance in facilitating the dispatch and safe operation of power systems. Nonetheless, the inherent instability of wind speed makes wind speed prediction challenging. Consequently, a short-term wind speed prediction framework, amalgamating secondary decomposition (SD)-Informer, has been proposed in this paper. Initially, the variational mode decomposition (VMD) is applied to decompose the primary wind speed sequence. Through the VMD feature decomposition module, it effectively filters and eliminates superfluous noise from wind speed data. Subsequently, the complete ensemble empirical mode decomposition with adaptive noise technique is introduced for a secondary decomposition targeting the high-frequency components derived from the initial decomposition. To address the limitation of neural network models in capturing essential information from lengthy sequential data concurrently, a predictive model based on Informer is proposed as wind speed prediction module, thereby enhancing prediction accuracy. The validation of this hybrid model encompasses four distinct time ranges. Multiple models are scrutinized through comparative analysis to ascertain the superior performance of the proposed hybrid model. The root mean square error of the proposed method is reduced by 33.02%、25.46%、24.26%, and 23.12% compared to gate recurrent unit (GRU), vision Transformer (ViT), attention (AT)-ViT, and CNN-atteneion (CA)-Bi-directional long short-term memory (BiLSTM) respectively. The mean absolute error of the proposed method in the first quarter is 0.432, with model comparison values reduction of 36.19%、22.99%、20.44%, and17.71% respectively. The experimental results indicate that the proposed model exhibits a strong capability in capturing the long-term dependencies between the input and output sequences of wind speed. It can perform multi-step predictions while ensuring high prediction accuracy. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jin2025Informer
ER  -

TY  - JOUR
AU  - Zhou, P.
AU  - Wu, B.
AU  - Wang, C.
AU  - He, L.
TI  - An improved hierarchical neural network model with local and global feature matching for script event prediction
PY  - 2025
T2  - Expert Systems with Applications
VL  - 259
C7  - 125325
DO  - 10.1016/j.eswa.2024.125325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203296210&doi=10.1016%2fj.eswa.2024.125325&partnerID=40&md5=8d72258c24d1690c5cd46bf9cf2eafb8
AB  - Script event prediction aims to predict subsequent events based on given context event sequences, requiring a deep understanding of script contexts. Many hierarchical neural network models have been proposed for this purpose. However, existing models often neglect high-level context modeling, while primarily focusing on low-level event arguments and middle-level event relations. To address this issue, we propose an improved hierarchical neural network model that integrates local and global feature matching for script event prediction. First, we extract low-level and middle-level event features using an event encoding layer and an event relation layer, respectively. In particular, the event encoding layer employs stacked transformers with learnable positional encoding to comprehensively capture the connections between event arguments. Then instead of previous local score-level event matching, we further introduce a novel feature-level event matching layer to globally match the context event chain and candidate events. This layer matches the candidate event associated with each context event based on multiple dimensionless similarity measures and aggregates these local matching vectors into a global matching vector using an attention mechanism, thereby capturing holistic contextual information. Finally, the global matching vector is fed into an event prediction layer comprising a classification network (e.g., a multi-layered perceptron) to compute the relatedness score. By stacking four bottom-up layers, our model learns multi-level event interactions and deeply understands the script context, resulting in more accurate event predictions. Experimental results on the New York Times corpus demonstrate that our model outperforms state-of-the-art baselines, while being computationally efficient, stable, and quick to converge during training. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhou2025improved
ER  -

TY  - JOUR
AU  - Zhu, X.
AU  - Ma, C.
AU  - Lei, H.
AU  - Xia, P.
AU  - Peng, Z.
TI  - A novel integrated prediction method using adaptive mode decomposition, attention mechanism and deep learning for coking products prices
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109504
DO  - 10.1016/j.engappai.2024.109504
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207031009&doi=10.1016%2fj.engappai.2024.109504&partnerID=40&md5=4ed458226ac6ae717139390c02c1bfaf
AB  - Accurate prediction of coking product prices is crucial for enhancing production efficiency, cost optimization, and profit maximization in smart coking facilities. To address the volatility caused by nonlinear factors such as raw material costs, substitutes, macroeconomic indicators, sudden events, policy changes, and market behaviors, we propose a novel integrated prediction method for coking product price prediction. This method combines Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) for signal decomposition, Bidirectional Encoder Representations from Transformers (BERT) for natural language processing, attention mechanisms (AT) to weigh feature importance, and an ensemble of Bidirectional Gated Recurrent Unit, Bidirectional Long Short-Term Memory, and Gated Recurrent Unit, abbreviated BBG, for robust feature extraction. We design a feature selection strategy to avoid data leakage and improve the predictive ability of the model, and describe a method to maintain textual data information integrity when combining data from different sources. Experimental results on coke and methanol datasets show that our approach retains multi-source text richness improves predictive capability, and outperforms other state-of-the-art methods, providing an effective tool for developing smart coke plants. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhu2025novel
ER  -

TY  - JOUR
AU  - Ramirez, I.
AU  - Pino, J.
AU  - Pardo, D.
AU  - Sanz, M.
AU  - del Rio, L.
AU  - Ortiz, A.
AU  - Morozovska, K.
AU  - Aizpurua, J.I.
TI  - Residual-based attention Physics-informed Neural Networks for spatio-temporal ageing assessment of transformers operated in renewable power plants
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109556
DO  - 10.1016/j.engappai.2024.109556
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208238685&doi=10.1016%2fj.engappai.2024.109556&partnerID=40&md5=089c2033415b4bc4da2a25f189fe85d4
AB  - Transformers are crucial for reliable and efficient power system operations, particularly in supporting the integration of renewable energy. Effective monitoring of transformer health is critical to maintain grid stability and performance. Thermal insulation ageing is a key transformer failure mode, which is generally tracked by monitoring the hotspot temperature (HST). However, HST measurement is complex, costly, and often estimated from indirect measurements. Existing HST models focus on space-agnostic thermal models, providing worst-case HST estimates. This article introduces a spatio-temporal model for transformer winding temperature and ageing estimation, which leverages physics-based partial differential equations (PDEs) with data-driven Neural Networks (NN) in a Physics Informed Neural Networks (PINNs) configuration to improve prediction accuracy and acquire spatio-temporal resolution. The computational accuracy of the PINN model is improved through the implementation of the Residual-Based Attention (PINN-RBA) scheme that accelerates the PINN model convergence. The PINN-RBA model is benchmarked against self-adaptive attention schemes and classical vanilla PINN configurations. For the first time, PINN based oil temperature predictions are used to estimate spatio-temporal transformer winding temperature values, validated through PDE numerical solution and fiber optic sensor measurements. Furthermore, the spatio-temporal transformer ageing model is inferred, which supports transformer health management decision-making. Results are validated with a distribution transformer operating on a floating photovoltaic power plant. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Ramirez2025Residual-based
ER  -

TY  - JOUR
AU  - Elforaici, M.E.A.
AU  - Montagnon, E.
AU  - Romero, F.P.
AU  - Le, W.T.
AU  - Azzi, F.
AU  - Trudel, D.
AU  - Nguyen, B.
AU  - Turcotte, S.
AU  - Tang, A.
AU  - Kadoury, S.
TI  - Semi-supervised ViT knowledge distillation network with style transfer normalization for colorectal liver metastases survival prediction
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103346
DO  - 10.1016/j.media.2024.103346
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206440337&doi=10.1016%2fj.media.2024.103346&partnerID=40&md5=da1b49b68aa9a47f00e93107b25122b7
AB  - Colorectal liver metastases (CLM) affect almost half of all colon cancer patients and the response to systemic chemotherapy plays a crucial role in patient survival. While oncologists typically use tumor grading scores, such as tumor regression grade (TRG), to establish an accurate prognosis on patient outcomes, including overall survival (OS) and time-to-recurrence (TTR), these traditional methods have several limitations. They are subjective, time-consuming, and require extensive expertise, which limits their scalability and reliability. Additionally, existing approaches for prognosis prediction using machine learning mostly rely on radiological imaging data, but recently histological images have been shown to be relevant for survival predictions by allowing to fully capture the complex microenvironmental and cellular characteristics of the tumor. To address these limitations, we propose an end-to-end approach for automated prognosis prediction using histology slides stained with Hematoxylin and Eosin (H&E) and Hematoxylin Phloxine Saffron (HPS). We first employ a Generative Adversarial Network (GAN) for slide normalization to reduce staining variations and improve the overall quality of the images that are used as input to our prediction pipeline. We propose a semi-supervised model to perform tissue classification from sparse annotations, producing segmentation and feature maps. Specifically, we use an attention-based approach that weighs the importance of different slide regions in producing the final classification results. Finally, we exploit the extracted features for the metastatic nodules and surrounding tissue to train a prognosis model. In parallel, we train a vision Transformer model in a knowledge distillation framework to replicate and enhance the performance of the prognosis prediction. We evaluate our approach on an in-house clinical dataset of 258 CLM patients, achieving superior performance compared to other comparative models with a c-index of 0.804 (0.014) for OS and 0.735 (0.016) for TTR, as well as on two public datasets. The proposed approach achieves an accuracy of 86.9% to 90.3% in predicting TRG dichotomization. For the 3-class TRG classification task, the proposed approach yields an accuracy of 78.5% to 82.1%, outperforming the comparative methods. Our proposed pipeline can provide automated prognosis for pathologists and oncologists, and can greatly promote precision medicine progress in managing CLM patients. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Elforaici2025Semi-supervised
ER  -

TY  - JOUR
AU  - Huang, J.
AU  - Yang, L.
AU  - Wang, F.
AU  - Wu, Y.
AU  - Nan, Y.
AU  - Wu, W.
AU  - Wang, C.
AU  - Shi, K.
AU  - Aviles-Rivero, A.I.
AU  - Schönlieb, C.-B.
AU  - Zhang, D.
AU  - Yang, G.
TI  - Enhancing global sensitivity and uncertainty quantification in medical image reconstruction with Monte Carlo arbitrary-masked mamba
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103334
DO  - 10.1016/j.media.2024.103334
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203410981&doi=10.1016%2fj.media.2024.103334&partnerID=40&md5=9a9ae941a75319839df6625d54ac8a1a
AB  - Deep learning has been extensively applied in medical image reconstruction, where Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) represent the predominant paradigms, each possessing distinct advantages and inherent limitations: CNNs exhibit linear complexity with local sensitivity, whereas ViTs demonstrate quadratic complexity with global sensitivity. The emerging Mamba has shown superiority in learning visual representation, which combines the advantages of linear scalability and global sensitivity. In this study, we introduce MambaMIR, an Arbitrary-Masked Mamba-based model with wavelet decomposition for joint medical image reconstruction and uncertainty estimation. A novel Arbitrary Scan Masking (ASM) mechanism “masks out” redundant information to introduce randomness for further uncertainty estimation. Compared to the commonly used Monte Carlo (MC) dropout, our proposed MC-ASM provides an uncertainty map without the need for hyperparameter tuning and mitigates the performance drop typically observed when applying dropout to low-level tasks. For further texture preservation and better perceptual quality, we employ the wavelet transformation into MambaMIR and explore its variant based on the Generative Adversarial Network, namely MambaMIR-GAN. Comprehensive experiments have been conducted for multiple representative medical image reconstruction tasks, demonstrating that the proposed MambaMIR and MambaMIR-GAN outperform other baseline and state-of-the-art methods in different reconstruction tasks, where MambaMIR achieves the best reconstruction fidelity and MambaMIR-GAN has the best perceptual quality. In addition, our MC-ASM provides uncertainty maps as an additional tool for clinicians, while mitigating the typical performance drop caused by the commonly used dropout. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Huang2025Enhancing
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Boels, M.
AU  - Garcia-Peraza-Herrera, L.C.
AU  - Vercauteren, T.
AU  - Dasgupta, P.
AU  - Granados, A.
AU  - Ourselin, S.
TI  - LoViT: Long Video Transformer for surgical phase recognition
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103366
DO  - 10.1016/j.media.2024.103366
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206302288&doi=10.1016%2fj.media.2024.103366&partnerID=40&md5=6a17302ca5c8039849f513eabafbb8b7
AB  - Online surgical phase recognition plays a significant role towards building contextual tools that could quantify performance and oversee the execution of surgical workflows. Current approaches are limited since they train spatial feature extractors using frame-level supervision that could lead to incorrect predictions due to similar frames appearing at different phases, and poorly fuse local and global features due to computational constraints which can affect the analysis of long videos commonly encountered in surgical interventions. In this paper, we present a two-stage method, called Long Video Transformer (LoViT), emphasizing the development of a temporally-rich spatial feature extractor and a phase transition map. The temporally-rich spatial feature extractor is designed to capture critical temporal information within the surgical video frames. The phase transition map provides essential insights into the dynamic transitions between different surgical phases. LoViT combines these innovations with a multiscale temporal aggregator consisting of two cascaded L-Trans modules based on self-attention, followed by a G-Informer module based on ProbSparse self-attention for processing global temporal information. The multi-scale temporal head then leverages the temporally-rich spatial features and phase transition map to classify surgical phases using phase transition-aware supervision. Our approach outperforms state-of-the-art methods on the Cholec80 and AutoLaparo datasets consistently. Compared to Trans-SVNet, LoViT achieves a 2.4 pp (percentage point) improvement in video-level accuracy on Cholec80 and a 3.1 pp improvement on AutoLaparo. Our results demonstrate the effectiveness of our approach in achieving state-of-the-art performance of surgical phase recognition on two datasets of different surgical procedures and temporal sequencing characteristics. The project page is available at https://github.com/MRUIL/LoViT. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2025LoViT
ER  -

TY  - JOUR
AU  - Liao, W.
AU  - Liu, Z.
AU  - Dai, H.
AU  - Wu, Z.
AU  - Zhang, Y.
AU  - Huang, X.
AU  - Chen, Y.
AU  - Jiang, X.
AU  - Liu, D.
AU  - Zhu, D.
AU  - Li, S.
AU  - Liu, W.
AU  - Liu, T.
AU  - Li, Q.
AU  - Cai, H.
AU  - Li, X.
TI  - Mask-guided BERT for few-shot text classification
PY  - 2024
T2  - Neurocomputing
VL  - 610
C7  - 128576
DO  - 10.1016/j.neucom.2024.128576
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204049043&doi=10.1016%2fj.neucom.2024.128576&partnerID=40&md5=507449ff5fc99e334a5bd5c4677e8aa5
AB  - Transformer-based language models have achieved significant success in various domains. However, the data-intensive nature of the transformer architecture requires much labeled data, which is challenging in low-resource scenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the difficulty of training robust models on small amounts of samples, which frequently leads to overfitting. Here we present Mask-BERT, a simple and modular framework to help BERT-based architectures tackle FSL. The proposed approach fundamentally differs from existing FSL strategies such as prompt tuning and meta-learning. The core idea is to selectively apply masks on text inputs and filter out irrelevant information, which guides the model to focus on discriminative tokens that influence prediction results. In addition, to make the text representations from different categories more separable and the text representations from the same category more compact, we introduce a contrastive learning loss function. Experimental results on open-domain and medical-domain datasets demonstrate the effectiveness of Mask-BERT. Code and data are available at: github.com/WenxiongLiao/mask-bert © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Liao2024Mask-guided
ER  -

TY  - JOUR
AU  - Mao, Y.
AU  - Feng, Q.
AU  - Zhang, Y.
AU  - Ning, Z.
TI  - Semantics and instance interactive learning for labeling and segmentation of vertebrae in CT images
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103380
DO  - 10.1016/j.media.2024.103380
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208238021&doi=10.1016%2fj.media.2024.103380&partnerID=40&md5=f5b93216e491b71783ba67f945da9db1
AB  - Automatically labeling and segmenting vertebrae in 3D CT images compose a complex multi-task problem. Current methods progressively conduct vertebra labeling and semantic segmentation, which typically include two separate models and may ignore feature interaction among different tasks. Although instance segmentation approaches with multi-channel prediction have been proposed to alleviate such issues, their utilization of semantic information remains insufficient. Additionally, another challenge for an accurate model is how to effectively distinguish similar adjacent vertebrae and model their sequential attribute. In this paper, we propose a Semantics and Instance Interactive Learning (SIIL) paradigm for synchronous labeling and segmentation of vertebrae in CT images. SIIL models semantic feature learning and instance feature learning, in which the former extracts spinal semantics and the latter distinguishes vertebral instances. Interactive learning involves semantic features to improve the separability of vertebral instances and instance features to help learn position and contour information, during which a Morphological Instance Localization Learning (MILL) module is introduced to align semantic and instance features and facilitate their interaction. Furthermore, an Ordinal Contrastive Prototype Learning (OCPL) module is devised to differentiate adjacent vertebrae with high similarity (via cross-image contrastive learning), and simultaneously model their sequential attribute (via a temporal unit). Extensive experiments on several datasets demonstrate that our method significantly outperforms other approaches in labeling and segmenting vertebrae. Our code is available at https://github.com/YuZhang-SMU/Vertebrae-Labeling-Segmentation © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Mao2025Semantics
ER  -

TY  - JOUR
AU  - Wang, C.-W.
AU  - Liu, T.-C.
AU  - Lai, P.-J.
AU  - Muzakky, H.
AU  - Wang, Y.-C.
AU  - Yu, M.-H.
AU  - Wu, C.-H.
AU  - Chao, T.-K.
TI  - Ensemble transformer-based multiple instance learning to predict pathological subtypes and tumor mutational burden from histopathological whole slide images of endometrial and colorectal cancer
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103372
DO  - 10.1016/j.media.2024.103372
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207317050&doi=10.1016%2fj.media.2024.103372&partnerID=40&md5=f61dea8d216c0b22bc0c334e160e1082
AB  - In endometrial cancer (EC) and colorectal cancer (CRC), in addition to microsatellite instability, tumor mutational burden (TMB) has gradually gained attention as a genomic biomarker that can be used clinically to determine which patients may benefit from immune checkpoint inhibitors. High TMB is characterized by a large number of mutated genes, which encode aberrant tumor neoantigens, and implies a better response to immunotherapy. Hence, a part of EC and CRC patients associated with high TMB may have higher chances to receive immunotherapy. TMB measurement was mainly evaluated by whole-exome sequencing or next-generation sequencing, which was costly and difficult to be widely applied in all clinical cases. Therefore, an effective, efficient, low-cost and easily accessible tool is urgently needed to distinguish the TMB status of EC and CRC patients. In this study, we present a deep learning framework, namely Ensemble Transformer-based Multiple Instance Learning with Self-Supervised Learning Vision Transformer feature encoder (ETMIL-SSLViT), to predict pathological subtype and TMB status directly from the H&E stained whole slide images (WSIs) in EC and CRC patients, which is helpful for both pathological classification and cancer treatment planning. Our framework was evaluated on two different cancer cohorts, including an EC cohort with 918 histopathology WSIs from 529 patients and a CRC cohort with 1495 WSIs from 594 patients from The Cancer Genome Atlas. The experimental results show that the proposed methods achieved excellent performance and outperforming seven state-of-the-art (SOTA) methods in cancer subtype classification and TMB prediction on both cancer datasets. Fisher's exact test further validated that the associations between the predictions of the proposed models and the actual cancer subtype or TMB status are both extremely strong (p<0.001). These promising findings show the potential of our proposed methods to guide personalized treatment decisions by accurately predicting the EC and CRC subtype and the TMB status for effective immunotherapy planning for EC and CRC patients. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2025Ensemble
ER  -

TY  - JOUR
AU  - Zheng, X.
AU  - Du, Y.
AU  - Qin, X.
TI  - CoMaSa:Context Multi-aware Self-attention for emotional response generation
PY  - 2025
T2  - Neurocomputing
VL  - 611
C7  - 128692
DO  - 10.1016/j.neucom.2024.128692
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205588231&doi=10.1016%2fj.neucom.2024.128692&partnerID=40&md5=748e0670db90a924049c8088d0027855
AB  - Dialogue generation is an important research direction in natural language generation, and generating utterances with appropriate contextual emotion is a challenging task. The previous work incorporates commonsense knowledge as an auxiliary information source by simply concatenating or adding it to the embeddings of the dialogue context. They did not consider updating the commonsense knowledge from the perspective of context semantic information or selecting context from the perspective of commonsense knowledge semantic information. At the same time, they did not extract emotional information from dialogue context and commonsense knowledge to enhance the embeddings of the dialogue text. These defects may lead to the dialogue model's inability to judge the semantic consistency between context and generated utterance, and result in the generation of utterance unassociated with the dialogue context and the corresponding context emotion being untrue. Our goal is to build an emotional dialogue generation model that can deeply integrate commonsense knowledge with dialogue context and achieve bidirectional semantic interaction and enhancement. Therefore, in this paper, we propose a context multi-aware self-attention emotion dialogue generation model that models from multiple aspects such as the semantic information, emotional information of context and external knowledge, it effectively alleviates the problems of generating utterance unrelated to the context and disordered emotional expressions in utterance. First, we adopt the transformer encoder as the basic framework and carefully construct a context-aware encoder capable of deeply extracting semantic information. Specifically, we ingeniously integrate different levels of positional information to simulate the natural flow of conversation between speakers. Then, we effectively integrate these positional information with the basic word embedding vectors, and enrich the dialogue's embedding representation. Lastly, by introducing the attention mechanism, the model can precisely capture and extract context information closely related to the current situation and achieve a deep understanding and accurate grasp of the dialogue content. Second, we consider that the relationship between context and commonsense knowledge is not just a unidirectional selection but a more intimate bidirectional interaction. Therefore, we designed a bidirectional interaction attention component for context and external knowledge. Specifically, we use the method of iterative similarity matrices to calculate the bidirectional similarity relationship between context and external knowledge. Then, using the attention algorithm, we calculate the connectivity from context to commonsense knowledge and from commonsense knowledge to context. Finally, by combining the semantic embeddings of both aspects, we achieve bidirectional updating of context and external knowledge. Third, we establish an emotion-aware decoder based on multi-task learning, which includes an emotion classifier and an utterance generator. In the emotion classifier, we establish an auxiliary task for emotion recognition to help the model understand the process of emotional transition. We use the output of the emotion recognition model as an additional supervisory signal to better control the generation of emotional responses. In the utterance generator, we integrate the output of the emotion classifier with the interaction vector from the bidirectional interaction attention component. This fusion allows us to generate utterance that aligns with the emotional context. Our experiments on DailyDialog and ESConv datasets show that CoMaSa outperforms the baselines in terms of Perplexity, Distinct-1, Distinct-2, and human evaluation. The experiment demonstrates the effectiveness of our Context Multi-aware Self-attention model in the task of emotion generation. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zheng2025CoMaSa:Context
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Hu, J.
AU  - Li, M.
AU  - Zhao, S.
TI  - A long-term dissolved oxygen prediction model in aquaculture using transformer with a dynamic adaptive mechanism
PY  - 2025
T2  - Expert Systems with Applications
VL  - 259
C7  - 125258
DO  - 10.1016/j.eswa.2024.125258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202970314&doi=10.1016%2fj.eswa.2024.125258&partnerID=40&md5=5dcc042b2032307c9923f63f94c8940e
AB  - The prediction of Dissolved Oxygen (DO) in oceans is crucial for the survival of marine life and the management of marine farms. However, due to the inherent instability and uncertainty of DO, prediction models frequently necessitate parameter adjustments, posing challenges to maintaining reliable predictive performance and generalization capabilities. Based on this, a long-term dissolved oxygen prediction model in aquaculture using Transformer with a dynamic adaptive mechanism is proposed in the paper. A multi-scale latent correlation decomposition strategy was devised, merging both time and frequency domain decompositions. This approach proficiently untangles time series exhibiting intricate non-linear cycles, thereby delving deeper into and furnishing a more comprehensive array of feature data. Furthermore, an uncertainty-aware attention mechanism was posited, ensuring accurate pinpointing of pivotal data amidst a highly volatile data environment, thus cementing prediction accuracy. Finally, the incorporation of an adaptive hyperparameter adjustment mechanism enables the model to recalibrate in line with feature insights, bolstering its generalization potential across marine farms in diverse regions. Empirical results show that the model proposed in this study can effectively accomplish high-precision long-term forecasting. When juxtaposed with other models under comparable conditions, its mean squared error significantly diminished by 40.2%, the mean absolute error contracted by 55.4%, and concurrently, the R2 value ascended by 7%. This research proffers a fresh vantage point for long-term marine chemical data predictions and extends robust technical bolstering for refining and augmenting aquacultural strategies. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2025long-term
ER  -

TY  - JOUR
AU  - Keddous, F.E.
AU  - Llanza, A.
AU  - Shvai, N.
AU  - Nakib, A.
TI  - Vision transformers inference acceleration based on adaptive layer normalization
PY  - 2024
T2  - Neurocomputing
VL  - 610
C7  - 128524
DO  - 10.1016/j.neucom.2024.128524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204355389&doi=10.1016%2fj.neucom.2024.128524&partnerID=40&md5=a711f27251c6eea6dbd7b32635837dd6
AB  - Over the past decade, deep neural networks (DNNs) have been widely used due to their remarkable accuracy in real-world applications. However, this increase in accuracy often results in computationally expensive models and high memory usage, leading to longer prediction latencies and exorbitant release costs. In this paper, we propose a new adaptive layer normalization (ALN) algorithm for transformer models, which tackles the computational, and memory problems encountered by traditional layer normalization (LN) techniques. The proposed method computes and stores statistical moments during the training and uses them directly during the inference phase, allowing the normalization layer to be merged with the nearest linear layer. The result is a significant acceleration in inference time, by up to 29%. In classification tasks, our evaluations on the ImageNet dataset show an improvement in accuracy of 0.1%, while maintaining comparable accuracy in object detection tasks on the COCO reference dataset. The proposed ALN algorithm is a simple and effective solution for improving the inference time of pre-trained transformer models, making it a valuable tool for natural language processing and computer vision tasks. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Keddous2024Vision
ER  -

TY  - JOUR
AU  - Wang, Q.
AU  - Zhao, S.
AU  - Xu, Z.
AU  - Zhou, S.K.
TI  - LACOSTE: Exploiting stereo and temporal contexts for surgical instrument segmentation
PY  - 2025
T2  - Medical Image Analysis
VL  - 99
C7  - 103387
DO  - 10.1016/j.media.2024.103387
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209140692&doi=10.1016%2fj.media.2024.103387&partnerID=40&md5=233365dcc2c0494fc0aaa162bdb71b91
AB  - Surgical instrument segmentation is instrumental to minimally invasive surgeries and related applications. Most previous methods formulate this task as single-frame-based instance segmentation while ignoring the natural temporal and stereo attributes of a surgical video. As a result, these methods are less robust against the appearance variation through temporal motion and view change. In this work, we propose a novel LACOSTE model that exploits Location-Agnostic COntexts in Stereo and TEmporal images for improved surgical instrument segmentation. Leveraging a query-based segmentation model as core, we design three performance-enhancing modules. Firstly, we design a disparity-guided feature propagation module to enhance depth-aware features explicitly. To generalize well for even only a monocular video, we apply a pseudo stereo scheme to generate complementary right images. Secondly, we propose a stereo-temporal set classifier, which aggregates stereo-temporal contexts in a universal way for making a consolidated prediction and mitigates transient failures. Finally, we propose a location-agnostic classifier to decouple the location bias from mask prediction and enhance the feature semantics. We extensively validate our approach on three public surgical video datasets, including two benchmarks from EndoVis Challenges and one real radical prostatectomy surgery dataset GraSP. Experimental results demonstrate the promising performances of our method, which consistently achieves comparable or favorable results with previous state-of-the-art approaches. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2025LACOSTE
ER  -

TY  - JOUR
AU  - Youwai, S.
AU  - Detcheewa, S.
TI  - Predicting rapid impact compaction of soil using a parallel transformer and long short-term memory architecture for sequential soil profile encoding
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109664
DO  - 10.1016/j.engappai.2024.109664
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209149262&doi=10.1016%2fj.engappai.2024.109664&partnerID=40&md5=507f7a4fe4ece535175178c3e8d49825
AB  - This study presents an advanced deep learning approach for predicting the effectiveness of Rapid Impact Compaction (RIC). The model integrates the focused attention mechanisms of transformer architectures with the sequential data processing capabilities of Long Short-Term Memory (LSTM) networks. Input parameters include the initial soil profile and feature vectors representing the soil's initial state, applied compaction effort, and compaction hammer energy. Utilizing an encoder-decoder framework, the model encodes soil profile information at various depths into tokens, which are subsequently decoded to predict the resulting ground improvement. An ablation study was conducted to assess the significance of each model component. The model's predictive accuracy was validated using field test data, demonstrating a strong correlation with observed outcomes (mean absolute error of 0.42 for test data). Shapley value analysis of the trained model revealed that compaction effort exerted the highest influence on predictions, followed by fine content and fill thickness. The model architecture also demonstrated successful application to alternative RIC case studies, indicating potential generalizability. Furthermore, the model's capability to simulate hypothetical scenarios with varying compaction efforts provides valuable insights for strategic planning and optimization of RIC project designs. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Youwai2025Predicting
ER  -

TY  - JOUR
AU  - Zahra, S.T.
AU  - Imdad, S.K.
AU  - Khan, S.
AU  - Khalid, S.
AU  - Baig, N.A.
TI  - Power transformer health index and life span assessment: A comprehensive review of conventional and machine learning based approaches
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109474
DO  - 10.1016/j.engappai.2024.109474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207344905&doi=10.1016%2fj.engappai.2024.109474&partnerID=40&md5=b8856e972067ede8a74b0af599f93397
AB  - Power transformers play a critical role within the electrical power system, making their health assessment and the prediction of their remaining lifespan paramount for the purpose of ensuring efficient operation and facilitating effective maintenance planning. This paper undertakes a comprehensive examination of existent literature, with a primary focus on both conventional and cutting-edge techniques employed within this domain. The merits and demerits of recent methodologies and techniques are subjected to meticulous scrutiny and explication. Furthermore, this paper expounds upon intelligent fault diagnosis methodologies and delves into the most widely utilized intelligent algorithms for the assessment of transformer conditions. Diverse Artificial Intelligence (AI) approaches, including Artificial Neural Networks (ANN) and Convolutional Neural Network (CNN), Support Vector Machine (SVM), Random Forest (RF), Genetic Algorithm (GA), and Particle Swarm Optimization (PSO), are elucidated offering pragmatic solutions for enhancing the performance of transformer fault diagnosis. The amalgamation of multiple AI methodologies and the exploration of time-series analysis further contribute to the augmentation of diagnostic precision and the early detection of faults in transformers. By furnishing a comprehensive panorama of AI applications in the field of transformer fault diagnosis, this study lays the groundwork for future research endeavors and the progression of this critical area of study. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zahra2025Power
ER  -

TY  - JOUR
AU  - Croce, D.
AU  - Smirnov, A.
AU  - Tiburzi, L.
AU  - Travaglini, S.
AU  - Costa, R.
AU  - Calabrese, A.
AU  - Basili, R.
AU  - Levialdi Ghiron, N.
AU  - Melino, G.
TI  - AI-driven transcriptomic encoders: From explainable models to accurate, sample-independent cancer diagnostics
PY  - 2024
T2  - Expert Systems with Applications
VL  - 258
C7  - 125126
DO  - 10.1016/j.eswa.2024.125126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202341406&doi=10.1016%2fj.eswa.2024.125126&partnerID=40&md5=b9fc8309c79bba5a03b1904698088b0d
AB  - In the rapidly evolving domain of medical technology, the utilization of sophisticated algorithms for deciphering transcriptional data has emerged as a critical aspect, especially in the oncology sector. These algorithms, drawing upon methodologies from fields such as natural language processing and advanced image analysis, can significantly enhance the accuracy in predicting cancer-related molecular states. Notably, Transformer models, renowned for their proficiency in handling extensive datasets, are now being adapted for breakthroughs in medical diagnostics or in stratifying patients according to prognostic levels. Our study contributes to the field of precision medicine by integrating Transformer-based learning, exemplified by the Geneformer model, with explainable AI techniques. These techniques are employed to find out the input variables (genes resulting from genomic transcription) most correlated with the decisions of neural network systems. This insight, a key goal in genomic research, aims to select the most relevant gene subset for each specific task in which a neural network is employed. This selection approach has proven to be effective in two classification tasks: cell type classification and breast cancer type classification. Such effectiveness has been demonstrated even across various cohorts of patients. When applying Geneformer-like architecture analyses solely to the selected gene subsets, the outcomes either maintain their accuracy or significantly improve. This approach, aims not only to contribute to the identification of vital genetic markers in cancer genomics, but also to exemplify the adaptability of AI models to different datasets, marking a significant step towards the development of accurate and universally applicable diagnostic tools for precision medicine. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Croce2024AI-driven
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Yu, X.
AU  - Liu, G.
AU  - Fan, X.
AU  - Ge, F.
AU  - Zhao, Y.
AU  - Zheng, X.
TI  - Transformer-based medication recommendation with a multiple graph augmentation strategy
PY  - 2024
T2  - Expert Systems with Applications
VL  - 257
C7  - 125091
DO  - 10.1016/j.eswa.2024.125091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201675490&doi=10.1016%2fj.eswa.2024.125091&partnerID=40&md5=fe31ddcbbe8a25ca48c221c308ef1b75
AB  - Medication recommendation (MR) is a promising task that benefits both patients and medical practitioners. However, the individual differences in patients and drug–drug interactions (DDIs) in medication combinations are two key factors that severely limit the personalization and safety of the present MR models. To alleviate the challenges mentioned above, this paper proposes a novel MR model named Trans-GAHNet, which innovatively leverages transformer-based representation learning and constructs multiple graphs for drug information augmentation. More specifically, the transformer network architecture is deployed to fully encode the sequential EHR data for effective patient representations, which addresses the cold start issue and enhances the interpretability of representation learning. Next, multiple graphs are employed to capture the co-occurrence and exclusiveness in drug pairs and to mitigate potential DDIs in drug combinations, thereby enhancing the personalization and safety of the predicted medication combinations. Finally, extensive experiments on real-world datasets are conducted to evaluate the proposed model, and the experimental results demonstrate that Trans-GAHNet outperforms the state-of-the-art baseline models on multiple metrics, with Jaccard, F1 and PRAUC scores of 0.5238, 0.6786 and 0.7795, respectively. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024Transformer-based
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Yuan, H.
AU  - Lin, K.
AU  - Zhang, Y.
AU  - Xue, Y.
AU  - Liu, P.
AU  - Chen, Z.
AU  - Wu, M.
TI  - Artificial intelligence-empowered assessment of bile duct stone removal challenges
PY  - 2024
T2  - Expert Systems with Applications
VL  - 258
C7  - 125146
DO  - 10.1016/j.eswa.2024.125146
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202552721&doi=10.1016%2fj.eswa.2024.125146&partnerID=40&md5=93665c30bd65b2952389f5ef1e919533
AB  - The aim of this investigation was to unravel the complexities inherent in endoscopic retrograde cholangiopancreatography (ERCP) procedures for bile duct stone removal by leveraging advanced artificial intelligence (AI) methodologies to support clinical decision-making and optimize patient outcomes. We introduced the Assessment of Stone Removal Challenges (ACRS) system, a novel integration of Data-efficient Image Transformers (DeiT) for image data analysis and eXtreme Gradient Boosting (XGBoost) for clinical data interpretation. Our study included a patient cohort of 2,129 individuals, focusing on training the ACRS system to achieve high diagnostic precision. Using logistic regression, we identified pivotal predictors affecting the complexity of bile duct stone removal. These findings were visually represented through forest plots and nomograms. Analytical and visualization processes were conducted using the Python and R programming languages, adhering to a p value significance threshold of less than 0.05. By utilizing DeiT enhanced by transfer learning and XGBoost for clinical data interpretation, the system achieved an accuracy of 0.83 and a perfect recall rate on a test set of 2,129 patients. Gradient-weighted class activation mapping (Grad-CAM) and SHapley Additive exPlanations (SHAP) provided in-depth diagnostic insights. Logistic regression was applied to identify crucial clinical predictors for stone removal difficulty, as visualized through forest plots and nomograms. These tools facilitated measurable assessments of procedural complexity, making significant strides in gastroenterology diagnostics and decision-making. By adopting causal inference techniques, the system effectively quantifies the influence of various clinical entities on stone removal difficulty, thereby augmenting both diagnostic precision and procedural strategies in ERCP. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wang2024Artificial
ER  -

TY  - JOUR
AU  - ÜZEN, H.
AU  - FIRAT, H.
AU  - Atila, O.
AU  - ŞENGÜR, A.
TI  - Swin transformer-based fork architecture for automated breast tumor classification
PY  - 2024
T2  - Expert Systems with Applications
VL  - 256
C7  - 125009
DO  - 10.1016/j.eswa.2024.125009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200591667&doi=10.1016%2fj.eswa.2024.125009&partnerID=40&md5=deb00f9d9bf323402af93d7dfcaba68a
AB  - Breast cancer constitutes a prevalent and escalating health concern globally. Additionally, the significance of early diagnosis for effective treatment cannot be overstated. Ultrasound imaging (UI) emerges as a cost-effective means for early diagnosis. However, the interpretation of user interface images can be challenging, leading to the development of computer-aided diagnostic systems. In this article, a network architecture named Swin Transformer-based Fork Network (SW-ForkNet) is developed for breast tumor classification. Utilizing the DenseNet121 backbone, SW-ForkNet amalgamates spatial, semantic, and long-context features. The inclusion of the spatial Squeeze-and-Excitation (sSE) block is instrumental for spatial details, while the Swin Transformer structure is employed for capturing global long-context features. Moreover, to optimize the acquisition of these features, a connection is established in the middle layer of the DenseNet121 architecture, feeding both sSE and Swin Transformers. In the network architecture's output, three distinct feature groups are vectorized, combined, and processed to obtain the final feature map. Finally, a prediction is generated by applying the softmax classifier to this concluding feature map. Experimental evaluations conducted on three datasets (BUSI, GDPH, and SYSUCC) demonstrate the superior performance of SW-ForkNet, showcasing high accuracy (Acc) and F1-Scores (F1S) compared to existing methods and state-of-the-art models. Notable achievements include 93.12 % Acc and 92.27 % F1s for BUSI, 96.15 % Acc and 96.04 % F1S for GDPH, and 94.88 % Acc and 94.03 % F1S for SYSUCC. Consequently, the proposed SW-ForkNet model seems to present itself as a novel and effective structure in breast tumor classification. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - ÜZEN2024Swin
ER  -

TY  - JOUR
AU  - Yang, C.
AU  - Xiao, Y.
AU  - Chu, L.
AU  - Yu, Z.
AU  - Zhou, J.
AU  - Zheng, H.
TI  - Saliency and edge features-guided end-to-end network for salient object detection
PY  - 2024
T2  - Expert Systems with Applications
VL  - 257
C7  - 125016
DO  - 10.1016/j.eswa.2024.125016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201579165&doi=10.1016%2fj.eswa.2024.125016&partnerID=40&md5=e3eb61de4745ea54bfc66a472fe9dbb2
AB  - The rapid development of the Vision Transformer backbones has enabled the capture of feature information with global dependencies, leading to excellent performance in salient object detection tasks. However, it fails to adequately emphasize fine local features of edges, resulting in coarse and blurry edges in the final output. Therefore, this paper proposes a set prediction method for salient object detection. The approach enables the model to simultaneously consider both saliency (salient object) and edge features, achieving an end-to-end edge feature fusion. There is no need to design multiple complex branch structures and multiple training as with other methods. The model integrates random edge neighborhood sampling to enhance the recognition accuracy of local edge features in images. This approach addresses the weak perception of local features by Transformers and the issue encountered during actual training, where edge pixels typically occupy a much smaller proportion of the image compared to the background, resulting in insufficient learning of edge features by the model. The proposed end-to-end model in this paper fuses multiple features, including edge and salient objects. They are extracted within a unified framework while simultaneously outputting edge and salient object maps. Experimental results on six public datasets show that the proposed method significantly improves model performance benchmarks for detecting salient objects. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yang2024Saliency
ER  -

TY  - JOUR
AU  - Ji, X.
AU  - Chen, S.
AU  - Hao, L.-Y.
AU  - Zhou, J.
AU  - Chen, L.
TI  - FBDPN: CNN-Transformer hybrid feature boosting and differential pyramid network for underwater object detection
PY  - 2024
T2  - Expert Systems with Applications
VL  - 256
C7  - 124978
DO  - 10.1016/j.eswa.2024.124978
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200744334&doi=10.1016%2fj.eswa.2024.124978&partnerID=40&md5=084646df4898c4d0a30122953ce6acb5
AB  - Despite advancements in underwater object detection (UOD) from optical underwater images in recent years, the task still poses significant challenges due to the chaotic underwater environment, as well as the substantial variations in scale and contour of objects. Existing deep learning-based schemes generally overlook the enhancement and refinement between multi-scale features of densely distributed underwater objects, leading to inaccurate localization and classification predictions with excessive information redundancy. To tackle the above issues, this article presents a novel feature boosting and differential pyramid network (FBDPN) for precise and efficient UOD. The salient properties of our paper are: (1) a heuristic feature pyramid network (FPN)-inspired architecture is constructed, which employs a convolutional neural network (CNN)-Transformer hybrid strategy to simultaneously facilitate the learning of multi-scale features and the capture of long-distance dependencies among pixels. (2) A neighborhood-scale feature boosting module (NSFBM) is developed to enhance contextual information between features of neighborhood scales. (3) A cross-scale feature differential module (CSFDM) is designed further to achieve effective information redundancy between features of different scales. Extensive experiments are conducted to reveal that our proposed FBDPN can outperform other state-of-the-art methods in both UOD performance and computational complexity. In addition, sufficient ablation studies are also performed to demonstrate the effectiveness of each component in our FBDPN. The source code is available at https://github.com/jixun-dmu/FBDPN. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ji2024FBDPN
ER  -

TY  - JOUR
AU  - de Lima, T.B.
AU  - Rolim, V.
AU  - Nascimento, A.C.A.
AU  - Miranda, P.
AU  - Macario, V.
AU  - Rodrigues, L.
AU  - Freitas, E.
AU  - Gašević, D.
AU  - Mello, R.F.
TI  - Towards explainable automatic punctuation restoration for Portuguese using transformers
PY  - 2024
T2  - Expert Systems with Applications
VL  - 257
C7  - 125097
DO  - 10.1016/j.eswa.2024.125097
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201575990&doi=10.1016%2fj.eswa.2024.125097&partnerID=40&md5=6ca56f828b55b711c0aa830994a77834
AB  - Accurate punctuation in written text enables unambiguous communication, minimizing the risk of misunderstandings. Conversely, faulty punctuation can confuse the intended meaning, posing challenges for the author. The existing literature offers a collection of systems and algorithms to assist users in writing tasks. However, those focusing on English tend to exhibit higher accuracy. Furthermore, most models for punctuation restoration yield results without offering insight into their decision-making processes. Therefore, this study evaluated state-of-the-art punctuation restoration models specifically for Brazilian Portuguese and incorporated the principles of explainable artificial intelligence to clarify their predictions transparently. The findings indicate that the models assessed achieved an accuracy comparable to those of their English-language counterparts. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - de Lima2024Towards
ER  -

TY  - JOUR
AU  - Yue, J.
AU  - Bi, X.
AU  - Chen, Z.
TI  - Heterogeneous-branch integration framework: Introducing first-order predicate logic in Logical Reasoning Question Answering
PY  - 2024
T2  - Neurocomputing
VL  - 609
C7  - 128504
DO  - 10.1016/j.neucom.2024.128504
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202802917&doi=10.1016%2fj.neucom.2024.128504&partnerID=40&md5=3e195d15818fbc8237a3024430970528
AB  - The logical reasoning question-answering is a critical task in natural language processing, as it equips models with human-like logical reasoning intelligence. Existing approaches focus on extracting and leveraging the hidden logical structures within text. However, previous works explore partial logical relationships and neglect the holistic extraction within the text. Moreover, they struggle to fully model logical connections, including long-distance dependencies and local topology information. To address these issues, we propose a novel heterogeneous-branch integration framework. Our framework is based on first-order predicate logic theory and consists of three primary components. First, we construct two heterogeneous logical graphs to model logical relationships within and between propositions. Second, we propose a novel Graph-Masked Transformer with a novel graph-masked multi-head attention mechanism to enable distant node interactions and local sparse relationship modeling. Third, we propose a novel multi-branch fusion module to integrate information from multiple sources and generate answer predictions. The proposed heterogeneous-branch integration framework outperforms the VDGN method by 2.73% in accuracy on the ReClor dataset and 2.15% on the LogiQA dataset. Our code and models will be made available at https://github.com/starry-y/HBI. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yue2024Heterogeneous-branch
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Wei, J.
AU  - Tian, F.
AU  - Wei, Y.
TI  - A comparative study of machine learning models for sentiment analysis of transboundary rivers news media articles
PY  - 2024
T2  - Soft Computing
VL  - 28
IS  - 23
C7  - 106876
SP  - 13331
EP  - 13347
DO  - 10.1007/s00500-024-10357-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211587251&doi=10.1007%2fs00500-024-10357-2&partnerID=40&md5=b7837067212f6cd8db853a3e0a046d14
AB  - Sentiment analysis of news media articles is essential for understanding the dynamics of conflict and cooperation in transboundary rivers. However, it is not known which machine learning model(s) can best meet the requirement of sentiment analysis for transboundary rivers. This study presents a comparative examination of ten machine learning models commonly used in the field of text sentiment analysis, including K-Nearest Neighbors, Naive Bayes, Support Vector Machine, Decision Tree, Random Forest, Gradient Boosting Decision Tree, Extreme Gradient Boosting, Multilayer Perceptron, Long Short-Term Memory and Bidirectional Encoder Representations from Transformers, for five-class sentiment classification of 9382 news articles (1977–2022) attending to transboundary water conflict and cooperation. By evaluating their performance in terms of accuracy, precision, recall and F1-score, the Bidirectional Encoder Representations from Transformers (BERT) model demonstrated good overall performance and prediction capabilities for news articles with conflictive sentiments. By comparing with the AFINN sentiment dictionary, BERT showed superior performance in the prediction and identification of conflictive sentiment labels. And by validating against historical water events in the three river basins, BERT performed best in the Indus River basin. The findings of this study hold significant implications for government agencies in transboundary rivers, allowing them to promptly assess and respond to public sentiment, thereby preventing water conflict and promoting water cooperation. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024comparative
ER  -

TY  - JOUR
AU  - Fan, Y.
AU  - Waldmann, P.
TI  - Tabular deep learning: a comparative study applied to multi-task genome-wide prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 322
DO  - 10.1186/s12859-024-05940-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205826603&doi=10.1186%2fs12859-024-05940-1&partnerID=40&md5=be12933541479a9c6937567fcfb084b6
AB  - Purpose: More accurate prediction of phenotype traits can increase the success of genomic selection in both plant and animal breeding studies and provide more reliable disease risk prediction in humans. Traditional approaches typically use regression models based on linear assumptions between the genetic markers and the traits of interest. Non-linear models have been considered as an alternative tool for modeling genomic interactions (i.e. non-additive effects) and other subtle non-linear patterns between markers and phenotype. Deep learning has become a state-of-the-art non-linear prediction method for sound, image and language data. However, genomic data is better represented in a tabular format. The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports successful results on various datasets. Tabular deep learning applications in genome-wide prediction (GWP) are still rare. In this work, we perform an overview of the main families of recent deep learning architectures for tabular data and apply them to multi-trait regression and multi-class classification for GWP on real gene datasets. Methods: The study involves an extensive overview of recent deep learning architectures for tabular data learning: NODE, TabNet, TabR, TabTransformer, FT-Transformer, AutoInt, GANDALF, SAINT and LassoNet. These architectures are applied to multi-trait GWP. Comprehensive benchmarks of various tabular deep learning methods are conducted to identify best practices and determine their effectiveness compared to traditional methods. Results: Extensive experimental results on several genomic datasets (three for multi-trait regression and two for multi-class classification) highlight LassoNet as a standout performer, surpassing both other tabular deep learning models and the highly efficient tree based LightGBM method in terms of both best prediction accuracy and computing efficiency. Conclusion: Through series of evaluations on real-world genomic datasets, the study identifies LassoNet as a standout performer, surpassing decision tree methods like LightGBM and other tabular deep learning architectures in terms of both predictive accuracy and computing efficiency. Moreover, the inherent variable selection property of LassoNet provides a systematic way to find important genetic markers that contribute to phenotype expression. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Fan2024Tabular
ER  -

TY  - JOUR
AU  - Chen, K.
AU  - Liu, Y.
AU  - Ji, T.
AU  - Yang, G.
AU  - Chen, Y.
AU  - Yang, C.
AU  - Zheng, Y.
TI  - TEST-Net: transformer-enhanced Spatio-temporal network for infectious disease prediction
PY  - 2024
T2  - Multimedia Systems
VL  - 30
IS  - 6
C7  - 312
DO  - 10.1007/s00530-024-01494-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206069662&doi=10.1007%2fs00530-024-01494-7&partnerID=40&md5=5197a6b3d251c49f2f82893e448fc453
AB  - Outbreaks of infectious diseases have caused tremendous human suffering and incalculable economic losses, and infectious diseases are a global public health problem that threatens human society. Therefore, it is necessary to model the spatial and temporal distribution characteristics of infectious diseases, explore the transmission trend of infectious diseases, establish an infection early warning model and take corresponding preventive and control measures, which can make the prevention and control work more targeted and forward-looking. Given the complex spatial correlation and temporal variation of infectious diseases, deep learning-based Spatio-temporal sequence prediction is widely employed because of its superior performance in capturing Spatio-temporal features. However, current deep learning-based infectious disease prediction methods utilize an encoder-decoder structure that provides barely satisfactory accuracy due to a lack of understanding of infectious disease prevalence factors or deficiencies in capturing representative Spatio-temporal patterns. In this paper, we develop the Transformer-Enhanced Spatio-temporal Network (TEST-Net) which consists of a temporal location coding module and a Spatio-temporal feature fusion module for Infectious disease prediction. Temporal information is input in TEST-Net by Temporal Location Encoding (TLE), and temporal and spatial correlation of sequences is extracted by a transformer-based attention network, and temporal features are fused with spatial features by a Spatio-temporal feature fusion network. Compared with other state-of-the-art methods, qualitative and quantitative results show that TSET-Net has an excellent performance in modeling the spatial and temporal distribution characteristics of data and performs well in the accuracy of long-term prediction of infectious disease. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chen2024TEST-Net
ER  -

TY  - JOUR
AU  - Baek, B.
AU  - Lee, H.
TI  - Crossfeat: a transformer-based cross-feature learning model for predicting drug side effect frequency
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 324
DO  - 10.1186/s12859-024-05915-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205976245&doi=10.1186%2fs12859-024-05915-2&partnerID=40&md5=ffd008f0a10ad3731fdfe2ffee34971e
AB  - Background: Safe drug treatment requires an understanding of the potential side effects. Identifying the frequency of drug side effects can reduce the risks associated with drug use. However, existing computational methods for predicting drug side effect frequencies heavily depend on known drug side effect frequency information. Consequently, these methods face challenges when predicting the side effect frequencies of new drugs. Although a few methods can predict the side effect frequencies of new drugs, they exhibit unreliable performance owing to the exclusion of drug-side effect relationships. Results: This study proposed CrossFeat, a model based on convolutional neural network-transformer architecture with cross-feature learning that can predict the occurrence and frequency of drug side effects for new drugs, even in the absence of information regarding drug-side effect relationships. CrossFeat facilitates the concurrent learning of drugs and side effect information within its transformer architecture. This simultaneous exchange of information enables drugs to learn about their associated side effects, while side effects concurrently acquire information about the respective drugs. Such bidirectional learning allows for the comprehensive integration of drug and side effect knowledge. Our five-fold cross-validation experiments demonstrated that CrossFeat outperforms existing studies in predicting side effect frequencies for new drugs without prior knowledge. Conclusions: Our model offers a promising approach for predicting the drug side effect frequencies, particularly for new drugs where prior information is limited. CrossFeat’s superior performance in cross-validation experiments, along with evidence from case studies and ablation experiments, highlights its effectiveness. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Baek2024Crossfeat
ER  -

TY  - JOUR
AU  - Chang, X.
AU  - Xu, X.
AU  - Qiu, B.
AU  - Wei, M.
AU  - Yan, X.
AU  - Liu, J.
TI  - Predicting steady degradation in ship power system: A deep learning approach based on comprehensive monitoring parameters
PY  - 2024
T2  - IET Intelligent Transport Systems
VL  - 18
IS  - 12
SP  - 2375
EP  - 2396
DO  - 10.1049/itr2.12575
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205872409&doi=10.1049%2fitr2.12575&partnerID=40&md5=a53c956088846a1e73cb6d67f6bdb28f
AB  - Steady degradation (SD) prediction is crucial for the intelligent operation and maintenance of ship power system (SPS). Addressing the challenge of predicting the SD process, this study introduces the YC2Model, a system-level predictive method that integrates encoding time slice data to images (ETSD2I) with a convolutional neural network and Transformer. Incorporating the Transformer, in particular, enables the YC2Model to predict the SD state of SPS over extended periods more effectively. Compared to baseline models, YC2Model demonstrates superior performance on key performance indicators, including the highest coefficient of determination ((Formula presented.)) of 0.960717, and the lowest symmetric mean absolute percentage error of 0.015500, mean square error of 0.707211 × 10−4, root mean square error of 0.008410, and mean absolute error of 0.006519, proving its superior predictive accuracy. The correlation between model performance variations and degradation mechanisms is validated through statistical analysis of the YC2Model's performance in different stages of the SD process. During the SD process, YC2Model exhibits high predictive accuracy, an ability to capture changes in degradation mechanisms and robust adaptability to degradation trends. This model can provide precise and reliable SD state predictions for the intelligent operation and maintenance of SPS. © 2024 The Author(s). IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Chang2024Predicting
ER  -

TY  - JOUR
AU  - Su, Y.
AU  - Zhang, J.
AU  - Li, Q.
TI  - SCSformer: cross-variable transformer framework for multivariate long-term time series forecasting via statistical characteristics space
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 24
SP  - 12922
EP  - 12948
DO  - 10.1007/s10489-024-05764-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206358367&doi=10.1007%2fs10489-024-05764-9&partnerID=40&md5=b479084a48af640c2ad784e38c965263
AB  - Deep learning-based models have emerged as promising tools for multivariate long-term time series forecasting. These models are finely structured to perform feature extraction from time series, greatly improving the accuracy of multivariate long-term time series forecasting. However, to the best of our knowledge, few scholars have focused their research on preprocessing time series, such as analyzing their periodic distributions or analyzing their values and volatility at the global level. In fact, properly preprocessing time series can often significantly improve the accuracy of multivariate long-term time series forecasting. In this paper, using the cross-variable transformer as a basis, we introduce a statistical characteristics space fusion module to preprocess the time series, this module takes the mean and standard deviation values of the time series during different periods as part of the model’s inputs and greatly improves the model’s performance. The Statistical Characteristics Space Fusion Module consists of a statistical characteristics space, which represents the mean and standard deviation values of a time series under different periods, and a convolutional neural network, which is used to fuse the original time series with the corresponding mean and standard deviation values. Moreover, to extract the linear dependencies of the time series variables more efficiently, we introduce three different linear projection layers at different nodes of the model, which we call the Multi-level Linear Projection Module. This new methodology, called the SCSformer, includes three innovations. First, we propose a Statistical Characteristics Space Fusion Module, which is capable of calculating the statistical characteristics space of the time series and fusing the original time series with a specific element of the statistical characteristics space as inputs of the model. Second, we introduce a Multi-level Linear Projection Module to capture linear dependencies of time series from different stages of the model. Third, we combine the Statistical Characteristics Space Fusion Module, the Multi-level Linear Projection Module, the Reversible Instance Normalization and the Cross-variable Transformer proposed in Client in a certain order to generate the SCSformer. We test this combination on nine real-world time series datasets and achieve optimal results on eight of them. Our code is publicly available at https://github.com/qiuyueli123/SCSformer. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Su2024SCSformer
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Wang, S.
AU  - Fu, X.
TI  - Long short-term temporal fusion transformer for short-term forecasting of limit order book in China markets
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 24
SP  - 12979
EP  - 13000
DO  - 10.1007/s10489-024-05789-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207311914&doi=10.1007%2fs10489-024-05789-0&partnerID=40&md5=27dc61c9a3ec2da8889ea4afc6ac99b6
AB  - Short-term forecasting of the Limit Order Book (LOB) is challenging due to market noise. Traditionally, technical analysis using candlestick charts has been effective for market analysis and predictions. Inspired by this, we introduce a novel methodology. First, we preprocess the LOB data into long-term frame data resembling candlestick patterns to reduce noise interference. We then present the Long Short-Term Temporal Fusion Transformer (LSTFT), skillfully integrating both short-term and long-term information to capture complex dependencies and enhance prediction accuracy. Additionally, we propose a Temporal Attention Mechanism (TAM) that effectively distinguishes between long-term and short-term temporal relationships in LOB data. Our experimental results demonstrate the effectiveness of our approach in accurately forecasting the Limit Order Book in the short term. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2024Long
ER  -

TY  - JOUR
AU  - Hao, Z.
AU  - Shao, J.
AU  - Gong, B.
AU  - Yang, J.
AU  - Jing, L.
AU  - Chen, Y.
TI  - Cycle association prototype network for few-shot semantic segmentation
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 138
C7  - 109309
DO  - 10.1016/j.engappai.2024.109309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203870803&doi=10.1016%2fj.engappai.2024.109309&partnerID=40&md5=4c93beb3dc38f134888cbbf0716b6fc6
AB  - Few-shot segmentation aims to train a segmentation model that can quickly adapt to novel classes referring to only a few annotated samples. Existing few-shot segmentation methods are based on the meta-learning strategy and extract support samples’ information from a support set and then apply the information to make predictions on query images. However, most methods abstract support features into prototype vectors and ignore the crucial relationship between query and support samples. To address the problem, we propose a cycle association prototype network that focuses on pixel-wise relationships between support and query images for more accurate segmentation. Specifically, a cycle-consistent prototype module is proposed to select reliable support features and to generate prototype. To capture cross-scale relations and overcome object variations, we introduce a scale-aware prior mask generation module to offer rich guidance for objects of varying sizes and shapes via calculating the pixel-level similarity between the support and query image features. Finally, a mask generation module, which contains two parallel modules, feature fusion module and transformer decoder, is utilized to predict the query image. Extensive experiments on two datasets show that our method yields superior performance with state-of-the-art methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hao2024Cycle
ER  -

TY  - JOUR
AU  - Cheng, Z.
AU  - Zhang, Y.
AU  - Yu, Y.
AU  - Song, Z.
AU  - Tang, C.
TI  - TinyDepth: Lightweight self-supervised monocular depth estimation based on transformer
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 138
C7  - 109313
DO  - 10.1016/j.engappai.2024.109313
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203868219&doi=10.1016%2fj.engappai.2024.109313&partnerID=40&md5=406b46567b2a1a77b901fa7833de84d8
AB  - Monocular depth estimation plays an important role in autonomous driving, virtual reality, augmented reality, and other fields. Self-supervised monocular depth estimation has received much attention because it does not require hard-to-obtain depth labels during training. The previously used convolutional neural network (CNN) has shown limitations in modeling large-scale spatial dependencies. A new idea for monocular depth estimation is replacing the CNN architecture or merging it with a Vision Transformer (ViT) architecture that can model large-scale spatial dependencies in images. However, there are still problems with too many parameters and calculations, making deployment difficult on mobile platforms. In response to these problems, we propose TinyDepth, a lightweight self-supervised monocular depth estimation method based on Transformer that employs hierarchical representation learning suitable for dense prediction, uses mobile convolution to reduce parameters and computational overhead. and includes a novel decoder based on multi-scale fusion attention that improves the local and global inference capability of the network through scale-wise attention processing and layer-wise fusion sampling for more accurate depth prediction. In experiments, TinyDepth achieved state-of-the-art results with few parameters on the Karlsruhe Institute of Technology and Toyota Technological Institute at Chicago (KITTI) dataset, and exhibited good generalization ability on the challenging indoor New York University (NYU) dataset. Source code is available at https://github.com/ZYCheng777/TinyDepth. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cheng2024TinyDepth
ER  -

TY  - JOUR
AU  - Xia, B.
AU  - Yang, Z.
AU  - Xie, M.
AU  - Chang, Y.
AU  - Yuan, B.
AU  - Li, Z.
AU  - Wang, X.
AU  - Liang, B.
TI  - Solving time-delay issues in reinforcement learning via transformers
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 23
SP  - 12156
EP  - 12176
DO  - 10.1007/s10489-024-05830-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203425212&doi=10.1007%2fs10489-024-05830-2&partnerID=40&md5=4fe56a4b22ba72cc27566b6ef35451b3
AB  - The presence of observation and action delays in remote control scenarios significantly challenges the decision-making of agents that depend on immediate interactions, particularly within traditional deep reinforcement learning (DRL) algorithms. Existing approaches attempt to tackle this problem through various strategies, such as predicting delayed states, transforming delayed Markov Decision Processes (MDPs) into delay-free equivalents. However, both model-free and model-based methods require extensive online data, making them time-consuming and resource-intensive. To effectively handle time-delay challenges and develop a competent and robust RL algorithm, the Augmented Decision Transformer (ADT) is proposed as the first offline RL algorithm designed to enable agents to manage diverse tasks with various constant delays. It transforms a deterministic delayed MDP (DDMDP) into a standard MDP by simulating trajectories in delayed environments using offline dataset from undelayed environments. The Decision Transformer, an autoregressive model, is then employed to train a decision model based on expected rewards, past state sequences and past action sequences. Extensive experiments conducted on MuJoCo and Adroit tasks validate the robustness and efficiency of the ADT, with its average performance across all tasks being 56% better than the worst-performing comparative algorithms. The results demonstrate that the ADT can outperform state-of-the-art RL counterparts, achieving superior performance across various tasks with different delay conditions. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xia2024Solving
ER  -

TY  - JOUR
AU  - Yue, B.
AU  - Qiu, S.
AU  - Yang, C.
AU  - Peng, L.
AU  - Zhang, Y.
TI  - Transformer-empowered receiver design of OFDM communication systems
PY  - 2024
T2  - Computer Communications
VL  - 228
C7  - 107960
DO  - 10.1016/j.comcom.2024.107960
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204942626&doi=10.1016%2fj.comcom.2024.107960&partnerID=40&md5=c5331e3d0b2894564ddad10961c4465d
AB  - With deep learning, we perform channel estimation and signal detection in massive Multiple Input Multiple Output (MIMO)-Orthogonal Frequency Division Multiplexing (OFDM) systems in this paper. Specifically, we design and extend the basic framework of receivers for MIMO-OFDM systems in an end-to-end approach. A Transformer-based MIMO-OFDM receiver called TCD-Receiver is proposed, which introduces a multi-attention mechanism to learn the channel characteristics by introducing a generic and flexible Transformer network structure. The network parameters are updated based on the relationship between the received signal and the original signal, where the final signal information is obtained without explicit channel estimation and the predicted transmit bits are directly output. The experimental results show that the TCD-Receiver proposed can effectively solve the channel distortion and detect the transmitted signals compared with the traditional communication receivers, and its performance can be comparable to that of the traditional OFDM receivers, and it also has obvious advantages in combating the complex and difficult-to-model channel environment as well as the nonlinear interference factors. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yue2024Transformer-empowered
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Wang, D.
AU  - Wang, W.
AU  - Wang, J.
AU  - Fang, J.
TI  - Correlation mining of multimodal features based on higher-order partial least squares for emotion recognition in conversations
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 138
C7  - 109350
DO  - 10.1016/j.engappai.2024.109350
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204176665&doi=10.1016%2fj.engappai.2024.109350&partnerID=40&md5=805eb24451c339955417f350c202a16c
AB  - In fields requiring an understanding of emotions, such as digital human interaction and public opinion analysis, achieving a dependable and interpretable model for mining correlations among multimodal features remains a primary objective. However, current deep learning methods often lack transparency and suffer from low interpretability. To address these challenges, we propose a novel Correlation Mining method based on Higher-Order Partial Least Squares (HOPLS) for multimodal Emotion Recognition in conversations (CMHER) in this paper. CMHER innovatively combines HOPLS with transformers and Gated Recurrent Units (GRUs) to compute correlation matrices within unimodal data streams and between cross-modal sources. HOPLS projects source data into a latent space to predict target data via correlation matrix computations, eliminating the need for Graphical Processing Unit (GPU) acceleration and making it suitable for experimental and edge systems. The integration of HOPLS with deep neural networks involves preprocessing multimodal features into suitable dimensions and latent representations, followed by HOPLS computing correlation matrices for cross-modal latent vectors and final labels through optimal joint subspace approximation, which aims at the improvements of both interpretability and reliability. Additionally, a generalization error fitting module further refines the predicted correlation matrices to improve predictive capability and overall model performance. Experiments on two public datasets validate the superiority of our proposed method. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Correlation
ER  -

TY  - JOUR
AU  - Sanabria, M.
AU  - Hirsch, J.
AU  - Poetsch, A.R.
TI  - Distinguishing word identity and sequence context in DNA language models
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 301
DO  - 10.1186/s12859-024-05869-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203874823&doi=10.1186%2fs12859-024-05869-5&partnerID=40&md5=cfa985529d638985a6de5d96a7bbfe03
AB  - Transformer-based large language models (LLMs) are very suited for biological sequence data, because of analogies to natural language. Complex relationships can be learned, because a concept of "words" can be generated through tokenization. Training the models with masked token prediction, they learn both token sequence identity and larger sequence context. We developed methodology to interrogate model learning, which is both relevant for the interpretability of the model and to evaluate its potential for specific tasks. We used DNABERT, a DNA language model trained on the human genome with overlapping k-mers as tokens. To gain insight into the model′s learning, we interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps. This task evaluates foundation models without interrogating specific genome biology, it does not depend on tokenization strategies, vocabulary size, the dictionary, or the number of training parameters. Lastly, there is no leakage of information from token identity into the prediction task, which makes it particularly useful to evaluate the learning of sequence context. We discovered that the model with overlapping k-mers struggles to learn larger sequence context. Instead, the learned embeddings largely represent token sequence. Still, good performance is achieved for genome-biology-inspired fine-tuning tasks. Models with overlapping tokens may be used for tasks where a larger sequence context is of less relevance, but the token sequence directly represents the desired learning features. This emphasizes the need to interrogate knowledge representation in biological LLMs. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Sanabria2024Distinguishing
ER  -

TY  - JOUR
AU  - Fontana Crespo, R.N.
AU  - Aliberti, A.
AU  - Bottaccioli, L.
AU  - Pasta, E.
AU  - Sirigu, S.A.
AU  - Macii, E.
AU  - Mattiazzo, G.
AU  - Patti, E.
TI  - A comparative analysis of Machine Learning Techniques for short-term grid power forecasting and uncertainty analysis of Wave Energy Converters
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 138
C7  - 109352
DO  - 10.1016/j.engappai.2024.109352
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204777658&doi=10.1016%2fj.engappai.2024.109352&partnerID=40&md5=d0236b9e444f33a240339c3f44c9f13a
AB  - Wave Energy is one of the renewable sources with greatest potential. Since power coming from waves fluctuates, the grid integration of wave energy involves several power conditioning stages to comply with grid quality requirements. However, to ensure full integration of wave energy in a smart grid scenario and unlock advanced monitoring and control techniques (e.g. Demand/Response), it is crucial to forecast the output power. This work proposes a methodology to forecast in short-term horizons (i.e. 15 min to 240 min) the power delivered to the grid of the Inertial Sea Wave Energy Converter (ISWEC), a device that harnesses wave power through the inertial effect of a gyroscope. Therefore, we designed, optimized and compared the performance of five known machine learning techniques for time series point forecasting: Random Forest, Support Vector Regression, Long Short-Term Memory Neural Network, Transformer Neural Network and 1 Dimensional Convolutional Neural Network. Additionally, we studied the efficacy of downsampling technique aggregating original dataset sampled every 0.1 s in time steps of 1min, 3min, 5min and 15min to compare the performance behaviour of the different machine learning models for these datasets. Furthermore, we implemented Prediction Intervals (PIs) to calculate the inherent uncertainties associated with the previously mentioned machine learning techniques. These PIs were built based on the Non-Parametric Kernel Density Estimator technique. The point forecasting and the PIs results showed that models’ performance improved as the downsampling increased. Moreover, the Random Forest model was the worst-performing in all cases. Finally, none of the other models can be considered the best overall. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Fontana Crespo2024comparative
ER  -

TY  - JOUR
AU  - Oliver, M.
AU  - Allou, N.
AU  - Devineau, M.
AU  - Allyn, J.
AU  - Ferdynus, C.
TI  - A transformer model for cause-specific hazard prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 175
DO  - 10.1186/s12859-024-05799-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192108759&doi=10.1186%2fs12859-024-05799-2&partnerID=40&md5=4a3ed79c22d5ee633504b325e549c5ef
AB  - Backgroud: Modelling discrete-time cause-specific hazards in the presence of competing events and non-proportional hazards is a challenging task in many domains. Survival analysis in longitudinal cohorts often requires such models; notably when the data is gathered at discrete points in time and the predicted events display complex dynamics. Current models often rely on strong assumptions of proportional hazards, that is rarely verified in practice; or do not handle sequential data in a meaningful way. This study proposes a Transformer architecture for the prediction of cause-specific hazards in discrete-time competing risks. Contrary to Multilayer perceptrons that were already used for this task (DeepHit), the Transformer architecture is especially suited for handling complex relationships in sequential data, having displayed state-of-the-art performance in numerous tasks with few underlying assumptions on the task at hand. Results: Using synthetic datasets of 2000–50,000 patients, we showed that our Transformer model surpassed the CoxPH, PyDTS, and DeepHit models for the prediction of cause-specific hazard, especially when the proportional assumption did not hold. The error along simulated time outlined the ability of our model to anticipate the evolution of cause-specific hazards at later time steps where few events are observed. It was also superior to current models for prediction of dementia and other psychiatric conditions in the English longitudinal study of ageing cohort using the integrated brier score and the time-dependent concordance index. We also displayed the explainability of our model’s prediction using the integrated gradients method. Conclusions: Our model provided state-of-the-art prediction of cause-specific hazards, without adopting prior parametric assumptions on the hazard rates. It outperformed other models in non-proportional hazards settings for both the synthetic dataset and the longitudinal cohort study. We also observed that basic models such as CoxPH were more suited to extremely simple settings than deep learning models. Our model is therefore especially suited for survival analysis on longitudinal cohorts with complex dynamics of the covariate-to-outcome relationship, which are common in clinical practice. The integrated gradients provided the importance scores of input variables, which indicated variables guiding the model in its prediction. This model is ready to be utilized for time-to-event prediction in longitudinal cohorts. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Oliver2024transformer
ER  -

TY  - JOUR
AU  - Schneider, D.
AU  - Lindner, K.
AU  - Vogelbacher, M.
AU  - Bellafkir, H.
AU  - Farwig, N.
AU  - Freisleben, B.
TI  - Recognition of European mammals and birds in camera trap images using deep neural networks
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 8
SP  - 1162
EP  - 1192
DO  - 10.1049/cvi2.12294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197437545&doi=10.1049%2fcvi2.12294&partnerID=40&md5=011ad0cfd230b4aa2d76c5e2d3a9ac40
AB  - Most machine learning methods for animal recognition in camera trap images are limited to mammal identification and group birds into a single class. Machine learning methods for visually discriminating birds, in turn, cannot discriminate between mammals and are not designed for camera trap images. The authors present deep neural network models to recognise both mammals and bird species in camera trap images. They train neural network models for species classification as well as for predicting the animal taxonomy, that is, genus, family, order, group, and class names. Different neural network architectures, including ResNet, EfficientNetV2, Vision Transformer, Swin Transformer, and ConvNeXt, are compared for these tasks. Furthermore, the authors investigate approaches to overcome various challenges associated with camera trap image analysis. The authors’ best species classification models achieve a mean average precision (mAP) of 97.91% on a validation data set and mAPs of 90.39% and 82.77% on test data sets recorded in forests in Germany and Poland, respectively. Their best taxonomic classification models reach a validation mAP of 97.18% and mAPs of 94.23% and 79.92% on the two test data sets, respectively. © 2024 The Author(s). IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Schneider2024Recognition
ER  -

TY  - JOUR
AU  - Aksamit, N.
AU  - Tchagang, A.
AU  - Li, Y.
AU  - Ombuki-Berman, B.
TI  - Hybrid fragment-SMILES tokenization for ADMET prediction in drug discovery
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 255
DO  - 10.1186/s12859-024-05861-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200259886&doi=10.1186%2fs12859-024-05861-z&partnerID=40&md5=ad9adcb793a7491349c1c631efbe5484
AB  - Background: Drug discovery and development is the extremely costly and time-consuming process of identifying new molecules that can interact with a biomarker target to interrupt the disease pathway of interest. In addition to binding the target, a drug candidate needs to satisfy multiple properties affecting absorption, distribution, metabolism, excretion, and toxicity (ADMET). Artificial intelligence approaches provide an opportunity to improve each step of the drug discovery and development process, in which the first question faced by us is how a molecule can be informatively represented such that the in-silico solutions are optimized. Results: This study introduces a novel hybrid SMILES-fragment tokenization method, coupled with two pre-training strategies, utilizing a Transformer-based model. We investigate the efficacy of hybrid tokenization in improving the performance of ADMET prediction tasks. Our approach leverages MTL-BERT, an encoder-only Transformer model that achieves state-of-the-art ADMET predictions, and contrasts the standard SMILES tokenization with our hybrid method across a spectrum of fragment library cutoffs. Conclusion: The findings reveal that while an excess of fragments can impede performance, using hybrid tokenization with high frequency fragments enhances results beyond the base SMILES tokenization. This advancement underscores the potential of integrating fragment- and character-level molecular features within the training of Transformer models for ADMET property prediction. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Aksamit2024Hybrid
ER  -

TY  - JOUR
AU  - Song, Y.
AU  - Xu, H.
AU  - Li, C.
AU  - He, Q.
AU  - Tian, Z.
AU  - Liu, X.
TI  - HMT: Hybrid mechanistic Transformer for bio-fabrication prediction under complex environmental conditions
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124389
DO  - 10.1016/j.eswa.2024.124389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196402110&doi=10.1016%2fj.eswa.2024.124389&partnerID=40&md5=f84aa1d61e7b5c4c3a782726c029ceb8
AB  - In the field of bio-manufacturing, hybrid models that combine mechanistic models with data-driven models have not been widely adopted. This is primarily due to the complexity of the manufacturing process itself and the limited quality of available bio-manufacturing data. To address these limitations, this study introduces a novel hybrid model that combines a mechanistic-feature network with a Transformer-based data-driven model (HMT), effectively overcoming these challenges. The HMT integrates mechanistic and data-driven modeling to accurately predict target variables in bio-manufacturing processes. Initially, the HMT utilizes a mechanistic model to explore the feature relationships of the target sequence variables. It then compresses temporal domain variables into a univariate time series and applies spatial fusion weights for spatial domain variables, achieving variable fusion independently in each domain. Subsequently, a Transformer-based data-driven model is employed to model and predict the fused target variables, utilizing attention mechanisms to capture feature relationships within and between sequences. Upon comparison with various data-driven models, particularly those in the bio-manufacturing sector that employ artificial neural network approaches, the hybrid model demonstrates superior performance in mean squared error, mean absolute error, mean absolute percentage error, robustness, and Theil's U statistic. The state-of-the-art performance of the HMT in long sequence prediction and short sequence prediction confirms its feasibility and potential for industrial applications.1 © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Song2024HMT
ER  -

TY  - JOUR
AU  - Jin, H.-J.
AU  - Zhao, Y.-P.
AU  - Pan, M.-N.
TI  - A novel method for aero-engine time-series forecasting based on multi-resolution transformer
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124597
DO  - 10.1016/j.eswa.2024.124597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197090974&doi=10.1016%2fj.eswa.2024.124597&partnerID=40&md5=25f3f7c4586e8fb03eaa03c542e23299
AB  - Time-series forecasting is widely studied in the data-driven component-level modeling, fault diagnosis, and performance prediction of aero-engines. The operational data of aero-engines have the characteristics of complexity and nonlinearity. This paper proposes a multi-resolution transformer (MRT) model for the non-steady state process of aero-engines. This transformer-based model can learn temporal patterns of different scales by performing multi-resolution down-sampling and patch-based tokeniczation on the input time-series. On this basis, a two-stage multi-resolution transformer (TSMRT) framework is proposed for the entire processes time-series modeling of aero-engines. The TSMRT framework employs Augmented Dickey-Fuller (ADF) test to classify aero-engine operational data into steady state processes and non-steady state processes, and models the two processes separately using time–frequency feature neural network (TFNN) model and MRT model. The time-series forecasting performance of the MRT model is validated on three publicly available benchmark datasets and an ablation study is conducted on turbofan engine test bench datasets. The results indicate that the TSMRT framework demonstrates superior forecasting performance across steady state, non-steady state, and entire processes. This framework stands out as a novel method for component-level modeling of aero-engines. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Jin2024novel
ER  -

TY  - JOUR
AU  - Zheng, Y.
AU  - Zhou, X.
TI  - Modeling multi-factor user preferences based on Transformer for next point of interest recommendation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124894
DO  - 10.1016/j.eswa.2024.124894
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199872104&doi=10.1016%2fj.eswa.2024.124894&partnerID=40&md5=2628fdb5d30f4cb5e2f2485d28e5da31
AB  - With the rapid development of the mobile network and the gradual popularization of mobile devices, more and more users try to find attractive places to visit through WeChat, Twitter applications. In this trend, personalized next point of interest(POI) recommendation in the Location-based Social Network (LBSN) has become the focus of research and practice. Most existing studies capture user interest changes between different days (i.e. weekend and weekday), however, they ignore seasonal factors in time transition and category factors and thus fail to capture seasonal-level and category-level movement patterns in users’ mobile trajectories. Besides, they neglect the relevance between POIs from all users’ trajectory and fail to generate expressive POI embedding representation without constructing trajectory graph, which will reduce the accuracy of the next POI recommendation. To address the issues above, a next POI recommendation method for modeling Multi-factor User Preferences based on Transformer (MUPT) is developed, which consists of a global POI relationship modeling, a local multi-factor user preference modeling and a prediction module. It first learns the collaborative information of users with similar behavior to generate expressive POI embedding representation. Then it captures the personalized movement patterns of users at the POI, category and time levels based on Transformer mechanism in the local module. Especially the seasonal and other fine-grained information on the time series are learned in the time preference modeling part. The prediction module designed tracks the relationship between multi-level motion pattern representation of user check-in behavior and the next POI accessed by the user, and it finally obtains user's preference probability for next POIs. An extensive experiment has been conducted on four datasets, and the experimental results analysis demonstrates that our proposed MUPT method is superior to other methods in terms of accuracy(ACC), mean reciprocal rank(MRR) and normalized discounted cumulative gain(NDCG). © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zheng2024Modeling
ER  -

TY  - JOUR
AU  - Zhu, Z.
AU  - Zheng, X.
AU  - Qi, G.
AU  - Gong, Y.
AU  - Li, Y.
AU  - Mazur, N.
AU  - Cong, B.
AU  - Gao, X.
TI  - Drug–target binding affinity prediction model based on multi-scale diffusion and interactive learning
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124647
DO  - 10.1016/j.eswa.2024.124647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197520182&doi=10.1016%2fj.eswa.2024.124647&partnerID=40&md5=682a711bdc286203cd8e71ff9758df8d
AB  - Drug–target interactions (DTIs) play a key role in drug discovery and development as they are critical in understanding the complex mechanisms of underlying drugs and their corresponding targets. Unfortunately, some studies do not fully recognize the significant contribution of graph structure to drug feature extraction, thereby neglecting the extraction of local and global structures inherent in molecular graphs. Furthermore, most existing drug–target binding affinity (DTA) prediction models ignore or simplify complex interaction mechanisms, thus compromising the predictive power of the models. Therefore, this paper proposes a novel DTA prediction model utilizing multi-scale diffusion and interactive learning (MDCT-DTA). To address the limitations of current methods, the multi-scale graph diffusion convolution (MGDC) module is introduced, which can effectively capture the complex interactions between drug molecular graph nodes. Furthermore, a CNN-Transformer Network (CTN) block is proposed to capture the interactions and interdependencies between different amino acids, thereby enhancing the representation and learning capabilities of the model. In addition, a local inter-layer information interaction structure is designed to specifically explore the relationship between drug features and protein features, so as to improve the representativeness and robustness of the model's structural features. The performance of the proposed model was evaluated using four publicly available benchmark datasets, Davis, KIBA, BindingDB, and Metz. The experimental results confirm that the proposed model can more accurately predict the binding affinity between a drug and its targets. They also provide a new perspective for the prediction task of DTA and contribute to the overall development and improvement of DTA prediction models. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhu2024Drug–target
ER  -

TY  - JOUR
AU  - Aksamit, N.
AU  - Hou, J.
AU  - Li, Y.
AU  - Ombuki-Berman, B.
TI  - Integrating transformers and many-objective optimization for drug design
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 208
DO  - 10.1186/s12859-024-05822-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195533391&doi=10.1186%2fs12859-024-05822-6&partnerID=40&md5=9005e1932ef780845a40d82b750e2949
AB  - Background: Drug design is a challenging and important task that requires the generation of novel and effective molecules that can bind to specific protein targets. Artificial intelligence algorithms have recently showed promising potential to expedite the drug design process. However, existing methods adopt multi-objective approaches which limits the number of objectives. Results: In this paper, we expand this thread of research from the many-objective perspective, by proposing a novel framework that integrates a latent Transformer-based model for molecular generation, with a drug design system that incorporates absorption, distribution, metabolism, excretion, and toxicity prediction, molecular docking, and many-objective metaheuristics. We compared the performance of two latent Transformer models (ReLSO and FragNet) on a molecular generation task and show that ReLSO outperforms FragNet in terms of reconstruction and latent space organization. We then explored six different many-objective metaheuristics based on evolutionary algorithms and particle swarm optimization on a drug design task involving potential drug candidates to human lysophosphatidic acid receptor 1, a cancer-related protein target. Conclusion: We show that multi-objective evolutionary algorithm based on dominance and decomposition performs the best in terms of finding molecules that satisfy many objectives, such as high binding affinity and low toxicity, and high drug-likeness. Our framework demonstrates the potential of combining Transformers and many-objective computational intelligence for drug design. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Aksamit2024Integrating
ER  -

TY  - JOUR
AU  - Han, Y.
AU  - Han, L.
AU  - Shi, X.
AU  - Li, J.
AU  - Huang, X.
AU  - Hu, X.
AU  - Chu, C.
AU  - Geng, Z.
TI  - Novel CNN-based transformer integrating Boruta algorithm for production prediction modeling and energy saving of industrial processes
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124447
DO  - 10.1016/j.eswa.2024.124447
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197076549&doi=10.1016%2fj.eswa.2024.124447&partnerID=40&md5=4aa951f14a6bd1cbb16afc5acc54abea
AB  - Industrial process data collected by sensors have characteristics of high dimensionality, non-linearity and dynamics. Consequently, the selection extraction is regarded as a critical part for reducing the dimension of the data and removing irrelevant variables of constructing the production prediction model of industrial processes. Therefore, a novel production prediction model using the Boruta algorithm integrating the convolutional neural network-based Transformer (BCT) is proposed in this paper. Primarily, the Boruta algorithm maps nonlinear high-dimensional data to a low-dimensional space to select features that are meaningful to the yield of the industrial process. Then, the features are extracted adaptively using a convolutional neural network (CNN), which is encoded based on the transformer layer to learn relevant information about the different representation spaces. Furthermore, a linear layer with highway connections is employed to obtain prediction results. Finally, the BCT method is applied to establish a realistic production prediction model of actual liquefied petroleum gas plants for energy saving. Compared with back propagation neural networks, the radial basis function, the extreme learning machine, and the transformer based on the CNN, the BCT method achieves a state-of-the-art level. Furthermore, the BCT method provides the operation guidance on the actual liquefied petroleum gas (LPG) production process with increasing the LPG yield by 17.21%, which can improve production efficiency and reducing energy consumption. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Han2024Novel
ER  -

TY  - JOUR
AU  - Jia, B.
AU  - Wu, H.
AU  - Guo, K.
TI  - Chaos theory meets deep learning: A new approach to time series forecasting
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124533
DO  - 10.1016/j.eswa.2024.124533
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197342566&doi=10.1016%2fj.eswa.2024.124533&partnerID=40&md5=ddd55a70f0249e7c25cf11deeb0dcc6c
AB  - We explore the influence and advantages of integrating chaotic systems with deep learning for time series forecasting in this paper. It proposes a novel deep learning method based on the Chen system, which leverages the randomness, sensitivity, and diversity of chaotic mapping to enhance the performance and efficiency of deep learning models. We introduce a deep learning framework that integrates chaotic systems, providing an innovative and effective approach for time series forecasting. The research utilizes three different types of deep learning models as baselines—Long Short-Term Memory, Neural Basis Expansion Analysis, and Transformer—and compares them with their chaotic counterparts to demonstrate the impact of chaotic systems on various deep learning architectures. Experimental validation is conducted on thirteen available time series datasets, assessing the models’ forecasting accuracy, runtime, and resource occupancy. The effectiveness and superiority of the chaotic deep learning method are verified across diverse datasets, including stock markets, electricity, and air quality, showcasing significant improvements over traditional model initialization methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Jia2024Chaos
ER  -

TY  - JOUR
AU  - Elhassan, M.A.M.
AU  - Zhou, C.
AU  - Benabid, A.
AU  - Adam, A.B.M.
TI  - P2AT: Pyramid pooling axial transformer for real-time semantic segmentation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124610
DO  - 10.1016/j.eswa.2024.124610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197499954&doi=10.1016%2fj.eswa.2024.124610&partnerID=40&md5=3086e13b290949c6c21f47bca3dba3d5
AB  - Recently, Transformer-based models have achieved promising results in various vision tasks, due to their ability to model long-range dependencies. However, transformers are computationally expensive, which limits their applications in real-time tasks such as autonomous driving. In addition, efficient local and global feature selection and fusion are vital for accurate dense prediction, especially driving scene understanding tasks. In this paper, we propose a real-time semantic segmentation architecture named Pyramid Pooling Axial Transformer (P2AT). The proposed P2AT takes a coarse feature from the CNN encoder to produce scale-aware contextual features, which are then combined with the multi-level feature aggregation scheme to produce enhanced contextual features. Specifically, we introduce a pyramid pooling axial transformer to capture intricate spatial and channel dependencies, leading to improved performance on semantic segmentation. Then, we design a Bidirectional Fusion module (BiF) to combine semantic information at different levels. Meanwhile, a Global Context Enhancer (GCE) is introduced to compensate for the inadequacy of concatenating different semantic levels. Finally, a decoder block is proposed to help maintain a larger receptive field. We evaluate P2AT variants on three challenging scene-understanding datasets. In particular, our P2AT variants achieve state-of-art results on the Camvid dataset 80.5%, 81.0%, 81.1% for P2AT-S, P2AT-M, and P2AT-L, respectively. Furthermore, our experiments on Cityscapes and Pascal VOC 2012 have demonstrated the efficiency of the proposed architecture. The source code will be available at https://github.com/mohamedac29/P2AT. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Elhassan2024P2AT
ER  -

TY  - JOUR
AU  - Wei, Z.
AU  - Zhao, C.
AU  - Zhang, M.
AU  - Xu, J.
AU  - Xu, N.
AU  - Wu, S.
AU  - Xin, X.
AU  - Yu, L.
AU  - Feng, W.
TI  - PrCRS: a prediction model of severe CRS in CAR-T therapy based on transfer learning
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 197
DO  - 10.1186/s12859-024-05804-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193804776&doi=10.1186%2fs12859-024-05804-8&partnerID=40&md5=629afbd214c9cf23d7e7abec7eb5780f
AB  - Background: CAR-T cell therapy represents a novel approach for the treatment of hematologic malignancies and solid tumors. However, its implementation is accompanied by the emergence of potentially life-threatening adverse events known as cytokine release syndrome (CRS). Given the escalating number of patients undergoing CAR-T therapy, there is an urgent need to develop predictive models for severe CRS occurrence to prevent it in advance. Currently, all existing models are based on decision trees whose accuracy is far from meeting our expectations, and there is a lack of deep learning models to predict the occurrence of severe CRS more accurately. Results: We propose PrCRS, a deep learning prediction model based on U-net and Transformer. Given the limited data available for CAR-T patients, we employ transfer learning using data from COVID-19 patients. The comprehensive evaluation demonstrates the superiority of the PrCRS model over other state-of-the-art methods for predicting CRS occurrence. We propose six models to forecast the probability of severe CRS for patients with one, two, and three days in advance. Additionally, we present a strategy to convert the model's output into actual probabilities of severe CRS and provide corresponding predictions. Conclusions: Based on our findings, PrCRS effectively predicts both the likelihood and timing of severe CRS in patients, thereby facilitating expedited and precise patient assessment, thus making a significant contribution to medical research. There is little research on applying deep learning algorithms to predict CRS, and our study fills this gap. This makes our research more novel and significant. Our code is publicly available at https://github.com/wzy38828201/PrCRS. The website of our prediction platform is: http://prediction.unicar-therapy.com/index-en.html. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Wei2024PrCRS
ER  -

TY  - JOUR
AU  - Ji, T.
AU  - Zhao, C.
AU  - Ji, Y.
AU  - Du, Y.
TI  - A two-stage framework for parking search behavior prediction through adversarial inverse reinforcement learning and transformer
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124548
DO  - 10.1016/j.eswa.2024.124548
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197018776&doi=10.1016%2fj.eswa.2024.124548&partnerID=40&md5=551a20906102c3fe223475796b711bc2
AB  - Parking scenarios are spatially dense and have a lot of interactions, making predicting vehicles’ search behavior crucial and challenging for autonomous driving. Existing data-driven prediction methods struggle to determine vehicles’ intents and consider the surrounding environment accurately. This study proposes a novel two-stage framework for parking search behavior prediction, involving parking intent and vehicle trajectory predictions based on imitation learning and deep learning. First, we develop an adversarial inverse reinforcement learning model for parking search intent (PSI-AIRL) learning from measured trajectory data in an actual parking lot. Then, we design an integrated convolutional neural network (CNN) and transformer model to forecast vehicle trajectory using historical observations and the predicted parking search intents. This two-stage framework achieves parking search intent prediction by applying global information about the parking lot while improving vehicle trajectory prediction's accuracy and robustness. Finally, the experiments are conducted on the Dragon Lake Parking (DLP) dataset to compare our framework with state-of-the-art models. The results show that our model outperforms other baseline models in accuracy for parking intent and vehicle trajectory predictions. Moreover, our model shows exceptional accuracy and robustness in predicting across diverse parking scenarios. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ji2024two-stage
ER  -

TY  - JOUR
AU  - Ramos-Acosta, E.R.
AU  - García-Guerrero, E.E.
AU  - López-Bonilla, O.R.
AU  - Tamayo-Pérez, U.J.
AU  - Aguirre-Castro, O.A.
AU  - Ramírez-Rios, L.Y.
AU  - Inzunza-Gonzalez, E.
TI  - A novel system for the classification of zinc-plated components by benchmarking deep neural networks
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124866
DO  - 10.1016/j.eswa.2024.124866
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199776802&doi=10.1016%2fj.eswa.2024.124866&partnerID=40&md5=b6c33e4fa21b31f910c359f8f55a02b4
AB  - Artificial intelligence (AI) has become the new technique for solving the most complicated challenges related to big data, image recognition, object detection, and prediction issues due to the fourth industrial revolution. This article introduces the development and implementation of a zinc-plated component recognition system within a manufacturing process using deep learning (DL) techniques. This paper aims to train and evaluate different DL algorithms to recognize five zinc-plated components and one assembly tray under different ambient light conditions and finishing. The proposed method begins with creating a custom dataset of 5.5K images, with six classes that match the assembly components. However, before the training stage starts, a subset between 5% and 10% is created. Eight deep neural networks have been benchmarked: Swing Transformer, Convnextv2, Xception41, Data-efficient image Transformer, Inception_v4, ViT, Resnet50 and Efficientnet_b0. The training stage is performed with the k-fold method using k = 6 and a progressive data size between different runs with an average of data utilized during training of 8%. In this study, convnextv2_tiny exhibits the highest F1-Score with 99.177%, followed by swin_tiny_patch4_window7_224 with 99.175%, while resnet50 achieved the lowest F1-Score at 95.886%. Therefore, the new generation of convolutional architectures is still better for classifying images. Thus, these algorithms can be adopted as good classifier models for zinc-plated component classification in the industrial manufacturing environment. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ramos-Acosta2024novel
ER  -

TY  - JOUR
AU  - Sadeghi, S.
AU  - Bui, A.
AU  - Forooghi, A.
AU  - Lu, J.
AU  - Ngom, A.
TI  - Can large language models understand molecules?
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 225
DO  - 10.1186/s12859-024-05847-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197180887&doi=10.1186%2fs12859-024-05847-x&partnerID=40&md5=d6306148d578fe6bcc56789b6d82f49c
AB  - Purpose: Large Language Models (LLMs) like Generative Pre-trained Transformer (GPT) from OpenAI and LLaMA (Large Language Model Meta AI) from Meta AI are increasingly recognized for their potential in the field of cheminformatics, particularly in understanding Simplified Molecular Input Line Entry System (SMILES), a standard method for representing chemical structures. These LLMs also have the ability to decode SMILES strings into vector representations. Method: We investigate the performance of GPT and LLaMA compared to pre-trained models on SMILES in embedding SMILES strings on downstream tasks, focusing on two key applications: molecular property prediction and drug-drug interaction prediction. Results: We find that SMILES embeddings generated using LLaMA outperform those from GPT in both molecular property and DDI prediction tasks. Notably, LLaMA-based SMILES embeddings show results comparable to pre-trained models on SMILES in molecular prediction tasks and outperform the pre-trained models for the DDI prediction tasks. Conclusion: The performance of LLMs in generating SMILES embeddings shows great potential for further investigation of these models for molecular embedding. We hope our study bridges the gap between LLMs and molecular embedding, motivating additional research into the potential of LLMs in the molecular representation field. GitHub: https://github.com/sshaghayeghs/LLaMA-VS-GPT. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Sadeghi2024Can
ER  -

TY  - JOUR
AU  - Ahmed, F.S.
AU  - Aly, S.
AU  - Liu, X.
TI  - EPI-Trans: an effective transformer-based deep learning model for enhancer promoter interaction prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 216
DO  - 10.1186/s12859-024-05784-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196151842&doi=10.1186%2fs12859-024-05784-9&partnerID=40&md5=ccaed3fd449a58cc80705d8015b3d775
AB  - Background: Recognition of enhancer–promoter Interactions (EPIs) is crucial for human development. EPIs in the genome play a key role in regulating transcription. However, experimental approaches for classifying EPIs are too expensive in terms of effort, time, and resources. Therefore, more and more studies are being done on developing computational techniques, particularly using deep learning and other machine learning techniques, to address such problems. Unfortunately, the majority of current computational methods are based on convolutional neural networks, recurrent neural networks, or a combination of them, which don’t take into consideration contextual details and the long-range interactions between the enhancer and promoter sequences. A new transformer-based model called EPI-Trans is presented in this study to overcome the aforementioned limitations. The multi-head attention mechanism in the transformer model automatically learns features that represent the long interrelationships between enhancer and promoter sequences. Furthermore, a generic model is created with transferability that can be utilized as a pre-trained model for various cell lines. Moreover, the parameters of the generic model are fine-tuned using a particular cell line dataset to improve performance. Results: Based on the results obtained from six benchmark cell lines, the average AUROC for the specific, generic, and best models is 94.2%, 95%, and 95.7%, while the average AUPR is 80.5%, 66.1%, and 79.6% respectively. Conclusions: This study proposed a transformer-based deep learning model for EPI prediction. The comparative results on certain cell lines show that EPI-Trans outperforms other cutting-edge techniques and can provide superior performance on the challenge of recognizing EPI. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Ahmed2024EPI-Trans
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Ma, X.
AU  - Deng, S.
AU  - Suo, Y.
AU  - Zhang, J.
AU  - Ng, W.W.Y.
TI  - Lightweight multimodal Cycle-Attention Transformer towards cancer diagnosis
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124616
DO  - 10.1016/j.eswa.2024.124616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198002492&doi=10.1016%2fj.eswa.2024.124616&partnerID=40&md5=d75d2011d05b4d05392e8cdc537e9da7
AB  - Cancer diagnosis, prognosis and therapeutic response predictions are based on data extracted from various modalities, such as histology slides, cell graphs and molecular profiles from genomic data. In recent years, with the increasing availability of multimodal biomedical data, an increasing number of multimodal fusion strategies have been proposed to overcome the challenge of data heterogeneity and make full use of intersections and complementarities of different data sources. However, most of them have the problem of parameter redundancy and inefficiency in the process of fusion. Therefore, in this work, we present a Cycle-Attention Transformer (Cy-Atten) framework that learns a more robust joint representation for multimodal cancer survival analysis. The Cy-Atten adopts a cycling mechanism with sparse attention and yields a theoretical cost of O(N) for adding a modality, which is proven to effectively reduce the parameter redundancy. Empirically in the experiments on two cancer datasets from the TCGA database, the parameters in our fusion part are only of the order of 103 considering three modalities. In addition to being lightweight, the Cy-Atten outperforms several state-of-the-art multimodal fusion methods in survival analysis and grade classification of two cancers from the TCGA database. Our work can be reproduced at https://github.com/dlmscl/Cycle-Attention-Transformer. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2024Lightweight
ER  -

TY  - JOUR
AU  - Hao, A.
AU  - Yuan, H.
AU  - Hui, S.C.
AU  - Su, J.
TI  - Effective type label-based synergistic representation learning for biomedical event trigger detection
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 251
DO  - 10.1186/s12859-024-05851-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200257970&doi=10.1186%2fs12859-024-05851-1&partnerID=40&md5=20766319435bede235f3460eb86748ff
AB  - Background: Detecting event triggers in biomedical texts, which contain domain knowledge and context-dependent terms, is more challenging than in general-domain texts. Most state-of-the-art models rely mainly on external resources such as linguistic tools and knowledge bases to improve system performance. However, they lack effective mechanisms to obtain semantic clues from label specification and sentence context. Given its success in image classification, label representation learning is a promising approach to enhancing biomedical event trigger detection models by leveraging the rich semantics of pre-defined event type labels. Results: In this paper, we propose the Biomedical Label-based Synergistic representation Learning (BioLSL) model, which effectively utilizes event type labels by learning their correlation with trigger words and enriches the representation contextually. The BioLSL model consists of three modules. Firstly, the Domain-specific Joint Encoding module employs a transformer-based, domain-specific pre-trained architecture to jointly encode input sentences and pre-defined event type labels. Secondly, the Label-based Synergistic Representation Learning module learns the semantic relationships between input texts and event type labels, and generates a Label-Trigger Aware Representation (LTAR) and a Label-Context Aware Representation (LCAR) for enhanced semantic representations. Finally, the Trigger Classification module makes structured predictions, where each label is predicted with respect to its neighbours. We conduct experiments on three benchmark BioNLP datasets, namely MLEE, GE09, and GE11, to evaluate our proposed BioLSL model. Results show that BioLSL has achieved state-of-the-art performance, outperforming the baseline models. Conclusions: The proposed BioLSL model demonstrates good performance for biomedical event trigger detection without using any external resources. This suggests that label representation learning and context-aware enhancement are promising directions for improving the task. The key enhancement is that BioLSL effectively learns to construct semantic linkages between the event mentions and type labels, which provide the latent information of label-trigger and label-context relationships in biomedical texts. Moreover, additional experiments on BioLSL show that it performs exceptionally well with limited training data under the data-scarce scenarios. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Hao2024Effective
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Ignacio, M.J.
AU  - Yu, S.
AU  - Jin, H.
AU  - Kim, Y.-G.
TI  - UET4Rec: U-net encapsulated transformer for sequential recommender
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124781
DO  - 10.1016/j.eswa.2024.124781
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198999455&doi=10.1016%2fj.eswa.2024.124781&partnerID=40&md5=23193e663407d733d9887ba68b1d967d
AB  - Recommending a tempting sequence of items according to a user's previous history of purchases and clicks, for instance, in the online shopping portals is challenging. And yet it is a crucial task for all service providers. One of the core components in the recommender systems is a sequential model with which an input sequence is transformed into the predicted items. Among many, deep neural networks, such as RNN, LSTM, and Transformer, have been favored for this purpose. However, improving the performance of these models remains an important task. To address this, we propose a novel sequential model by combining a U-net and Transformer, called U-net Encapsulated Transformer. This hybrid architecture places a transformer model between a convolutional encoder and its decoder, wherein each convolutional layer processes 1D signal, i.e. text. The primary benefit of this structure is that the computational burden is reduced since the embedding size of the input to the Transformer is drastically decreased as the signal has to go through the multi-layer convolutional encoder. This solution leverages recommendation lists for action predictions and uses user feedback as direct rewards for updating the model. In addition, the loss function mechanism is improved by including contrastive and reinforcement learning losses. Evaluation of the proposed model, including extensive ablation study, is carried out on four standard benchmark datasets, such as RC15, RetailRocket, MovieLens-1M, and Amazon-Beauty, demonstrating superior performance compared to state-of-the-art methods. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wang2024UET4Rec
ER  -

TY  - JOUR
AU  - Feng, B.-M.
AU  - Zhang, Y.-Y.
AU  - Niu, N.-W.-J.
AU  - Zheng, H.-Y.
AU  - Wang, J.-L.
AU  - Feng, W.-F.
TI  - DeFuseDTI: Interpretable drug target interaction prediction model with dual-branch encoder and multiview fusion
PY  - 2024
T2  - Future Generation Computer Systems
VL  - 161
SP  - 239
EP  - 247
DO  - 10.1016/j.future.2024.07.014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198967123&doi=10.1016%2fj.future.2024.07.014&partnerID=40&md5=88ecb1521db2f839dd922358712f25cf
AB  - Predicting the interaction between drugs and targets is a crucial step in drug development, and computer-based deep learning approaches have the potential to significantly reduce costs. Existing models using a single encoder often suffer from insufficient cross-modal feature extraction, with most models tending to overly focus on extracting locally aggregated information, thereby diluting the detailed features of each target residue and drug atom. Additionally, the lack of effective interaction fusion between drug and target lead to prediction results lacking reliable interpretability, posing a more urgent issue. To address these challenges, we propose a dual-branch encoder model, DeFuseDTI, which includes base encoder and detail encoder to extract locally aggregated features and detailed features of each target residue and drug atom. The detail encoder (utilizing Invertible Neural Networks for targets and graph transformers for drugs) can capture furtherly the features of each atom and residue, providing rich and precise features for model interpretability. For better achieve interactive learning of drug and target features, the Multiview Fusion Attention learning module was introduced to integrate multiview features and generate a unified representations for decoding prediction results. Based on the module's unique attention mechanism, drug-target importance matrices can be obtained, which offer interpretable analysis at the molecular level. Experimental results and analyses demonstrate that DeFuseDTI outperforms several state-of-the-art models on four public datasets. Its significant interpretability holds promise for providing accurate and scientifically meaningful guidance for biochemical experiments at the molecular level. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Feng2024DeFuseDTI
ER  -

TY  - JOUR
AU  - Wu, M.
AU  - Zhang, D.
AU  - Hua, Y.
AU  - Si, M.
AU  - Liu, P.
AU  - Wang, Q.
TI  - TransFusion: Efficient Vision Transformer based on 3D transesophageal echocardiography images for the left atrial appendage segmentation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 255
C7  - 124727
DO  - 10.1016/j.eswa.2024.124727
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199041010&doi=10.1016%2fj.eswa.2024.124727&partnerID=40&md5=fd2e23ec89d5c0576e1824ab377279b8
AB  - 3D transesophageal echocardiography (TEE) is widely used in the preoperative guidance of left atrial appendage closure (LAAC), and is the preferred imaging examination recommended by expert consensus. The precise extraction of the left atrial appendage (LAA) is the essential initial step for establishing an automated predictive procedure of the LAAC. However, due to the inherent limitations of the ultrasound images and the unique morphological features of the LAA, segmenting the LAA in TEE images is a challenging task. In this paper, we propose a novel Transformer-based dual feature fusion network (TransFusion) for LAA segmentation in TEE images. Our TransFusion includes both intra-stage and inter-stage multi-scale feature fusions. Specifically, in each stage of the encoder, we introduce a Multi-Scale Vision Transformer (MSViT) block for extracting and enhancing multi-scale feature representations. Additionally, we use a Feature Fusion module (FFM) to fuse the features across different stages in parallel and alleviate the semantic gap and better recovering the spatial details. Finally, the convolutional neural network (CNN) as the decoder is used to output the results of LAA segmentation. We compare our method with several state-of-the-art methods on our private clinical dataset. Experimental results demonstrate the superior robustness and segmentation performance of our method and its capability to accurately extract the LAA. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wu2024TransFusion
ER  -

TY  - JOUR
AU  - He, S.
AU  - Yun, L.
AU  - Yi, H.
TI  - Fusing graph transformer with multi-aggregate GCN for enhanced drug–disease associations prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 79
DO  - 10.1186/s12859-024-05705-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185447456&doi=10.1186%2fs12859-024-05705-w&partnerID=40&md5=b33e2a40b658508475ee4b368363ecfd
AB  - Background: Identification of potential drug–disease associations is important for both the discovery of new indications for drugs and for the reduction of unknown adverse drug reactions. Exploring the potential links between drugs and diseases is crucial for advancing biomedical research and improving healthcare. While advanced computational techniques play a vital role in revealing the connections between drugs and diseases, current research still faces challenges in the process of mining potential relationships between drugs and diseases using heterogeneous network data. Results: In this study, we propose a learning framework for fusing Graph Transformer Networks and multi-aggregate graph convolutional network to learn efficient heterogenous information graph representations for drug–disease association prediction, termed WMAGT. This method extensively harnesses the capabilities of a robust graph transformer, effectively modeling the local and global interactions of nodes by integrating a graph convolutional network and a graph transformer with self-attention mechanisms in its encoder. We first integrate drug–drug, drug–disease, and disease–disease networks to construct heterogeneous information graph. Multi-aggregate graph convolutional network and graph transformer are then used in conjunction with neural collaborative filtering module to integrate information from different domains into highly effective feature representation. Conclusions: Rigorous cross-validation, ablation studies examined the robustness and effectiveness of the proposed method. Experimental results demonstrate that WMAGT outperforms other state-of-the-art methods in accurate drug–disease association prediction, which is beneficial for drug repositioning and drug safety research. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - He2024Fusing
ER  -

TY  - JOUR
AU  - Sargsyan, K.
AU  - Lim, C.
TI  - Using protein language models for protein interaction hot spot prediction with limited data
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 115
DO  - 10.1186/s12859-024-05737-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187917332&doi=10.1186%2fs12859-024-05737-2&partnerID=40&md5=47f855b48d4a2ff4411636e6c8b8c5b9
AB  - Background: Protein language models, inspired by the success of large language models in deciphering human language, have emerged as powerful tools for unraveling the intricate code of life inscribed within protein sequences. They have gained significant attention for their promising applications across various areas, including the sequence-based prediction of secondary and tertiary protein structure, the discovery of new functional protein sequences/folds, and the assessment of mutational impact on protein fitness. However, their utility in learning to predict protein residue properties based on scant datasets, such as protein–protein interaction (PPI)-hotspots whose mutations significantly impair PPIs, remained unclear. Here, we explore the feasibility of using protein language-learned representations as features for machine learning to predict PPI-hotspots using a dataset containing 414 experimentally confirmed PPI-hotspots and 504 PPI-nonhot spots. Results: Our findings showcase the capacity of unsupervised learning with protein language models in capturing critical functional attributes of protein residues derived from the evolutionary information encoded within amino acid sequences. We show that methods relying on protein language models can compete with methods employing sequence and structure-based features to predict PPI-hotspots from the free protein structure. We observed an optimal number of features for model precision, suggesting a balance between information and overfitting. Conclusions: This study underscores the potential of transformer-based protein language models to extract critical knowledge from sparse datasets, exemplified here by the challenging realm of predicting PPI-hotspots. These models offer a cost-effective and time-efficient alternative to traditional experimental methods for predicting certain residue properties. However, the challenge of explaining why specific features are important for determining certain residue properties remains. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Sargsyan2024Using
ER  -

TY  - JOUR
AU  - Zeng, X.
AU  - Chen, W.
AU  - Lei, B.
TI  - CAT-DTI: cross-attention and Transformer network with domain adaptation for drug-target interaction prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 141
DO  - 10.1186/s12859-024-05753-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189203029&doi=10.1186%2fs12859-024-05753-2&partnerID=40&md5=6fa839cabc9870933ca5805b7ef66862
AB  - Accurate and efficient prediction of drug-target interaction (DTI) is critical to advance drug development and reduce the cost of drug discovery. Recently, the employment of deep learning methods has enhanced DTI prediction precision and efficacy, but it still encounters several challenges. The first challenge lies in the efficient learning of drug and protein feature representations alongside their interaction features to enhance DTI prediction. Another important challenge is to improve the generalization capability of the DTI model within real-world scenarios. To address these challenges, we propose CAT-DTI, a model based on cross-attention and Transformer, possessing domain adaptation capability. CAT-DTI effectively captures the drug-target interactions while adapting to out-of-distribution data. Specifically, we use a convolution neural network combined with a Transformer to encode the distance relationship between amino acids within protein sequences and employ a cross-attention module to capture the drug-target interaction features. Generalization to new DTI prediction scenarios is achieved by leveraging a conditional domain adversarial network, aligning DTI representations under diverse distributions. Experimental results within in-domain and cross-domain scenarios demonstrate that CAT-DTI model overall improves DTI prediction performance compared with previous methods. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zeng2024CAT-DTI
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Huang, T.
AU  - Wang, D.
AU  - Zeng, W.
AU  - Sun, Y.
AU  - Zhang, L.
TI  - MSCAN: multi-scale self- and cross-attention network for RNA methylation site prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 32
DO  - 10.1186/s12859-024-05649-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182390871&doi=10.1186%2fs12859-024-05649-1&partnerID=40&md5=5749da43ff4c226ff91617a9f16a7e87
AB  - Background: Epi-transcriptome regulation through post-transcriptional RNA modifications is essential for all RNA types. Precise recognition of RNA modifications is critical for understanding their functions and regulatory mechanisms. However, wet experimental methods are often costly and time-consuming, limiting their wide range of applications. Therefore, recent research has focused on developing computational methods, particularly deep learning (DL). Bidirectional long short-term memory (BiLSTM), convolutional neural network (CNN), and the transformer have demonstrated achievements in modification site prediction. However, BiLSTM cannot achieve parallel computation, leading to a long training time, CNN cannot learn the dependencies of the long distance of the sequence, and the Transformer lacks information interaction with sequences at different scales. This insight underscores the necessity for continued research and development in natural language processing (NLP) and DL to devise an enhanced prediction framework that can effectively address the challenges presented. Results: This study presents a multi-scale self- and cross-attention network (MSCAN) to identify the RNA methylation site using an NLP and DL way. Experiment results on twelve RNA modification sites (m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um) reveal that the area under the receiver operating characteristic of MSCAN obtains respectively 98.34%, 85.41%, 97.29%, 96.74%, 99.04%, 79.94%, 76.22%, 65.69%, 92.92%, 92.03%, 95.77%, 89.66%, which is better than the state-of-the-art prediction model. This indicates that the model has strong generalization capabilities. Furthermore, MSCAN reveals a strong association among different types of RNA modifications from an experimental perspective. A user-friendly web server for predicting twelve widely occurring human RNA modification sites (m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um) is available at http://47.242.23.141/MSCAN/index.php . Conclusions: A predictor framework has been developed through binary classification to predict RNA methylation sites. © 2024, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Wang2024MSCAN
ER  -

TY  - JOUR
AU  - Ren, Z.
AU  - Yu, J.
AU  - Huang, J.
AU  - Yang, X.
AU  - Leng, S.
AU  - Liu, Y.
AU  - Yan, S.
TI  - Physically-guided temporal diffusion transformer for long-term time series forecasting
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 304
C7  - 112508
DO  - 10.1016/j.knosys.2024.112508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203638408&doi=10.1016%2fj.knosys.2024.112508&partnerID=40&md5=ea7bca33f1a32df46af5bd7a227ebcb2
AB  - Transformer has shown excellent performance in long-term time series forecasting because of its capability to capture long-term dependencies. However, existing Transformer-based approaches often overlook the unique characteristics inherent to time series, particularly multi-scale periodicity, which leads to a gap in inductive biases. To address this oversight, the temporal diffusion Transformer (TDT) was developed in this study to reveal the intrinsic evolution processes of time series. First, to uncover the connections among the periods of multi-periodic time series, the series are transformed into various types of patches using a multi-scale Patch method. Inspired by the principles of heat conduction, TDT conceptualizes the evolution of a time series as a diffusion process. TDT aims to achieve global consistency by minimizing energy constraints, which is accomplished through the iterative updating of patches. Finally, the results of these iterations across multiple periods are aggregated to form the TDT output. Compared to previous advanced models, TDT achieved state-of-the-art predictive performance in our experiments. In most datasets, TDT outperformed the baseline model by approximately 2% in terms of mean square error (MSE) and mean absolute error (MAE). Its effectiveness was further validated through ablation, efficiency, and hyperparameter analyses. TDT offers intuitive explanations by elucidating the diffusion process of time series patches throughout the iterative procedure. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Ren2024Physically-guided
ER  -

TY  - JOUR
AU  - Iliadis, D.
AU  - De Baets, B.
AU  - Pahikkala, T.
AU  - Waegeman, W.
TI  - A comparison of embedding aggregation strategies in drug–target interaction prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 59
DO  - 10.1186/s12859-024-05684-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184544856&doi=10.1186%2fs12859-024-05684-y&partnerID=40&md5=3f0080924dbc10fa403111f5e9c411c5
AB  - The prediction of interactions between novel drugs and biological targets is a vital step in the early stage of the drug discovery pipeline. Many deep learning approaches have been proposed over the last decade, with a substantial fraction of them sharing the same underlying two-branch architecture. Their distinction is limited to the use of different types of feature representations and branches (multi-layer perceptrons, convolutional neural networks, graph neural networks and transformers). In contrast, the strategy used to combine the outputs (embeddings) of the branches has remained mostly the same. The same general architecture has also been used extensively in the area of recommender systems, where the choice of an aggregation strategy is still an open question. In this work, we investigate the effectiveness of three different embedding aggregation strategies in the area of drug–target interaction (DTI) prediction. We formally define these strategies and prove their universal approximator capabilities. We then present experiments that compare the different strategies on benchmark datasets from the area of DTI prediction, showcasing conditions under which specific strategies could be the obvious choice. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Iliadis2024comparison
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Wang, Y.
AU  - Xu, C.
AU  - Wang, X.
AU  - Zhang, Y.
TI  - Computer vision-driven forest wildfire and smoke recognition via IoT drone cameras
PY  - 2024
T2  - Wireless Networks
VL  - 30
IS  - 9
SP  - 7603
EP  - 7616
DO  - 10.1007/s11276-024-03718-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189959912&doi=10.1007%2fs11276-024-03718-0&partnerID=40&md5=3d251d7be6c2bfd9ce0789241bf0a19b
AB  - Forest wildfires often lead to significant casualties and economic losses, making early detection crucial for prevention and control. Internet of Things connected cameras mounted on drone provide wide monitoring coverage and flexibility, while computer vision technology enhances the accuracy and response time of forest wildfire monitoring. However, the small-scale nature of early wildfire targets and the complexity of the forest environment pose significant challenges to accurately and promptly identify fires. To address challenges such as high false-positive rates and inefficiency in existing methods, we propose a Forest Wildfire and Smoke Recognition Network termed FWSRNet. Firstly, we adopt Vision Transformer, which has shown superior performance in recent traditional classification tasks, as the backbone network. Secondly, to enhance the extraction of subtle differential features, we introduce a self-attention mechanism to guide the network in selecting discriminative image patches and calculating their relationships. Next, we employ a contrastive feature learning strategy to eliminate redundant information, making the model more discriminative. Finally, we construct a target loss function for model prediction. Under various proportions of training and testing dataset allocations, the model exhibits recognition accuracies of 94.82, 95.05, 94.90, and 94.80% for forest fires. The average accuracy of 94.89% surpasses five comparative models, demonstrating the potential of this method in IoT-enhanced aerial forest fire recognition. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Wang2024Computer
ER  -

TY  - JOUR
AU  - Min, X.
AU  - Yang, C.
AU  - Xie, J.
AU  - Huang, Y.
AU  - Liu, N.
AU  - Jin, X.
AU  - Wang, T.
AU  - Kong, Z.
AU  - Lu, X.
AU  - Ge, S.
AU  - Zhang, J.
AU  - Xia, N.
TI  - Tpgen: a language model for stable protein design with a specific topology structure
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 35
DO  - 10.1186/s12859-024-05637-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182823512&doi=10.1186%2fs12859-024-05637-5&partnerID=40&md5=ea54f28fac4b12048e87c96109ac0ac8
AB  - Background: Natural proteins occupy a small portion of the protein sequence space, whereas artificial proteins can explore a wider range of possibilities within the sequence space. However, specific requirements may not be met when generating sequences blindly. Research indicates that small proteins have notable advantages, including high stability, accurate resolution prediction, and facile specificity modification. Results: This study involves the construction of a neural network model named TopoProGenerator(TPGen) using a transformer decoder. The model is trained with sequences consisting of a maximum of 65 amino acids. The training process of TopoProGenerator incorporates reinforcement learning and adversarial learning, for fine-tuning. Additionally, it encompasses a stability predictive model trained with a dataset comprising over 200,000 sequences. The results demonstrate that TopoProGenerator is capable of designing stable small protein sequences with specified topology structures. Conclusion: TPGen has the ability to generate protein sequences that fold into the specified topology, and the pretraining and fine-tuning methods proposed in this study can serve as a framework for designing various types of proteins. © 2024, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Min2024Tpgen
ER  -

TY  - JOUR
AU  - Lao, C.
AU  - Zheng, P.
AU  - Chen, H.
AU  - Liu, Q.
AU  - An, F.
AU  - Li, Z.
TI  - DeepAEG: a model for predicting cancer drug response based on data enhancement and edge-collaborative update strategies
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 105
DO  - 10.1186/s12859-024-05723-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187130252&doi=10.1186%2fs12859-024-05723-8&partnerID=40&md5=d752736d2439433a62f9499e3fd7d976
AB  - Motivation: The prediction of cancer drug response is a challenging subject in modern personalized cancer therapy due to the uncertainty of drug efficacy and the heterogeneity of patients. It has been shown that the characteristics of the drug itself and the genomic characteristics of the patient can greatly influence the results of cancer drug response. Therefore, accurate, efficient, and comprehensive methods for drug feature extraction and genomics integration are crucial to improve the prediction accuracy. Results: Accurate prediction of cancer drug response is vital for guiding the design of anticancer drugs. In this study, we propose an end-to-end deep learning model named DeepAEG which is based on a complete-graph update mode to predict IC50. Specifically, we integrate an edge update mechanism on the basis of a hybrid graph convolutional network to comprehensively learn the potential high-dimensional representation of topological structures in drugs, including atomic characteristics and chemical bond information. Additionally, we present a novel approach for enhancing simplified molecular input line entry specification data by employing sequence recombination to eliminate the defect of single sequence representation of drug molecules. Our extensive experiments show that DeepAEG outperforms other existing methods across multiple evaluation parameters in multiple test sets. Furthermore, we identify several potential anticancer agents, including bortezomib, which has proven to be an effective clinical treatment option. Our results highlight the potential value of DeepAEG in guiding the design of specific cancer treatment regimens. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Lao2024DeepAEG
ER  -

TY  - JOUR
AU  - Liang, D.
AU  - Zhang, H.
AU  - Yuan, D.
AU  - Zhang, M.
TI  - Periodformer: An efficient long-term time series forecasting method based on periodic attention
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 304
C7  - 112556
DO  - 10.1016/j.knosys.2024.112556
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204888105&doi=10.1016%2fj.knosys.2024.112556&partnerID=40&md5=0606e50a28c74080c9db37e76cd6dbb8
AB  - As Transformer-based models have achieved impressive performance across various time series tasks, Long-Term Series Forecasting (LTSF) has garnered extensive attention in recent years. The intricate complexity of the Attention mechanism leads to pronounced overfitting of time series data, thereby impeding the efficient and accurate forecasting of long-term sequences. To better cope with this, we design a lightweight Period-Attention mechanism (Periodformer), which renovates the aggregation of long-term subseries via explicit periodicity and short-term subseries via built-in proximity. Meanwhile, a gating mechanism is embedded into Periodformer to regulate the influence of the attention module on the prediction results. This gives Periodformer a much more powerful and flexible sequence modeling capability with linear computational complexity, guaranteeing higher prediction performance and shorter runtime on real devices. Experimental results show that Periodformer consistently performs best on six widely used benchmark datasets. Compared with the state-of-the-art methods, the prediction error of Periodformer was reduced by 13% and 26% for multivariate and univariate forecasting, respectively. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Liang2024Periodformer
ER  -

TY  - JOUR
AU  - Kwak, I.-Y.
AU  - Kim, B.-C.
AU  - Lee, J.
AU  - Kang, T.
AU  - Garry, D.J.
AU  - Zhang, J.
AU  - Gong, W.
TI  - Proformer: a hybrid macaron transformer model predicts expression values from promoter sequences
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 81
DO  - 10.1186/s12859-024-05645-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185523971&doi=10.1186%2fs12859-024-05645-5&partnerID=40&md5=0ec96a548507eb93bb7c41ea1657c09b
AB  - The breakthrough high-throughput measurement of the cis-regulatory activity of millions of randomly generated promoters provides an unprecedented opportunity to systematically decode the cis-regulatory logic that determines the expression values. We developed an end-to-end transformer encoder architecture named Proformer to predict the expression values from DNA sequences. Proformer used a Macaron-like Transformer encoder architecture, where two half-step feed forward (FFN) layers were placed at the beginning and the end of each encoder block, and a separable 1D convolution layer was inserted after the first FFN layer and in front of the multi-head attention layer. The sliding k-mers from one-hot encoded sequences were mapped onto a continuous embedding, combined with the learned positional embedding and strand embedding (forward strand vs. reverse complemented strand) as the sequence input. Moreover, Proformer introduced multiple expression heads with mask filling to prevent the transformer models from collapsing when training on relatively small amount of data. We empirically determined that this design had significantly better performance than the conventional design such as using the global pooling layer as the output layer for the regression task. These analyses support the notion that Proformer provides a novel method of learning and enhances our understanding of how cis-regulatory sequences determine the expression values. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Kwak2024Proformer
ER  -

TY  - JOUR
AU  - Barrere, K.
AU  - Soullard, Y.
AU  - Lemaitre, A.
AU  - Coüasnon, B.
TI  - Training transformer architectures on few annotated data: an application to historical handwritten text recognition
PY  - 2024
T2  - International Journal on Document Analysis and Recognition
VL  - 27
IS  - 4
SP  - 553
EP  - 566
DO  - 10.1007/s10032-023-00459-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183051675&doi=10.1007%2fs10032-023-00459-2&partnerID=40&md5=5c475f16b4e09c44bcb8fd86e9d2aede
AB  - Transformer-based architectures show excellent results on the task of handwritten text recognition, becoming the standard architecture for modern datasets. However, they require a significant amount of annotated data to achieve competitive results. They typically rely on synthetic data to solve this problem. Historical handwritten text recognition represents a challenging task due to degradations, specific handwritings for which few examples are available and ancient languages that vary over time. These limitations also make it difficult to generate realistic synthetic data. Given sufficient and appropriate data, Transformer-based architectures could alleviate these concerns, thanks to their ability to have a global view of textual images and their language modeling capabilities. In this paper, we propose the use of a lightweight Transformer model to tackle the task of historical handwritten text recognition. To train the architecture, we introduce realistic looking synthetic data reproducing the style of historical handwritings. We present a specific strategy, both for training and prediction, to deal with historical documents, where only a limited amount of training data are available. We evaluate our approach on the ICFHR 2018 READ dataset which is dedicated to handwriting recognition in specific historical documents. The results show that our Transformer-based approach is able to outperform existing methods. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Barrere2024Training
ER  -

TY  - JOUR
AU  - Yang, T.
AU  - Wang, Y.
AU  - He, Y.
TI  - TEC-miTarget: enhancing microRNA target prediction based on deep learning of ribonucleic acid sequences
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 159
DO  - 10.1186/s12859-024-05780-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190783400&doi=10.1186%2fs12859-024-05780-z&partnerID=40&md5=45169046289c997dbd1d23b2a064fb66
AB  - Background: MicroRNAs play a critical role in regulating gene expression by binding to specific target sites within gene transcripts, making the identification of microRNA targets a prominent focus of research. Conventional experimental methods for identifying microRNA targets are both time-consuming and expensive, prompting the development of computational tools for target prediction. However, the existing computational tools exhibit limited performance in meeting the demands of practical applications, highlighting the need to improve the performance of microRNA target prediction models. Results: In this paper, we utilize the most popular natural language processing and computer vision technologies to propose a novel approach, called TEC-miTarget, for microRNA target prediction based on transformer encoder and convolutional neural networks. TEC-miTarget treats RNA sequences as a natural language and encodes them using a transformer encoder, a widely used encoder in natural language processing. It then combines the representations of a pair of microRNA and its candidate target site sequences into a contact map, which is a three-dimensional array similar to a multi-channel image. Therefore, the contact map's features are extracted using a four-layer convolutional neural network, enabling the prediction of interactions between microRNA and its candidate target sites. We applied a series of comparative experiments to demonstrate that TEC-miTarget significantly improves microRNA target prediction, compared with existing state-of-the-art models. Our approach is the first approach to perform comparisons with other approaches at both sequence and transcript levels. Furthermore, it is the first approach compared with both deep learning-based and seed-match-based methods. We first compared TEC-miTarget’s performance with approaches at the sequence level, and our approach delivers substantial improvements in performance using the same datasets and evaluation metrics. Moreover, we utilized TEC-miTarget to predict microRNA targets in long mRNA sequences, which involves two steps: selecting candidate target site sequences and applying sequence-level predictions. We finally showed that TEC-miTarget outperforms other approaches at the transcript level, including the popular seed match methods widely used in previous years. Conclusions: We propose a novel approach for predicting microRNA targets at both sequence and transcript levels, and demonstrate that our approach outperforms other methods based on deep learning or seed match. We also provide our approach as an easy-to-use software, TEC-miTarget, at https://github.com/tingpeng17/TEC-miTarget. Our results provide new perspectives for microRNA target prediction. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Yang2024TEC-miTarget
ER  -

TY  - JOUR
AU  - Yao, D.
AU  - Li, B.
AU  - Zhan, X.
AU  - Zhan, X.
AU  - Yu, L.
TI  - GCNFORMER: graph convolutional network and transformer for predicting lncRNA-disease associations
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 5
DO  - 10.1186/s12859-023-05625-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181246956&doi=10.1186%2fs12859-023-05625-1&partnerID=40&md5=0baa1864bd9e2b4d5afbccee2a6e6802
AB  - Background: A growing body of researches indicate that the disrupted expression of long non-coding RNA (lncRNA) is linked to a range of human disorders. Therefore, the effective prediction of lncRNA-disease association (LDA) can not only suggest solutions to diagnose a condition but also save significant time and labor costs. Method: In this work, we proposed a novel LDA predicting algorithm based on graph convolutional network and transformer, named GCNFORMER. Firstly, we integrated the intraclass similarity and interclass connections between miRNAs, lncRNAs and diseases, and built a graph adjacency matrix. Secondly, to completely obtain the features between various nodes, we employed a graph convolutional network for feature extraction. Finally, to obtain the global dependencies between inputs and outputs, we used a transformer encoder with a multiheaded attention mechanism to forecast lncRNA-disease associations. Results: The results of fivefold cross-validation experiment on the public dataset revealed that the AUC and AUPR of GCNFORMER achieved 0.9739 and 0.9812, respectively. We compared GCNFORMER with six advanced LDA prediction models, and the results indicated its superiority over the other six models. Furthermore, GCNFORMER's effectiveness in predicting potential LDAs is underscored by case studies on breast cancer, colon cancer and lung cancer. Conclusions: The combination of graph convolutional network and transformer can effectively improve the performance of LDA prediction model and promote the in-depth development of this research filed. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Yao2024GCNFORMER
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Meng, X.
AU  - Li, R.
AU  - Huang, B.
AU  - Wang, X.
TI  - NanoBERTa-ASP: predicting nanobody paratope based on a pretrained RoBERTa model
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 122
DO  - 10.1186/s12859-024-05750-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188353610&doi=10.1186%2fs12859-024-05750-5&partnerID=40&md5=edf44754062fb0be0f0bfffa936322ed
AB  - Background: Nanobodies, also known as VHH or single-domain antibodies, are unique antibody fragments derived solely from heavy chains. They offer advantages of small molecules and conventional antibodies, making them promising therapeutics. The paratope is the specific region on an antibody that binds to an antigen. Paratope prediction involves the identification and characterization of the antigen-binding site on an antibody. This process is crucial for understanding the specificity and affinity of antibody-antigen interactions. Various computational methods and experimental approaches have been developed to predict and analyze paratopes, contributing to advancements in antibody engineering, drug development, and immunotherapy. However, existing predictive models trained on traditional antibodies may not be suitable for nanobodies. Additionally, the limited availability of nanobody datasets poses challenges in constructing accurate models. Methods: To address these challenges, we have developed a novel nanobody prediction model, named NanoBERTa-ASP (Antibody Specificity Prediction), which is specifically designed for predicting nanobody-antigen binding sites. The model adopts a training strategy more suitable for nanobodies, based on an advanced natural language processing (NLP) model called BERT (Bidirectional Encoder Representations from Transformers). To be more specific, the model utilizes a masked language modeling approach named RoBERTa (Robustly Optimized BERT Pretraining Approach) to learn the contextual information of the nanobody sequence and predict its binding site. Results: NanoBERTa-ASP achieved exceptional performance in predicting nanobody binding sites, outperforming existing methods, indicating its proficiency in capturing sequence information specific to nanobodies and accurately identifying their binding sites. Furthermore, NanoBERTa-ASP provides insights into the interaction mechanisms between nanobodies and antigens, contributing to a better understanding of nanobodies and facilitating the design and development of nanobodies with therapeutic potential. Conclusion: NanoBERTa-ASP represents a significant advancement in nanobody paratope prediction. Its superior performance highlights the potential of deep learning approaches in nanobody research. By leveraging the increasing volume of nanobody data, NanoBERTa-ASP can further refine its predictions, enhance its performance, and contribute to the development of novel nanobody-based therapeutics. Github repository: https://github.com/WangLabforComputationalBiology/NanoBERTa-ASP © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Li2024NanoBERTa-ASP
ER  -

TY  - JOUR
AU  - He, X.
AU  - Yan, M.
TI  - GraphKM: machine and deep learning for KM prediction of wildtype and mutant enzymes
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 135
DO  - 10.1186/s12859-024-05746-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188814486&doi=10.1186%2fs12859-024-05746-1&partnerID=40&md5=7527270d649e22817b33906afb7401c2
AB  - Michaelis constant (KM) is one of essential parameters for enzymes kinetics in the fields of protein engineering, enzyme engineering, and synthetic biology. As overwhelming experimental measurements of KM are difficult and time-consuming, prediction of the KM values from machine and deep learning models would increase the pace of the enzymes kinetics studies. Existing machine and deep learning models are limited to the specific enzymes, i.e., a minority of enzymes or wildtype enzymes. Here, we used a deep learning framework PaddlePaddle to implement a machine and deep learning approach (GraphKM) for KM prediction of wildtype and mutant enzymes. GraphKM is composed by graph neural networks (GNN), fully connected layers and gradient boosting framework. We represented the substrates through molecular graph and the enzymes through a pretrained transformer-based language model to construct the model inputs. We compared the difference of the model results made by the different GNN (GIN, GAT, GCN, and GAT-GCN). The GAT-GCN-based model generally outperformed. To evaluate the prediction performance of the GraphKM and other reported KM prediction models, we collected an independent KM dataset (HXKm) from literatures. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - He2024GraphKM
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Cui, S.
AU  - Li, T.
AU  - Liu, H.
AU  - Yang, Q.
AU  - Yang, H.
TI  - Fast CU partition algorithm based on swin-transformer for depth intra coding in 3D-HEVC
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 42
C7  - 115644
SP  - 90315
EP  - 90329
DO  - 10.1007/s11042-024-18926-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190405082&doi=10.1007%2fs11042-024-18926-1&partnerID=40&md5=a88c80a16b122e4080bf6162b8f2b2a1
AB  - The three-dimensional High Efficiency Video Coding (3D-HEVC) standard is an extension of the High Efficiency Video Coding (HEVC) standard which is the latest three-dimensional (3D) video coding standard available. Based on the HEVC standard, 3D-HEVC adds some advanced techniques that are conducive to depth map coding at the expense of a significant increase in coding complexity. In this paper, a Swin-CNN network is proposed, which leverages the advantages of Swin Transformer in extracting global information and convolutional neural network (CNN) in extracting local information. Through Swin-CNN, the coding tree unit (CTU) partition structure in depth intra coding (DIC) can be predicted accurately. In addition, we construct a large-scale depth map dataset to train the Swin-CNN. Finally, we use the proposed algorithm to replace the search process of CTU quadtree partition in DIC. Experimental results show that the proposed algorithm can reduce the coding time by 60.9% to 67.5% without compromising the quality of the synthesised views, effectively reducing the coding complexity of 3D-HEVC. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2024Fast
ER  -

TY  - JOUR
AU  - Singh, A.K.
AU  - Rao, A.
AU  - Chattopadhyay, P.
AU  - Maurya, R.
AU  - Singh, L.
TI  - Effective plant disease diagnosis using Vision Transformer trained with leafy-generative adversarial network-generated images
PY  - 2024
T2  - Expert Systems with Applications
VL  - 254
C7  - 124387
DO  - 10.1016/j.eswa.2024.124387
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195391167&doi=10.1016%2fj.eswa.2024.124387&partnerID=40&md5=c357469b70d22d0a25434fc4c78f02ba
AB  - Agriculture, as the foundation of human civilization, is critical to the global economy, providing food for billions. Plant diseases, caused by factors such as bacteria, fungi, viruses, and others, loom large over crop yields, jeopardizing farmers’ livelihoods worldwide. Rapid and accurate identification of these diseases is critical for agricultural productivity protection and to date, several automated plant disease diagnosis methods have been developed by researchers worldwide. However, the issue of having limited labeled datasets for certain plant leaf diseases poses a significant challenge in training classification models effectively. This scarcity often results in class imbalance which adversely affects a model's ability to accurately predict all the disease classes. It appears there is a need to explore synthetic data generation techniques to train the model for making a better prediction. Further, the disease prediction model should be lightweight so that it can be conveniently integrated with low-end devices with less computational power that farmers can afford to purchase. In this work, we aim to develop an effective neural augmentation model that can render synthetic disease patterns on uninfected leaf images thereby enhancing the leaf disease dataset by adding artificial samples corresponding to those disease classes for which only minor ground truth information is available. Our work extends the state-of-the-art by introducing a new model for leaf disease augmentation, termed “LeafyGAN”, that comprises two key elements: a segmentation model and a disease translation model, both of which are GAN-based. The segmentation model is a pix2pix GAN that is trained to separate foreground leaf images from the background and is trained using a combination of L1 loss and standard GAN loss. The disease translation model is a CycleGAN which is trained using a combination of adversarial loss and cycle consistency loss, which uses the generated segmented mask to render synthetic disease patterns to the extracted leaf regions. A lightweight MobileViT model trained using this augmented data has been seen to perform disease diagnosis with a remarkable accuracy of 99.92% on the PlantVillage dataset and 75.72% on the PlantDoc dataset. Notably, our model achieves an accuracy that is comparable with the recent CNN and Transformer-based models with a significantly lesser number of parameters. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Singh2024Effective
ER  -

TY  - JOUR
AU  - Sun, J.
AU  - Peng, Y.
TI  - The cross-modality survival prediction method of glioblastoma based on dual-graph neural networks
PY  - 2024
T2  - Expert Systems with Applications
VL  - 254
C7  - 124394
DO  - 10.1016/j.eswa.2024.124394
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195394834&doi=10.1016%2fj.eswa.2024.124394&partnerID=40&md5=6f4bc009a1a3317977e0dee96e248cca
AB  - Glioma, the highly lethal malignant brain tumor originating from abnormal proliferation of glial cells, exhibits a varied overall survival rate influenced by multiple factors. Accurate prediction rate of survival periods assist physicians in selecting the most suitable treatment plans to improve patient overall survival (OS) rates. The paper proposes a dual-graph neural network (GNN) with manually constructed feature relational graph for OS prediction and inference of different survival periods in glioblastoma based on cross-modality data. Specifically, five radiomic features from magnetic resonance imaging are extracted to construct two sets of feature relational graphs. The main GNN is utilized to extract comprehensive features, including age, brain MRI features, and radiomics features of gliomas. The branch GNN additionally extracts radiomics features specific to gliomas, constraining the feature weights of the main GNN through attention mechanisms. Pretraining an autoencoder to extract deep features from patient text information. The text features and image features are then reorganized based on features from different modalities through a transformer decoder. Finally, a multi-layer perceptron is utilized for regression and classification, thus enabling the classification and prediction of patient survival. The proposed method achieved an accuracy of 0.586 for classifying and predicting the survival of glioma patients in the short, medium, and long term on the BraTS20 dataset, outperforming state-of-the-art methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Sun2024cross-modality
ER  -

TY  - JOUR
AU  - Yang, Q.
AU  - Xu, X.
AU  - Wang, Z.
AU  - Yu, J.
AU  - Hu, X.
TI  - Are Graphs and GCNs necessary for short-term metro ridership forecasting?
PY  - 2024
T2  - Expert Systems with Applications
VL  - 254
C7  - 124431
DO  - 10.1016/j.eswa.2024.124431
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195452105&doi=10.1016%2fj.eswa.2024.124431&partnerID=40&md5=87e9083672dae10e4e684ecbb6a58780
AB  - Short-term metro ridership prediction is of great significance to efficient and economic operation of Urban Rail Transit (URT) systems. With the popularity of Graph Convolution Networks (GCN) and Transformers, the recent notable metro ridership forecasting methods are GCN-based and Transformer-based models. However, existing methods face the following drawbacks. First, GCN-based models fail to effectively capture global spatial correlations which are significant for accurate prediction. Second, Transformer-based models are prone to loss temporal information due to the permutation-invariant and anti-order properties of the self-attention which they used for capturing temporal correlations. To overcome the drawbacks, we propose a novel sequence-to-sequence metro ridership prediction model, named SDT-GRU, with Stacked DT-GRU layers as both encoder and decoder. The core component of our model is DT-GRU, which integrates Dual-branch Transformer decoder into the GRU to effectively capture global spatial correlations and temporal correlations with Transformer decoder and GRU, separately. In particular, the DT-GRU module uses one branch Transformer encoder layer to capture spatial correlations within the same timestamp, and adopts another Transformer encoder layer to implicitly capture spatio-temporal correlations among previous timestamps. Then, outputs of the two Transformer encoder layers are fed into a GRU layer to capturing spatio-temporal patterns. To evaluate the effectiveness of the proposed SDT-GRU, we conduct comprehensive experiments on three real-world metro ridership datasets from Beijing, Shanghai and Hangzhou. Experimental results demonstrate that our SDT-GRU achieves better prediction performance than the state-of-the-art baselines. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yang2024Are
ER  -

TY  - JOUR
AU  - Tang, P.
AU  - Ding, Z.
AU  - Lv, M.
AU  - Jiang, M.
AU  - Xu, W.
TI  - YOLO-RSFM: An efficient road small object detection method
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 13
SP  - 4263
EP  - 4274
DO  - 10.1049/ipr2.13247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204777311&doi=10.1049%2fipr2.13247&partnerID=40&md5=90eb9036286dc605482e433fd259993c
AB  - To tackle challenges in road multi-object detection, such as object occlusion, small object detection, and multi-scale object detection difficulties, a new YOLOv8n-RSFM structure is proposed. The key improvement of this structure lies in the introduction of the transformer decoder head, which optimizes the matching between the ground truth and predicted boxes, thereby effectively addressing issues of object overlap and multi-scale detection. Additionally, a small object detection layer is incorporated to retain crucial information beneficial for detecting small objects, significantly improving the detection accuracy for small targets. To enhance learning capacity and reduce redundant computations, the FasterNet backbone is employed to replace CSPDarknet53, thus accelerating the training process. Finally, the INNER-MPDIoU loss function is introduced to replace the original algorithm's complete IoU to accelerate the convergence and obtain more accurate regression results. A series of experiments were conducted on different datasets. The experimental results show that the proposed model YOLOv8N-RSFM outperforms the original model YOLOv8n in small target detection. On the VisDrone, TinyPerson, and VSCrowd datasets, the mean accuracy percentage improved by 7.9%, 12.3%, and 4.5%, respectively. © 2024 The Author(s). IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tang2024YOLO-RSFM
ER  -

TY  - JOUR
AU  - Xie, S.
AU  - Chen, Q.
AU  - Fang, X.
AU  - Sun, Q.
TI  - Global information regulation network for multimodal sentiment analysis
PY  - 2024
T2  - Image and Vision Computing
VL  - 151
C7  - 105297
DO  - 10.1016/j.imavis.2024.105297
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206092188&doi=10.1016%2fj.imavis.2024.105297&partnerID=40&md5=fa15358bfdd443a385c61db7139d640c
AB  - Human language is considered multimodal, containing natural language, visual elements, and acoustic signals. Multimodal Sentiment Analysis (MSA) concentrates on the integration of various modalities to capture the sentiment polarity or intensity expressed in human language. Nevertheless, the absence of a comprehensive strategy for processing and integrating multimodal representations results in the inclusion of inaccurate or noisy data from diverse modalities in the ultimate decision-making process, potentially leading to the neglect of crucial information within or across modalities. To address this issue, we propose the Global Information Regulation Network (GIRN), a novel framework designed to regulate information flow and decision-making processes across various stages, ranging from unimodal feature extraction to multimodal outcome prediction. Specifically, before modal fusion stage, we maximize the mutual information between modalities and refine the input signals through random feature erasing, yielding a more robust unimodal representation. In the process of modal fusion, we enhance the traditional Transformer encoder through the gate mechanism and stacked attention to dynamically fuse the target and auxiliary modalities. After modal fusion, cross-hierarchical contrastive learning and decision gate are employed to integrate the valuable information represented in different categories and hierarchies. Extensive experiments conducted on the CMU-MOSI and CMU-MOSEI datasets suggest that our methodology outperforms existing approaches across nearly all criteria. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xie2024Global
ER  -

TY  - JOUR
AU  - Cao, A.
AU  - Shen, G.
TI  - Diff-STAR: Exploring student-teacher adaptive reconstruction through diffusion-based generation for image harmonization
PY  - 2024
T2  - Image and Vision Computing
VL  - 151
C7  - 105254
DO  - 10.1016/j.imavis.2024.105254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203792269&doi=10.1016%2fj.imavis.2024.105254&partnerID=40&md5=7c6f3f212117bd5e9ddfd0a23ad32b48
AB  - Image harmonization aims to seamlessly integrate foreground and background elements from distinct photos into a visually realistic composite. However, achieving high-quality image composition remains challenging in adjusting color balance, retaining fine details, and ensuring perceptual consistency. This article introduces a novel approach named Diffusion-based Student-Teacher Adaptive Reconstruction (Diff-STAR) to address foreground adjustment by framing it as an image reconstruction task. Leveraging natural photographs for model pretraining eliminates the need for data augmentation within Diff-STAR's framework. Employing the pre-trained Denoising Diffusion Implicit Model (DDIM) enhances photorealism and fidelity in generating high-quality outputs from reconstructed latent representations. By effectively identifying similarities in low-frequency style and semantic relationships across various regions within latent images, we develop a student-teacher architecture combining Transformer encoders and decoders to predict adaptively masked patches derived through diffusion processes. Evaluated on the public datasets, including iHarmony4 and RealHM, the experiment results confirm Diff-STAR's superiority over other state-of-the-art approaches based on metrics including Mean Squared Error (MSE) and Peak Signal-to-noise ratio (PSNR). © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cao2024Diff-STAR
ER  -

TY  - JOUR
AU  - Huang, T.
AU  - Rizvi, S.A.
AU  - Thakur, R.K.
AU  - Socrates, V.
AU  - Gupta, M.
AU  - van Dijk, D.
AU  - Taylor, R.A.
AU  - Ying, R.
TI  - HEART: Learning better representation of EHR data with a heterogeneous relation-aware transformer
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 159
C7  - 104741
DO  - 10.1016/j.jbi.2024.104741
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208171966&doi=10.1016%2fj.jbi.2024.104741&partnerID=40&md5=4d47f514c67e902d943acde1427298f0
AB  - Objective: Pretrained language models have recently demonstrated their effectiveness in modeling Electronic Health Record (EHR) data by modeling the encounters of patients as sentences. However, existing methods fall short of utilizing the inherent heterogeneous correlations between medical entities—which include diagnoses, medications, procedures, and lab tests. Existing studies either focus merely on diagnosis entities or encode different entities in a homogeneous space, leading to suboptimal performance. Motivated by this, we aim to develop a foundational language model pre-trained on EHR data with explicitly incorporating the heterogeneous correlations among these entities. Methods: In this study, we propose HEART, a heterogeneous relation-aware transformer for EHR. Our model includes a range of heterogeneous entities within each input sequence and represents pairwise relationships between entities as a relation embedding. Such a higher-order representation allows the model to perform complex reasoning and derive attention weights in the heterogeneous context. Additionally, a multi-level attention scheme is employed to exploit the connection between different encounters while alleviating the high computational costs. For pretraining, HEART engages with two tasks, missing entity prediction and anomaly detection, which both effectively enhance the model's performance on various downstream tasks. Results: Extensive experiments on two EHR datasets and five downstream tasks demonstrate HEART's superior performance compared to four SOTA foundation models. For instance, HEART achieves improvements of 12.1% and 4.1% over Med-BERT in death and readmission prediction, respectively. Additionally, case studies show that HEART offers interpretable insights into the relationships between entities through the learned relation embeddings. Conclusion: We study the problem of EHR representation learning and propose HEART, a model that leverages the heterogeneous relationships between medical entities. Our approach includes a multi-level encoding scheme and two specialized pretrained objectives, designed to boost both the efficiency and effectiveness of the model. We have comprehensively evaluated HEART across five clinically significant downstream tasks using two EHR datasets. The experimental results verify the model's great performance and validate its practical utility in healthcare applications. Code: https://github.com/Graph-and-Geometric-Learning/HEART. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Huang2024HEART
ER  -

TY  - JOUR
AU  - Li, B.
AU  - Yang, P.
AU  - Sun, Y.
AU  - Hu, Z.
AU  - Yi, M.
TI  - Multi-view pre-trained transformer via hierarchical capsule network for answer sentence selection
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 21
SP  - 10561
EP  - 10580
DO  - 10.1007/s10489-024-05513-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201628254&doi=10.1007%2fs10489-024-05513-y&partnerID=40&md5=c74b9b5dfcb1286d2b70d3228e515e5f
AB  - Answer selection requires technology that effectively captures in-depth semantic information between the question and the corresponding answer. Most existing studies focus on using linear or pooling operations to directly classify the output representation, resulting in the absence of critical information and the emergence of single-label predictions. To address these issues, we propose a novel Multi-view Pre-trained Transformer with Hierarchical Capsule Network (MPT-HCN). Specifically, we propose a Hierarchical Capsule Network composed of three capsule networks to independently process high-dimensional sparse information of words, semantic information of similar expressions, and feature classification information so that multiple attributes can be fully considered and accurately clustered. Moreover, we consider the impact of the intermediate encoder layer output information on the overall sequence semantic representation and propose a Multi-view Information Fusion that obtains the final semantic representation information by weighted fusion of the output information of all encoder layers, thereby avoiding the appearance of a single prediction label. Extensive experiments on five typical representative datasets, especially on the WikiQA dataset, show that our model MPT-HCN (RL) achieves an excellent performance of 0.939 on MAP and 0.942 on MRR, which is a significant improvement of 3.9% and 2.7% respectively, compared to the state-of-the-art baseline model. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Multi-view
ER  -

TY  - JOUR
AU  - Yang, S.
AU  - Wu, Q.
AU  - Wang, Y.
AU  - Lin, T.
TI  - SSGCRTN: a space-specific graph convolutional recurrent transformer network for traffic prediction
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 22
SP  - 11978
EP  - 11994
DO  - 10.1007/s10489-024-05815-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203259118&doi=10.1007%2fs10489-024-05815-1&partnerID=40&md5=0d2a9045130505f674fe8e45a8c3065a
AB  - Current research often formalizes traffic prediction tasks as spatio-temporal graph modeling problems. Despite some progress, this approach still has the following limitations. First, space can be divided into intrinsic and latent spaces. Static graphs in intrinsic space lack flexibility when facing changing prediction tasks, while dynamic relationships in latent space are influenced by multiple factors. A deep understanding of specific traffic patterns in different spaces is crucial for accurately modeling spatial dependencies. Second, most studies focus on correlations in sequential time periods, neglecting both reverse and global temporal correlations. This oversight leads to incomplete temporal representations in models. In this work, we propose a Space-Specific Graph Convolutional Recurrent Transformer Network (SSGCRTN) to address these limitations simultaneously. For the spatial aspect, we propose a space-specific graph convolution operation to identify patterns unique to each space. For the temporal aspect, we introduce a spatio-temporal interaction module that integrates spatial and temporal domain knowledge of nodes at multiple granularities. This module learns and utilizes parallel spatio-temporal relationships between different time points from both forward and backward perspectives, revealing latent patterns in spatio-temporal associations. Additionally, we use a transformer-based global temporal fusion module to capture global spatio-temporal correlations. We conduct experiments on four real-world traffic flow datasets (PeMS03/04/07/08) and two traffic speed datasets (PeMSD7(M)/(L)), achieving better performance than existing technologies. Notably, on the PeMS08 dataset, our model improves the MAE by 6.41% compared to DGCRN. The code of SSGCRTN is available at https://github.com/OvOYu/SSGCRTN. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Yang2024SSGCRTN
ER  -

TY  - JOUR
AU  - Li, N.
AU  - Huang, K.
AU  - Wu, Q.
AU  - Zhao, Y.
TI  - Integrating pseudo labeling with contrastive clustering for transformer-based semi-supervised action recognition
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 22
SP  - 11177
EP  - 11195
DO  - 10.1007/s10489-024-05661-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200993354&doi=10.1007%2fs10489-024-05661-1&partnerID=40&md5=cf795c4b3ef3aeea295a40214fd5b84e
AB  - Video action recognition with semi-supervised learning is a challenging research topic due to the low-labeling ratio. Previous works mainly tackle the problem with two kinds of approaches: pseudo labeling and contrastive learning. Different from existing approaches that often treat the two parts separately, we propose an integrated learning framework that incorporates pseudo labeling and contrastive clustering in a coherent and mutually beneficial way. On one hand, the contrastive learning aggregates data from the same class into clusters, yielding more reliable pseudo labels for training the classifier; on the other hand, the re-trained classifier predicts categories for unlabeled data, thereby guiding contrastive learning to establish discriminative representations. We theoretically prove that the two iterative operations can be formulated as an E-M algorithm and validate its generalization ability upon the semi-supervised classification task with experiments. Specifically, we construct a MoCo-like structure to implement the proposed learning framework and explore the potential of employing the video tramsformer for semi-supervised action recognition. Furthermore, We also devise a global-local view sampling strategy for video data augmentation, which verifies to facilitate the representation learning and advance the performance. We implement extensive experiments on three video action recognition datasets with a series of data labeling ratios. Compared with state-of-the-art (SOTA) methods, the proposed approach achieves superior or competitive performances. For example, with 1% labeling ratio, the top-1 accuracy increase to 49.1% and 52.4% on UCF-101 and Kinetics-400 datasets, respectively, surpassing SOTA by 2.8% and 3.3%. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2024Integrating
ER  -

TY  - JOUR
AU  - Wang, B.
AU  - Dabbaghjamanesh, M.
AU  - Kavousi-Fard, A.
AU  - Yue, Y.
TI  - AI-enhanced multi-stage learning-to-learning approach for secure smart cities load management in IoT networks
PY  - 2024
T2  - Ad Hoc Networks
VL  - 164
C7  - 103628
DO  - 10.1016/j.adhoc.2024.103628
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201517922&doi=10.1016%2fj.adhoc.2024.103628&partnerID=40&md5=2b4d7316963cde4d37a92fc0a286c19d
AB  - In the context of rapidly urbanizing smart cities reliant on IoT networks, efficient load management is critical for sustainable energy use. This paper proposes an AI-enhanced Multi-Stage Learning-to-Learning (MSLL) approach tailored for secure load management in IoT networks. The proposed approach leverages MMStransformer, a transformer-based model designed to handle multivariate, correlated data, and to capture long-range dependencies inherent in load forecasting. MMStransformer employs a multi-mask learning-to-learning strategy, optimizing computational efficiency without compromising prediction accuracy. The study addresses the dynamic and complex nature of smart city data by integrating diverse environmental and operational variables. Security and privacy concerns inherent in IoT networks are also addressed, ensuring secure data handling and communication. Experimental results demonstrate the efficacy of the proposed approach, achieving competitive performance compared to traditional methods and baseline models. The findings highlight the potential of AI-driven solutions in enhancing load forecasting accuracy while ensuring robust security measures in smart city infrastructures. This research contributes to advancing the state-of-the-art in AI applications for sustainable urban development and energy management. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wang2024AI-enhanced
ER  -

TY  - JOUR
AU  - Areshey, A.
AU  - Mathkour, H.
TI  - Exploring transformer models for sentiment classification: A comparison of BERT, RoBERTa, ALBERT, DistilBERT, and XLNet
PY  - 2024
T2  - Expert Systems
VL  - 41
IS  - 11
C7  - e13701
DO  - 10.1111/exsy.13701
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201081226&doi=10.1111%2fexsy.13701&partnerID=40&md5=8f0c514ee82585b64e7d7ba9c2a2738f
AB  - Transfer learning models have proven superior to classical machine learning approaches in various text classification tasks, such as sentiment analysis, question answering, news categorization, and natural language inference. Recently, these models have shown exceptional results in natural language understanding (NLU). Advanced attention-based language models like BERT and XLNet excel at handling complex tasks across diverse contexts. However, they encounter difficulties when applied to specific domains. Platforms like Facebook, characterized by continually evolving casual and sophisticated language, demand meticulous context analysis even from human users. The literature has proposed numerous solutions using statistical and machine learning techniques to predict the sentiment (positive or negative) of online customer reviews, but most of them rely on various business, review, and reviewer features, which leads to generalizability issues. Furthermore, there have been very few studies investigating the effectiveness of state-of-the-art pre-trained language models for sentiment classification in reviews. Therefore, this study aims to assess the effectiveness of BERT, RoBERTa, ALBERT, DistilBERT, and XLNet in sentiment classification using the Yelp reviews dataset. The models were fine-tuned, and the results obtained with the same hyperparameters are as follows: 98.30 for RoBERTa, 98.20 for XLNet, 97.40 for BERT, 97.20 for ALBERT, and 96.00 for DistilBERT. © 2024 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Areshey2024Exploring
ER  -

TY  - JOUR
AU  - Han, J.
AU  - Wang, S.
AU  - Deng, X.
AU  - Liu, W.
TI  - High-performance mitosis detection using single-level feature and hybrid label assignment
PY  - 2024
T2  - Image and Vision Computing
VL  - 151
C7  - 105291
DO  - 10.1016/j.imavis.2024.105291
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205289739&doi=10.1016%2fj.imavis.2024.105291&partnerID=40&md5=72578bb2f0aaecf0e985c500473f757d
AB  - Mitosis detection poses a significant challenge in medical image analysis, primarily due to the substantial variability in the appearance and shape of mitotic targets. This paper introduces an efficient and accurate mitosis detection framework, which stands apart from previous mitosis detection techniques with its two key features: Single-Level Feature (SLF) for bounding box prediction and Dense-Sparse Hybrid Label Assignment (HLA) for bounding box matching. The SLF component of our method employs a multi-scale Transformer backbone to capture the global context and morphological characteristics of both mitotic and non-mitotic cells. This information is then consolidated into a single-scale feature map, thereby enhancing the model's receptive field and reducing redundant detection across various feature maps. In the HLA component, we propose a hybrid label assignment strategy to facilitate the model's adaptation to mitotic cells of different shapes and positions during training, thereby improving the model's adaptability to diverse cell morphologies. Our method has been tested on the largest mitosis detection datasets and achieves state-of-the-art (SOTA) performance, with an F1 score of 0.782 on the TUPAC 16 benchmark, and 0.792 with test time augmentation (TTA). Our method also exhibits superior accuracy and faster processing speed compared to previous methods. The source code and pretrained models will be released to facilitate related research. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Han2024High-performance
ER  -

TY  - JOUR
AU  - Pourbehzadi, M.
AU  - Javidi, G.
AU  - Howell, C.J.
AU  - Kamar, E.
AU  - Sheybani, E.
TI  - Enhanced (cyber) situational awareness: Using interpretable principal component analysis (iPCA) to automate vulnerability severity scoring
PY  - 2024
T2  - Decision Support Systems
VL  - 186
C7  - 114308
DO  - 10.1016/j.dss.2024.114308
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203133481&doi=10.1016%2fj.dss.2024.114308&partnerID=40&md5=931bc984689f65da24ec09990f4428cf
AB  - The Common Vulnerability Scoring System (CVSS) is widely used in the cybersecurity industry to assess the severity of vulnerabilities. However, manual assessments and human error can lead to delays and inconsistencies. This study employs situational awareness theory to develop an automated decision support system, integrating perception, comprehension, and projection components to enhance effectiveness. Specifically, an interpretable principal component analysis (iPCA) combined with machine learning is utilized to forecast CVSS scores using text descriptions from the Common Vulnerabilities and Exposures (CVE) database. Different forecasting approaches, including traditional machine learning models, Long-Short Term Memory Neural Networks, and Transformer architectures (ChatGPT) are compared to determine the best performance. The results show that iPCA combined with support vector regression achieves a high performance (R2 = 98%) in predicting CVSS scores using CVE text descriptions. The results indicate that the variability, length, and details in the vulnerability description contribute to the performance of the transformer model. These findings are consistent across vulnerability descriptions from six companies between 2017 and 2019. The study's outcomes have the potential to enhance organizations' security posture, improving situational awareness and enabling better managerial decision-making in cybersecurity. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Pourbehzadi2024Enhanced
ER  -

TY  - JOUR
AU  - Dong, L.
AU  - Chen, L.
AU  - Zheng, C.
AU  - Fu, Z.
AU  - Zukaib, U.
AU  - Cui, X.
AU  - Shen, Z.
TI  - OCIE: Augmenting model interpretability via Deconfounded Explanation-Guided Learning
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 302
C7  - 112390
DO  - 10.1016/j.knosys.2024.112390
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201642657&doi=10.1016%2fj.knosys.2024.112390&partnerID=40&md5=0cbe7c10cb2a02378405fe76253e54b5
AB  - Deep neural networks (DNNs) often encounter significant challenges related to opacity, inherent biases, and shortcut learning, which undermine their practical reliability. In this study, we address these issues by constructing a causal graph to model the unbiased learning process of DNNs. This model reveals that recurrent background information in training samples acts as a confounder, leading to spurious correlations between model inputs and outputs, causing biased predictions. To mitigate these problems and promote unbiased feature learning, we propose the Object-guided Consistency Interpretation Enhancement (OCIE) methodology. OCIE enhances DNN interpretability by integrating explicit objects and explanations into the model's learning process. Initially, OCIE employs a graph-based algorithm to identify explicit objects within self-supervised vision transformer-learned features. Subsequently, it constructs class prototypes to eliminate invalid detected objects. Finally, OCIE aligns explanations with explicit objects, directing the model's attention towards the most distinctive classification features rather than irrelevant backgrounds. Extensive experiments on different image classification datasets, including general (ImageNet), fine-grained (Stanford Cars and CUB-200), and medical (HAM) datasets, using two prevailing network architectures, demonstrate that OCIE significantly enhances explanation consistency across all datasets. Furthermore, OCIE proves particularly advantageous for fine-grained classification, especially in few-shot scenarios, by improving both interpretability and classification performance. Additionally, our findings highlight the impact of centralized explanations on the sufficiency of model decisions, suggesting that focusing explanations on explicit objects improves the reliability of DNN predictions. Our code is available at: https://github.com/DLAIResearch/OCIE. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Dong2024OCIE
ER  -

TY  - JOUR
AU  - Zhuang, W.
AU  - Fan, J.
AU  - Fang, J.
AU  - Fang, W.
AU  - Xia, M.
TI  - Rethinking general time series analysis from a frequency domain perspective
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 301
C7  - 112281
DO  - 10.1016/j.knosys.2024.112281
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200823152&doi=10.1016%2fj.knosys.2024.112281&partnerID=40&md5=041cb593271cd90f3896d5ed345769f2
AB  - Recently, Transformers and MLPs based models have dominated and made significant progress in time series analysis. However, these methods struggle to capture the complete periodic features to model the global dependencies of time series. To this end, we provide a new perspective to explore the potential of time series in the frequency domain. Specifically, we propose the DFT-based Amplitude-Phase Decoupling Network (APDNet), which learns the significance changes and periodicity characteristics of time series by decoupling the real and imaginary parts in the complex frequency domain. First, we propose the Fourier Temporal/Variable Interaction Module to model time dependency and dependency multiple variables, respectively. Secondly, we innovatively propose the Dimensional Expanded Feature Embedding Module (DEFEM), which expands time series into a higher-dimensional representation space to preserve more independent features. Finally, through extensive experiments on multiple real-world datasets, our APDNet achieves state-of-the-art performance in various tasks such as long-term and short-term forecasting, anomaly detection, imputation, and classification. Code is available at: https://github.com/CodeJester196/APDNet. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Zhuang2024Rethinking
ER  -

TY  - JOUR
AU  - Cao, Z.
AU  - Lyu, L.
AU  - Qi, R.
AU  - Wang, J.
TI  - CrowdUNet: Segmentation assisted U-shaped crowd counting network
PY  - 2024
T2  - Neurocomputing
VL  - 601
C7  - 128215
DO  - 10.1016/j.neucom.2024.128215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199472162&doi=10.1016%2fj.neucom.2024.128215&partnerID=40&md5=8b49b2c64ced818fc6fbda0bd4c5ceed
AB  - With the end of the COVID-19 pandemic, the number of pedestrians in various public places has increased dramatically. Estimating the size and density distribution of crowds accurately from images is essential for public safety. At present, there are still many factors that limit the accuracy of dense crowd counting, such as perspective distortion, background clutter and heavy occlusion. To be capable of accurately estimating the crowd size in RGB images, we propose a crowd counting network called CrowdUNet, which is assisted by a segmentation task. It applies the segmentation results to the crowd counts, making the network more focused on the prediction of foreground regions. We combine Swin Transformer Block and CNN to build a Swin Transformer Convolution(STC) module to extract deep semantic features. We analyze the characteristics of crowd images and propose a novel decoder structure called Coordinate Decoder(CD), which better aggregates low and high level features and improve the robustness of the network. In order to obtain accurate regression results, we also propose a regression head with multi-scale receptive fields, which is called Spatial Pyramid Convolution (SPC). Extensive experiments on four challenging crowd counting datasets namely ShanghaiTech A, ShanghaiTech B, UCF p=CC 50, and UCF-QNRF have validated the proposed method. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cao2024CrowdUNet
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Xu, H.
AU  - Zhang, T.
AU  - Li, X.
AU  - Li, G.
AU  - Tian, W.
TI  - DDGformer: Direction- and distance-aware graph transformer for traffic flow prediction
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 302
C7  - 112381
DO  - 10.1016/j.knosys.2024.112381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201423457&doi=10.1016%2fj.knosys.2024.112381&partnerID=40&md5=a7e33a153506c69f3eaa9325c81769f4
AB  - Being an indispensable core technology of intelligent transportation systems, accurate traffic flow prediction contributes to improving people's travel efficiency and safety. How to accurately model the dynamic spatio-temporal correlation in traffic data is a key challenge in traffic flow prediction. The models based on self-attention and Graph Neural Networks (GNN) have shown great potential in addressing this challenge. However, existing methods ignore the relative distance and direction of traffic flow series, and cannot accurately capture the real dynamic spatio-temporal correlations in traffic systems. To overcome this limitation, we propose a novel framework called Direction- and Distance-aware Graph Transformer (DDGformer). Specifically, it utilizes a self-attention module that simultaneously perceives direction and distance, enabling it to identify the relative position and direction of the original traffic flow series, and models long-term temporal correlations. Additionally, a dynamically enhanced adaptive graph convolution network is designed to capture dynamic traffic patterns in traffic systems. Extensive experimental results on four real-world traffic datasets show that our approach is overall more competitive and exhibits outstanding computational efficiency. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Li2024DDGformer
ER  -

TY  - JOUR
AU  - Lu, D.
AU  - Schwartz, S.
AU  - Xu, L.
AU  - Shafiee, M.J.
AU  - Vinson, N.G.
AU  - Czarnecki, K.J.
AU  - Wong, A.
TI  - Integrating deep transformer and temporal convolutional networks for SMEs revenue and employment growth prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 252
C7  - 124129
DO  - 10.1016/j.eswa.2024.124129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192246655&doi=10.1016%2fj.eswa.2024.124129&partnerID=40&md5=7dd519464eeeab854263a6b5b019258b
AB  - Although the accurate potential for growth prediction is very important for Government grants and contributions programs to better support Small and Medium-sized Enterprises (SMEs), it is a challenging task due to the data heterogeneity (both structured data and free text data bilingual in English and French), the class imbalance issue, and the difficulties in efficient feature learning. To address these challenges, this paper presents a novel BERT-TCN model for portfolio predictions in government funding programs, with the following key contributions. First, we describe the application of a novel architecture to a prediction task involving sequential, structured, partially quantitative input data and free text input data. Specifically, our novel model predicts the growth of firms receiving government funding for innovation. Our model also deals with class imbalance in the data and the difficulties in efficient feature learning. Our model integrates a Transformer model, i.e., BERT, for text modeling with a Temporal Convolutional Network (TCN) for sequential prediction. Second, we also developed various performance evaluation criteria in Section 4.3, allowing comprehensive assessments of the proposed approach from both the machine learning perspective and funding program-specific perspective. Third, the importance of features (both text and numerical features) is quantified and evaluated, allowing insights into how different features contribute to the prediction and explainability of the proposed model. The proposed approach is trained and tested on a large dataset from a rich database, demonstrating that the proposed approach can greatly help individual human experts improve their results. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Lu2024Integrating
ER  -

TY  - JOUR
AU  - Wan, Y.
AU  - Shao, M.
AU  - Cheng, Y.
AU  - Zuo, W.
TI  - Image all-in-one adverse weather removal via dynamic model weights generation
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 302
C7  - 112324
DO  - 10.1016/j.knosys.2024.112324
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201512770&doi=10.1016%2fj.knosys.2024.112324&partnerID=40&md5=bd2c8daad5982d26513c70b50843c099
AB  - Restoring image under multiple weather conditions in an all-in-one fashion remains a formidable challenge due to images captured under different weather conditions exhibit different degradation characteristics and patterns. However, existing all-in-one adverse weather removal methods mainly focus on learning shared generic knowledge of multiple weather conditions via fixed network parameters, which fails to adjust for different instances to fit exclusive features characterization of specific weather conditions. To tackle this issue, we propose a novel dynamic weights generation network (DwGN) that can adaptively mine and extract instance-exclusive degradation features for different weather conditions via dynamically generated convolutional weights. Specifically, we first propose two fundamental dynamic weights convolutions, which can automatically generate optimal convolutional weights for distinct pending features via a lightweight yet efficient mapping layer. The predicted convolutional weights are then incorporated into the convolution operation to extract instance-exclusive features for different weather conditions. Building upon the dynamic weights convolutions, we further devise a tailored weight adaptive Transformer blocks (WATB) which consists of two core modules: half-dynamic multi-head cross-attention (HDMC) that performs exclusive-generic feature interaction, and half-dynamic feed-forward network (HDFN) that performs selected exclusive-generic feature transformation and aggregation. Considering communal features shared between different weather conditions (e.g., background representation), both HDMC and HDFN deploy only half of the dynamic weights convolutions for instance-exclusive feature characterization, while still deploying half of the static convolutions to characterize generic features. Through adaptive weight tuning, our DwGN can adaptively adapt to different weather scenarios and effectively capture the instance-exclusive degradation features, thus enjoying better flexibility and adaptability under all-in-one adverse weather removal. Extensive experiments demonstrate that our DwGN performs favorably against state-of-the-art algorithms. In particular, our proposed DwGN achieves the best PSNR and SSIM scores on all five tasks both in the task-specific setting and in the all-in-one setting. Furthermore, our method has shown consistent performance improvement in both real-world and high-level visual applications. The implementation code is available at https://github.com/Jeasco/DwGN. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Wan2024Image
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Liu, T.
AU  - Yang, Y.
AU  - Kang, J.
AU  - Ren, L.
AU  - Ding, H.
AU  - Zhang, Y.
TI  - ACVPred: Enhanced prediction of anti-coronavirus peptides by transfer learning combined with data augmentation
PY  - 2024
T2  - Future Generation Computer Systems
VL  - 160
SP  - 305
EP  - 315
DO  - 10.1016/j.future.2024.06.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195813698&doi=10.1016%2fj.future.2024.06.008&partnerID=40&md5=68242fb18db13bc649630115da4d0032
AB  - Anti-coronavirus peptides (ACVPs) have garnered significant attention in COVID-19 therapeutic research due to their precise targeting, low risk of drug resistance, flexible synthesis, and effectiveness against viral mutations. Although some in-silico methods have been developed to predict ACVPs, they suffer from challenges such as limited datasets and a lack of interpretability. Hence, this study introduces ACVPred, an algorithm for ACVP prediction, based on two few-shot learning strategies: transfer learning and data augmentation strategies. Our experiments demonstrate that data augmentation can significantly enhance model performance, while transfer learning can effectively prevent overfitting and strengthen generalizability. Compared to existing methods, ACVPred exhibits superior performance and robust generalization both in training and independent test datasets. Moreover, the interpretability study of the model reveals that its transformer-based core can effectively capture key motifs on ACVP sequences, demonstrating strong feature learning capabilities. Additionally, the findings suggest that the sequence feature weights and key motif positions tend to be distributed towards the N-terminal end of ACVP sequences, providing vital clues for the design of ACVPs. In summary, ACVPred is not only a practical and valuable tool for aiding in the design of ACVPs, but its algorithmic concept also serves as an important reference for research on other small sample prediction problems. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Xu2024ACVPred
ER  -

TY  - JOUR
AU  - Nahli, A.
AU  - Li, D.
AU  - Uddin, R.
AU  - Irfan, M.
AU  - Oubibi, M.
AU  - Lu, Q.
AU  - Zhang, J.Q.
TI  - ExposureNet: Mobile camera exposure parameters autonomous control for blur effect prevention
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 12
SP  - 3403
EP  - 3414
DO  - 10.1049/ipr2.13182
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199792894&doi=10.1049%2fipr2.13182&partnerID=40&md5=1cfca7a017da63db28de141bf6deb85e
AB  - The quality of images we perceive visually is heavily impacted by the settings used for camera exposure. When these settings are imbalanced, it can result in an undesired prominent phenomenon known as blur effects. To address this problem, an ExposureNet project has been undertaken, which aims to develop an autonomous camera exposure settings control system for blur effects prevention. The proposed ExposureNet model is a CNN/Transformer hybrid neural structure, created and trained in a comprehensive manner to effectively predict the ideal exposure settings based on the semantic features of the scene being captured. This system is designed to learn the necessary steps for processing, such as identifying relevant scene features, using only two camera exposure parameters (shutter speed (SHS) and ISO) as training signals. As a result, this system can associate the semantic features of a scene with the appropriate exposure parameter adjustments, customized to the scene's dynamics and lighting conditions. By simultaneously optimizing all processing steps and bypassing traditional post-processing stages, the proposed system is designed to achieve faster performance, reduced computational cost, and lower power consumption. Experimental results demonstrate that the proposed system significantly outperforms existing methods and achieves cutting-edge performance. © 2024 The Author(s). IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Nahli2024ExposureNet
ER  -

TY  - JOUR
AU  - Ryumin, D.
AU  - Axyonov, A.
AU  - Ryumina, E.
AU  - Ivanko, D.
AU  - Kashevnik, A.
AU  - Karpov, A.
TI  - Audio–visual speech recognition based on regulated transformer and spatio–temporal fusion strategy for driver assistive systems
PY  - 2024
T2  - Expert Systems with Applications
VL  - 252
C7  - 124159
DO  - 10.1016/j.eswa.2024.124159
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193071470&doi=10.1016%2fj.eswa.2024.124159&partnerID=40&md5=74b397a2f5c5ed0aca8c914792b593fc
AB  - This article presents a research methodology for audio–visual speech recognition (AVSR) in driver assistive systems. These systems necessitate ongoing interaction with drivers while driving through voice control for safety reasons. The article introduces a novel audio–visual speech command recognition transformer (AVCRFormer) specifically designed for robust AVSR. We propose (i) a multimodal fusion strategy based on spatio–temporal fusion of audio and video feature matrices, (ii) a regulated transformer based on iterative model refinement module with multiple encoders, (iii) a classifier ensemble strategy based on multiple decoders. The spatio–temporal fusion strategy preserves contextual information of both modalities and achieves their synchronization. An iterative model refinement module can bridge the gap between acoustic and visual data by leveraging their impact on speech recognition accuracy. The proposed multi-prediction strategy demonstrates superior performance compared to traditional single-prediction strategy, showcasing the model's adaptability across diverse audio–visual contexts. The transformer proposed has achieved the highest values of speech command recognition accuracy, reaching 98.87% and 98.81% on the RUSAVIC and LRW corpora, respectively. This research has significant implications for advancing human–computer interaction. The capabilities of AVCRFormer extend beyond AVSR, making it a valuable contribution to the intersection of audio–visual processing and artificial intelligence. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ryumin2024Audio–visual
ER  -

TY  - JOUR
AU  - Wei, F.
AU  - Wang, S.
AU  - Sun, Y.
AU  - Yin, B.
TI  - A dual attentional skip connection based Swin-UNet for real-time cloud segmentation
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 12
SP  - 3460
EP  - 3479
DO  - 10.1049/ipr2.13186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198663344&doi=10.1049%2fipr2.13186&partnerID=40&md5=e02012e103bc13399faab214f2d75a34
AB  - Developing real-time cloud segmentation technology is urgent for many remote sensing based applications such as weather forecasting. Existing deep learning based cloud segmentation methods involve two shortcomings. (a): They tend to produce discontinuous boundaries and fail to capture less salient feature, which corresponds to thin cloud pixels; (b): they are unrobust towards different scenarios. Those issues are circumvented by integrating U-Net and the swin transformer together, with an efficiently designed dual attention mechanism based skip connection. Typically, a swin transformer based encoder-decoder network, by incorporating a dual attentional skip connection with Swin-UNet (DASUNet) is proposed. DASUNet captures the global relationship of image patches based on its window attention mechanism, which fits the real-time requirement. Moreover, DASUNet characterizes the less salient features by equipping with token dual attention modules among the skip connection, which compensates the ignorance of less salient features incurred from traditional attention mechanism during the stacking of transformer layers. Experiments on ground-based images (SWINySeg) and remote sensing images (HRC-WHU, 38-Cloud) show that, DASUNet achieves the state-of-the-art or competitive results for cloud segmentation (six top-1 positions of six metrics among 11 methods on SWINySeg, two top-1 positions of five metrics among 10 methods on HRC-WHU, two top-1 positions of four metrics among 12 methods with ParaNum (Formula presented.) on 38-Cloud), with 100FPS implementation speed averagely for each (Formula presented.) image. © 2024 The Author(s). IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wei2024dual
ER  -

TY  - JOUR
AU  - Yu, D.
AU  - Guo, G.
AU  - Wang, D.
AU  - Zhang, H.
AU  - Li, B.
AU  - Xu, G.
AU  - Deng, S.
TI  - Modeling dynamic spatio-temporal correlations and transitions with time window partitioning for traffic flow prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 252
C7  - 124187
DO  - 10.1016/j.eswa.2024.124187
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193530362&doi=10.1016%2fj.eswa.2024.124187&partnerID=40&md5=6bec0d1779930ebfb1783a0df89e133f
AB  - Predicting traffic flow represents a critical undertaking within the domain of Intelligent Transportation Systems (ITS), given its pivotal role in optimizing traffic management strategies. Nevertheless, this endeavor is fraught with challenges, stemming from the inherent complexity and dynamic nature of traffic systems. Existing methods still suffer from the following three main limitations: (i) modeling the spatio-temporal correlations in a static way, restricting the ability to learn dynamic correlations; (ii) only capturing short-term local temporal features while neglecting long-term temporal patterns; (iii) cannot learn the latent relationships between traffic nodes at different time steps. Therefore, we propose a novel method named InOutformer based on In-Time-Window self-attention and Out-Time-Window self-attention to predict traffic flow. This method can effectively capture both short-term local temporal features and model long-term global temporal patterns, while also capturing dynamic spatial correlations between nodes. Specifically, we first propose a novel time window partitioning mechanism to replace the conventional sliding time window approach, in order to capture dynamic temporal features. Second, two specially designed temporal self-attention modules are used to learn short-term local temporal features and model long-term global temporal patterns, respectively. Then, a 2D-attention method is devised to capture the spatial correlations of nodes at different time steps. Moreover, by exploiting transition flow data, the detrimental effects due to spatial information propagation delays are effectively mitigated. Extensive experiments on four real-world traffic datasets demonstrate that the proposed model InOutformer outperforms the baselines, including several state-of-the-art methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yu2024Modeling
ER  -

TY  - JOUR
AU  - Acikalin, U.U.
AU  - Gorgun, M.K.
AU  - Kutlu, M.
AU  - Tas, B.K.O.
TI  - How you describe procurement calls matters: Predicting outcome of public procurement using call descriptions
PY  - 2024
T2  - Natural Language Engineering
VL  - 30
IS  - 6
SP  - 1255
EP  - 1276
DO  - 10.1017/S135132492300030X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171798403&doi=10.1017%2fS135132492300030X&partnerID=40&md5=f43424d3875e510ac7da832255800ff0
AB  - A competitive and cost-effective public procurement (PP) process is essential for the effective use of public resources. In this work, we explore whether descriptions of procurement calls can be used to predict their outcomes. In particular, we focus on predicting four well-known economic metrics: (i) the number of offers, (ii) whether only a single offer is received, (iii) whether a foreign firm is awarded the contract, and (iv) whether the contract price exceeds the expected price. We extract the European Union’s multilingual PP notices, covering 22 different languages. We investigate fine-tuning multilingual transformer models and propose two approaches: (1) multilayer perceptron (MLP) models with transformer embeddings for each business sector in which the training data are filtered based on the procurement category and (2) a k-nearest neighbor (KNN)-based approach fine-tuned using triplet networks. The fine-tuned MBERT model outperforms all other models in predicting calls with a single offer and foreign contract awards, whereas our MLP-based filtering approach yields state-of-the-art results in predicting contracts in which the contract price exceeds the expected price. Furthermore, our KNN-based approach outperforms all the baselines in all tasks and our other proposed models in predicting the number of offers. Moreover, we investigate cross-lingual and multilingual training for our tasks and observe that multilingual training improves prediction accuracy in all our tasks. Overall, our experiments suggest that notice descriptions play an important role in the outcomes of PP calls. © The Author(s), 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Acikalin2024How
ER  -

TY  - JOUR
AU  - Yuan, Q.
TI  - Multiscale Global Attention Network With Edge Perceptron for Automatic Road Extraction From Remote Sensing Imagery
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 5005205
DO  - 10.1109/LGRS.2024.3478847
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206995406&doi=10.1109%2fLGRS.2024.3478847&partnerID=40&md5=fb93e6df1abe32a21bf9a53f43b4006b
AB  - Automatic road interpretation using remote sensing images is crucial for intelligent city construction and is widely applied in various domains such as automatic driving navigation, cartography, and urban planning. Recently, deep learning algorithms, especially for convolutional neural networks (CNNs) and Transformers, have been utilized with large-scale remote sensing datasets to extract abundant semantic features, significantly improving the accuracy and efficiency of road extraction. However, these models ignore the correlation between multiscale local context and global semantics, which could cause fragmentary prediction in complex remote sensing environments. In addition, the edge features of roads often cannot be accurately constructed due to the lack of semantic guidance. To address the aforementioned issues, this study developed a hybrid deep neural network integrating CNN and Transformer structures. In the encoder, a multiscale global attention pyramid (MGAP) is constructed to enhance the overall semantic representation of the road with a local context. The road edge perceptron is designed in the decoder to improve edge prediction accuracy by establishing hierarchical spatial attention. Quantitative experiments and visual analysis on two public road datasets have confirmed that the proposed network architecture and modules can improve road extraction accuracy with high efficiency (achieving an average 71% IOU and 83% F1 score).  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yuan2024Multiscale
ER  -

TY  - JOUR
AU  - He, X.
AU  - Zhou, Y.
AU  - Liu, B.
AU  - Zhao, J.
AU  - Yao, R.
TI  - Remote sensing image semantic segmentation via class-guided structural interaction and boundary perception
PY  - 2024
T2  - Expert Systems with Applications
VL  - 252
C7  - 124019
DO  - 10.1016/j.eswa.2024.124019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193604650&doi=10.1016%2fj.eswa.2024.124019&partnerID=40&md5=07e77fb1e212c21dcbaed926b7418284
AB  - Existing remote sensing semantic segmentation methods generally ignore the structural information of objects that is vital in the human visual recognition system. The absence of overall structural information often results in weak perceptions of subtle textures and fragmented predictions, especially for complex and variable ground object scenarios. Besides, they still suffer from the semantic ambiguity caused by the unclear object boundary features in remote sensing images. In this paper, we propose a novel remote sensing semantic segmentation framework, called CSBNet, which aims to enhance the capacity of class-guided structural interaction and boundary perception simultaneously. It consists of a class-guided structure interaction module (CSIM), a Transformer-based context aggregation module (TCAM) and a class-guided boundary supervision module (CBSM). The CSIM has the ability to progressively extract the class-specific structural features, i.e., refining the structural information of each class by iteratively exchanging information between initial coarse class tokens and contexts. Meanwhile, the TCAM is constructed to provide CSIM with more discriminative multi-scale contexts without losing spatial features. In particular, the CBSM plays an auxiliary role, which applies the boundary information obtained from the class tokens to supervise the segmentation of boundary regions. When tested on the ISPRS dataset, LoveDA dataset, UAVid dataset, our method significantly outperforms the state-of-the-art remote sensing semantic segmentation approaches. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - He2024Remote
ER  -

TY  - JOUR
AU  - Babaali, M.
AU  - Fatemi, A.
AU  - Ali Nematbakhsh, M.
TI  - Aspect extraction with enriching word representation and post-processing rules
PY  - 2024
T2  - Expert Systems with Applications
VL  - 252
C7  - 124174
DO  - 10.1016/j.eswa.2024.124174
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193900513&doi=10.1016%2fj.eswa.2024.124174&partnerID=40&md5=1135fea4ce0e673d2699faf246faa952
AB  - The detection of mentioned aspects in product reviews is one of the significant and complex tasks in opinion mining. Recently, contextual-based approaches have significantly improved the accuracy of aspect extraction over non-contextual embeddings. However, these approaches are often computationally expensive and time-consuming; thus, applying such heavy models with insufficient resources and within runtime systems is impractical in many realistic scenarios. The present investigation sought an efficient, practical deep-learning-based model that relies on the complementary power of various existing non-contextual embeddings. In this regard, two morphology-based (character and FastText) and two syntax-based (POS and extended dependency skip-gram) embeddings were used alongside a base word embedding (GloVe) to form an enriched word representation layer. The presented model was integrated into the proposed network architecture (extended BiGRU). Finally, two novel post-processing rules were applied to refine the errors in the model's predictions. The proposed model achieved F-scores of 0.86, 0.91, 0.79, and 0.80 for the SemEval 2014 laptop domain and the SemEval 2015–2016 restaurant domain, respectively. Furthermore, the results were validated by comparing the computational and temporal efficiency of the proposed model with seven BERT-family transformers through statistical tests. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Babaali2024Aspect
ER  -

TY  - JOUR
AU  - Alsuhaibani, M.
AU  - Dodge, H.H.
AU  - Mahoor, M.H.
TI  - Mild cognitive impairment detection from facial video interviews by applying spatial-to-temporal attention module
PY  - 2024
T2  - Expert Systems with Applications
VL  - 252
C7  - 124185
DO  - 10.1016/j.eswa.2024.124185
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193504335&doi=10.1016%2fj.eswa.2024.124185&partnerID=40&md5=23102528f411950d7503422dc0649a13
AB  - Early detection of Mild Cognitive Impairment (MCI) leads to early interventions to slow the progression from MCI into dementia. Deep Learning (DL) algorithms could help achieve early non-invasive and low-cost detection of MCI. This paper presents the detection of MCI in older adults using DL models based only on facial features extracted from video-recorded conversations at home. We used the data collected from the I-CONECT behavioral intervention study (NCT02871921), where several sessions of semi-structured interviews between socially isolated older individuals and interviewers were video recorded. We develop a framework that extracts holistic spatial facial features using a convolutional autoencoder and temporal information using transformers. We proposed the Spatial-to-Temporal Attention Module (STAM) to detect the I-CONECT study participants’ cognitive conditions (MCI vs. those with normal cognition (NC)) using facial and interaction features. The interaction features of the facial features improved the prediction performance compared with applying facial features solely. The detection accuracy using this combined method reached 88%, whereas the accuracy without applying the segments and sequences information of the facial features within a video on a certain theme was 84%. Overall, the results show that spatiotemporal facial features modeled using DL algorithms have a discriminating power for the detection of MCI. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Alsuhaibani2024Mild
ER  -

TY  - JOUR
AU  - Fu, J.
AU  - Zhang, X.
AU  - Wang, Y.
AU  - Zeng, W.
AU  - Zheng, N.
TI  - Understanding mobile GUI: From pixel-words to screen-sentences
PY  - 2024
T2  - Neurocomputing
VL  - 601
C7  - 128200
DO  - 10.1016/j.neucom.2024.128200
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199295931&doi=10.1016%2fj.neucom.2024.128200&partnerID=40&md5=bbbd62971e986f90893bb2b8340c0e0c
AB  - The ubiquity of mobile phones makes mobile GUI understanding an important task. Most previous works in this domain require human-created metadata of screens (e.g. View Hierarchy) during inference, which unfortunately is often not available or reliable enough for GUI understanding. Inspired by the impressive success of Transformers in NLP tasks, targeting for purely vision-based GUI understanding, we extend the concepts of Words/Sentence to Pixel-Words/Screen-Sentence, and propose a mobile GUI understanding architecture: Pixel-Words to Screen-Sentence (PW2SS). In analogy to the individual Words, we define the Pixel-Words as atomic visual components (text and graphic components), which are visually consistent and semantically clear across screenshots of a large variety of design styles. The Pixel-Words extracted from a screenshot are aggregated into Screen-Sentence with a Screen Transformer proposed to model their relations. Since the Pixel-Words are defined as atomic visual components, the ambiguity between their visual appearance and semantics is dramatically reduced. We are able to make use of metadata available in training data to auto-generate high-quality annotations for Pixel-Words. A dataset, RICO-PW, of screenshots with Pixel-Words annotations is built based on the public RICO dataset, which will be released to help to address the lack of high-quality training data in this area. We train a detector to extract Pixel-Words from screenshots on this dataset and achieve metadata-free GUI understanding during inference. We conduct experiments and show that Pixel-Words can be well extracted on RICO-PW and well generalized to a new dataset, P2S-UI, collected by ourselves. The effectiveness of PW2SS is further verified in the GUI understanding tasks including relation prediction, clickability prediction, screen retrieval, and app type classification. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Fu2024Understanding
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Fang, F.
AU  - Liu, L.
AU  - Chen, K.
AU  - Du, Y.
TI  - Prediction of drug targets related to HCC metastasis from the perspective of programmed cell death based on transformer
PY  - 2024
T2  - Future Generation Computer Systems
VL  - 160
SP  - 918
EP  - 925
DO  - 10.1016/j.future.2024.06.053
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197661309&doi=10.1016%2fj.future.2024.06.053&partnerID=40&md5=8d8dfca6e2f9878c677eb21d2e04e758
AB  - Hepatocellular carcinoma (HCC) ranks as the sixth most prevalent cancer globally and the third leading cause of cancer-related deaths. The early diagnosis of HCC is challenging, and its propensity for metastasis results in generally poor prognosis. Existing studies have demonstrated a close association between HCC metastasis and programmed cell death (PCD). However, due to the high-dimensional, high-order nonlinear interactions and complex regulatory mechanisms of genes, establishing the biological process from genes to PCD to HCC metastasis through biological experiments is difficult. These genes represent crucial drug targets for blocking HCC progression. Deep learning technologies, particularly Transformer models, have shown great potential in analyzing clinical and genetic data in oncology. In this study, we identified 147 key genes related to PCD that are closely associated with HCC metastasis and developed a Transformer-based predictive model for HCC metastasis. To elucidate the potential of these genes as drug targets, we first investigated the impact of various types of PCD on the pathophysiology of HCC. Subsequently, we validated the drug responses of different patients through immunoassays and drug sensitivity tests. Finally, survival analysis indicated that these genes significantly affect patient survival rates. In summary, we have identified numerous drug targets influencing HCC metastasis through PCD. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Huang2024Prediction
ER  -

TY  - JOUR
AU  - Wang, M.
AU  - Li, Z.
AU  - Wang, J.
AU  - Zou, W.
AU  - Zhou, J.
AU  - Gan, J.
TI  - TracKGE: Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 301
C7  - 112218
DO  - 10.1016/j.knosys.2024.112218
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199790433&doi=10.1016%2fj.knosys.2024.112218&partnerID=40&md5=6c1dfc3e03bcc7fc0c46a5b571952a12
AB  - Knowledge Graphs, fundamental to intelligent applications, are increasingly critical in various domains, enhancing tasks like precise searching and personalized recommendation. Effectively representing entities and relationships in these graphs is key, especially as the Transformer model, despite its representational prowess, faces challenges in adapting to the graph's structure and complex relations. In this work, we present the Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding (TracKGE). Specifically, TracKGE transforms the structural information of the knowledge graph into a sequence format that is more manageable for Transformers. In addition, we employ a relation-pattern adaptive contrastive learning module to capture a richer semantic and complex relationship pattern information of the knowledge graph. Lastly, by introducing a mask node model, it addresses the issue of incomplete information in the knowledge graph, further enhancing the model's capability to capture implicit relationships within it. To evaluate the performance of our model, we have chosen well-established models as baselines and executed link prediction tasks on four renowned datasets. Our experimental results reveal that our model excels in representing the semantics and intricate structures of Knowledge Graphs. It outperforms other advanced baseline models, showcasing its superior capability in handling complex data representations. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Wang2024TracKGE
ER  -

TY  - JOUR
AU  - Hasan, M.J.
AU  - Rafat, K.
AU  - Rahman, F.
AU  - Mohammed, N.
AU  - Rahman, S.
TI  - DeepMarkerNet: Leveraging supervision from the Duchenne Marker for spontaneous smile recognition
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 186
SP  - 148
EP  - 155
DO  - 10.1016/j.patrec.2024.09.015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205692232&doi=10.1016%2fj.patrec.2024.09.015&partnerID=40&md5=4d0309492968c2d62222d149f5ac1579
AB  - Distinguishing between spontaneous and posed smiles from videos poses a significant challenge in pattern classification literature. Researchers have developed feature-based and deep learning-based solutions for this problem. To this end, deep learning outperforms feature-based methods. However, certain aspects of feature-based methods could improve deep learning methods. For example, previous research has shown that Duchenne Marker (or D-Marker) features from the face play a vital role in spontaneous smiles, which can be useful to improve deep learning performances. In this study, we propose a deep learning solution that leverages D-Marker features to improve performance further. Our multi-task learning framework, named DeepMarkerNet, integrates a transformer network with the utilization of facial D-Markers for accurate smile classification. Unlike past methods, our approach simultaneously predicts the class of the smile and associated facial D-Markers using two different feed-forward neural networks, thus creating a symbiotic relationship that enriches the learning process. The novelty of our approach lies in incorporating supervisory signals from the pre-calculated D-Markers (instead of as input in previous works), harmonizing the loss functions through a weighted average. In this way, our training utilizes the benefits of D-Markers, but the inference does not require computing the D-Marker. We validate our model's effectiveness on four well-known smile datasets: UvA-NEMO, BBC, MMI facial expression, and SPOS datasets, and achieve state-of-the-art results. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hasan2024DeepMarkerNet
ER  -

TY  - JOUR
AU  - Yan, W.
AU  - Cao, H.
AU  - Chen, J.
AU  - Wu, T.
TI  - FETR: Feature Transformer for vehicle-infrastructure cooperative 3D object detection
PY  - 2024
T2  - Neurocomputing
VL  - 600
C7  - 128147
DO  - 10.1016/j.neucom.2024.128147
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197780092&doi=10.1016%2fj.neucom.2024.128147&partnerID=40&md5=60c089ed4732c04af585103fbb9af19d
AB  - 3D object detection plays a crucial role in the perception system of autonomous vehicles, however, the vehicle's field of view is restricted due to obstructions from nearby vehicles and buildings. Vehicle-infrastructure cooperation can compensate for the issue of visibility, but due to discrepancies in timestamps between vehicle and infrastructure sensors as well as data transmission delays, there is typically a time asynchrony between vehicle and infrastructure data. Therefore, Feature Transformer (FETR) has been introduced, which is a vehicle-infrastructure cooperative 3D object detection model utilizing Transformer as a Feature Predictor. The Transformer Predictor is capable of predicting features of future frame based on the current frame features, efficiently addressing the problem of time asynchrony. Additionally, to enhance the precision of 3D object detection, we have introduced a plug-and-play module named Mask Feature Enhancement (MFE), MFE employs a mask to amplify the features in the object region while simultaneously diminishing the features of the surrounding environment, enlarging the difference between object features and environmental features, thereby improving the detection effect. Experimental results show that FETR attains a 68.15 BEV-mAP (IoU=0.5) on the DAIR-V2X dataset, with a 200ms latency, and the data transmission is merely 6.0×104 bytes, constituting just 4.2% of the original point cloud data, outperforming current vehicle-infrastructure cooperative models in terms of both precision and data transmission. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yan2024FETR
ER  -

TY  - JOUR
AU  - Kilimci, Z.H.
AU  - Yalcin, M.
TI  - ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 156
C7  - 102951
DO  - 10.1016/j.artmed.2024.102951
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201605596&doi=10.1016%2fj.artmed.2024.102951&partnerID=40&md5=2067d4413c02f4412c28c687478f28d2
AB  - Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify ACPs for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBERT, BioBERT, and SciBERT are employed to detect ACPs from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the literature studies. The proposed framework, ESM, exhibits 96.45% of accuracy for AntiCp2 dataset, 97.66% of accuracy for cACP-DeepGram dataset, and 88.51% of accuracy for ACP-740 dataset, thence determining new state-of-the-art. The code of proposed framework is publicly available at github (https://github.com/mstf-yalcin/acp-esm). © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Kilimci2024ACP-ESM
ER  -

TY  - JOUR
AU  - Gao, L.
AU  - Zhang, H.
AU  - Liu, Y.
AU  - Sheng, N.
AU  - Feng, H.
AU  - Xu, H.
TI  - PGCL: Prompt guidance and self-supervised contrastive learning-based method for Visual Question Answering
PY  - 2024
T2  - Expert Systems with Applications
VL  - 251
C7  - 124011
DO  - 10.1016/j.eswa.2024.124011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190991880&doi=10.1016%2fj.eswa.2024.124011&partnerID=40&md5=89a61b996467312c1edece5f39a8aa01
AB  - Recent works have demonstrated the efficacy of Chain-of-Thought (CoT), which comprises multimodal information, in multiple complex reasoning tasks. CoT, involving multiple stages of reasoning, has also been applied to Visual Question Answering (VQA) for scientific questions. Existing research on CoT in science-oriented VQA primarily concentrates on the extraction and integration of visual and textual information. However, they overlook the fact that image-question pairs, categorized by different attributes (such as subject, topic, category, skill, grade, and difficulty), emphasize distinct text information, visual information, and reasoning capabilities. Therefore, this work proposes a novel VQA method termed PGCL, founded on the prompt guidance strategy and self-supervised contrastive learning. PGCL strategically excavates and integrates text and visual information based on attribute information. Specifically, two prompt templates are first crafted. They are subsequently combined with the attribution information and the interference information of image-question pairs to generate a series of prompt positive and prompt negative samples respectively. The mining of visual and text representations is then guided by constructed prompts. These prompt-guided representations are integrated and enhanced via transformer architecture and self-supervised contrastive learning. The fused features are eventually learned to predict answers for VQA. Sufficient experiments have convincingly substantiated the individual contributions of the components within PGCL, as well as the performance of PGCL. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Gao2024PGCL
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Mei, J.
AU  - Li, X.
AU  - Lu, Y.
AU  - Yu, Q.
AU  - Wei, Q.
AU  - Luo, X.
AU  - Xie, Y.
AU  - Adeli, E.
AU  - Wang, Y.
AU  - Lungren, M.P.
AU  - Zhang, S.
AU  - Xing, L.
AU  - Lu, L.
AU  - Yuille, A.
AU  - Zhou, Y.
TI  - TransUNet: Rethinking the U-Net architecture design for medical image segmentation through the lens of transformers
PY  - 2024
T2  - Medical Image Analysis
VL  - 97
C7  - 103280
DO  - 10.1016/j.media.2024.103280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200251767&doi=10.1016%2fj.media.2024.103280&partnerID=40&md5=2ef9d0fa530d482b5993ddccd20c8900
AB  - Medical image segmentation is crucial for healthcare, yet convolution-based methods like U-Net face limitations in modeling long-range dependencies. To address this, Transformers designed for sequence-to-sequence predictions have been integrated into medical image segmentation. However, a comprehensive understanding of Transformers’ self-attention in U-Net components is lacking. TransUNet, first introduced in 2021, is widely recognized as one of the first models to integrate Transformer into medical image analysis. In this study, we present the versatile framework of TransUNet that encapsulates Transformers’ self-attention into two key modules: (1) a Transformer encoder tokenizing image patches from a convolution neural network (CNN) feature map, facilitating global context extraction, and (2) a Transformer decoder refining candidate regions through cross-attention between proposals and U-Net features. These modules can be flexibly inserted into the U-Net backbone, resulting in three configurations: Encoder-only, Decoder-only, and Encoder+Decoder. TransUNet provides a library encompassing both 2D and 3D implementations, enabling users to easily tailor the chosen architecture. Our findings highlight the encoder's efficacy in modeling interactions among multiple abdominal organs and the decoder's strength in handling small targets like tumors. It excels in diverse medical applications, such as multi-organ segmentation, pancreatic tumor segmentation, and hepatic vessel segmentation. Notably, our TransUNet achieves a significant average Dice improvement of 1.06% and 4.30% for multi-organ segmentation and pancreatic tumor segmentation, respectively, when compared to the highly competitive nn-UNet, and surpasses the top-1 solution in the BrasTS2021 challenge. 2D/3D Code and models are available at https://github.com/Beckschen/TransUNet and https://github.com/Beckschen/TransUNet-3D, respectively. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:C期刊; 
LB  - Chen2024TransUNet
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Zhang, X.
AU  - Li, L.
AU  - Wang, X.
AU  - Cheng, J.
AU  - Gao, C.
AU  - Ling, J.
TI  - An estimation method for multidimensional urban street walkability based on panoramic semantic segmentation and domain adaptation
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 136
C7  - 108905
DO  - 10.1016/j.engappai.2024.108905
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197749737&doi=10.1016%2fj.engappai.2024.108905&partnerID=40&md5=8f5f1445ce4da8a927f9046d99004f48
AB  - Urban walkability is a critical aspect of urban planning. Since the traditional measurement methods constrained by cost, time, and scalability researchers have turned to computer-assisted audits based on Panoramic Street View Images (PSVIs). However overlook image distortion and data annotation issues, impacting predictive accuracy. Current evaluations often lack a holistic approach, making comparison challenging. In response, a multidimensional evaluation approach is proposed through three indices: street red quality, physical walkability, and perceived walkability. To enhance accuracy, a Transformer-based Doubly Deformable Panoramic semantic segmentation Network (TDDPassNet) is introduced to calculate key metrics informing ecological quality and spatial layout evaluations. An unsupervised domain adaptation method is proposed for insufficient labeled data. Furthermore, a Geographic Information System (GIS) analysis was conducted to assess the physical walkability index. Human–machine adversarial technology and a random forest model evaluate the perceived walkability index. A comprehensive evaluation framework is presented using the Analytic Hierarchy Process to assign weights to assessment indices across the three dimensions. A case study was conducted in Lijiang City, China, to demonstrate the practical application of the methodology. Extensive experiments are conducted, TDDPassNet exhibits an average increase of 5.3% in mIoU across diverse datasets compared to the prevailing models. This study evaluated 47,758 sampling sites, providing insights into urban planning and development in similar contexts © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024estimation
ER  -

TY  - JOUR
AU  - Zhao, R.
AU  - Xi, Z.
AU  - Liu, H.
AU  - Jian, X.
AU  - Zhang, J.
AU  - Zhang, Z.
AU  - Li, S.
TI  - MIST: Multi-instance selective transformer for histopathological subtype prediction
PY  - 2024
T2  - Medical Image Analysis
VL  - 97
C7  - 103251
DO  - 10.1016/j.media.2024.103251
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197357893&doi=10.1016%2fj.media.2024.103251&partnerID=40&md5=96e89dae9eb7ddea6ad087e0f0d3d52c
AB  - Accurate histopathological subtype prediction is clinically significant for cancer diagnosis and tumor microenvironment analysis. However, achieving accurate histopathological subtype prediction is a challenging task due to (1) instance-level discrimination of histopathological images, (2) low inter-class and large intra-class variances among histopathological images in their shape and chromatin texture, and (3) heterogeneous feature distribution over different images. In this paper, we formulate subtype prediction as fine-grained representation learning and propose a novel multi-instance selective transformer (MIST) framework, effectively achieving accurate histopathological subtype prediction. The proposed MIST designs an effective selective self-attention mechanism with multi-instance learning (MIL) and vision transformer (ViT) to adaptive identify informative instances for fine-grained representation. Innovatively, the MIST entrusts each instance with different contributions to the bag representation based on its interactions with instances and bags. Specifically, a SiT module with selective multi-head self-attention (S-MSA) is well-designed to identify the representative instances by modeling the instance-to-instance interactions. On the contrary, a MIFD module with the information bottleneck is proposed to learn the discriminative fine-grained representation for histopathological images by modeling instance-to-bag interactions with the selected instances. Substantial experiments on five clinical benchmarks demonstrate that the MIST achieves accurate histopathological subtype prediction and obtains state-of-the-art performance with an accuracy of 0.936. The MIST shows great potential to handle fine-grained medical image analysis, such as histopathological subtype prediction in clinical applications. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2024MIST
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Zhang, L.
AU  - Ren, L.
TI  - Semi-supervised medical image segmentation via cross teaching between MobileNet and MobileViT
PY  - 2024
T2  - Image and Vision Computing
VL  - 150
C7  - 105196
DO  - 10.1016/j.imavis.2024.105196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200636704&doi=10.1016%2fj.imavis.2024.105196&partnerID=40&md5=fda2ac9a52e12ac5bf1c59fca2e65e45
AB  - Recently, deep learning methods that use a combination of convolutional neural networks and Transformers have shown excellent results in both completely supervised and semi-supervised medical image segmentation tasks. This study provides a simple and effective framework for semi-supervised medical image segmentation by introducing cross teaching between MobileNet and MobileViT. Specifically, we built two different two-path parallel semantic segmentation networks with MobileNet and MobileViT as the main modules. Cross teaching between MobileNet and MobileViT was performed, in which the prediction of each network was used as a pseudo-label to supervise the training of other networks in a direct end-to-end manner. Finally, experiments on two common benchmark tests showed that the proposed framework was superior to six existing semi-supervised learning methods. This shows that our framework can effectively use unlabeled data to improve the performance and is superior to the latest semi-supervised segmentation method. Codes are available at: github.com/yywbkn/MV2-cross-teaching-MobileViT. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Semi-supervised
ER  -

TY  - JOUR
AU  - Zhang, M.
AU  - Hu, H.
AU  - Li, Z.
TI  - Multi-granularity transformer fusion for temporal action localization
PY  - 2024
T2  - Soft Computing
VL  - 28
IS  - 20
SP  - 12377
EP  - 12388
DO  - 10.1007/s00500-024-09955-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198975290&doi=10.1007%2fs00500-024-09955-x&partnerID=40&md5=26919043754c4ec6b9de2f276489a6ca
AB  - Temporal action localization plays a significant role in video understanding, which aims to recognize action category as well as temporal interval in untrimmed videos. Most of previous transformer-based methods employ a feature space of single-temporal granularity. However, low-level temporal features can not provide enough semantic information for action recognition while high-level temporal features lack rich details for boundary localization. To address the above issue, we propose a multi-granularity transformer fusion framework (MGTF) to localize temporal actions in videos. Specifically, the MGTF builds a multi-granularity feature fusion pipeline based on transformer, and uses a direct set prediction strategy to generate action instances. Through top-down cross-granularity attention interaction, the low-level features of boundary details and high-level semantic information can be combined to improve the feature discrimination. To reduce computation cost, we design temporal shift attention to adaptively focus on a sparse set of key segments. In addition, actionness regression head is utilized to refine the confidence score of different candidate instances. As a self-contained system, MGTF achieves state-of-the-art performance on THUMOS’14 and comparable performance on ActivityNet-1.3. Ablation studies and qualitative visualization also demonstrate the effectiveness of the proposed approach. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2024Multi-granularity
ER  -

TY  - JOUR
AU  - Basak, S.
AU  - Gautam, A.
TI  - Diffusion-based normality pre-training for weakly supervised video anomaly detection
PY  - 2024
T2  - Expert Systems with Applications
VL  - 251
C7  - 124013
DO  - 10.1016/j.eswa.2024.124013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191016608&doi=10.1016%2fj.eswa.2024.124013&partnerID=40&md5=72982ba234cab5a41df4acaa6294700a
AB  - Weakly supervised video anomaly detection is the task of detecting anomalous frames in videos where no frame-level labels are provided at training phase. Previous methods usually employed a multiple instance learning (MIL)-based ranking loss to ensure inter-class separation. However, these methods are unable to completely utilise the information from the huge amounts of normal frames. Moreover, the performance of these methods is misguided by the erroneous initial prediction of the MIL-based classifier. Taking these shortcomings into consideration, we propose a diffusion-based normality learning pretrain step, which first involves training a Global–Local Feature Encoder (GLFE) model with only normal videos to understand the feature distribution of normal frames. The resulting pre-trained Global–Local feature encoder is further optimised using Multi-Sequence Contrastive loss using both normal and anomalous videos. Our proposed GLFE model captures long- and short-range temporal features using a Transformer block and pyramid of dilated convolutions in a two-branch setup. The model adaptively learns the relation between the two branch features by introducing the Co-Attention module, which provides a learnable fusion of features. Additionally we introduced a triplet contrastive loss to provide better separation between abnormal and normal frames in anomalous videos. The developed methodology is evaluated through extensive experiments on two public benchmark datasets (UCF-Crime and ShanghaiTech). The results obtained are comparable to or better than the existing state-of-the-art weakly supervised methods. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Basak2024Diffusion-based
ER  -

TY  - JOUR
AU  - Bai, J.
AU  - Fan, Y.
AU  - Zhao, Z.
TI  - Discrete codebook collaborating with transformer for thangka image inpainting
PY  - 2024
T2  - Multimedia Systems
VL  - 30
IS  - 5
C7  - 238
DO  - 10.1007/s00530-024-01439-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200685071&doi=10.1007%2fs00530-024-01439-0&partnerID=40&md5=4572afcf6286626381fc1d13999500c5
AB  - Thangka, as a precious heritage of painting art, holds irreplaceable research value due to its richness in Tibetan history, religious beliefs, and folk culture. However, it is susceptible to partial damage and form distortion due to natural erosion or inadequate conservation measures. Given the complexity of textures and rich semantics in thangka images, existing image inpainting methods struggle to recover their original artistic style and intricate details. In this paper, we propose a novel approach combining discrete codebook learning with a transformer for image inpainting, tailored specifically for thangka images. In the codebook learning stage, we design an improved network framework based on vector quantization (VQ) codebooks to discretely encode intermediate features of input images, yielding a context-rich discrete codebook. The second phase introduces a parallel transformer module based on a cross-shaped window, which efficiently predicts the index combinations for missing regions under limited computational cost. Furthermore, we devise a multi-scale feature guidance module that progressively fuses features from intact areas with textural features from the codebook, thereby enhancing the preservation of local details in non-damaged regions. We validate the efficacy of our method through qualitative and quantitative experiments on datasets including Celeba-HQ, Places2, and a custom thangka dataset. Experimental results demonstrate that compared to previous methods, our approach successfully reconstructs images with more complete structural information and clearer textural details. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Bai2024Discrete
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Zhou, L.
AU  - Wang, H.
TI  - Multi-scale feature correspondence and pseudo label retraining strategy for weakly supervised semantic segmentation
PY  - 2024
T2  - Image and Vision Computing
VL  - 150
C7  - 105215
DO  - 10.1016/j.imavis.2024.105215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201717685&doi=10.1016%2fj.imavis.2024.105215&partnerID=40&md5=73c78470188c4a90265373c102af3420
AB  - Recently, the performance of semantic segmentation using weakly supervised learning has significantly improved. Weakly supervised semantic segmentation (WSSS) that uses only image-level labels has received widespread attention, it employs Class Activation Maps (CAM) to generate pseudo labels. Compared to traditional use of pixel-level labels, this technique greatly reduces annotation costs by utilizing simpler and more readily available image-level annotations. Besides, due to the local perceptual ability of Convolutional Neural Networks (CNN), the generated CAM cannot activate the entire object area. Researchers have found that this CNN limitation can be compensated for by using Vision Transformer (ViT). However, ViT also introduces an over-smoothing problem. Recent research has made good progress in solving this issue, but when discussing CAM and its related segmentation predictions, it is easy to overlook their intrinsic information and the interrelationships between them. In this paper, we propose a Multi-Scale Feature Correspondence (MSFC) method. Our MSFC can obtain the feature correspondence of CAM and segmentation predictions at different scales, re-extract useful semantic information from them, enhancing the network's learning of feature information and improving the quality of CAM. Moreover, to further improve the segmentation precision, we design a Pseudo Label Retraining Strategy (PLRS). This strategy refines the accuracy in local regions, elevates the quality of pseudo labels, and aims to enhance segmentation precision. Experimental results on the PASCAL VOC 2012 and MS COCO 2014 datasets show that our method achieves impressive performance among end-to-end WSSS methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Multi-scale
ER  -

TY  - JOUR
AU  - Chu, M.
AU  - De Maria, G.L.
AU  - Dai, R.
AU  - Benenati, S.
AU  - Yu, W.
AU  - Zhong, J.
AU  - Kotronias, R.
AU  - Walsh, J.
AU  - Andreaggi, S.
AU  - Zuccarelli, V.
AU  - Chai, J.
AU  - Channon, K.
AU  - Banning, A.
AU  - Tu, S.
TI  - DCCAT: Dual-Coordinate Cross-Attention Transformer for thrombus segmentation on coronary OCT
PY  - 2024
T2  - Medical Image Analysis
VL  - 97
C7  - 103265
DO  - 10.1016/j.media.2024.103265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199006048&doi=10.1016%2fj.media.2024.103265&partnerID=40&md5=86f7a62c9c6a2e5f77e7d8363a7b77ee
AB  - Acute coronary syndromes (ACS) are one of the leading causes of mortality worldwide, with atherosclerotic plaque rupture and subsequent thrombus formation as the main underlying substrate. Thrombus burden evaluation is important for tailoring treatment therapy and predicting prognosis. Coronary optical coherence tomography (OCT) enables in-vivo visualization of thrombus that cannot otherwise be achieved by other image modalities. However, automatic quantification of thrombus on OCT has not been implemented. The main challenges are due to the variation in location, size and irregularities of thrombus in addition to the small data set. In this paper, we propose a novel dual-coordinate cross-attention transformer network, termed DCCAT, to overcome the above challenges and achieve the first automatic segmentation of thrombus on OCT. Imaging features from both Cartesian and polar coordinates are encoded and fused based on long-range correspondence via multi-head cross-attention mechanism. The dual-coordinate cross-attention block is hierarchically stacked amid convolutional layers at multiple levels, allowing comprehensive feature enhancement. The model was developed based on 5,649 OCT frames from 339 patients and tested using independent external OCT data from 548 frames of 52 patients. DCCAT achieved Dice similarity score (DSC) of 0.706 in segmenting thrombus, which is significantly higher than the CNN-based (0.656) and Transformer-based (0.584) models. We prove that the additional input of polar image not only leverages discriminative features from another coordinate but also improves model robustness for geometrical transformation.Experiment results show that DCCAT achieves competitive performance with only 10% of the total data, highlighting its data efficiency. The proposed dual-coordinate cross-attention design can be easily integrated into other developed Transformer models to boost performance. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chu2024DCCAT
ER  -

TY  - JOUR
AU  - Tong, X.
AU  - Song, J.
AU  - Li, W.
AU  - Xu, C.
TI  - Penetration game strategy of high dynamic vehicles with constraints of No-fly zones and interceptors
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 136
C7  - 109018
DO  - 10.1016/j.engappai.2024.109018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199947899&doi=10.1016%2fj.engappai.2024.109018&partnerID=40&md5=29b589c95707dfea6341b96f68ffed73
AB  - This study investigates the penetration game strategy of the high dynamic vehicle against high-velocity interceptors in environments with multiple static no-fly zones. The primary issue addressed is the deficiency in control precision and the inadequacy of control margin under conditions of complex multi-constraint coupling. Firstly, an enhanced artificial potential field method is devised for the lateral penetration guidance strategy of high dynamic vehicles, which includes a predictive repulsion potential field, a buffer zone and new potential field functions. This approach not only averts trajectory oscillations caused by heading judgment ambiguity in the tangent direction of the obstacle area, but also significantly mitigates the inherent conflict between obstacle avoidance and target reachability. Secondly, considering the potential failure of the lateral penetration guidance strategy due to the high-velocity maneuvering of interceptors and detection sensor errors of the high dynamic vehicle, this paper initially designs a Kalman filter to denoise the detection information and provide a single-step optimal estimate. Subsequently, a multi-step state predictor based on the Transformer network is proposed, which obtains its future multi-step early warning information from the denoised detection historical data and refines it based on three-dimensional geometry knowledge. Then, the combination of the filtered estimate and the refined early warning information substantially enhances the success rate of the high dynamic vehicle in game confrontations with the high-velocity interceptors. Lastly, the numerical simulations are conducted to verify the effectiveness and performance of the penetration game guidance strategy. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tong2024Penetration
ER  -

TY  - JOUR
AU  - He, Y.
AU  - Qin, Y.
AU  - Chen, L.
AU  - Zhang, P.
AU  - Ben, X.
TI  - Efficient abnormal behavior detection with adaptive weight distribution
PY  - 2024
T2  - Neurocomputing
VL  - 600
C7  - 128187
DO  - 10.1016/j.neucom.2024.128187
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198558537&doi=10.1016%2fj.neucom.2024.128187&partnerID=40&md5=5fb9fa64438eaa6accbb35334f837ec0
AB  - In recent years, there has been notable progress of recognizing and detecting human abnormal behavior in the field of computer vision. However, it remains an exceptionally difficult task due to serious background interference in surveillance videos, multi-scale variations, inter-target occlusions, and constraints on real-time performance. To address these problems, this paper proposes a new framework called efficient abnormal behavior detection (EABD) that simultaneously integrates spatio-temporal feature modeling and long-term dependency modeling. Then we introduce a new block for adaptive weight distribution to avoid noise interference. Meanwhile, we incorporate the detection head with attention and the SIoU loss function to improve network performance for detecting targets at various scales. Finally, the SoftNMS strategy is employed to enhance the prediction effect for overlapping objects of specific video frames in the inference stage. We conduct extensive experiments on four benchmark datasets, i.e., UCSD Ped1, UCSD Ped2, ShanghaiTech, and CUHK Avenue datasets. Our proposed EABD achieves AUC of 97.8%, 98.7%, 86.7%, and 95.4%, respectively. The experimental results show superiority over other related methods and demonstrate the effectiveness of our proposed method. Additionally, it achieves a maximum inference speed of 71.9 fps. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - He2024Efficient
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Li, M.
AU  - Yan, H.
TI  - Utilizing motion segmentation for optimizing the temporal adjacency matrix in 3D human pose estimation
PY  - 2024
T2  - Neurocomputing
VL  - 600
C7  - 128153
DO  - 10.1016/j.neucom.2024.128153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198089147&doi=10.1016%2fj.neucom.2024.128153&partnerID=40&md5=1d5acbb8db67a12dc97429b2a41d8ddf
AB  - In monocular 3D human pose estimation, modeling the temporal relation of human joints is crucial for prediction accuracy. Currently, most methods utilize transformer to model the temporal relation among joints. However, existing transformer-based methods have limitations. The temporal adjacency matrix utilized within the self-attention of the temporal transformer inaccurately models the temporal relationships between frames, particularly in cases where distinct motions exhibit significant correlation despite having different physical interpretations and large temporal spans. To address this issue, we construct an artificial temporal adjacency matrix based on input data and introduce a temporal adjacency matrix hybrid module to blend this matrix with the model's inherent temporal adjacency matrix, resulting in a novel composite temporal adjacency matrix. Through extensive experiments on Human3.6M and MPI-INF-3DHP datasets using state-of-the-art methods as benchmarks, our proposed method demonstrates a maximum improvement of up to 5.6% compared to the original approach. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Utilizing
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Xin, J.
TI  - Deep learning-driven intelligent pricing model in retail: from sales forecasting to dynamic price optimization
PY  - 2024
T2  - Soft Computing
VL  - 28
IS  - 20
SP  - 12281
EP  - 12297
DO  - 10.1007/s00500-024-09937-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199856988&doi=10.1007%2fs00500-024-09937-z&partnerID=40&md5=21e1ff59559443d350a4d8dd7f3502fd
AB  - Under the wave of the digital era, the retail industry is facing unprecedented fierce competition and a rapidly changing market environment. In this context, developing smart and efficient pricing strategies has become a top priority in the industry. Faced with this challenge, traditional pricing methods are inadequate due to their slow response, insufficient adaptability to instant changes in the market, and over-reliance on historical data and human experience. In response to this urgent need, this study aims to design an intelligent pricing model rooted in deep learning to enhance the vitality and competitiveness of the retail industry. The emerging solution adopted in this article combines Temporal Fusion Transformer (TFT), Ensemble of Simplified RNNs (ES-RNN), and dynamic attention mechanisms, aiming to accurately capture and analyze complex time series data through these advanced technologies. TFT processes multivariate and multi-level data, ES-RNN technology integrates multiple simple versions of recurrent neural networks to enhance predictive power, and the dynamic attention mechanism allows the model to dynamically weight the importance of different points in the time series, thereby improving the effectiveness of feature extraction. Test experimental results on four different data sets show that our models all show excellent performance, and the accuracy of predicted product sales far exceeds traditional models. In addition, with its ability to dynamically adjust pricing, the model demonstrates excellent stability and adaptability amid market fluctuations. This research not only promotes the intelligent transformation of retail pricing strategies, but also provides a more strategic tool for enterprises to compete for market share. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Deep
ER  -

TY  - JOUR
AU  - Safdar, M.
AU  - Li, Y.F.
AU  - El Haddad, R.
AU  - Zimmermann, M.
AU  - Wood, G.
AU  - Lamouche, G.
AU  - Wanjara, P.
AU  - Zhao, Y.F.
TI  - Accelerated semantic segmentation of additively manufactured metal matrix composites: Generating datasets, evaluating convolutional and transformer models, and developing the MicroSegQ+ Tool
PY  - 2024
T2  - Expert Systems with Applications
VL  - 251
C7  - 123974
DO  - 10.1016/j.eswa.2024.123974
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190815672&doi=10.1016%2fj.eswa.2024.123974&partnerID=40&md5=a4496228dabb192ee0f46510a3b4530a
AB  - Data-driven applications are penetrating every aspect of Additive Manufacturing (AM) to enable efficient resolution of key existing challenges. One such application is semantic segmentation which automatically quantifies post-process structure data from graphic or 3D computer representations. In industrial settings, these models can expedite the development of new materials or processes. However, Additively Manufactured (AMed) materials offer unique challenges, which require new models to be developed and trained. These challenges include out-of-balance classes (e.g., defects), massive labeling efforts, and significant data preparation costs. Recent applications of semantic segmentation in AM have shown the potential of ensemble-based approaches at the expense of increased parameters and computational burden while ignoring the minority classes. In this work, we propose a reproducible method and develop an associated tool to rapidly segment and subsequently quantify industrial AMed metallographic images. First, two new datasets representing AMed materials are generated from extensive experimentation. Subsequently, state-of-the-art models from convolutional and self-attention categories are evaluated in their ability to segment the datasets of interest. Finally, a modular software tool is developed for industrial applications. The developed Microstructure Segmentation, Quantification, and Fusion (+) tool or MicroSegQ+ enables a weighted pairing of predictions from different semantic segmentation models. The pairing strategy helps to exploit the complimentary performance of convolutional and transformer models on multi-class metallographic images from a Metal Matrix Composite (MMC) material system. In addition to developing models on this MMC dataset, the proposed strategy is evaluated on an open-source metal AM dataset. We also evaluate the generalizability of the best-performing model on a second MMC dataset from a different industrial setting that shows an overall accuracy of 93 % without fine-tuning. The proposed tool enables rapid quantification under 1 min, unlike the existing semi-automatic approach that takes 1–2 h of segmentation effort on single bead cross-sections. The tool is wrapped into a single executable file for industrial deployment. The work also contributes to two annotated datasets from a direct energy deposition (DED) AM process. The datasets can be used to develop and validate new semantic segmentation models of AMed microstructures, whereas the functionality of the tool can be expanded upstream to include data and modeling steps, enabling a no-code pipeline for the industry. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Safdar2024Accelerated
ER  -

TY  - JOUR
AU  - Yu, P.
AU  - Ping, M.
AU  - Ma, J.
AU  - Cao, J.
TI  - Unsupervised Signal Anomaly Transformer method: Achieving bearing life anomaly detection without the need for failure samples
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 136
C7  - 108940
DO  - 10.1016/j.engappai.2024.108940
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199007397&doi=10.1016%2fj.engappai.2024.108940&partnerID=40&md5=db50ccf9642710787f7cc64021ba7b13
AB  - Bearings are a crucial component, whose performance and lifespan directly affect the safety and operational efficiency of the entire mechanical system. However, in the case of new components or new process bearing equipment that lack complete life-cycle data, supervised learning methods relying on labels may fail. Therefore, a specialized unsupervised anomaly detection method for bearing signals has been proposed. Drawing on the ideas of the anomaly transformer, an unsupervised signal anomaly transformer method is proposed. This method optimizes the anomaly transformer based on signal input and uses a convolutional neural network (CNN) encoder–decoder structure to encode and reconstruct signals. Given the instability of symmetric Kullback–Leibler (KL) divergence in the overlapping area of probability distributions, this method uses the Wasserstein distance to measure the distance between two distributions. Additionally, a new metric is proposed for comparing the decoder-reconstructed signal to the original signal. To verify the effectiveness of this method, an objective evaluation was conducted using simulated signals, achieving an average accuracy of 99.54%. Furthermore, the 2012 IEEE and XJTU-SY real datasets were used for subjective evaluation of anomaly detection signals. Multiple results confirm that this method has strong competitiveness in bearing signal anomaly detection, significantly improving the prediction accuracy and reliability of anomalies in bearings without full life data. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yu2024Unsupervised
ER  -

TY  - JOUR
AU  - Xia, X.
AU  - Ma, Y.
TI  - Cross-stage feature fusion and efficient self-attention for salient object detection
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 104
C7  - 104271
DO  - 10.1016/j.jvcir.2024.104271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202768172&doi=10.1016%2fj.jvcir.2024.104271&partnerID=40&md5=c72e957286fbe79de7c0ec946f6b5766
AB  - Salient Object Detection (SOD) approaches usually aggregate high-level semantics with object details layer by layer through a pyramid fusion structure. However, the progressive feature fusion mechanism may lead to gradually dilution of valuable semantics and prediction accuracy. In this work, we propose a Cross-stage Feature Fusion Network (CFFNet) for salient object detection. CFFNet consists of a Cross-stage Semantic Fusion Module (CSF), a Feature Filtering and Fusion Module (FFM), and a progressive decoder to tackle the above problems. Specifically, to alleviate the semantics dilution problem, CSF concatenates different stage backbone features and extracts multi-scale global semantics using transformer blocks. Global semantics are then distributed to corresponding backbone stages for cross-stage semantic fusion. The FFM module implements efficient self-attention-based feature fusion. Different from regular self-attention which has quadratic computational complexity. Finally, a progressive decoder is adopted to refine saliency maps. Experimental results demonstrate that CFFNet outperforms state-of-the-arts on six SOD datasets. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xia2024Cross-stage
ER  -

TY  - JOUR
AU  - Cai, L.
AU  - Chen, L.
AU  - Huang, J.
AU  - Wang, Y.
AU  - Zhang, Y.
TI  - Know your orientation: A viewpoint-aware framework for polyp segmentation
PY  - 2024
T2  - Medical Image Analysis
VL  - 97
C7  - 103288
DO  - 10.1016/j.media.2024.103288
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200272419&doi=10.1016%2fj.media.2024.103288&partnerID=40&md5=a9f2bdc3cae30e7f7198f7f7013ca57f
AB  - Automatic polyp segmentation in endoscopic images is critical for the early diagnosis of colorectal cancer. Despite the availability of powerful segmentation models, two challenges still impede the accuracy of polyp segmentation algorithms. Firstly, during a colonoscopy, physicians frequently adjust the orientation of the colonoscope tip to capture underlying lesions, resulting in viewpoint changes in the colonoscopy images. These variations increase the diversity of polyp visual appearance, posing a challenge for learning robust polyp features. Secondly, polyps often exhibit properties similar to the surrounding tissues, leading to indistinct polyp boundaries. To address these problems, we propose a viewpoint-aware framework named VANet for precise polyp segmentation. In VANet, polyps are emphasized as a discriminative feature and thus can be localized by class activation maps in a viewpoint classification process. With these polyp locations, we design a viewpoint-aware Transformer (VAFormer) to alleviate the erosion of attention by the surrounding tissues, thereby inducing better polyp representations. Additionally, to enhance the polyp boundary perception of the network, we develop a boundary-aware Transformer (BAFormer) to encourage self-attention towards uncertain regions. As a consequence, the combination of the two modules is capable of calibrating predictions and significantly improving polyp segmentation performance. Extensive experiments on seven public datasets across six metrics demonstrate the state-of-the-art results of our method, and VANet can handle colonoscopy images in real-world scenarios effectively. The source code is available at https://github.com/1024803482/Viewpoint-Aware-Network. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Cai2024Know
ER  -

TY  - JOUR
AU  - Hadid, A.
AU  - Chakraborty, T.
AU  - Busby, D.
TI  - When geoscience meets generative AI and large language models: Foundations, trends, and future challenges
PY  - 2024
T2  - Expert Systems
VL  - 41
IS  - 10
C7  - e13654
DO  - 10.1111/exsy.13654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195594534&doi=10.1111%2fexsy.13654&partnerID=40&md5=ad315f8c10cdb2debe53deddfc2ea0a6
AB  - Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This article explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain, such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modelling and uncertainty quantification. © 2024 The Author(s). Expert Systems published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Hadid2024When
ER  -

TY  - JOUR
AU  - Tuna, E.
AU  - Baykal, A.
AU  - Soysal, A.
TI  - Multivariate and multistep mobile traffic prediction with SLA constraints: A comparative study
PY  - 2024
T2  - Ad Hoc Networks
VL  - 163
C7  - 103594
DO  - 10.1016/j.adhoc.2024.103594
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198905657&doi=10.1016%2fj.adhoc.2024.103594&partnerID=40&md5=6ade6ba8da64142cca79a54eaab39401
AB  - This paper proposes a new method for predicting downlink traffic volume in mobile networks, aiming to minimize overprovisioning while meeting specified service-level agreement (SLA) violation rates. We introduce a multivariate and multi-step prediction approach and compare four machine learning (ML) architectures: long short-term memory (LSTM), convolutional neural network (CNN), transformer, and light gradient-boosting machine (LightGBM). Our models predict up to 24 steps ahead and are evaluated under both single-step and multi-step conditions. Additionally, we propose parametric loss functions to adhere to SLA violation rate constraints. Our results emphasize the importance of using parametric loss functions to meet SLA constraints. We discovered that LSTM when paired with our custom multivariate feature sets, outperforms the transformer architecture in short-term forecasting up to 4 h ahead. For these short-term predictions, we demonstrate that methods based on domain knowledge, like our custom feature sets combined with simpler models such as LSTM, surpass more complex models like transformers. However, for long-term forecasting (8 to 24 h ahead), transformers outperform all other models. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Tuna2024Multivariate
ER  -

TY  - JOUR
AU  - Huang, H.
AU  - Duan, Z.
AU  - Zhan, W.
AU  - Min, G.
AU  - Peng, K.
TI  - Optimal service caching, pricing and task partitioning in mobile edge computing federation
PY  - 2024
T2  - Future Generation Computer Systems
VL  - 159
SP  - 340
EP  - 352
DO  - 10.1016/j.future.2024.05.031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194085260&doi=10.1016%2fj.future.2024.05.031&partnerID=40&md5=30a5cbc4167ca842128f0847d567fb96
AB  - Mobile Edge Computing (MEC) federations aim to establish a joint edge service model between Edge Infrastructure Providers (EIPs) and clouds, facilitating the sharing and utilization of MEC services and resources. However, in such a hierarchical multi-EIP MEC federation environment, optimizing service caching, task partitioning, and pricing strategies to maximize the profits gained by EIPs and minimize the cost of mobile devices (MDs) is challenging. To address this challenge, This paper first formulates a two-stage multi-leader, multi-follower Stackelberg game between EIPs and MDs. Then, a new method combining a Stackelberg-based Multi-Agent Deep Deterministic Policy Gradient (STMADDPG) algorithm and a Transformer-based Popularity Prediction (TPP) model is devised to learn the optimal strategies. Extensive experiments with real-world datasets are conducted to demonstrate the excellent performance of the proposed STMADDPG-TPP method. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Huang2024Optimal
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Guo, Y.
TI  - CL-AP2: A composite learning approach to attack prediction via attack portraying
PY  - 2024
T2  - Journal of Network and Computer Applications
VL  - 230
C7  - 103963
DO  - 10.1016/j.jnca.2024.103963
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198989258&doi=10.1016%2fj.jnca.2024.103963&partnerID=40&md5=f81456d222e7bb887b519c373342f224
AB  - The capabilities of accurate prediction of cyberattacks have long been desired as detection methods cannot avoid the damages caused by occurrences of cyberattack. Attack prediction still remains an open issue especially to specify the upcoming steps of an attack with the quickly evolving intelligent techniques at the attackers’ side. This study proposes a composite learning approach (namely CL-AP2), which fulfills this task in two phases of “attack portraying” and “attack prediction”: (1) (Attack Portraying) CL-AP2 generates a Temporal Attack Knowledge Graph (TAKG) from real-time system logs providing full knowledge that formulates time-aware entities related to attacks and the relations amongst them; Over the TAKG, a Tactic-based Cyber Kill Chain (TCKC) model highlights the attacker's portrait via evaluation of behaviors in the past, i.e., presenting the tactical path and attack steps taken by the attacker; (2) (Attack Prediction) The Soft Actor–Critic algorithm applies to identify the most possible attack trajectory confined in the attack portrait; The transformer model finally derives the specific attack technique to be taken next. Experiments have been performed versus the state-of-the-art counterparts over a public dataset and results indicate that: (1) CL-AP2 can effectively reveal the tactical path taken by the attacker and form a complete portrait of the attack; and (2) CL-AP2 excels in predicting attack techniques to be taken by attackers and providing the defense guidance against the predicted attacks. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Liu2024CL-AP2
ER  -

TY  - JOUR
AU  - Tian, G.
AU  - Zhang, C.
AU  - Shi, Y.
AU  - Li, X.
TI  - MultiWaveNet: A long time series forecasting framework based on multi-scale analysis and multi-channel feature fusion
PY  - 2024
T2  - Expert Systems with Applications
VL  - 251
C7  - 124088
DO  - 10.1016/j.eswa.2024.124088
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191594225&doi=10.1016%2fj.eswa.2024.124088&partnerID=40&md5=2b0b81bffc524d979e04e274bb5ccfac
AB  - Long time series forecasting is widely used in areas such as power dispatch, traffic control, and weather forecasting. The pattern of seasonality and trends in long time series are often complex, especially when they are presented at different time scales. Existing methods typically focus on only one scale or randomly select scales, which leads to a significant loss of valuable information. Additionally, current methods often transform multi-channel data into a single-channel format, ignoring interactions and complex relationships between channels. The paper proposes MultiWaveNet, a novel long time series forecasting framework that addresses seasonality as well as trends separately. For the seasonal component, the framework uses multi-scale wavelet decomposition to generate subseries at multiple scales. A learnable optimization factor is introduced simultaneously to separate high-frequency components mixed in low-frequency series after wavelet decomposition. In order to reduce information redundancy and model complexity, the paper develops a wavelet domain sampling encoder that consists of just one Transformer encoder, ensuring effective modeling of long-term dependencies while maintaining feature extraction effectiveness. As for the trend component, unlike previous research, the weights of channels are adjusted based on their importance, allowing the more crucial channels to have a greater impact and thereby addressing the limitations of individual processing methods. The paper performs extensive experiments on nine standard datasets, demonstrating that MultiWaveNet is the most competitive method. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Tian2024MultiWaveNet
ER  -

TY  - JOUR
AU  - Cox, J.
AU  - Liu, P.
AU  - Stolte, S.E.
AU  - Yang, Y.
AU  - Liu, K.
AU  - See, K.B.
AU  - Ju, H.
AU  - Fang, R.
TI  - BrainSegFounder: Towards 3D foundation models for neuroimage segmentation
PY  - 2024
T2  - Medical Image Analysis
VL  - 97
C7  - 103301
DO  - 10.1016/j.media.2024.103301
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201141568&doi=10.1016%2fj.media.2024.103301&partnerID=40&md5=140b6765353985eb502da0bb912153a5
AB  - The burgeoning field of brain health research increasingly leverages artificial intelligence (AI) to analyze and interpret neuroimaging data. Medical foundation models have shown promise of superior performance with better sample efficiency. This work introduces a novel approach towards creating 3-dimensional (3D) medical foundation models for multimodal neuroimage segmentation through self-supervised training. Our approach involves a novel two-stage pretraining approach using vision transformers. The first stage encodes anatomical structures in generally healthy brains from the large-scale unlabeled neuroimage dataset of multimodal brain magnetic resonance imaging (MRI) images from 41,400 participants. This stage of pertaining focuses on identifying key features such as shapes and sizes of different brain structures. The second pretraining stage identifies disease-specific attributes, such as geometric shapes of tumors and lesions and spatial placements within the brain. This dual-phase methodology significantly reduces the extensive data requirements usually necessary for AI model training in neuroimage segmentation with the flexibility to adapt to various imaging modalities. We rigorously evaluate our model, BrainSegFounder, using the Brain Tumor Segmentation (BraTS) challenge and Anatomical Tracings of Lesions After Stroke v2.0 (ATLAS v2.0) datasets. BrainSegFounder demonstrates a significant performance gain, surpassing the achievements of the previous winning solutions using fully supervised learning. Our findings underscore the impact of scaling up both the model complexity and the volume of unlabeled training data derived from generally healthy brains. Both of these factors enhance the accuracy and predictive capabilities of the model in neuroimage segmentation tasks. Our pretrained models and code are at https://github.com/lab-smile/BrainSegFounder. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Cox2024BrainSegFounder
ER  -

TY  - JOUR
AU  - Chaurasia, S.
AU  - Bharti, K.K.
AU  - Gupta, A.
TI  - A multi-model attention based CNN-BiLSTM model for personality traits prediction based on user behavior on social media
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 300
C7  - 112252
DO  - 10.1016/j.knosys.2024.112252
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199266683&doi=10.1016%2fj.knosys.2024.112252&partnerID=40&md5=7ff9157884b92c301cf9b78b77820329
AB  - The prediction of an individual's personality traits through the analysis of their online social media activities is an area of research that has gained considerable attention in the digital era. The statistical data derived from people's thoughts that are conveyed through their status updates on social media serves as an essential resource for understanding the various aspects of human behavior and personality. The present study is motivated by the various applications associated with personality prediction, such as targeted advertising, personalized entertainment, and customized recommendations. A multi-model attention-based convolutional neural network-bidirectional long short-term memory (CNN+BiLSTM) is proposed in the present work for personality traits prediction. The proposed model utilizes pre-trained language models, such as Global Vectors for Word Representation (GloVe) and Bidirectional Encoder Representations from Transformers (BERT), to create vector representations of words, which effectively captures word semantics. Additionally, network features such as size, betweenness, transitivity, and density are integrated with text features to enhance personality traits prediction. The results highlight the contextual understanding of the BERT model and emphasize the effectiveness of the proposed model, particularly the fusion of the attention layer with the CNN+BiLSTM architecture, which significantly improves information extraction and prediction capabilities. The integration of social network features strengthens the classifier's ability to predict personality traits, resulting in improved overall performance. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Chaurasia2024multi-model
ER  -

TY  - JOUR
AU  - Sattarzadeh, A.R.
AU  - Pathirana, P.N.
AU  - Kutadinata, R.
AU  - Huynh, V.T.
TI  - Extracting long-term spatiotemporal characteristics of traffic flow using attention-based convolutional transformer
PY  - 2024
T2  - IET Intelligent Transport Systems
VL  - 18
IS  - 10
SP  - 1797
EP  - 1814
DO  - 10.1049/itr2.12468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178894858&doi=10.1049%2fitr2.12468&partnerID=40&md5=2bd4828330cd8a36c52575fe8dae2e63
AB  - Predicting traffic flow is vital for optimizing transportation efficiency, reducing fuel consumption, and minimizing commute times. While artificial intelligence tools have been effective in addressing this, there have been some difficulties in processing spatial and temporal data. Current transformer-based methods, although cutting-edge for traffic prediction, encounter challenges with handling long sequences and capturing temporal relations effectively. Addressing these, the research introduces a model combining multi-scale attention modules within transformer layers. This model employs spatio-temporal transformer blocks, enriched with multi-scale convolutional attention mechanisms, allowing for a deeper understanding of temporal and spatial traffic patterns. This unique attention mechanism enhances data feature interpretation, leading to heightened prediction precision. The tests on extensive traffic datasets showcase the model's prowess in capturing both local and global traffic features, resulting in superior traffic status predictions. In summary, the innovative model offers an efficacious approach to long-sequence traffic data learning and temporal relationship extraction, setting a new benchmark in traffic flow prediction accuracy. © 2023 The Author(s). IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Sattarzadeh2024Extracting
ER  -

TY  - JOUR
AU  - Guo, L.
AU  - Chen, Z.
AU  - Cheng, S.
AU  - Yang, F.
AU  - Tao, W.
TI  - Learning compact and overlap-biased interactions for point cloud registration
PY  - 2024
T2  - Neurocomputing
VL  - 598
C7  - 127949
DO  - 10.1016/j.neucom.2024.127949
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196479786&doi=10.1016%2fj.neucom.2024.127949&partnerID=40&md5=2359d761af5cf1d175eee974629ff79c
AB  - Point cloud registration is a fundamental task in computer vision. Recent Transformer based methods for point cloud registration take advantage of the interaction modeling ability of the attention operation. However, feature ambiguity and low overlap are still the bottleneck in real scenes point cloud registration. In this paper, we present a new neural network to solve these two problems in Transformer architecture. First, we propose an Optimal Transport guided Cross Attention (OT-CA) to build compact interactions in CA which can mitigating the feature ambiguity problem. It uses a Spatial Consistency guided cost Regularization (SCR) to build the cost for the optimal transport problem, and get the weight matrix of CA by solving it. The structure information and more reasonable interactions can alleviate the feature ambiguity problem with fewer computing resources. Meanwhile, we propose a Separate-and-Joint Overlap Prediction module to solve the low-overlap problem. It adopts separate branches and training steps for feature matching and overlap prediction to reduce negative impacts between these two tasks, and adopts a joint training process to make full use of overlap information for learning better feature matching. Finally, the proposed modules are embedded into a coarse-to-fine pipeline. Our method shows state-of-the-art performance on three benchmark datasets. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Guo2024Learning
ER  -

TY  - JOUR
AU  - Luo, X.
AU  - Zhu, A.
AU  - Zhang, J.
AU  - Shao, J.
TI  - HierarT: Multi-hop temporal knowledge graph forecasting with hierarchical reinforcement learning
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 300
C7  - 112164
DO  - 10.1016/j.knosys.2024.112164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197338740&doi=10.1016%2fj.knosys.2024.112164&partnerID=40&md5=74b534f3d8b280c0a8d1c5423ecd62a6
AB  - Temporal knowledge graph (TKG) multi-hop reasoning is a dominant approach that infers the target entity by walking along the path connecting entities and relations. However, in most TKGs, there are multiple relations related to an identical entity and multiple tail entities for an identical pair of head entity and relation. This characteristic leads to a significant amount of redundant data in the binary action space which is a collection of binary tuples composed of relations and entities, thereby impeding model inference, i.e., action space explosion. We propose a method to address this issue that dismantles the reasoning process into a relation level for relation reasoning and an entity level for entity reasoning. In addition, hybrid time encoding is proposed to enhance the utilization of the timestamp information in the reasoning process. Moreover, K-means-based reward shaping is proposed to alleviate the issue of sparse reward matrices by comparing the pre-clustered labels of both the predicted entity and the target entity. A text transformer module is used to deal with the limitation of a single information modality by integrating the text information of TKG into model reasoning. Our method is evaluated using four benchmark datasets, and the results verify its superiority over state-of-the-art baselines. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Luo2024HierarT
ER  -

TY  - JOUR
AU  - Hou, J.
AU  - Omar, N.
AU  - Tiun, S.
AU  - Saad, S.
AU  - He, Q.
TI  - TCHFN: Multimodal sentiment analysis based on Text-Centric Hierarchical Fusion Network
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 300
C7  - 112220
DO  - 10.1016/j.knosys.2024.112220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198735982&doi=10.1016%2fj.knosys.2024.112220&partnerID=40&md5=89bb65381ba883bacfd23d05fa9dd8b9
AB  - Multimodal sentiment analysis (MSA) has become a popular field of research in recent years. The aim is to combine the three modalities of text, video, and audio to obtain comprehensive emotional information. However, current research often treats these three modalities equally, downplaying the crucial role of text modality in MSA and ignoring the redundant information generated during multimodal fusion. To address these problems, we propose the Text-Centric Hierarchical Fusion Network (TCHFN), employing a hierarchical fusion strategy. In this framework, low-level fusion involves cross-modal interactions between pairs of modalities, while high-level fusion extends these interactions to involve all three modalities. Through the design of the Cross-modal Reinforced Transformer (CRT), we achieve cross-modal enhancement of the target modality, facilitating a nuanced fusion process with text serving as its core. Additionally, we design Text-Centric Contrastive Learning (TCCL) to align non-text modalities with the text modality, emphasising the central role of text in the fusion process. After fusion, a multimodal fusion output gate is employed to mitigate redundant information within the multimodal fusion representation, which is subsequently processed by a linear layer for prediction. Simultaneously, to fully leverage limited labelled datasets, we introduced knowledge distillation. This approach involves preserving the model parameters that yield the best performance during training as a teacher model. The teacher model aids in capturing rich emotional information, enabling the model to transcend local optima and discover more optimal parameters, thereby enhancing overall model performance. Extensive experiments on the CMU-MOSI, CMU-MOSEI, and CH-SIMS datasets demonstrate the superiority of our model over state-of-the-art methods in MSA tasks. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Hou2024TCHFN
ER  -

TY  - JOUR
AU  - Muaad, A.Y.
AU  - Davanagere, H.J.
AU  - Hussain, J.
AU  - Al-antari, M.A.
TI  - Deep ensemble transfer learning framework for COVID-19 Arabic text identification via deep active learning and text data augmentation
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 33
SP  - 79337
EP  - 79375
DO  - 10.1007/s11042-024-18487-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186600324&doi=10.1007%2fs11042-024-18487-3&partnerID=40&md5=d76824da8ca2b09752d3b45b2f61f3e3
AB  - Since the declaration of COVID-19 as an epidemic by the World Health Organization in September 2019, the task of monitoring and managing the spread of misinformation related to COVID-19 on social media has become increasingly challenging. Particularly, when it comes to Arabic text recognition, tracking and identifying misleading information regarding COVID-19 on social media platforms presents significant difficulties. The detection of such text is crucial in order to safeguard our communities from the dissemination of false rumors and to establish a reliable framework for text detection. This research paper introduces a novel deep ensemble learning framework that aims to recognize ten distinct categories of Arabic text related to COVID-19, including rumors, restrictions, celebrity news, informational news, plans, requests, advice, personal anecdotes, and others. To build our framework, we leverage a dataset called ArCOVID-19Vac (Dataset1), which consists of 10,000 text samples. In addition, the DAL technique is employed to automatically annotate new text samples acquired for Dataset2. To further expand our datasets, we employ back translation and random insertion augmentation strategies, resulting in Datasets3 and Datasets4, each containing 24,000 text samples. By merging the original and augmented datasets, we create Dataset5, which comprises a total of 39,000 text samples. The final text prediction is carried out using three transformer-based BERT models through ensemble transfer learning. Our proposed ensemble framework is evaluated using each dataset independently, and it demonstrates promising results, particularly when utilizing the largest dataset (Dataset5), achieving an accuracy of 93%, precision of 92%, recall of 93%, and an F1-score of 91%. Furthermore, our proposed model exhibits performance improvements of 27%, 18%, 2%, and 1% when utilizing Datasets2, 3, 4, and 5, respectively. The comprehensive experimental results demonstrate that our ensemble framework outperforms other state-of-the-art AI-based models. The encouraging performance of our framework in accurately identifying Arabic text has the potential to enhance decision-making processes regarding the identification of misleading information and to facilitate the development of strategies to combat such issues in the future. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Muaad2024Deep
ER  -

TY  - JOUR
AU  - Zhang, K.
AU  - Yuan, Z.
AU  - Huang, T.
TI  - Diverse and tailored image generation for zero-shot multi-label classification
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 299
C7  - 112077
DO  - 10.1016/j.knosys.2024.112077
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195815517&doi=10.1016%2fj.knosys.2024.112077&partnerID=40&md5=67a33813e1eb0d69bfe249e223c769ec
AB  - Recently, zero-shot multi-label classification has garnered considerable attention owing to its capacity to predict unseen labels without human annotations. Nevertheless, prevailing approaches often use seen classes as imperfect proxies for unseen classes, resulting in suboptimal performance. Drawing inspiration from the success of text-to-image generation models in producing realistic images, we propose an innovative solution: generating synthetic data to construct a training set explicitly tailored for proxyless training of unseen labels. Our approach introduces a novel image generation framework that produces multi-label synthetic images of unseen classes for classifier training. To enhance the diversity of the generated images, we leverage a pretrained large language model to generate diverse prompts. Employing a pretrained multimodal contrastive language-image pretraining (CLIP) model as a discriminator, we assessed whether the generated images accurately represented the target classes. This enables automatic filtering of inaccurately generated images and preserves classifier accuracy. To refine the text prompts for more precise and effective multi-label object generation, we introduced a CLIP score-based discriminative loss to fine-tune the text encoder in the diffusion model. In addition, to enhance the visual features of the target task while maintaining the generalization of the original features and mitigating catastrophic forgetting resulting from fine-tuning the entire visual encoder, we propose a feature fusion module inspired by transformer attention mechanisms. This module aids in capturing the global dependencies between multiple objects more effectively. Extensive experimental results validated the effectiveness of our approach, demonstrating significant improvements over state-of-the-art methods. The code is available at https://github.com/TAKELAMAG/Diff-ZS-MLC. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Zhang2024Diverse
ER  -

TY  - JOUR
AU  - Karkera, T.
AU  - Adak, C.
AU  - Chattopadhyay, S.
AU  - Saqib, M.
TI  - Detecting severity of Diabetic Retinopathy from fundus images: A transformer network-based review
PY  - 2024
T2  - Neurocomputing
VL  - 597
C7  - 127991
DO  - 10.1016/j.neucom.2024.127991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195554483&doi=10.1016%2fj.neucom.2024.127991&partnerID=40&md5=a4a19d4f6bfbbe46d0ee2b06b75246c9
AB  - Diabetic Retinopathy (DR) is considered one of the significant concerns worldwide, primarily due to its impact on causing vision loss among most people with diabetes. The severity of DR is typically comprehended manually by ophthalmologists from fundus photography-based retina images. This paper deals with an automated understanding of the severity stages of DR. In the literature, researchers have focused on this automation using traditional machine learning-based algorithms and convolutional architectures. However, the past works hardly focused on essential parts of the retinal image to improve the model performance. In this study, we adopt and fine-tune transformer-based learning models to capture the crucial features of retinal images for a more nuanced understanding of DR severity. Additionally, we explore the effectiveness of image transformers to infer the degree of DR severity from fundus photographs. For experiments, we utilized the publicly available APTOS-2019 blindness detection dataset, where the performances of the transformer-based models were quite encouraging. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Karkera2024Detecting
ER  -

TY  - JOUR
AU  - Xu, L.
AU  - Pan, Z.
AU  - Chen, H.
AU  - Wang, S.
TI  - MTdyg: Multi-scale transformers with continuous time dynamic graph model for link prediction
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 300
C7  - 112245
DO  - 10.1016/j.knosys.2024.112245
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199296540&doi=10.1016%2fj.knosys.2024.112245&partnerID=40&md5=4cdfcdbed34b56da2e9597d6408c496b
AB  - Link prediction through continuous dynamic graph neural networks is a challenging endeavour. Previous studies have considered historic interaction sequences among pairs of nodes. However, this approach does not sufficiently model the links between them. Thus, the frequency of historical common neighbours was proposed to obtain more information about node pairs. Nonetheless, this measure fails to consider the timing of interactions because the relative importance of different interactions shifts over time. Multi-scale transformers with a continuous time dynamic graph model (MTdyg) are our response to this challenge to enhance link prediction. The novel MTdyg model employs a multi-scale patching strategy that dynamically adjusts based on the interaction frequency, feeding segmented interaction sequences into the transformer. This methodology significantly improves the model's ability to assimilate historical data. Furthermore, we developed a temporal attention-based historical common neighbour encoding technique to effectively identify linkages between source and target nodes in interaction sequences. Extensive testing on eight public datasets confirmed that MTdyg delivers superior performance on most datasets, demonstrating its effectiveness in capturing the nuances of node interactions over time. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Xu2024MTdyg
ER  -

TY  - JOUR
AU  - Yan, C.
AU  - Wang, H.
AU  - Liu, J.
AU  - Jiang, X.
AU  - Hu, Y.
AU  - Tang, X.
AU  - Kang, G.
AU  - Gavves, E.
TI  - PiClick: Picking the desired mask from multiple candidates in click-based interactive segmentation
PY  - 2024
T2  - Neurocomputing
VL  - 599
C7  - 128083
DO  - 10.1016/j.neucom.2024.128083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196957828&doi=10.1016%2fj.neucom.2024.128083&partnerID=40&md5=7e854b1a92a82967f86761bba8f920ed
AB  - Click-based interactive segmentation aims to generate target masks via human clicking, which facilitates efficient pixel-level annotation and image editing. In such a task, target ambiguity remains a problem hindering the accuracy and efficiency of segmentation. That is, in scenes with rich context, one click may correspond to multiple potential targets, while most previous interactive segmentors only generate a single mask and fail to deal with target ambiguity. In this paper, we propose a novel interactive segmentation network named PiClick, to yield all potentially reasonable masks and suggest the most plausible one for the user. Specifically, PiClick utilizes a Transformer-based architecture to generate all potential target masks by mutually interactive mask queries. Moreover, a Target Reasoning module is designed in PiClick to automatically suggest the user-desired mask from all candidates, relieving target ambiguity and extra-human efforts. Extensive experiments on 9 interactive segmentation datasets demonstrate PiClick performs favorably against previous state-of-the-arts considering the segmentation results. Moreover, we show that PiClick effectively reduces human efforts in annotating and picking the desired masks. To ease the usage and inspire future research, we release the source code of PiClick together with a plug-and-play annotation tool at https://github.com/cilinyan/PiClick. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yan2024PiClick
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Yang, X.
AU  - Tang, D.
AU  - Zhou, Z.
TI  - RDTN: Residual Densely Transformer Network for hyperspectral image classification
PY  - 2024
T2  - Expert Systems with Applications
VL  - 250
C7  - 123939
DO  - 10.1016/j.eswa.2024.123939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189934751&doi=10.1016%2fj.eswa.2024.123939&partnerID=40&md5=7e28f62699ea2e5b3cb040099d4179f2
AB  - Transformer-based methods have achieved significant success in hyperspectral image (HSI) classification, which attribute to the strong capability of capturing the global dependencies from the input. However, the existing Transformer-based HSI classification methods are challenged in retrieving sufficient abound local information using the linear projection modules. Moreover, they do not fully use the hierarchical representations extracted from the original hyperspectral images. To overcome these challenges, this paper proposes a novel transformer model, called Residual Densely Transformer Network (RDTN) to comprehensively exploit the multi-hierarchical features and the local–global dependencies along the spatial–spectral dimensions from the hyperspectral images. Specially, the proposed RDTN is built with two modules: a Cross-Scale Convolution Attention (CSCA) module to extract abundant local spatial–spectral features using the multiscale convolution attention layers, and a Local Residual Transformer Block (LRTB) to respectively capture the abundant global dependencies along the spatial–spectral dimensions. Additionally, LRTB uses a residual connection operation to make full use of the hierarchical representations of all the transformer encoder layers. After acquiring dense global representations, we introduce a Global Residual Connection (GRC) to jointly fuse the local features obtained by CSCA, and then feed the fusion representations into the final avg-pooling layer and a classifier to predict the category. Finally, we conduct the extensive experiments based on four public benchmarks datasets, whose results are demonstrated that the proposed RDTN outperforms the state-of-the-art methods. The codes of this work are available at https://github.com/xiachangxue/DeepHyperX. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024RDTN
ER  -

TY  - JOUR
AU  - Cui, D.
AU  - Xin, C.
AU  - Wu, L.
AU  - Wang, X.
TI  - ConvTransformer Attention Network for temporal action detection
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 300
C7  - 112264
DO  - 10.1016/j.knosys.2024.112264
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199385687&doi=10.1016%2fj.knosys.2024.112264&partnerID=40&md5=f9f87ff7fc6e4644f946ed81ae8e7846
AB  - Boundary detection is a challenging problem in Temporal Action Detection (TAD). While transformer-based methods achieve satisfactory results by incorporating self-attention mechanisms to model global dependencies for boundary detection, they face two key issues. Firstly, they lack explicit learning of local relationships; this limitation results in imprecise boundary detection when subtle appearance changes occur between adjacent clips. Secondly, transformer-based methods lead to feature convergence across multiple actions due to the self-attention mechanism's tendency to distribute focus across the entire input video, resulting in the prediction of imprecisely overlapping actions. To address these challenges, we introduce the ConvTransformer Attention Network (CTAN), a novel framework comprised of two primary components: (1) The Temporal Attention Block (TAB), a temporal attention mechanism designed to emphasize critical temporal positions enriched with essential action-related features. (2) The ConvTransformer Block (CTB), which employs a hybrid structure for capturing nuanced appearance changes locally and action transitions globally. Facilitated with these components, CTAN is adept at focusing on motion features between overlapping actions, and precisely capturing both local differences between adjacent clips and global action transitions. The extensive experiments on multiple datasets, including THUMOS14, MultiTHUMOS, and ActivityNet, confirm the effectiveness of CTAN. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Cui2024ConvTransformer
ER  -

TY  - JOUR
AU  - Ge, Y.
AU  - Chen, Z.
AU  - Yu, M.
AU  - Yue, Q.
AU  - You, R.
AU  - Zhu, L.
TI  - MambaTSR: You only need 90k parameters for traffic sign recognition
PY  - 2024
T2  - Neurocomputing
VL  - 599
C7  - 128104
DO  - 10.1016/j.neucom.2024.128104
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196815674&doi=10.1016%2fj.neucom.2024.128104&partnerID=40&md5=8f158a8ee9043c67f42d1376ad8ec648
AB  - Traffic Sign Recognition (TSR) has made significant progress in recent years, and both convolution neural network (CNN)-based and transformer-based models have been widely explored. In addition, combining CNN and transformer can effectively utilize both local and global information for judgment. However, this approach is still affected by the secondary complexity of transformer and cannot maximize the performance. Recently, a state space model (SSM)-based architecture called Mamba has been proposed, which excels in long-range modelling while maintaining linear complexity. When we directly use the Mamba architecture for TSR, it performs poorly because the local features cannot be fully utilized, which are crucial for recognizing traffic sign details. In this paper, we explore the potential of this SSM-based model in TSR from both efficiency and effectiveness perspectives, and we customize a MambaTSR architecture with ∼90k parameters and ∼1.4 ms processing time. Specifically, we use patch embedding and a four-stage encoder at the macro level, while at the micro level we employ three-stream adaptive mining embedding (TAME) to obtain local information and four efficient visual state space (EVSS) blocks to explore global associations. Experiments on German, China, and India datasets show that our method achieves optimal performance and reduces parameters by ∼89 % and processing time by ∼58 % compared to the state-of-the-art method. The code can be accessed at https://github.com/1024AILab/MambaTSR. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Ge2024MambaTSR
ER  -

TY  - JOUR
AU  - Wu, L.
AU  - Xin, C.
AU  - Li, Z.
AU  - Cui, D.
TI  - Dual-branch Cross-scale Feature Interaction for Temporal Action Detection
PY  - 2024
T2  - Neurocomputing
VL  - 597
C7  - 128087
DO  - 10.1016/j.neucom.2024.128087
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197030270&doi=10.1016%2fj.neucom.2024.128087&partnerID=40&md5=698a2efac4e03a69f2a7743a8bf6331a
AB  - Temporal Action Detection (TAD) is aim to predict action boundary and category simultaneously. Most existing RGB-based methods model temporal dependency using pyramid-style features without interaction among different scales, which usually result in inaccurate prediction for long-term actions. The reason is that features at different scales involve information with different granularity, which is suitable for either prediction of action boundary or category. In this paper, we present a novel Dual-branch Cross-scale Feature Interaction (DCFI) method that directly exchanges different scale information from both temporal and spatial perspective for TAD. To be specific, in one branch, a cross-scale temporal transformer module is devised to enable both semantic and temporal communications among different scale features with a merge-to-split mechanism. While the other branch designs a cross-scale spatial mixer module to mine the most salient spatial difference between consecutive and long-term frames via a scale-mixer. Benefiting from these two modules, DCFI achieves comprehensive temporal as well as spatial interaction across all feature scales, and thus accurately predicts the boundaries of different time-span action instances. Extensive experiments on two challenging benchmarks, i.e., THUMOS-14 and ActivityNet-1.3, demonstrate that our DCFI achieves new state-of-the-art performance with only RGB. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wu2024Dual-branch
ER  -

TY  - JOUR
AU  - Şimsek, M.U.
AU  - Kök, İ.
AU  - Özdemir, S.
TI  - DeepFogAQ: A fog-assisted decentralized air quality prediction and event detection system
PY  - 2024
T2  - Expert Systems with Applications
VL  - 251
C7  - 123920
DO  - 10.1016/j.eswa.2024.123920
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190749379&doi=10.1016%2fj.eswa.2024.123920&partnerID=40&md5=17edd9a40401d1c6d05e06fc1d1d621a
AB  - Air pollution is a pervasive environmental and public health concern, prompting the imperative development of predictive systems to facilitate proactive interventions. The complexity of predicting air pollution arises from intricate factors, including the accumulation of pollutants, traffic dynamics, and industrial emissions. Traditional methodologies, reliant on historical or real-time data analysis, often encounter limitations in providing comprehensive and accurate solutions to this multifaceted problem. To address the existing problem, we propose a novel fog-assisted decentralized air quality prediction and event detection system (DeepFogAQ) for managing air pollution of future cities. We integrate Deep Learning (DL), Fog Computing (FC), Complex Event Processing (CEP), and virtualization technologies within the architecture of DeepFogAQ. Specifically, for predicting pollutant concentrations, we employ Transformers, CNN-LSTM, GRU, and RFR models. Additionally, we construct Fog and Cloud layers based on container-based virtualization technology. To demonstrate the feasibility of the system, the developed ML/DL models were run on DeepFogAQ and alarm levels for future air quality were derived. In this way, both the success of the prediction models and the validity of the architecture were ensured. Experimental results showed that Transformers is the most successful model in air quality prediction and event detection. As a result, the proposed DeepFogAQ architecture has the potential to offer a powerful alternative to decision-makers to solve the air pollution problem with its decentralized, scalable, and fault-tolerant structure. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Şimsek2024DeepFogAQ
ER  -

TY  - JOUR
AU  - Su, J.
AU  - Xie, D.
AU  - Duan, Y.
AU  - Zhou, Y.
AU  - Hu, X.
AU  - Duan, S.
TI  - MDCNet: Long-term time series forecasting with mode decomposition and 2D convolution
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 299
C7  - 111986
DO  - 10.1016/j.knosys.2024.111986
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195176613&doi=10.1016%2fj.knosys.2024.111986&partnerID=40&md5=1d7a7ee29f452cc20f66d24ae68218e7
AB  - Long-term time series forecasting is widely used in various real-world applications, such as weather, traffic, energy, healthcare, etc. Recently, time series decomposition techniques have been adopted in many mainstream forecasting models, such as the prevalent Transformer-based models, to help capture sophisticated temporal patterns and achieve success in several benchmark tasks. However, conventional decomposition algorithms are often based on simple operations or limited to specific fields, and therefore are not effective and applicable enough, especially for complex time series. In this paper, we propose Mode Decomposition and 2D Convolutional Network (MDCNet), a structure-simple yet effective forecasting architecture based on a more effective decomposition method and a multi-frequency time series feature extraction network with multi-scale 2D convolution. Specifically, we first introduce a Variational Mode Decomposition Block to discover intricate time patterns, which decompose time series into trend components and stationary modal components at different main frequencies. Then, we design a Trend Prediction Block and an Intrinsic Mode Functions Prediction Block to capture global correlation and hidden dependencies within different main frequencies, respectively. Furthermore, a Frequency Enhancement Module is designed to further reduce the impact of noise in long-term time series. Experiments on eight benchmark datasets show that MDCNet significantly reduces the error of the previous state-of-the-art method by 15.1% and 11.5% for multivariate and univariate time series, respectively. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; 
LB  - Su2024MDCNet
ER  -

TY  - JOUR
AU  - Kazama, K.
AU  - Fujita, K.
AU  - Shinoda, Y.
AU  - Koike, S.
TI  - Sika deer trajectory prediction considering environmental factors by timeseries transformer-based architecture
PY  - 2024
T2  - Expert Systems with Applications
VL  - 250
C7  - 123630
DO  - 10.1016/j.eswa.2024.123630
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189702399&doi=10.1016%2fj.eswa.2024.123630&partnerID=40&md5=768c747318b9163c74d1ac66aa5b819d
AB  - Recently, the damage to agriculture, forestry, and fishery by wildlife has become a serious social problem. The damage caused by a conflict between wildlife and human society often causes less motivation for farming and is expected to significantly inhibit the development of local agriculture and forestry. However, the current management of wildlife is limited to primitive methods such as stabilizing the population by culling reliant on experience. To prevent this problem, the trajectory prediction of wildlife is one of the solutions for efficient wildlife management. In this study, we propose a machine learning architecture for predicting wildlife trajectories, considering surrounding environmental factors. Particularly, we propose a machine learning architecture that more accurately predicts trajectories using a timeseries transformer model that can learn long-term dependencies and add a submodel that can consider surrounding environmental factors. The proposed architecture allows interpreting which past trajectory areas should be focused on when predicting a trajectory by visualizing the weight of the focus mechanism, one of the elements comprising the transformer model. Further, the proposed architecture can decide the priority of elements of a multivariate timeseries input by considering a variable selection network (VSN), which considers the relationship of timeseries between a given time point and those before and after using casual convolutions. The main advantage of our methods is to understand the potential environmental factors to predict animal trajectories by analyzing the importance of each input feature representation in VSN. We experimented to evaluate the proposed method using one of the largest biologging datasets of sika deer (Cervus nippon) in Kanagawa Prefecture, Japan. The proposed method outperforms existing methods on various evaluation metrics and can effectively consider environmental factors in predicting trajectories. In addition, we analyze the results and show that the proposed architecture can pay attention to the times that individuals moved significantly within the observation period by visualizing the trajectories for the best and worst cases and the weight of each environmental factor. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kazama2024Sika
ER  -

TY  - JOUR
AU  - Zong, X.
AU  - Qi, Y.
AU  - Yan, H.
AU  - Ye, Q.
TI  - An Intelligent Deep Learning Framework for Traffic Flow Imputation and Short-term Prediction Based on Dynamic Features
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 300
C7  - 112178
DO  - 10.1016/j.knosys.2024.112178
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197052972&doi=10.1016%2fj.knosys.2024.112178&partnerID=40&md5=175ab8997307be8940f93818a30ccdca
AB  - The accurate prediction of traffic flow has emerged as a focal point in the cutting-edge sphere of intelligent transportation. Extant methodologies rely on deep learning for short-term forecasts but are hampered by two critical limitations: the omission of vital traffic flow data and an overemphasis on static rather than dynamic attributes. This paper presents a solution to these challenges through the creation of a dynamic attention generative adversarial network (DATGAN) that is specifically engineered to impute missing traffic data accurately. DATGAN introduces two groundbreaking features: first, an innovative attention module that is adept at identifying local correlations, and second, novel spatial-correction graph convolutional layers that are designed to capture the ever-changing spatial dynamic dependencies. Building on this foundation, the parallel spatial–temporal Transformer (PSTTransformer) is proposed, which integrates both spatial and temporal attention blocks to manage dynamic spatial-temporal dependencies for future short-term traffic predictions. This dual-block approach not only embeds periodic information via a fusion self-attention mechanism in the temporal attention blocks, but also synergizes graph convolutional networks with self-attention mechanisms in the spatial attention blocks through a gate mechanism. A comprehensive comparative analysis conducted on traffic datasets revealed that our methodology outperforms current leading models by reducing the mean squared error by 5% in data imputation tasks and shows robust performance in traffic prediction scenarios. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; 
LB  - Zong2024Intelligent
ER  -

TY  - JOUR
AU  - Liu, A.
AU  - Zhang, Y.
TI  - An efficient spatial-temporal transformer with temporal aggregation and spatial memory for traffic forecasting
PY  - 2024
T2  - Expert Systems with Applications
VL  - 250
C7  - 123884
DO  - 10.1016/j.eswa.2024.123884
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190296259&doi=10.1016%2fj.eswa.2024.123884&partnerID=40&md5=c208c68a3c85c6543affba1e72ea037b
AB  - Traffic forecasting technology has widespread applications in various domains, such as urban traffic planning and intelligent transportation systems. Traffic forecasting encounters challenges in effectively capturing the intricate spatial–temporal correlations in traffic data. While the latest methods have achieved satisfactory performance, they still suffer from two limitations: (i) Most methods overlook the memory of valuable traffic patterns at each traffic node, thus making it struggle to reveal dynamic spatial–temporal correlations using their inherent periodicity and trend characteristics from a broader perspective. (ii) As the research progresses, recently proposed models become increasingly complex and massive. To address these issues, we propose a Spatial-Temporal Aggregation Memory Transformer (STAMT) for traffic forecasting. Specifically, we propose a memory bank to enhance vanilla spatial attention and cache the traffic patterns of historical input. By querying these traffic patterns, which contain rich spatial–temporal semantic information, the model can optimize prediction performance by extracting trends and regularities across various periods. To reduce the computational costs, we introduce a temporal module to capture temporal correlations while reducing temporal dimension information. In addition, we leverage the random feature map and matrix multiplication associativity property, which reduce the quadratic complexity of spatial attention to linearity with regard to the number of nodes. Ultimately, our theoretical analysis concludes that a single-layer spatial attention network is sufficient to capture spatial–temporal correlations deeply without stacking. Extensive experiments on nine real-world datasets demonstrate that STAMT outperforms state-of-the-art baselines in regular, long-range, and large-scale traffic forecasting tasks while significantly reducing the computational costs. Codes are available at https://github.com/LiuAoyu1998/STAMT. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2024efficient
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Guo, Z.
AU  - Xu, C.
AU  - Lin, J.
TI  - A multimodal stepwise-coordinating framework for pedestrian trajectory prediction
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 299
C7  - 112038
DO  - 10.1016/j.knosys.2024.112038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195886247&doi=10.1016%2fj.knosys.2024.112038&partnerID=40&md5=dd1b9c901b03de5f02ab0f5ddca50b45
AB  - Pedestrian trajectory prediction from the first-person view has still been considered one of the challenging problems in automatic driving due to the difficulty of understanding and predicting pedestrian actions. Observing that pedestrian motion naturally contains the repetitive pattern of the gait cycle and global intention information, we design a Multimodal Stepwise-Coordinating Network, namely MSCN, to sufficiently leverage the underlying human motion properties. Specifically, we first design a multimodal spatial-frequency encoder, which encodes the periodicity of pedestrian motion with a frequency-domain enhanced Transformer and other visual information with a spatial-domain Transformer. Then, we propose a stepwise-coordinating decoder structure, which leverages both local and global information in sequence decoding through a two-stage decoding process. After generating a coarse sequence from the stepwise trajectory predictor, we design a coordinator to aggregate the corresponding representations used to generate the coarse sequence. Subsequently, the coordinator learns to output a refined sequence through a knowledge distillation process based on the aggregated representations. In this way, MSCN can adequately capture the representations of short-term motion behaviors, thus modeling better long-term sequence prediction. Extensive experiments show that the proposed model can achieve significant improvements over state-of-the-art approaches on the PIE and JAAD datasets by 16.1% and 16.4% respectively. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Wang2024multimodal
ER  -

TY  - JOUR
AU  - Cai, M.
AU  - Zhao, L.
AU  - Qiang, Y.
AU  - Wang, L.
AU  - Zhao, J.
TI  - CHNet: A multi-task global–local Collaborative Hybrid Network for KRAS mutation status prediction in colorectal cancer
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 155
C7  - 102931
DO  - 10.1016/j.artmed.2024.102931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200131125&doi=10.1016%2fj.artmed.2024.102931&partnerID=40&md5=3e48d69aee373a9cdfe130eec6c89e8f
AB  - Accurate prediction of Kirsten rat sarcoma (KRAS) mutation status is crucial for personalized treatment of advanced colorectal cancer patients. However, despite the excellent performance of deep learning models in certain aspects, they often overlook the synergistic promotion among multiple tasks and the consideration of both global and local information, which can significantly reduce prediction accuracy. To address these issues, this paper proposes an innovative method called the Multi-task Global–Local Collaborative Hybrid Network (CHNet) aimed at more accurately predicting patients’ KRAS mutation status. CHNet consists of two branches that can extract global and local features from segmentation and classification tasks, respectively, and exchange complementary information to collaborate in executing these tasks. Within the two branches, we have designed a Channel-wise Hybrid Transformer (CHT) and a Spatial-wise Hybrid Transformer (SHT). These transformers integrate the advantages of both Transformer and CNN, employing cascaded hybrid attention and convolution to capture global and local information from the two tasks. Additionally, we have created an Adaptive Collaborative Attention (ACA) module to facilitate the collaborative fusion of segmentation and classification features through guidance. Furthermore, we introduce a novel Class Activation Map (CAM) loss to encourage CHNet to learn complementary information between the two tasks. We evaluate CHNet on the T2-weighted MRI dataset, and achieve an accuracy of 88.93% in KRAS mutation status prediction, which outperforms the performance of representative KRAS mutation status prediction methods. The results suggest that our CHNet can more accurately predict KRAS mutation status in patients via a multi-task collaborative facilitation and considering global–local information way, which can assist doctors in formulating more personalized treatment strategies for patients. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cai2024CHNet
ER  -

TY  - JOUR
AU  - Xue, Y.
AU  - Guan, S.
AU  - Jia, W.
TI  - BGformer: An improved Informer model to enhance blood glucose prediction
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 157
C7  - 104715
DO  - 10.1016/j.jbi.2024.104715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202301587&doi=10.1016%2fj.jbi.2024.104715&partnerID=40&md5=211ebe90951fe054bb6a018bb0b65456
AB  - Accurately predicting blood glucose levels is crucial in diabetes management to mitigate patients’ risk of complications. However, blood glucose values exhibit instability, and existing prediction methods often struggle to capture their volatile nature, leading to inaccurate trend forecasts. To address these challenges, we propose a novel blood glucose level prediction model based on the Informer architecture: BGformer. Our model introduces a feature enhancement module and a microscale overlapping concerns mechanism. The feature enhancement module integrates periodic and trend feature extractors, enhancing the model's ability to capture relevant information from the data. By extending the feature extraction capacity of time series data, it provides richer feature representations for analysis. Meanwhile, the microscale overlapping concerns mechanism adopts a window-based strategy, computing attention scores only within specific windows. This approach reduces computational complexity while enhancing the model's capacity to capture local temporal dependencies. Furthermore, we introduce a dual attention enhancement module to augment the model's expressive capability. Through prediction experiments on blood glucose values from sixteen diabetic patients, our model outperformed eight benchmark models in terms of both MAE and RMSE metrics for future 60-minute and 90-minute predictions. Our proposed scheme significantly improves the model's dependency-capturing ability, resulting in more accurate blood glucose level predictions. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xue2024BGformer
ER  -

TY  - JOUR
AU  - Jung, A.
AU  - Hong, S.
AU  - Hyun, Y.
TI  - Scale-aware token-matching for transformer-based object detector
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 185
SP  - 197
EP  - 202
DO  - 10.1016/j.patrec.2024.08.006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202028518&doi=10.1016%2fj.patrec.2024.08.006&partnerID=40&md5=34fdf59870e740aeb99a4c0fd819cfd9
AB  - Owing to the advancements in deep learning, object detection has made significant progress in estimating the positions and classes of multiple objects within an image. However, detecting objects of various scales within a single image remains a challenging problem. In this study, we suggest a scale-aware token matching to predict the positions and classes of objects for transformer-based object detection. We train a model by matching detection tokens with ground truth considering its size, unlike the previous methods that performed matching without considering the scale during the training process. We divide one detection token set into multiple sets based on scale and match each token set differently with ground truth, thereby, training the model without additional computation costs. The experimental results demonstrate that scale information can be assigned to tokens. Scale-aware tokens can independently learn scale-specific information by using a novel loss function, which improves the detection performance on small objects. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jung2024Scale-aware
ER  -

TY  - JOUR
AU  - Artaud, C.
AU  - De-Silva, V.
AU  - Pina, R.
AU  - Shi, X.
TI  - Generating neural architectures from parameter spaces for multi-agent reinforcement learning
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 185
SP  - 272
EP  - 278
DO  - 10.1016/j.patrec.2024.07.013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199897142&doi=10.1016%2fj.patrec.2024.07.013&partnerID=40&md5=1dd6711d4c50e4fd9b291593814bea84
AB  - We explore a data-driven approach to generating neural network parameters to determine whether generative models can capture the underlying distribution of a collection of neural network checkpoints. We compile a dataset of checkpoints from neural networks trained within the multi-agent reinforcement learning framework, thus potentially producing previously unseen combinations of neural network parameters. In particular, our generative model is a conditional transformer-based variational autoencoder that, when provided with random noise and a specified performance metric – in our context, returns – predicts the appropriate distribution over the parameter space to achieve the desired performance metric. Our method successfully generates parameters for a specified optimal return without further fine-tuning. We also show that the parameters generated using this approach are more constrained and less variable and, most importantly, perform on par with those trained directly under the multi-agent reinforcement learning framework. We test our method on the neural network architectures commonly employed in the most advanced state-of-the-art algorithms. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Artaud2024Generating
ER  -

TY  - JOUR
AU  - Hao, B.
AU  - Hu, Y.
AU  - Adams, W.G.
AU  - Assoumou, S.A.
AU  - Hsu, H.E.
AU  - Bhadelia, N.
AU  - Paschalidis, I.C.
TI  - A GPT-based EHR modeling system for unsupervised novel disease detection
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 157
C7  - 104706
DO  - 10.1016/j.jbi.2024.104706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201403611&doi=10.1016%2fj.jbi.2024.104706&partnerID=40&md5=ec882d09c4832b58f9820ad71cdba5b2
AB  - Objective: To develop an Artificial Intelligence (AI)-based anomaly detection model as a complement of an “astute physician” in detecting novel disease cases in a hospital and preventing emerging outbreaks. Methods: Data included hospitalized patients (n = 120,714) at a safety-net hospital in Massachusetts. A novel Generative Pre-trained Transformer (GPT)-based clinical anomaly detection system was designed and further trained using Empirical Risk Minimization (ERM), which can model a hospitalized patient's Electronic Health Records (EHR) and detect atypical patients. Methods and performance metrics, similar to the ones behind the recent Large Language Models (LLMs), were leveraged to capture the dynamic evolution of the patient's clinical variables and compute an Out-Of-Distribution (OOD) anomaly score. Results: In a completely unsupervised setting, hospitalizations for Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) infection could have been predicted by our GPT model at the beginning of the COVID-19 pandemic, with an Area Under the Receiver Operating Characteristic Curve (AUC) of 92.2 %, using 31 extracted clinical variables and a 3-day detection window. Our GPT achieves individual patient-level anomaly detection and mortality prediction AUC of 78.3 % and 94.7 %, outperforming traditional linear models by 6.6 % and 9 %, respectively. Different types of clinical trajectories of a SARS-CoV-2 infection are captured by our model to make interpretable detections, while a trend of over-pessimistic outcome prediction yields a more effective detection pathway. Furthermore, our comprehensive GPT model can potentially assist clinicians with forecasting patient clinical variables and developing personalized treatment plans. Conclusion: This study demonstrates that an emerging outbreak can be accurately detected within a hospital, by using a GPT to model patient EHR time sequences and labeling them as anomalous when actual outcomes are not supported by the model. Such a GPT is also a comprehensive model with the functionality of generating future patient clinical variables, which can potentially assist clinicians in developing personalized treatment plans. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hao2024GPT-based
ER  -

TY  - JOUR
AU  - Khan, M.A.
AU  - Prasad, B.K.
AU  - Qi, G.
AU  - Song, W.
AU  - Ye, F.
AU  - Ali, Z.
AU  - Ullah, I.
AU  - Kefalas, P.
TI  - UTMGAT: a unified transformer with memory encoder and graph attention networks for multidomain dialogue state tracking
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 17-18
SP  - 8347
EP  - 8366
DO  - 10.1007/s10489-024-05571-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196916524&doi=10.1007%2fs10489-024-05571-2&partnerID=40&md5=8cf8f795404e54cfda411496316629d9
AB  - Spoken dialogue systems (SDS) heavily rely on dialogue state tracking (DST) for success. However, providing sufficient computational power for training proves challenging, given that DST involves tracking states from both user and system utterances. While machine learning approaches have improved DST, they have notable limitations. These approaches often overlook unseen slot values during training and use two separate modules to extract, generate, or match slot values, leading to high time and resource consumption. Moreover, learning and deducing relevant values for related slots remain understudied challenges. To address these gaps, this paper introduces UTMGAT-a Unified Transformer with Memory Encoder and Graph Attention Networks (GAT) for Multidomain DST. UTMGAT employs a BERT tokenizer to construct user utterances and a candidate sets vocabulary, reducing the need for constant retraining when dealing with unseen values. It utilizes a single transformer to gather dialogue context for slots and generate slot values, enhancing prediction accuracy while reducing memory and computation time. UTMGAT incorporates an embedding layer aggregator to filter out unnecessary values, identify required nodes for GAT, and establish relationships among relevant values associated with related slots. This approach simplifies graph representation and diminishes required computation power. The input to the GAT maintains equal size with batch sizes, generated through padding. Finally, we have experimentally evaluated our model against several models including LLM approaches over four popular datasets with our approach outperforming all competing models except two approaches on one dataset. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Khan2024UTMGAT
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Ren, M.
AU  - Wang, Z.
AU  - Li, G.
TI  - MEMF: Multi-entity multimodal fusion framework for sales prediction in live streaming commerce
PY  - 2024
T2  - Decision Support Systems
VL  - 184
C7  - 114277
DO  - 10.1016/j.dss.2024.114277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197270719&doi=10.1016%2fj.dss.2024.114277&partnerID=40&md5=94f1408b74744fce523e837f1033ac36
AB  - Live streaming commerce thrives with a rich tapestry of multimodal information that intertwines with various entities, including the anchor, the commodities, and the live streaming environment. Despite the wealth of data at hand, the synthesis and analysis of this information to predict sales remains a significant challenge. This study introduces a framework for multi-entity multimodal fusion, which is characterized by the effective synthesis of multimodal data and its prioritization of entity-level fusion, thereby providing a comprehensive feature representation for improving predictive performance. In addressing the multimodal data associated with a diverse range of products, our framework improves the Transformer architecture to initially capture the intra-product modal features and subsequently integrate the inter-product features. Data experiments are conducted on a real-world dataset from Taobao Live. The framework outperforms both traditional machine learning methods and state-of-the-art multimodal fusion methods, which affirms its value as a robust decision-support tool for sales prediction, enabling more accurate pre-event predictions and strategic planning. We also examine the impact of different types of information in accurate sales prediction. It is found that harnessing a comprehensive suite of data leads to optimal performance across all evaluation metrics. Commodity-related data is primary factor in determining the prediction accuracy, followed by video data and streaming room-related data, providing insights regarding the resource allocation for collecting and analyzing multimodal data from live streaming platforms. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Xu2024MEMF
ER  -

TY  - JOUR
AU  - Fan, J.
AU  - Ji, Y.
AU  - Wu, H.
AU  - Ge, Y.
AU  - Sun, D.
AU  - Wu, J.
TI  - An unsupervised video anomaly detection method via Optical Flow decomposition and Spatio-Temporal feature learning
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 185
SP  - 239
EP  - 246
DO  - 10.1016/j.patrec.2024.08.013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202351481&doi=10.1016%2fj.patrec.2024.08.013&partnerID=40&md5=9fbfdf50a0e2b818ec6e2df5517cff0f
AB  - The purpose of this paper is to present an unsupervised video anomaly detection method using Optical Flow decomposition and Spatio-Temporal feature learning (OFST). This method employs a combination of optical flow reconstruction and video frame prediction to achieve satisfactory results. The proposed OFST framework is composed of two modules: the Multi-Granularity Memory-augmented Autoencoder with Optical Flow Decomposition (MG-MemAE-OFD) and a Two-Stream Network based on Spatio-Temporal feature learning (TSN-ST). The MG-MemAE-OFD module is composed of three functional blocks: optical flow decomposition, autoencoder, and multi-granularity memory networks. The optical flow decomposition block is used to extract the main motion information of objects in optical flow, and the granularity memory network is utilized to memorize normal patterns and improve the quality of the reconstructions. To predict video frames, we introduce a two-stream network based on spatiotemporal feature learning (TSN-ST), which adopts parallel standard Transformer blocks and a temporal block to learn spatiotemporal features from video frames and optical flows. The OFST combines these two modules so that the prediction error of abnormal samples is further increased due to the larger reconstruction error. In contrast, the normal samples obtain a lower reconstruction error and prediction error. Therefore, the anomaly detection capability of the method is greatly enhanced. Our proposed model was evaluated on public datasets. Specifically, in terms of the area under the curve (AUC), our model achieved an accuracy of 85.74% on the Ped1 dataset, 99.62% on the Ped2 dataset, 93.89% on the Avenue dataset, and 76.0% on the ShanghaiTech Dataset. Our experimental results show an average improvement of 1.2% compared to the current state-of-the-art. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Fan2024unsupervised
ER  -

TY  - JOUR
AU  - Luo, A.
AU  - Luo, Y.
AU  - Liu, H.
AU  - Du, W.
AU  - Wu, X.
AU  - Chen, H.
AU  - Yang, H.
TI  - An improved transformer-based model for long-term 4D trajectory prediction in civil aviation
PY  - 2024
T2  - IET Intelligent Transport Systems
VL  - 18
IS  - 9
SP  - 1588
EP  - 1598
DO  - 10.1049/itr2.12530
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196741818&doi=10.1049%2fitr2.12530&partnerID=40&md5=b509ee60501da2de6b73252cf3fa035b
AB  - Four-dimensional trajectory prediction is a crucial component of air traffic management, and its accuracy is closely related to the efficiency and safety of air transportation. Although long short-term memory (LSTM) or its variants have been widely used in recent studies, they may produce unacceptable results in long-term prediction due to the iterative output that accumulates error. To address this issue, a transformer-based long-term trajectory prediction model is proposed here, which utilizes the self-attention mechanism to extract time series features from historical trajectory data. For long-term prediction scenarios, we a trajectory stabilization module is introduced to ensure the stationarity of the time series for better predictability. Additionally, the transformer output strategy is improved to generate the prediction sequence by a single step instead of serial dynamic decoding, thus effectively enhancing the precision and inference speed. The proposed model is validated using real data obtained from China's Southwest Air Traffic Management Bureau. The experimental results demonstrate that this model outperforms the benchmark model. Further ablation experiments and visualizations are performed to analyze the impact of trajectory stabilization and one-step inference strategy. © 2024 The Author(s). IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Luo2024improved
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Zhu, Z.
AU  - Li, K.
AU  - Zhou, L.
AU  - Zhao, Z.
AU  - Pei, H.
TI  - Joint training strategy of unimodal and multimodal for multimodal sentiment analysis
PY  - 2024
T2  - Image and Vision Computing
VL  - 149
C7  - 105172
DO  - 10.1016/j.imavis.2024.105172
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198601047&doi=10.1016%2fj.imavis.2024.105172&partnerID=40&md5=f63f21966b4213b0c0a5ffdcfda1ffe3
AB  - With the explosive growth of social media video content, research on multimodal sentiment analysis (MSA) has attracted considerable attention recently. Despite significant progress in MSA, there remains challenges: current research mostly focuses on learning either unimodal features or aspects of multimodal interactions, neglecting the importance of simultaneously considering both unimodal features and intermodal interactions. To address the aforementioned challenges, this paper proposes a fusion strategy called Joint Training of Unimodal and Multimodal (JTUM). Specifically, this strategy combines unimodal label generation module with cross-modal transformer. The unimodal label generation module aims to generate more distinctive labels for each unimodal input, facilitating more effective learning of unimodal representations. Meanwhile, cross-modal transformer is designed to treat each modality as a target modality and optimize it using other modalities as source modalities, thereby learning the interactions between each pair of modalities. By jointly training unimodal and multimodal tasks, our model can focus on individual modality features while learning the interactions between modalities. Finally, to better capture temporal information and make predictions, we also added self-attention transformer as sequence models. Experimental results on the CMU-MOSI and CMU-MOSEI datasets demonstrate that JTUM outperforms current main methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Li2024Joint
ER  -

TY  - JOUR
AU  - Mostafaei, S.H.
AU  - Tanha, J.
AU  - Sharafkhaneh, A.
TI  - A novel deep learning model based on transformer and cross modality attention for classification of sleep stages
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 157
C7  - 104689
DO  - 10.1016/j.jbi.2024.104689
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199101013&doi=10.1016%2fj.jbi.2024.104689&partnerID=40&md5=c1196fdd14002a3c738ffad573301966
AB  - The classification of sleep stages is crucial for gaining insights into an individual's sleep patterns and identifying potential health issues. Employing several important physiological channels in different views, each providing a distinct perspective on sleep patterns, can have a great impact on the efficiency of the classification models. In the context of neural networks and deep learning models, transformers are very effective, especially when dealing with time series data, and have shown remarkable compatibility with sequential data analysis as physiological channels. On the other hand, cross-modality attention by integrating information from multiple views of the data enables to capture relationships among different modalities, allowing models to selectively focus on relevant information from each modality. In this paper, we introduce a novel deep-learning model based on transformer encoder-decoder and cross-modal attention for sleep stage classification. The proposed model processes information from various physiological channels with different modalities using the Sleep Heart Health Study Dataset (SHHS) data and leverages transformer encoders for feature extraction and cross-modal attention for effective integration to feed into the transformer decoder. The combination of these elements increased the accuracy of the model up to 91.33% in classifying five classes of sleep stages. Empirical evaluations demonstrated the model's superior performance compared to standalone approaches and other state-of-the-art techniques, showcasing the potential of combining transformer and cross-modal attention for improved sleep stage classification. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Mostafaei2024novel
ER  -

TY  - JOUR
AU  - Sun, S.
AU  - Gong, X.
TI  - Event-driven weakly supervised video anomaly detection
PY  - 2024
T2  - Image and Vision Computing
VL  - 149
C7  - 105169
DO  - 10.1016/j.imavis.2024.105169
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199539252&doi=10.1016%2fj.imavis.2024.105169&partnerID=40&md5=857c162f6317d87ecee2ea2b8739060c
AB  - Inspired by the observations of human working manners, this work proposes an event-driven method for weakly supervised video anomaly detection. Complementary to the conventional snippet-level anomaly detection, this work designs an event analysis module to predict the event-level anomaly scores as well. It first generates event proposals simply via a temporal sliding window and then constructs a cascaded causal transformer to capture temporal dependencies for potential events of varying durations. Moreover, a dual-memory augmented self-attention scheme is also designed to capture global semantic dependencies for event feature enhancement. The network is learned with a standard multiple instance learning (MIL) loss, together with normal-abnormal contrastive learning losses. During inference, the snippet- and event-level anomaly scores are fused for anomaly detection. Experiments show that the event-level analysis helps to detect anomalous events more continuously and precisely. The performance of the proposed method on three public datasets demonstrates that the proposed approach is competitive with state-of-the-art methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Sun2024Event-driven
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Guo, B.
AU  - Zhang, F.
AU  - Chen, J.
AU  - Chen, R.
TI  - Prompt guidance query with cascaded constraint decoders for human–object interaction detection
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 6
SP  - 772
EP  - 787
DO  - 10.1049/cvi2.12276
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189625642&doi=10.1049%2fcvi2.12276&partnerID=40&md5=6a35a55b3083b485e17b522cf625d1bf
AB  - Human–object interaction (HOI) detection, which localises and recognises interactions between human and object, requires high-level image and scene understanding. Recent methods for HOI detection typically utilise transformer-based architecture to build unified future representation. However, these methods use random initial queries to predict interactive human–object pairs, leading to a lack of prior knowledge. Furthermore, most methods provide unified features to forecast interactions using conventional decoder structures, but they lack the ability to build efficient multi-task representations. To address these problems, we propose a novel two-stage HOI detector called PGCD, mainly consisting of prompt guidance query and cascaded constraint decoders. Firstly, the authors propose a novel prompt guidance query generation module (PGQ) to introduce the guidance-semantic features. In PGQ, the authors build visual-semantic transfer to obtain fuller semantic representations. In addition, a cascaded constraint decoder architecture (CD) with random masks is designed to build fine-grained interaction features and improve the model's generalisation performance. Experimental results demonstrate that the authors’ proposed approach obtains significant performance on the two widely used benchmarks, that is, HICO-DET and V-COCO. © 2024 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2024Prompt
ER  -

TY  - JOUR
AU  - Parri, S.
AU  - Teeparthi, K.
TI  - SVMD-TF-QS: An efficient and novel hybrid methodology for the wind speed prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123516
DO  - 10.1016/j.eswa.2024.123516
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185845182&doi=10.1016%2fj.eswa.2024.123516&partnerID=40&md5=f0d11fd9e49565b0642f0eb112227988
AB  - Wind power is gaining significant attention as a renewable and environmentally friendly energy source. However, accurate forecasting of wind speed poses challenges due to its inherent variability and stochastic nature. To address this issue, a novel hybrid model (SVMD-TF-QS) for wind speed prediction (WSP) is proposed in this study. The model combines successive variational mode decomposition (SVMD) with a Transformer (TF) based model that incorporates a novel query selection (QS) mechanism. The SVMD component of the hybrid model offers several improvements, including enhanced mode extraction, adaptive mode determination, robustness against initial values of center frequencies, and improved computational efficiency. By decomposing the wind speed data using SVMD, the transformed data is then fed into the TF-QS model. The proposed approach effectively combines the benefits of the QS mechanism and the Transformer model to accurately predict wind speed while minimizing computational load. This is achieved by introducing a deterministic algorithm within the QS mechanism, which computes a sparse approximation of the attention matrix used in the Transformer model. This further enhances the predictive capabilities of the hybrid model. To evaluate its performance and generalization capability, extensive assessments are conducted using data from two wind farms located in Leicester and Portland. The assessments cover various time periods, including 5 min, 10 min, 15 min, 30 min, 1 h, and 2 h WSP intervals. The results of this study provide robust evidence supporting the effectiveness of the proposed hybrid model in WSP for the diverse wind farms and scenarios. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Parri2024SVMD-TF-QS
ER  -

TY  - JOUR
AU  - Zhu, S.
AU  - Li, S.
AU  - Xiong, D.
TI  - VisTFC: Vision-guided target-side future context learning for neural machine translation[Formula presented]
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123411
DO  - 10.1016/j.eswa.2024.123411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185406599&doi=10.1016%2fj.eswa.2024.123411&partnerID=40&md5=40e98b7610cde3cf383893ed23fe03ec
AB  - Visual features encompass visual information extracted from images or videos, serving as supplementary input to enhance the efficacy of neural machine translation (NMT) systems. By seamlessly integrating these visual features into the translation process, NMT models can tap into the expansive visual context, thereby making more precise predictions during translation. Nonetheless, limited efforts have been directed towards exploring the potential of learning target-side future context using visual features to augment NMT performance. To bridge this gap, this paper introduces the Vision-guided Target-side Future Context (VisTFC) learning framework for NMT. Our core objective is to refine translation quality by effectively harnessing and incorporating target-side future contextual insights derived from the visual modality. The VisTFC framework consists of three pivotal components. Firstly, a graph-based multimodal encoder–decoder is established, constructing a bipartite vision-source/target graph. This enables the acquisition of vision-fused textual representations, synthesizing both linguistic and visual attributes to enhance translation accuracy. Secondly, a target-side future context predictor, incorporating a dynamic routing mechanism, infers future context by synergizing visual information. This empowers the model to anticipate and assimilate contextual cues, ensuring more coherent and contextually coherent translations. Thirdly, a sigmoid update gate is introduced, facilitating controlled integration of predicted future context into the decoding process, enabling the decoder to flexibly adapt and utilize the inferred context. Moreover, the VisTFC framework is fortified with additional loss functions that enforce source/target-vision consistency, reinforcing its robustness and effectiveness. Our results demonstrate that our model can achieve substantial improvements, reaching up to 1.0/0.9/1.1 BLEU points beyond the performance of the most robust baselines. This superior performance is evident on both the Test2016 and Test2017 datasets, as well as on the MSCOCO test sets for English-French translation tasks. Furthermore, our experiments underscore the efficacy of VisTFC, even in scenarios with limited resources, such as the English-Hausa language pair. Here, the model achieves notable enhancements, with improvements of up to 1.8/1.9 BLEU points compared to the strongest text-only NMT models on E-Test and C-Test test sets. These findings provide strong evidence supporting our model's ability to effectively harness target-side future contextual information from the visual modality, resulting in substantial enhancements in machine translation quality. Further analysis and visualization suggest that VisTFC is capable of learning target-side future context from visual signals for better translation. We also have open-sourced our work in Github. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhu2024VisTFC
ER  -

TY  - JOUR
AU  - Darko, A.P.
AU  - Antwi, C.O.
AU  - Adjei, K.
AU  - Zhang, B.
AU  - Ren, J.
TI  - Predicting determinants influencing user satisfaction with mental health app: An explainable machine learning approach based on unstructured data
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123647
DO  - 10.1016/j.eswa.2024.123647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187783064&doi=10.1016%2fj.eswa.2024.123647&partnerID=40&md5=6399450ebaaf98fbac879fedff86d5ba
AB  - In the contemporary digital landscape, the rising concern for mental health has sparked a surge in the use of mental health apps (MHAs) as accessible tools for addressing psychological well-being. Maintaining a high level of user satisfaction (USAT) is important for MHAs in the highly competitive app market. Leveraging BERT (Bidirectional Encoder Representations from Transformers), a state-of-the-art deep learning (DL) model, we perform topic modeling and sentiment analysis on 17,717 user online reviews. Specifically, we employ the BERTopic model to identify the determinants of USAT with MHAs. Utilizing a BERT-base-multilingual-uncase-sentiment model, we perform sentiment analysis to distinguish determinants that elicit satisfaction from those causing dissatisfaction. Also, this study tests and compares six machine learning (ML) algorithms to predict the influence of determinants on USAT with MHAs. The Light Gradient Boosting Machine (LightGBM) emerges as the top performer, showcasing its efficacy in predicting USAT determinants. By using SHAP (Shapley Additive exPlanations), an explainable ML model with cross-validation, we visualize the results of the LightGBM. The SHAP values show that the five most influential determinants of USAT with MHAs include soothing audio experience, smoking cessation support, payment and subscription management, tracking progress and mindful meditation experience. This study facilitates a deeper understanding of user experiences through the identification and prediction of determinants of USAT with MHAs. Understanding these factors and their interplay is essential for developers, clinicians, and stakeholders who aim to enhance MHAs’ services and ultimately improve the well-being of users. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Darko2024Predicting
ER  -

TY  - JOUR
AU  - Bi, S.
AU  - Ali, Z.
AU  - Wu, T.
AU  - Qi, G.
TI  - Knowledge-enhanced model with dual-graph interaction for confusing legal charge prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123626
DO  - 10.1016/j.eswa.2024.123626
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187235986&doi=10.1016%2fj.eswa.2024.123626&partnerID=40&md5=1c4005722c0c1b33ce81f38af221e67a
AB  - The rapid development of natural language processing (NLP) technologies has enabled the emergence of legal intelligence assistance systems, with legal charge prediction (LCP) being a critical technology. The automatic LCP aims to determine the final charges based on fact descriptions of criminal cases. LCP assists human judges in managing workloads and improving efficiency, provides accessible legal guidance for individuals, and supports enterprises in litigation financing and compliance monitoring. However, distinguishing between confusing charges in real-world judicial practice remains a significant challenge. Most exist works cannot effectively capture complex relationships and discern subtle differences in fact descriptions while ignoring the legal schematic knowledge. In order to improve confusing LCP performance, we propose a novel knowledge-aware model for legal charge prediction that leverages Graph Neural Networks (GNNs) to capture complex relationships within criminal case descriptions. Specifically, the model constructs structural and semantic graphs from fact descriptions and integrates information from both through a dual-graph interaction process. A legal knowledge transformer generates key knowledge representations at schema and charge levels, while a knowledge matching network incorporates hierarchical charge knowledge into facts. Besides, we also propose two real-world datasets namely Criminal-All and Criminal-Confusing, containing 203 different charges and 86 confusing charges, respectively. To the best of our knowledge, these datasets are the first well-organized datasets for confusing LCP task. Experimental results demonstrate that the proposed model outperforms baselines and significantly improves the distinction of confusing charges, providing valuable support for intelligent legal judgment systems. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Bi2024Knowledge-enhanced
ER  -

TY  - JOUR
AU  - Fischer, T.
AU  - Sterling, M.
AU  - Lessmann, S.
TI  - Fx-spot predictions with state-of-the-art transformer and time embeddings
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123538
DO  - 10.1016/j.eswa.2024.123538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187712684&doi=10.1016%2fj.eswa.2024.123538&partnerID=40&md5=0e15d1181964c82eaa2f7702fe00595d
AB  - The transformer architecture with its attention mechanism is the state-of-the-art deep learning method for sequence learning tasks and has achieved superior results in many areas such as NLP. Utilizing the transformer architecture for the prediction of sequential time series such as financial time series has hardly been investigated in previous studies. In this research paper, the transformer architecture with time embeddings is used in foreign exchange (FX) trading, the world's largest financial market, and tests its suitability. A systematic comparison is made between transformer and benchmark models. It also examined which influence multivariate, cross-sectional input data have on the forecasting performance of the various models. The goal of the paper is to contribute to the empirical literature on FX forecasting by introducing a transformer with time embeddings to the forecasting community and assessing the accuracy of corresponding models by forecasting exchange rate movements. Empirical results indicate the suitability of transformer models for FX-Spot forecasting in general but also evidence the need for transformer models for multivariate, cross-sectional input data to outperform other state-of-the-art neural networks such as LSTM. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Fischer2024Fx-spot
ER  -

TY  - JOUR
AU  - Kim, H.
AU  - Hong, T.
TI  - Enhancing emotion recognition using multimodal fusion of physiological, environmental, personal data
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123723
DO  - 10.1016/j.eswa.2024.123723
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188634661&doi=10.1016%2fj.eswa.2024.123723&partnerID=40&md5=5ad3d54e4daa2b855b6c8eac099c4bf4
AB  - Human emotion recognition, crucial for interpersonal relations and human-building interaction, identifies emotions from various behavioral signals to improve user interactions. To enhance the performance of emotion recognition, this study proposed a novel model that fuses physiological, environmental, and personal data. A unique dataset was created via experiments conducted in an environmental chamber, and an emotion recognition model was subsequently developed using a multimodal fusion approach. The model transforms physiological data into 2D images to capture time series and spatial features and uniquely incorporates metadata, including environmental and personal data. The model's generalizability was validated using a leave-one-sample-out approach. The result showed 31.6% reduction of error with a predicted area when physiological, environmental, and personal data were fused in the emotion recognition model, suggesting that incorporating various contextual factors beyond physiological changes, such as the surrounding environment and inherent or acquired individual traits, can significantly enhance the model's understanding of emotions. Furthermore, the model was to be robust to individual differences, offering consistent emotion recognition across different subjects. These findings suggest that the proposed model can serve as a potent tool for emotion recognition in built environmental applications. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kim2024Enhancing
ER  -

TY  - JOUR
AU  - Zeng, X.
AU  - Jiang, Y.
AU  - Wang, Y.
AU  - Fu, Q.
AU  - Ding, W.
TI  - Progressive prediction: Video anomaly detection via multi-grained prediction
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 10
SP  - 2568
EP  - 2583
DO  - 10.1049/ipr2.13117
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194927729&doi=10.1049%2fipr2.13117&partnerID=40&md5=90c8a8b98f38217d47c3ca0346a90ad6
AB  - Video Anomaly Detection (VAD) has been an active research field for several decades. However, most existing approaches merely extract a single type of feature from videos and define a single paradigm to indicate the extent of abnormalities. A coarse-to-fine three-level prediction is built by integrating different levels of spatio-temporal representations, better highlighting the difference between normal and abnormal behaviors. First, an object-level trajectory prediction is proposed to model human historical position using a graph transformer network. Subsequently, skeleton-level prediction is achieved by incorporating the positional information from the trajectory prediction. More importantly, based on the predicted skeleton, a skeleton-guided pixel-level region prediction is performed. A novel Skeleton Conditioned Generative Adversarial Network (SCGAN) is designed to explore the correlation between skeleton-level and pixel-level motion prediction. Benefiting from SCGAN, the prediction of human regions is contributed by both coarse-grained and fine-grained motion features. This three-level prediction, namely Progressive Prediction Video Anomaly Detection (P3VAD), enlarges the prediction error on irregular motion patterns. Besides, a pixel-level analysis method is proposed to achieve Background-bias Elimination (BE) and denoise the predicted region. Experimental results validate the effectiveness of P3VAD on the four benchmark datasets (ShanghaiTech, CUHK Avenue, IITB-Corridor, and ADOC). © 2024 The Author(s). IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zeng2024Progressive
ER  -

TY  - JOUR
AU  - Zeng, W.
AU  - Lin, Q.
AU  - Zhu, B.
AU  - Peng, C.
AU  - Yu, R.
TI  - Modeling vehicle U-turning behavior near intersections: A deep learning approach based on TCN and multi-head attention
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123674
DO  - 10.1016/j.eswa.2024.123674
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188721545&doi=10.1016%2fj.eswa.2024.123674&partnerID=40&md5=a1bac7e5a4c45a4a93a3a9dbc99b55cc
AB  - In U-turn bays near intersections, the conflict between U-turning vehicles and those going straight-ahead results in traffic accidents since straight-ahead vehicles cannot reliably anticipate the behavior of oncoming U-turning vehicles. However, previous studies on modeling U-turning behavior do not effectively capture the spatial–temporal interaction between the U-turning and surrounding vehicles. To address this issue, a deep-learning framework based on a temporal convolutional network (TCN) and multi-head attention mechanism is developed. The TCN is utilized to capture long-term dependencies of vehicles in the shared left- and U-turn lanes by extracting vehicle historical motion features. The self-attention mechanism extracts salient features related to the U-turn intentions, classifying the vehicles into left- and U-turning vehicles based on their driving intentions. A parallel TCN and spatial multi-head attention structure is constructed to model vehicle–vehicle interactions to further predict the future trajectory of U-turning vehicles. Finally, the obtained features are input into a Transformer-based decoder module and trajectory generator to predict the future displacement and body orientation of U-turning vehicles. The model is validated via comparison with state-of-the-art models and the observed trajectories under various scenarios. Ablation studies are conducted to quantify the efficacy of each module. Further, the effect of the surrounding homogenous and heterogeneous vehicles on U-turning vehicles in four different U-turn scenarios is quantified using spatial–temporal variation graphs and attention matrices. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zeng2024Modeling
ER  -

TY  - JOUR
AU  - Cao, H.
AU  - Xiao, W.
AU  - Sun, J.
AU  - Gan, M.-G.
AU  - Wang, G.
TI  - A hybrid data- and model-driven learning framework for remaining useful life prognostics
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 135
C7  - 108557
DO  - 10.1016/j.engappai.2024.108557
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196523356&doi=10.1016%2fj.engappai.2024.108557&partnerID=40&md5=1ea716641da796b6f5584b2f06136ffa
AB  - The efficient and safe production of machinery equipment relies on the health of its mechanical components, making prognostics and health management (PHM) a critical aspect of production processes. One key PHM measure is the remaining useful life (RUL), which estimates the expected lifespan of a component in a production line before requiring repair or replacement. However, state-of-the-art RUL prediction methods, including data-driven, model-based, and hybrid approaches, face limitations such as incomplete/imprecise physical models, uncertainties in degradation processes, and measurement data noise. To address these limitations, this paper proposes a novel hybrid RUL prediction framework that combines the strengths of data-based and model-driven approaches. The framework includes an exponential model to leverage physical knowledge and a multi-head attention transformer to extract information from data. An extended Kalman filter is used to estimate unknown degradation process parameters and provide physical model information for the prediction process. A regression token is introduced to efficiently fuse the deep learning model and the stochastic filtering method. Numerical tests using real-world rolling bearing degradation datasets demonstrate the superiority of the proposed method over competitive alternatives. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Cao2024hybrid
ER  -

TY  - JOUR
AU  - Lu, C.
AU  - Mak, M.-W.
TI  - DITA: DETR with improved queries for end-to-end temporal action detection
PY  - 2024
T2  - Neurocomputing
VL  - 596
C7  - 127914
DO  - 10.1016/j.neucom.2024.127914
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195816136&doi=10.1016%2fj.neucom.2024.127914&partnerID=40&md5=5688ee0488ed22f4ec1071f0edfde80a
AB  - The DEtection TRansformer (DETR), with its elegant architecture and set prediction, has revolutionized object detection. However, DETR-like models have yet to achieve comparable success in temporal action detection (TAD). To address this gap, we introduce a series of improvements to the original DETR, proposing a new DETR-based model for TAD that achieves competitive performance relative to conventional TAD methods. Specifically, we adapt advanced techniques from DETR variants used in object detection, including deformable attention, denoising training, and selective query recollection. Furthermore, we propose several new techniques aimed at enhancing detection precision and model convergence speed, such as geographic query grouping and learnable proposals. Leveraging these innovations, we introduce a new model called DETR with Improved queries for Temporal Action Detection (DITA). DITA not only adheres to DETR's elegant design philosophy but is also competitive to state-of-the-art action detection models. Remarkably, it is the first TAD model to achieve an mAP over 70% on THUMOS14, outperforming the previous best DETR variant by 13.5 percentage points. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Lu2024DITA
ER  -

TY  - JOUR
AU  - Azam, S.
AU  - Munir, F.
AU  - Kyrki, V.
AU  - Kucner, T.P.
AU  - Jeon, M.
AU  - Pedrycz, W.
TI  - Exploring Contextual Representation and Multi-modality for End-to-end Autonomous Driving
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 135
C7  - 108767
DO  - 10.1016/j.engappai.2024.108767
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195421264&doi=10.1016%2fj.engappai.2024.108767&partnerID=40&md5=13bb197ef62fd84391ece8b5fffd383b
AB  - Learning contextual and spatial environmental representations enhances autonomous vehicle's hazard anticipation and decision-making in complex scenarios. Recent perception systems enhance spatial understanding with sensor fusion but often lack global environmental context. Humans, when driving, naturally employ neural maps that integrate various factors such as historical data, situational subtleties, and behavioral predictions of other road users to form a rich contextual understanding of their surroundings. This neural map-based comprehension is integral to making informed decisions on the road. In contrast, even with their significant advancements, autonomous systems have yet to fully harness this depth of human-like contextual understanding. Motivated by this, our work draws inspiration from human driving patterns and seeks to formalize the sensor fusion approach within an end-to-end autonomous driving framework. We introduce a framework that integrates three cameras (left, right, and center) to emulate the human field of view, coupled with top-down bird-eye-view semantic data to enhance contextual representation. The sensor data is fused and encoded using a self-attention mechanism, leading to an auto-regressive waypoint prediction module. We treat feature representation as a sequential problem, employing a vision transformer to distill the contextual interplay between sensor modalities. The efficacy of the proposed method is experimentally evaluated in both open and closed-loop settings. Our method achieves displacement error by 0.67m in open-loop settings, surpassing current methods by 6.9% on the nuScenes dataset. In closed-loop evaluations on CARLA's Town05 Long and Longest6 benchmarks, the proposed method enhances driving performance, route completion, and reduces infractions. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Azam2024Exploring
ER  -

TY  - JOUR
AU  - Buoy, R.
AU  - Iwamura, M.
AU  - Srun, S.
AU  - Kise, K.
TI  - Towards reduced-complexity scene text recognition (RCSTR) through a novel salient feature selection
PY  - 2024
T2  - International Journal on Document Analysis and Recognition
VL  - 27
IS  - 3
SP  - 289
EP  - 302
DO  - 10.1007/s10032-024-00474-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193753410&doi=10.1007%2fs10032-024-00474-x&partnerID=40&md5=ce69acca79c129a99cccdd29f2289923
AB  - The integration of an attention mechanism has played a crucial role in many recent scene text recognition (STR) methods. It enables the capture of spatial feature dependencies (known as self-attention) and the identification of relevant features while predicting a character (known as cross-attention). However, computations and memory requirements in the self-attention and cross-attention layers increase quadratically and linearly with the feature map size, respectively, leading to a computational bottleneck in low-resource environments. But, is it necessary to attend to the entire feature maps? On the other hand, text in a natural scene is continuous and oriented in a specific direction, and it does not occupy the entire image. Therefore, utilizing only a small salient subset of features in text regions is sufficient for accurately predicting characters. Based on this salient feature selection, we propose a reduced-complexity scene text recognition framework that significantly reduces model complexities and memory requirements in the self-attention and cross-attention layers. We validate the proposed framework by employing a convolutional STR architecture with both connectionist temporal classification and transformer decoders. Through the model complexity and performance analyses on public benchmark datasets, we demonstrate that the proposed method can substantially reduce model complexities while still maintaining reasonably robust recognition accuracy. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Buoy2024Towards
ER  -

TY  - JOUR
AU  - Feng, J.
AU  - Wu, P.
AU  - Xu, R.
AU  - Zhang, X.
AU  - Wang, T.
AU  - Li, X.
TI  - CSFNet: a compact and efficient convolution-transformer hybrid vision model
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 29
SP  - 72679
EP  - 72699
DO  - 10.1007/s11042-024-18417-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184928031&doi=10.1007%2fs11042-024-18417-3&partnerID=40&md5=6d666c9616ea85362be0f6a85078f8e4
AB  - The Vision Transformer (ViT) has demonstrated impressive performance in various visual tasks, but its high computational requirements limit its applicability on edge devices. Conversely, convolutional neural networks (CNNs) are commonly used in mobile applications, but their static and weak global properties hinder their performance. In this work, we propose a lightweight, high-density predictive classification hybrid-based model called CSFNet, which combines good local inductive bias capability with long-distance modeling property. To establish local-global information association, we introduce two layered structures. Firstly, we use the Local-Attention Block (LAB) with adaptive kernels and channel expansion ratio to aggregate n×n local information layer by layer, capturing multi-stage detail features and inducing efficient local inductive properties. Secondly, we introduce a linear complexity Channel-Spatial Fusion Attention (CSFA) that projects the attention matrix from both channel and tokens dimensions. The relationships between tokens are aggregated stage by stage to encode efficient contextual association information using low-rank matrix and element-by-element operations to reduce computational complexity. Experimental results demonstrate that our proposed CSFNet-XXS/XS/S models with 1.4M/2.4M/5.6M parameters and 0.3G/0.5G/1.1G multiply-adds (MAdds) achieve 70.23%/74.91%/78.82% top-1 accuracy on ImageNet-1k with competitive performance compared to recent mainstream methods. Furthermore, CSFNet performs well on small-scale datasets, MS-COCO2017 and ADE-20K. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Feng2024CSFNet
ER  -

TY  - JOUR
AU  - Jawad, M.A.
AU  - Khursheed, F.
AU  - Nawaz, S.
AU  - Mir, A.H.
TI  - Towards improved fundus disease detection using Swin Transformers
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 32
SP  - 78125
EP  - 78159
DO  - 10.1007/s11042-024-18627-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186186121&doi=10.1007%2fs11042-024-18627-9&partnerID=40&md5=158a89997ef2fa2b23399331feec487d
AB  - Ocular diseases can have debilitating consequences on visual acuity if left untreated, necessitating early and accurate diagnosis to improve patients' quality of life. Although the contemporary clinical prognosis involving fundus screening is a cost-effective method for detecting ocular abnormalities, however, it is time-intensive due to limited resources and expert ophthalmologists. While computer-aided detection, including traditional machine learning and deep learning, has been employed for enhanced prognosis from fundus images, conventional deep learning models often face challenges due to limited global modeling ability, inducing bias and suboptimal performance on unbalanced datasets. Presently, most studies on ocular disease detection focus on cataract detection or diabetic retinopathy severity prediction, leaving a myriad of vision-impairing conditions unexplored. Minimal research has been conducted utilizing deep models for identifying diverse ocular abnormalities from fundus images, with limited success. The study leveraged the capabilities of four Swin Transformer models (Swin-T, Swin-S, Swin-B, and Swin-L) for detecting various significant ocular diseases (including Cataracts, Hypertensive Retinopathy, Diabetic Retinopathy, Myopia, and Age-Related Macular Degeneration) from fundus images of the ODIR dataset. Swin Transformer models, confining self-attention to local windows while enabling cross-window interactions, demonstrated superior performance and computational efficiency. Upon assessment across three specific ODIR test sets, utilizing metrics such as AUC, F1-score, Kappa score, and a composite metric representing an average of these three (referred to as the final score), all Swin models exhibited superior performance metric scores than those documented in contemporary studies. The Swin-L model, in particular, achieved final scores of 0.8501, 0.8211, and 0.8616 on the Off-site, On-site, and Balanced ODIR test sets, respectively. An external validation on a Retina dataset further substantiated the generalizability of Swin models, with the models reporting final scores of 0.9058 (Swin-T), 0.92907 (Swin-S), 0.95917 (Swin-B), and 0.97042 (Swin-L). The results, corroborated by statistical analysis, underline the consistent and stable performance of Swin models across varied datasets, emphasizing their potential as reliable tools for multi-ocular disease detection from fundus images, thereby aiding in the early diagnosis and intervention of ocular abnormalities. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jawad2024Towards
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liu, H.
AU  - Chen, Y.
AU  - Chen, D.
TI  - Probabilistic gear fatigue life prediction based on physics-informed transformer
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123882
DO  - 10.1016/j.eswa.2024.123882
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189653227&doi=10.1016%2fj.eswa.2024.123882&partnerID=40&md5=757024bfe94075f155108a0d56ff16fa
AB  - Gear fatigue testing is a complex process that is both time-consuming and labor-intensive, and often produces dispersed results. Traditional statistical analysis methods for probability-stress-life (P-S-N) and fatigue limit require large sample sizes. This study proposes a novel probabilistic gear fatigue life prediction method based on physics-informed Transformer. This method seeks to overcome the limitations of traditional statistical analysis methods and data-driven models by integrating stress-life physical knowledge with the data-driven model. Specifically, based on the obtained gear fatigue limit, this method predicts the probabilistic fatigue life at each stress level by using only a set of probability distribution characteristics of fatigue life under constant amplitude load. The proposed method was validated through multiple cases of gear bending fatigue tests with varying materials, treatments, and geometries, and prediction errors were within an error factor of 2. Compared with other traditional machine learning methods, the accuracy of life prediction was improved by 19.74% to 29.44%. Additionally, feature analysis was conducted to identify key parameters influencing the accuracy of probabilistic fatigue life prediction and provide a range of optimal parameter selection, which is expected to significantly promote the efficiency of fatigue basic data construction in the gear industry. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024Probabilistic
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Chen, N.
AU  - Deng, Z.
AU  - Huang, S.
TI  - Multivariate time series anomaly detection via dynamic graph attention network and Informer
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 17-18
SP  - 7636
EP  - 7658
DO  - 10.1007/s10489-024-05575-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195686367&doi=10.1007%2fs10489-024-05575-y&partnerID=40&md5=fab89cc08b6d67de589afa4f630cc679
AB  - In the industrial Internet, industrial software plays a central role in enhancing the level of intelligent manufacturing. It enables the promotion of digital collaborative services. Effective anomaly detection of multivariate time series can ensure the quality of industrial software. Extensive research has been conducted on time series anomaly detection to identify abnormal data. However, detecting anomalies in multivariate time series, which consist of high-dimensional, high-noise, and random data, poses significant challenges. The states of different timestamps within a time series sample can influence the overall correlation of sensor features. Unfortunately, existing methods often overlook this impact, making it difficult to capture subtle variations in the delayed response of attacked sensors.Consequently, there are false alarms and abnormal omissions. To address these limitations, this paper proposes an anomaly detection method called DGINet. DGINet leverages a dynamic graph attention network and Informer to capture and integrate feature correlation across different time states. By combining GRU and Informer, DGINet effectively captures continuous correlations in long time series. Moreover, DGINet simultaneously optimizes the reconstruction and forecasting modules, enhancing its overall performance. Experimental results on four benchmark datasets demonstrate that DGINet outperforms state-of-the-art methods by achieving up to a 2% improvement in accuracy. Further analysis reveals that DGINet excels in accurately detecting anomalies in long time series and locating candidate abnormal attack points. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Huang2024Multivariate
ER  -

TY  - JOUR
AU  - Cai, J.
AU  - Wang, C.-H.
AU  - Hu, K.
TI  - LCDFormer: Long-term correlations dual-graph transformer for traffic forecasting
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123721
DO  - 10.1016/j.eswa.2024.123721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188729855&doi=10.1016%2fj.eswa.2024.123721&partnerID=40&md5=076ed87ea47b955295bf805f1ce40a37
AB  - Traffic forecasting has always been a critical component of intelligent transportation systems. Due to the complexity of traffic prediction models, most research just only consider short-term historical data in the temporal dimension. However, learning temporal patterns necessitates the involvement of long-term historical data. Additionally, many models are limited in capturing spatial features by only considering short-distance spatial information connected to the target node. To solve these problems, we propose a dual-graph transformer, namely Long-term Correlations Dual-graph transFormer (LCDFormer), designed to capture long-term correlations and long-distance spatial correlations. It is entirely based on attention mechanisms, and as far as we know, there is limited research adopting this approach. Our work addresses this gap in the literature. In particular, we have devised a time aggregation method capable of consolidating long-term historical time series, concurrently addressing the impact of long-term temporal correlations while minimizing the influence of redundant data. Subsequently, we have introduced a novel spatio-temporal attention module that compresses spatial information to generate short-term input sequences while modeling dynamic long-range spatial correlations. We conducted extensive experiments with LCDFormer on five real-world traffic datasets. The results indicate that LCDFormer, considering long-term spatio-temporal correlations, is better able to learn the spatio-temporal patterns of traffic data. Compared to the current state-of-the-art baseline, our model has demonstrated outstanding predictive performance with a maximum improvement of 5.02% in mean absolute error, 4.33% in root mean square error and 7.32% in mean absolute percentage error. The source codes are available at: https://github.com/NanakiC/LCDFormer. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Cai2024LCDFormer
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Ding, F.
AU  - Dai, Y.
AU  - Li, L.
AU  - Chen, T.
AU  - Tan, H.
TI  - Spatial-temporal graph convolution network model with traffic fundamental diagram information informed for network traffic flow prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123543
DO  - 10.1016/j.eswa.2024.123543
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187700950&doi=10.1016%2fj.eswa.2024.123543&partnerID=40&md5=ae862c20546edc67000580f1302eda31
AB  - Accurate and fine-grained traffic state prediction has always been an important research field. For long-term traffic flow prediction, the high-dimensional and coupled traffic feature evolution patterns are deeply recessive, posing challenges in effectively characterizing and modeling them. This paper proposed a novel spatial–temporal graph convolution network model with traffic Fundamental Diagram (FD) information informed. The model decouples the high-dimensional spatiotemporal relationships in the transportation network and fully leverages the physical evolution laws of traffic states. First, the Graph Convolutional Network (GCN) with a spatial attention mechanism was proposed to capture spatial relations of the road network. The mechanism can better represent the spatial dynamics of the graph adjacency matrix in GCN. Second, this study injected prior physical knowledge into the graph adjacency matrix. This process was achieved by embedding characteristics of FDs from historical traffic data on the diagonal of the matrix, by which the propagation pattern of traffic states in road network could be considered. Third, to further catch the time dependence of the road network, the Gated Recurrent Unit (GRU) structure and the Transformer encoding structure were employed to locally and globally reform traffic state time sequences. Finally, experiments on a revised traffic dataset demonstrated that the proposed method consistently outperforms other baselines regarding Mean Absolute Error and Root Mean Square Error across all cases. Moreover, it achieved the optimal Mean Absolute Percentage Error in the 30- and 60-minute prediction tasks. This study shows a novel solution to inform traffic physical laws into data-driven state prediction models, and the reliability of the proposed method in long-term prediction offers valuable support for improving traffic management and alleviating traffic congestion. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2024Spatial-temporal
ER  -

TY  - JOUR
AU  - Suneera, C.M.
AU  - Prakash, J.
AU  - Alaparthi, V.S.
TI  - Predicting semantic category of answers for question answering systems using transformers: a transfer learning approach
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 32
SP  - 77393
EP  - 77413
DO  - 10.1007/s11042-024-18609-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185957501&doi=10.1007%2fs11042-024-18609-x&partnerID=40&md5=283be47f79b8c6f25b35590447402447
AB  - A question-answering (QA) system is a key application in the field of natural language processing (NLP) that provides relevant answers to user queries written in natural language. In factoid QA using knowledge bases, predicting the semantic category of answers, such as location, person, or numerical values, helps to reduce the search spaces and is an essential step in formal query construction for answer retrieval. However, finding the semantics in sequence data like questions is challenging. In this regard, Recursive neural networks based deep learning methods have been applied. But, they are inefficient in handling long-term dependencies. Recently, pre-trained language models employing transformers are proven effective and can generate context-dependent embedding for words and sentences from their encoders with attention mechanisms. However, to train an efficient transformer model for semantic category prediction requires a large dataset and high computational resources. Therefore, in this work, we employ a transfer learning approach using pre-trained transformer models by efficiently adapting them to predict the semantic category of answers from input questions. Here, embeddings from the encoders of the text-to-text transfer transformer (T5) model have been leveraged to obtain an efficient question representation and to train the classification model which is named as QcT5. Along with QcT5, an extensive experimental study on other recent transformer models - BERT, RoBERTa, DeBERTa, and XLNet, is conducted, and their performance is analyzed in various fine-tuning settings. Experimental results indicate that the QcT5 model significantly improves the performance compared to the selected state-of-the-art methods by achieving an f1-score of 98.7%, 89.9% on TREC-6, and TREC-50 datasets respectively. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Suneera2024Predicting
ER  -

TY  - JOUR
AU  - Banerjee, A.
AU  - Biswas, S.
AU  - Lladós, J.
AU  - Pal, U.
TI  - SemiDocSeg: harnessing semi-supervised learning for document layout analysis
PY  - 2024
T2  - International Journal on Document Analysis and Recognition
VL  - 27
IS  - 3
SP  - 317
EP  - 334
DO  - 10.1007/s10032-024-00473-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195414364&doi=10.1007%2fs10032-024-00473-y&partnerID=40&md5=d59e051e60534461f717e73af2e8ab76
AB  - Document Layout Analysis (DLA) is the process of automatically identifying and categorizing the structural components (e.g. Text, Figure, Table, etc.) within a document to extract meaningful content and establish the page’s layout structure. It is a crucial stage in document parsing, contributing to their comprehension. However, traditional DLA approaches often demand a significant volume of labeled training data, and the labor-intensive task of generating high-quality annotated training data poses a substantial challenge. In order to address this challenge, we proposed a semi-supervised setting that aims to perform learning on limited annotated categories by eliminating exhaustive and expensive mask annotations. The proposed setting is expected to be generalizable to novel categories as it learns the underlying positional information through a support set and class information through Co-Occurrence that can be generalized from annotated categories to novel categories. Here, we first extract features from the input image and support set with a shared multi-scale feature acquisition backbone. Then, the extracted feature representation is fed to the transformer encoder as a query. Later on, we utilize a semantic embedding network before the decoder to capture the underlying semantic relationships and similarities between different instances, enabling the model to make accurate predictions or classifications with only a limited amount of labeled data. Extensive experimentation on competitive benchmarks like PRIMA, DocLayNet, and Historical Japanese (HJ) demonstrate that this generalized setup obtains significant performance compared to the conventional supervised approach. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Banerjee2024SemiDocSeg
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Yang, S.
AU  - Wang, Y.
AU  - Yang, G.
TI  - PPTtrack: Pyramid pooling based Transformer backbone for visual tracking
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123716
DO  - 10.1016/j.eswa.2024.123716
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188815296&doi=10.1016%2fj.eswa.2024.123716&partnerID=40&md5=36f299f73b4ce22d7ead0c62881174ee
AB  - In visual tracking, Convolutional Neural Network (CNN) is usually used as feature extractor, and can fully explore local dependencies of image blocks, which is help for improving tracking performance. However, CNN ignores global dependencies in image blocks. The global modeling is crucial in visual tracking. Recently, Transformer has gained attention to fully explore global dependencies on sequential data. However, Transformer's unique multi-head self-attention mechanism results in high computational complexity. In this paper, we design a pyramid pooling based Transformer backbone network for visual tracking. Pyramid pooling refers to multiple pooling operations for feature map with different receptive fields and strides. The output data of each pooling layer is concatenated to form the final pooled feature map. On the one hand, after flattening the feature map with pyramid pooling, its sequence length will be greatly reduced. This will effectively reduce the computational complexity of the multi-head self-attention. On the other hand, pyramid pooling can extract multi-scale features, makes the feature maps contain more global context information. Finally, we propose a novel tracker with the designed pyramid pooling based Transformer backbone network and the Transformer based model predictor. We train the proposed tracker by end-to-end, and evaluate it on seven tracking benchmarks including UAV123, NFS, Trackingnet, LaSOT, GOT-10K, VOT2020 and RGBT2019. The proposed tracker achieves 79.8% robustness and 35 FPS on the VOT2020 dataset. The experiment demonstrates that proposed tracker achieves superior tracking performance with state-of-the-art trackers. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wang2024PPTtrack
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Zhao, F.
AU  - Liu, H.
AU  - Yu, J.
TI  - Data and knowledge-driven deep multiview fusion network based on diffusion model for hyperspectral image classification
PY  - 2024
T2  - Expert Systems with Applications
VL  - 249
C7  - 123796
DO  - 10.1016/j.eswa.2024.123796
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189540695&doi=10.1016%2fj.eswa.2024.123796&partnerID=40&md5=cd67e89eaddde2ac935c5573601453ce
AB  - It is a crucial means for humans to perceive geomorphic features and landscape architectures by classifying ground objects in hyperspectral images (HSIs). Currently, the exponential development of neural networks has provided a powerful support for the accurate HSI classification. However, existing neural network-based methods usually rely solely on the data to drive the classification model, lacking attention to valuable land-cover distribution knowledge in HSIs. In view of this, to utilize hyperspectral data and distribution knowledge simultaneously, a data and knowledge-driven deep multiview fusion network based on diffusion model (DKDMN) is proposed in this paper. DKDMN extracts knowledge from unlabeled data in HSIs through a diffusion model-based knowledge learning framework (DMKLF), and combines raw hyperspectral data with the acquired knowledge through a designed deep multiview network architecture (DMNA) to mine complicated land-cover distribution information and reflect sample relationships. First, the proposed DMKLF utilizes the data distribution reconstructed by the diffusion model as a knowledge source for one view to enhance the network cross-sample awareness ability. On the other hand, the original HSI patches are considered a data source for another view, which co-drives DMNA with the unsupervised diffusion knowledge extracted by DMKLF to perform effective feature extraction. Second, taking into account the characteristics of each view and the feature similarity between these two views, a joint loss function specifically for DMNA is suggested to minimize the difference between the model predictions and the real labels. Finally, a multi-backbone integration classification framework (MBICF) is designed by deeply fusing three vision architectures to capture multi-scale spectral features and local–global features, thereby achieving pixel-wise classification effectively. Experimental results on four publicly available HSI datasets demonstrate that the proposed DKDMN achieves competitive classification accuracy compared with other state-of-the-art methods. For instance, the proposed DKDMN achieves an overall accuracy improvement of 1.62% and 2.18% on the Indian Pines and Salinas Valley datasets, respectively, compared to the multiple vision architecture-based hybrid network (MVAHN). The related code will be released at https://github.com/ZJier/DKDMN. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2024Data
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Kong, D.
AU  - Gao, J.
AU  - Li, J.
AU  - Yin, B.
TI  - Joint multi-scale transformers and pose equivalence constraints for 3D human pose estimation
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 103
C7  - 104247
DO  - 10.1016/j.jvcir.2024.104247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200950006&doi=10.1016%2fj.jvcir.2024.104247&partnerID=40&md5=d939e7dace8fb254c2c152d753cd8267
AB  - Different from image-based 3D pose estimation, video-based 3D pose estimation gains performance improvement with temporal information. However, these methods still face the challenge of insufficient generalization ability, including human motion speed, body shape, and camera distance. To address the above problems, we propose a novel approach, referred to as joint Spatial–temporal Multi-scale Transformers and Pose Transformation Equivalence Constraints (SMT-PTEC) for 3D human pose estimation from videos. We design a more general spatial–temporal multi-scale feature extraction strategy, and introduce optimization constraints that adapt to the diversity of data to improve the accuracy of pose estimation. Specifically, we first introduce a spatial multi-scale transformer to extract multi-scale features of pose and establish a cross-scale information transfer mechanism, which effectively explores the underlying knowledge of human motion. Then, we present a temporal multi-scale transformer to explore multi-scale dependencies between frames, enhance the adaptability of the network to human motion speed, and improve the estimation accuracy through a context aware fusion of multi-scale predictions. Moreover, we add pose transformation equivalence constraints by changing the training samples with horizontal flipping, scaling, and body shape transformation to effectively overcome the influence of camera distance and body shape for the prediction accuracy. Extensive experimental results demonstrate that our approach achieves superior performance with less computational complexity than previous state-of-the-art methods. Code is available at https://github.com/JNGao123/SMT-PTEC. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2024Joint
ER  -

TY  - JOUR
AU  - Kharsa, R.
AU  - Elnagar, A.
AU  - Yagi, S.
TI  - BERT-Based Arabic Diacritization: A state-of-the-art approach for improving text accuracy and pronunciation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 248
C7  - 123416
DO  - 10.1016/j.eswa.2024.123416
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185405591&doi=10.1016%2fj.eswa.2024.123416&partnerID=40&md5=e4b3f0b3093bd83f5c46da44336fcfa6
AB  - In order to accurately represent the meaning and pronunciation of Arabic words and sentences, the presence of diacritics plays a crucial role. Over the years, researchers have dedicated significant efforts to enhancing automated diacritization systems. This paper introduces a novel approach for Arabic diacritization utilizing Bidirectional Encoder representations from Transformers (BERT) models. To evaluate the effectiveness of the proposed approach, two publicly available datasets, namely the Arabic Diacritization (AD) dataset and the Tashkeela Processed (TP) dataset, were employed. The performance of the models was assessed using various error metrics, including Diacritic Error Rate (DER) and Word Error Rate (WER). The findings demonstrate the superior performance of BERT in the diacritization process, surpassing all models employed in other diacritization systems. On the AD dataset, the proposed system achieved state-of-the-art (SOTA) syntactic DER and WER of 1.14% and 3.34%, respectively. For morphological diacritization, the best results yielded a DER of 0.92% and a WER of 1.91%. These outcomes reflect a remarkable relative error reduction of over 30% compared to previous research. Additionally, on the TP dataset, the BERT models exhibited a substantial decrease in DER, reducing the benchmark from 4.0% to 1.11%. Furthermore, this study introduces a real-time diacritization system called SUKOUN, which offers diacritized text through a user-friendly website. A comparison with existing automatic diacritization tools, using six example texts, reveals the superior prediction accuracy and preservation of input format provided by SUKOUN. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kharsa2024BERT-Based
ER  -

TY  - JOUR
AU  - Ahmad, M.W.
AU  - Akram, M.U.
AU  - Mohsan, M.M.
AU  - Saghar, K.
AU  - Ahmad, R.
AU  - Butt, W.H.
TI  - Transformer-based sensor failure prediction and classification framework for UAVs
PY  - 2024
T2  - Expert Systems with Applications
VL  - 248
C7  - 123415
DO  - 10.1016/j.eswa.2024.123415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184824778&doi=10.1016%2fj.eswa.2024.123415&partnerID=40&md5=3d66a1f784e8977b5ab7cdc05bafb7b1
AB  - Unmanned aerial vehicles (UAVs) heavily rely on sensors to perceive their environment, ensuring safe flight operations. However, sensor failures can occur unexpectedly, jeopardizing flight safety. To address this issue, we propose an innovative real-time solution for diagnosing and preventing sensor failures during autonomous flights. Our study is motivated by the lack of sensor failure datasets for UAVs. We contribute by generating the first comprehensive UAV sensor failures dataset, encompassing 70 autonomous flight data instances with over 7 h of flight time. Our Biomisa Arducopter Sensory Critique (BASiC) dataset includes various sensor failure scenarios, such as GPS, remote control, accelerometer, gyroscope, compass, and barometer. In this paper, we introduce an attention-based novel framework leveraging transformer neural network architecture for UAV sensor failure prediction and classification. The proposed framework analyzes our multivariate spatio-temporal BASiC dataset using transformers. We conducted ablation studies to evaluate transformer performance under different hyperparameter settings, demonstrating the effects of parameter tuning. Our framework achieved an average accuracy of 86% in predicting sensor failures, anticipating them 1 min and 2 s before occurrence - a 30-second improvement over the established LSTM-based (long short-term memory) approach. Additionally, our framework attained a 94% accuracy in classifying sensor failures. This performance evaluation highlights the potential of our optimized framework for integration in mission-critical UAVs, enabling real-time sensor failure prediction and classification. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ahmad2024Transformer-based
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Zhou, J.
AU  - Lin, Z.
AU  - Zhou, T.
TI  - Dynamic spatial aware graph transformer for spatiotemporal traffic flow forecasting
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 297
C7  - 111946
DO  - 10.1016/j.knosys.2024.111946
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193748535&doi=10.1016%2fj.knosys.2024.111946&partnerID=40&md5=089c0dbad68b9cd21d8bf62ceb3e6e8f
AB  - Accurately predicting traffic flow is a crucial upstream technique in intelligent transportation systems for future travel plans, the efficiency of urban transport, and the regulation of transport departments, etc. The mainstream spatiotemporal graph convolutional neural networks are usually based on prior knowledge to predefine adjacency matrix graphs for spatial dependencies of the road network. However, modeling spatial correlation statically limits these models to accurately predict traffic flow, since the spatial correlations of road segments change over time. To address these issues, we propose a spatiotemporal gated transformer network with a graph latent information learning structure, termed GL-STGTN, for spatiotemporal traffic flow forecasting. First, we propose a graph latent information learning structure to dynamically learn the spatial dependencies for road network conditions from global and local learning perspectives. Second, we design a spatiotemporal gated transformer network (STGTN) block, which consists of a localized geographically aware block to extract the local embedding of spatial correlations and a temporal-aware enlarged block to extract local temporal dependencies. The learned spatial and temporal feature embeddings are further aggregated in a spatial multi-head attention module and a temporal multi-head attention module, respectively. In the end, a spatiotemporal fusion layer fuses the spatial and temporal information from the stacked STGTN blocks. Experiments on two public real-world benchmark datasets show that our model outperforms six state-of-the-art models for multi-step traffic flow forecasting. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; 
LB  - Li2024Dynamic
ER  -

TY  - JOUR
AU  - Tho, B.D.
AU  - Nguyen, M.-T.
AU  - Le, D.T.
AU  - Ying, L.-L.
AU  - Inoue, S.
AU  - Nguyen, T.-T.
TI  - Improving biomedical Named Entity Recognition with additional external contexts
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 156
C7  - 104674
DO  - 10.1016/j.jbi.2024.104674
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196043671&doi=10.1016%2fj.jbi.2024.104674&partnerID=40&md5=7b2d68715e9f8b1e8394c7d1c7697714
AB  - Objective: Biomedical Named Entity Recognition (bio NER) is the task of recognizing named entities in biomedical texts. This paper introduces a new model that addresses bio NER by considering additional external contexts. Different from prior methods that mainly use original input sequences for sequence labeling, the model takes into account additional contexts to enhance the representation of entities in the original sequences, since additional contexts can provide enhanced information for the concept explanation of biomedical entities. Methods: To exploit an additional context, given an original input sequence, the model first retrieves the relevant sentences from PubMed and then ranks the retrieved sentences to form the contexts. It next combines the context with the original input sequence to form a new enhanced sequence. The original and new enhanced sequences are fed into PubMedBERT for learning feature representation. To obtain more fine-grained features, the model stacks a BiLSTM layer on top of PubMedBERT. The final named entity label prediction is done by using a CRF layer. The model is jointly trained in an end-to-end manner to take advantage of the additional context for NER of the original sequence. Results: Experimental results on six biomedical datasets show that the proposed model achieves promising performance compared to strong baselines and confirms the contribution of additional contexts for bio NER. Conclusion: The promising results confirm three important points. First, the additional context from PubMed helps to improve the quality of the recognition of biomedical entities. Second, PubMed is more appropriate than the Google search engine for providing relevant information of bio NER. Finally, more relevant sentences from the context are more beneficial than irrelevant ones to provide enhanced information for the original input sequences. The model is flexible to integrate any additional context types for the NER task. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tho2024Improving
ER  -

TY  - JOUR
AU  - Tofighi, N.J.
AU  - Elfkir, M.H.
AU  - Imamoglu, N.
AU  - Ozcinar, C.
AU  - Erdem, A.
AU  - Erdem, E.
TI  - Omnidirectional image quality assessment with local–global vision transformers
PY  - 2024
T2  - Image and Vision Computing
VL  - 148
C7  - 105151
DO  - 10.1016/j.imavis.2024.105151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196951314&doi=10.1016%2fj.imavis.2024.105151&partnerID=40&md5=89b01622a79cd8af8455b8729600a733
AB  - With the rising popularity of omnidirectional images (ODIs) in virtual reality applications, the need for specialized image quality assessment (IQA) methods becomes increasingly critical. Traditional IQA approaches, designed for rectilinear images, often fail to evaluate ODIs accurately due to their 360-degree scene representation. Addressing this, we introduce the Local–Global Transformer for 360-degree Image Quality Assessment (LGT360IQ). This novel framework features dual branches tailored to mimic top-down and bottom-up visual attention mechanisms, adapted for the spherical characteristics of ODIs. The local branch processes tangent viewports from salient regions within the equirectangular projection image, extracting detailed features for granular quality assessment. In parallel, the global branch utilizes a task-dependent token sampling strategy for holistic image feature processing and quality score prediction. This integrated approach combines local and global information, offering an effective IQA method for ODIs. Our extensive evaluation across three benchmark ODI datasets, CVIQ, OIQA, and ODI, demonstrates LGT360IQ superior performance and establishes its role in advancing the field of IQA for omnidirectional images. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tofighi2024Omnidirectional
ER  -

TY  - JOUR
AU  - Naseem, U.
AU  - Thapa, S.
AU  - Zhang, Q.
AU  - Wang, S.
AU  - Rashid, J.
AU  - Hu, L.
AU  - Hussain, A.
TI  - Graph learning with label attention and hyperbolic embedding for temporal event prediction in healthcare
PY  - 2024
T2  - Neurocomputing
VL  - 592
C7  - 127736
DO  - 10.1016/j.neucom.2024.127736
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192208763&doi=10.1016%2fj.neucom.2024.127736&partnerID=40&md5=feafc3ee51222be26a736895b5cabf18
AB  - The digitization of healthcare systems has led to the proliferation of electronic health records (EHRs), serving as comprehensive repositories of patient information. However, the vast volume and complexity of EHR data present challenges in extracting meaningful insights. This paper addresses the need for automated analysis of EHRs by proposing a novel graph learning model with label attention (GLLA) for temporal event prediction. GLLA utilizes graph neural networks to capture intricate relationships between medical codes and patients, incorporating hierarchical structures and shared risk factors. Furthermore, it introduces the Label Attention and Attention-based Transformer (LAAT) algorithm to analyze unstructured clinical notes as a multi-label classification problem. Evaluation on the widely-used MIMIC III dataset demonstrates the efficacy of GLLA in enhancing diagnostic prediction performance. The contributions of this research include a comprehensive analysis of existing models, the identification of limitations, and the development of innovative approaches to improve the accuracy and effectiveness of EHR analysis. Ultimately, GLLA aims to advance healthcare decision-making, disease management strategies, and patient outcomes. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Naseem2024Graph
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Tan, C.
AU  - Cai, Z.
AU  - Zhu, L.
AU  - Feng, Y.
AU  - Liang, S.
TI  - Cellular traffic forecasting based on inverted transformer for mobile perception dual-level base station sleep control
PY  - 2024
T2  - Ad Hoc Networks
VL  - 161
C7  - 103505
DO  - 10.1016/j.adhoc.2024.103505
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192256681&doi=10.1016%2fj.adhoc.2024.103505&partnerID=40&md5=5a657d4bf1296b9d9ed8badec3e333e8
AB  - Due to the extensive implementation of the fifth generation wireless communication networks (5 G), numerous base stations are being strategically deployed in densely inhabited areas to address the escalating need for network traffic. Within wireless cellular networks, over 80% of energy consumption is primarily concentrated on the side of the base station. In comparison to 4 G base stations, the 5 G base stations exhibit notable enhancements in terms of bandwidth, peak rate, and transmission power. Nonetheless, they suffer from limited signal coverage and extensive resource consumption. To address this challenge effectively, the present study introduces a Mobile Perception Dual-Level (MPDL) base station sleep control strategy based on cellular traffic forecasting. The strategy aims to satisfy the demands for reduced power consumption and enhanced service quality by monitoring both the current network traffic of the base station and the user's mobility, consequently placing the base station into two different sleep states. Specifically, we first designed an inverted Transformer (iTransformer) model to accurately forecast cellular traffic. The model is capable of effectively capturing both the spatial and temporal attributes of cellular traffic. It also takes into account the impact of geographical features, such as Points of Interest (POIs) and the quantity of Base Stations (BSs), on the forecasting outcomes. Consequently, it attains precise predictions of the cellular traffic. Based on the forecasting outcomes of cellular traffic, this study presents a mobility perception dual-level sleep strategy. This strategy proposal differentiates sleep into deep sleep and light sleep, while also taking into account the mobility attributes of users. It incorporates considerations for Quality of Service (QoS) and energy consumption. We assess the performance and application impacts of cellular traffic forecasting and base station sleep strategy in real-world datasets. Several experiments and validations have confirmed that the MPDL, as proposed in this paper, effectively decreases power consumption by a range of 22% to 41% when compared to baselines. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhang2024Cellular
ER  -

TY  - JOUR
AU  - Wu, R.
AU  - Liu, Y.
AU  - Wang, X.
AU  - Yang, P.
TI  - Visual tracking based on spatiotemporal transformer and fusion sequences
PY  - 2024
T2  - Image and Vision Computing
VL  - 148
C7  - 105107
DO  - 10.1016/j.imavis.2024.105107
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195308379&doi=10.1016%2fj.imavis.2024.105107&partnerID=40&md5=0c3d4598869798df5d2836fdc0f9495f
AB  - Currently, Transformer-based visual tracking methods have exhibited impressive performance. However, despite their widespread adoption, they still have certain limitations. For example, the design of the Transformer framework is somewhat original and redundant, resulting in lower efficiency. In addition, their application methods lack time consideration, and there is a lack of spatiotemporal correlation between tracking video sequences and predicting coordinate sequences, making it difficult to effectively integrate, and the robustness of corresponding tracking templates is insufficient. To address these issues, we propose a new visual tracking method (STFS). Firstly, it introduces a novel Flatten Transformer architecture, which, in comparison to previous modules, offers enhanced efficiency and expressiveness. Secondly, it takes multi frame feature maps and bounding box coordinates as inputs, integrates spatiotemporal information through the spatiotemporal sequence attention module, and provides relevant sequences for historical trend prediction. Finally, it uses diffusion methods to construct tracking templates and improve stability. To verify the performance of the tracker, we conducted experiments on benchmark datasets including GOT-10 K, LaSOT, TrackingNet, VOT2020, OTB100, and UAV123. The results demonstrate that STFS has achieved competitive experimental results. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2024Visual
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Xu, Y.
AU  - Wang, Z.
AU  - Fan, R.
AU  - Guo, Y.
AU  - Li, W.
TI  - Knowledge Graph-Aware Deep Interest Extraction Network on Sequential Recommendation
PY  - 2024
T2  - Neural Processing Letters
VL  - 56
IS  - 4
C7  - 207
DO  - 10.1007/s11063-024-11665-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197383743&doi=10.1007%2fs11063-024-11665-2&partnerID=40&md5=9e586227586882df11f96031271476e0
AB  - Sequential recommendation is the mainstream approach in the field of click-through-rate (CTR) prediction for modeling users’ behavior. This behavior implies the change of the user’s interest, and the goal of sequential recommendation is to capture this dynamic change. However, existing studies have focused on designing complex dedicated networks to capture user interests from user behavior sequences, while neglecting the use of auxiliary information. Recently, knowledge graph (KG) has gradually attracted the attention of researchers as a structured auxiliary information. Items and their attributes in the recommendation, can be mapped to knowledge triples in the KG. Therefore, the introduction of KG to recommendation can help us obtain more expressive item representations. Since KG can be considered a special type of graph, it is possible to use the graph neural network (GNN) to propagate the rich information contained in the KG into the item representation. Based on this idea, this paper proposes a recommendation method that uses KG as auxiliary information. The method first propagates the knowledge information in the KG using GNN to obtain a knowledge-rich item representation. Then the temporal features in the item sequence are extracted using a transformer for CTR prediction, namely the Knowledge Graph-Aware Deep Interest Extraction network (KGDIE). To evaluate the performance of this model, we conducted extensive experiments on two real datasets with different scenarios. The results showed that the KGDIE method could outperform several state-of-the-art baselines. The source code of our model is available at https://github.com/gylgyl123/kgdie. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Knowledge
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Zhao, Z.
AU  - Gu, Y.
AU  - Xu, Y.
TI  - Query-guided generalizable medical image segmentation
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 184
SP  - 52
EP  - 58
DO  - 10.1016/j.patrec.2024.06.005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196033366&doi=10.1016%2fj.patrec.2024.06.005&partnerID=40&md5=e6232da0907a24709a1e75707cbbff8c
AB  - The practical implementation of deep neural networks in clinical settings faces hurdles due to variations in data distribution across different centers. While the incorporation of query-guided Transformer has improved performance across diverse tasks, the full scope of their generalization capabilities remains unexplored. Given the ability of the query-guided Transformer to dynamically adjust to individual samples, fulfilling the need for domain generalization, this paper explores the potential of query-based Transformer for cross-center generalization and introduces a novel Query-based Cross-Center medical image Segmentation mechanism (QuCCeS). By integrating a query-guided Transformer into a U-Net-like architecture, QuCCeS utilizes attribution modeling capability of query-guided Transformer decoder for segmentation in fluctuating scenarios with limited data. Additionally, QuCCeS incorporates an auxiliary task with adaptive sample weighting for coarse mask prediction. Experimental results demonstrate QuCCeS's superior generalization on unseen domains. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Yang2024Query-guided
ER  -

TY  - JOUR
AU  - Javed, S.
AU  - Mahmood, A.
AU  - Qaiser, T.
AU  - Werghi, N.
AU  - Rajpoot, N.
TI  - Unsupervised mutual transformer learning for multi-gigapixel Whole Slide Image classification
PY  - 2024
T2  - Medical Image Analysis
VL  - 96
C7  - 103203
DO  - 10.1016/j.media.2024.103203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194136618&doi=10.1016%2fj.media.2024.103203&partnerID=40&md5=3e397860b1f45e103ac826158f60b2f3
AB  - The classification of gigapixel Whole Slide Images (WSIs) is an important task in the emerging area of computational pathology. There has been a surge of interest in deep learning models for WSI classification with clinical applications such as cancer detection or prediction of cellular mutations. Most supervised methods require expensive and labor-intensive manual annotations by expert pathologists. Weakly supervised Multiple Instance Learning (MIL) methods have recently demonstrated excellent performance; however, they still require large-scale slide-level labeled training datasets that require a careful inspection of each slide by an expert pathologist. In this work, we propose a fully unsupervised WSI classification algorithm based on mutual transformer learning. The instances (i.e., patches) from gigapixel WSIs are transformed into a latent space and then inverse-transformed to the original space. Using the transformation loss, pseudo labels are generated and cleaned using a transformer label cleaner. The proposed transformer-based pseudo-label generator and cleaner modules mutually train each other iteratively in an unsupervised manner. A discriminative learning mechanism is introduced to improve normal versus cancerous instance labeling. In addition to the unsupervised learning, we demonstrate the effectiveness of the proposed framework for weakly supervised learning and cancer subtype classification as downstream analysis. Extensive experiments on four publicly available datasets show better performance of the proposed algorithm compared to the existing state-of-the-art methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Javed2024Unsupervised
ER  -

TY  - JOUR
AU  - Sajith Variyar, V.V.
AU  - Sowmya, V.
AU  - Sivanpillai, R.
AU  - Brown, G.K.
TI  - A multi-branch dual attention segmentation network for epiphyte drone images
PY  - 2024
T2  - Image and Vision Computing
VL  - 148
C7  - 105099
DO  - 10.1016/j.imavis.2024.105099
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195097606&doi=10.1016%2fj.imavis.2024.105099&partnerID=40&md5=03f6ca8d5e6b14ddc6bcca77a4405274
AB  - Acquiring images of epiphytes growing on trees using Unmanned Aerial Vehicles (UAVs) enables botanists to efficiently collect data on these important plant species. Despite the advantages offered by UAVs, challenges such as complex backgrounds, uneven lighting inside the tree canopy, and accessibility issues hinder the acquisition of quality images, resulting in acquiring images datasets of heterogenous quality. AI/Deep Learning algorithms can be used to segment target plants in these images for selecting sampling locations. Existing DL models require large volume of data for training, and they tend to prioritize local features over global ones, impacting segmentation accuracy, particularly on smaller, heterogeneous quality image datasets. To overcome these limitations, we propose a multi-branch dual attention segmentation network designed to effectively handle small datasets with heterogeneous quality. The proposed network incorporates dedicated branches for extracting both global and local features, utilizing spatial and channel attention mechanisms to focus on important regions. Through a fusion process and a decoder with crossed fusion technique, this network effectively combines and enhances features from multiple branches, resulting in improved segmentation performance. Output obtained from the trained model demonstrated major improvements in predicting the boundary regions and class labels, even in close-range, low-light, and zoomed/cropped images. The average Intersection over Union (IoU) scores of the trained model was 5% higher for images acquired close range, 48% higher for images in low-light conditions, and 68% higher for zoomed/cropped images when compared to those obtained from TransUnet, a state-of-the-art vision transformer model trained on epiphyte dataset. The proposed network can be used for segmenting epiphytes in images of heterogeneous quality as well as identifying targets in images acquired in domains such as agriculture and forestry. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Sajith Variyar2024multi-branch
ER  -

TY  - JOUR
AU  - Qian, L.
AU  - Zheng, K.
AU  - Wang, L.
AU  - Li, S.
TI  - Student State-aware knowledge tracing based on attention mechanism: A cognitive theory view
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 184
SP  - 190
EP  - 196
DO  - 10.1016/j.patrec.2024.06.009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197405887&doi=10.1016%2fj.patrec.2024.06.009&partnerID=40&md5=8a1f4f1b79a55bb40f34ce29bbef2a39
AB  - Knowledge tracing evaluates students’ knowledge state and predicts future performance by analyzing their past interactions. Recent research integrates features of learning activities into knowledge tracing to enhance interpretability. Ausubel's cognitive theory underscores the significance of cognitive accumulation in learning, perceiving it as a process in which new content is linked and integrated with students’ existing knowledge. Yet, current studies often overlook this cognitive property and its impact on performance prediction. Therefore, we propose an attention-based knowledge tracing model, named Student State-aware knowledge tracing (SSKT). To align with this cognitive process, we incorporate suitable Query, Key, and Value objects into the attention mechanism, effectively modeling how students extract, integrate, and apply information from their existing knowledge. Meanwhile, traditional RNN-based models encounter the issue of losing early learning data due to gradient vanishing in long sequences. Our hybrid model, which combines LSTM and Transformer, efficiently extracts early learning information using an attention mechanism. Extensive experiments on real-world datasets validate the effectiveness and interpretability of SSKT. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Qian2024Student
ER  -

TY  - JOUR
AU  - Yolcu Oztel, G.
TI  - Vision transformer and CNN-based skin lesion analysis: classification of monkeypox
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 28
SP  - 71909
EP  - 71923
DO  - 10.1007/s11042-024-19757-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197771577&doi=10.1007%2fs11042-024-19757-w&partnerID=40&md5=80cc66c8f2815c6e35e2cd40891dcbae
AB  - Monkeypox is an important health problem. Rapid diagnosis of monkeypox skin lesions and emergency isolation when necessary is essential. Also, some skin lesions, such as melanoma, can be fatal and must be rapidly distinguished. However, in some cases, it is difficult to distinguish the lesions visually. Methods such as dermoscopy, high-resolution ultrasound imaging, etc. can be used for better observation. But these methods are often based on qualitative analysis, subjective and time-consuming. Therefore, in this study, a quantitative and objective classification tool has been developed to assist dermatologists and scientists. The proposed system classifies seven skin lesions, including monkeypox. A popular approach Vision Transformer and some popular deep learning convolutional networks have been trained with the transfer learning approach and all results have been compared. Then, the models that show the best accuracy score have been combined to make the final prediction using bagging-ensemble learning. The proposed ensemble-based system produced 81.91% Accuracy, 65.94% Jaccard, 87.16% Precision, 74.12% Recall, and 78.16% Fscore values. In terms of different criteria metrics, the system produced competitive or even better results than the literature. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yolcu Oztel2024Vision
ER  -

TY  - JOUR
AU  - Pitz, E.
AU  - Pochiraju, K.
TI  - A neural network transformer model for composite microstructure homogenization
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 134
C7  - 108622
DO  - 10.1016/j.engappai.2024.108622
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194152679&doi=10.1016%2fj.engappai.2024.108622&partnerID=40&md5=8f5de3bdecda58f6f2d4a7b313be0e3f
AB  - Heterogeneity and uncertainty in a composite microstructure lead to either computational bottlenecks if modeled rigorously or to solution inaccuracies in the stress field and failure predictions if approximated. Although methods suitable for analyzing arbitrary and non-linear microstructures exist, their computational cost makes them impractical to use in large-scale structural analysis. Surrogate models or Reduced Order Models (ROMs) commonly enhance efficiencies but are typically calibrated with a single microstructure. Homogenization methods, such as the Mori–Tanaka method, offer rapid homogenization for a wide range of constituent properties. However, simplifying assumptions, like stress and strain averaging in phases, render the consideration of both deterministic and stochastic variations in microstructure infeasible. This paper illustrates a transformer neural network architecture that captures the knowledge of various microstructures and constituents, enabling it to function as a computationally efficient homogenization surrogate model. Given an image or an abstraction of an arbitrary composite microstructure of linearly elastic fibers in an elastoplastic matrix, the transformer network predicts the history-dependent, non-linear, and homogenized stress–strain response. Two methods for encoding microstructure features were tested: calculating two-point statistics using Principal Component Analysis (PCA) for dimensionality reduction and employing an autoencoder with a Convolutional Neural Network (CNN). Both methods accurately predict the homogenized material response. The developed transformer neural network offers an efficient means for microstructure-to-property translation, generalizable and extendable to a variety of microstructures. The paper describes the network architecture, training and testing data generation, and performance under cycling and random loadings. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Pitz2024neural
ER  -

TY  - JOUR
AU  - Wang, B.
AU  - Hu, X.
AU  - Ge, R.
AU  - Xu, C.
AU  - Zhang, J.
AU  - Gao, Z.
AU  - Zhao, S.
AU  - Polat, K.
TI  - Prediction of Freezing of Gait in Parkinson's disease based on multi-channel time-series neural network
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 154
C7  - 102932
DO  - 10.1016/j.artmed.2024.102932
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198515489&doi=10.1016%2fj.artmed.2024.102932&partnerID=40&md5=e9b8374f7d6cf20650693a4e25fb5396
AB  - Freezing of Gait (FOG) is a noticeable symptom of Parkinson's disease, like being stuck in place and increasing the risk of falls. The wearable multi-channel sensor system is an efficient method to predict and monitor the FOG, thus warning the wearer to avoid falls and improving the quality of life. However, the existing approaches for the prediction of FOG mainly focus on a single sensor system and cannot handle the interference between multi-channel wearable sensors. Hence, we propose a novel multi-channel time-series neural network (MCT-Net) approach to merge multi-channel gait features into a comprehensive prediction framework, alerting patients to FOG symptoms in advance. Owing to the causal distributed convolution, MCT-Net is a real-time method available to give optimal prediction earlier and implemented in remote devices. Moreover, intra-channel and inter-channel transformers of MCT-Net extract and integrate different sensor position features into a unified deep learning model. Compared with four other state-of-the-art FOG prediction baselines, the proposed MCT-Net obtains 96.21% in accuracy and 80.46% in F1-score on average 2 s before FOG occurrence, demonstrating the superiority of MCT-Net. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Prediction
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Tian, Y.
AU  - Geng, F.
AU  - Wang, R.
TI  - DFSTrack: Dual-stream fusion Siamese network for human pose tracking in videos
PY  - 2024
T2  - Image and Vision Computing
VL  - 148
C7  - 105117
DO  - 10.1016/j.imavis.2024.105117
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196509410&doi=10.1016%2fj.imavis.2024.105117&partnerID=40&md5=916262f86fc4974a2303bcc91442c4b8
AB  - Human pose tracking is a challenging task that involves estimating the human pose and tracking it across multiple frames in a video sequence. In recent years, deep learning-based methods have made significant progress in this field, achieving state-of-the-art performance. However, due to complex background and occlusion among people missed detection and incorrect association matching are still the challenging problems. To address these issues, we adopt a top-down framework to perform human pose tracking in the paper. We propose a human detection prediction recovery module (HDP module) to recover missed detection, and propose a dual-stream fusion Siamese network for human matching (DFSTrack). Specifically, we design a residual graph convolutional block (RGCN block) for spatial position encoding of human keypoints, and use spatial self-attention and temporal cross-attention to design a dual-stream spatial–temporal fusion transformer (DST Transformer). The graph convolutional block and transformer are cascaded to simultaneously obtain information on the spatial and temporal positions of human keypoints, allowing the Siamese network to solve the erroneous human matching. Experimental results on the PoseTrack17 dataset, PoseTrack18 dataset and PoseTrack21 dataset demonstrate that our proposed method outperforms state-of-the-art methods on human pose tracking tasks. Our code and pretrained models are available at https://github.com/yhtian2023/DFSTrack. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024DFSTrack
ER  -

TY  - JOUR
AU  - Gao, P.
AU  - Tao, C.
AU  - Guan, D.
TI  - FEF-Net: feature enhanced fusion network with crossmodal attention for multimodal humor prediction
PY  - 2024
T2  - Multimedia Systems
VL  - 30
IS  - 4
C7  - 195
DO  - 10.1007/s00530-024-01402-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197551926&doi=10.1007%2fs00530-024-01402-z&partnerID=40&md5=48598d07afad2945210ed4cd099949a2
AB  - Humor segment prediction in video involves the comprehension and analysis of humor. Traditional humor prediction has been text-based; however, with the evolution of multimedia, the focus has shifted to multimodal approaches in humor prediction, marking a current trend in research. In recent years, determining whether a video is humorous has remained a challenge within the domain of sentiment analysis. Researchers have proposed multiple data fusion methods to address humor prediction and sentiment analysis. Within the realm of studying humor and emotions, text modality assumes a leading role, while audio and video modalities serve as supplementary data sources for multimodal humor prediction. However, these auxiliary modalities contain significant irrelevant information unrelated to the prediction task, resulting in redundancy. Current multimodal fusion models primarily emphasize fusion methods but overlook the issue of high redundancy in auxiliary modalities. The lack of research on reducing redundancy in auxiliary modalities introduces noise, thereby increasing the overall training complexity of models and diminishing predictive accuracy. Hence, developing a humor prediction method that effectively reduces redundancy in auxiliary modalities is pivotal for advancing multimodal research. In this paper, we propose the Feature Enhanced Fusion Network (FEF-Net), leveraging cross-modal attention to augment features from auxiliary modalities using knowledge from textual data. This mechanism generates weights to emphasize the redundancy of each corresponding time slice in the auxiliary modality. Further, employing Transformer encoders extracts high-level features for each modality, thereby enhancing the performance of humor prediction models. Experimental comparisons were conducted using the UR-FUNNY and MUStARD multimodal humor prediction models, revealing a 3.2% improvement in ‘Acc-2’ compared to the optimal model. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Gao2024FEF-Net
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Guo, S.
AU  - Wang, L.
AU  - Han, S.
TI  - CompleteDT: Point cloud completion with information-perception transformers
PY  - 2024
T2  - Neurocomputing
VL  - 592
C7  - 127790
DO  - 10.1016/j.neucom.2024.127790
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192301823&doi=10.1016%2fj.neucom.2024.127790&partnerID=40&md5=b9f50048b59e9e1d9a8ac1ad48079408
AB  - In this work, we propose a novel point cloud completion network, called CompleteDT. To fully capture the 3D geometric structure of point clouds, we introduce an Information-Perception Transformer (IPT) that can simultaneously capture local features and global geometric relations. CompleteDT comprises a Feature Encoder, Query Generator, and Query Decoder. Feature Encoder extracts local features from multi-resolution point clouds to capture intricate geometrical structures. Query Generator uses the proposed IPT, utilizing the Point Local Attention (PLA) and Point Global Attention (PGA) modules, to learn local features and global correlations, and generate query features that represent predicted point clouds. The PLA captures local information within local points by adaptively measuring weights of neighboring points, while PGA adapts multi-head self-attention by transforming it into a layer-by-layer form where each head learns global features in a high-dimensional space of different dimensions. By dense connections, the module allows for direct information exchange between each head and facilitates the capture of long global correlations. By combining the strengths of both PLA and PGA, the IPT can fully leverage local and global features to facilitate CompleteDT to complete point clouds. Lastly, the query features undergo refining to generate a complete point cloud through the Query Decoder. Our experimental results demonstrate that CompleteDT outperforms current state-of-the-art methods, effectively learning from incomplete inputs and predicting complete outputs. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Li2024CompleteDT
ER  -

TY  - JOUR
AU  - Kobayashi, K.
AU  - Takamizawa, Y.
AU  - Miyake, M.
AU  - Ito, S.
AU  - Gu, L.
AU  - Nakatsuka, T.
AU  - Akagi, Y.
AU  - Harada, T.
AU  - Kanemitsu, Y.
AU  - Hamamoto, R.
TI  - Can physician judgment enhance model trustworthiness? A case study on predicting pathological lymph nodes in rectal cancer
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 154
C7  - 102929
DO  - 10.1016/j.artmed.2024.102929
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198042984&doi=10.1016%2fj.artmed.2024.102929&partnerID=40&md5=91d6392e9a83968f163b1f97cffe0898
AB  - Explainability is key to enhancing the trustworthiness of artificial intelligence in medicine. However, there exists a significant gap between physicians’ expectations for model explainability and the actual behavior of these models. This gap arises from the absence of a consensus on a physician-centered evaluation framework, which is needed to quantitatively assess the practical benefits that effective explainability should offer practitioners. Here, we hypothesize that superior attention maps, as a mechanism of model explanation, should align with the information that physicians focus on, potentially reducing prediction uncertainty and increasing model reliability. We employed a multimodal transformer to predict lymph node metastasis of rectal cancer using clinical data and magnetic resonance imaging. We explored how well attention maps, visualized through a state-of-the-art technique, can achieve agreement with physician understanding. Subsequently, we compared two distinct approaches for estimating uncertainty: a standalone estimation using only the variance of prediction probability, and a human-in-the-loop estimation that considers both the variance of prediction probability and the quantified agreement. Our findings revealed no significant advantage of the human-in-the-loop approach over the standalone one. In conclusion, this case study did not confirm the anticipated benefit of the explanation in enhancing model reliability. Superficial explanations could do more harm than good by misleading physicians into relying on uncertain predictions, suggesting that the current state of attention mechanisms should not be overestimated in the context of model explainability. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Kobayashi2024Can
ER  -

TY  - JOUR
AU  - Karami, H.
AU  - Atienza, D.
AU  - Ionescu, A.
TI  - TEE4EHR: Transformer event encoder for better representation learning in electronic health records
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 154
C7  - 102903
DO  - 10.1016/j.artmed.2024.102903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196421043&doi=10.1016%2fj.artmed.2024.102903&partnerID=40&md5=852fb3c04c2152c52ca33341ec7539ab
AB  - Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing values in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data consistent with irregular sampling patterns. Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in various benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network, which gives superior performance in negative log-likelihood and future event prediction. Besides, we propose an algorithm for aggregating attention weights to reveal the events’ interactions. Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series. Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and be useful for clinical prediction tasks. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Karami2024TEE4EHR
ER  -

TY  - JOUR
AU  - He, M.
AU  - Yang, Z.
AU  - Zhang, G.
AU  - Long, Y.
AU  - Song, H.
TI  - IIMT-net: Poly-1 weights balanced multi-task network for semantic segmentation and depth estimation using interactive information
PY  - 2024
T2  - Image and Vision Computing
VL  - 148
C7  - 105109
DO  - 10.1016/j.imavis.2024.105109
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195644343&doi=10.1016%2fj.imavis.2024.105109&partnerID=40&md5=0332d545ad97ef5b0cdee5b8a8c2c4b3
AB  - Semantic segmentation and depth estimation are two basic researchable problems in computer vision. In common, we explore the two tasks separately. However, in some scenes, such as autonomous driving, they need be done at the same time. Meanwhile, there exists interconnected information between two tasks, which can jointly promote the performances of them. Thus, we explore the two tasks based on multi-task learning to jointly train the tasks and gain predictions together. In this paper, we build Interactive Information Multi-Task Network (IIMT-Net) incorporating the information interactive modules, trained with proposed task-balancing strategy. To be specific, we construct the principal part of encoder and decoder based on Transformer to well capture the global information. For better utilization of the task interaction between two tasks, we also add information fusion modules in two sub-decoders. In addition, the task-balancing strategy, Poly-1 weights, is designed as the balance among samples with different degrees of difficulty to ensure the network won't be biased towards any task severely. The proposed approach's exceptional performance has been extensively showcased through experimental results on the NYU Depth V2 dataset, the Cityscapes dataset, and the SUN RGB-D dataset. Our model can complete the predictions of semantic segmentation task and depth estimation task together and obtain mIoU values of 46.66% on the NYU Depth V2 dataset, 66.37% on the Cityscapes dataset, and 49.89% on the SUN RGB-D dataset, respectively with rmse values of 0.648, 6.630 and 0.401 for depth estimation task, which outperform most existing methods in multi-task learning. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - He2024IIMT-net
ER  -

TY  - JOUR
AU  - Kumar, M.
AU  - Singh, R.
AU  - Mukherjee, P.
TI  - VTHSC-MIR: Vision Transformer Hashing with Supervised Contrastive learning based medical image retrieval
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 184
SP  - 28
EP  - 36
DO  - 10.1016/j.patrec.2024.06.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195639832&doi=10.1016%2fj.patrec.2024.06.003&partnerID=40&md5=3d16cfdab795705f867562e016a56dc7
AB  - In past few years, deep learning based medical image analysis technologies have significantly improved computer-assisted tasks like detecting, diagnosing, and predicting medical outcomes. The monitoring and diagnosis of ailments such as cancer and COVID-19 rely primarily on retrieving medical images. As the medical databases size is increasing rapidly it causes difficulty in managing and querying them. The main challenge lies in achieving superior retrieval performance while handling the intricacies of medical imaging datasets. To tackle this, we propose a novel end-to-end trainable framework for medical image retrieval using a vision transformer hashing with Supervised Contrastive (VTHSC) learning. Leveraging the self-attention mechanism of transformers and supervised contrastive loss, our model surpasses existing hashing-based retrieval methods. Focusing on the most recent COVID-19 and breast cancer datasets, we aim to efficiently retrieve relevant medical images from large datasets. Using the ImageNet-pretrained ViT as its backbone network, the VTHSC model incorporates a hashing head combined with a supervised contrastive loss and employs joint loss optimization. The VTHSC model is subsequently fine- tuned for a retrieval task, employing four different hashing frameworks: Deep Supervised Hashing (DSH), GreedyHash, Improved Deep Hashing Network (IDHN), and Deep Polarized Network (DPN). Our model achieves outstanding Mean Average Precision (MAP) scores of 98.9 for the BreakHis dataset and 96.03 for the COVID dataset. Notably, the VTHSC model surpasses several competing hashing-based retrieval methods by a substantial gain in terms of performance across various metrics such as precision, recall, and Top-6 retrieved images retrieval performance on the two benchmark medical image datasets. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Kumar2024VTHSC-MIR
ER  -

TY  - JOUR
AU  - Cui, Y.
AU  - Yu, Z.
AU  - Feng, Y.
AU  - Wang, H.
AU  - Li, J.
TI  - A multi-scale no-reference video quality assessment method based on transformer
PY  - 2024
T2  - Multimedia Systems
VL  - 30
IS  - 4
C7  - 201
DO  - 10.1007/s00530-024-01403-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197679874&doi=10.1007%2fs00530-024-01403-y&partnerID=40&md5=f8a939df9f4884dff388de265078c20b
AB  - Video quality assessment is essential for optimizing user experience, enhancing network efficiency, supporting video production and editing, improving advertising effectiveness, and strengthening security in monitoring and other domains. Reacting to the prevailing focus of current research on video detail distortion while overlooking the temporal relationships between video frames and the impact of content-dependent characteristics of the human visual system on video quality, this paper proposes a multi-scale no-reference video quality assessment method based on transformer. On the one hand, spatial features of the video are extracted using a network that combines swin-transformer and deformable convolution, and further information preservation is achieved through mixed pooling of features in video frames. On the other hand, a pyramid aggregation module is utilized to merge long-term and short-term memories, enhancing the ability to capture temporal changes. Experimental results on public datasets such as KoNViD-1k, CVD2014, and LIVE-VQC demonstrate the effectiveness of the proposed method in video quality prediction. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cui2024multi-scale
ER  -

TY  - JOUR
AU  - Chen, W.
AU  - Zhao, W.
AU  - Chen, Z.
AU  - Liu, T.
AU  - Liu, L.
AU  - Liu, J.
AU  - Yuan, Y.
TI  - Mask-aware transformer with structure invariant loss for CT translation
PY  - 2024
T2  - Medical Image Analysis
VL  - 96
C7  - 103205
DO  - 10.1016/j.media.2024.103205
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193745701&doi=10.1016%2fj.media.2024.103205&partnerID=40&md5=0cd9aee26660c0cbdd8c0734246a7291
AB  - Multi-phase enhanced computed tomography (MPECT) translation from plain CT can help doctors to detect the liver lesion and prevent patients from the allergy during MPECT examination. Existing CT translation methods directly learn an end-to-end mapping from plain CT to MPECT, ignoring the crucial clinical domain knowledge. As clinicians subtract the plain CT from MPECT images as subtraction image to highlight the contrast-enhanced regions and further to facilitate liver disease diagnosis in the clinical diagnosis, we aim to exploit this domain knowledge for automatic CT translation. To this end, we propose a Mask-Aware Transformer (MAFormer) with structure invariant loss for CT translation, which presents the first effort to exploit this domain knowledge for CT translation. Specifically, the proposed MAFormer introduces a mask estimator to predict the subtraction image from the plain CT image. To integrate the subtraction image into the network, the MAFormer devises a Mask-Aware Transformer based Normalization (MATNorm) as normalization layer to highlight the contrast-enhanced regions and capture the long-range dependencies among these regions. Moreover, aiming to preserve the biological structure of CT slices, a structure invariant loss is designed to extract the structural information and minimize the structural similarity between the plain and synthetic CT images to ensure the structure invariant. Extensive experiments have proven the effectiveness of the proposed method and its superiority to the state-of-the-art CT translation methods. Source code is to be released. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chen2024Mask-aware
ER  -

TY  - JOUR
AU  - Mishra, A.
AU  - Sharma, A.
TI  - Deep learning based continuous integration and continuous delivery software defect prediction with effective optimization strategy
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 296
C7  - 111835
DO  - 10.1016/j.knosys.2024.111835
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192337258&doi=10.1016%2fj.knosys.2024.111835&partnerID=40&md5=b88c9ceaeb4c9d9ef4c2a54d12655e97
AB  - Software defect prediction is one of the most difficult tasks in the IT sector. Continuous Integration and Continuous Delivery (CI/CD) software defect prediction is used in earlier stage, which consumes less amount of time. Various learning algorithms, such as convolutional neural networks and other machine learning algorithms (ML), are employed to forecast the flaws in the software model. In these existing algorithms, some issues are noticed, such as high computational complexity, excessive time consumption, the need for more energy to predict the model and a high-loss function. To address these issues, a novel deep learning (DL)-based CI/CD software defect prediction technique applying an effective optimization strategy is provided to improve the model's efficiency. The numerical data are collected from open source, and the obtained data is initially labeled based on time domain limitations. Initially, the Modified Synthetic Minority Over-Sampling Technique (M-SMOTE) mechanism is applied to balance the data to avoid overfitting problems, and data normalization is performed to rescale and normalize the data properly. After moralization, the optimal set of features is extracted from the data using Focal Bidirectional Encoder Representations from Transformers (F-BERT) to enhance the efficiency of the model. Finally, the software defects are predicted using Bidirectional Long Short-Term Memory (Bi-LSTM) integrated into the convolutional Gated recurrent units (GRU) model (Bi-CGRU) based on collected features. Hybrid Levy Rao (HLR) optimization is used to tune the hyperparameters properly in the classifier model. The proposed model's performance indicators are examined. The proposed model has a 95.32 % accuracy, a 93.3 % recall, a 94.98 % Matthews correlation coefficient, and an F1-score of 91.355 %. The proposed model generates less labeling noise and wait time than existing methods. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Mishra2024Deep
ER  -

TY  - JOUR
AU  - Hong, J.-T.
AU  - Bai, Y.-L.
AU  - Huang, Y.-T.
AU  - Chen, Z.-R.
TI  - Hybrid carbon price forecasting using a deep augmented FEDformer model and multimodel optimization piecewise error correction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 247
C7  - 123325
DO  - 10.1016/j.eswa.2024.123325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184137387&doi=10.1016%2fj.eswa.2024.123325&partnerID=40&md5=c1683eb477d889a28e97e17a3a1cde6f
AB  - Accurate and robust carbon price forecasting is crucial for stabilizing the carbon financial market and reducing reliance on fossil resources. This study introduces a novel hybrid model, combining a deep augmented frequency enhanced decomposed transformer (DA-FEDformer), improved complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN), and a multimodel optimization piecewise error correction, for accurate carbon price prediction. To leverage frequency domain information, the proposed DA-FEDformer model enhances the decoder and encoder layers by incorporating a multilayer perceptron layer. A novel improved kernel mean square error loss function is devised for the model, and the evolved sign momentum optimizer is employed for further optimization. To further improve the prediction accuracy, a data postprocessing method is integrated into the model. The DA-FEDformer predicts the carbon price, and the ICEEMDAN method decomposes the error sequence into subsequences. These subsequences are forecasted using five different models. Finally, the DA-FEDformer prediction results and the error correction results are combined to obtain the final carbon price sequence. This hybrid model is systematically evaluated using carbon price data from Hubei, Guangzhou, and Beijing in China. The results demonstrate that the hybrid model achieves favorable performance on three datasets. This innovative approach provides a promising solution for carbon price forecasting in China. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Hong2024Hybrid
ER  -

TY  - JOUR
AU  - Duan, C.
AU  - Wu, Z.
AU  - Zhu, L.
AU  - Xu, X.
AU  - Zhu, J.
AU  - Wei, Z.
AU  - Yang, X.
TI  - DSTN: Dynamic Spatio-Temporal Network for Early Fault Warning in Chemical Processes
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 296
C7  - 111892
DO  - 10.1016/j.knosys.2024.111892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192683038&doi=10.1016%2fj.knosys.2024.111892&partnerID=40&md5=5469be8cba2992a96630cb0b62f38ea6
AB  - Multivariate time series prediction, especially in early fault warning for chemical processes, poses significant challenges. The advent of graph neural network (GNN) method has made breakthroughs in this domain by enabling the processing of topological data. However, the traditional methods suffer from the issue of over-smoothing and inability to capture intricate multi-scale spatio-temporal dependencies. Additionally, the existing graph structures fall short in describing the complex spatial relationships among multi-stage sensors, impeding their adaptability to dynamically evolving chain reaction scenarios. To alleviate these limitations, a novel Dynamic spatio-Temporal Network for early fault warning in chemical processes, named DSTN for short, is proposed in this paper. We extract the spatial and temporal features of the time series by the designed dynamic GNN and the improved Transformer network. Then, we integrate the spatio-temporal features through the residual network. DSTN has the following advantages: (1) A one-dimensional convolutional neural network is seamlessly incorporated into the Transformer architecture for bolstering its capacity to discern both global and local features within time series. (2) The continuous sliding window and mutual information methods are employed to construct a dynamic topology graph, and a K-order adjacency matrix is designed to rectify the inefficiencies in learning weights associated with convolution kernel parameters. (3) Multiple spatio-temporal modules interconnected via residual connection to adaptively fuse multi-scale features. Experimental results demonstrate that our proposed DSTN method outperforms existing methods in terms of both performance and interpretability in early fault warning of chemical processes. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Duan2024DSTN
ER  -

TY  - JOUR
AU  - Abduallah, Y.
AU  - Wang, J.T.L.
AU  - Wang, H.
AU  - Jing, J.
TI  - A transformer-based framework for predicting geomagnetic indices with uncertainty quantification
PY  - 2024
T2  - Journal of Intelligent Information Systems
VL  - 62
IS  - 4
SP  - 887
EP  - 903
DO  - 10.1007/s10844-023-00828-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176789534&doi=10.1007%2fs10844-023-00828-7&partnerID=40&md5=00703d4992174bfc016dd35b09574696
AB  - Geomagnetic activities have a crucial impact on Earth, which can affect spacecraft and electrical power grids. Geospace scientists use a geomagnetic index, called the Kp index, to describe the overall level of geomagnetic activity. This index is an important indicator of disturbances in the Earth’s magnetic field and is used by the U.S. Space Weather Prediction Center as an alert and warning service for users who may be affected by the disturbances. Another commonly used index, called the ap index, is converted from the Kp index. Early and accurate prediction of the Kp and ap indices is essential for preparedness and disaster risk management. In this paper, we present a deep learning framework, named GNet, to perform short-term forecasting of the Kp and ap indices. Specifically, GNet takes as input time series of solar wind parameters’ values, provided by NASA’s Space Science Data Coordinated Archive, and predicts as output the Kp and ap indices respectively at time point t+w hours for a given time point t where w ranges from 1 to 9. GNet combines transformer encoder blocks with Bayesian inference, which is capable of quantifying both aleatoric uncertainty (data uncertainty) and epistemic uncertainty (model uncertainty) in making predictions. Experimental results show that GNet outperforms closely related machine learning methods in terms of the root mean square error and R-squared score. Furthermore, GNet can provide both data and model uncertainty quantification results, which the existing methods cannot offer. To our knowledge, this is the first time that Bayesian transformers have been used for geomagnetic activity prediction. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Abduallah2024transformer-based
ER  -

TY  - JOUR
AU  - Yu, L.-R.
AU  - Lu, Q.-H.
AU  - Xue, Y.
TI  - DTAAD: Dual Tcn-attention networks for anomaly detection in multivariate time series data
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 295
C7  - 111849
DO  - 10.1016/j.knosys.2024.111849
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191866498&doi=10.1016%2fj.knosys.2024.111849&partnerID=40&md5=0e1fafdb8bd1c2852ae6fdebdd346b65
AB  - Anomaly detection techniques enable effective anomaly detection and diagnosis in multi-variate time series data, which are of major significance for today's industrial applications. However, establishing an anomaly detection system that can be rapidly and accurately located is a challenging problem due to the lack of anomaly labels, the high dimensional complexity of the data, memory bottlenecks in actual hardware, and the need for fast reasoning. In this paper, we propose an anomaly detection and diagnosis model, DTAAD, based on Transformer and Dual Temporal Convolutional Network (TCN). Our overall model is an integrated design in which an autoregressive model (AR) combines with an autoencoder (AE) structure. Scaling methods and feedback mechanisms are introduced to improve prediction accuracy and expand correlation differences. Constructed by us, the Dual TCN-Attention Network (DTA) uses only a single layer of Transformer encoder in our baseline experiment, belonging to an ultra-lightweight model. Our extensive experiments on seven public datasets validate that DTAAD exceeds the majority of currently advanced baseline methods in both detection and diagnostic performance. Specifically, DTAAD improved F1 scores by 8.38% and reduced training time by 99% compared to the baseline. The code and training scripts are publicly available on GitHub at https://github.com/Yu-Lingrui/DTAAD. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; FMS:C; 
LB  - Yu2024DTAAD
ER  -

TY  - JOUR
AU  - Malik, M.S.I.
AU  - Nawaz, A.
AU  - Jamjoom, M.M.
AU  - Ignatov, D.I.
TI  - Effectiveness of ELMo embeddings, and semantic models in predicting review helpfulness
PY  - 2024
T2  - Intelligent Data Analysis
VL  - 28
IS  - 4
SP  - 1045
EP  - 1065
DO  - 10.3233/IDA-230349
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199674576&doi=10.3233%2fIDA-230349&partnerID=40&md5=2caae236272f24a35cc1b57996319fda
AB  - Online product reviews (OPR) are a commonly used medium for consumers to communicate their experiences with products during online shopping. Previous studies have investigated the helpfulness of OPRs using frequency-based, linguistic, meta-data, readability, and reviewer attributes. In this study, we explored the impact of robust contextual word embeddings, topic, and language models in predicting the helpfulness of OPRs. In addition, the wrapper-based feature selection technique is employed to select effective subsets from each type of features. Five feature generation techniques including word2vec, FastText, Global Vectors for Word Representation (GloVe), Latent Dirichlet Allocation (LDA), and Embeddings from Language Models (ELMo), were employed. The proposed framework is evaluated on two Amazon datasets (Video games and Health & personal care). The results showed that the ELMo model outperformed the six standard baselines, including the fine-Tuned Bidirectional Encoder Representations from Transformers (BERT) model. In addition, ELMo achieved Mean Square Error (MSE) of 0.0887 and 0.0786 respectively on two datasets and MSE of 0.0791 and 0.0708 with the wrapper method. This results in the reduction of 1.43% and 1.63% in MSE as compared to the fine-Tuned BERT model on respective datasets. However, the LDA model has a comparable performance with the fine-Tuned BERT model but outperforms the other five baselines. The proposed framework demonstrated good generalization abilities by uncovering important factors of product reviews and can be evaluated on other voting platforms.  © 2024-IOS Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Malik2024Effectiveness
ER  -

TY  - JOUR
AU  - Su, W.
AU  - He, Y.
AU  - Zhang, H.
AU  - Yang, W.
TI  - MDEConvFormer: estimating monocular depth as soft regression based on convolutional transformer
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 26
SP  - 68793
EP  - 68811
DO  - 10.1007/s11042-024-18290-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183134012&doi=10.1007%2fs11042-024-18290-0&partnerID=40&md5=dff2db5cea72ee8f665aaf33c8b25b13
AB  - Estimating depth from a single monocular image is a promising but challenging task in scene understanding. While Convolutional Neural Networks have been the dominant architectures, recently Vision Transformers have been gaining momentum to take over in pixel-level classification tasks. However, as a substantial regression problem, depth estimation normally requires effective multi-scale context. The chasm of transferring above two architectures to regression has received little research attention. We are committed to focusing on the fusion of multiple scales in both structures and error compensation for the transformation from classification to regression. We also concerned with the fact that the loss function in traditional regression tasks is usually built on the similarity of pixel prediction. The high-level similarity constraints of pixels are usually ignored. This paper explores the feasibility of performing soft regression on the probability distribution of classification generated from the proposed convolutional transformer. A well-designed deep learning model utilizes a multi-scale context of both convolutional networks and transformers. Pyramidally repeated context fusions guarantee that each representation receives multi-scale contextual information from parallel representations. We allow each depth class to be shifted adaptively and depth estimation is calculated as the expected value of probability distribution. Homogeneous embedding loss is used for transferring task-specific appealing properties such as geometric information, semantic cues as well as global context. Experiments subsequently confirm competitive results on the popular indoor and outdoor datasets compared with the recent state-of-the-art methods. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Su2024MDEConvFormer
ER  -

TY  - JOUR
AU  - Jiang, T.
AU  - Wang, Y.
AU  - Hou, F.
AU  - Wang, R.
TI  - IENet: inheritance enhancement network for video salient object detection
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 28
SP  - 72007
EP  - 72026
DO  - 10.1007/s11042-024-18408-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184165596&doi=10.1007%2fs11042-024-18408-4&partnerID=40&md5=116b33b5ead83cffe9aa2d74010ade1e
AB  - Effective utilization of spatiotemporal information is essential for improving the accuracy and robustness of Video Salient Object Detection (V-SOD). However, current methods have not fully utilized historical frame information, ultimately resulting in insufficient integration of complementary semantic information. To address this issue, we propose a novel Inheritance Enhancement Network (IENet) based on Transformer. The core of IENet is a Heritable Multi-Frame Attention (HMA) module, which fully exploits long-term context and frame-aware temporal modeling in feature extraction through unidirectional cross-frame enhancement. In contrast to existing methods, our heritable strategy is based on the unidirectional inheritance model using attention maps which ensure the information propagation for each frame is consistent and orderly, avoiding additional interference. Furthermore, we propose an auxiliary attention loss by using inherited attention maps to direct the network to focus more on target regions. The experimental results of our IENet reveal its effectiveness in handling challenging scenes on five popular benchmark datasets. For instance, in the cases of VOS and DAVSOD, our method achieves 0.042% and 0.070% for MAE compared to other competitive models. Particularly, IENet excels in inheriting finer details from historical frames even in complex environments. The module and predicted maps are publicly available at https://github.com/TOMMYWHY/IENet © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jiang2024IENet
ER  -

TY  - JOUR
AU  - Chakraborty, K.
AU  - Bhattacharyya, S.
AU  - Bag, R.
AU  - Mršić, L.
TI  - Sentiment analysis on labeled and unlabeled datasets using BERT architecture
PY  - 2024
T2  - Soft Computing
VL  - 28
IS  - 15-16
SP  - 8623
EP  - 8640
DO  - 10.1007/s00500-023-08876-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164145246&doi=10.1007%2fs00500-023-08876-5&partnerID=40&md5=1c63cb45b374650d6ec66fb1cbb86d10
AB  - Sentiment analysis (SA) is the study of human perception in any subject of practice. It retrieves data from datasets using natural language processing (NLP) methodologies and algorithms that are either regulation-based, blended, or rely on machine learning approaches. SA is garnering fame for its capacity to fit in a large chunk of data with user evaluations, uncover a trend, and come to a consensus derived from real facts rather than hypotheses established on a limited number of observations. The flexible nature of sentiment gathering has helped in playing a critical role in both commercial and research applications in the last few years. This study presents new sentiment analysis models based on Bidirectional Encoder Representations from Transformers (BERT) for both labeled and unlabeled datasets. The labeled datasets using supervised learning are modeled in a hybrid architecture of fine-tuned BERT and interval Type—2 fuzzy sets. The inclusion of interval Type-2 fuzzy logic for handling reluctance or inaccuracy in data shows commendable results for the labeled datasets. For the prediction of sentiments in unlabeled datasets, they are embedded through a BERT tokenizer with the help of a threshold and activation functions. The coupling of a multi-layer perceptron with the BERT parser substantially decreases the time and complexity compared to supervised learning. Both the models have been implemented on multiple datasets and have outperformed existing state-of-the-art techniques in this field. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chakraborty2024Sentiment
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Lin, T.
AU  - Gong, Z.
AU  - Huang, X.
TI  - SIANet: 3D object detection with structural information augment network
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 5
SP  - 682
EP  - 695
DO  - 10.1049/cvi2.12272
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182820527&doi=10.1049%2fcvi2.12272&partnerID=40&md5=a998d221d7f9146013153b9288a243e5
AB  - 3D object detection technology from point clouds has been widely applied in the field of automatic driving in recent years. In practical applications, the shape point clouds of some objects are incomplete due to occlusion or far distance, which means they suffer from insufficient structural information. This greatly affects the detection performance. To address this challenge, the authors design a Structural Information Augment (SIA) Network for 3D object detection, named SIANet. Specifically, the authors design a SIA module to reconstruct the complete shapes of objects within proposals for enhancing their geometric features, which are further fused into the spatial feature of the object for box refinement to predict accurate detection boxes. Besides, the authors construct a novel Unet-liked Context-enhanced Transformer backbone network, which stacks Context-enhanced Transformer modules and an upsampling branch to capture contextual information efficiently and generate high-quality proposals for the SIA module. Extensive experiments show that the authors’ well-designed SIANet can effectively improve detection performance, especially surpassing the baseline network by 1.04% mean Average Precision (mAP) gain in the KITTI dataset and 0.75% LEVEL_2 mAP gain in the Waymo dataset. © 2024 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhou2024SIANet
ER  -

TY  - JOUR
AU  - Guarascio, M.
AU  - Minici, M.
AU  - Pisani, F.S.
AU  - De Francesco, E.
AU  - Lambardi, P.
TI  - Movie tag prediction: An extreme multi-label multi-modal transformer-based solution with explanation
PY  - 2024
T2  - Journal of Intelligent Information Systems
VL  - 62
IS  - 4
SP  - 1021
EP  - 1043
DO  - 10.1007/s10844-023-00836-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181465499&doi=10.1007%2fs10844-023-00836-7&partnerID=40&md5=1018bc85af96d5ef22ba9e42fe6e4c60
AB  - Providing rich and accurate metadata for indexing media content is a crucial problem for all the companies offering streaming entertainment services. These metadata are commonly employed to enhance search engine results and feed recommendation algorithms to improve the matching with user interests. However, the problem of labeling multimedia content with informative tags is challenging as the labeling procedure, manually performed by domain experts, is time-consuming and prone to error. Recently, the adoption of AI-based methods has been demonstrated to be an effective approach for automating this complex process. However, developing an effective solution requires coping with different challenging issues, such as data noise and the scarcity of labeled examples during the training phase. In this work, we address these challenges by introducing a Transformer-based framework for multi-modal multi-label classification enriched with model prediction explanation capabilities. These explanations can help the domain expert to understand the system’s predictions. Experimentation conducted on two real test cases demonstrates its effectiveness. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Guarascio2024Movie
ER  -

TY  - JOUR
AU  - Lin, X.
AU  - Wang, D.
AU  - Zhou, G.
AU  - Liu, C.
AU  - Chen, Q.
TI  - TransPose: 6D object pose estimation with geometry-aware Transformer
PY  - 2024
T2  - Neurocomputing
VL  - 589
C7  - 127652
DO  - 10.1016/j.neucom.2024.127652
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190834440&doi=10.1016%2fj.neucom.2024.127652&partnerID=40&md5=c20f12e89ebc540b3b37705982551a1b
AB  - Efficient and accurate estimation of objects’ pose is essential in numerous practical applications. Due to the depth data contains abundant geometric information, some existing methods devote to extract features from 3D point cloud. However, these depth-based methods focus on extracting the point cloud local features and consider less about the global information. How to extract and utilize the local and global geometry features in depth information is crucial to achieve accurate predictions. To this end, we propose TransPose, a novel 6D pose framework that exploits Transformer Encoder with geometry-aware module to develop better learning of point cloud feature representations. To better extract local geometry features, we finely design the graph convolution network-based feature extractor that first uniformly sample point cloud and extract point pair features of point cloud. To further improve robustness to occlusion, we adopt Transformer to perform the propagation of global information, making each local feature obtains global information. Moreover, we introduce geometry-aware module in Transformer Encoder, which to form an effective constrain for point cloud feature learning and makes the global information exchange more tightly coupled with point cloud tasks. Extensive experiments indicate the effectiveness of TransPose, our pose estimation pipeline achieves competitive results on three benchmark datasets. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Lin2024TransPose
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Ma, Y.
AU  - Yu, Z.
AU  - Zhao, H.
TI  - RCDformer: Transformer-based dense depth estimation by sparse radar and camera
PY  - 2024
T2  - Neurocomputing
VL  - 589
C7  - 127668
DO  - 10.1016/j.neucom.2024.127668
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191560406&doi=10.1016%2fj.neucom.2024.127668&partnerID=40&md5=617dad4e71de1ed6fd91e6fdc54b2762
AB  - Accurate depth cues are crucial for 3D perception tasks, and monocular depth estimation networks are no longer sufficient for realistic scenarios. Currently, the most effective approaches are to introduce depth information from other modalities into the image. Radar has become a popular sensor for fusion with cameras due to its low price and all-weather working characteristics. This paper aims to explore how to more effectively integrate the heterogeneous data of radar point clouds and RGB images to improve the performance of depth estimation. Most of the previous works have not fully exploited the potential of integrating these two modalities, so we propose RCDformer, a novel network based on the transformer architecture that fuses radar-camera for dense depth estimation. Without reducing the receptive field, our approach can fully model the contextual relationships between sensors to reduce the impact of radar noise on overall performance. With the proposed Radar-guided Multi-scale Depth Fusion (RGDF) module, the prior spatial information mapped by the Radar Feature Extractor (RFE) is embedded into a set of multi-scale hierarchical features output by Image Feature Extractor (IFE) via the modified deformable cross-attention, which aims to guide the depth prediction of images. Furthermore, we discover that incorporating the Radar Cross Section (RCS) attribute as an extended channel for the radar map is beneficial for dense depth estimation, which improves the overall performance of our model. We evaluate the proposed method on the nuScenes dataset, and the experiment results show that our method still achieves significant advantages in most metrics compared to the state-of-the-art models. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Huang2024RCDformer
ER  -

TY  - JOUR
AU  - Olorunnimbe, K.
AU  - Viktor, H.
TI  - Ensemble of temporal Transformers for financial time series
PY  - 2024
T2  - Journal of Intelligent Information Systems
VL  - 62
IS  - 4
SP  - 1087
EP  - 1111
DO  - 10.1007/s10844-024-00851-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186462952&doi=10.1007%2fs10844-024-00851-2&partnerID=40&md5=ba49929dce1790348e2cb578286074d1
AB  - The accuracy of price forecasts is important for financial market trading strategies and portfolio management. Compared to traditional models such as ARIMA and other state-of-the-art deep learning techniques, temporal Transformers with similarity embedding perform better for multi-horizon forecasts in financial time series, as they account for the conditional heteroscedasticity inherent in financial data. Despite this, the methods employed in generating these forecasts must be optimized to achieve the highest possible level of precision. One approach that has been shown to improve the accuracy of machine learning models is ensemble techniques. To this end, we present an ensemble approach that efficiently utilizes the available data over an extended timeframe. Our ensemble combines multiple temporal Transformer models learned within sliding windows, thereby making optimal use of the data. As combination methods, along with an averaging approach, we also introduced a stacking meta-learner that leverages a quantile estimator to determine the optimal weights for combining the base models of smaller windows. By decomposing the constituent time series of an extended timeframe, we optimize the utilization of the series for financial deep learning. This simplifies the training process of a temporal Transformer model over an extended time series while achieving better performance, particularly when accounting for the non-constant variance of financial time series. Our experiments, conducted across volatile and non-volatile extrapolation periods, using 20 companies from the Dow Jones Industrial Average show more than 40% and 60% improvement in predictive performance compared to the baseline temporal Transformer. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Olorunnimbe2024Ensemble
ER  -

TY  - JOUR
AU  - Ma, X.
AU  - Jin, R.
AU  - Wang, J.
AU  - Chung, T.-S.
TI  - Attentional bias for hands: Cascade dual-decoder transformer for sign language production
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 5
SP  - 696
EP  - 708
DO  - 10.1049/cvi2.12273
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187194070&doi=10.1049%2fcvi2.12273&partnerID=40&md5=89a93cafeef0a1640786edcd282b0932
AB  - Sign Language Production (SLP) refers to the task of translating textural forms of spoken language into corresponding sign language expressions. Sign languages convey meaning by means of multiple asynchronous articulators, including manual and non-manual information channels. Recent deep learning-based SLP models directly generate the full-articulatory sign sequence from the text input in an end-to-end manner. However, these models largely down weight the importance of subtle differences in the manual articulation due to the effect of regression to the mean. To explore these neglected aspects, an efficient cascade dual-decoder Transformer (CasDual-Transformer) for SLP is proposed to learn, successively, two mappings SLPhand: Text → Hand pose and SLPsign: Text → Sign pose, utilising an attention-based alignment module that fuses the hand and sign features from previous time steps to predict more expressive sign pose at the current time step. In addition, to provide more efficacious guidance, a novel spatio-temporal loss to penalise shape dissimilarity and temporal distortions of produced sequences is introduced. Experimental studies are performed on two benchmark sign language datasets from distinct cultures to verify the performance of the proposed model. Both quantitative and qualitative results show that the authors’ model demonstrates competitive performance compared to state-of-the-art models, and in some cases, achieves considerable improvements over them. © 2024 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Ma2024Attentional
ER  -

TY  - JOUR
AU  - Jiang, B.
AU  - Wang, K.
TI  - Railway accident causation prediction with improved transformer model based on lexical information and contextual relationships
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 296
C7  - 111897
DO  - 10.1016/j.knosys.2024.111897
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193687297&doi=10.1016%2fj.knosys.2024.111897&partnerID=40&md5=0d3015d437b5cf05f305a4eff901f506
AB  - The railway system is a prime example of a safety-critical system. Predicting the causes of railway accidents holds immense significance in enhancing railway transportation safety. Previous approaches to railway causation analysis have encountered huge challenges regarding data processing and analytical capabilities. To address this concern, this paper proposes an innovative deep model framework based on the Transformer architecture that utilizes historical data on railway equipment accidents to predict the causes behind such incidents. Firstly, this paper proposes the utilization of Convolutional Block Attention in the domain of text processing, serving as a lexical encoder to augment word semantics acquisition in accident texts. Subsequently, in order to address the deficiency of traditional Transformers that lack positional representation information, we propose incorporating a BiGRU (Bidirectional Gated Recurrent Unit) as a contextual positional information encoder to capture contextual positional information in railway accident data effectively. Finally, considering that accident data reports are discrete tabular data, this study suggests employing cue word techniques for preprocessing accident data to alleviate the model's learning burden. We applied the proposed model to the FRA (Federal Railroad Administration) dataset. The results demonstrate that our model surpasses the current state-of-the-art language models, exhibiting superior performance compared to the optimal model with a notable improvement of 3.56%, 0.42%, and 0.76% in Precision, Recall, and F1-score, respectively. Furthermore, our model accurately predicts accident categories prone to misjudgment even when trained on limited data, outperforming existing language models. The study findings will contribute to the prevention and management of railway accidents. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; 
LB  - Jiang2024Railway
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Yang, K.
AU  - Ding, Q.
AU  - Wang, R.
AU  - Sun, J.
TI  - TQRFormer: Tubelet query recollection transformer for action detection
PY  - 2024
T2  - Image and Vision Computing
VL  - 147
C7  - 105059
DO  - 10.1016/j.imavis.2024.105059
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192871973&doi=10.1016%2fj.imavis.2024.105059&partnerID=40&md5=c26faccd02c1419630657c8528490f86
AB  - Spatial and temporal action detection aims to precisely locate actions while predicting their respective categories. The existing solution, TubeR (Zhao et al., 2022), is designed to directly detect action tubes in videos by recognizing and localizing actions using a unified representation. However, a potential challenge arises during the decoding stage, leading to a gradual decrease in the model's performance in action detection, specifically in terms of the confidence associated with detected actions. In this paper, we propose TQRFormer: Tubelet Query Recollection Transformer, enabling the subsequent decoder to obtain information from the previous stage. Specifically, we designed Query Recollection Attention to correct errors and output the synthesized results, effectively breaking the limitations of sequential decoding. During the training stage, TubeR (Zhao et al., 2022) generates a limited number of positive sample queries through a one-to-one matching strategy, potentially impacting the effectiveness of training with positive samples. To enhance the quantity of positive samples, we propose a stage matching approach that combines both one-to-many matching and one-to-one matching without additional queries. This approach serves to boost the overall number of positive samples for improved training outcomes. We also propose a more elegant classification head that contains the start and end frames of the small tubes information, eliminating the necessity for a separate action switch. The performance of TQRFormer is superior to previous state-of-the-art technologies on public action detection datasets, including AVA, UCF101–24, JHMDB-21 and MultiSports. The code will available at https://github.com/ykyk000/TQRFormer. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024TQRFormer
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Wang, Y.
TI  - Chfnet: a coarse-to-fine hierarchical refinement model for monocular depth estimation
PY  - 2024
T2  - Machine Vision and Applications
VL  - 35
IS  - 4
C7  - 78
DO  - 10.1007/s00138-024-01560-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195557999&doi=10.1007%2fs00138-024-01560-0&partnerID=40&md5=a99faacdd22e9ea004cedd0a7ca78ece
AB  - In recent years, many researchers have exploited multiple depth estimation architectures to produce high-quality depth maps from a single image. For monocular depth estimation, abundant multiscale features can significantly improve the prediction accuracy. Furthermore, multilevel refinement of the depth map through the model can effectively enhance the overall quality of the depth map. Therefore, we propose an efficient and effective module called light densely connected atrous spatial pyramid (LightDASP), which is employed to extract multiscale information at denser and larger scales from different levels of encoded features without significantly increasing the model size. Next, we propose a hierarchical reconstruction strategy that generates more accurate depth maps by refining the depth maps generated in the previous stage after each decoding stage. Additionally, to provide spatial location information to the decoder, the edge map is incorporated into the generation of a more rational refinement map. The experimental results, conducted on benchmark datasets in both indoor and outdoor scenes, demonstrate that our approach achieves efficient and competitive performance compared to existing methods for monocular depth estimation. We strike a balance between performance and efficiency, resulting in a model with greater potential for practical application. The code is available at https://github.com/ChenAndJiayi/CHFNet upon article acceptance. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chen2024Chfnet
ER  -

TY  - JOUR
AU  - Jiao, Z.
AU  - Wang, X.
AU  - Li, J.
AU  - Gao, R.
AU  - He, M.
AU  - Liang, J.
AU  - Xia, Z.
AU  - Gao, Q.
TI  - HandFormer: Hand pose reconstructing from a single RGB image
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 183
SP  - 155
EP  - 164
DO  - 10.1016/j.patrec.2024.05.019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194392255&doi=10.1016%2fj.patrec.2024.05.019&partnerID=40&md5=5a390942f6fd7e3e5ab3d58adc793d88
AB  - We propose a multi-task progressive Transformer framework to reconstruct hand poses from a single RGB image to address challenges such as hand occlusion hand distraction, and hand shape bias. Our proposed framework comprises three key components: the feature extraction branch, palm segmentation branch, and parameter prediction branch. The feature extraction branch initially employs the progressive Transformer to extract multi-scale features from the input image. Subsequently, these multi-scale features are fed into a multi-layer perceptron layer (MLP) for acquiring palm alignment features. We employ an efficient fusion module to enhance the parameter prediction further features to integrate the palm alignment features with the backbone features. A dense hand model is generated using a pre-computed articulated mesh deformed hand model. We evaluate the performance of our proposed method on STEREO, FreiHAND, and HO3D datasets separately. The experimental results demonstrate that our approach achieves 3D mean error metrics of 10.92 mm, 12.33 mm and 9.6 mm for the respective datasets. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Jiao2024HandFormer
ER  -

TY  - JOUR
AU  - Xia, L.
AU  - Xiao, Q.
TI  - Human–object interaction detection based on disentangled axial attention transformer
PY  - 2024
T2  - Machine Vision and Applications
VL  - 35
IS  - 4
C7  - 72
DO  - 10.1007/s00138-024-01558-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194887152&doi=10.1007%2fs00138-024-01558-8&partnerID=40&md5=bc872e28820383aa56f9dc94a85bce5f
AB  - Human–object interaction (HOI) detection aims to localize and infer interactions between human and objects in an image. Recent work proposed transformer encoder–decoder architectures for HOI detection with exceptional performance, but possess certain drawbacks: they do not employ a complete disentanglement strategy to learn more discriminative features for different sub-tasks; they cannot achieve sufficient contextual exchange within each branch, which is crucial for accurate relational reasoning; their transformer models suffer from high computational costs and large memory usage due to complex attention calculations. In this work, we propose a disentangled transformer network that disentangles both the encoder and decoder into three branches for human detection, object detection, and interaction classification. Then we propose a novel feature unify decoder to associate the predictions of each disentangled decoder, and introduce a multiplex relation embedding module and an attentive fusion module to perform sufficient contextual information exchange among branches. Additionally, to reduce the model’s computational cost, a position-sensitive axial attention is incorporated into the encoder, allowing our model to achieve a better accuracy-complexity trade-off. Extensive experiments are conducted on two public HOI benchmarks to demonstrate the effectiveness of our approach. The results indicate that our model outperforms other methods, achieving state-of-the-art performance. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xia2024Human–object
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Xue, X.
TI  - A transfer learning-based long short-term memory model for the prediction of river water temperature
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108605
DO  - 10.1016/j.engappai.2024.108605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192848040&doi=10.1016%2fj.engappai.2024.108605&partnerID=40&md5=0400e0bd714ce33c6a3b159d70f73a4e
AB  - Water temperature affects many physical, chemical and biological processes in rivers and plays a crucial role in determining the quality of aquatic ecosystems. Due to the complexity and nonlinear characteristics of most factors affecting river water temperature, it is difficult for traditional models to accurately predict river water temperature. In this context, accurate prediction of river water temperature calls for new and innovative machine learning techniques. This paper presents a new hybrid model, called LSTM-Encoder, that combines long short-term memory (LSTM) with transformer encoder. To improve the accuracy of the hybrid LSTM-Encoder model, wavelet threshold denoising (WTD) method was used to denoise the data. The proposed model was compared with the Air2water model as well as eight other artificial intelligence (AI) models. The results show that the mean absolute percentage error (MAPE), mean absolute error (MAE), root mean squared error (RMSE) and coefficient of determination (R2) values of the WTD-LSTM-Encoder model are 2.9, 0.279 °C, 0.567 °C and 0.867, respectively, for the training datasets and 3.2, 0.312 °C, 0.625 °C and 0.714, respectively, for the testing datasets, indicating that the proposed WTD-LSTM-Encoder model has the best comprehensive performance in predicting the river water temperature. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Chen2024transfer
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Shen, J.
AU  - Wang, D.
AU  - Lu, W.
AU  - Chen, Y.
TI  - Multi-modal transform-based fusion model for new product sales forecasting
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108606
DO  - 10.1016/j.engappai.2024.108606
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193803212&doi=10.1016%2fj.engappai.2024.108606&partnerID=40&md5=5cbf5fe76805966e63a1cd795ea0924d
AB  - New product sales prediction is crucial for the digital economy as it enables businesses to make informed decisions about product development, inventory management, marketing strategies, and ultimately driving economic growth and innovation. In the digital economy era, traditional sales forecasting methods often struggle to address the unique challenges of forecasting demand for new products, primarily due to limited historical data and high levels of uncertainty. To address this challenge, we propose a multi-modal transform-based fusion model for new product sales prediction (M2TFM), which integrates multiple data sources (e.g., product images, attributes, text descriptions and context factors like holidays, weather and trends.) to predict new product sales with remarkable accuracy. The proposed method leverages diffusion embedding to fuse heterogeneous data modalities including images, text, and time series into a unified representation that models their complex interactions. By encoding multi modal data using Transformer self-attention, our approach is able to extract nuanced signals across modalities to make more accurate new product sales forecasts. We perform a comprehensive evaluation on a large e-commerce dataset with more than 10,000 fashion items, and the results demonstrate that the proposed method is more effective than existing state-of-the-art baselines for new product sales forecasting. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2024Multi-modal
ER  -

TY  - JOUR
AU  - Wen, J.
AU  - Zhang, N.
AU  - Lu, X.
AU  - Hu, Z.
AU  - Huang, H.
TI  - Mgformer: Multi-group transformer for multivariate time series classification
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108633
DO  - 10.1016/j.engappai.2024.108633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194043949&doi=10.1016%2fj.engappai.2024.108633&partnerID=40&md5=ef3ff9a3e47d4bb0a57e3c928f98e108
AB  - Multivariate time series classification (MTSC) is a crucial task in data science, providing a foundation for analyzing and predicting complex, multi-dimensional data patterns. However, traditional MTSC methods are challenging to handle high-dimensional data effectively and necessitate complex feature engineering. Although deep learning methods have shown excellent performance in handling high-dimensional data, they have difficulty learning diverse temporal patterns in multivariate time series (MTS) and fail to capture deep channel-wise correlations. To this end, we propose a novel MTSC model based on Transformers named Mgformer, which has two basic structures, i.e., the multi-group Transformer module and the channel attention mask module. The multi-group Transformer module combines temporal patching and multiple groups of Transformers to learn complex with diverse temporal patterns at different scales. An attention masking strategy is employed by the channel attention mask module to improve the model's capacity to learn channel-wise correlations and decrease information loss during training. Experimental results on 27 benchmark MTS datasets show that Mgformer is better than state-of-the-art MTSC methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wen2024Mgformer
ER  -

TY  - JOUR
AU  - Gong, X.
AU  - Zhang, Y.
AU  - Hu, S.
TI  - Visual tracking with pyramidal feature fusion and transformer based model predictor
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108461
DO  - 10.1016/j.engappai.2024.108461
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190991509&doi=10.1016%2fj.engappai.2024.108461&partnerID=40&md5=5e66ca5b659b7f0630603666e5891e9c
AB  - Discriminative correlation filters (DCF) have achieved much success in visual tracking. However, most of them simply rely on the features extracted by the last layer of the backbone, while ignoring the low-level rich structural information. In addition, they normally minimize the tailored objective functions to predict the target model in a direct way, which introduces inductive bias and limits the expressivity of the trackers. In view of this, a pyramidal feature fusion module is proposed in this paper to integrate the low-resolution, semantically strong features with high-resolution, semantically weak features. Then, an asymmetric Transformer structure is applied to predict the weights of the model. Finally, a feature refinement module is employed to optimize the search features. Extensive experiments on 5 mainstream datasets demonstrate the superiority of our tracker, where it has achieved better feature expression and more precise target localization. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Gong2024Visual
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Yang, S.
AU  - Wang, Y.
TI  - Dynamic region-aware transformer backbone network for visual tracking
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108329
DO  - 10.1016/j.engappai.2024.108329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189454900&doi=10.1016%2fj.engappai.2024.108329&partnerID=40&md5=3d9ffc72621521bb7435128e09a47219
AB  - In visual tracking, the Transformer architecture is widely used because it can capture the global dependencies of sequence data without inductive bias. However, the attention mechanism of Transformer will bring ultra-high computational complexity and space occupancy, so that the tracking task cannot meet the real-time requirements. In this paper, we explore a sparsity region-aware attention mechanism. The sparse attention mechanism retains the regions with semantic relevance, and performs fine-grained attention calculation in this region. In the region-aware attention mechanism, a DropKey technique is introduced to reduce model over-fitting and improve the generalization ability of the model. Using region-aware attention as the basic building block, we design a dynamic region-aware Transformer backbone for visual tracking. This backbone network can effectively reduce the computational complexity while exploring global context dependencies. Based on the region-aware Transformer backbone network, this paper proposes a dynamic region-aware Transformer backbone visual tracking algorithm, which uses an optimization based model predictor to fully fuse object appearance and background information, so as to achieve more robust object tracking. The proposed tracker is trained in an end-to-end manner and experimentally evaluated on eight tracking benchmarks. Experimental results show that the algorithm has good tracking performance, especially in the application of unmanned aerial vehicle (UAV) tracking, our proposed tracker achieves an area under curve (AUC) score of 66.5% on the UAV123 dataset. Code is available at https://github.com/YSGFF/RTDiMP. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Dynamic
ER  -

TY  - JOUR
AU  - Zhai, H.
AU  - Zheng, W.
AU  - Ouyang, Y.
AU  - Pan, X.
AU  - Zhang, W.
TI  - Multi-focus image fusion via interactive transformer and asymmetric soft sharing
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 107967
DO  - 10.1016/j.engappai.2024.107967
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184504008&doi=10.1016%2fj.engappai.2024.107967&partnerID=40&md5=425ce19a1b6bdf27a98cc7397f0b8e80
AB  - Multi-focus image fusion technology is wildly used in the digital photography, and also be considered as a pre-task of other high level vision tasks. The main purpose is producing an all-in-focus image from multiple partly focused sources accurately, naturally and efficiently. Nowadays, transformer models have achieved great success in numerous vision-related tasks, and its powerful attention modeling ability brings significant possibilities for focus property detection. To make multi-focus image fusion technology even further, in this paper, a novel multi-focus image fusion method using interactive transformer and asymmetric soft sharing is proposed. First, for taking the transformer's advantages in global context modeling and improve its limitations in diversity and efficiency, a locally-enhanced interactive approach is devised. More specifically, it used cross-scale and cross-domain computation strategy to overcome the transformer's certain limitations when comes to domain-specific task, and simultaneously alleviate the insufficient local feature perception and redundant computational cost of existing approach. Second, to cope with the problems of fusion image distortion and artifacts, the proposed method adopts a multi-task learning strategy with asymmetric soft sharing. It predicts the fusion images and decision maps at the same time for avoiding image distortion and further obtaining natural fusion effect. Experimental results reveal that, the proposed method reaches promising focus property detection performance and high-fidelity fusion results. Moreover, when compared with other state-of-the-art methods on five multi-focus image datasets, it is more prominent in both qualitative and quantitative analysis as well as efficiency. The source code is available at https://github.com/zwy0913/MFFT. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhai2024Multi-focus
ER  -

TY  - JOUR
AU  - Jiangyan, Z.
AU  - Ma, J.
AU  - Wu, J.
TI  - A regularized constrained two-stream convolution augmented Transformer for aircraft engine remaining useful life prediction
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108161
DO  - 10.1016/j.engappai.2024.108161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187206982&doi=10.1016%2fj.engappai.2024.108161&partnerID=40&md5=e5242023b87d902ada9c19a8ee3c8ab9
AB  - Remaining Useful Life (RUL) prediction is of great significance for maintaining the reliability and safety of industrial equipment. To address the challenges faced by existing methods in simultaneously extracting local and global degradation information from monitoring data. This paper proposes a Two-Stream Convolution Augmented Transformer (TACT) model based on L2 regularization constraint. Specifically, we design the parallel multi-scale Convolution Neural Network (CNN) and Transformer module to combine the local modeling ability of CNN and the global modeling ability of Transformer to improve the overall architecture of RUL prediction model. Moreover, the two-stream network based on the parallel structure also realizes the synchronous extraction of different time steps and sensor features in the sequence. Then, in the process of model training, the prediction reliability constraint is fused, the delay prediction constraint term is introduced, and the L2 regularization loss function is constructed. Finally, extensive experiments on the commercial modular aero-propulsion system simulation (C-MAPSS) show that our model provides competitive performance in terms of Root-Mean-Square Error (RMSE) and Score metrics. Compared to the state-of-the-art method based on Recurrent Neural Network (RNN) or CNN and its variants, Score is reduced by at least 2.71% and RMSE by at least 3.13%. Compared to the Transformer-based improved method, the Score is decreased by at least 4.54% and the RMSE is decreased by at least 2.78%. The effectiveness of the proposed method is demonstrated. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Jiangyan2024regularized
ER  -

TY  - JOUR
AU  - Zu, B.
AU  - Cao, T.
AU  - Li, Y.
AU  - Li, J.
AU  - Ju, F.
AU  - Wang, H.
TI  - SwinT-SRNet: Swin transformer with image super-resolution reconstruction network for pollen images classification
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108041
DO  - 10.1016/j.engappai.2024.108041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185491739&doi=10.1016%2fj.engappai.2024.108041&partnerID=40&md5=c56a21c66e3914fd7674bf78dc107e71
AB  - With the intensification of urbanization in human society, pollen allergy has become a seasonal epidemic disease with a considerable incidence rate, seriously affecting the healthy life of residents. Accurately classifying and recognizing major allergenic pollens for effective pollen monitoring and forecasting is of great practical significance for improving urban livability and citizens’ quality of life. With the development of deep learning, automatic classification gradually replaces the process of manually recognizing pollen grains. Recently, Swin Transformer (SwinT) has demonstrated strong competitiveness in various tasks. In order to solve the problem of low resolution and complex background information of pollen images, we propose a novel classification framework titled Swin Transformer with Image Super-resolution Reconstruction Network (SwinT-SRNet) for pollen images classification. In the proposed SwinT-SRNet network, an image super-resolution reconstruction method based on the Efficient Super-resolution Transformer (ESRT) is designed to eliminate the blurring problem that arises when resizing low-resolution images to fit the training dimensions of the SwinT model. Furthermore, a high-frequency (HF) information extraction module is proposed to capture high-frequency information in images to provide richer information for the SwinT-SRNet classification network. Extensive experimental evaluations on a self-constructed allergic pollen dataset (POLLEN8BJ) in Beijing, China, as well as a public pollen dataset POLLEN20L-det, show that the SwinT-SRNet model achieves remarkable accuracies of 99.46% and 98.98%. Notably, even without pre-training weights, the model achieved 98.57% and 98.31% accuracy on the POLLEN8BJ and POLLEN20L-det datasets, which are 1.05% and 1.19% higher than SwinT, respectively. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zu2024SwinT-SRNet
ER  -

TY  - JOUR
AU  - Kim, G.
AU  - Choi, J.G.
AU  - Lim, S.
TI  - Using transformer and a reweighting technique to develop a remaining useful life estimation method for turbofan engines
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108475
DO  - 10.1016/j.engappai.2024.108475
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191311100&doi=10.1016%2fj.engappai.2024.108475&partnerID=40&md5=6339c150308b6990d6b61d17b389fb07
AB  - Estimating the Remaining Useful Life (RUL) of industrial machinery is an important task in Prognostics and Health Management (PHM). Accurate RUL prediction based on current health status and real-time sensor measurements can help establish efficient maintenance strategies in advance, thus improving the productivity and efficiency of machinery operations. However, considering the nature of industrial machinery, a data imbalance problem, which exists in current RUL estimation datasets like the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dataset, hinders data-driven approaches. To address the detrimental data imbalance problem and improve estimation performance, this research proposes an Adaptive RUL-wise Reweighting (ARR) technique. ARR uses kernel smoothing to maintain the inherent continuity of RUL and a reweighting method to rebalance the effects of samples with different ground-truth RULs. In addition, this research proposes a novel RUL estimation method that uses a transformer architecture, which has not yet been widely applied for PHM tasks. Using a transformer-based estimation model with high expressive power capable of handling multivariate time-series data has proven effective in RUL estimation. Comprehensive experiments using the C-MAPSS dataset based on cross validation are conducted to find optimal hyperparameter configurations and to validate the proposed method's effectiveness in RUL estimation. For subsets FD001 and FD003 of the C-MAPSS dataset, the proposed method provides state-of-the-art estimation performance with the lowest Root Mean Squared Error (RMSE) values of 11.36 and 11.28 and score values of 192.22 and 133.41, respectively. The proposed method also shows highly competitive performance on subsets FD002 and FD004 of the C-MAPSS dataset. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Kim2024Using
ER  -

TY  - JOUR
AU  - Cai, Z.
AU  - He, D.
AU  - Yang, Z.
AU  - Yang, F.
AU  - Yin, Z.
TI  - STransLOT: splitting-refusion transformer for low-light object tracking
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 23
SP  - 64015
EP  - 64036
DO  - 10.1007/s11042-023-15256-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182225797&doi=10.1007%2fs11042-023-15256-6&partnerID=40&md5=4684ceb9e23c4bf055526ec8f5bbb337
AB  - In the field of tracking, more and more trackers are using the great potential of the transformer to form the framework. Most of them use the Siamese-based backbone and employ the attention mechanism to capture the spatio-temporal features, which benefits the similarity learning and establishing the positional relationship between the template patch and the search region. However, tracking a target accurately in low-light scenarios is one of the most challenging tasks in recent years. To alleviate this defect, we propose an improved Splitting-refusion Transformer for Low-light Object Tracking (STransLOT). Building on the irreplaceable success that Transformer trackers have achieved in visual tracking this year, our STransLOT is combined with a Transformer-like feature fusion module and a classical prediction head. The pixel-level splitting module splits the original image into the part high-light image and part low-light image, while the refusion module fuses the feature maps of these three inputs to improve the low-light feature representation. Experiments show that our STransLOT achieves remarkable results on the LOTD50 dataset and other low-light sequences of public benchmarks. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cai2024STransLOT
ER  -

TY  - JOUR
AU  - Nguyen, N.L.
AU  - Yoo, M.
TI  - Multi-agent trajectory prediction with adaptive perception-guided transformers
PY  - 2024
T2  - IET Intelligent Transport Systems
VL  - 18
IS  - 7
SP  - 1196
EP  - 1209
DO  - 10.1049/itr2.12502
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186940679&doi=10.1049%2fitr2.12502&partnerID=40&md5=317faa4256d55c6d86a36652c14464b7
AB  - The ability to predict the trajectory of an autonomous vehicle accurately is crucial for safe and efficient navigation. However, predicting diverse and multimodal futures can be challenging. Recent approaches such as attention and graph neural networks have achieved state-of-the-art performance by considering agent interactions and map contexts. This study focused on multi-agent prediction using an agent-centric approach with transformers. This enables parallel computation and a comprehensive understanding of the environment. Two main features are introduced: an adaptive receptive field (ARF) that captures the relevant surroundings for each agent, and perception encoding, which serves as spatial context embeddings. The ARF adapts to the agent's velocity and rotation, focusing attention ahead at high speeds or to the sides when it is slower. Perception encoding divides agents or lanes into levels and encodes the information of each level. This approach enables the efficient encoding of complex spatial relationships. The proposed method combines these advances with transformer modelling for multi-agent trajectory prediction while ensuring real-time prediction capabilities. The approach is evaluated on the Argoverse benchmark and better performance than the state-of-the-art baseline is achieved. By addressing challenges such as multimodal outputs and robustness, the study enhances the safety and efficiency of autonomous driving systems by more accurately predicting trajectories. © 2024 The Authors. IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Nguyen2024Multi-agent
ER  -

TY  - JOUR
AU  - Mao, Y.
AU  - Chen, Z.
AU  - Liu, S.
AU  - Li, Y.
TI  - Unveiling the potential: Exploring the predictability of complex exchange rate trends
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108112
DO  - 10.1016/j.engappai.2024.108112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188030550&doi=10.1016%2fj.engappai.2024.108112&partnerID=40&md5=b93f0022fdd5ca7cb57e164589ce4ddc
AB  - Forecasting exchange rates is challenging due to its diverse features and complex patterns. Inspired the theory of receptive fields, we proposed two models: the Transformer with Convolutional Neural Network (CNN-Transformer) and the Long Short Term Memory networks with Convolutional Neural Network (CNN-LSTM). These models leverage Convolutional Neural Network (CNN) modules to expand the learnable timestep of Long Short Term Memory networks (LSTM) and reduce the complexity of Transformer. Generally, CNN-LSTM demonstrates the highest predictive accuracy. Furthermore, there is a silver lining: the sentiment in past news is closely linked to future exchange rates. In order to introduce the news sentiment to improve the performance of models, we fine-tune a pre-trained model, Bidirectional Encoder Representations from Transformers with Whole Word Masking (BERT-WWM), to extract the sentiment information from news dataset. However, the effectiveness of introducing news sentiment is greatly dependent on the timesteps. Longer timesteps often increase the likelihood of success for this method. We believe this pattern relates to the timeliness of news and the delayed impact of news events. Also, it's important to note that the content of news text significantly influences the forecasting performance. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Mao2024Unveiling
ER  -

TY  - JOUR
AU  - Song, K.
AU  - Yu, Y.
AU  - Zhang, T.
AU  - Li, X.
AU  - Lei, Z.
AU  - He, H.
AU  - Wang, Y.
AU  - Gao, S.
TI  - Short-term load forecasting based on CEEMDAN and dendritic deep learning
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 294
C7  - 111729
DO  - 10.1016/j.knosys.2024.111729
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189756860&doi=10.1016%2fj.knosys.2024.111729&partnerID=40&md5=3e28a1616a64644721bce257b7326e8a
AB  - Short-term load forecasting (STLF) plays a key role in improving the operational efficiency of real-time electricity markets by reducing load uncertainty, optimising the allocation of generation resources and increasing the reliability of electricity supply. Despite significant advances in the field, achieving high accuracy in STLF remains a challenge due to the inherent complexity and volatility of load data. This study proposes a novel STLF method that synergistically combines the strengths of a dendritic neuron model (DNM), long short-term memory, and complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) to address these challenges. First, historical load data is decomposed into components of different frequencies using CEEMDAN. Then, LSTM is used to extract the temporal characteristics of these load subsequence components in combination with various influencing factors such as temperature and humidity. Uniquely, this study innovatively integrates a dendritic neuron model instead of the traditional fully connected layer, a structural innovation that enhances the model's ability to explore the intrinsic correlations of the time series data in depth. This allows the model to process and predict each component individually, and then later reconstruct and sum these independent prediction results to obtain a final prediction value with higher accuracy. Experiments are conducted on the Panama electricity load dataset to compare the proposed dendritic learning model with several state-of-the-art models, including CrossFormer and Transformer. The results confirm that the proposed model has significantly better prediction accuracy. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; 
LB  - Song2024Short-term
ER  -

TY  - JOUR
AU  - Han, J.
AU  - Shin, M.
AU  - Paik, J.
TI  - Robust point cloud registration using Hough voting-based correspondence outlier rejection
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 107985
DO  - 10.1016/j.engappai.2024.107985
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183980163&doi=10.1016%2fj.engappai.2024.107985&partnerID=40&md5=1d4e8b6512693ffa39633cda4955d802
AB  - In this paper, we present a novel method for point cloud registration in large-scale 3D scenes. Our approach is accurate and robust, and does not rely on unrealistic assumptions. We address the challenges posed by scanning equipment like LiDAR, which often produce point clouds with dense properties. Additionally, our method is effective even in scenes with low overlap rates, specifically less than 30%. Our approach begins by computing overlap region-based correspondences. This involves extracting deep geometric features from point cloud pairs, which is especially beneficial in enhancing registration performance in cases with low overlap ratios. We then construct efficient triplets that vote in the 6D Hough space, representing the transformation parameters. This process involves creating a quartet from overlap region-based correspondences and then forming a final triplet following a sampling process. To mitigate ambiguity during training, we use similarity values of the triplet as features of each vote when configuring votes for network input. Our framework incorporates the architecture of the Fully Convolutional Geometric Features (FCGF) network, augmented with a transformer's attention mechanism, to reduce noise in the voting process. The final stage involves identifying the consensus of correspondence in the Hough space using a binning approach, which enables us to predict the final transformation parameters. Our method has demonstrated state-of-the-art performance on indoor datasets, including high overlap ratio data like 3DMatch and low overlap ratio data like 3DLoMatch. It has also shown comparable performance to leading methods on outdoor datasets like KITTI. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Han2024Robust
ER  -

TY  - JOUR
AU  - Chen, P.
AU  - Ma, Z.
AU  - Xu, C.
AU  - Jin, Y.
AU  - Zhou, C.
TI  - Self-Supervised Transfer Learning for Remote Wear Evaluation in Machine Tool Elements With Imaging Transmission Attenuation
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 13
SP  - 23045
EP  - 23054
DO  - 10.1109/JIOT.2024.3382878
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189139377&doi=10.1109%2fJIOT.2024.3382878&partnerID=40&md5=ef37ae5029fcb579b20b7330a7412e67
AB  - The Industrial Internet of Things (IIoT) has significantly advanced traditional industrial systems, especially in facilitating remote monitoring and predictive maintenance for computer numerical control (CNC) machines. Ball screw drives (BSDs), crucial in CNC machining, require regular upkeep, often challenged by environmental influences and the limitations of wired sensor-based diagnostic procedures. Wireless sensors offer a cost-effective solution but struggle with data integrity during transmission, impacting remote wear evaluation of BSDs. Current recovery methods are not always adequate, often relying on extensive historical data and suffering from accumulating errors. Addressing these limitations, a novel self-supervised transfer learning (SSTL) model is proposed for remote wear assessment of machine tool components. This model integrates an image capture module into CNC surveillance systems and employs a LocalMIM module, which is pretrained and fine-tuned to adapt to various domains, especially for image quality deterioration during data transmission. The SSTL model is designed to function effectively despite significant pixel data loss, eliminating the need for historical data for image restoration. This innovation is particularly adept at evaluating wear in environments with compromised image transmission, providing a robust predictive maintenance strategy for BSDs that is less affected by data loss, aiding a pressing industrial requirement for consistent and dependable remote monitoring solutions.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Chen2024Self-Supervised
ER  -

TY  - JOUR
AU  - Xiang, C.
AU  - Gan, V.J.L.
AU  - Deng, L.
AU  - Guo, J.
AU  - Xu, S.
TI  - Unified weakly and semi-supervised crack segmentation framework using limited coarse labels
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108497
DO  - 10.1016/j.engappai.2024.108497
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191340005&doi=10.1016%2fj.engappai.2024.108497&partnerID=40&md5=0b38b63e95f2955b5816b68ccdb3ec38
AB  - Obtaining extensive, high-quality datasets for crack segmentation with pixel-level labels is expensive and labor-intensive. The Unified Weakly and Semi-supervised Crack Segmentation (UWSCS) framework addresses this challenge by leveraging a limited number of images with coarse labels and a larger set of unlabeled images. Two label correction modules, based on super-pixel segmentation and a shrink module, are incorporated in the model training to improve crack label accuracy and optimize edge refinement. UWSCS employs a dual-encoder fusion network, combining transformers and convolutional neural networks, to enhance crack segmentation in complex backgrounds. An enhanced algorithm using the medial axis transform is proposed for accurately quantifying crack length and width. Extensive experiments were conducted on both synthetic and real crack datasets to validate the superior performance of UWSCS. The results underscore the significant impact of label quality and quantity used in training on model prediction accuracy. Trained on a concrete crack dataset with limited coarse labels, UWSCS achieves an Intersection of Union (IoU) of 77.53%, surpassing the fully supervised model using the same number of coarse labels by 28.64%. It closely approaches the performance of a fully supervised model with the same number of fine labels (IoU of 80.21%). UWSCS outperforms other advanced networks and semi-supervised/weakly supervised algorithms when trained with a limited set of more cost-effective manually labeled coarse labels. Integrated with the crack segmentation network, super-pixel segmentation, and shrink modules during training, UWSCS with limited coarse labels performs similarly to a fully supervised model using fine labels, thereby reducing manual labeling costs by over 90% and enhancing detection efficiency in practical engineering. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xiang2024Unified
ER  -

TY  - JOUR
AU  - Peng, X.
AU  - Chen, Z.
AU  - Zhang, J.
AU  - Li, Z.
AU  - Du, W.
TI  - A truncated Gaussian distribution based multi-scale segment-wise fusion transformer model for multi-step commodity price forecasting
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108434
DO  - 10.1016/j.engappai.2024.108434
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191008452&doi=10.1016%2fj.engappai.2024.108434&partnerID=40&md5=ee20f9ad0e42e7b886f3d255f56cedd4
AB  - Accurately forecasting commodity price trends is crucial for producers, market participants, and related enterprises to make informed decisions regarding production planning and scheduling. However, achieving high accuracy in multi-step forecasting poses significant challenges due to the unique financial characteristics inherent in commodities. Thus, this paper proposes a novel truncated Gaussian distribution based multi-scale segment-wise fusion Transformer for multi-step commodity price forecasting. First, a multi-scale segment-wise fusion module, which capture the time dependencies from different time granularity, is designed to describe the time-varying trend characteristics of commodity prices. Second, considering the characteristics of price range fluctuation and truncation, a truncated Gaussian distribution is introduced to describe price uncertainty. Last, to evaluate the proposed method's effectiveness, extensive experiments are conducted using real data on energy chemical product prices. The experimental results demonstrate that the proposed method accurately captures price change trends and effectively estimates price uncertainty. Compared to the widely adopted Autoformer, our approach achieves approximately 30% reductions in both root mean square error (RMSE) and mean absolute error (MAE) metrics. Additionally, it exhibits certain advantages over the current state-of-the-art (SOTA). In the 20-step and 60-step multi-step prediction tasks, the proposed method achieves RMSE values of 91.18 and 142.94, respectively, surpassing the current SOTA. The introduced research framework provides valuable insights for decision-makers engaged in analyzing and forecasting commodity markets. The code is available on https://github.com/dean-ob/TGD-MSSF. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Peng2024truncated
ER  -

TY  - JOUR
AU  - Khan, M.S.
AU  - Malik, M.S.I.
AU  - Nadeem, A.
TI  - Detection of violence incitation expressions in Urdu tweets using convolutional neural network
PY  - 2024
T2  - Expert Systems with Applications
VL  - 245
C7  - 123174
DO  - 10.1016/j.eswa.2024.123174
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182027983&doi=10.1016%2fj.eswa.2024.123174&partnerID=40&md5=e0766770fc300eb72efcf5b0205e820e
AB  - The popularity and widespread use of social media are constantly generating unmonitored data, spreading unwanted content such as hate speech and expressions that incite violence. Automatic detection of violence incitation is a challenging task and to the best of our knowledge, Urdu language has been completely neglected. Therefore, a robust framework is proposed for identifying expressions exhibiting violence incitation in Urdu tweets. The potentials of the semantic, word embeddings, and language models are explored to learn contextualized representations of the violence incitation in Urdu tweets. In addition, the strength of the 1-Dimensional Convolutional Neural Network (1D-CNN) is exploited by tunning its parameters on the newly proposed annotated Urdu corpus. The annotated dataset consists of 4808 tweets manually collected from Pakistani Twitter accounts. The performance of 1D-CNN with word uni-gram, Urdu Bidirectional Encoder Representations from Transformer (Urdu-BERT), and Urdu- Robustly Optimized BERT Approach (Urdu-RoBERTa) models is compared to fine-tuned Urdu-RoBERTa, Bidirectional Long short-term memory (BiLSTM), Convolutional BiLSTM (CBi-LSTM), and six state-of-the-art Machine Learning (ML) models. The results reveal that the 1D-CNN with word uni-gram model shows benchmark performance by demonstrating 89.84% accuracy and 89.80% macro f1-score. Furthermore, it outperforms all comparable models and achieves 89.76% f1-score for the violence class, and 89.84% f1-score for not-violence class identification. The uniqueness of the proposed model is evaluated using MARS shine-through and MARS occlusion metrics and the CNN model outperformed the others. The MARS metrics facilitate evaluation and visualization of the classifier performance in terms of capturing unique true positive samples that are not predicted by other models. The findings of the proposed framework are very supportive for further investigation in this domain. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Khan2024Detection
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Zhang, D.
AU  - Wulamu, A.
TI  - A Multi-User-Multi-Scenario-Multi-Mode aware network for personalized recommender systems
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108169
DO  - 10.1016/j.engappai.2024.108169
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186735820&doi=10.1016%2fj.engappai.2024.108169&partnerID=40&md5=8bbf1a6571226e796d1064ce2509a0f2
AB  - User personalized recommendation is increasingly vital in many industrial applications. How to precisely mine user's dynamic interests from multiple scenarios is a challenge task in Click-Through Rate (CTR) prediction. Existing works obtain representations based on feature engineering from training data. However, the CTR models are often sensitive to different users and scenarios. To address these concerns, we propose a novel approach, Multi-User-Multi-Scenario-Multi-Mode (MUMSMM), which learns user personalized preference from history behavior. Specifically, we adapt the cognitive gate-net, which can screen applicable networks automatically for different users and scenarios. Then, we design a feature mechanism to recognize valuable information, while also having an adaptive gate to optimize the hyper-parameters among tasks. Besides, we propose a novel interest unit, which can capture the user diverse interests and adjust the intensity. Furthermore, to generate a more stable interest representation, we employ transformer network. Our innovative approach can be flexibly embedded into the mainstream recommended CTR model. Extensive experiments on three public benchmark datasets (Alibaba, Amazon, and JD) show that the proposed MUMSMM model outperforms state-of- the-art models by an average improvement of +2.49% in AUC (Area Under Curve) and +4.33% of HR@10 (Hits Rate), respectively. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Multi-User-Multi-Scenario-Multi-Mode
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Sang, H.
AU  - Liu, Q.
AU  - Chen, W.
AU  - Zhao, Z.
TI  - Neural differential constraint-based pedestrian trajectory prediction model in ego-centric perspective
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 107993
DO  - 10.1016/j.engappai.2024.107993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185559492&doi=10.1016%2fj.engappai.2024.107993&partnerID=40&md5=fe1f525bdf9c66f30e91a54918c87bcb
AB  - Autonomous vehicles offer significant advantages for transportation systems, particularly in enhancing traffic safety. To achieve this goal, it is crucial to comprehensively understand and predict the future trajectories of pedestrians in proximity to autonomous vehicles. Many contemporary approaches for predicting pedestrian trajectories heavily rely on neural networks, especially recurrent neural networks. However, these approaches do not explicitly incorporate the dynamics of pedestrian movement and instead rely on data-driven black-box models. Consequently, these models may fall short in terms of interpretability and fail to adhere to the fundamental principles of kinematics. In response to these limitations, our work introduces an innovative model for pedestrian trajectory prediction grounded in neural differential constraints. We aim to investigate temporal changes in pedestrian state variables, such as position and speed, using neural networks. During the prediction process, the output of the neural network is governed by differential equations. This approach ensures that the generated trajectories align with the fundamental principles of physics, harnessing the combined power of neural networks and physics-based pedestrian motion models. Furthermore, our research endeavors to develop a cohesive framework that seamlessly integrates pedestrian movement patterns with the influence of ego-vehicles, while also considering potential destinations to inform future trajectory planning. We conducted extensive experiments on two publicly available real-world datasets to assess the effectiveness of our model in enhancing prediction accuracy and providing coherent explanations of pedestrian motion, comparing it to state-of-the-art methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Neural
ER  -

TY  - JOUR
AU  - Wu, D.
AU  - Cheng, L.
AU  - Li, R.
AU  - Yang, P.
AU  - Xu, X.
AU  - Wang, X.
AU  - Lee, C.-H.
TI  - Automatic segmentation of curtain wall frame using a context collaboration pyramid network
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108309
DO  - 10.1016/j.engappai.2024.108309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189016111&doi=10.1016%2fj.engappai.2024.108309&partnerID=40&md5=24a8593010e8811235b6a26cbe04f37d
AB  - Accurate positioning of curtain wall frames is crucial for the automated installation of curtain wall modules. However, the current robot-based installation methods overly depend on visual guidance from operators, resulting in high costs and limiting construction efficiency. The development of deep learning has introduced an image segmentation approach that offers a new solution for the visual positioning of curtain wall frames. This paper proposes a context collaboration pyramid network to automatically segment curtain wall frames by incorporating context interaction and channel guided pyramid structure. The model adopts an “encoder-decoder” architecture with a feature interaction block strategically inserted between the encoder and decoder. Specifically, the encoder utilizes the pyramid pooling Transformer as a backbone to extract multi-level features from original RGB images. The decoder employs a channel guided pyramid convolution module to integrate multi-scale features and achieve finer prediction. Meanwhile, a context interaction fusion module between the features of adjacent levels was designed carefully to enhance the collaboration of the architecture. In addition, a benchmark dataset for the curtain wall frame segmentation task, consisting of 1547 images, was established. The dataset incorporates challenging scenarios, including strong lights, low contrast, and cluttered backgrounds. This method is evaluated on the collected dataset, and achieves an impressive accuracy of 97.30% and an F1-Score of 88.95%, outperforming other segmentation networks. Overall, the proposed method can extract target information accurately and efficiently and provide critical visual guidance for the robot, so as to promote the automatic installation level of the curtain wall module. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wu2024Automatic
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Dai, R.
AU  - Liu, D.
AU  - Wang, K.
AU  - Yuan, X.
AU  - Liu, C.
TI  - A task-oriented deep learning framework based on target-related transformer network for industrial quality prediction applications
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108361
DO  - 10.1016/j.engappai.2024.108361
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189445136&doi=10.1016%2fj.engappai.2024.108361&partnerID=40&md5=266f24000740e35fdc303004f9da0a7b
AB  - Executing various production tasks is critical to the safe operation and efficient production of industrial processes. As one of them, the detection task of key quality variables directly affects the operation optimization and decision-making of industrial processes, but it is severely limited by the harsh environment and detection instruments. Therefore, the real-time prediction task of key quality variables becomes the basis for optimal control of industrial processes. To address this issue, this paper proposes a task-oriented deep learning framework based on a target-related transformer (TR-Former) network for industrial quality prediction tasks. Specifically, a new target-related self-attention (TR-SA) mechanism is developed to guide feature learning by adding attention scores between task-related target variables and other variables. As a result, the learned features in this instance will be guaranteed to be relevant to the target variable and useful for the quality prediction task. Moreover, the long-range dynamics of industrial process data can also be captured, which can further improve the prediction performance of the model. Finally, extensive experiments were conducted on two industrial processes to validate the superiority of the proposed method in terms of quality prediction tasks. The experimental results demonstrate that the proposed TR-Former method exhibits an improvement ranging from 3% to 13% in the mean absolute error indicator compared to the traditional transformer and other state-of-the-art methods. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wang2024task-oriented
ER  -

TY  - JOUR
AU  - Gao, F.
AU  - Huang, W.
AU  - Weng, L.
AU  - Zhang, Y.
TI  - SIF-TF: A Scene-Interaction fusion Transformer for trajectory prediction
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 294
C7  - 111744
DO  - 10.1016/j.knosys.2024.111744
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189937390&doi=10.1016%2fj.knosys.2024.111744&partnerID=40&md5=75eb3ecfdca041a02c2bd1df73eca996
AB  - Accurate pedestrian trajectory prediction is essential for the advancement of intelligent robot or autonomous vehicle, which is a challenging and interesting task. In this paper, a Scene-Interaction fusion Transformer (SIF-TF) for trajectory prediction is proposed, which takes into account three fundamental factors, i.e. social interaction, past trajectory, and semantic scene. A scene-social modeling method is added to the model to integrate social interaction and semantic scene. The proposed SIF-TF contains two critical components: the scene-social transformer and the temporal transformer. The scene-social transformer is tasked with capturing social interaction and semantic scene information, while the temporal transformer focuses on extracting temporal correlation information. Furthermore, the SIF-TF employs a two-stage trajectory prediction approach to jointly generate future trajectories. To evaluate the effectiveness, the comparative experiments were conducted on five widely-used public datasets. The experiments results, with an average evaluation metric of ADE/FDE of 0.23/0.47, significantly outperforms other state-of-the-art methods. These findings demonstrate that the proposed SIF-TF is capable of delivering more precise pedestrian trajectory predictions across diverse scene backgrounds. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Gao2024SIF-TF
ER  -

TY  - JOUR
AU  - Mishra, A.K.
AU  - Renganathan, J.
AU  - Gupta, A.
TI  - Volatility forecasting and assessing risk of financial markets using multi-transformer neural network based architecture
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108223
DO  - 10.1016/j.engappai.2024.108223
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188055514&doi=10.1016%2fj.engappai.2024.108223&partnerID=40&md5=8c841ec81315d6545868d847b49a8f70
AB  - This research introduces a more reliable model for predicting market volatility. The model incorporates Transformer and Multi-transformer layers with the GARCH and LSTM models and compares their performance to classic GARCH-type models. Euro-US Dollar FX Spot Rate (EURO-USD), Australian-US Dollar FX Spot Rate (AUD-USD), S&P 500 Index, FTSE 100 Index, Reliance Industries Ltd., and Samsung Electronics Co Ltd. are analyzed. The timeframe examined is January 2005 to December 2021, with training from 2005 to 2016 and testing from 2017 to 2021. Empirical evidence suggests that hybrid Neural-network models, notably Transformer-based models, outperform individual transformers, deep learning, neural networks, and traditional GARCH-type models, even in unpredictable conditions like the COVID-19 pandemic. Within the hybrid Neural-network models, MT-GARCH and MTL-GARCH showed lower validation error (RMSE) than the other models, showing that the bagging mechanism added to the attention mechanism of the Multi-Transformer architecture helped to lower the error in the variance in the noisy data of the daily returns of the assets, reducing the RMSE of the hybrid multi-Transformer models. In addition, three to four of the five hybrid neural-network models showed appropriate risk estimates for the entire test period, as observed from the Christoffersen test. Moreover, the lengthy sample period helps test whether hybrid models perform better than classic GARCH-type models in volatile conditions like the COVID-19 pandemic. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Mishra2024Volatility
ER  -

TY  - JOUR
AU  - Danyal, M.M.
AU  - Khan, S.S.
AU  - Khan, M.
AU  - Ullah, S.
AU  - Mehmood, F.
AU  - Ali, I.
TI  - Proposing sentiment analysis model based on BERT and XLNet for movie reviews
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 24
SP  - 64315
EP  - 64339
DO  - 10.1007/s11042-024-18156-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182477854&doi=10.1007%2fs11042-024-18156-5&partnerID=40&md5=f91f2e6bafde7bad33a7c4f5fa5f79bd
AB  - Movie reviews are a valuable source of information for potential viewers. However, reading all of the reviews can be time-consuming and overwhelming. Summarizing all of the reviews will help you make the correct choice without wasting time reading all of the reviews. Sentiment analysis, or opinion mining, can extract subjective information from movie reviews, such as the reviewer’s overall opinion of the movie, its strengths and weaknesses, and the reviewer’s recommendations. This information can help potential viewers make informed decisions about whether or not to watch a movie. XLNet and Bidirectional Encoder Representations from Transformers (BERT) are pre-trained advanced language models that learn bidirectional relationships between words, improving performance on many natural language processing tasks. BERT uses a masked language modeling objective, while XLNet uses a permutation language modeling objective. This experiment is based on the proposed method for XLNet and BERT, two advanced techniques and popular baseline techniques using the Internet Movie Database (IMDB) Dataset of 50K reviews and the Rotten Tomatoes dataset. We pre-processed both datasets using data cleaning, the removal of duplicate reviews, lemmatization, and handling of chat words to improve baseline technique results. The results indicate that XLNet achieved the highest accuracy on both datasets. As a result of the research experiment, sentiment analysis provides insights into how emotions and attitudes are expressed in movie reviews that can be used to predict a movie’s performance based on their overall sentiment. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Danyal2024Proposing
ER  -

TY  - JOUR
AU  - Lin, M.
AU  - Li, G.
AU  - Hao, Y.
TI  - Bridging local and global representations for self-supervised monocular depth estimation
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108277
DO  - 10.1016/j.engappai.2024.108277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188827393&doi=10.1016%2fj.engappai.2024.108277&partnerID=40&md5=3f620a0562404c60e315224d540027c0
AB  - Monocular depth estimation is a challenging problem, especially in a self-supervised manner without relying on the depth ground truth. The self-supervised approach places higher demands on the global and local feature extraction capabilities of the network. Based on this view, we propose to perform efficient hybrid feature extraction by exploiting the capacity of the Transformer and convolutional neural network to model long-range dependencies and local correlations at the same time. A bowknot-type fuser is designed to align features extracted from different sources as well as bridge global and local semantic representations. To obtain higher-quality pseudo-labels from the extracted features, we suggest the pseudo-label smoothing technique to fully utilize the multi-scale features, consequently boosting the effect of self-distillation loss as an auxiliary supervision to train the neural network. In addition, we propose pixel adaptive smoothness loss to refine the predicted depth map by introducing the image's textural and spatial information. The suggested method is trained on the KITTI benchmark using stereo image pairs and achieves competitive depth estimation performance in contrast with previous approaches. The code and models are available at https://github.com/MaylingLin/BLGR-Depth. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Lin2024Bridging
ER  -

TY  - JOUR
AU  - Nakamoto, I.
AU  - Zhuang, W.
AU  - Chen, H.
AU  - Guo, Y.
TI  - PDSMNet: Parallel pyramid dual-stream modeling for automatic lung COVID-19 infection segmentations
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 133
C7  - 108541
DO  - 10.1016/j.engappai.2024.108541
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192052306&doi=10.1016%2fj.engappai.2024.108541&partnerID=40&md5=5d4e0fd4bae6db5970179d0ee068232d
AB  - Artificial intelligence-based segmentation models can assist the early-stage detection of lung COVID-19 infections or lesions from medical images with higher efficiency versus traditional techniques, yet challenges remain attributable to factors such as heterogeneities in infection traits, small infection regions, blurred boundary context, mixtures of varying infection regions, and obscure intensity contrast between lesions and normal tissues. This study aims to improve the performance of automatic segmentation of lung COVID-19 infections by proposing a novel approach named parallel pyramid dual-stream modeling network (PDSMNet) with two major contributions: (1) refined design of the framework including (a) a transformer module termed parallel pyramid dual-stream module (PDSM) to effectively preserve channel, spatial, and other latent features; (b) fusion of a multi-scale pyramid parallel-pooling module (MPM) that extracts features in parallel at differentiated scales; (c) calibration of the skip-connection architectures to optimize prediction and preserve features; (d) calibration of attention mechanisms reflecting multiple sources of information including parallel-, serial-, and cross-attention contexts; and (e) improvement of the integral functionality of the framework in curtailing the burdens of parameter computations in a multi-modality scenario. (2) loss functions accounting for the training losses of normal tissues, diseases, and boundaries respectively to enhance the performance of the network. The calibrated loss design allowing for a margin improves the capacity of predictions. We conducted experiments using three different datasets with different modalities and compared the proposed framework PDSMNet with two other benchmarks and eight similar state-of-the-art (SOTA) networks. The experiments observed consistent performance improvements across all datasets. PDSMNet attained asymptotically a maximum increase of 16.5%, 6.2%, and 15.5% for mean F1 score (mF1S), mean dice-score coefficient (mDSC), mean intersection over union (mIoU) versus SOTA PDEAtt-UNet, a maximum increase of 49.6%, 25.6%, and 38.0% for mF1S, mDSC, and mIoU versus InfNet, a maximum increase of 26.1%, 10.8%, 21.8% versus MiniSeg, a maximum increase of 14.0%, 3.0%, and 13.4% versus TransUNet, and a maximum increase of 37.9%, 16.8%, 31.2% versus Attention-UNet respectively. For other SOTA models such as MT-UNet, UCTransNet, and UTNetV2, a sizeable enhancement of performance was observed as well. PDSMNet also yielded asymptotically a maximum 30.6%, 14.8%, 26.3% increase of mF1S, mDSC, mIoU versus benchmark UNet, and a maximum increase of 42.8%, 21.5%, 33.3% versus benchmark UNet++ respectively. PDSMNet demonstrated reduced computational costs as well, yielding approximately 0.53 M of parameters and 6.55G of floating-point operations per second (FLOPs) respectively using different datasets, and the quantitative and qualitative ablation tests reinforced the effectiveness of the various components of the proposed framework. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Nakamoto2024PDSMNet
ER  -

TY  - JOUR
AU  - Guo, W.
AU  - Yang, S.
AU  - Ren, Y.
AU  - Huang, Y.
TI  - CrowdTrans: Learning top-down visual perception for crowd counting by transformer
PY  - 2024
T2  - Neurocomputing
VL  - 587
C7  - 127650
DO  - 10.1016/j.neucom.2024.127650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190123729&doi=10.1016%2fj.neucom.2024.127650&partnerID=40&md5=8dd4df83b86380d2d8e7359314721c6e
AB  - Recent advancements in crowd counting methods have relied on density maps as an intermediary representation for counting, whereby the ground truth of the density map is obtained through the convolution of dot annotations with a fixed Gaussian kernel. However, the presence of perspective phenomena introduces scale variations among targets, leading to a significant challenge in scene generalization. Existing approaches suffer from limitations in accommodating a limited number of scales within the density map generation and prediction processes. In order to address this problem, we introduce a novel transformer network, CrowdTrans, which incorporates a two-channel tasks-based density map estimator and generator. This innovative approach learns a density map by leveraging both pixel-wise classification and regression. Furthermore, we devise an end-to-end framework that facilitates the joint learning of the density map estimator and the corresponding label generator. Through extensive experimentation on widely utilized datasets, our results demonstrate the state-of-the-art performance of our proposed method, thus validating the effectiveness of our novel designs. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Guo2024CrowdTrans
ER  -

TY  - JOUR
AU  - Song, Y.
AU  - Wang, J.
AU  - Ge, Y.
AU  - Li, L.
AU  - Guo, J.
AU  - Dong, Q.
AU  - Liao, Z.
TI  - Medical image classification: Knowledge transfer via residual U-Net and vision transformer-based teacher-student model with knowledge distillation
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 102
C7  - 104212
DO  - 10.1016/j.jvcir.2024.104212
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196740525&doi=10.1016%2fj.jvcir.2024.104212&partnerID=40&md5=187a435e4183c517893c413545af350d
AB  - With the widespread integration of deep learning techniques in the domain of medical image analysis, there is a prevailing consensus regarding their efficacy in handling high-dimensional and intricate medical image data. However, it is imperative to acknowledge that while complex deep models exhibit a remarkable capacity for processing high-dimensional and intricate data, they often necessitate a substantial allocation of computational resources and time. Furthermore, lightweight models, despite their computational efficiency, tend to underperform when compared to their more intricate counterparts in terms of performance. Hence, the prevailing aspiration is to transfer the cognitive prowess of complex models to their lightweight counterparts. Addressing the aforementioned concern, this study proposes a knowledge distillation approach that encompasses joint feature and soft label transfer. It entails the transference of knowledge from the teacher model's intermediate features and predictive outcomes to the student model. The student model leverages this knowledge to emulate the behavior of the teacher model, thereby enhancing the precision of its own predictions. Building upon this foundation, we introduce a Res-Transformer teacher model based on the U-Net architecture and a student model known as ResU-Net, which is grounded in residual modules. The Res-Transformer teacher model employs multi-layer residual attention during the downsampling process to capture deep-level features of the image. Subsequently, we have incorporated a Multi-layer Perceptual Attention module (MPA) for each skip connection layer, facilitating the integration of hierarchical upsampled information to restore fine-grained details within the feature maps. The ResU-Net student model enhances network stability through the utilization of residual modules and optimizes skip connections to recover any lost image information during convolutional operations. Lastly, we conducted experimental assessments on multiple disease datasets. The results reveal that the ACC of the Res-Transformer model achieves an impressive 96.9%. Furthermore, through the knowledge distillation method, rich knowledge is effectively transferred to the ResU-Net model, resulting in a remarkable ACC improvement of 7.2%. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Song2024Medical
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Wu, P.
AU  - Zhang, X.
AU  - Xu, R.
AU  - Liang, J.
TI  - Add-Vit: CNN-Transformer Hybrid Architecture for Small Data Paradigm Processing
PY  - 2024
T2  - Neural Processing Letters
VL  - 56
IS  - 3
C7  - 198
DO  - 10.1007/s11063-024-11643-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195604176&doi=10.1007%2fs11063-024-11643-8&partnerID=40&md5=8724f76eea814e71e8d462f448259dd0
AB  - The vision transformer(ViT), pre-trained on large datasets, outperforms convolutional neural networks (CNN) in computer vision(CV). However, if not pre-trained, the transformer architecture doesn’t work well on small datasets and is surpassed by CNN. Through analysis, we found that:(1) the division and processing of tokens in the ViT discard the marginalized information between token. (2) the isolated multi-head self-attention (MSA) lacks prior knowledge. (3) the local inductive bias capability of stacked transformer block is much inferior to that of CNN. We propose a novel architecture for small data paradigms without pre-training, named Add-Vit, which uses progressive tokenization with feature supplementation in patch embedding. The model’s representational ability is enhanced by using a convolutional prediction module shortcut to connect MSA and capture local features as additional representations of the token. Without the need for pre-training on large datasets, our best model achieved 81.25% accuracy when trained from scratch on the CIFAR-100. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Chen2024Add-Vit
ER  -

TY  - JOUR
AU  - Li, R.
AU  - Wang, W.
AU  - Hu, H.
AU  - Chen, T.
AU  - Zhao, M.
TI  - Ultrahigh-definition video quality assessment: A new dataset and benchmark
PY  - 2024
T2  - Neurocomputing
VL  - 586
C7  - 127633
DO  - 10.1016/j.neucom.2024.127633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189860021&doi=10.1016%2fj.neucom.2024.127633&partnerID=40&md5=cdaf5613b6718d7c14ce4f938014a258
AB  - Video quality assessment (VQA) based on deep learning requires a massive amount of data for support. However, existing mainstream datasets do not consider the Ultrahigh-definition VQA (UHD-VQA) task, such as KoNViD1k and LIVE-Qualcomm, and can only be used for general resolution VQA tasks. These VQA datasets suffer from limitations, including low resolution and restricted scenarios. To address these issues, we present a novel UHD-VQA dataset, named UHD-VQ5k, which contains 5500 video clips, each 10 s in duration, with a resolution of 3840 × 2160 and a frame rate of 30 frames per second. Moreover, we provide strict expert ratings for each video in accordance with the ITU-R BT.500-13 standard. In addition, for the task of VQA, we propose a Hybrid Resformer Video Quality Assessment (HR-VQA) Network. The network consists of two branches, IQA and VQA, to take both video frames and video segments as inputs. In the IQA branch, features are extracted using a Resformer architecture, which including two parallel components: ResNet50 and ViT (Vision Transformer). These two components are connected through the Bidirectional Local Global Interaction module. And in the VQA branch, video segment quality is evaluated by extracting features with Swin-3D (Video Swin Transformer). The scores from both branches are individually regressed and combined through ensemble learning to obtain the ultimate video quality score. Furthermore, we introduce a “Usability Rate (UR)” metric that further enhances the accuracy of individual video predictions. Through experimental validation, our algorithm not only achieves state-of-the-art (SOTA) performance on the UHD-VQ5k dataset but also demonstrates promising results on the KONVID1k dataset and the preliminary dataset of the NAIC2023 Challenge. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Ultrahigh-definition
ER  -

TY  - JOUR
AU  - Luo, Q.
AU  - He, S.
AU  - Han, X.
AU  - Wang, Y.
AU  - Li, H.
TI  - LSTTN: A Long-Short Term Transformer-based spatiotemporal neural network for traffic flow forecasting
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 293
C7  - 111637
DO  - 10.1016/j.knosys.2024.111637
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188837810&doi=10.1016%2fj.knosys.2024.111637&partnerID=40&md5=b67b86957886eba930cf671afcaf4a7a
AB  - Accurate traffic forecasting is a fundamental problem in intelligent transportation systems and learning long-range traffic representations with key information through spatiotemporal graph neural networks (STGNNs) is a basic assumption of current traffic flow prediction models. However, due to structural limitations, existing STGNNs can only utilize short-range traffic flow data; therefore, the models cannot adequately learn the complex trends and periodic features in traffic flow. Besides, it is challenging to extract the key temporal information from the long historical traffic series and obtain a compact representation. To solve the above problems, we propose a novel LSTTN (Long-Short Term Transformer-based Network) framework comprehensively considering the long- and short-term features in historical traffic flow. First, we employ a masked subseries Transformer to infer the content of masked subseries from a small portion of unmasked subseries and their temporal context in a pretraining manner, forcing the model to efficiently learn compressed and contextual subseries temporal representations from long historical series. Then, based on the learned representations, long-term trend is extracted by using stacked 1D dilated convolution layers, and periodic features are extracted by dynamic graph convolution layers. For the difficulties in making time-step level prediction, LSTTN adopts a short-term trend extractor to learn fine-grained short-term temporal features. Finally, LSTTN fuses the long-term trend, periodic features and short-term features to obtain the prediction results. Experiments on four real-world datasets show that in 60-minute-ahead long-term forecasting, the LSTTN model achieves a minimum improvement of 5.63% and a maximum improvement of 16.78% over baseline models. The source code is availble at https://github.com/GeoX-Lab/LSTTN. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; FMS:C; 
LB  - Luo2024LSTTN
ER  -

TY  - JOUR
AU  - Murhij, Y.
AU  - Yudin, D.
TI  - OFMPNet: Deep end-to-end model for occupancy and flow prediction in urban environment
PY  - 2024
T2  - Neurocomputing
VL  - 586
C7  - 127649
DO  - 10.1016/j.neucom.2024.127649
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189747106&doi=10.1016%2fj.neucom.2024.127649&partnerID=40&md5=dd50f2115e924783259962a57e0791a8
AB  - The task of motion prediction is pivotal for autonomous driving systems, providing crucial data to choose a vehicle behavior strategy within its surroundings. Existing motion prediction techniques primarily focus on predicting the future trajectory of each agent in the scene individually, utilizing its past trajectory data. In this paper, we introduce an end-to-end neural network methodology designed to predict the future behaviors of all dynamic objects in the environment. This approach leverages the occupancy map and the scene's motion flow. We are investigating various alternatives for constructing a deep encoder–decoder model called OFMPNet. This model uses a sequence of bird's-eye-view road images, occupancy grid, and prior motion flow as input data. The encoder of the model can incorporate transformer, attention-based, or convolutional units. The decoder considers the use of both convolutional modules and recurrent blocks. Additionally, we propose a novel time-weighted motion flow loss, whose application has shown a substantial decrease in end-point error. Our approach has achieved state-of-the-art results on the Waymo Occupancy and Flow Prediction benchmark, with a Soft IoU of 52.1% and an AUC of 76.75% on Flow-Grounded Occupancy. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Murhij2024OFMPNet
ER  -

TY  - JOUR
AU  - Zheng, Y.
AU  - Wang, C.
AU  - Huang, C.
AU  - Li, K.
AU  - Yang, J.
AU  - Xie, N.
AU  - Liu, B.
AU  - Zhang, Y.
TI  - Hierarchical spatial–temporal autocorrelation graph neural network for online wind turbine pitch system fault detection
PY  - 2024
T2  - Neurocomputing
VL  - 586
C7  - 127574
DO  - 10.1016/j.neucom.2024.127574
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190724938&doi=10.1016%2fj.neucom.2024.127574&partnerID=40&md5=f059d88a574eb165a9b4a91eea87a582
AB  - The advancement of low-cost, non-manually labeled big data technologies for fault detection in wind turbines is crucial to guarantee their safe and efficient operation. In this context, Normal Behavior Modelling (NBM) is a prevalent approach. However, existing NBM methods for wind turbine fault detection inadequately utilize complex spatial–temporal correlations within the Supervisory Control and Data Acquisition (SCADA) during the normal behavior prediction stage. To cope with this limitation, this paper propose a hierarchical spatial-temporal autocorrelation graph neural network method for online wind turbine pitch system fault detection. This approach integrates a dynamic graph network with an adaptive structure for spatial correlation learning and a transformer model with autocorrelation attention to identify periodic time-distance correlations. Furthermore, a hierarchical neural network, specifically designed for wind turbine physical structure, enhances local information extraction through seven latent graph neural networks and a probsparse attention mechanism. The proposed method demonstrates significant effectiveness in real-world applications, as evidenced by data from a Shanghai wind farm. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zheng2024Hierarchical
ER  -

TY  - JOUR
AU  - Gupta, V.
AU  - Yadav, A.
AU  - Vishwakarma, D.K.
TI  - HumanPoseNet: An all-transformer architecture for pose estimation with efficient patch expansion and attentional feature refinement
PY  - 2024
T2  - Expert Systems with Applications
VL  - 244
C7  - 122894
DO  - 10.1016/j.eswa.2023.122894
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180534028&doi=10.1016%2fj.eswa.2023.122894&partnerID=40&md5=851ffb4c89827a9ccbd7775dba5bafae
AB  - Human pose estimation from images is an exceedingly challenging task due to occlusion, blur, illumination, and size variations. Several research works have addressed this problem by designing novel encoders that extract discriminative features from input images. However, the design of decoders is an understudied problem as most approaches use the conventional transposed convolution for feature upsampling. In this paper, we propose a novel transformer-based pose estimation architecture, HumanPoseNet with a novel decoder design. The encoder is a transformer with dual-attention for highlighting important spatial and channel regions. The decoder contains a novel Patch Expansion module for feature upsampling which is computationally more efficient than the traditional transpose convolution. The decoder also contains an Attentional Feature Refinement Block that is integrated with the attention mechanism to extract refined features. Extensive experiments conducted on the MS COCO benchmark dataset proves that HumanPoseNet beats other state-of-the-art models, achieving an average precision (AP) score of 77.3. A qualitative analysis is conducted and the results prove that HumanPoseNet is able to predict accurate pose keypoints, even in occluded/blurred images. An ablation study is done to verify the complementary contributions of Patch Expansion and Attentional Feature Refinement Module. HumanPoseNet is easy to train as the model converges swiftly in merely 50 epochs while existing state-of-the-art methods are usually trained for 200 epochs or more. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Gupta2024HumanPoseNet
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Li, B.
AU  - Su, S.-F.
AU  - Yang, W.
AU  - Xie, L.
TI  - A Novel Hybrid Transformer-Based Framework for Solar Irradiance Forecasting under Incomplete Data Scenarios
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 6
SP  - 8605
EP  - 8615
DO  - 10.1109/TII.2024.3369671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188664899&doi=10.1109%2fTII.2024.3369671&partnerID=40&md5=8c8272a2709684644446a639f3c9c75a
AB  - Accurate prediction of solar irradiance is crucial for the effective utilization of solar energy. However, in real-world scenarios, complex irradiance patterns and prevalent incomplete data pose challenges to precise forecasting, resulting in additional uncertainties and instability. To address these issues, this study proposes a novel irradiance forecasting model that integrates a Mask-Transformer data imputation module and a prediction module centered around the typical patterns representation mechanism. The Mask-Transformer leverages a mask modeling mechanism to model the context of missing data, facilitating accurate estimation of missing values and reducing noise and uncertainty in the input data. The typical patterns representation mechanism comprises a series decomposition module and a feature fusion module, providing the module with the capability to mitigate nonlinearity and nonstationarity in solar irradiance data. This enhancement leads to improved short-term forecasting performance while maintaining long-term forecasting capabilities. Experimental results on two datasets demonstrate that the proposed model exhibits sufficient robustness and accuracy, making it effective in scenarios with incomplete data.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Zhang2024Novel
ER  -

TY  - JOUR
AU  - Liu, E.
AU  - He, B.
AU  - Zhu, D.
AU  - Chen, Y.
AU  - Xu, Z.
TI  - Tiny polyp detection from endoscopic video frames using vision transformers
PY  - 2024
T2  - Pattern Analysis and Applications
VL  - 27
IS  - 2
C7  - 38
DO  - 10.1007/s10044-024-01254-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189948075&doi=10.1007%2fs10044-024-01254-3&partnerID=40&md5=07d473d08bbfb5217ffbaac94f4fbd3f
AB  - Deep learning techniques can be effective in helping doctors diagnose gastrointestinal polyps. Currently, processing video frame sequences containing a large amount of spurious noise in polyp detection suffers from elevated recall and mean average precision. Moreover, the mean average precision is also low when the polyp target in the video frame has large-scale variability. Therefore, we propose a tiny polyp detection from endoscopic video frames using Vision Transformers, named TPolyp. The proposed method uses a cross-stage Swin Transformer as a multi-scale feature extractor to extract deep feature representations of data samples, improves the bidirectional sampling feature pyramid, and integrates the prediction heads of multiple channel self-attention mechanisms. This approach focuses more on the feature information of the tiny object detection task than convolutional neural networks and retains relatively deeper semantic information. It additionally improves feature expression and discriminability without increasing the computational complexity. Experimental results show that TPolyp improves detection accuracy by 7%, recall by 7.3%, and average accuracy by 7.5% compared to the YOLOv5 model, and has better tiny object detection in scenarios with blurry artifacts. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Liu2024Tiny
ER  -

TY  - JOUR
AU  - Zhao, P.
AU  - Hu, W.
AU  - Cao, D.
AU  - Zhang, Z.
AU  - Huang, Y.
AU  - Dai, L.
AU  - Chen, Z.
TI  - Probabilistic Multienergy Load Forecasting Based on Hybrid Attention-Enabled Transformer Network and Gaussian Process-Aided Residual Learning
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 6
SP  - 8379
EP  - 8393
DO  - 10.1109/TII.2024.3366946
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188675315&doi=10.1109%2fTII.2024.3366946&partnerID=40&md5=01f6d7d4225560270aad5206bc0e4344
AB  - Precise multienergy load forecasting (MELF) significantly contributes to the stable and economic operation of integrated energy systems (IES). However, existing MELF approaches exhibit three primary limitations: (i) naively aggregate all input features without explicit mechanisms to capture complex coupling relationships between multiple energy loads; (ii) incapable of fully exploiting the local load characteristics of each individual task; (iii) provide only deterministic forecasting results. To address these limitations, in this article, we propose a global-local probabilistic multi-energy load forecasting framework based on hybrid attention mechanism-enabled Transformer (HAT) network and sparse variational Gaussian process (SVGP)-aided residual learning method. Specifically, HAT is first utilized to capture the consumption behavior of the multi-energy loads. It employs a temporal attention module to extract the load patterns of each task and a task attention module to explicitly capture the coupling relationships between different tasks. The multiple pieces of information are fused through a gated fusion unit for the joint predictions of multiple loads. Then, an SVGP with a composite kernel is adopted to learn the local load characteristics specific to each individual task by modeling the residual of the forecasting outcomes. This further enhances the performance of the proposed method and allows us to achieve effective quantification of the forecasting uncertainties. Numerical simulations using real IES load data reveal that the proposed framework outperforms state-of-the-art deterministic load forecasting by 11% at least in mean absolute percentage error (MAPE) and probabilistic load forecasting by 5% at least in both pinball loss and Winkler score metrics.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zhao2024Probabilistic
ER  -

TY  - JOUR
AU  - Xiang, S.
AU  - Li, N.
AU  - Wang, Y.
AU  - Zhou, S.
AU  - Wei, J.
AU  - Li, S.
TI  - Automatic Delineation of the 3D Left Atrium from LGE-MRI: Actor-Critic Based Detection and Semi-Supervised Segmentation
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 6
SP  - 3545
EP  - 3556
DO  - 10.1109/JBHI.2024.3373127
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187321834&doi=10.1109%2fJBHI.2024.3373127&partnerID=40&md5=a72b4adc147ab4bf99e86270ab1a91cf
AB  - Accurate and automatic delineation of the left atrium (LA) is crucial for computer-aided diagnosis of atrial fibrillation-related diseases. However, effective model training typically requires a large amount of labeled data, which is time-consuming and labor-intensive. In this study, we propose a novel LA delineation framework. The region of LA is first detected using an actor-critic based deep reinforcement learning method with a shape-adaptive detection strategy using only box-level annotations, bypassing the need for voxel-level labeling. With the effectively detected LA, the impacts of class-imbalance and interference from surrounding tissues are significantly reduced. Subsequently, a semi-supervised segmentation scheme is coined to precisely delineate the contour of LA in 3D volume. The scheme integrates two independent networks with distinct structures, enabling implicit consistency regularization, capturing more spatial features, and avoiding the error accumulation present in current mainstream semi-supervised frameworks. Specifically, one network is combined with Transformer to capture latent spatial features, while the other network is based on pure CNN to capture local features. The difference prediction between these two sub-networks is exploited to mutually provide high-quality pseudo-labels and correct the cognitive bias. Experimental results on two public datasets demonstrate that our proposed strategy outperforms several state-of-the-art methods in terms of accuracy and clinical convenience.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Xiang2024Automatic
ER  -

TY  - JOUR
AU  - Qian, W.
AU  - Guo, D.
AU  - Li, K.
AU  - Zhang, X.
AU  - Tian, X.
AU  - Yang, X.
AU  - Wang, M.
TI  - Dual-Path TokenLearner for Remote Photoplethysmography-Based Physiological Measurement With Facial Videos
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 3
SP  - 4465
EP  - 4477
DO  - 10.1109/TCSS.2024.3356713
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186964150&doi=10.1109%2fTCSS.2024.3356713&partnerID=40&md5=03480946834a83d0373db2e3902edc91
AB  - Remote photoplethysmography (rPPG)-based physiological measurement is an emerging yet crucial vision task, whose challenge lies in exploring accurate rPPG prediction from facial videos accompanied by noises of illumination variations, facial occlusions, head movements, etc., in a noncontact manner. Existing mainstream convolutional neural network (CNN)-based models make efforts to detect physiological signals by capturing subtle color changes in facial regions of interest (ROI) caused by heartbeats. However, such models are constrained by the limited local spatial or temporal receptive fields in the neural units. Unlike them, a native transformer-based framework called dual-path TokenLearner (dual-TL) is proposed in this article, which utilizes the concept of learnable tokens to integrate both spatial and temporal informative contexts from the global perspective of the video. Specifically, the proposed dual-TL uses a spatial TokenLearner (S-TL) to explore associations in different facial ROIs, which promises the rPPG prediction far away from noisy ROI disturbances. Complementarily, a temporal TokenLearner (T-TL) is designed to infer the quasi-periodic pattern of heartbeats, which eliminates temporal disturbances such as head movements. The two TokenLearners, S-TL and T-TL, are executed in a dual-path mode. This enables the model to reduce noise disturbances for final rPPG signal prediction. Extensive experiments on four physiological measurement benchmark datasets are conducted. The dual-TL achieves state-of-the-art performances in both intra and cross-dataset testings, demonstrating its immense potential as a basic backbone for rPPG measurement.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Qian2024Dual-Path
ER  -

TY  - JOUR
AU  - Zhai, R.
AU  - Zheng, J.
AU  - Song, Z.
AU  - Ge, Z.
TI  - Reliable Soft Sensors with an Inherent Process Graph Constraint
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 6
SP  - 8798
EP  - 8806
DO  - 10.1109/TII.2024.3372013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189311015&doi=10.1109%2fTII.2024.3372013&partnerID=40&md5=e7e521e8de2870795b10a7044b6b787a
AB  - Nowadays, data-driven models have been prevalent in predicting hard-to-measure key quality indicators of industrial processes in order to improve product quality and process safety. Such models are called soft sensors as they can serve the same role as physical sensors, but they do not require extra physical devices. Despite their success, soft sensors suffer from poor reliability. Reliability is the ability of soft sensors to give accurate predictions not only at the time they are trained, but also in the long term, despite potential drifts of the process. This is important when soft sensors are to be applied in critical industrial processes. In order to alleviate this problem, in this article, we propose a graph-constrained soft-sensor (GCSS) model that uses graph convolutions based on the a priori undirected graph of the process variables. Based on the modern control theory, we also propose an approach to extracting an undirected graph from process diagrams of the target process. This approach can identify relationships between process variables, which is easy to use and can be applied to a majority of industrial processes. The extracted graph structure serves as a constraint, and pushes the data-driven GCSS model into the direction of the true inner structure of the target process. With the aid of a priori graph knowledge, the GCSS model enjoys better generalizability and reliability. This has been validated in a simulation example and a real-world high-low transformer process. Compared to other soft sensors, the test performance of the GCSS model is improved by 6.5%. In the high-low transformer process, the GCSS model has the best test performance and the gap between training and test performance is reduced by 54%.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhai2024Reliable
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Li, S.
AU  - Li, D.
AU  - Zhu, J.
AU  - Guan, Q.
TI  - Transformer-Based Predictive Beamforming for Integrated Sensing and Communication in Vehicular Networks
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 11
SP  - 20690
EP  - 20705
DO  - 10.1109/JIOT.2024.3372060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186963229&doi=10.1109%2fJIOT.2024.3372060&partnerID=40&md5=44656233c615b1f7080c3056d18fbbc5
AB  - Against the backdrop of the increasingly scarce spectrum, the integrated sensing and communication (ISAC) is emerging as a promising technology to enable simultaneous sensing and communication between vehicles and their surroundings in the vehicular networks. However, to realize ISAC, an effective beamforming design is essential. Motivated by this, this work investigates the beamforming scheme for ISAC-based vehicular networks and a Transformer-based predictive beamforming approach is proposed. In details, a novel transmission protocol is developed to bypass the need for the roadside unit (RSU) to acquire channel state information (CSI) and historical channel parameters. It can establishes a direct relationship between the signal echoes and beamforming matrix in data-driven manner to reduce the signaling overhead. Then, an optimization problem maximizing the communication sum rate is formulated to design the optimal beamforming scheme. Due to the nonconvex nature of the objective function and constraints, a penalty-based method is exploited to transform it to an unconstrained optimization problem and the echoes-based convolution Transformer network (ECT-Net) is proposed to solve it. As a realization of the ECT-Net, the convolutional module and attention mechanism are integrated to jointly capture the reflected echoes' local and global spatial dependencies, improving the performance of predictive beamforming. Extensive simulations are carried out and show that the proposed Transformer-based predictive beamforming method can achieve higher communication sum rate than state-of-the-art beamforming methods.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhang2024Transformer-Based
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - He, K.
AU  - Xu, D.
AU  - Shi, H.
AU  - Zhang, H.
AU  - Zhao, K.
TI  - RegFSC-Net: Medical Image Registration via Fourier Transform with Spatial Reorganization and Channel Refinement Network
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 6
SP  - 3489
EP  - 3500
DO  - 10.1109/JBHI.2024.3376334
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188689641&doi=10.1109%2fJBHI.2024.3376334&partnerID=40&md5=9300700f2e4b8a4dfbc1ab166c1bc7ca
AB  - Medical image registration is crucial in medical image analysis applications. Recently, U-Net-style networks have been commonly used for unsupervised image registration, predicting dense displacement fields in full-resolution space. However, this process is resource-intensive and time-consuming for high-resolution volumetric image data. To address this challenge, this paper proposes a novel model named RegFSC-Net, which utilizes Fourier transform with spatial reorganization (SR) and channel refinement (CR) network for registration. We embed efficient feature extraction modules SR and CR modules into the encoder, and adopt a parameter-free model to drive the decoder to improve the U-shaped network. Precisely, RegFSC-Net does not directly predict the full-resolution displacement field in space but learns the low-dimensional representation of the displacement field in the bandlimited Fourier domain, which is beneficial in reducing network parameters, memory usage, and computational costs. Experimental results show that RegFSC-Net outperforms various state-of-the-art methods. Specifically, in comparison to the widely recognized Transformer-based method TransMorph, RegFSC-Net utilizes only around 8.2% of its parameters, resulting in a 1.95% higher Dice score and significantly faster inference speeds of 126.67% and 419.99% on GPU and CPU, respectively. Furthermore, we also designed three variants of RegFSC-Net and demonstrated their potential applications in computer-aided diagnosis.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2024RegFSC-Net
ER  -

TY  - JOUR
AU  - Yin, Z.
AU  - Du, Y.
AU  - Liu, Y.
AU  - Wang, Y.
TI  - Multi-layer cross-modality attention fusion network for multimodal sentiment analysis
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 21
SP  - 60171
EP  - 60187
DO  - 10.1007/s11042-023-17685-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181480466&doi=10.1007%2fs11042-023-17685-9&partnerID=40&md5=f744117710fa39df8cebd0842d3a5f6a
AB  - Sentiment analysis aims to detect the sentiment polarity towards the massive opinions and reviews emerging on the internet. With the increasing of multimodal information on social media, such as text, image, audio and video, multimodal sentiment analysis has attracted more attention in recent years and our work focuses on the text and image data. The previous works usually ignore the semantic alignment between the text and image, and cannot capture the interaction between them, which will affect the correct judgement for the sentiment polarity prediction. To resolve these problems, we propose a novel multimodal sentiment analysis model LXMERT-MMSA based on cross-modality attention mechanism. The single-modality feature is encoded by multi-layer Transformer encoder to achieve the deep semantic information implied in the text and image. Moreover, the cross-modality attention mechanism enables the model to fuse the text and image features effectively and achieve the rich semantic information by the alignment. It improves the ability of the model to capture the semantic relation between text and image. The evaluation metrics of accuracy and F1 score are used, and the experimental results on MVSA-multiple dataset and Twitter dataset show that our proposed model outperforms the previous SOTA model, and the ablation experimental results further prove that the model can make well use of multimodal features. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Yin2024Multi-layer
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Meng, Z.
TI  - Interpretable vision transformer based on prototype parts for COVID-19 detection
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 7
SP  - 1927
EP  - 1937
DO  - 10.1049/ipr2.13074
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188077584&doi=10.1049%2fipr2.13074&partnerID=40&md5=400be143699f3c8f1bce08dc4ace8189
AB  - Over the past few years, the COVID-19 virus has had a significant impact on the physical and mental health of people around the world. Therefore, in order to effectively distinguish COVID-19 patients, many deep learning efforts have used chest medical images to detect COVID-19. As with model accuracy, interpretability is also important in the work related to human health. This work introduces an interpretable vision transformer that uses the prototype method for the detection of positive patients with COVID-19. The model can learn the prototype features of each category based on the structural characteristics of ViT. The predictions of the model are obtained by comparing all the features of the prototype in the designed prototype block. The proposed model was applied to two chest X-ray datasets and one chest CT dataset, achieving classification performance of 99.3%, 96.8%, and 98.5% respectively. Moreover, the prototype method can significantly improve the interpretability of the model. The decisions of the model can be interpreted based on prototype parts. In the prototype block, the entire inference process of the model can be shown and the predictions of the model can be demonstrated to be meaningful through the visualization of the prototype features. © 2024 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Xu2024Interpretable
ER  -

TY  - JOUR
AU  - Xiang, L.
AU  - Yin, H.
TI  - Feature-enhanced representation with transformers for multi-view stereo
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 6
SP  - 1530
EP  - 1539
DO  - 10.1049/ipr2.13046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186947626&doi=10.1049%2fipr2.13046&partnerID=40&md5=35853aff9fc8d7c03eb9650e7ef5e274
AB  - Most existing multi-view stereo (MVS) methods fail to consider global context information in the stage of feature extraction and cost aggregation. As transformers have shown remarkable performance on various vision tasks due to their ability to perceive global contextual information, this paper proposes a transformer-based feature enhancement network (TF-MVSNet) to facilitate feature representation learning by combining local features (both 2D and 3D) with long-range contextual information. To reduce memory consumption of feature matching, the cross-attention mechanism is leveraged to efficiently construct 3D cost volumes under the epipolar constraint. Additionally, a colour-guided network is designed to refine depth maps at a coarse stage, hence reducing incorrect depth predictions at a fine stage. Extensive experiments were performed on the DTU dataset and Tanks and Temples (T&T) benchmark and results are reported. © 2024 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xiang2024Feature-enhanced
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Ding, F.
AU  - Wang, Z.
AU  - Xiao, F.
AU  - Lu, C.X.
AU  - Huang, X.
TI  - Forecasting backdraft with multimodal method: Fusion of fire image and sensor data
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 132
C7  - 107939
DO  - 10.1016/j.engappai.2024.107939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183454251&doi=10.1016%2fj.engappai.2024.107939&partnerID=40&md5=85da2062392f7c2e308603ef04844042
AB  - Experienced firefighters can fuse the flame image, smoke pattern, and varying temperature, sound, and odour in complex and fast-changing fire scenes to foresee flashover and explosion. This study mimics firefighters and proposes a novel transformer algorithm for the fusion of fire images and temperature sensor data to forecast the backdraft explosion in a building fire. The model of backdraft forecast is demonstrated with full-scale fire tests. After training 2674 fire scenarios with various fire intensities and images from various view angles, the Fusion-Transformer model can forecast the risk of backdraft with an overall accuracy of 84%. Moreover, the occurrence time and explosion scale of backdraft can be predicted with the Mean Absolute Error (MAE) of 1.6 s and 0.14 m, respectively. Compared with the single modal model, the fusion of fire images and temperature sensor data improves the accuracy of backdraft forecast by over 50%. This work demonstrates the use of a transformer algorithm in forecasting fire evolution and critical events. It also bridges the gap between data fusion methods and fire forecast, which inspires future universal AI-driven smart firefighting practices. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zhang2024Forecasting
ER  -

TY  - JOUR
AU  - Yang, C.
AU  - Wang, Y.
AU  - Yang, B.
AU  - Chen, J.
TI  - GRAformer: A gated residual attention transformer for multivariate time series forecasting
PY  - 2024
T2  - Neurocomputing
VL  - 581
C7  - 127466
DO  - 10.1016/j.neucom.2024.127466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187215002&doi=10.1016%2fj.neucom.2024.127466&partnerID=40&md5=67c12aa2a4b787935586ed3ad04c70b2
AB  - Recurrent Neural Networks (RNNs), particularly when equipped with output windows – a standard practice in contemporary time series forecasting – have shown proficiency in handling short-term dependencies. Nonetheless, RNNs can encounter challenges in maintaining hidden states over extended forecasting periods, particularly in longer-term predictions where increased hidden state sizes and extended look-back windows can lead to gradient instability. In contrast, Transformer-based models, with their distinctive architecture designed to encode complex contextual relationships and enable computations to be done in parallel, are emerging as a popular alternative in this field. However, current research has mainly focused on modifying attention mechanisms, overlooking opportunities to improve the feedforward layer, which could lead to efficiency limitations. Moreover, prevailing methods often assume absolute independence between channels, disregarding distinct features among variables and failing to fully leverage channel-specific information. To address these gaps, we propose an efficient transformer design for multivariate time series prediction. Our approach integrates two key components: (i) a gated residual attention unit that enhances predictive accuracy and computational efficiency, and (ii) a channel embedding technique that differentiates between series and boosts performance. Theoretically, we prove that our model has recurrent dynamics introduced by the RNN layer. Through extensive experiments on real-world data, we demonstrate that our proposed method achieves competitive predictive accuracy compared to prior approaches while exhibiting accelerated processing relative to state-of-the-art transformers. Our code, data, and trained models are available at https://github.com/MythosAd/GRAformer. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Yang2024GRAformer
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Wang, C.
AU  - Qiu, M.
AU  - Chen, C.
AU  - Gao, M.
AU  - Zhou, A.
TI  - Accelerating BERT inference with GPU-efficient exit prediction
PY  - 2024
T2  - Frontiers of Computer Science
VL  - 18
IS  - 3
C7  - 183308
DO  - 10.1007/s11704-022-2341-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182849003&doi=10.1007%2fs11704-022-2341-9&partnerID=40&md5=0414efcb19cbb22a65c4e731b303ba9a
AB  - BERT is a representative pre-trained language model that has drawn extensive attention for significant improvements in downstream Natural Language Processing (NLP) tasks. The complex architecture and massive parameters bring BERT competitive performance but also result in slow speed at model inference time. To speed up BERT inference, FastBERT realizes adaptive inference with an acceptable drop in accuracy based on knowledge distillation and the early-exit technique. However, many factors may limit the performance of FastBERT, such as the teacher classifier that is not knowledgeable enough, the batch size shrinkage and the redundant computation of student classifiers. To overcome these limitations, we propose a new BERT inference method with GPU-Efficient Exit Prediction (GEEP). GEEP leverages the shared exit loss to simplify the training process of FastBERT from two steps into only one step and makes the teacher classifier more knowledgeable by feeding diverse Transformer outputs to the teacher classifier. In addition, the exit layer prediction technique is proposed to utilize a GPU hash table to handle the token-level exit layer distribution and to sort test samples by predicted exit layers. In this way, GEEP can avoid batch size shrinkage and redundant computation of student classifiers. Experimental results on twelve public English and Chinese NLP datasets prove the effectiveness of the proposed approach. The source codes of GEEP will be released to the public upon paper acceptance. © 2024, Higher Education Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Li2024Accelerating
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Zhang, C.
AU  - Liu, L.
AU  - Zhang, X.
TI  - Gated Transient Fluctuation Dual Attention Unit Network for Long-Term Remaining Useful Life Prediction of Rotating Machinery Using IIoT
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 10
SP  - 18593
EP  - 18604
DO  - 10.1109/JIOT.2024.3363837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187263243&doi=10.1109%2fJIOT.2024.3363837&partnerID=40&md5=72296ac5325f285910aba4a9ea4ece89
AB  - The Industrial Internet of Things (IIoT) has greatly facilitated the development of prognostics health management (PHM) for rotating machinery. In the era of IIoT, the long-term prediction of remaining useful life (RUL) can provide a reliable basis for maintenance decisions of rotating machinery. However, most existing RUL prediction methods neglect to learn the transient fluctuation information in the health indicator (HI), which leads to low long-term prediction accuracy. Therefore, a new gated transient fluctuation dual attention unit (GTFDAU) network is designed to achieve sufficient learning of transient fluctuation information, which can improve long-term prediction accuracy. The GTFDAU network mainly comprises three novel gate structures: 1) transient fluctuation gate; 2) historical attention gate; and 3) current attention gate. The transient fluctuation gate is used to capture transient fluctuation information, which can deeply mine the historical information. The historical attention gate is used to adaptively focus on transient fluctuation information and the hidden state of the last moment, which can effectively reshape the historical information. The current attention gate is used to adaptively focus on historical information and current input information, which can comprehensively update the current hidden state. The proposed method has superior long-term prediction capability compared to existing state-of-the-art methods without compromising short-term prediction performance through experimental verification of RUL for rolling bearings and fatigue gears.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Li2024Gated
ER  -

TY  - JOUR
AU  - Das, S.
AU  - Singh, A.
AU  - Saha, S.
AU  - Maurya, A.
TI  - Negative Review or Complaint? Exploring Interpretability in Financial Complaints
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 3
SP  - 3606
EP  - 3615
DO  - 10.1109/TCSS.2023.3338357
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181568133&doi=10.1109%2fTCSS.2023.3338357&partnerID=40&md5=2e9a3f5c15325729dc36784579322fd9
AB  - In the financial service sector, customer service is the most critical tool for long-term business growth. A financial complaint detection (CD) system could aid in the identification of shortcomings in product features and service delivery. This could further ensure faster resolution of customer complaints and thereby help retain existing clients and attract new ones. Prior research has prioritized only complaint identification and prediction of the corresponding severity levels; the first aim is to categorize a textual element as a complaint or a noncompliant. The other attempts to classify complaints into several severity levels based on the degree of risk the complainant is willing to endure. Identifying the reason or source of a complaint in a text is a significant but underexplored area in natural language processing study. We propose an explainable complaint cause identification approach with a dyadic attention mechanism at the sentence and word levels, enabling it to give varying amounts of emphasis to more and less important information. As the first subtask, the model simultaneously trains CD, sentiment detection, and emotion recognition tasks. Afterwards, we identify the complaint's cause and its severity level. To do this, the causal span annotations for complaint tweets are added to an existing financial complaints corpus. The findings suggest that conventional computing techniques can be adapted to solve extremely relevant new problems, generating novel opportunities for research11The code and dataset are available at https://github.com/sarmistha-D/Complaint-HaN.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Das2024Negative
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Meng, L.
AU  - Gu, Y.
TI  - SageFormer: Series-Aware Framework for Long-Term Multivariate Time-Series Forecasting
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 10
SP  - 18435
EP  - 18448
DO  - 10.1109/JIOT.2024.3363451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184810053&doi=10.1109%2fJIOT.2024.3363451&partnerID=40&md5=656f71eeadbf84359196f781f5a8acc9
AB  - In the burgeoning ecosystem of Internet of Things, multivariate time-series (MTS) data has become ubiquitous, highlighting the fundamental role of time-series forecasting across numerous applications. The crucial challenge of long-term MTS forecasting requires adept models capable of capturing both intra- and inter-series dependencies. Recent advancements in deep learning, notably Transformers, have shown promise. However, many prevailing methods either marginalize interseries dependencies or overlook them entirely. To bridge this gap, this article introduces a novel series-aware framework, explicitly designed to emphasize the significance of such dependencies. At the heart of this framework lies our specific implementation: the SageFormer. As a series-aware graph-enhanced Transformer model, SageFormer proficiently discerns and models the intricate relationships between series using graph structures. Beyond capturing diverse temporal patterns, it also curtails redundant information across series. Notably, the series-aware framework seamlessly integrates with existing Transformer-based models, enriching their ability to comprehend interseries relationships. Extensive experiments on real-world and synthetic data sets validate the superior performance of SageFormer against contemporary state-of-the-art approaches.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhang2024SageFormer
ER  -

TY  - JOUR
AU  - Shen, X.
AU  - Huang, X.
AU  - Zou, S.
AU  - Gan, X.
TI  - Multimodal Knowledge-enhanced Interactive Network with Mixed Contrastive Learning for Emotion Recognition in Conversation
PY  - 2024
T2  - Neurocomputing
VL  - 582
C7  - 127550
DO  - 10.1016/j.neucom.2024.127550
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188641847&doi=10.1016%2fj.neucom.2024.127550&partnerID=40&md5=f050a1c1a90821c5f7a8b47ccd49634d
AB  - Emotion Recognition in Conversations (ERC) aims to accurately identify the emotional labels of each utterance in a conversation, holding significant application value in human–computer interaction. Existing research suggests introducing commonsense knowledge (CSK) and multimodal information enhances model performance in ERC tasks. However, several challenges persist: (1) the neglect of complex psychological influences between utterances; (2) noise issues within modal information; (3) prediction challenges for emotion labels with few samples in different categories that exhibit semantic similarity but distinct emotional categories. To address the above problems, we propose a Multimodal Knowledge-enhanced Interactive Network with Mixed Contrastive Learning (MKIN-MCL). Firstly, we establish a knowledge aggregation graph to capture the dependencies of commonsense knowledge (CSK) between utterances during a conversation. We actively aggregate relevant knowledge information to enhance text features. Simultaneously, we apply feature filters for acoustic and visual modalities to eliminate noise and enhance feature quality. Furthermore, we implement an interactive attention module by stacking designed Cross-modal Interactive Transformers (CITs) to continuously explore the relevance between the interacting parties in their respective semantic spaces, thus improving the effectiveness of modality interaction while reducing noise generated during the interaction. Lastly, we employ the Mixed Contrastive Learning (MCL) strategy to enhance the model's ability to handle few-shot labels. This strategy utilizes unsupervised contrastive learning to improve the representation capability of the multimodal fusion features and supervised contrastive learning to extract information from few-shot labels. Extensive experiments on two benchmark datasets, IEMOCAP and MELD, validate the effectiveness and superiority of the proposed model. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Shen2024Multimodal
ER  -

TY  - JOUR
AU  - Dou, R.
AU  - Li, J.
AU  - Wan, X.
AU  - Chang, H.
AU  - Zheng, H.
AU  - Gao, G.
TI  - A Decoder Structure Guided CNN-Transformer Network for face super-resolution
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 4
SP  - 473
EP  - 484
DO  - 10.1049/cvi2.12251
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177571417&doi=10.1049%2fcvi2.12251&partnerID=40&md5=7a541f540b30c235939951043a8799fd
AB  - Recent advances in deep convolutional neural networks have shown improved performance in face super-resolution through joint training with other tasks such as face analysis and landmark prediction. However, these methods have certain limitations. One major limitation is the requirement for manual marking information on the dataset for multi-task joint learning. This additional marking process increases the computational cost of the network model. Additionally, since prior information is often estimated from low-quality faces, the obtained guidance information tends to be inaccurate. To address these challenges, a novel Decoder Structure Guided CNN-Transformer Network (DCTNet) is introduced, which utilises the newly proposed Global-Local Feature Extraction Unit (GLFEU) for effective embedding. Specifically, the proposed GLFEU is composed of an attention branch and a Transformer branch, to simultaneously restore global facial structure and local texture details. Additionally, a Multi-Stage Feature Fusion Module is incorporated to fuse features from different network stages, further improving the quality of the restored face images. Compared with previous methods, DCTNet improves Peak Signal-to-Noise Ratio by 0.23 and 0.19 dB on the CelebA and Helen datasets, respectively. Experimental results demonstrate that the designed DCTNet offers a simple yet powerful solution to recover detailed facial structures from low-quality images. © 2023 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Dou2024Decoder
ER  -

TY  - JOUR
AU  - Gai, L.
AU  - Xing, M.
AU  - Chen, W.
AU  - Zhang, Y.
AU  - Qiao, X.
TI  - Comparing CNN-based and transformer-based models for identifying lung cancer: which is more effective?
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 20
SP  - 59253
EP  - 59269
DO  - 10.1007/s11042-023-17644-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180244988&doi=10.1007%2fs11042-023-17644-4&partnerID=40&md5=8fc4e1db91b8c541e8aa3a076962cda1
AB  - Lung cancer constitutes the most severe cause of cancer-related mortality. Recent evidence supports that early detection by means of computed tomography (CT) scans significantly reduces mortality rates. Given the remarkable progress of Vision Transformers (ViTs) in the field of computer vision, we have delved into comparing the performance of ViTs versus Convolutional Neural Networks (CNNs) for the automatic identification of lung cancer based on a dataset of 212 medical images. Importantly, neither ViTs nor CNNs require lung nodule annotations to predict the occurrence of cancer. To address the dataset limitations, we have trained both ViTs and CNNs with three advanced techniques: transfer learning, self-supervised learning, and sharpness-aware minimizer. Remarkably, we have found that CNNs achieve highly accurate prediction of a patient’s cancer status, with an outstanding recall (93.4%) and area under the Receiver Operating Characteristic curve (AUC) of 98.1%, when trained with self-supervised learning. Our study demonstrates that both CNNs and ViTs exhibit substantial potential with the three strategies. However, CNNs are more effective than ViTs with the insufficient quantities of dataset. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Gai2024Comparing
ER  -

TY  - JOUR
AU  - Asudani, D.S.
AU  - Nagwani, N.K.
AU  - Singh, P.
TI  - A comparative evaluation of machine learning and deep learning algorithms for question categorization of VQA datasets
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 19
SP  - 57829
EP  - 57859
DO  - 10.1007/s11042-023-17797-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180212462&doi=10.1007%2fs11042-023-17797-2&partnerID=40&md5=57d07b34ae3e7eaba9d775babafe81ae
AB  - Question classification primarily involves categorizing questions based on the type of answer, with less emphasis on the words or phrases used to form the query. Question classification is crucial in the Visual Question Answering (VQA) system, and the dataset’s quality plays an essential role in the system’s development. The available question categorization in the VQA and TDIUC datasets shows imbalance, and the VQA model trained on imbalanced datasets performs poorly in handling language-prior problems, failing to categorize questions, and predicting incorrect outcomes. Therefore, developing a better classification method for classifying questions into appropriate categories based on phrases is necessary. This paper examines the effectiveness of the synthetic minority oversampling technique (SMOTE) in addressing the class imbalance problem within the question classification task using the LSTM, selected machine learning models and BERT-based transformer model. The preprocessing and analysis module efficiently categorizes input question sets by identifying valuable phrases and obtaining an evenly distributed dataset based on question categories from both datasets. The performance evaluation of Naive Bayes, SVM, Random Forests, and XGBoost models shows that the XGBoost model outperforms other selected classifiers, and the LSTM model achieves higher accuracy but requires more computation time. The empirical assessment indicates that the BERT-based transformer model exceeds the traditional models employed for comparison. The ablation study also reveals that utilizing SMOTE techniques for question classification tasks achieves slightly improved accuracy at the expense of higher computation time and resources. It is concluded that the BERT-based transformer model efficiently and precisely performs question classification tasks. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Asudani2024comparative
ER  -

TY  - JOUR
AU  - Wei, M.
AU  - Li, J.
AU  - Kang, H.
AU  - Huang, Y.
AU  - Lu, J.-G.
TI  - BEV-CFKT: A LiDAR-camera cross-modality-interaction fusion and knowledge transfer framework with transformer for BEV 3D object detection
PY  - 2024
T2  - Neurocomputing
VL  - 582
C7  - 127527
DO  - 10.1016/j.neucom.2024.127527
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187954789&doi=10.1016%2fj.neucom.2024.127527&partnerID=40&md5=d3a7fb8ceb224cbdec580d7806aae7f6
AB  - The BEV-CFKT proposed in this paper leverages knowledge transfer through transformers for LiDAR-Camera fusion in the Bird's-Eye-View (BEV) space, aiming to achieve accurate and robust 3D object detection. BEV-CFKT comprises three main components, which include the generation of BEV features from images and point clouds, cross-modality interaction, and hybrid object queries using a monocular detection head. By unifying features from both point clouds and images into the BEV space, we simplify modal interaction, facilitate knowledge transfer, and extract richer structural and semantic information from multimodal data. This effectively enhances the network's performance. To further improve detection performance, BEV-CFKT incorporates a temporal fusion module. Additionally, a hybrid object queries module based on a monocular detection head accelerates the convergence of our model. We demonstrate the effectiveness of our approach through an extensive set of experiments. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wei2024BEV-CFKT
ER  -

TY  - JOUR
AU  - Jiang, K.
AU  - Yang, W.
AU  - Huang, S.
TI  - LaTAS-F: Locality-aware transformer architecture search with multi-source fusion for driver continuous braking intention inference
PY  - 2024
T2  - Expert Systems with Applications
VL  - 242
C7  - 122719
DO  - 10.1016/j.eswa.2023.122719
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179124899&doi=10.1016%2fj.eswa.2023.122719&partnerID=40&md5=7becd1439b7069a53953a07e991a837d
AB  - Precise inference of driver braking intention is highly correlated with traffic safety, energy consumption, and driving comfort of electrified vehicles (EVs). Until recently, gratifying results have been achieved in accurately inferring braking intention as discrete states, such as classify brake or no brake, and judge normal or emergency brake. However, accurately and quantitively predicting driver brake intensity is significant for enhancing vehicle safety, its related research is especially rarely seen. To mitigate this deficiency, a novel framework, locality-aware transformer architecture search with multi-source fusion (LaTAS-F), is put forward for continuous braking intention (CBI) inference in this paper. To consider the comprehensively complicated 'driver-vehicle' interactions, data composed by driver physical state and vehicle state are collected with multi-source sensors. A kernel principal component analysis (KPCA) method is proposed to fuse multi-source data while removing redundancies. In addition, an improved transformer with enhanced locality-aware attention mechanism (ELAM) is elaborately designed to alleviate the incapability of self-attention mechanism (SAM) in canonical transformer when capturing local context. In particular, due to the inefficiency of designing the transformer entirely by hand, a tree-structured parzen estimator (TPE) strategy is implemented to automatically design the most effective and practical model architecture. The performance of LaTAS-F framework is evaluated in various of historical and predicted horizons. Data is collected from 21 subjects, and experimental results demonstrate that our proposed framework can accurately predict CBI of 200 ms in the future, outperforming baselines with RMSE of 0.428 Mpa and R2 of 0.963. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Jiang2024LaTAS-F
ER  -

TY  - JOUR
AU  - Chen, Y.-C.
AU  - Chen, Y.-L.
AU  - Hsu, C.-H.
TI  - G-TransRec: A Transformer-Based Next-Item Recommendation With Time Prediction
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 3
SP  - 4175
EP  - 4188
DO  - 10.1109/TCSS.2024.3354315
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186104368&doi=10.1109%2fTCSS.2024.3354315&partnerID=40&md5=898e66d9afcc999c63631c98a83cb7d8
AB  - Recently, due to the surge in e-commerce, growing attention has been paid to how to recommend a customer's next purchase based on sequential or session-based data. However, most prior studies have generally focused on what items may be interesting for users, but have neglected the consideration of when the next items are likely to be purchased. Clearly, the timing information is an essential factor for companies to adopt proper selling strategies at the 'right' time. In this study, a novel recommendation system, G-TransRec, is proposed to predict customers' next items of interest with the potential purchase time by exploiting a user temporal interaction sequence. Moreover, by integrating the graph embedding technique, we include the global user information to explore more collaborative knowledge for effective recommendations. Several experiments were conducted on two real datasets to demonstrate the performance and superiority of the proposed model compared with the state-of-the-art methods on several evaluation metrics. We also use a case study to show the practicability of the proposed G-TransRec for users to recommend what they want at what time from a massive amount of merchandise.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chen2024G-TransRec
ER  -

TY  - JOUR
AU  - Jiang, J.
AU  - Wang, H.
AU  - Wu, J.
AU  - Liu, C.
TI  - Segmentation from localization: a weakly supervised semantic segmentation method for resegmenting CAM
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 19
SP  - 57785
EP  - 57810
DO  - 10.1007/s11042-023-17779-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179349619&doi=10.1007%2fs11042-023-17779-4&partnerID=40&md5=c19bab10c83f3660ab6fb59be29b14f0
AB  - Semantic segmentation has wide applications in computer vision tasks. Due to the high labor cost of pixel-level annotation, weakly supervised semantic segmentation(WSSS) methods based on image-level labels have become an important research topic. However, existing WSSS based on image-level labels has problems such as sparse segmentation results and inaccurate object boundaries. To overcome these problems, we propose a novel locate-then-segment framework that separates the localization process and segmentation process of WSSS. During the localization process we use class activation map(CAM) to locate the rough position of the object as most WSSS methods do. During the segmentation process, we focused on designing the object segmenter to refine the CAM to obtain the pseudo mask. The object segmenter consists of a dual localization feature fusion module and a boundary enhancement decoder. The former effectively extracts the semantic features of the object and finds the whole object; the latter judges long-range pixels to search for the exact object boundary. Additionally, we utilize extra pixel-level labels to train our object segmenter and add some constraints to optimize its training process. Finally, we apply the trained object segmenter to weakly supervised segmented data to improve the prediction results of CAM. Experimental results show that our proposed method significantly improves the quality of pseudo masks and obtains competitive segmentation results. Compared to existing methods, our method has the best result on the PASCAL VOC 2012 validation set with 68.8% mIoU and the competitive result on the test set with 67.9% mIoU. Our method outperforms all CNN-based methods on the MS COCO 2014 validation set, second only to transformer-based methods, achieving 36.5% mIoU. Code is available at https://github.com/wjlbnw/SegmentationFromLocalization. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jiang2024Segmentation
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Wang, Y.
AU  - Jiang, G.
AU  - Cheng, B.
AU  - Zhou, H.
TI  - Deep learning-based power usage effectiveness optimization for IoT-enabled data center
PY  - 2024
T2  - Peer-to-Peer Networking and Applications
VL  - 17
IS  - 3
SP  - 1702
EP  - 1719
DO  - 10.1007/s12083-024-01663-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188333771&doi=10.1007%2fs12083-024-01663-5&partnerID=40&md5=9e4c227f492f8f0b3a0e76976a2a4217
AB  - The proliferation of data centers is driving increased energy consumption, leading to environmentally unacceptable carbon emissions. As the use of Internet-of-Things (IoT) techniques for extensive data collection in data centers continues to grow, deep learning-based solutions have emerged as attractive alternatives to suboptimal traditional methods. However, existing approaches suffer from unsatisfactory performance, unrealistic assumptions, and an inability to address practical data center optimization. In this paper, we focus on power usage effectiveness (PUE) optimization in IoT-enabled data centers using deep learning algorithms. We first develop a deep learning-based PUE optimization framework tailored to IoT-enabled data centers. We then formulate the general PUE optimization problem, simplifying and specifying it for the minimization of long-term energy consumption in chiller cooling systems. Additionally, we introduce a transformer-based prediction network designed for energy consumption forecasting. Subsequently, we transform this formulation into a Markov decision process (MDP) and present the branching double dueling deep Q-network. This approach effectively tackles the challenges posed by enormous action spaces within MDP by branching actions into sub-actions. Extensive experiments conducted on real-world datasets demonstrate the exceptional performance of our algorithms, excelling in prediction precision, optimization convergence, and optimality while effectively managing a substantial number of actions on the order of 1013. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Sun2024Deep
ER  -

TY  - JOUR
AU  - Umer, M.
AU  - Alarfaj, A.A.
AU  - Alabdulqader, E.A.
AU  - Alsubai, S.
AU  - Cascone, L.
AU  - Narducci, F.
TI  - Enhancing fall prediction in the elderly people using LBP features and transfer learning model
PY  - 2024
T2  - Image and Vision Computing
VL  - 145
C7  - 104992
DO  - 10.1016/j.imavis.2024.104992
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189693533&doi=10.1016%2fj.imavis.2024.104992&partnerID=40&md5=bd7069f9ddb10e74215f7edf1a4b8a94
AB  - In an era where the detection and prevention of falls are crucial for the well-being of elderly and vulnerable individuals, achieving high accuracy in identifying such incidents is of utmost importance. This study introduces a modified NASNet, a novel transformer learning model designed for the classification of fall and not fall people based on local binary patterns (LBP) features. The modified NASNet model demonstrates high performance, achieving an accuracy, precision, recall, and F1 score of 99% with LBP features in differentiating fall from not fall. To assess the performance of NASNet, this research work conducted a comparative analysis with other prominent deep learning, and transfer learning models, as well as state-of-the-art machine learning frameworks. The findings indicate NASNet's enhanced performance in fall detection, highlighting its potential for application in real-time fall detection systems, contributing to a safer environment for individuals at risk. This research sets the stage for enhanced healthcare and assistance for vulnerable populations, addressing a critical concern in the healthcare sector. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Umer2024Enhancing
ER  -

TY  - JOUR
AU  - Akbar, S.
AU  - Zou, Q.
AU  - Raza, A.
AU  - Alarfaj, F.K.
TI  - iAFPs-Mv-BiTCN: Predicting antifungal peptides using self-attention transformer embedding and transform evolutionary based multi-view features with bidirectional temporal convolutional networks
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 151
C7  - 102860
DO  - 10.1016/j.artmed.2024.102860
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189006428&doi=10.1016%2fj.artmed.2024.102860&partnerID=40&md5=3bd5e6a4ee95653b051056524d19af52
AB  - Globally, fungal infections have become a major health concern in humans. Fungal diseases generally occur due to the invading fungus appearing on a specific portion of the body and becoming hard for the human immune system to resist. The recent emergence of COVID-19 has intensely increased different nosocomial fungal infections. The existing wet-laboratory-based medications are expensive, time-consuming, and may have adverse side effects on normal cells. In the last decade, peptide therapeutics have gained significant attention due to their high specificity in targeting affected cells without affecting healthy cells. Motivated by the significance of peptide-based therapies, we developed a highly discriminative prediction scheme called iAFPs-Mv-BiTCN to predict antifungal peptides correctly. The training peptides are encoded using word embedding methods such as skip-gram and attention mechanism-based bidirectional encoder representation using transformer. Additionally, transform-based evolutionary features are generated using the Pseduo position-specific scoring matrix using discrete wavelet transform (PsePSSM-DWT). The fused vector of word embedding and evolutionary descriptors is formed to compensate for the limitations of single encoding methods. A Shapley Additive exPlanations (SHAP) based global interpolation approach is applied to reduce training costs by choosing the optimal feature set. The selected feature set is trained using a bi-directional temporal convolutional network (BiTCN). The proposed iAFPs-Mv-BiTCN model achieved a predictive accuracy of 98.15 % and an AUC of 0.99 using training samples. In the case of the independent samples, our model obtained an accuracy of 94.11 % and an AUC of 0.98. Our iAFPs-Mv-BiTCN model outperformed existing models with a ~4 % and ~5 % higher accuracy using training and independent samples, respectively. The reliability and efficacy of the proposed iAFPs-Mv-BiTCN model make it a valuable tool for scientists and may perform a beneficial role in pharmaceutical design and research academia. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - CCF:C期刊; 
LB  - Akbar2024iAFPs-Mv-BiTCN
ER  -

TY  - JOUR
AU  - Zhao, B.
AU  - Deng, W.
AU  - Li, Z.H.H.
AU  - Zhou, C.
AU  - Gao, Z.
AU  - Wang, G.
AU  - Li, X.
TI  - LESS: Label-efficient multi-scale learning for cytological whole slide image screening
PY  - 2024
T2  - Medical Image Analysis
VL  - 94
C7  - 103109
DO  - 10.1016/j.media.2024.103109
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186117792&doi=10.1016%2fj.media.2024.103109&partnerID=40&md5=9133ea417db593e48bba8f10de7858d2
AB  - In computational pathology, multiple instance learning (MIL) is widely used to circumvent the computational impasse in giga-pixel whole slide image (WSI) analysis. It usually consists of two stages: patch-level feature extraction and slide-level aggregation. Recently, pretrained models or self-supervised learning have been used to extract patch features, but they suffer from low effectiveness or inefficiency due to overlooking the task-specific supervision provided by slide labels. Here we propose a weakly-supervised Label-Efficient WSI Screening method, dubbed LESS, for cytological WSI analysis with only slide-level labels, which can be effectively applied to small datasets. First, we suggest using variational positive-unlabeled (VPU) learning to uncover hidden labels of both benign and malignant patches. We provide appropriate supervision by using slide-level labels to improve the learning of patch-level features. Next, we take into account the sparse and random arrangement of cells in cytological WSIs. To address this, we propose a strategy to crop patches at multiple scales and utilize a cross-attention vision transformer (CrossViT) to combine information from different scales for WSI classification. The combination of our two steps achieves task-alignment, improving effectiveness and efficiency. We validate the proposed label-efficient method on a urine cytology WSI dataset encompassing 130 samples (13,000 patches) and a breast cytology dataset FNAC 2019 with 212 samples (21,200 patches). The experiment shows that the proposed LESS reaches 84.79%, 85.43%, 91.79% and 78.30% on the urine cytology WSI dataset, and 96.88%, 96.86%, 98.95%, 97.06% on the breast cytology high-resolution-image dataset in terms of accuracy, AUC, sensitivity and specificity. It outperforms state-of-the-art MIL methods on pathology WSIs and realizes automatic cytological WSI cancer screening. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Zhao2024LESS
ER  -

TY  - JOUR
AU  - Su, X.
AU  - Liu, S.
AU  - Li, R.
AU  - Bing, Z.
AU  - Knoll, A.
TI  - Efficient Stereo Matching Using Swin Transformer and Multilevel Feature Consistency in Autonomous Mobile Systems
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 5
SP  - 7957
EP  - 7965
DO  - 10.1109/TII.2024.3367033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187333612&doi=10.1109%2fTII.2024.3367033&partnerID=40&md5=a4aa93a3c3bcab0acff4e8339037def8
AB  - In this article, we propose a Swin Transformer and multilevel Feature Consistency based Network (STFC-Net), which is a multilevel cascade stereo matching method to predict the disparity in a coarse-to-fine manner. 1) To alleviate the problem of the limited receptive field of existing convolutional neural network (CNN)-based methods, inspired by the capability of modeling the large-scale dependence of transformer, we adopt a multilevel feature extraction module combining CNN and Swin Transformer to capture long-range context information; a multiscale cascaded cost aggregation module is used to cover different image regions with less memory consumption. 2) To make full use of the hierarchical features, we checked the multilevel left-right feature consistency in an unsupervised manner to improve the disparity accuracy. The experimental results show that our method outperforms some previous CNN methods on the Scene Flow and KITTI datasets with lower computational time complexity. Moreover, it generalizes well in some unknown and challenging real-world scenarios.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Su2024Efficient
ER  -

TY  - JOUR
AU  - Tong, N.
AU  - Gou, S.
AU  - Yang, Y.
AU  - Liu, B.
AU  - Bai, Y.
AU  - Liu, J.
AU  - Ding, T.
TI  - Fully Automatic Fine-Grained Grading of Lumbar Intervertebral Disc Degeneration Using Regional Feature Recalibration Network
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 5
SP  - 3042
EP  - 3054
DO  - 10.1109/JBHI.2024.3366780
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186092952&doi=10.1109%2fJBHI.2024.3366780&partnerID=40&md5=ae000f729e6849746474e301b14daf94
AB  - Accurate fine-grained grading of lumbar intervertebral disc (LIVD) degeneration is essential for the diagnosis and treatment design of high-incidence low back pain. However, the grading accuracy is still challenged by lacking the fine-grained degenerative details, which is mainly due to the existing grading methods are easily dominated by the salient nucleus pulposus regions in LIVD, overlooking the inconspicuous degeneration changes of the surrounding structures. In this study, a novel regional feature recalibration network (RFRecNet) is proposed to achieve accurate and reliable LIVD degeneration grading. Detection transformer (DETR) is first utilized to detect all LIVDs and then input to the proposed RFRecNet for the fine-grained grading. To obtain sufficient features from both the salient nucleus pulposus and the surrounding regions, a regional cube-based feature boosting and suppression (RC-FBS) module is designed to adaptively recalibrate the feature extraction and utilization from the various regions in LIVD, and a feature diversification (FD) module is proposed to capture the complementary semantic information from the multi-scale features for the comprehensive fine-grained degeneration grading. Extensive experiments were conducted on a clinically collected dataset, which consists of 500 MR scans with a total of 10225 LIVDs. An average grading accuracy of 90.5%, specificity of 97.5%, sensitivity of 90.8%, and Cohen's kappa correlation coefficient of 0.876 are obtained, which indicate that the proposed framework is promising to provide doctors with reliable and consistent fine-grained quantitative evaluation results of the LIVD degeneration conditions for the optimal surgical plan design.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Tong2024Fully
ER  -

TY  - JOUR
AU  - Pehlivan, S.
AU  - Laaksonen, J.
TI  - Temporal teacher with masked transformers for semi-supervised action proposal generation
PY  - 2024
T2  - Machine Vision and Applications
VL  - 35
IS  - 3
C7  - 36
DO  - 10.1007/s00138-024-01521-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187783451&doi=10.1007%2fs00138-024-01521-7&partnerID=40&md5=8d912e034ca43c85e1c11487181ac67b
AB  - By conditioning on unit-level predictions, anchor-free models for action proposal generation have displayed impressive capabilities, such as having a lightweight architecture. However, task performance depends significantly on the quality of data used in training, and most effective models have relied on human-annotated data. Semi-supervised learning, i.e., jointly training deep neural networks with a labeled dataset as well as an unlabeled dataset, has made significant progress recently. Existing works have either primarily focused on classification tasks, which may require less annotation effort, or considered anchor-based detection models. Inspired by recent advances in semi-supervised methods on anchor-free object detectors, we propose a teacher-student framework for a two-stage action detection pipeline, named Temporal Teacher with Masked Transformers (TTMT), to generate high-quality action proposals based on an anchor-free transformer model. Leveraging consistency learning as one self-training technique, the model jointly trains an anchor-free student model and a gradually progressing teacher counterpart in a mutually beneficial manner. As the core model, we design a Transformer-based anchor-free model to improve effectiveness for temporal evaluation. We integrate bi-directional masks and devise encoder-only Masked Transformers for sequences. Jointly training on boundary locations and various local snippet-based features, our model predicts via the proposed scoring function for generating proposal candidates. Experiments on the THUMOS14 and ActivityNet-1.3 benchmarks demonstrate the effectiveness of our model for temporal proposal generation task. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Pehlivan2024Temporal
ER  -

TY  - JOUR
AU  - Tamboli, D.
AU  - Chen, J.
AU  - Jotheeswaran, K.P.
AU  - Yu, D.
AU  - Aggarwal, V.
TI  - Reinforced Sequential Decision-Making for Sepsis Treatment: The PosNegDM Framework With Mortality Classifier and Transformer
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 5
SP  - 3114
EP  - 3122
DO  - 10.1109/JBHI.2024.3377214
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188001478&doi=10.1109%2fJBHI.2024.3377214&partnerID=40&md5=9e35b646d07b336d3e43a812d46e2f12
AB  - Sepsis, a life-threatening condition triggered by the body's exaggerated response to infection, demands urgent intervention to prevent severe complications. Existing machine learning methods for managing sepsis struggle in offline scenarios, exhibiting suboptimal performance with survival rates below 50%. This paper introduces the PosNegDM - 'Reinforcement Learning with Positive and Negative Demonstrations for Sequential Decision-Making' framework utilizing an innovative transformer-based model and a feedback reinforcer to replicate expert actions while considering individual patient characteristics. A mortality classifier with 96.7% accuracy guides treatment decisions towards positive outcomes. The PosNegDM framework significantly improves patient survival, saving 97.39% of patients, outperforming established machine learning algorithms (Decision Transformer and Behavioral Cloning) with survival rates of 33.4% and 43.5%, respectively. Additionally, ablation studies underscore the critical role of the transformer-based decision maker and the integration of a mortality classifier in enhancing overall survival rates. In summary, our proposed approach presents a promising avenue for enhancing sepsis treatment outcomes, contributing to improved patient care and reduced healthcare costs.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tamboli2024Reinforced
ER  -

TY  - JOUR
AU  - Kim, J.
AU  - Kim, T.
AU  - Kim, J.
TI  - Two-pathway spatiotemporal representation learning for extreme water temperature prediction
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 131
C7  - 107718
DO  - 10.1016/j.engappai.2023.107718
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182415275&doi=10.1016%2fj.engappai.2023.107718&partnerID=40&md5=817d0486ab480113d565cbb65945e61c
AB  - Accurate predictions of extreme water temperatures are criticalto understanding the variability of the marine environment and reducing marine disasters maximized by global warming. In this study, we propose a two-pathway framework with separated spatial and temporal encoders for accurate prediction of water temperature, especially extremely high water temperature, through effective spatiotemporal representation learning. The spatial and temporal encoder networks based on the Transformer's self-attention mechanism performs the task of predicting the water temperature time series at the 16 coastal locations around the Korean Peninsula for the seven consecutive days ahead at daily intervals with various combinations of patch embedding methods, positional embedding for spatial features. Comparative experiments with conventional deep convolutional and recurrent networks are also conducted for comparison. By comparing and assessing these results, the proposed two-pathway framework can improve the predictability of extremely high coastal water temperature by better capturing spatiotemporal interrelationships and long-range dependencies from open ocean and regional sea, and further determines the optimal architectural details of self-attention-based spatial and temporal encoders. Furthermore, to examine the explainability of the proposed model and its consistency with domain knowledge, spatial and temporal attention maps are visualized and analyzed that represents weights for spatiotemporal input sequences that are more relevant to predict for future predictions. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Kim2024Two-pathway
ER  -

TY  - JOUR
AU  - Zhao, H.
AU  - Cai, H.
AU  - Liu, M.
TI  - Transformer based multi-modal MRI fusion for prediction of post-menstrual age and neonatal brain development analysis
PY  - 2024
T2  - Medical Image Analysis
VL  - 94
C7  - 103140
DO  - 10.1016/j.media.2024.103140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187201544&doi=10.1016%2fj.media.2024.103140&partnerID=40&md5=d9c6c7a6f300fd5d3b7b3247c02d7151
AB  - The brain development during the perinatal period is characterized by rapid changes in both structure and function, which have significant impact on the cognitive and behavioral abilities later in life. Accurate assessment of brain age is a crucial indicator for brain development maturity and can help predict the risk of neonatal pathology. However, evaluating neonatal brains using magnetic resonance imaging (MRI) is challenging due to its complexity, multi-dimension, and noise with subtle alterations. In this paper, we propose a multi-modal deep learning framework based on transformers for precise post-menstrual age (PMA) estimation and brain development analysis using T2-weighted structural MRI (T2-sMRI) and diffusion MRI (dMRI) data. First, we build a two-stream dense network to learn modality-specific features from T2-sMRI and dMRI of brain individually. Then, a transformer module based on self-attention mechanism integrates these features for PMA prediction and preterm/term classification. Finally, saliency maps on brain templates are used to enhance the interpretability of results. Our method is evaluated on the multi-modal MRI dataset of the developing Human Connectome Project (dHCP), which contains 592 neonates, including 478 term-born and 114 preterm-born subjects. The results demonstrate that our method achieves a 0.5-week mean absolute error (MAE) in PMA estimation for term-born subjects. Notably, preterm-born subjects exhibit delayed brain development, worsening with increasing prematurity. Our method also achieves 95% accuracy in classification of term-born and preterm-born subjects, revealing significant group differences. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zhao2024Transformer
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Lyu, J.
AU  - Cheng, P.
AU  - Tam, R.
AU  - Tang, X.
TI  - SSiT: Saliency-Guided Self-Supervised Image Transformer for Diabetic Retinopathy Grading
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 5
SP  - 2806
EP  - 2817
DO  - 10.1109/JBHI.2024.3362878
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184826507&doi=10.1109%2fJBHI.2024.3362878&partnerID=40&md5=3913a040c1b1d492c8fb6d147539f575
AB  - Self-supervised Learning (SSL) has been widely applied to learn image representations through exploiting unlabeled images. However, it has not been fully explored in the medical image analysis field. In this work, Saliency-guided Self-Supervised image Transformer (SSiT) is proposed for Diabetic Retinopathy (DR) grading from fundus images. We novelly introduce saliency maps into SSL, with a goal of guiding self-supervised pre-training with domain-specific prior knowledge. Specifically, two saliency-guided learning tasks are employed in SSiT: 1) Saliency-guided contrastive learning is conducted based on the momentum contrast, wherein fundus images' saliency maps are utilized to remove trivial patches from the input sequences of the momentum-updated key encoder. Thus, the key encoder is constrained to provide target representations focusing on salient regions, guiding the query encoder to capture salient features. 2) The query encoder is trained to predict the saliency segmentation, encouraging the preservation of fine-grained information in the learned representations. To assess our proposed method, four publicly-accessible fundus image datasets are adopted. One dataset is employed for pre-training, while the three others are used to evaluate the pre-trained models' performance on downstream DR grading. The proposed SSiT significantly outperforms other representative state-of-the-art SSL methods on all downstream datasets and under various evaluation settings. For example, SSiT achieves a Kappa score of 81.88% on the DDR dataset under fine-tuning evaluation, outperforming all other ViT-based SSL methods by at least 9.48%.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Huang2024SSiT
ER  -

TY  - JOUR
AU  - Ramirez, I.
AU  - Aizpurua, J.I.
AU  - Lasa, I.
AU  - del Rio, L.
TI  - Probabilistic feature selection for improved asset lifetime estimation in renewables. Application to transformers in photovoltaic power plants
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 131
C7  - 107841
DO  - 10.1016/j.engappai.2023.107841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181888895&doi=10.1016%2fj.engappai.2023.107841&partnerID=40&md5=d443b35e09da73448604868534f66977
AB  - The increased penetration of renewable energy sources (RESs) as an effective mechanism to reduce carbon emissions leads to an increased weather dependency for power and energy systems. This has created dynamic operation and degradation phenomena, which affect the lifetime estimation of the assets operated with RESs. For the reliable and efficient operation of RES it is crucial to monitor the health of its constituent components and feature selection is a crucial step for building robust and accurate health monitoring approaches. In this context, this paper presents a probabilistic feature selection approach, which probabilistically weights and selects features through a heuristic and iterative process for an improved asset lifetime estimation. Power transformers are key power grid assets and they are used to demonstrate the validity and impact of the proposed approach. The approach is tested on two different photovoltaic power plants operated in Spain and Australia. Results consistently show that the proposed feature-selection approach reduces the prediction error and consistently selects relevant features. The approach has been applied to transformer lifetime estimation, but it can be generally applied to assist in the lifetime estimation of other components operated in RESs. Part of the studies presented here as well as source codes are all open-source under the GitHub repository https://github.com/iramirezg/FeatureSelection. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Ramirez2024Probabilistic
ER  -

TY  - JOUR
AU  - Yan, B.
AU  - Tian, J.
AU  - Wan, J.
AU  - Qiu, Y.
AU  - Chen, W.
TI  - Real-time prediction of horizontal drilling pressure based on convolutional Transformer
PY  - 2024
T2  - Concurrency and Computation: Practice and Experience
VL  - 36
IS  - 10
C7  - e8006
DO  - 10.1002/cpe.8006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181254520&doi=10.1002%2fcpe.8006&partnerID=40&md5=4d0184ac9b302f8d25496d09c39eb969
AB  - During horizontal drilling operations, real-time prediction of drilling pressure during the drilling process can help the drilling team cope with the complex and changing working environment downhole, adjust the parameters of the drilling rig promptly, make correct decisions, reduce the probability of drilling accidents, and avoid affecting the duration and cost of the project. This study provides a method for real-time prediction of the drilling pressure of horizontal drilling rigs. A deep learning model based on a convolutional Transformer is trained for accurate real-time prediction by extracting real-time operating data of the horizontal drilling rig from the data acquisition system. The method proposed in this study can be a useful tool to improve the performance of horizontal drilling rigs and can assist the drilling team in operating horizontal drilling rigs. The results of the case study show that: (1) the proposed convolutional Transformer model provides reliable real-time prediction with an MAE of 0.304 MPa and an RMSE of 0.508 MPa; (2) the proposed method can quickly and accurately predict the trend of drilling pressure change in the next period based on the current change of drilling pressure, and grasp the dynamics of drilling pressure of horizontal drilling rigs in advance. Further research could focus on assisted decision-making and intelligent optimization to provide solutions for preventing drilling accidents and improving horizontal rig performance based on the prediction. © 2024 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Yan2024Real-time
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Wang, L.
AU  - Yu, M.
AU  - Wu, R.
AU  - Steffens, D.C.
AU  - Potter, G.G.
AU  - Liu, M.
TI  - Hybrid representation learning for cognitive diagnosis in late-life depression over 5 years with structural MRI
PY  - 2024
T2  - Medical Image Analysis
VL  - 94
C7  - 103135
DO  - 10.1016/j.media.2024.103135
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187197639&doi=10.1016%2fj.media.2024.103135&partnerID=40&md5=572776bc62e02d24dc7ef120577733df
AB  - Late-life depression (LLD) is a highly prevalent mood disorder occurring in older adults and is frequently accompanied by cognitive impairment (CI). Studies have shown that LLD may increase the risk of Alzheimer's disease (AD). However, the heterogeneity of presentation of geriatric depression suggests that multiple biological mechanisms may underlie it. Current biological research on LLD progression incorporates machine learning that combines neuroimaging data with clinical observations. There are few studies on incident cognitive diagnostic outcomes in LLD based on structural MRI (sMRI). In this paper, we describe the development of a hybrid representation learning (HRL) framework for predicting cognitive diagnosis over 5 years based on T1-weighted sMRI data. Specifically, we first extract prediction-oriented MRI features via a deep neural network, and then integrate them with handcrafted MRI features via a Transformer encoder for cognitive diagnosis prediction. Two tasks are investigated in this work, including (1) identifying cognitively normal subjects with LLD and never-depressed older healthy subjects, and (2) identifying LLD subjects who developed CI (or even AD) and those who stayed cognitively normal over five years. We validate the proposed HRL on 294 subjects with T1-weighted MRIs from two clinically harmonized studies. Experimental results suggest that the HRL outperforms several classical machine learning and state-of-the-art deep learning methods in LLD identification and prediction tasks. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhang2024Hybrid
ER  -

TY  - JOUR
AU  - Tang, Y.
AU  - He, H.
AU  - Wang, Y.
TI  - Hierarchical vector transformer vehicle trajectories prediction with diffusion convolutional neural networks
PY  - 2024
T2  - Neurocomputing
VL  - 580
C7  - 127526
DO  - 10.1016/j.neucom.2024.127526
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187207191&doi=10.1016%2fj.neucom.2024.127526&partnerID=40&md5=81ba678d5b7aac7998ea27db813fa76b
AB  - In dynamic and interactive autonomous driving scenarios, accurately predicting the future movements of vehicle agents is crucial. However, current methods often fail to capture trajectory uncertainty, leading to limitations in trajectory prediction performance. To address these limitations, this paper introduces the hierarchical vector transformer diffusion model, a novel trajectory prediction method that prioritizes both speed and accuracy. The proposed model decomposes the traffic scene modeling into local patches and global interactions, allowing for the acquisition of relevant environmental and global information. Moreover, a local diffusion encoder is employed to effectively capture the aleatoric uncertainty. The proposed model utilizes an adaptive graph structure to exploit the spatial and temporal relationships inherent in the trajectory data. By employing a graph diffusion process, the model effectively captures dynamic features from the historical trajectory information. Moreover, the model demonstrates adaptability by dynamically adjusting to diverse trajectory data and scenarios, thereby enabling the generation of predicted trajectories that are uncertainty aware. This approach contributes to more effective and efficient modeling of dynamic autonomous driving scenarios. Experimental results demonstrate the superior speed and accuracy of the proposed method compared to existing approaches for trajectory prediction. The proposed method significantly enhances prediction accuracy, achieving results of ADE 0.68 and FDE 1.02 on the Argoverse dataset. In comparison to the baseline model, there are notable improvements in ADE and FDE by 0.03 and 0.06, respectively. It is noteworthy that this method also reduces the inference time by 7% when compared to the currently fastest method. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Tang2024Hierarchical
ER  -

TY  - JOUR
AU  - Wang, M.
AU  - He, X.
AU  - Liu, L.
AU  - Fang, Q.
AU  - Zhang, M.
AU  - Chen, H.
AU  - Liu, Y.
TI  - HCT: Chinese Medical Machine Reading Comprehension Question-Answering via Hierarchically Collaborative Transformer
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 5
SP  - 3055
EP  - 3066
DO  - 10.1109/JBHI.2024.3368288
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186065691&doi=10.1109%2fJBHI.2024.3368288&partnerID=40&md5=25054d690a3ba8247a70455942676ae4
AB  - Chinese medical machine reading comprehension question-answering (cMed-MRCQA) is a critical component of the intelligence question-answering task, focusing on the Chinese medical domain question-answering task. Its purpose enable machines to analyze and understand the given text and question and then extract the accurate answer. To enhance cMed-MRCQA performance, it is essential to possess a profound comprehension and analysis of the context, deduce concealed information from the textual content and, subsequently, precisely determine the answer's span. The answer span has predominantly been defined by language items, with sentences employed in most instances. However, it is worth noting that sentences may not be properly split to varying degrees in various languages, making it challenging for the model to predict the answer zone. To alleviate this issue, this paper presents a novel architecture called HCT based on a Hierarchically Collaborative Transformer. Specifically, we presented a hierarchical collaborative method to locate the boundaries of sentence and answer spans separately. First, we designed a hierarchical encoding module to obtain the local semantic features of the corpus; second, we proposed a sentence-level self-attention module and a fused interaction-attention module to get the global information about the text. Finally, the model is trained by combining loss functions. Extensive experiments were conducted on the public dataset CMedMRC and the reconstruction dataset eMedicine to validate the effectiveness of the proposed method. Experimental results showed that the proposed method performed better than the state-of-the-art methods. Using the F1 metric, our model scored 90.4% on the CMedMRC and 73.2% on eMedicine.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024HCT
ER  -

TY  - JOUR
AU  - Nouraei, B.
AU  - Shanbehzadeh, J.
AU  - Asghari, P.
TI  - Predictive typing method for Persian office automation
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 131
C7  - 107792
DO  - 10.1016/j.engappai.2023.107792
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183113160&doi=10.1016%2fj.engappai.2023.107792&partnerID=40&md5=c73843692f8d1435e9a98b2f7f1f43bd
AB  - Typing is a time-consuming task and predictive text is proposed as a solution. Recently, Generative Pre-trained Transformers (GPT) have employed autoregressive deep learning to tackle text prediction. However, they face costly retraining, especially for low-resource languages (such as Persian) or domains, and lack controllability. Text augmentation with prompting methods and fine-tuning GPT models on templated data using conditional elements (labels or keywords) aims to address these problems, enhancing controllable text generation in low-resource scenarios. These methods involve discovering and mapping conditional elements to training texts, which is unsuitable for typing assistants. Meanwhile, they do hold inappropriate pre-defined elements for wide use. This paper introduces Conditional GPT-2-Persian (CGPT-2-Persian), which utilizes the initial word of each sentence as the associated conditional element to address practical challenges, extracting labels, and handling in-domain unseen data posed by the mentioned methods. This method outperforms Persian text generation methods in terms of BLEU and ROUGE scores, achieving 87.39% and 14.29%, respectively, after fine-tuning for ten epochs. This study can be efficient for other low-resource languages or domains. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Nouraei2024Predictive
ER  -

TY  - JOUR
AU  - Pinasthika, K.
AU  - Laksono, B.S.P.
AU  - Irsal, R.B.P.
AU  - Shabiyya, S.H.
AU  - Yudistira, N.
TI  - SparseSwin: Swin transformer with sparse transformer block
PY  - 2024
T2  - Neurocomputing
VL  - 580
C7  - 127433
DO  - 10.1016/j.neucom.2024.127433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186687757&doi=10.1016%2fj.neucom.2024.127433&partnerID=40&md5=68701c7aa4969a7a512880ce1db41cd4
AB  - Advancements in computer vision research have put transformer architecture as the state-of-the-art in computer vision tasks. One of the known drawbacks of the transformer architecture is the high number of parameters, this can lead to a more complex and inefficient algorithm. This paper aims to reduce the number of parameters and in turn, made the transformer more efficient. We present Sparse Transformer (SparTa) Block, a modified transformer block with an addition of a sparse token converter that reduces the dimension of high-level features to the number of latent tokens. We implemented the SparTa Block within the Swin-T architecture (SparseSwin) to leverage Swin's proficiency in extracting low-level features and enhance its capability to extract information from high-level features while reducing the number of parameters. The proposed SparseSwin model outperforms other state-of-the-art models in image classification with an accuracy of 87.26%, 97.43%, and 85.35% on the ImageNet100, CIFAR10, and CIFAR100 datasets respectively. Despite its fewer parameters, the result highlights the potential of a transformer architecture using a sparse token converter with a limited number of tokens to optimize the use of the transformer and improve its performance. The code is available at https://github.com/KrisnaPinasthika/SparseSwin. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Pinasthika2024SparseSwin
ER  -

TY  - JOUR
AU  - Kim, Y.-M.
AU  - Song, S.
AU  - Koo, B.-M.
AU  - Son, J.
AU  - Lee, Y.
AU  - Baek, J.-G.
TI  - Enhancing Long-Term Cloud Workload Forecasting Framework: Anomaly Handling and Ensemble Learning in Multivariate Time Series
PY  - 2024
T2  - IEEE Transactions on Cloud Computing
VL  - 12
IS  - 2
SP  - 789
EP  - 799
DO  - 10.1109/TCC.2024.3400859
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193223602&doi=10.1109%2fTCC.2024.3400859&partnerID=40&md5=db64c57089b261eb252498756ba06c1c
AB  - Forecasting workloads and responding promptly with resource scaling and migration is critical to optimizing operations and enhancing resource management in cloud environments. However, the diverse and dynamic nature of devices within cloud environments complicates workload forecasting. These challenges often lead to service level agreement violations or inefficient resource usage. Hence, this paper proposes an Enhanced Long-Term Cloud Workload Forecasting (E-LCWF) framework designed specifically for efficient resource management in these heterogeneous and dynamic environments. The E-LCWF framework processes individual resource workloads as multivariate time series and enhances model performance through anomaly detection and handling. Additionally, the E-LCWF framework employs an error-based ensemble approach, using transformer-based models and Long-Term Time Series Forecasting (LTSF) linear models, each of which has demonstrated exceptional performance in LTSF. Experimental results obtained using virtual machine data from real-world management information systems and manufacturing execution systems show that the E-LCWF framework outperforms state-of-the-art models in forecasting accuracy.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Kim2024Enhancing
ER  -

TY  - JOUR
AU  - Chen, M.
AU  - Zhang, Y.
AU  - Ji, Z.
AU  - Briso-Rodriguez, C.
AU  - Zhang, K.
TI  - AI-Enhanced Generalizable Scheme for Path Loss Prediction in LoRaWAN
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 8
SP  - 14593
EP  - 14606
DO  - 10.1109/JIOT.2023.3342984
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180292742&doi=10.1109%2fJIOT.2023.3342984&partnerID=40&md5=6335a3b17ececa32cb8ca2b4d9c61ffe
AB  - Long-range wide-area network (LoRaWAN) is a widely used technology in the Internet of Things (IoT), which provides long-range (LoRa) communication with low power consumption. In LoRaWAN, an accurate path loss (PL) model is essential to realize link budget and network coverage planning. In this article, we present an artificial intelligence (AI)-enhanced generalizable scheme for PL prediction in LoRaWAN. We propose a network that performs corrective adjustments to improve the PL estimates of empirical models. The network termed STransRadio benefits from the self-attention computation in Swin Transformer to model the LoRa correlation about propagation for enhancing the adjustment prediction accuracy. To generalize our scheme to new scenarios, an multiscenario deep transfer learning (MDTL) algorithm is proposed, which finetunes the pretrained STransRadio network with limited data. We conduct simulations and measurements in the 868-MHz bands to assess the performance of the scheme in terms of prediction accuracy and generalization ability. The effectiveness of the proposed scheme has been verified with both simulations and measurements. Moreover, the STransRadio network in the scheme outperforms the convolutional neural network (CNN) and deep vision transformer (DeepViT). With the MDTL algorithm, our scheme can achieve excellent prediction performances when it is applied in a new scenario with limited training data. Furthermore, we verify that the scheme utilized in the simulated scenario can be transferred to both the new simulated scenario and the realistic scenario. With only 100 samples, the scheme achieves root mean square error (RMSE) values of 7.27 and 5.96 dB between the predicted and actual PL, respectively. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chen2024AI-Enhanced
ER  -

TY  - JOUR
AU  - Borah, J.
AU  - Kumar, S.
AU  - Kumar, N.
AU  - Nadzir, M.S.M.
AU  - Cayetano, M.G.
AU  - Ghayvat, H.
AU  - Majumdar, S.
AU  - Kumar, N.
TI  - AiCareBreath: IoT-Enabled Location-Invariant Novel Unified Model for Predicting Air Pollutants to Avoid Related Respiratory Disease
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 8
SP  - 14625
EP  - 14633
DO  - 10.1109/JIOT.2023.3342872
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181581604&doi=10.1109%2fJIOT.2023.3342872&partnerID=40&md5=0dd3cbb79a0a5462c362c33964af31cc
AB  - This article presents a location-invariant air pollution prediction model with good geographic generalizability. The model uses a light GBR as part of a machine-learning framework to capture the spatial identification of air contaminants. Given the dynamic nature of air pollution, the model also uses a random forest to capture temporal dependencies in the data. Our model uses a transfer learning strategy to deal with location variability. The algorithm can learn concentration patterns because it has been trained on a vast data set of air quality measurements from various locations. The trained model is then improved using information from a particular target site, customizing it to the features of the target area. Experiments are carried out on a comprehensive data set containing air pollution measurements from various places to assess the efficacy of the proposed model. The recommended method performs better than standard models at forecasting air pollution levels, proving its dependability in various geographical settings. An interpretability analysis is also performed to learn about the variables affecting air pollution levels. We identify the geographical patterns associated with high-pollutant concentrations by visualizing the learned representations within the model, giving important information for environmental planning and mitigation methods. The observations show that the model outperforms state-of-the-art forecasting based on recurrent neural network and transformer-based models. The suggested methodology for forecasting air contaminants has the potential to improve air quality management and aid in decision-making across numerous regions. This helps safeguard the environment and public health by creating more precise and dependable air pollution forecast systems.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Borah2024AiCareBreath
ER  -

TY  - JOUR
AU  - Yang, B.
AU  - Lu, Y.
AU  - Wan, R.
AU  - Hu, H.
AU  - Yang, C.
AU  - Ni, R.
TI  - Meta-IRLSOT++: A meta-inverse reinforcement learning method for fast adaptation of trajectory prediction networks
PY  - 2024
T2  - Expert Systems with Applications
VL  - 240
C7  - 122499
DO  - 10.1016/j.eswa.2023.122499
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177493939&doi=10.1016%2fj.eswa.2023.122499&partnerID=40&md5=cec4348618495cde799729d89900f4a6
AB  - Recent research on pedestrian trajectory prediction based on deep learning has made significant progress. However, the previous methods do not deeply explore the relationship between scene information and trajectory. Moreover, the training model requires massive data and only targets specific scenes, so the prediction performance is poor when the new scene samples are limited. To solve the above problems, a meta-inverse reinforcement learning-based framework, dubbed Meta-IRLSOT++, is proposed in this work. IRLSOT++ improves the solid baseline IRLSOT, and the main contributions are as follows: (1) An inverse reinforcement learning framework is introduced to explore the trajectory–scene association to achieve task-level scene understanding, enhancing the correlation between trajectory and scene. The trajectory heat maps describing pedestrians dynamic characteristics are leveraged to align better the trajectory and scene semantic segmentation predicted by TopFormer. (2) A Transformer-based encoder–decoder network is proposed to fuse the trajectory and plan cues for better generating multi-modal trajectories with multi-head attention. The social graph attention and pseudo-oracle predictor are introduced to capture pedestrians’ social interactions and intent states, ameliorating trajectory prediction performance. (3) Meta-learning is leveraged to achieve collaborative training based on IRLSOT++ to improve the model generalization in new scenes, enabling fast adaptation of trajectory prediction. Experimental results on the Stanford Drone Dataset (SDD) indicate that IRLSOT++ can precisely forecast future trajectories by improving IRLSOT, decreasing Average Displacement Error/ Final Displacement Error (ADE/FDE) values from 9.66/13.05 to 8.36/12.28. Moreover, the meta-learning strategy quickly adapts IRLSOT++ to the new scene, achieving ADE/FDE values of 7.31/11.02 and 15.42/26.55 when Tpred is set to 12 and 24, respectively. Both quantitative and qualitative experimental results show that Meta-IRLSOT++ has accuracy and fast adaptability, which is beneficial for real-world trajectory prediction tasks. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yang2024Meta-IRLSOT++
ER  -

TY  - JOUR
AU  - Mei, J.
AU  - Wang, M.
AU  - Yang, Y.
AU  - Li, Z.
AU  - Liu, Y.
TI  - Learning spatiotemporal relationships with a unified framework for video object segmentation
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 8
SP  - 6138
EP  - 6153
DO  - 10.1007/s10489-024-05486-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192264458&doi=10.1007%2fs10489-024-05486-y&partnerID=40&md5=3bb18bf1f4ee8a6f44f4714b6d240bf5
AB  - Video object segmentation (VOS) has made significant progress with matching-based methods, but most approaches still show two problems. Firstly, they apply a complicated and redundant two-extractor pipeline to use more reference frames for cues, increasing the models’ parameters and complexity. Secondly, most of these methods neglect the spatial relationships (inside each frame) and do not fully model the temporal relationships (among different frames), i.e., they need adequate modeling of spatial-temporal relationships. In this paper, to address the two problems, we propose a unified transformer-based framework for VOS, a compact and unified single-extractor pipeline with strong spatial and temporal interaction ability. Specifically, to slim the common-used two-extractor pipeline while keeping the model’s effectiveness and flexibility, we design a single dynamic feature extractor with an ingenious dynamic input adapter to encode two significant inputs, i.e., reference sets (historical frames with predicted masks) and query frame (current frame), respectively. Moreover, the relationships among different frames and inside every frame are crucial for this task. We introduce a vision transformer to exploit and model both the temporal and spatial relationships simultaneously. By the cascaded design of the proposed dynamic feature extractor, transformer-based relationship module, and target-enhanced segmentation, our model implements a unified and compact pipeline for VOS. Extensive experiments demonstrate the superiority of our model over state-of-the-art methods on both DAVIS and YouTube-VOS datasets. We also explore potential solutions, such as sequence organizers, to improve the model’s efficiency. On DAVIS17 validation, we achieve ∼50% faster inference speed with only a slight 0.2% (J&F) drop in segmentation quality. Codes are available at https://github.com/sallymmx/TransVOS.git. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Mei2024Learning
ER  -

TY  - JOUR
AU  - Zhao, F.
AU  - Tao, R.
AU  - Wang, W.
AU  - Cui, B.
AU  - Xu, Y.
AU  - Ai, Q.
TI  - Collaborative learning of supervision and correlation for generalized zero-shot extreme multi-label learning
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 8
SP  - 6285
EP  - 6298
DO  - 10.1007/s10489-024-05498-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192545827&doi=10.1007%2fs10489-024-05498-8&partnerID=40&md5=716231bd023a594c285ca3f893aa105e
AB  - Generalized zero-shot extreme multi-label learning (GZXML) aims to predict relevant labels for unknown instances from a set of seen and unseen labels and is widely used in engineering applications. Since the supervisory information of the instances is incomplete in this task, the existing methods classify such instances based on the semantic relationships between the instances and labels. However, the supervisory information of the seen labels is also crucial for achieving high prediction performance. To bridge this gap, we propose collaborative learning of supervision and correlations for GZXML (CLSC-XML). CLSC-XML leverages both the semantic relationships between instances and labels and the supervisory information of the seen labels to enhance the prediction results for unseen labels. Specifically, CLSC-XML extracts discriminative and representational features, which are then fed into classification and correlation modules for collaborative learning. Furthermore, to enrich the incomplete supervised information, we propose the generation of features for unseen labels (GFUL) algorithm. The classifier is trained alternately with the GFUL algorithm. The classifier provides semantic guidance to the GFUL algorithm, and in turn, the GFUL algorithm helps the classification model enrich the supervised information. Experimental results show that CLSC-XML outperforms the state-of-the-art methods and requires less training time. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2024Collaborative
ER  -

TY  - JOUR
AU  - Meybodi, Z.H.
AU  - Mohammadi, A.
AU  - Hou, M.
AU  - Rahimian, E.
AU  - Heidarian, S.
AU  - Abouei, J.
AU  - Plataniotis, K.N.
TI  - Multi-content time-series popularity prediction with Multiple-model Transformers in MEC networks
PY  - 2024
T2  - Ad Hoc Networks
VL  - 157
C7  - 103436
DO  - 10.1016/j.adhoc.2024.103436
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185411098&doi=10.1016%2fj.adhoc.2024.103436&partnerID=40&md5=a4781b51bca957f642feea14fefab595
AB  - Coded/uncoded content placement in Mobile Edge Caching (MEC) has evolved as an efficient solution to meet the significant growth of global mobile data traffic by boosting the content diversity in the storage of caching nodes. To meet the dynamic nature of the historical request pattern of multimedia contents, the main focus of recent researches has been shifted to develop data-driven and real-time caching schemes. In this regard and with the assumption that users’ preferences remain unchanged over a short horizon, the Top-K popular contents. These contents refer to the most requested content in the upcoming period. Most existing data-driven popularity prediction models, however, are not suitable for the coded/uncoded content placement frameworks. On the one hand, in coded/uncoded content placement, in addition to classifying contents into two groups, i.e., popular and non-popular, the probability of content request is required to identify which content should be stored partially/completely, where this information is not provided by existing data-driven popularity prediction models. On the other hand, the assumption that users’ preferences remain unchanged over a short horizon only works for content with a smooth request pattern. To tackle these challenges, we develop a Multiple-model (hybrid) Transformer-based Edge Caching (MTEC) framework with higher generalization ability, suitable for various types of content with different time-varying behavior, that can be adapted with coded/uncoded content placement frameworks. In this work, we consider Top-K content as the output of the 1st Stage of the proposed MTEC framework, which includes both popular and mediocre content. Simulation results corroborate the effectiveness of the proposed MTEC caching framework in comparison to its counterparts in terms of the cache-hit ratio, classification accuracy, and the transferred byte volume. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Meybodi2024Multi-content
ER  -

TY  - JOUR
AU  - Luo, Y.
AU  - Lin, H.
AU  - Huang, W.
AU  - Wang, Y.
AU  - Du, J.
AU  - Guo, J.-M.
TI  - Pose focus transformer meet inter-part relation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 240
C7  - 122476
DO  - 10.1016/j.eswa.2023.122476
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179747341&doi=10.1016%2fj.eswa.2023.122476&partnerID=40&md5=e2d1d916108eda5f5eec0c0d0edf780d
AB  - Human pose estimation in crowded scenes is a challenging task. Due to overlap and occlusion, it is difficult to infer pose clues from individual keypoints. We proposed PFFormer, a new transformer-based approach that treats pose estimation as a hierarchical set prediction problem that first focuses on human windows and coarsely predicts whole-body poses globally within them. In PFFormer, we designed a Windows Clustering Transformer (WCT), which reorganizes the image windows by filtering the attentive windows and fusing the inattentive ones, allowing the transformer to focus on the important regions while reducing the interference from the complex background, followed by compensating for the loss of information with a global transformer. Then we partition the learned body pose into a set of structural parts and perform the Inter-Part Relation Module (IPRM) to capture the correlation between multiple parts. These full-body poses and component features are refined at a finer level through the Part-to-Joint Decoder (PJD). Extensive experiments show that PFFormer performs favorably against its counterpart on challenging datasets, including COCO2017, CrowdPose, and OChuman datasets. The performance of crowded scenes, in particular, demonstrates the robustness of the proposed methods to deal with occlusion. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Luo2024Pose
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Pan, H.
AU  - Liang, Y.
AU  - Shao, M.
AU  - Xie, S.
AU  - Lu, S.
AU  - Liao, S.
TI  - PMFN-SSL: Self-supervised learning-based progressive multimodal fusion network for cancer diagnosis and prognosis
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 289
C7  - 111502
DO  - 10.1016/j.knosys.2024.111502
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185553513&doi=10.1016%2fj.knosys.2024.111502&partnerID=40&md5=fa6fc68e9807ac82a68987df9eb309e4
AB  - The integration of digital pathology images and genetic data is a developing field in cancer research, presenting potential opportunities for predicting survival and classifying grades through multiple source data. However, obtaining comprehensive annotations proves challenging in practical medical settings, and the extraction of features from high-resolution pathology images is hindered by inter-domain disparities. Current data fusion methods ignore the spatio-temporal incongruity among multimodal data. To address the above challenges, we propose a novel self-supervised transformer-based pathology feature extraction strategy, and construct an interpretable Progressive Multimodal Fusion Network (PMFN-SSL) for cancer diagnosis and prognosis. Our contributions are mainly divided into three aspects. Firstly, we propose a joint patch sampling strategy based on the information entropy and HSV components of an image, which reduces the demand for sample annotations and avoid image quality degradation caused by manual contamination. Secondly, a self-supervised transformer-based feature extraction module for pathology images is proposed and innovatively leverages partially weakly supervised labeling to align the extracted features with downstream medical tasks. Further, we improve the existing multimodal feature fusion model with an progressive fusion strategy to reduce the inconsistency between multimodal data due to differences in collection of temporal and spatial. Abundant ablation and comparison experiments demonstrate that the proposed data preprocessing method and multimodal fusion paradigm strengthen the quality of feature extraction and improve the prediction based on real cancer grading and prognosis. Code and trained models are made available at: https://github.com/Mercuriiio/PMFN-SSL. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Li2024PMFN-SSL
ER  -

TY  - JOUR
AU  - Liu, K.
AU  - Qi, Y.
AU  - Xu, G.
AU  - Li, J.
TI  - YOLOv5s maritime distress target detection method based on swin transformer
PY  - 2024
T2  - IET Image Processing
VL  - 18
IS  - 5
SP  - 1258
EP  - 1267
DO  - 10.1049/ipr2.13024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182226019&doi=10.1049%2fipr2.13024&partnerID=40&md5=fb26585a1876007efc87ce6ab93a086a
AB  - In recent years, the task of maritime emergency rescue has increased, while the cost of time for traditional methods of search and rescue is pretty long with poor effect subject to the constraints of the complex circumstances around the sea, the effective conditions, and the support capability. This paper applies deep learning and proposes a YOLOv5s-SwinDS algorithm for target detection in distress at sea. Firstly, the backbone network of the YOLOv5s algorithm is replaced by swin transformer, and a multi-level feature fusion module is introduced to enhance the feature expression ability for maritime targets. Secondly, deformable convolutional networks v2 (DCNv2) is used instead of traditional convolution to improve the recognition capability for irregular targets when the neck network features are output. Finally, the CIoU loss function is replaced with SIoU to reduce the redundant box effectively while accelerating the convergence and regression of the predicted box. Experimenting on the publicly dataset SeaDronesSee, the (Formula presented.), (Formula presented.), (Formula presented.) and (Formula presented.) of YOLOv5s-SwinDS model are 87.9%, 75.8%, 79.1% and 42.9%, respectively, which get higher results than the original YOLOv5s model, the YOLOv7 series of models, and the YOLOv8 series of models. The experiments verifies that the algorithm has good performance in detecting maritime distress targets. © 2024 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2024YOLOv5s
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Tang, X.
AU  - Cao, B.
AU  - Peng, Y.
AU  - He, X.
AU  - Ye, S.
AU  - Dai, F.
TI  - Boundary guided network with two-stage transfer learning for gastrointestinal polyps segmentation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 240
C7  - 122503
DO  - 10.1016/j.eswa.2023.122503
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177855737&doi=10.1016%2fj.eswa.2023.122503&partnerID=40&md5=3c6679f5c408c30dedd3449fb26545ab
AB  - The automated segmentation of polyps plays a crucial role in the early diagnosis and treatment of gastrointestinal diseases. However, due to the diversity of polyp lesions and complex imaging environment, the accurate identification of the true lesion area is challenging, especially for small polyps. The blurred boundary of polyps can also result in over or under-segmentation issues. This research proposes a boundary-guided network with two-stage transfer learning: (1) the network is trained to determine the region of interest for polyp lesions and save the initial weights; (2) transfer learning is applied to leverage the learned prior knowledge to perform fine segmentation of the region of interest. It can accurately identify the lesion area, thereby achieving good segmentations, especially for small polyps. Besides, the pyramid vision transformer is used as the feature backbone. Boundary feature extraction module (BFE), deep feature extraction module (DFE), and multi-scale fusion module (MF) are designed to generate boundary maps that guide the decoder in generating prediction maps. Experimental results show that the proposed method outperforms the comparative methods on four public datasets and a private dataset (including gastric polyps), with mDSC scores exceeding 85%. Notably, on the ETIS-Larib dataset, the mDSC score is improved by 11.7% compared to methods used for comparison. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024Boundary
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Han, S.
AU  - Liu, D.
AU  - Ming, D.
TI  - Focus and imagine: Occlusion suppression and repairing transformer for occluded person re-identification
PY  - 2024
T2  - Neurocomputing
VL  - 578
C7  - 127442
DO  - 10.1016/j.neucom.2024.127442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186116399&doi=10.1016%2fj.neucom.2024.127442&partnerID=40&md5=62e4dc7d0f0289bd5bebc50cd992268c
AB  - Occlusion scenarios pose a great challenge to person re-identification (ReID) task because various occlusions may weaken the discriminative features and introduce interference. Recently, Transformer-based networks, which can aggregate features of all the image patches to construct global features adaptively, have shown advantages in occluded person ReID. Existing methods mainly adopted Transformer as a feature extractor and enhanced local features from the output of the Transformer encoder. However, during the processing of self-attention blocks, disturbing features from occlusions may be diffused into all the tokens, making it difficult to construct effective local features. Therefore, we consider predicting the occlusion situation of images before feature extraction and guiding the Transformer encoder to focus on visible regions, suppressing interference from occlusion. Furthermore, we propose to imagine the partial target under occlusion and reconstruct pseudo-holistic features for more robust retrieval. To this end, the Occlusion Suppression and Repairing Transformer (OSRTrans) is proposed. First, we use a self-supervised occlusion predictor to predict occlusion scores of image patches. Then the Occlusion Suppression Encoder (OSE), guided by occlusion predictions, suppresses the interference from occlusion regions and constructs a global feature. Finally, inspired by contrastive learning, the Feature Repairing Head (FRH) is proposed to reconstruct pseudo-holistic features. Our method enhances model's ability of extracting discriminative local features, and achieve the state-of-the-art performance on occluded person ReID benchmarks, e.g., Rank-1 of 72.9% on Occluded-DukeMTMC. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhang2024Focus
ER  -

TY  - JOUR
AU  - Sharma, O.
AU  - Sahoo, N.C.
AU  - Puhan, N.B.
TI  - Transformer based composite network for autonomous driving trajectory prediction on multi-lane highways
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 7
SP  - 5486
EP  - 5520
DO  - 10.1007/s10489-024-05461-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191101184&doi=10.1007%2fs10489-024-05461-7&partnerID=40&md5=f52b4357f0dc0f036ef89b397ce2a7a3
AB  - In order to navigate through complex traffic scenarios safely and efficiently, the autonomous vehicle (AV) predicts its own behavior and future trajectory based on the predicted trajectories of surrounding vehicles to avoid potential collisions. Further, the predicted trajectories of surrounding vehicles (target vehicles) are greatly influenced by their driving behavior and prior trajectory. In this article, we propose a novel Transformer-based composite network to predict both driver behavior and future trajectory of a target vehicle in a highway driving scenario. The powerful multi-head attention mechanism of the transformer is exploited to extract social-temporal interaction between target vehicle and its surrounding vehicles. The prediction of both lateral and longitudinal behavior is carried out within the behavior prediction module, and this additional information is further utilized by the trajectory predictor module to ensure precise trajectory prediction. Furthermore, mixture density network is augmented in the model to handle uncertainties in the predicted trajectories. The proposed model’s performance is compared with several state-of-the-art models on real-world Next Generation Simulation (NGSIM) dataset. The results indicate the superiority of the proposed model over all contemporary state-of-the-art models, as evaluated using Root Mean Square Error (RMSE) metric. The proposed model predicts a 5s long trajectory with an 11% lower RMSE than the state-of-the-art model. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Sharma2024Transformer
ER  -

TY  - JOUR
AU  - Pereira, J.A.
AU  - Pereira, J.A.
AU  - Zanchettin, C.
AU  - do Nascimento Fidalgo, R.
TI  - PrAACT: Predictive Augmentative and Alternative Communication with Transformers[Formula presented]
PY  - 2024
T2  - Expert Systems with Applications
VL  - 240
C7  - 122417
DO  - 10.1016/j.eswa.2023.122417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177759947&doi=10.1016%2fj.eswa.2023.122417&partnerID=40&md5=d7967926859674cf48435b4c744106ee
AB  - Augmentative and Alternative Communication (AAC) systems assist individuals with complex communication needs, allowing them to construct sentences by selecting communication cards. The facilitation of sentence construction primarily entails enabling efficient communication card selection. An approach to this involves using language models for communication card prediction. Nonetheless, the heterogeneity of the AAC population poses unique challenges due to diverse vocabulary needs, suggesting one-size-fits-all approaches may be insufficient. This study introduces PrAACT, a method that leverages large, transformer-based language models, such as BERT, for communication card prediction. This method focuses on easy adaptability to incorporate user-specific vocabularies into the model. The method involves adapting a text corpus to the AAC domain, fine-tuning a transformer-based language model, and replacing the language model weights with an encoded representation of the user's vocabulary. We conducted an assessment of PrAACT under both zero-shot and few-shot scenarios. The performance of the models produced using PrAACT was superior to those pre-trained for the task. In addition, the main advantage of PrAACT is that it allows to quickly adapt a transformer-based language model to communication card prediction according to the user's vocabulary. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Pereira2024PrAACT
ER  -

TY  - JOUR
AU  - Wu, D.
AU  - Peng, K.
AU  - Wang, S.
AU  - Leung, V.C.M.
TI  - Spatial-Temporal Graph Attention Gated Recurrent Transformer Network for Traffic Flow Forecasting
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 8
SP  - 14267
EP  - 14281
DO  - 10.1109/JIOT.2023.3340182
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179811864&doi=10.1109%2fJIOT.2023.3340182&partnerID=40&md5=3236fe230f13777aa809bd410e8003ca
AB  - With the significant increase in the number of motor vehicles, road-related issues, such as traffic congestion and accidents, have also escalated. The development of an accurate and efficient traffic flow forecasting model is essential for helping car owners plan their journeys. Despite advancements in forecasting models, there are three remaining issues: 1) failing to effectively use cyclical data; 2) failing to adequately capture spatial dependencies; and 3) high-time complexity and memory usage. To tackle the aforementioned challenges, we present a novel spatial-temporal graph attention gated recurrent transformer network (STGAGRTN) for traffic flow forecasting. Specifically, the use of a spatial transformer module allows for the extraction of dynamic spatial dependencies among individual nodes, going beyond the limitation of only considering neighboring nodes. Subsequently, we propose a temporal transformer to extract periodic information from traffic data and capture long-term dependencies. Additionally, we utilize two additional classical techniques to complement the aforementioned modules for extracting characteristics. By incorporating comprehensive spatial-temporal characteristics into our model, we can accurately predict multiple nodes simultaneously. Finally, we have successfully optimized the computational complexity of the transformer module from \mathcal {O}(n{2}) to \mathcal {O}(n \log n). Our model has undergone extensive testing on four authentic data sets, providing compelling evidence of its superior predictive capabilities. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Wu2024Spatial-Temporal
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Zhao, Y.
AU  - Wang, S.
AU  - Wei, J.
TI  - TransDiff: medical image segmentation method based on Swin Transformer with diffusion probabilistic model
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 8
SP  - 6543
EP  - 6557
DO  - 10.1007/s10489-024-05496-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193278129&doi=10.1007%2fs10489-024-05496-w&partnerID=40&md5=f22c3d5ed17899695194b43a5d9af57a
AB  - Medical image segmentation can provide a reliable basis for clinical analysis and diagnosis. However, this task is challenging due to the low contrast, boundary ambiguity between organs or lesions and surrounding tissues, and noise interference of images. To address this challenge, which is unique to medical images, and further improve the segmentation accuracy and precision, a medical image segmentation model (TransDiff) is proposed from the perspective of improving model robustness and enriching semantic information. TransDiff comprises three parts: a variational autoencoder (VAE), a diffusion transformer model and a Swin Transformer. The VAE constructs a latent space to provide an environment for fully extracting and fusing features. The diffusion model predicts and removes noise by inferring semantics through the propagation of information between nodes. The Swin Transformer enriches discriminative features as a conditional part. TransDiff inherits the robustness to noise and missing data of the diffusion model and the feature enrichment of the Swin Transformer, thus exhibiting a higher understanding of semantic information. It performs well on medical datasets with three different image modalities, outperforms existing medical image segmentation methods in terms of segmentation precision and accuracy, and has good generalizability. The codes and trained models will be publicly available at https://github.com/xiaoxiao1997/TransDiff. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liu2024TransDiff
ER  -

TY  - JOUR
AU  - Shen, L.
AU  - Wei, Y.
AU  - Wang, Y.
AU  - Qiu, H.
TI  - Take an Irregular Route: Enhance the Decoder of Time-Series Forecasting Transformer
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 8
SP  - 14344
EP  - 14356
DO  - 10.1109/JIOT.2023.3341099
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179798915&doi=10.1109%2fJIOT.2023.3341099&partnerID=40&md5=223ace244e4f6a384a7656a31f868ce8
AB  - With the development of Internet of Things (IoT) systems, precise long-term forecasting method is requisite for decision makers to evaluate current statuses and formulate future policies. Currently, transformer and MLP are two paradigms for deep time-series forecasting and the former one is more prevailing in virtue of its exquisite attention mechanism and encoder-decoder architecture. However, data scientists seem to be more willing to dive into the research of encoder, leaving decoder unconcerned. Some researchers even adopt linear projections in lieu of the decoder to reduce the complexity. We argue that both extracting the features of input sequence and seeking the relations of input and prediction sequence, which are respective functions of encoder and decoder, are of paramount significance. Motivated from the success of FPN in CV field, we propose FPPformer to utilize bottom-up and top-down architectures, respectively, in encoder and decoder to build the full and rational hierarchy. The cutting-edge patchwise attention is exploited and further developed with the combination, whose format is also different in encoder and decoder, of revamped elementwise attention in this work. Extensive experiments with six state-of-the-art baselines on twelve benchmarks verify the promising performances of FPPformer and the importance of elaborately devising decoder in time-series forecasting transformer. The source code is released in https://github.com/OrigamiSL/FPPformer. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Shen2024Take
ER  -

TY  - JOUR
AU  - Lv, G.
AU  - Ding, Y.
AU  - Chen, X.
AU  - Zheng, Y.
TI  - MP2PMatch: A Mask-guided Part-to-Part Matching network based on transformer for occluded person re-identification
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 100
C7  - 104128
DO  - 10.1016/j.jvcir.2024.104128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189039850&doi=10.1016%2fj.jvcir.2024.104128&partnerID=40&md5=1d5e60980d74c56417b666a4a8435ea1
AB  - Occluded person re-identification (ReID) remains challenging due to the misaligned body parts. Existing works, mainly utilizing extra clues, excel in predicting holistic person images but falter when confronting substantial occlusion. This paper proposes a transformer-based Mask-guided Part-to-Part Matching (MP2PMatch) network for fine-grained matching. Firstly, the Consistency Occlusion Augmentation (COA) processes holistic person images and corresponding body part masks to construct occluded “image-mask” pairs. Next, we introduce learnable part tokens to capture semantic features of various body parts, performing “pull close” and “push apart” operations based on identity labels and part visibility, ensuring the one-to-one correspondence between part features and body parts. Additionally, the proposed Body Region Attention (BRA) utilizes the overall attention on body regions to guide the network to overcome interference from both occlusion and background. Extensive experiments demonstrate that MP2PMatch achieves exceptional occluded ReID performance. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Lv2024MP2PMatch
ER  -

TY  - JOUR
AU  - Xing, Z.
AU  - Zhu, L.
AU  - Yu, L.
AU  - Xing, Z.
AU  - Wan, L.
TI  - Hybrid Masked Image Modeling for 3D Medical Image Segmentation
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 4
SP  - 2115
EP  - 2125
DO  - 10.1109/JBHI.2024.3360239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184315889&doi=10.1109%2fJBHI.2024.3360239&partnerID=40&md5=8a902625fcffb86831b2fc9d21c06d02
AB  - Masked image modeling (MIM) with transformer backbones has recently been exploited as a powerful self-supervised pre-training technique. The existing MIM methods adopt the strategy to mask random patches of the image and reconstruct the missing pixels, which only considers semantic information at a lower level, and causes a long pre-training time. This paper presents HybridMIM, a novel hybrid self-supervised learning method based on masked image modeling for 3D medical image segmentation. Specifically, we design a two-level masking hierarchy to specify which and how patches in sub-volumes are masked, effectively providing the constraints of higher level semantic information. Then we learn the semantic information of medical images at three levels, including: 1) partial region prediction to reconstruct key contents of the 3D image, which largely reduces the pre-training time burden (pixel-level); 2) patch-masking perception to learn the spatial relationship between the patches in each sub-volume (region-level); and 3) drop-out-based contrastive learning between samples within a mini-batch, which further improves the generalization ability of the framework (sample-level). The proposed framework is versatile to support both CNN and transformer as encoder backbones, and also enables to pre-train decoders for image segmentation. We conduct comprehensive experiments on five widely-used public medical image segmentation datasets, including BraTS2020, BTCV, MSD Liver, MSD Spleen, and BraTS2023. The experimental results show the clear superiority of HybridMIM against competing supervised methods, masked pre-training approaches, and other self-supervised methods, in terms of quantitative metrics, speed performance and qualitative observations.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Xing2024Hybrid
ER  -

TY  - JOUR
AU  - Huang, J.
AU  - Chen, Z.
AU  - Ma, Y.
AU  - Fan, F.
AU  - Tang, L.
AU  - Xiang, X.
TI  - PTET: A progressive token exchanging transformer for infrared and visible image fusion
PY  - 2024
T2  - Image and Vision Computing
VL  - 144
C7  - 104957
DO  - 10.1016/j.imavis.2024.104957
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186316298&doi=10.1016%2fj.imavis.2024.104957&partnerID=40&md5=85ae6762635de9873d3b218794938c95
AB  - Integrating complementary information from different modalities is one of the key challenges in image fusion. Most of the existing deep learning-based methods still rely on a one-off fusion layer to integrate the features extracted from two modalities into one. Such an information interaction pattern only considers significant feature integration but neglects the removal of hazardous information that is widely present in the source images. To overcome these limitations, we propose a progressive token exchanging Transformer for infrared and visible image fusion, named PTET. Different from the one-time fusion layer, we devise a progressive token exchange strategy to gradually transfer features from source images and remove harmful information simultaneously. A predictor is utilized to assess the saliency of Transformer tokens from both modalities. Afterwards, an exchanger is designed to perform beneficial token transfer and insignificant token elimination. Through the cascading layers, our network enhances the feature of fusion branch in a progressive manner. Innovative exchange loss and rank loss are introduced to constrain the fusion network. Extensive experiments on MSRS and LLVIP datasets demonstrate the superiority of our PTET compared to nine state-of-the-art alternatives. Visualization of token exchanging strategy and ablation study reveals the effectiveness of our designs. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Huang2024PTET
ER  -

TY  - JOUR
AU  - Almodovar, C.
AU  - Sabrina, F.
AU  - Karimi, S.
AU  - Azad, S.
TI  - LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
VL  - 21
IS  - 2
SP  - 1715
EP  - 1723
DO  - 10.1109/TNSM.2024.3358730
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183971853&doi=10.1109%2fTNSM.2024.3358730&partnerID=40&md5=5096da30ccadcb30474e6125e6b4fdd3
AB  - System logs are a valuable source of information for monitoring and maintaining the security and stability of computer systems. Techniques based on Deep Learning and Natural Language Processing have demonstrated effectiveness in detecting abnormal behaviour from these system logs. However, existing anomaly detection approaches have limitations in terms of flexibility and practicality. Techniques that rely on log templates such as DeepLog and LogBERT fail to capture semantic information and are unable to handle variability in log content. On the other hand, classification-based approaches such as LogSy, LogRobust and HitAnomaly require time-consuming data labelling for supervised training. In this paper, a novel log anomaly detection model named LogFiT is proposed. The LogFiT model doesn't make use of a vocabulary of log templates and it doesn't require any labeled data as the model only requires self-supervised training. The LogFiT model uses a pretrained Bidirectional Encoder Representations from Transformers (BERT)-based language model fine-tuned to recognise the linguistic patterns of the normal log data. The LogFiT model is trained using masked sentence prediction on the normal log data only. Consequently, when presented with the new log data, the model's top-{k} token prediction accuracy serves as a threshold for determining whether the new log data deviates from the normal log data. Experimental results show that LogFiT's F1 score exceeds that of baselines on the HDFS, BGL, and Thunderbird datasets. Critically, when variability is introduced in the log data during evaluation, LogFiT retains its effectiveness compared to that of baselines.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Almodovar2024LogFiT
ER  -

TY  - JOUR
AU  - Kwong, N.-W.
AU  - Chan, Y.-L.
AU  - Tsang, S.-H.
AU  - Huang, Z.
AU  - Lam, K.-M.
TI  - Spatiotemporal feature learning for no-reference gaming content video quality assessment
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 100
C7  - 104118
DO  - 10.1016/j.jvcir.2024.104118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187780566&doi=10.1016%2fj.jvcir.2024.104118&partnerID=40&md5=50a07b1114549c0474c53f381d7dd90c
AB  - Recently, over-the-top live gaming content video (GCV) services have significantly contributed to the overall internet traffic. Consequently, there is a growing demand of GCV quality assessment (GCVQA) to maintain service quality. Although recent literature has proposed a few GCVQA methods, these mainly focus on extracting spatial features and temporal fusion separately, limiting their performance due to the neglect of spatiotemporal feature learning, which is crucial for GCV as it typically shares spatial and temporal features across frames. To address this, we propose a novel GCVQA model, focusing on GCV spatiotemporal feature learning. First, we employ a multi-task self-supervised learning spatiotemporal pyramid convolutional neural network (STP-CNN) model to extract short-term spatiotemporal quality feature representations (STQFR) of GCVs. Our STP-CNN model specifically extracts multiscale spatiotemporal features from various temporal scales of multi-frames in pyramid mode, enabling dynamic learning of diverse spatiotemporal cues. Subsequently, we propose the differential Transformer model to process all short-term STQFR within a GCV, extracting global spatiotemporal features of GCV to assess the overall quality of GCV. To evaluate the effectiveness of our proposed method, we conducted experiments using four GCVQA datasets. The results demonstrate that our method outperforms existing approaches in predicting the perceived quality of GCV. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Kwong2024Spatiotemporal
ER  -

TY  - JOUR
AU  - Wang, H.-K.
AU  - Zhang, X.
AU  - Long, H.
AU  - Yao, S.
AU  - Zhu, P.
TI  - W-FENet: Wavelet-based Fourier-Enhanced Network Model Decomposition for Multivariate Long-Term Time-Series Forecasting
PY  - 2024
T2  - Neural Processing Letters
VL  - 56
IS  - 2
C7  - 43
DO  - 10.1007/s11063-024-11478-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185268737&doi=10.1007%2fs11063-024-11478-3&partnerID=40&md5=8a4aba90002e7cd8e80e8ce59fae82f3
AB  - Accurately predicting the future trend of a time series holds immense importance for decision-making and planning across various domains, including energy planning, weather forecasting, traffic warning, and other practical applications. Recently, deep learning methods based on transformers and time convolution networks (TCN) have achieved a surprising performance in long-term sequence prediction. However, the attention mechanism for calculating global correlation is highly complex, and TCN methods do not fully consider the characteristics of time-series data. To address these challenges, we introduce a new learning model named wavelet-based Fourier-enhanced network model decomposition (W-FENet). Specifically, we have used trend decomposition and wavelet transform to decompose the original data. This processed time-series data can then be more effectively analyzed by the model and mined for different components in the series, as well as capture the local details and overall trendiness of the series. An efficient feature extraction method, Fourier enhancement-based feature extraction (FEMEX), is introduced in our model. The mechanism converts time-domain information into frequency-domain information through a Fourier enhancement module, and the obtained frequency-domain information is better captured by the model than the original time-domain information in terms of periodicity, trend, and frequency features. Experiments on multiple benchmark datasets show that, compared with the state-of-the-art methods, the MSE and MAE of our model are improved by 11.1 and 6.36% on average, respectively, covering three applications (i.e. ETT, Exchange, and Weather). © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2024W-FENet
ER  -

TY  - JOUR
AU  - Fan, W.
AU  - He, Y.
AU  - Zhu, F.
TI  - RM-GPT: Enhance the comprehensive generative ability of molecular GPT model via LocalRNN and RealFormer
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 150
C7  - 102827
DO  - 10.1016/j.artmed.2024.102827
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186658776&doi=10.1016%2fj.artmed.2024.102827&partnerID=40&md5=3fea7ea537e9ad5ce81c049c518e9b98
AB  - Due to the surging of cost, artificial intelligence-assisted de novo drug design has supplanted conventional methods and become an emerging option for drug discovery. Although there have arisen many successful examples of applying generative models to the molecular field, these methods struggle to deal with conditional generation that meet chemists’ practical requirements which ask for a controllable process to generate new molecules or optimize basic molecules with appointed conditions. To address this problem, a Recurrent Molecular-Generative Pretrained Transformer model is proposed, supplemented by LocalRNN and Residual Attention Layer Transformer, referred to as RM-GPT. RM-GPT rebuilds GPT model's architecture by incorporating LocalRNN and Residual Attention Layer Transformer so that it is able to extract local information and build connectivity between attention blocks. The incorporation of Transformer in these two modules enables leveraging the parallel computing advantages of multi-head attention mechanisms while extracting local structural information effectively. Through exploring and learning in a large chemical space, RM-GPT absorbs the ability to generate drug-like molecules with conditions in demand, such as desired properties and scaffolds, precisely and stably. RM-GPT achieved better results than SOTA methods on conditional generation. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Fan2024RM-GPT
ER  -

TY  - JOUR
AU  - Alkhodari, M.
AU  - Hadjileontiadis, L.J.
AU  - Khandoker, A.H.
TI  - Identification of Congenital Valvular Murmurs in Young Patients Using Deep Learning-Based Attention Transformers and Phonocardiograms
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 4
SP  - 1803
EP  - 1814
DO  - 10.1109/JBHI.2024.3357506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183941562&doi=10.1109%2fJBHI.2024.3357506&partnerID=40&md5=361ef0fe03630404df1d9366b51cd806
AB  - One in every four newborns suffers from congenital heart disease (CHD) that causes defects in the heart structure. The current gold-standard assessment technique, echocardiography, causes delays in the diagnosis owing to the need for experts who vary markedly in their ability to detect and interpret pathological patterns. Moreover, echo is still causing cost difficulties for low- and middle-income countries. Here, we developed a deep learning-based attention transformer model to automate the detection of heart murmurs caused by CHD at an early stage of life using cost-effective and widely available phonocardiography (PCG). PCG recordings were obtained from 942 young patients at four major auscultation locations, including the aortic valve (AV), mitral valve (MV), pulmonary valve (PV), and tricuspid valve (TV), and they were annotated by experts as absent, present, or unknown murmurs. A transformation to wavelet features was performed to reduce the dimensionality before the deep learning stage for inferring the medical condition. The performance was validated through 10-fold cross-validation and yielded an average accuracy and sensitivity of 90.23% and 72.41%, respectively. The accuracy of discriminating between murmurs' absence and presence reached 76.10% when evaluated on unseen data. The model had accuracies of 70%, 88%, and 86% in predicting murmur presence in infants, children, and adolescents, respectively. The interpretation of the model revealed proper discrimination between the learned attributes, and AV channel was found important (score > 0.75) for the murmur absence predictions while MV and TV were more important for murmur presence predictions. The findings potentiate deep learning as a powerful front-line tool for inferring CHD status in PCG recordings leveraging early detection of heart anomalies in young people. It is suggested as a tool that can be used independently from high-cost machinery or expert assessment.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Alkhodari2024Identification
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Ma, Y.
AU  - Zhang, W.
AU  - Zhao, X.
AU  - Zhao, X.
TI  - Learning on sample-efficient and label-efficient multi-view cardiac data with graph transformer
PY  - 2024
T2  - Pattern Recognition Letters
VL  - 180
SP  - 127
EP  - 133
DO  - 10.1016/j.patrec.2024.03.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188435498&doi=10.1016%2fj.patrec.2024.03.001&partnerID=40&md5=dcb866232862f0979585c68290b09ca4
AB  - Predicting cardiovascular disease has been a challenging task, as assessing samples based on a single view of information may be insufficient. Therefore, in this paper, we focus on the challenge of predicting cardiovascular disease using multi-view cardiac data. However, multi-view cardiac data is usually difficult to collect and label. Based on this motivation, learning an effective predictive model on sample-efficient and label-efficient multi-view cardiac data is urgently needed. To address the aforementioned issues, we propose a multi-view learning method: (i) our method utilizes graph learning to establish and extract relationships between data, enabling learning from a small number of labeled data and a small number of samples; (ii) our method integrates features from multiple views to utilize complementary information in the data; (iii) for data without a provided graph of relationships between samples, we utilize the mechanism of transformers to learn the relationships between samples in a data-driven manner. We validate the effectiveness of our method on real heart disease datasets. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Learning
ER  -

TY  - JOUR
AU  - Aslam, N.
AU  - Kolekar, M.H.
TI  - TransGANomaly: Transformer based Generative Adversarial Network for Video Anomaly Detection
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 100
C7  - 104108
DO  - 10.1016/j.jvcir.2024.104108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186760292&doi=10.1016%2fj.jvcir.2024.104108&partnerID=40&md5=83f669d02cb76cbc98513b0f08122d01
AB  - Video anomaly detection aims to identify a set of abnormal events in videos. Deep reconstruction and prediction-based models have been employed to detect anomalies. Deep reconstruction models sometimes recreate the abnormal events along with the normal ones. However, the prediction-based approaches have demonstrated encouraging results. This paper presents a video vision transformer (ViViT) based generative adversarial network (GAN), TransGANomaly, a novel approach for detecting anomalies. The proposed framework is a video frame predictor and trained only on normal video data adversarially. The generator of the GAN is a ViViT network that receives 3D input tokens from the video snippets. The generator aims to predict the future frame based on past sequences. After that, the predicted and original frames are given to the model's discriminator for binary classification. Extensive experiments have been performed on UCSD Pedestrian, CUHK Avenue, and ShanghiaTech datasets to validate the efficacy of the proposed method. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Aslam2024TransGANomaly
ER  -

TY  - JOUR
AU  - Chang, B.
AU  - Li, J.
AU  - Ren, L.
AU  - Chen, Z.
TI  - Dual branch Transformer-CNN parametric filtering network for underwater image enhancement
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 100
C7  - 104131
DO  - 10.1016/j.jvcir.2024.104131
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189532657&doi=10.1016%2fj.jvcir.2024.104131&partnerID=40&md5=d50c7249de8c272498c8f1f6ae93a6ce
AB  - Due to the absorption and scattering of light on the water surface, underwater images often face challenges such as low contrast, color deviation, insufficient exposure, and blurred details, exacerbating the difficulty of underwater tasks. In recent years, underwater image enhancement has become increasingly crucial in marine applications. Among existing underwater enhancement methods, the focus has often been on pixel-level learning, which may lead to image noise and an inability to finely adjust the image. In this paper, we propose a dual-branch Transformer-CNN Parameter Filtering network for underwater image enhancement, referred to as DTCPF. Specifically, to better aggregate window information, we introduce an overlapping window self-attention module to enhance interaction between windows. Additionally, we employ an improved Transformer encoder and decoder, utilizing long-distance attention and reversible neural networks to extract low-frequency and high-frequency information from the image. Moreover, we introduce a regression parameter filtering group for regression prediction, using the predicted parameters to enhance the image and obtain a reliable underwater enhancement model. Our approach undergoes qualitative and quantitative analyses on four real underwater datasets, demonstrating outstanding performance. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chang2024Dual
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Cui, G.
AU  - Li, Z.
AU  - Zhao, J.
TI  - Lightweight Patch-Wise Casformer for dynamic scene deblurring
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 100
C7  - 104112
DO  - 10.1016/j.jvcir.2024.104112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187711969&doi=10.1016%2fj.jvcir.2024.104112&partnerID=40&md5=f82e7cec722306ac676ccb804f3cbd1f
AB  - In dynamic scenes, motion blur can often occur, which is non-uniform and can be difficult to remove. Recently, the Transformer has shown excellent performance in various image-related tasks such as classification, recognition, and segmentation. Using a Transformer-based backbone network has also shown potential advantages in image deblurring. However, the computational complexity of Transformers increases quadratically with spatial resolution, making it difficult to apply to high-resolution images. To address the above issue, we propose a cascade Transformer (Casformer) that consists of two key modules: Deep Separable Attention (DSA) and Double-Flow Gate (DFG). Our approach effectively reduces computational complexity while suppressing blurry information. Additionally, we discovered an inconsistency between training and testing images during the image restoration process. We addressed this issue by experimentally verifying an inference aggregation method (IAM) that independently predicts patches during inference to address the problem of imbalanced information distribution. Experimental results demonstrate that our design performs well on GoPro and other datasets, e.g. 29.20 dB PSNR on RealBlur-J, exceeding the previous state-of-the-art (SOTA) 0.14 dB. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chen2024Lightweight
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Ruan, S.
AU  - Huang, T.
AU  - Zhou, H.
AU  - Zhang, S.
AU  - Wang, Y.
AU  - Wang, L.
AU  - Huang, Z.
AU  - Liu, Y.
TI  - A lightweight multi-layer perceptron for efficient multivariate time series forecasting
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 288
C7  - 111463
DO  - 10.1016/j.knosys.2024.111463
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184840871&doi=10.1016%2fj.knosys.2024.111463&partnerID=40&md5=7e449bb8e4bf1b44cc07b787d6d949bd
AB  - Efficient and effective multivariate time series (MTS) forecasting is critical for real-world applications, such as traffic management and energy dispatching. Most of the current deep learning studies (e.g., Spatio-Temporal Graph Neural Networks and Transformers) fall short in a trade-off between performance and efficiency. Existing MTS forecasting studies have yet to fully and simultaneously address issues such as modelling both temporal and variate dependencies, as well as the temporal locality, hindering broader applications. In this paper, we propose a lightweight model, i.e., Time Series MLP (TSP). TSP is built upon MLP and relies on the PrecMLP with the proposed computationally free Precurrent mechanism to model both the variate dependency and temporal locality, thus being simple, effective and versatile. Extensive experiments show that TSP outperforms state-of-the-art methods on 16 datasets for both Long-term Time-series Forecasting and Traffic Forecasting tasks. Furthermore, it attains a significant reduction of at least 95.97% in practical training speed on the CPU. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; 
LB  - Wang2024lightweight
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Zhang, D.
AU  - Xie, Y.
AU  - Wulamu, A.
TI  - A multi-type semantic interaction and enhancement method for tax question understanding
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 130
C7  - 107783
DO  - 10.1016/j.engappai.2023.107783
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181151173&doi=10.1016%2fj.engappai.2023.107783&partnerID=40&md5=1874d8c4609733ce5506a691c3b66fd1
AB  - Problem classification serves as a fundamental process in a tax intelligence consulting system, enabling the categorization of user-posed questions according to their semantic attributes. This categorization is pivotal in ensuring accurate question comprehension. Nevertheless, the inclusion of intricate professional terminology and the frequent alterations in linguistic structures associated with tax-related matters may culminate in suboptimal classification outcomes and hinder the precise comprehension of user demands. To address these issues, we propose a multitype semantic interaction and enhancement method (MtSIEM) to classify tax related issues that integrates entity and nonentity semantics to represent the semantic features of tax-related domain issues. Specifically, a pretraining language model and multigram mechanism are adopted to enhance the feature extraction ability. A soft attention module is also simplified to allocate interaction information weights, thereby adaptively determining the importance of the feature elements. These three components are used to perform precise learning on the tax question data. Subsequently, a dynamic routing architecture is employed to capture the relationships between the different problem features, resulting in predictive vectors. A series of comparative experiments on tax question data demonstrated that the proposed model achieved a classification accuracy of approximately 94.46%, an improvement of 2.99% compared with the baseline. Therefore, the proposed model can be utilized to predict the semantic category of tax-related issues, assisting intelligent tax advisory systems in matching questions with the most relevant knowledge and professional domains, thereby enabling faster retrieval of pertinent information and enhancing the timeliness of responses. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024multi-type
ER  -

TY  - JOUR
AU  - Ryumina, E.
AU  - Markitantov, M.
AU  - Ryumin, D.
AU  - Karpov, A.
TI  - OCEAN-AI framework with EmoFormer cross-hemiface attention approach for personality traits assessment
PY  - 2024
T2  - Expert Systems with Applications
VL  - 239
C7  - 122441
DO  - 10.1016/j.eswa.2023.122441
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175688728&doi=10.1016%2fj.eswa.2023.122441&partnerID=40&md5=7c8f1c1d44333db9b2923b8136dbbd4d
AB  - Psychological and neurological studies earlier suggested that a personality type can be determined by the whole face as well as by its sides. This article discusses novel research using deep neural networks that address the features of both sides of the face (hemifaces) to assess the human's Big Five personality traits (PT). For this, we have developed a real-time approach called EmoFormer with cross-hemiface attention. The novelty of the presented approach lies in the confirmation that each hemiface exhibits high predictive capabilities in terms of human's PT distinction. Our approach is based on a novel mid-level emotional feature extractor for each hemiface and a cross-hemiface attention fusion strategy for hemiface feature aggregation. The consequent fusion of both hemifaces has outperformed the use of the whole face by the relative value of 3.6% in terms of Concordance Correlation Coefficient (0.634 vs. 0.612) on the ChaLearn First Impressions V2 corpus. The proposed approach has also outperformed all the existing state-of-the-art approaches for PT assessment based on the face modality. We have also analyzed the “best hemiface”, the one that predicts PT more accurately in terms of demographic characteristics (gender, ethnicity, and age). We have found that the best hemiface for two of the five PT (Openness to experience and Non-Neuroticism) is different depending on demographic characteristics. For the other three traits, the right hemiface is dominant for Extraversion, while the left one is more indicative of Conscientiousness and Agreeableness. These findings support previous psychological and neurological research. Besides, we provide an open-source framework referred to as OCEAN-AI that can be seamlessly integrated into expert systems with practical applications in various domains including healthcare, education, and human resources. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ryumina2024OCEAN-AI
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Wang, L.
TI  - Multi-granularity sequence generation for hierarchical image classification
PY  - 2024
T2  - Computational Visual Media
VL  - 10
IS  - 2
SP  - 243
EP  - 260
DO  - 10.1007/s41095-022-0332-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181257843&doi=10.1007%2fs41095-022-0332-2&partnerID=40&md5=bca88c3ce30fe9d901cd00d5678b6564
AB  - Hierarchical multi-granularity image classification is a challenging task that aims to tag each given image with multiple granularity labels simultaneously. Existing methods tend to overlook that different image regions contribute differently to label prediction at different granularities, and also insufficiently consider relationships between the hierarchical multi-granularity labels. We introduce a sequence-to-sequence mechanism to overcome these two problems and propose a multi-granularity sequence generation (MGSG) approach for the hierarchical multi-granularity image classification task. Specifically, we introduce a transformer architecture to encode the image into visual representation sequences. Next, we traverse the taxonomic tree and organize the multi-granularity labels into sequences, and vectorize them and add positional information. The proposed multi-granularity sequence generation method builds a decoder that takes visual representation sequences and semantic label embedding as inputs, and outputs the predicted multi-granularity label sequence. The decoder models dependencies and correlations between multi-granularity labels through a masked multi-head self-attention mechanism, and relates visual information to the semantic label information through a cross-modality attention mechanism. In this way, the proposed method preserves the relationships between labels at different granularity levels and takes into account the influence of different image regions on labels with different granularities. Evaluations on six public benchmarks qualitatively and quantitatively demonstrate the advantages of the proposed method. Our project is available at https://github.com/liuxindazz/mgsg .[Figure not available: see fulltext.] © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Liu2024Multi-granularity
ER  -

TY  - JOUR
AU  - Wei, C.
AU  - Fan, Y.
AU  - Zhang, J.
AU  - Jia, Z.
AU  - Yan, R.
TI  - Dynamic Relation Graph Learning for Time-Aware Service Recommendation
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
VL  - 21
IS  - 2
SP  - 1503
EP  - 1517
DO  - 10.1109/TNSM.2023.3325977
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174815944&doi=10.1109%2fTNSM.2023.3325977&partnerID=40&md5=f65b551b7373d0918ea68d3d925e50c7
AB  - Driven by Service-Oriented Computing, time-aware service recommendation aims to support personalized mashup development, adapting to the rapid shifts of users' dynamic preferences. Recently, users' social connections have shown significant benefits to time-aware service recommendation, and graph neural networks have demonstrated great success in learning the pattern of information flow among users. However, the current paradigm always presumes a given social network, which is not necessarily consistent with the similarities of service preferences among users and is expensive to collect for most service platforms. We propose a novel idea to learn the graph structure among historical mashups and make time-aware service recommendation for dynamic mashup creation collectively in a coupled framework. This idea raises two challenges, i.e., scalability and accuracy. To solve both challenges simultaneously, we introduce the Dynamic Relation Graph Learning (DRGL) framework for time-aware service recommendation. For scalability, our framework has a coarse-to-fine recalling strategy to learn the graph structure among the mashups, which enables the exploration of potential links among all historical mashups while maintaining a tractable amount of computation. For accuracy, we leverage recent advances in self-attention mechanisms to the mashup modeling and propose a transformer-based mashup encoder, which considers long-range dependencies in dense mashups for more accurate mashup representations. Extensive experiments show that the DRGL model consistently outperforms the state-of-the-art methods in terms of prediction accuracy for mashup creation.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wei2024Dynamic
ER  -

TY  - JOUR
AU  - Meng, H.
AU  - Yang, Q.
AU  - Zhou, J.
AU  - Gao, D.
TI  - An underwater organisms recognition method based on machine vision in complex marine environment
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 13
SP  - 38551
EP  - 38565
DO  - 10.1007/s11042-023-16995-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173736442&doi=10.1007%2fs11042-023-16995-2&partnerID=40&md5=a18a1531638045db54f95484076cb53c
AB  - To meet the requirements for parallelity and accuracy in marine biosensing, this article proposes an improved YOLOv5 algorithm based on lightweight enhanced networks. Before training improved models, UWCNN algorithms enhanced underwater target images to solve problems such as color deviation, image noise and image vagueness.In improving the YOLOv5 algorithm, this paper introduced, first, the Swin-Transformer main core module to improve the model’s generalization capabilities; secondly, the use of the EMA structure in the head prediction section and the introduction of the GAM attention mechanism in the main core to enhance the robustness of the model; and finally, the introducation of Focal-EIOU Loss for precision boundary frame regression efficient losses.The results showed that the detection speed improved by 2 points compared to the original YOLOv5 algorithm, with the AP of sea cucumber, sea urchins, scallops, and starfish increased by 14%, 1%,5% and 5% respectively, and the mAP increased 6.26%. Furthermore, the fps value has increased to 38.86 phases per second.The method is directly targeted at detection of shallow-sea organisms and can provide useful reference to the intelligent equipment of underwater robots. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Meng2024underwater
ER  -

TY  - JOUR
AU  - Huang, S.
AU  - Liu, Y.
TI  - FL-Net: A multi-scale cross-decomposition network with frequency external attention for long-term time series forecasting
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 288
C7  - 111473
DO  - 10.1016/j.knosys.2024.111473
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184762395&doi=10.1016%2fj.knosys.2024.111473&partnerID=40&md5=25eb38c22dc8842d80cda4857d22e655
AB  - Many real-world applications, such as energy consumption alerts and long-term traffic planning, require the prediction of data changes over extended horizons. Long-term time series forecasting (LTSF) demands methods with robust prediction capabilities. Recently, transformer-based methods have shown immense potential for LTSF. However, these methods rely heavily on positional encoding to maintain temporal information, inevitably leading to the loss of temporal patterns. Moreover, various self-attention mechanisms often capture only intrasequence features, requiring a greater ability to capture intersequence features. The quadratic complexities of time and memory render training challenging when dealing with lengthy input sequences. We propose FL-Net to enhance the accuracy of LTSF. To capture the seasonal and trend components in the time series accurately, FL-Net segments the input sequences into coarse-grained trends and seasonal components using moving averages. Two sets of encoders extract the temporal features from these components. Our proposed frequency external attention method utilizes two external, compact, learnable, and shared memories to learn and store the time- and frequency-domain features of the entire training set, demonstrating high efficiency in terms of linear complexity. Simultaneously, we propose a multi-scale cross-decomposition method that further decomposes trends and seasonal elements into finer-grained components, thereby enhancing the capability of the model to extract temporal features. Experimental results on nine real-world benchmark datasets demonstrate that FL-Net achieves higher prediction accuracy in long-term forecasting than state-of-the-art methods. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; 
LB  - Huang2024FL-Net
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Tian, S.
AU  - Yu, L.
AU  - Shi, X.
AU  - Wang, F.
TI  - Image-text fusion transformer network for sarcasm detection
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 14
SP  - 41895
EP  - 41909
DO  - 10.1007/s11042-023-17252-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174216927&doi=10.1007%2fs11042-023-17252-2&partnerID=40&md5=4c401c05c17c0c8f5d28b76646ce5d3c
AB  - Sarcasm is a sophisticated method to convey ideas. Usually, the literal meaning of a sarcasm message is the opposite of its true intent. The development of social platforms has enriched the way users express their thoughts. User-posted information now incorporates not only text but also images. Traditional Sarcasm detection methods rely solely on textual data, failing to leverage the valuable information provided by images. This limitation leads to incomplete information for sarcasm detection, thereby compromising the accuracy of detection results. To address this, the paper proposes a new image-text fusion Transformer network (ITFT-Net) for sarcasm detection. This model uses the Bidirectional Encoder Representations from Transformers (BERT) model to extract text features. Additionally, it introduces the ResNet-101 model with a Transformer Encoder block to extract image features. Due to the lack of adaptive correlation in multimodal feature fusion, a multimodal fusion Transformer Encoder (MFTE) module is designed to enhance the fusion of the image and text features. Finally, the fusion features, processed by the Transformer Encoder module, is utilized for prediction. Experimental results on public datasets have demonstrated that the proposed model outperforms the baseline model in terms of accuracy and F1 value by 0.75% and 0.69% respectively. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Liu2024Image-text
ER  -

TY  - JOUR
AU  - Peng, C.
AU  - Liu, Y.
AU  - Ouyang, Y.
AU  - Tang, Z.
AU  - Luo, L.
AU  - Gui, W.
TI  - Grade Prediction of Froth Flotation Based on Multistep Fusion Transformer Model
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 4
SP  - 6030
EP  - 6040
DO  - 10.1109/TII.2023.3342458
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181554700&doi=10.1109%2fTII.2023.3342458&partnerID=40&md5=8a2e3256ffab70e3eb68030ef9165786
AB  - Accurate and timely foam grade prediction plays an important role in the flotation foam industry process. However, the information between foam characteristic series and foam grade series at different sampling times often does not match, making the prediction result lagging behind. A multistep fusion transformer (MSFT) model is designed in this article. First, we extract multiple froth time series as input to correlate feature information and grade information under multiple time series, then, a self-attention structure is designed to fuse at multiple scales, which enhances the degree of information correlation under different time series, finally, the information matrix is passed through the fully connected layer to obtain the final prediction result. Compared with the existing froth grade network recurrent neural networks (RNN), long short-term memory (LSTM), gated recurrent unit, Transformer, Enc-Dec (RNN), feature reconstruction-regression, Siamese time series and difference (LSTM), and FlotationNet models, the MSFT model has reduced the baseline by 30.3%, 30.3%, 30%, 66.9%, 30%, 45.8%, 55.2%, and 52.5%, respectively, among all indicators. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Peng2024Grade
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Cao, Y.
AU  - Xu, H.
AU  - Huang, Y.
AU  - He, Q.
AU  - Chen, X.
AU  - Tang, X.
AU  - Liu, X.
TI  - Hidformer: Hierarchical dual-tower transformer using multi-scale mergence for long-term time series forecasting
PY  - 2024
T2  - Expert Systems with Applications
VL  - 239
C7  - 122412
DO  - 10.1016/j.eswa.2023.122412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176391575&doi=10.1016%2fj.eswa.2023.122412&partnerID=40&md5=3c96e5ab8f149df49e83b652ee9cbfe8
AB  - Long-term time series forecasting has received a lot of popularity because of its great practicality. It is also an extremely challenging task since it requires using limited observations to predict values in the long future accurately. Recent works have demonstrated that Transformer has strong potential for this task. However, the permutation-invariant property of the Transformer and some other prominent shortcomings in the current Transformer-based models, such as missing multi-scale local features and information from the frequency domain, significantly limit their performance. To improve the accuracy of the long-term time series forecasting, we propose a Transformer-based model called Hidformer. This model can either learn temporal dynamics from the time domain or discover particular patterns from the frequency domain. We also design a segment-and-merge architecture to provide semantic meanings for the inputs and help the model capture multi-scale local features. Besides, we replace Transformer's multi-head attention with highly-efficient recurrence and linear attention, which gives our model an advantage over other Transformer-based models in terms of computational efficiency. Extensive experiments are conducted on seven real-world benchmarks to verify the effectiveness of Hidformer. The experimental results show that Hidformer achieves 72 top-1 and 69 top-2 scores out of 88 configurations. It dramatically improves the prediction accuracy and outperforms the previous state-of-the-art, proving the superiority of our proposed method. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2024Hidformer
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Zhang, Y.
AU  - Zhang, W.
AU  - Zhao, S.
AU  - Piao, X.
AU  - Yin, B.
TI  - CSAT: Contrastive Sampling-Aggregating Transformer for Community Detection in Attribute-Missing Networks
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 2
SP  - 2277
EP  - 2290
DO  - 10.1109/TCSS.2023.3292145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167818102&doi=10.1109%2fTCSS.2023.3292145&partnerID=40&md5=d6d69a2a59472d712db500777da5960e
AB  - Community detection aims to identify dense subgroups of nodes within a network. However, in real-world networks, node attributes are often missing, making traditional methods less effective. In networks with missing attributes, the main challenge of community detection is to deal with the missing attribute information efficiently and use network structure information to make accurate predictions. This article proposes an innovative method called contrastive sampling-aggregating transformer (CSAT) for community detection in attribute-missing networks. CSAT incorporates the contrastive learning principle to capture hidden patterns among nodes and to aggregate information from different samples to create a more robust and accurate methodology for community detection. Specifically, CSAT utilizes a sampling and propagation strategy to obtain different samples and smooth attribute features of the network structure and leverages the Transformer architecture to model the pairwise relationships between nodes. Therefore, our method can address the attribute-missing issue by integrating the auxiliary information from both the network structure and other sources. Extensive experiments on several benchmark datasets demonstrate CSAT's superior performance compared to the state-of-the-art methods for community detection. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Li2024CSAT
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Ma, Y.
AU  - Schubert, M.
AU  - Ouyang, Y.
AU  - Rong, W.
AU  - Xiong, Z.
TI  - Multimodal Contrastive Transformer for Explainable Recommendation
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 2
SP  - 2632
EP  - 2643
DO  - 10.1109/TCSS.2023.3276273
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161019457&doi=10.1109%2fTCSS.2023.3276273&partnerID=40&md5=99d78b30f9243ab71cd27f4259f6dfd7
AB  - Explanations play an essential role in helping users evaluate results from recommender systems. Various natural language generation methods have been proposed to generate explanations for the recommendation. However, they usually suffer from two problems. First, since user-provided review text contains noisy data, the generated explanations may be irrelevant to the recommended items. Second, as lacking some supervision signals, most of the generated sentences are similar, which cannot meet the diversity and personalized needs of users. To tackle these problems, we propose a multimodal contrastive transformer (MMCT) model for an explainable recommendation, which incorporates multimodal information into the learning process, including sentiment features, item features, item images, and refined user reviews. Meanwhile, we propose a dynamic fusion mechanism during the decoding stage, which generates supervision signals to guide the explanation generation. Additionally, we develop a contrastive objective to generate diverse explainable texts. Comprehensive experiments on two real-world datasets show that the proposed model outperforms comparable explainable recommendation baselines in terms of explanation performance and recommendation performance. Efficiency analysis and robustness analysis verify the advantages of the proposed model. While ablation analysis establishes the relative contributions of the respective components and various modalities, the case study shows the working of our model from an intuitive sense.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Liu2024Multimodal
ER  -

TY  - JOUR
AU  - Ilias, L.
AU  - Mouzakitis, S.
AU  - Askounis, D.
TI  - Calibration of Transformer-Based Models for Identifying Stress and Depression in Social Media
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 2
SP  - 1979
EP  - 1990
DO  - 10.1109/TCSS.2023.3283009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162686923&doi=10.1109%2fTCSS.2023.3283009&partnerID=40&md5=959d36894f0dea4678590944e662f07d
AB  - In today's fast-paced world, the rates of stress and depression present a surge. People use social media for expressing their thoughts and feelings through posts. Therefore, social media provide assistance for the early detection of mental health conditions. Existing methods mainly introduce feature extraction approaches and train shallow machine learning (ML) classifiers. For addressing the need of creating a large feature set and obtaining better performance, other research studies use deep neural networks or language models based on transformers. Despite the fact that transformer-based models achieve noticeable improvements, they cannot often capture rich factual knowledge. Although there have been proposed a number of studies aiming to enhance the pretrained transformer-based models with extra information or additional modalities, no prior work has exploited these modifications for detecting stress and depression through social media. In addition, although the reliability of a machine learning (ML) model's confidence in its predictions is critical for high-risk applications, there is no prior work taken into consideration the model calibration. To resolve the above issues, we present the first study in the task of depression and stress detection in social media, which injects extra-linguistic information in transformer-based models, namely, bidirectional encoder representations from transformers (BERT) and MentalBERT. Specifically, the proposed approach employs a multimodal adaptation gate for creating the combined embeddings, which are given as input to a BERT (or MentalBERT) model. For taking into account the model calibration, we apply label smoothing. We test our proposed approaches in three publicly available datasets and demonstrate that the integration of linguistic features into transformer-based models presents a surge in performance. Also, the usage of label smoothing contributes to both the improvement of the model's performance and the calibration of the model. We finally perform a linguistic analysis of the posts and show differences in language between stressful and nonstressful texts, as well as depressive and nondepressive posts. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Ilias2024Calibration
ER  -

TY  - JOUR
AU  - Wu, S.
AU  - Yang, Y.
AU  - Zhang, F.
TI  - Medical Image Segmentation with Dual-Encoding and Multi-Level Feature Adaptive Fusion
PY  - 2024
T2  - International Journal of Pattern Recognition and Artificial Intelligence
VL  - 38
IS  - 4
C7  - 2454004
DO  - 10.1142/S0218001424540041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191547225&doi=10.1142%2fS0218001424540041&partnerID=40&md5=61ae0c64556ab9a78fa926eb37efca00
AB  - Purpose: Accurate segmentation of medical images is critical for disease diagnosis, surgical planning and prognostic assessment. TransUNet, a hybrid CNN-Transformer-based method, extracts local features using CNN and compensates for the lack of long-range dependencies through a self-attention mechanism. However, the initial focus on extracting local features from specific regions impacts the generation of subsequent global features, thus constraining the model's capacity to effectively capture a broader range of semantic information. Effective integration of local and global features plays a pivotal role in achieving precise and dense prediction. Therefore, we propose a novel hybrid CNN-Transformer-based method aimed at enhancing medical image segmentation. Approach: In this study, a dual-encoder parallel structure is used to enhance the feature representation of the input image. By introducing a multi-scale adaptive feature fusion module, a fine fusion of local features across perceptual domains is realized in the decoding process. The generalized convolutional block attention module helps to increase cross-channel interactions in layers with more channels, thus enabling the fusion of local features and global representations at different resolutions during the decoding process. Results: The proposed method achieves average DSC scores of 79.98%, 84.83% and 85.78% on the Synapse, ISIC2017 and Pediatric Pyelonephritis datasets, respectively. These scores are 2.5%, 0.56% and 0.42% higher than those of TransUNet. The best performance of 91.66% is observed on the ACDC dataset, representing improvements of 2.46% and 7.24% compared to HiFormer and DAE-Former, respectively. Conclusions: The experimental results show that the proposed model has a significant competitive advantage in terms of ACDC image segmentation performance. © 2024 World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2024Medical
ER  -

TY  - JOUR
AU  - Paeedeh, N.
AU  - Pratama, M.
AU  - Ma'sum, M.A.
AU  - Mayer, W.
AU  - Cao, Z.
AU  - Kowlczyk, R.
TI  - Cross-domain few-shot learning via adaptive transformer networks
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 288
C7  - 111458
DO  - 10.1016/j.knosys.2024.111458
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184742982&doi=10.1016%2fj.knosys.2024.111458&partnerID=40&md5=fef4a7cfb60cb36e120607823364391c
AB  - Most few-shot learning works rely on the same domain assumption between the base and the target tasks, hindering their practical applications. This paper proposes an adaptive transformer network (ADAPTER), a simple but effective solution for cross-domain few-shot learning where there exist large domain shifts between the base task and the target task. ADAPTER is built upon the idea of bidirectional cross-attention to learn transferable features between the two domains. The proposed architecture is trained with DINO to produce diverse, and less biased features to avoid the supervision collapse problem. Furthermore, the label smoothing approach is proposed to improve the consistency and reliability of the predictions by also considering the predicted labels of the close samples in the embedding space. The performance of ADAPTER is rigorously evaluated in the BSCD-FSL benchmarks in which it outperforms prior arts with significant margins. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Paeedeh2024Cross-domain
ER  -

TY  - JOUR
AU  - Yi, X.
AU  - Fu, Y.
AU  - Liu, R.
AU  - Zhang, H.
AU  - Hua, R.
TI  - TSGET: Two-Stage Global Enhanced Transformer for Automatic Radiology Report Generation
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 4
SP  - 2152
EP  - 2162
DO  - 10.1109/JBHI.2024.3350077
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182354601&doi=10.1109%2fJBHI.2024.3350077&partnerID=40&md5=10d3d4755ff0d0a1844f559721a0df93
AB  - Recently, automatic radiology report generation, which targets to generate multiple sentences that can accurately describe medical observations for given X-ray images, has gained increasing attention. Existing methods commonly employ the attention mechanism for accurate word generation. However, such attention-based methods fail to leverage useful image-level global features, thereby limiting the model's reasoning ability. To tackle this challenge, we propose two-stage global enhancement layers to facilitate the Transformer to generate more reliable reports from a global perspective. Specifically, the 1st Global Enhancement Layer (1st GEL) is designed to capture the global visual context features by establishing the relationships between image-level global features and previously generated words. The 2nd Global Enhancement Layer (2nd GEL) is devised to capture the region-global level features by building the relationships between image-level global features and region-level information. The experiments demonstrate that by integrating the aforementioned two-stage global enhancement layers into the Transformer model, our proposal achieves state-of-the-art (SOTA) performance on various Natural Language Generation (NLG) evaluation metrics. Further Clinical Efficacy (CE) evaluations also validate that our proposal is able to predict more critical information.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Yi2024TSGET
ER  -

TY  - JOUR
AU  - Zhu, H.
AU  - Wei, P.
AU  - Xu, Z.
TI  - A Spatio-Temporal Enhanced Graph-Transformer AutoEncoder embedded pose for anomaly detection
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 3
SP  - 405
EP  - 419
DO  - 10.1049/cvi2.12257
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177569090&doi=10.1049%2fcvi2.12257&partnerID=40&md5=c3ab736caabdbd02300937c659ce8705
AB  - Due to the robustness of skeleton data to human scale, illumination changes, dynamic camera views, and complex backgrounds, great progress has been made in skeleton-based video anomaly detection in recent years. The spatio-temporal graph convolutional network has been proven to be effective in modelling the spatio-temporal dependencies of non-Euclidean data such as human skeleton graphs, and the autoencoder based on this basic unit is widely used to model sequence features. However, due to the limitations of the convolution kernel, the model cannot capture the correlation between non-adjacent joints, and it is difficult to deal with long-term sequences, resulting in an insufficient understanding of behaviour. To address this issue, this paper applies the Transformer to the human skeleton and proposes the Spatio-Temporal Enhanced Graph-Transformer AutoEncoder (STEGT-AE) to improve the capability of modelling. In addition, the multi-memory model with skip connections is employed to provide different levels of coding features, thereby enhancing the ability of the model to distinguish similar heterogeneous behaviours. Furthermore, the STEGT-AE has a single encoder-double decoder architecture, which can improve the detection performance by the combining reconstruction and prediction error. The experimental results show that performances of STEGT-AE is significantly better than other advanced algorithms on four baseline datasets. © 2023 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhu2024Spatio-Temporal
ER  -

TY  - JOUR
AU  - Guo, Z.
AU  - Wei, B.
AU  - Liu, J.
AU  - Liu, X.
AU  - Zhang, Z.
AU  - Wang, Y.
TI  - USTST: unsupervised self-training similarity transfer for cross-domain facial expression recognition
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 14
SP  - 41703
EP  - 41723
DO  - 10.1007/s11042-023-17317-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174025086&doi=10.1007%2fs11042-023-17317-2&partnerID=40&md5=7bb24de8539aaba4b6b06fca06e26136
AB  - Facial expression recognition (FER) is one of the popular research topics in the field of computer vision. When most of the deep learning expression recognition methods that achieve satisfactory results with a single dataset are applied to a new dataset, additional costs result from labeling the new data. FER under cross-dataset also suffers from difficulties such as data discrepancy and expression ambiguity. To address these issues, we propose an Unsupervised Self-Training Similarity Transfer (USTST) method for cross-domain FER. The Cross-Swin-Transformer (CST) module is designed to extract features and assign greater attention weight to the similar regions of the source and target domain images. The Self-Training Resampling (STR) and the Knowledge Transfer (KT) modules are then constructed to improve the confidence of the model prediction for the target domain. We also design ambiguity suppression loss and cross-domain loss to improve the ability of the model to discriminate expressions while transferring knowledge across domains. The experimental results with the RAF-DB dataset as the source domain and the CK+, JAFFE, SFEW, FER2013 and ExpW datasets as the target domains, show that our approach achieves much higher performance than the state-of-the-art cross-domain FER methods, while requiring no labels of new datasets. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023. corrected publication 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Guo2024USTST
ER  -

TY  - JOUR
AU  - Wu, C.-C.
AU  - Chen, Y.-L.
AU  - Yeh, Y.-H.
TI  - A Deep Recommendation Model Considering the Impact of Time and Individual Diversity
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 2
SP  - 2558
EP  - 2569
DO  - 10.1109/TCSS.2023.3272633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160255300&doi=10.1109%2fTCSS.2023.3272633&partnerID=40&md5=68da2fb31bfbe461d060f568424b0858
AB  - Collaborative filtering (CF) technology has been widely used in recommendation systems. Usually, the latent factor model (LFM) is used as the basis for implementing CF recommendation in deep learning systems. This study differs from previous studies in two respects. First, for different target items, the user embedding vector should be dynamically adjusted according to the content of the target item. Therefore, we have added an attention mechanism to dynamically adjust the user's embedding vector. However, people's preferences usually change over time. Therefore, based on the above attention model, this study considers two time-decay functions to emphasize the user's recent preferences. The first decay function considers the situation where the recent rating is more important than the long ago rating. The second time-decay function considers the situation, whereby users generally prefer movies that have been released recently rather than movies that have been released a long time ago. By combining these two time-decay functions with the attention model, we propose a time-decay adaptive latent factor model (TDADLFM) model for item score prediction. This study applies this model to a dataset integrating Movielens-10M and HetRec2011 and proves that all three new considerations can improve recommendation performance.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wu2024Deep
ER  -

TY  - JOUR
AU  - Le, Y.
AU  - Xiao, S.
AU  - Xiao, Z.
AU  - Li, K.
TI  - Topology-aware Multi-task Learning Framework for Civil Case Judgment Prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122103
DO  - 10.1016/j.eswa.2023.122103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175460928&doi=10.1016%2fj.eswa.2023.122103&partnerID=40&md5=c9aa6af7201d70e91e977b3f68f6118a
AB  - The civil case judgment prediction (CCJP) task involves automatically determining whether the plea of a plaintiff should be supported by analyzing the given civil case materials. However, most existing studies usually rely on inadequate legal essential elements (e.g., fact descriptions and pleas), and are specifically designed for single-cause scenarios. Consequently, these methods struggle to generalize effectively to real courts, where civil cases involve more complicated legal elements and numerous causes. To resolve the above limitations, we present a novel Topology-aware Multi-task Learning framework, called TML. Concretely, TML adopts the transformer-family pre-trained language models (PLMs) as the backbone to capture the fine-grained semantic interactions among various legal elements. To exploit the structural information of the case, we collocate distinct special tokens for each legal element, and then extract the features of the case from different perspectives. Furthermore, to address multiple-cause scenarios, TML incorporates a multi-task learning paradigm to simultaneously predict multiple civil judicial subtasks (e.g., civil causes, civil law articles and final judgment of pleas). To utilize topological dependencies among subtasks, three parameter-free retrievers are integrated to establish inter-task connections. Extensive experiments are conducted on a real-world dataset, and the experimental results show the effectiveness of our proposed method. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Le2024Topology-aware
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Dai, C.
AU  - Wang, W.
AU  - Qiu, T.
TI  - Global–Local Association Discrepancy for Multivariate Time Series Anomaly Detection in IIoT
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 7
SP  - 11287
EP  - 11297
DO  - 10.1109/JIOT.2023.3330696
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177058592&doi=10.1109%2fJIOT.2023.3330696&partnerID=40&md5=99d235947c4ae28d9c23f25559877e3c
AB  - Detecting anomalies in multivariate time series (MTS) data collected from industrial Internet of Things (IIoT) systems is essential for a variety of applications, including smart manufacturing. Existing methods typically learn local spatiotemporal representations from nearby time points and neighboring nodes to reconstruct or predict sensor data. However, these local representations are insufficient to model the complex nonlinear topological relationships and dynamic temporal patterns of IIoT systems, which often results in a high-false alarm rate. To address this issue, we propose a new MTS anomaly detection framework called GLAD, which is based on the global-local association discrepancy. The key concept is to detect anomalies based on the difference between the global and local spatiotemporal associations of each data sample, as the association distribution of each data sample provides a more informative description. Specifically, we introduce a Gumbel-Softmax-based graph structure learning strategy to capture the global topological connections from data. Based on the topological graph structure, we utilize a graph attention network (GAT) and transformer to extract both the global and local spatiotemporal associations of each data sample. Finally, we leverage the global-local association discrepancy to effectively detect anomalies from normal data samples. Extensive experiments on five real-world data sets demonstrate the superiority of GLAD over other state-of-the-art methods.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Zhou2024Global–Local
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Liu, X.
AU  - Tao, W.
AU  - Zhang, L.
AU  - Zou, J.
AU  - Pan, Y.
AU  - Pan, Z.
TI  - Location and time embedded feature representation for spatiotemporal traffic prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 239
C7  - 122449
DO  - 10.1016/j.eswa.2023.122449
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176380144&doi=10.1016%2fj.eswa.2023.122449&partnerID=40&md5=fb797dce51f0e9cf3a03e0d43adfd1e0
AB  - As a fundamental spatiotemporal sequence forecasting problem, traffic prediction is pivotal in transportation management and urban computing. Nonetheless, the intricate and dynamic nature of spatiotemporal correlations presents significant obstacles in acquiring precise forecasts. Existing techniques utilize graph convolutional networks in conjunction with temporal modules, such as recurrent neural networks or transformer-based structures, to effectively extract spatiotemporal features. Unfortunately, current approaches struggle with outliers and fail to capture potential global correlations between different timestamps. In this study, we propose an innovative Spatio-Temporal Graph Convolution Network with Embedded location and time features (STEGCN) for traffic prediction problems, which can generate precise and prompt predictions. STEGCN effectively captures the complex interdependencies among location, time, and traffic volume by leveraging the TransD algorithm to embed their representations. For each timestamp, a graph convolution module is exploited to capture the spatial features, merged with the embeddings of location and time that serve as global external information. Then, we leverage a temporal module composed of 1-D convolutions to capture the spatiotemporal patterns. The traffic volume embedding is employed to constrain predictions within a reasonable range. Extensive experiments and rigorous analysis show that our STEGCN model outperforms state-of-the-art baselines, demonstrating exceptional performance and potential for practical application. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024Location
ER  -

TY  - JOUR
AU  - Sun, J.
AU  - Dodge, H.H.
AU  - Mahoor, M.H.
TI  - MC-ViViT: Multi-branch Classifier-ViViT to detect Mild Cognitive Impairment in older adults using facial videos
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121929
DO  - 10.1016/j.eswa.2023.121929
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173249557&doi=10.1016%2fj.eswa.2023.121929&partnerID=40&md5=a676d1f5acc199001508fb8a3aeeb4d9
AB  - Deep machine learning models including Convolutional Neural Networks (CNN) have been successful in the detection of Mild Cognitive Impairment (MCI) using medical images, questionnaires, and videos. This paper proposes a novel Multi-branch Classifier-Video Vision Transformer (MC-ViViT) model to distinguish MCI from those with normal cognition by analyzing facial features. The data comes from the I-CONECT, a behavioral intervention trial aimed at improving cognitive function by providing frequent video chats. MC-ViViT extracts spatiotemporal features of videos in one branch and augments representations by the MC module. The I-CONECT dataset is challenging as the dataset is imbalanced containing Hard-Easy and Positive–Negative samples, which impedes the performance of MC-ViViT. We propose a loss function for Hard-Easy and Positive–Negative Samples (HP Loss) by combining Focal loss and AD-CORRE loss to address the imbalanced problem. Our experimental results on the I-CONECT dataset show the great potential of MC-ViViT in predicting MCI with a high accuracy of 90.63% accuracy on some of the interview videos. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Sun2024MC-ViViT
ER  -

TY  - JOUR
AU  - Shen, X.
AU  - Chen, J.
AU  - Zhu, S.
AU  - Yan, R.
TI  - A decentralized federated learning-based spatial–temporal model for freight traffic speed forecasting
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122302
DO  - 10.1016/j.eswa.2023.122302
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175150837&doi=10.1016%2fj.eswa.2023.122302&partnerID=40&md5=a8b8ebe7a1a2ae92ff7395003e0fbc85
AB  - Accurately understanding the spatial–temporal information of future freight traffic speed in the metropolitan area is of vital importance to formulate freight-related traffic management strategies. In this study, we develop a novel decentralized federated learning-based spatial–temporal model for freight traffic speed forecasting while implementing collaborative training among multiple participants instead of requiring an exclusive cloud center server for centralized data processing. First, a tailored spatial–temporal transformer network is proposed to substitute the existing graph convolutional network for local personalized learning of each participant. Second, a decentralized federated learning model is designed to fuse local personalization models for freight traffic speed forecasting. The associated convergence properties are theoretically illustrated. rgb]0,0,0Finally, the experiments based on a real-world freight dataset of member cities in the Nanjing Metropolitan Area demonstrate that the proposed approach can accurately forecast freight traffic speed and outperform existing traffic speed forecasting methods, with the average improvement of 8.3% for MAE, 8.2% for RMSE, and 8.6% for MAPE respectively. The visualization results reveal that the proposed approach is able to effectively capture the internal spatial–temporal dependencies among urban regions from various neighboring cities, providing the insights for collaboratively developing proactive freight-related traffic management strategies. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Shen2024decentralized
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Wu, X.
AU  - Liu, Y.
AU  - Zhou, X.
AU  - Cao, Y.
AU  - Xu, Y.
AU  - Cui, L.
AU  - Miao, C.
TI  - Estimating package arrival time via heterogeneous hypergraph neural network
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121740
DO  - 10.1016/j.eswa.2023.121740
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173211338&doi=10.1016%2fj.eswa.2023.121740&partnerID=40&md5=0005a2ad820e175fa41213e9addf4435
AB  - Estimated Time of Arrival (ETA) for packages plays an essential role in intelligent logistics. As a classic ETA method, Origin–Destination-based (OD-based) ETA predicts the delivery time only based on the attributes (i.e., sender address, receiver address, seller, and payment time) of packages under the condition that the delivery route is unavailable. However, existing OD-based methods only exploit attributes associated with an individual order, which fails to model the higher-order interactions within orders and attributes, and fail to sufficiently exploit the graph-structure knowledge (i.e., relation of orders and attributes) and feature-based knowledge (i.e., statistical properties) of orders simultaneously, resulting in inaccurate predictions. In this paper, we propose a novel Heterogeneous HyperGraph Neural Network (H2GNN) for estimating package arrival time. Specifically, to better capture the high-order interactions within orders and attributes, we construct an order heterogeneous hypergraph that utilizes hyperedges to represent orders and nodes to represent order attributes. Besides, we extend the hypergraph learning for large-scale e-commerce data by Hyper-GraphSAGE. Overall, H2GNN can provide informatively representations of packages while preserving both structure-based knowledge learned by hypergraph and feature-based knowledge captured by Transformer. Experimental results on large-scale Alibaba logistics data demonstrate the superior performance of H2GNN compared to the baselines. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2024Estimating
ER  -

TY  - JOUR
AU  - Liu, Q.
AU  - Sang, H.
AU  - Wang, J.
AU  - Chen, W.
AU  - Liu, Y.
TI  - Non-probability sampling network based on anomaly pedestrian trajectory discrimination for pedestrian trajectory prediction
PY  - 2024
T2  - Image and Vision Computing
VL  - 143
C7  - 104954
DO  - 10.1016/j.imavis.2024.104954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185887897&doi=10.1016%2fj.imavis.2024.104954&partnerID=40&md5=5d98e32174d1ca6edb1b7028c94e0316
AB  - Pedestrian trajectory prediction in first-person view is an important support for achieving fully automated driving in cities. However, existing pedestrian trajectory prediction methods still have significant shortcomings in terms of pedestrian trajectory diversity, dynamic scene constraints, and dependence on long-term trajectory prediction. We proposes a non-probability sampling network based on pedestrian trajectory anomaly recognition (ADsampler) to predict multiple possible future pedestrian trajectories. First, by incorporating pose and optical flow information, ADsampler models the multi-dimensional motion characteristics of pedestrians based on observed trajectory information and discriminates trajectory states. The sampling range in the Gaussian latent space is determined based on the recognition results. Next, velocity and yaw information of the car are introduced to model the car's motion state. A subtraction fusion network is employed to remove redundant image feature constraints in highly dynamic scenes. Finally, ADsampler utilizes a novel trajectory decoding network that combines the position encoding capability of GRU with the long-term dependency capturing ability of Transformer to decode and predict the fused features. we evaluate our model on crowded videos in the public datasets JAAD, PIE, ETH and UCY. Experiments demonstrate that the proposed method outperforms state-of-the-art approaches in prediction accuracy. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Liu2024Non-probability
ER  -

TY  - JOUR
AU  - Weissenbacher, D.
AU  - Courtright, K.
AU  - Rawal, S.
AU  - Crane-Droesch, A.
AU  - O'Connor, K.
AU  - Kuhl, N.
AU  - Merlino, C.
AU  - Foxwell, A.
AU  - Haines, L.
AU  - Puhl, J.
AU  - Gonzalez-Hernandez, G.
TI  - Detecting goals of care conversations in clinical notes with active learning
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 151
C7  - 104618
DO  - 10.1016/j.jbi.2024.104618
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187206059&doi=10.1016%2fj.jbi.2024.104618&partnerID=40&md5=ba3ba1790abab884289a3867158fb1dd
AB  - Objective: Goals of care (GOC) discussions are an increasingly used quality metric in serious illness care and research. Wide variation in documentation practices within the Electronic Health Record (EHR) presents challenges for reliable measurement of GOC discussions. Novel natural language processing approaches are needed to capture GOC discussions documented in real-world samples of seriously ill hospitalized patients’ EHR notes, a corpus with a very low event prevalence. Methods: To automatically detect sentences documenting GOC discussions outside of dedicated GOC note types, we proposed an ensemble of classifiers aggregating the predictions of rule-based, feature-based, and three transformers-based classifiers. We trained our classifier on 600 manually annotated EHR notes among patients with serious illnesses. Our corpus exhibited an extremely imbalanced ratio between sentences discussing GOC and sentences that do not. This ratio challenges standard supervision methods to train a classifier. Therefore, we trained our classifier with active learning. Results: Using active learning, we reduced the annotation cost to fine-tune our ensemble by 70% while improving its performance in our test set of 176 EHR notes, with 0.557 F1-score for sentence classification and 0.629 for note classification. Conclusion: When classifying notes, with a true positive rate of 72% (13/18) and false positive rate of 8% (13/158), our performance may be sufficient for deploying our classifier in the EHR to facilitate bedside clinicians’ access to GOC conversations documented outside of dedicated notes types, without overburdening clinicians with false positives. Improvements are needed before using it to enrich trial populations or as an outcome measure. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Weissenbacher2024Detecting
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Yang, L.
AU  - Li, Z.
AU  - Yang, W.
AU  - Han, Z.
AU  - Guo, J.
AU  - Yu, J.
TI  - Multi-level relation learning for cross-domain few-shot hyperspectral image classification
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 5
SP  - 4392
EP  - 4410
DO  - 10.1007/s10489-024-05384-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188639658&doi=10.1007%2fs10489-024-05384-3&partnerID=40&md5=ae4b42b4b58da3c5014c6c6499d20069
AB  - Cross-domain few-shot hyperspectral image classification focuses on learning prior knowledge from a large number of labeled samples from source domains and then transferring the knowledge to the tasks which contain few labeled samples in target domains. Following the metric-based manner, many current methods first extract the features of the query and support samples, and then directly predict the classes of query samples according to their distance to the support samples or prototypes. The relations between samples have not been fully explored and utilized. Different from current works, this paper proposes to learn sample relations on different levels and take them into the model learning process, to improve the cross-domain few-shot hyperspectral image classification. Building on current method of "Deep Cross-Domain Few-Shot Learning for Hyperspectral Image Classification" which adopts a domain discriminator to deal with domain-level distribution difference, the proposed method applies contrastive learning to learn the class-level sample relations to obtain more discriminable sample features. In addition, it adopts a transformer based cross-attention learning module to learn the set-level sample relations and acquire the attention from query samples to support samples. Our experimental results have demonstrated the contribution of the multi-level relation learning mechanism for few-shot hyperspectral image classification when compared with the state of the art methods. All the codes are available at github https://github.com/HENULWY/STBDIP. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Liu2024Multi-level
ER  -

TY  - JOUR
AU  - Xu, S.
AU  - Chen, X.
AU  - Zheng, Y.
AU  - Zhou, G.
AU  - Chen, Y.
AU  - Zha, H.
AU  - Zhao, H.
TI  - ECT: Fine-grained edge detection with learned cause tokens
PY  - 2024
T2  - Image and Vision Computing
VL  - 143
C7  - 104947
DO  - 10.1016/j.imavis.2024.104947
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185840902&doi=10.1016%2fj.imavis.2024.104947&partnerID=40&md5=bbda5596d4036746fdc9660b24943b08
AB  - In this study, we tackle the challenging fine-grained edge detection task, which refers to predicting specific edges caused by reflectance, illumination, normal, and depth changes, respectively. Prior methods exploit multi-scale convolutional networks, which are limited in three aspects: (1) Convolutions are local operators while identifying the cause of edge formation requires looking at far away pixels. (2) Priors specific to edge cause are fixed in prediction heads. (3) Using separate networks for generic and fine-grained edge detection, and the constraint between them may be violated. To address these three issues, we propose a two-stage transformer-based network sequentially predicting generic edges and fine-grained edges, which has a global receptive field thanks to the attention mechanism. The prior knowledge of edge causes is formulated as four learnable cause tokens in a cause-aware decoder design. Furthermore, to encourage the consistency between generic edges and fine-grained edges, an edge aggregation and alignment loss is exploited. We evaluate our method on the public benchmark BSDS-RIND and several newly derived benchmarks, and achieve new state-of-the-art results. Our code, data, and models are publicly available at https://github.com/Daniellli/ECT.git. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xu2024ECT
ER  -

TY  - JOUR
AU  - Xiang, F.
AU  - Zhang, Y.
AU  - Zhang, S.
AU  - Wang, Z.
AU  - Qiu, L.
AU  - Choi, J.-H.
TI  - Bayesian gated-transformer model for risk-aware prediction of aero-engine remaining useful life
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121859
DO  - 10.1016/j.eswa.2023.121859
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173260608&doi=10.1016%2fj.eswa.2023.121859&partnerID=40&md5=a5e422faf2df550190f89b8c9a29c3a8
AB  - Remaining Useful Life (RUL) prediction plays a critical role in the prognostics and health management (PHM) for aero-engines. A variety of Deep Learning (DL) approaches have emerged for RUL prediction due to their flexibility of the architectures and superiority with nonlinear responses. The mainstream DL models usually focus on overall prediction accuracy, however, model reliability is actually the key impeding industrial applications. This paper proposes the Bayesian Gated-Transformer (BGT) model for reliable RUL prediction with quantified uncertainty. The BGT model is rooted in the transformer architecture and enhanced with the gated mechanism to balance between long-term trends and short-term patterns. Both the epistemic and aleatory uncertainties are quantified through the Bayesian setup of model weights and the introduced noise channel. The training of model weights is formulated with sampling-based variational inference which approximates the posterior of model uncertainty with Gaussian distributions. The BGT model has been applied to the NASA CMAPSS and N-CMAPSS datasets. Compared with alternative DL models, the BGT model demonstrates better or similar accuracy regarding overall prediction. The BGT model is capable of effective uncertainty quantification which enables risk-aware RUL prediction. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Xiang2024Bayesian
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Zhao, T.
AU  - Wang, S.
AU  - Li, X.
TI  - MDF-DMC: A stock prediction model combining multi-view stock data features with dynamic market correlation information
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122134
DO  - 10.1016/j.eswa.2023.122134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174970347&doi=10.1016%2fj.eswa.2023.122134&partnerID=40&md5=171b524ac56b08315832cd2321fa6e25
AB  - Using machine learning coupled with stock price data to predict stock price trends has attracted increasing attention from data mining and machine learning communities. An accurate prediction results can help investors reduce investment risks and improve investment returns. The research on correlation stocks is one of the most important directions among many studies. Due to the high volatility and randomness of stock data, the correlation between stocks changes over time, which makes the stock correlation in static correlation stock sets often inconsistent with reality. Furthermore, various raw data related to stocks contain sufficient stock history information to analyze the future trend of stocks, but traditional prediction models cannot make good use of this information, which restricts the learning ability of the model and reduces the prediction accuracy. In this paper, we propose a stock prediction model combining multi-view stock data features with dynamic market correlation information (MDF-DMC). The model extracts stock trend features by combining multi-view raw data of a single stock with a Multi-layer Perceptron Mixer (MLP-Mixer); The improved Transformer encoder learns the correlation between the stock to be predicted and all the selected stocks in the stock market dynamically and extracts the features of the market correlation. We have conducted a large number of experiments on a total of 578 stocks in the stock markets of China and the United States, and the results show that our model has achieved excellent accuracy and returns across all data sets. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yang2024MDF-DMC
ER  -

TY  - JOUR
AU  - Monteiro, N.R.C.
AU  - Oliveira, J.L.
AU  - Arrais, J.P.
TI  - TAG-DTA: Binding-region-guided strategy to predict drug-target affinity using transformers
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122334
DO  - 10.1016/j.eswa.2023.122334
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175161264&doi=10.1016%2fj.eswa.2023.122334&partnerID=40&md5=8f4fedf608eb7df1001c0dd1bef9dc74
AB  - The proper assessment of target-specific compound selectivity is paramount in the drug discovery context, promoting the identification of drug-target interactions (DTIs) and the discovery of potential leads. On that account, the accurate prediction of an unbiased drug-target binding affinity (DTA) metric is pivotal to understanding the binding process. Most in silico computational approaches, however, neglect the inter-dependency of the proteomics, chemical, and pharmacological spaces and the explainability during the model construction. Furthermore, these methods have yet to actively include information associated with binding pockets during the learning process, which is essential to DTA prediction performance and model explainability. In this study, we propose an end-to-end binding-region-guided Transformer-based architecture that simultaneously predicts the 1D binding pocket and the binding affinity of DTI pairs, where the prediction of the 1D binding pocket guides and conditions the prediction of DTA. This architecture uses 1D raw sequential and structural data to represent the proteins and compounds, respectively, and combines multiple Transformer-Encoder blocks to capture and learn the proteomics, chemical, and pharmacological contexts. The predicted 1D binding pocket conditions the attention mechanism of the Transformer-Encoder used to learn the pharmacological space in order to model the inter-dependency amongst binding-related positions. The results show that the proposed architecture, TAG-DTA, achieved the best performance in DTA prediction compared to state-of-the-art benchmarks, including in unknown subsets of the proteomics and chemical representation spaces. Moreover, the 1D binding pocket prediction increases the discriminative power and robustness of the aggregate representation of the pharmacological space and improves the DTA prediction performance. Overall, this research study validates the applicability of an end-to-end Transformer-based architecture in the context of drug discovery, and that combining computationally different yet contextually related tasks is critical to new findings in the DTI domain. Additionally, it shows that TAG-DTA is capable of providing increasing DTI and prediction understanding due to the nature of the attention blocks and prediction of the 1D binding pocket. The data and source code used in this study are available at: https://github.com/larngroup/TAG-DTA. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Monteiro2024TAG-DTA
ER  -

TY  - JOUR
AU  - Dang, M.
AU  - Liu, G.
AU  - Li, H.
AU  - Xu, Q.
AU  - Wang, X.
AU  - Pan, R.
TI  - Multi-object behaviour recognition based on object detection cascaded image classification in classroom scenes
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 6
SP  - 4935
EP  - 4951
DO  - 10.1007/s10489-024-05409-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190159890&doi=10.1007%2fs10489-024-05409-x&partnerID=40&md5=c9b5d965497773060fce15b88d18c27b
AB  - For multi-object behaviour recognition in classroom scenes, crowded objects have heavy occlusion, invisible keypoints, scale variation, which directly overwhelms the recognition performance. Due to the dense student objects and similar student behaviours, multi-object behaviour recognition brings great challenges. Therefore, we proposed multi-object behaviour recognition based on object detection cascaded image classification. Specifically, object detection extracts student objects, followed by Vision Transformer (ViT) classification of student behaviour. To ensure the accuracy of behaviour recognition, it is first necessary to improve the detection performance of object detection. This paper proposes the Shallow Auxiliary Module for object detection to assist the backbone network in extracting hybrid multi-scale feature information. The multi-scale and multi-channel feature information is fused to alleviate object overlap and scale variation. We propose a Scale Assignment Fusion Mechanism that non-heuristically guides objects to learn the optimal feature layer. Furthermore, the Anchor-free Dynamic Label Assignment can suppress the prediction of low-quality bounding boxes, stabling training and improving detection performance. The proposed student object detector achieves the state-of-the-art mAP50 of 88.03 and APl of 57.64, outperforming state-of-the-art object detection methods. Our multi-object behaviour recognition method achieves the recognition of four behaviour classes, which is significantly better than the results of other comparison methods. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Dang2024Multi-object
ER  -

TY  - JOUR
AU  - Sun, W.
AU  - Ma, Y.
AU  - Wang, R.
TI  - k-NN attention-based video vision transformer for action recognition
PY  - 2024
T2  - Neurocomputing
VL  - 574
C7  - 127256
DO  - 10.1016/j.neucom.2024.127256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183165396&doi=10.1016%2fj.neucom.2024.127256&partnerID=40&md5=e18454fee76c6bb4e054e5adc036ed22
AB  - Action Recognition aims to understand human behavior and predict a label for each action. Recently, Vision Transformer (ViT) has achieved remarkable performance on action recognition, which models the long sequences token over spatial and temporal index in a video. The fully-connected self-attention layer is the fundamental key in the vanilla Transformer. However, the redundant architecture of the vision Transformer model ignores the locality of video frame patches, which involves non-informative tokens and potentially leads to increased computational complexity. To solve this problem, we propose a k-NN attention-based Video Vision Transformer (k-ViViT) network for action recognition. We adopt k-NN attention to Video Vision Transformer (ViViT) instead of original self-attention, which can optimize the training process and neglect the irrelevant or noisy tokens in the input sequence. We conduct experiments on the UCF101 and HMDB51 datasets to verify the effectiveness of our model. The experimental results illustrate that the proposed k-ViViT achieves superior accuracy compared to several state-of-the-art models on these action recognition datasets. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Sun2024k-NN
ER  -

TY  - JOUR
AU  - Xie, J.
AU  - Liu, Z.
AU  - Li, G.
AU  - Song, Y.
TI  - Audio-visual saliency prediction with multisensory perception and integration
PY  - 2024
T2  - Image and Vision Computing
VL  - 143
C7  - 104955
DO  - 10.1016/j.imavis.2024.104955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186499102&doi=10.1016%2fj.imavis.2024.104955&partnerID=40&md5=9bcebbddf259bb74f9ac4677f5dcab09
AB  - Audio-visual saliency prediction (AVSP) is a task that aims to model human attention patterns in the perception of auditory and visual scenes. Given the challenges associated with perceiving and combining multi-modal saliency features from videos, this paper presents a multi-sensory framework for AVSP. This framework is designed to extract audio, motion and image saliency features and integrate them effectively, which can then serve as a general architecture for the AVSP task. To obtain multi-sensory information, we develop a three-stream encoder that extracts audio, motion and image saliency features. In particular, we utilize a pre-trained encoder with knowledge related to image saliency to extract saliency features for each frame. The image saliency features are then incorporated with motion features using a spatial attention module. For motion features, 3D convolutional neural networks (CNNs) like S3D are commonly used in AVSP models. However, these networks are unable to effectively capture the global motion relationship in videos. To tackle this problem, we incorporate Transformer- and MLP-based motion encoders into the AVSP models. To learn joint audio-visual representations, an audio-visual fusion block is exploited to enhance the correlation between audio and visual motion features under the supervision of a cosine similarity loss in a self-supervised manner. Finally, a multi-stage decoder integrates audio, motion and image saliency features to generate the final saliency map. We evaluate our methods on six audio-visual eye-tracking datasets. Experimental results demonstrate that our method achieves compelling performance compared to the state-of-the-art methods. The source code is available at https://github.com/oraclefina/MSPI. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Xie2024Audio-visual
ER  -

TY  - JOUR
AU  - Kabir, S.
AU  - Vranic, S.
AU  - Mahmood Al Saady, R.
AU  - Salman Khan, M.
AU  - Sarmun, R.
AU  - Alqahtani, A.
AU  - Abbas, T.O.
AU  - Chowdhury, M.E.H.
TI  - The utility of a deep learning-based approach in Her-2/neu assessment in breast cancer
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122051
DO  - 10.1016/j.eswa.2023.122051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175424135&doi=10.1016%2fj.eswa.2023.122051&partnerID=40&md5=2ade3d48540efdb3644d393d6c17701d
AB  - Introduction: HER-2/neu is a protein present on the surface of specific cancer cells and has been linked to the development and progression of certain cancer types. It is present in 15 to 20% of breast cancers and is clinically significant due to the availability of multiple anti-Her2 treatment options. Immunohistochemistry (IHC) is the most commonly used method to evaluate and quantify the expression of Her-2/neu. Although IHC is well-standardized in clinical practice, it is still subjected to inter-observer variability. Automating Her-2/neu scoring can improve accuracy, efficiency, consistency, and cost-effectiveness while reducing pathologists' workload. Materials and Methods: A deep learning-based automatic framework was utilized for the automatic detection of Her-2/neu score from whole slide images (WSI). The framework consists of three phases: identification of tumor patches, scoring of tumor patches, and Her-2/neu score prediction for whole slide images (WSI) based on the distribution of each score. This work used the dataset from the University of Warwick HER2 challenge contest. Two expert pathologists evaluated all 86 WSIs and assigned Her-2/neu scores to them. In addition, patches were generated from 50 WSIs and annotated individually by the pathologists. A total of 6641 extracted patches were generated out of which, 947 were labeled as 0, 327 as 1+, 1401 as 2+, 2950 as 3+, and 1016 were marked for discarding. Four pre-trained image classification models, namely DenseNet201, GoogleNet, MobileNet_v2, and a Vision Transformer based model, were fine-tuned, and tested on the generated patches. In order to predict the Her-2/neu score of the entire WSI, a random forest classifier was trained to predict the Her-2/neu score from the percentages of patches of each score present in the whole slide image. Results: In patch classification performances, the vision transformer-based model outperformed the other models by achieving an accuracy of 92.6% on tumor patch classification and 91.15% on patch score classification. The random forest classifier achieved an accuracy of 88% on four score classification (0, 1+, 2 + and 3 + ) and 96% on three score classification (0/1+, 2 + and 3 + ). Conclusion: The proposed deep learning-based framework for the automatic detection and evaluation of Her-2/neu expression in breast cancer obtained encouraging results. This framework has the potential to be used as a prognostic tool, providing a cost-effective and time-efficient alternative for generating clinically relevant results. However, additional research is required to assess the applicability of this pipeline in different contexts. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kabir2024utility
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Luo, S.
AU  - Pan, L.
AU  - Wu, Z.
TI  - Adapt to small-scale and long-term time series forecasting with enhanced multidimensional correlation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122203
DO  - 10.1016/j.eswa.2023.122203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174623097&doi=10.1016%2fj.eswa.2023.122203&partnerID=40&md5=cb8ca9301efc31d0fb8ba898491175e3
AB  - Multivariate time series forecasting aims to predict time series data comprising several linked variables or characteristics and is frequently used in stock forecasting, energy forecasting, etc. The tough task is to acquire further historical data to forecast future values while boosting the capacity to mine relationships between and within sequences. The existing methods neglect the weighted influence of various neighbors and relationships on the sequence instance, as well as the semantic information of the instance itself, making the inter-instance correlation measure inaccurate. Meanwhile, the length of the sequence input is limited and the variable features in the multivariate sequence are treated equally, short-term and multi-feature interference cannot be eliminated, causing the learnt time series features to deviate from the real features. In this work, we provide a Multivariate Time Series Forecasting model that emphasizes Relationships between and within sequences (MTSFR). Use the BERT model to characterize the text attributes of instances and construct basic semantic embeddings. Meanwhile, instance-level and relation-level attention are used to model topological relations among different instances. Computes the cross-correlation of multivariate sequences within instances and performs attention weighting for multivariate sequence encoding. And choose the Transformer model to realize the trend prediction of long-term multivariate series. Experimental results show that the F1 value of our approach achieves 68.50% and 74.66% under the CSI300 and S&P500 data sets respectively, both of which are superior to the SOTA technique. Furthermore, the model is suited for small-scale sequence relationship modeling and is effective at handling long-term multivariate sequence forecasting problems. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024Adapt
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Wang, Y.
AU  - Mo, L.
AU  - Li, C.
AU  - Xu, M.
AU  - Kong, W.
AU  - Dai, G.
TI  - Temporal-channel cascaded transformer for imagined handwriting character recognition
PY  - 2024
T2  - Neurocomputing
VL  - 573
C7  - 127243
DO  - 10.1016/j.neucom.2024.127243
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182707156&doi=10.1016%2fj.neucom.2024.127243&partnerID=40&md5=59585886deb59064fd2b8a2b938bffc1
AB  - Neuroelectric signals recorded by micro-electrodes reflect the spontaneous and rhythmic activities of brain neurons. Numerous deep learning frameworks have been designed for various neuroelectric signal decoding tasks, most of which are based on convolutional neural network (CNN) and recurrent neural network (RNN). However, neither CNNs or RNNs can perceive the global dependencies of neural activities in both time and channel dimensions. To address this issue, this paper presents a temporal-channel cascaded transformer network to decode the neural activities of imagined handwriting movements, which can perform imagined handwriting character recognition from spiking activity recorded by two micro-electrode arrays (MEAs). Specifically, we design a temporal-channel cascaded framework and a dense residual transformer encoder structure, which can promote the hierarchical learning and fusion of the temporal and channel features. In addition, a mutual learning strategy of multiple class tokens is proposed to improve classification performance. We conduct performance evaluation experiments on a single-character handwriting-imagination dataset and a sentence handwriting-imagination dataset, which are collected from the public Handwriting BCI dataset. The comparison results demonstrate the superiority of the proposed framework and strategy. Especially in the imagined single-character recognition task, the recognition accuracy of our model can achieve 95.78%, which provides an improvement of +2% over the existing state of the art models. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhou2024Temporal-channel
ER  -

TY  - JOUR
AU  - Sheng, S.
AU  - Zheng, T.
AU  - Ren, Z.
AU  - Zhang, Y.
AU  - Fu, W.
TI  - SS-MVMETRO: Semi-supervised multi-view human mesh recovery transformer
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 6
SP  - 5027
EP  - 5043
DO  - 10.1007/s10489-024-05435-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190393504&doi=10.1007%2fs10489-024-05435-9&partnerID=40&md5=6574cbb83c482e2efaf3c43fd8469a31
AB  - Abstract: Parametric methods are widely utilized in RGB-based human mesh recovery, relying on precise statistical human body model parameters that are challenging to obtain. In contrast, non-parametric transformer-based approaches excel but are applied only to monocular RGB tasks. To address these limitations, this paper presents Semi-Supervised Multi-View Human Mesh Recovery Transformer (SS-MVMETRO), which combines multi-view information with non-parametric methods for the first time. Our model encodes different images according to their respective view directions, fusing local features around key points of joints and vertices. Then, a residual-like structure is proposed to integrate the fused features in the mesh recovery transformer, which subsequently predicts the 3D coordinates of the human mesh vertices. Additionally, we divide different views into the main view and auxiliary views and propose a semi-supervised training approach that requires fewer matching labels. The efficacy of our work is validated on two datasets, Human3.6M and Mpi_inf_3dph, through quantitative and qualitative experiments. The results indicate that SS-MVMETRO improves the reconstruction accuracy, surpassing previous image-based methods by at least 8.9% in terms of Procrustes Analysis Mean-Per-Joint-Position-Error (PA-MPJPE). Graphical abstract: (Figure presented.) © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Sheng2024SS-MVMETRO
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Lu, S.-Y.
AU  - Wang, S.-H.
AU  - Zhang, Y.-D.
TI  - RanMerFormer: Randomized vision transformer with token merging for brain tumor classification
PY  - 2024
T2  - Neurocomputing
VL  - 573
C7  - 127216
DO  - 10.1016/j.neucom.2023.127216
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182503105&doi=10.1016%2fj.neucom.2023.127216&partnerID=40&md5=d33536ff9f654e33142cc6b1cae860b6
AB  - Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:C期刊; 
LB  - Wang2024RanMerFormer
ER  -

TY  - JOUR
AU  - Hoang, T.L.
AU  - Ta, V.C.
TI  - Balancing structure and position information in Graph Transformer network with a learnable node embedding
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122096
DO  - 10.1016/j.eswa.2023.122096
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174212661&doi=10.1016%2fj.eswa.2023.122096&partnerID=40&md5=150efdf499dd6c4d9664347408359458
AB  - The Transformer-based graph neural network models have achieved remarkable results in graph representation learning in recent years. One of the main challenges in graph representation learning with Transformer architecture is the non-existence of a universal positional encoding. Standard position encoding methods usually evolve the usage of the graph Laplacian matrix eigenvectors. However, exploiting the structural information from these eigenvectors failed to perform graph learning tasks requiring the node's local structures. In our work, we propose a novel node encoding that leverages both the node's global position information and the node's local structural information, which can generalize well for a wide range of graph learning tasks. The global position encoding branch operates on the eigenvalues and eigenvectors of the Laplacian matrix of the entire graph. The structural encoding branch is derived through the spectral-based encoding of the local subgraph. It represents the local properties, which are usually omitted in the Laplacian position encoding because of the cutoff of high graph frequencies. Two encoding branches are designed with learnable weights and mapped into predefined embedding spaces. Then, a weighted combination is employed to create a unique location encoding for each node. We validate the efficiency of our proposed encoding through various graph learning datasets, including node classification, link prediction, graph classification, and graph regression tasks. The overall results demonstrate that our structural and positional encoding can balance between the local and global structural information and outperforms most of the baseline models. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Hoang2024Balancing
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Wang, L.
AU  - Cheng, S.
TI  - Enhanced transformer encoder and hybrid cascaded upsampler for medical image segmentation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121965
DO  - 10.1016/j.eswa.2023.121965
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173281100&doi=10.1016%2fj.eswa.2023.121965&partnerID=40&md5=6988c2656bd8e95204d669f60192db81
AB  - UNet has been highly successful in various medical image segmentation tasks, but the restricted field of perception of convolutional operations has led to the lack of UNet's ability to explicitly model global context information. Vision Transformer captures global relevance through self-attention (SA), thus alleviating the problem of perceived wild locality in convolution neural network (CNN) architectures. However, traditional Transformer typically by means of SA with high computational complexity, and the fusion mechanism is static MLP mode, which is not efficient enough. In addition, the current segmentation methods usually perform simple feature fusion on the decoder side of the U-shaped architecture, which cannot meet the potential demand for important features when generating predictive maps. To solve these problems, we propose the E-TUNet network. On the one hand, we designed the Enhanced Transformer as the encoder by introducing EMSA and DynaMixer MLP. The Enhanced Transformer has high computational efficiency and dynamic mixing weights, which alleviates the problem of single static fusion mechanism. On the other hand, we introduce G-L MLP block with global-local space interaction capability to form hybrid cascaded upsampler for importance computation and matching of decoder side features. The hybrid cascaded upsampler has stronger information representation capabilities and effectively combines CNN and MLP to capture local and global dependencies. We demonstrate the effectiveness of our E-TUNet on two different public available datasets. Extensive experiments have shown that our method is highly competitive compared to other methods. In particular, on publicly available datasets (Synapse and ACDC), the mean DSC (%) is 82.15 and 91.12, respectively. HD95 (mm) is 17.89 on the Synapse dataset. E-TUNet has achieved significant performance improvement in multi-organ segmentation tasks, reaching a advanced level. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2024Enhanced
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Yang, B.
AU  - Mao, R.
AU  - Li, Q.
TI  - MGT: Multi-Granularity Transformer leveraging multi-level relation for sequential recommendation
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121808
DO  - 10.1016/j.eswa.2023.121808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174524237&doi=10.1016%2fj.eswa.2023.121808&partnerID=40&md5=45c4a42da6e97e6298c1100591058ab4
AB  - Sequential recommendation has been a popular research topic in recent times, aiming to predict the next item in a user's sequence based on their past behaviors. Self-Attention (SA)-based models have shown state-of-the-art performance in this domain. These SA-based models adopt vanilla self-attention mechanism, which takes every single item as the minimum modeling unit and is sufficient to capture the point-level relation: several previously interacted items affecting the target item individually. However, we argue that vanilla self-attention mechanism in existing SA-based models neglects the collective influence of a group of items and thus cannot explicitly capture union-level relation: several previous items affecting the target items jointly. To address this limitation, we propose Multi-Granularity Transformer (MGT) that leverages both point-level and union-level relation for sequential recommendation. The proposed MGT employs a new multi-granularity self-attention (MGSA) mechanism that simultaneously captures multi-level relation (point-level and union-level relation). Specifically, MGSA partitions item latent space into different attention heads and forces different attention heads to account for point-level and union-level relation, respectively. Moreover, to improve the ability of feedforward layer in modeling local patterns, we further propose to incorporate a cross-token scheme into existing point-wise feedforward layer to enable local information interaction between adjacent items. Extensive experiments are conducted on three widely-used benchmark datasets to demonstrate the effectiveness and rationality of the proposed MGT over several state-of-the-art sequential recommendation models. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2024MGT
ER  -

TY  - JOUR
AU  - Huang, S.
AU  - Liu, Y.
AU  - Zhang, F.
AU  - Li, Y.
AU  - Li, J.
AU  - Zhang, C.
TI  - CrossWaveNet: A dual-channel network with deep cross-decomposition for Long-term Time Series Forecasting
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121642
DO  - 10.1016/j.eswa.2023.121642
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173142863&doi=10.1016%2fj.eswa.2023.121642&partnerID=40&md5=3b29f3eab8977754d255872b94ef074e
AB  - Many real-world applications require predicting data changes over a longer period, such as early warning for energy consumption and long-term planning for transportation. Long-term Time Series Forecasting (LTSF) demands models with high predictive capability. Recently, transformer-based models have achieved notable success in LTSF. However, the inherent nature of the permutation-invariant self-attention mechanism in Transformers can lead to the loss of certain temporal patterns. Therefore, we propose a dual-channel network with deep cross-decomposition for LTSF, called CrossWaveNet. In order to better capture long-term dependencies, unlike the complex network structure of Transformer, a simpler and more effective dual-channel network model for season and trend-cyclical is constructed. The original time series is decomposed into seasonal and trend-cyclical components simultaneously, and the dual-channel network structure is used to extract their features, respectively. This structure can improve the model's generalization ability, which can have good results on various types of time series data. To effectively improve the accuracy of data decomposition, the moving average method is first used to obtain coarse-grained seasonal and trend-cyclical components, and then the extracted seasonal and trend-cyclical components are gradually merged into their respective channels through the dual-channel network with deep cross-decomposition, thereby obtaining fine-grained components and effectively improving prediction performance. Compared with the state-of-the-art methods in long-term forecasting, CrossWaveNet has achieved the highest prediction accuracy and significant relative performance improvement in fields such as energy, transportation, weather, and disease transmission. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Huang2024CrossWaveNet
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Li, B.
AU  - Zhou, X.
AU  - Li, D.
AU  - Duan, Q.
TI  - FishTrack: Multi-object tracking method for fish using spatiotemporal information fusion
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122194
DO  - 10.1016/j.eswa.2023.122194
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175152872&doi=10.1016%2fj.eswa.2023.122194&partnerID=40&md5=9da69105ab9f8617436be8fde105707c
AB  - Tracking the fish is a key step in analyzing fish behavior, evaluating their health levels, and warning of abnormal water quality, so it is of significant importance for intelligent monitoring in fish farming. However, multi-object tracking for fish is a very challenging task due to foam occlusion in the factory tank, high individual similarity, and fast-paced motion of fish. To address the above issues, an online multi-fish tracking model called FishTrack is proposed with 3 branches of target detection, track prediction, and re-identification, which establishes the motion model and appearance model for fish simultaneously, thus achieving the online multi-fish tracking. It is a complete Encoder-Decoder structure and the Pyramid Vision Transformer (PVT) is adopted as the backbone network to extract multi-level features. Then an Encoder is specially designed to encode the historical information of the positions of fish, and automatically update its spatiotemporal information in an autoregressive fashion, to perform the fusion of the spatiotemporal information of fish targets and avoid manual selection of spatiotemporal features. Finally, a parallel dual-Decoder is used to decode the motion and appearance features of fish to reduce the interference of the two optimization directions during the joint model training. The motion cues are first used in linear assignment to reduce the interference of occlusion and deformation issues, and when the motion model fails to track, the appearance cues can recover the identity to deal with long occlusion. The experiments on the established multiple fish tracking dataset showed that the higher order tracking accuracy (HOTA) reached 71.4%, the multi-object tracking accuracy (MOTA) reached 94.8%, the most tracked ratio (MT) reached 93.3%, and the identification F1 score (IDF1) reached 82.5%. The results show that FishTrack can solve the problem of tracking accuracy decrease caused by foam occlusion and fish deformation, and save the inference time by sharing features, increasing the robustness of online multi-fish tracking in factory farming. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Liu2024FishTrack
ER  -

TY  - JOUR
AU  - Huang, T.
AU  - Hu, S.
AU  - Yang, H.
AU  - Geng, J.
AU  - Li, Z.
AU  - Xu, Z.
AU  - Ou, X.
TI  - Response speed enhanced fine-grained knowledge tracing: A multi-task learning perspective
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 122107
DO  - 10.1016/j.eswa.2023.122107
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174713371&doi=10.1016%2fj.eswa.2023.122107&partnerID=40&md5=70864f0a7369e82e1c346771527b44dc
AB  - The primary objective of knowledge tracing (KT) is to trace learners’ changing knowledge states and predict their future performance by analyzing their learning trajectories. One of the fundamental assumptions underpinning KT is that estimating knowledge states is roughly equivalent to predicting future performance. However, this assumption has not been extensively explored in most studies, particularly in relation to the consistency between observable performance and latent knowledge state. To address this challenge, we propose a novel response speed enhanced fine-grained knowledge tracing (FKT) method. FKT leverages response speed through response time and integrates speed prediction as an additional task within a multi-task learning framework. Through this framework, FKT can separate representations of different knowledge state in the feature space, thereby facilitating fine-grained knowledge tracing. Moreover, we divide the task of predicting learner performance into three procedures: obtaining historical knowledge state, inferring future latent traits, and forecasting future performance. To this end, we formalize each learner's response interaction as a time cell and develop an encoder–decoder–predictor framework for KT. To enhance the accuracy of performance prediction, we introduce a time-distance attention mechanism and knowledge proficiency component and provide two multi-task objective functions. Our experimental results on four real-world datasets demonstrate the superiority of future performance prediction and good interpretability of FKT. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Huang2024Response
ER  -

TY  - JOUR
AU  - Choi, J.-W.
AU  - Yang, M.
AU  - Kim, J.-W.
AU  - Shin, Y.M.
AU  - Shin, Y.-G.
AU  - Park, S.
TI  - Prognostic prediction of sepsis patient using transformer with skip connected token for tabular data
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 149
C7  - 102804
DO  - 10.1016/j.artmed.2024.102804
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184996436&doi=10.1016%2fj.artmed.2024.102804&partnerID=40&md5=8440a00d504ebf4113b48baf4cc326eb
AB  - Sepsis is known as a common syndrome in intensive care units (ICU), and severe sepsis and septic shock are among the leading causes of death worldwide. The purpose of this study is to develop a deep learning model that supports clinicians in efficiently managing sepsis patients in the ICU by predicting mortality, ICU length of stay (>14 days), and hospital length of stay (>30 days). The proposed model was developed using 591 retrospective data with 16 tabular data related to a sequential organ failure assessment (SOFA) score. To analyze tabular data, we designed the modified architecture of the transformer that has achieved extraordinary success in the field of languages and computer vision tasks in recent years. The main idea of the proposed model is to use a skip-connected token, which combines both local (feature-wise token) and global (classification token) information as the output of a transformer encoder. The proposed model was compared with four machine learning models (ElasticNet, Extreme Gradient Boosting [XGBoost]), and Random Forest) and three deep learning models (Multi-Layer Perceptron [MLP], transformer, and Feature-Tokenizer transformer [FT-Transformer]) and achieved the best performance (mortality, area under the receiver operating characteristic (AUROC) 0.8047; ICU length of stay, AUROC 0.8314; hospital length of stay, AUROC 0.7342). We anticipate that the proposed model architecture will provide a promising approach to predict the various clinical endpoints using tabular data such as electronic health and medical records. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Choi2024Prognostic
ER  -

TY  - JOUR
AU  - Yao, J.
AU  - Han, L.
AU  - Yang, K.
AU  - Guo, G.
AU  - Liu, N.
AU  - Huang, X.
AU  - Zheng, Z.
AU  - Zhang, D.
AU  - Han, J.
TI  - Contextual Dependency Vision Transformer for spectrogram-based multivariate time series analysis
PY  - 2024
T2  - Neurocomputing
VL  - 572
C7  - 127215
DO  - 10.1016/j.neucom.2023.127215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182259311&doi=10.1016%2fj.neucom.2023.127215&partnerID=40&md5=e77016708c360f36f6288420771bc666
AB  - Multivariate time series (MTS) analysis plays an important role in various real-world applications. Existing Transformer-based methods address this problem based on hierarchical semantic representations across different scales. However, most of them ignore exploiting the helpful multiple temporal and variable relationships within the hierarchical semantic representations. To this end, this paper proposes a novel method named Contextual Dependency Vision Transformer (CD-ViT), which generates multi-grained semantic information based on spectrogram and explores mutual dependencies between multi-variable and multi-temporal representations. CD-ViT contains two key modules, i.e., the Hierarchical Variable-dependency Transformer (HVT) module and the Bidirectional Temporal-dependency Interaction (BTI) module. Specifically, the HVT module progressively establishes mutual dependencies between multiple variables, from fine to coarse scales, with shared parameters. The BTI module employs two bidirectional flows to fuse multi-temporal tokens through zoom-in and zoom-out operations. Comprehensive experiments on widely used datasets, including UEA, Olszewski, UCI, MIMIC III, and ETT, demonstrate that the proposed approach achieves significant improvement on three popular tasks, i.e., classification, regression, and forecasting. The code is available at https://github.com/Kali-github/CD-ViT. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Yao2024Contextual
ER  -

TY  - JOUR
AU  - Xu, W.
AU  - Yang, H.
AU  - Shi, Y.
AU  - Tan, T.
AU  - Liu, W.
AU  - Pan, X.
AU  - Deng, Y.
AU  - Gao, F.
AU  - Su, R.
TI  - ERNet: Edge Regularization Network for Cerebral Vessel Segmentation in Digital Subtraction Angiography Images
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 3
SP  - 1472
EP  - 1483
DO  - 10.1109/JBHI.2023.3342195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180358312&doi=10.1109%2fJBHI.2023.3342195&partnerID=40&md5=eee86dcd0a27cc76b3923546ffa6d481
AB  - Stroke is a leading cause of disability and fatality in the world, with ischemic stroke being the most common type. Digital Subtraction Angiography images, the gold standard in the operation process, can accurately show the contours and blood flow of cerebral vessels. The segmentation of cerebral vessels in DSA images can effectively help physicians assess the lesions. However, due to the disturbances in imaging parameters and changes in imaging scale, accurate cerebral vessel segmentation in DSA images is still a challenging task. In this paper, we propose a novel Edge Regularization Network (ERNet) to segment cerebral vessels in DSA images. Specifically, ERNet employs the erosion and dilation processes on the original binary vessel annotation to generate pseudo-ground truths of False Negative and False Positive, which serve as constraints to refine the coarse predictions based on their mapping relationship with the original vessels. In addition, we exploit a Hybrid Fusion Module based on convolution and transformers to extract local features and build long-range dependencies. Moreover, to support and advance the open research in the field of ischemic stroke, we introduce FPDSA, the first pixel-level semantic segmentation dataset for cerebral vessels. Extensive experiments on FPDSA illustrate the leading performance of our ERNet.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Xu2024ERNet
ER  -

TY  - JOUR
AU  - Lee, K.-H.
AU  - Lim, H.J.
AU  - Yun, G.J.
TI  - A data-driven framework for designing microstructure of multifunctional composites with deep-learned diffusion-based generative models
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 129
C7  - 107590
DO  - 10.1016/j.engappai.2023.107590
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178657667&doi=10.1016%2fj.engappai.2023.107590&partnerID=40&md5=09571b4636cd1e4a7ab3eaadb9f1c418
AB  - This paper introduces a novel integrated microstructure design methodology that replaces the common existing design approaches for multifunctional composites: 1) reconstruction of microstructures, 2) analyzing and quantifying material properties, and 3) inverse design of materials. The problem of microstructure reconstruction is addressed using the diffusion-based generative model (DGM), which is a state-of-the-art generative model formulated with a Markovian diffusion process. Then, the conditional formulation of DGM is introduced for guidance to the embedded desired material properties with a transformer-based attention mechanism, which enables the inverse design of multifunctional composites. Furthermore, a convolutional neural network (CNN)-based surrogate model is utilized to facilitate the prediction of linear/nonlinear material properties for building microstructure-property linkages. Combined, the proposed artificial intelligence-based design framework enables large data processing and database construction that is often not affordable with resource-intensive finite element method (FEM)-based direct numerical simulation (DNS) or iterative reconstruction methods. It is worth noting that the proposed DGM-based methodology is not susceptible to unstable training or mode collapse, which are common issues in generative models that are often difficult to address even with extensive hyperparameter tuning. An example case is presented to demonstrate the effectiveness of the proposed approach, which is designing mechanoluminescence (ML) particulate composites. The results show that the designed ML microstructure samples with the proposed generative and surrogate models meet the multiple design requirements (e.g., volume fraction, elastic constant, and light sensitivity). This assessment demonstrates that the proposed integrated methodology provides an end-to-end solution for practical material design applications. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Lee2024data-driven
ER  -

TY  - JOUR
AU  - Mohammed, A.A.Q.
AU  - Geng, X.
AU  - Wang, J.
AU  - Ali, Z.
TI  - Driver distraction detection using semi-supervised lightweight vision transformer
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 129
C7  - 107618
DO  - 10.1016/j.engappai.2023.107618
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179586283&doi=10.1016%2fj.engappai.2023.107618&partnerID=40&md5=09ddb109e857afb2e7cec0352c7319bb
AB  - The continuously increasing number of traffic accidents necessitates addressing distracted driving, which is responsible for numerous fatalities. Enhancing driver behavior recognition, particularly through developing a highly reliable Advanced Driver Assistance System (ADAS), holds substantial potential for cultivating safer transportation systems. Inspired by the success of Convolutional Neural Networks (CNNs), various networks have been proposed to enhance the detection accuracy of distracting behaviors. However, existing models have too many parameters and rely heavily on extensive labeled data, leading to time-consuming labeling and large models. To address these limitations, we propose a distracted behavior detection method based on a lightweight vision transformer trained using pseudo-label-based semi-supervised learning to learn discriminative representations from labeled and unlabeled data while ensuring a small model and speedy inference. Specifically, we create strong and weak augmented versions of the input minibatch and employ a hybrid lightweight transformer model in a teacher-student network. Pseudo-labels are generated from the teacher's predictions on weakly augmented data. The student model aligns with these labels on strongly augmented input, with teacher parameters evolving through exponential moving average. Our method presents a real-time, accurate solution for distracted driver detection, with the potential to significantly enhance road safety by reducing accidents. The effectiveness of the proposed approach is demonstrated through a comparative evaluation against alternative fully-supervised and semi-supervised methods. Furthermore, our method is evaluated in naturalistic driving settings with varying lighting and complex backgrounds. Experiments conducted on two publicly available driver distraction detection datasets show that our method outperforms current state-of-the-art approaches. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Mohammed2024Driver
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - He, J.
AU  - Wang, D.
AU  - Wang, Q.
AU  - Wan, B.
AU  - Luo, X.
TI  - Multimodal transformer with adaptive modality weighting for multimodal sentiment analysis
PY  - 2024
T2  - Neurocomputing
VL  - 572
C7  - 127181
DO  - 10.1016/j.neucom.2023.127181
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182018321&doi=10.1016%2fj.neucom.2023.127181&partnerID=40&md5=7af0fbe6cb365a56d53775da74ee9077
AB  - Multimodal Sentiment Analysis (MSA) constitutes a pivotal technology in the realm of multimedia research. The efficacy of MSA models largely hinges on the quality of multimodal fusion. Notably, when conveying information pertinent to specific tasks or applications, not all modalities hold equal importance. Previous research, however, has either disregarded the importance of modalities altogether or solely focused on the importance of linguistic and non-linguistic modalities while neglecting the importance between non-linguistic modalities. To facilitate effective multimodal information fusion based on the relative importance of modalities, a novel multimodal fusion mode named Multimodal Transformer with Adaptive Modality Weighting (MTAMW) is proposed in this paper. Specifically, we introduce a multimodal adaptive weight matrix that allocates appropriate weights to each modality based on its contribution to sentiment analysis. Furthermore, a multimodal attention mechanism is introduced, utilizing multiple Softmax functions to compute attention weights, thereby efficiently fusion multimodal information via a single-stream Transformer. By meticulously considering the relative importance of each modality during the fusion process, more effective multimodal information fusion is achievable. Extensive experiments on benchmark datasets show that it is superior to or comparable to state-of-the-art methods on MSA tasks. The codes for our experiments are available at https://github.com/Vamos66/MTAMW. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Wang2024Multimodal
ER  -

TY  - JOUR
AU  - Yaermaimaiti, Y.
AU  - Yan, T.
AU  - Zhao, Y.
AU  - Kari, T.
TI  - Research on 3D Face Reconstruction Algorithm Based on ResNet and Transformer
PY  - 2024
T2  - International Journal of Computational Intelligence and Applications
VL  - 23
IS  - 1
C7  - 2350035
DO  - 10.1142/S1469026823500359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185267648&doi=10.1142%2fS1469026823500359&partnerID=40&md5=fdfc350ba2e1d3c5631c67cbeef713cc
AB  - In view of the problems of high production cost, scarcity and lack of diversity of 3D face datasets, this paper designs an end-to-end self-supervised learning 3D face reconstruction algorithm with a single 2D face image as input, which only uses 2D face datasets to complete model training. First, the improved ResNet module is introduced to preprocess the input face image. The deep residual neural network has strong feature extraction and characterization ability for the image, which can provide rich high-level semantic feature maps for the subsequent subnetwork. Then, add transformer module completely based on self-attention mechanism to the parameter prediction subnetwork, which can make different parameters of the subnetwork focus on self-related feature map information and avoid interference from invalid feature map information, so as to further improve the parameter prediction accuracy of the subnetwork. Next, training, ablation and comparison experiments were conducted on CelebA, BFM and Photoface datasets, and the combined function of pixel loss function and perceptual loss function was selected as the loss function. The experimental results show that: compared with the historical optimal results of the same network structure, the scale-invariant depth error (SIDE) and mean angle deviation (MAD) are improved by 5.9% and 10.8%, respectively, which strongly proves the effectiveness of the algorithm. Finally, in order to verify the actual effect of the 3D face reconstruction algorithm, examples are selected in this paper for reconstruction. The 3D faces generated by the algorithm all have a good sense of reality, which intuitively and effectively proves the advancement of the algorithm.  © 2024 World Scientific Publishing Europe Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Yaermaimaiti2024Research
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Wang, N.
AU  - Zhu, Z.
AU  - Gao, H.
AU  - Lu, N.
AU  - Su, H.
AU  - Wang, X.
TI  - Multi-omics fusion based on attention mechanism for survival and drug response prediction in Digestive System Tumors
PY  - 2024
T2  - Neurocomputing
VL  - 572
C7  - 127168
DO  - 10.1016/j.neucom.2023.127168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181960205&doi=10.1016%2fj.neucom.2023.127168&partnerID=40&md5=8c6a6fdbedf4d4a210767f4cc02d9697
AB  - In recent decades, digestive system tumors (DST) have become the primary cause of cancer-related deaths worldwide. Improving tumor prognosis and drug response prediction holds significant importance in personalized medicine. In order to construct an effective and interpretable model that integrates multiple omics data, the Multi-omics Fusion Graph Attention Network (MFGAN) is proposed for survival prediction and drug response prediction in DST. In this method, the similarity matrix of each kind of omics data is calculated and a new graph structure is learned by Graph Transformer (GT). Next, to learn the features of every kind of omics data from the TCGA and GDSC databases, the Graph Attention Network (GAN) is used. Lastly, the View Correlation Discovery Network (VCDN) combines different types of omics data features to predict survival risk and drug response. Among them, the survival prediction results showed an improvement of up to 9% relative to other methods in terms of the c-index metric, with a minimum improvement of 2.6%. In terms of drug response prediction performance, there was an improvement of 4%. The ablation experiment demonstrates MFGAN's feature integration capability, and the functional enrichment analysis for significant genes explains the functional characteristics of the model. Furthermore, the prediction of unknown tumor drug response demonstrates the model's prediction ability. The proposed high-prediction comprehensive model could have important potential value for the personalized medicine of DST. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhou2024Multi-omics
ER  -

TY  - JOUR
AU  - Dai, L.
AU  - Yang, X.
AU  - Li, H.
AU  - Zhao, X.
AU  - Lin, L.
AU  - Jiang, Y.
AU  - Wang, Y.
AU  - Li, Z.
AU  - Shen, H.
TI  - A clinically actionable and explainable real-time risk assessment framework for stroke-associated pneumonia
PY  - 2024
T2  - Artificial Intelligence in Medicine
VL  - 149
C7  - 102772
DO  - 10.1016/j.artmed.2024.102772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183968072&doi=10.1016%2fj.artmed.2024.102772&partnerID=40&md5=8e8f0f3c260f4829bc071058968ce0bb
AB  - The current medical practice is more responsive rather than proactive, despite the widely recognized value of early disease detection, including improving the quality of care and reducing medical costs. One of the cornerstones of early disease detection is clinically actionable predictions, where predictions are expected to be accurate, stable, real-time and interpretable. As an example, we used stroke-associated pneumonia (SAP), setting up a transformer-encoder-based model that analyzes highly heterogeneous electronic health records in real-time. The model was proven accurate and stable on an independent test set. In addition, it issued at least one warning for 98.6 % of SAP patients, and on average, its alerts were ahead of physician diagnoses by 2.71 days. We applied Integrated Gradient to glean the model's reasoning process. Supplementing the risk scores, the model highlighted critical historical events on patients' trajectories, which were shown to have high clinical relevance. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Dai2024clinically
ER  -

TY  - JOUR
AU  - Liu, R.W.
AU  - Zheng, W.
AU  - Liang, M.
TI  - Spatio-temporal multi-graph transformer network for joint prediction of multiple vessel trajectories
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 129
C7  - 107625
DO  - 10.1016/j.engappai.2023.107625
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178398416&doi=10.1016%2fj.engappai.2023.107625&partnerID=40&md5=4818a0b1262d440a2b2e20f8c3ca5494
AB  - The vessel trajectory prediction plays a vital role in guaranteeing traffic safety for unmanned surface vehicles and autonomous surface vessels. By leveraging advanced satellite communication technology, AIS provides massive vessel trajectories, significantly enhancing maritime safety and decision-making. This research proposes a spatio-temporal multi-graph transformer network (ST-MGT), aiming to predict multiple vessel trajectories simultaneously. This innovative model amalgamates the capabilities of graph convolutional networks (GCNs) and transformer models to proficiently address the spatial and temporal interactions amongst vessels. The ST-MGT is comprised of three crucial layers. The temporal transformer layer employs sophisticated temporal transformer and memory mechanisms to discern the intricate temporal correlations between vessel movements. The spatial multi-graph transformer layer constructs a comprehensive multi-graph representation to illuminate spatial correlations between vessels. It incorporates a spatial graph convolutional network and transformer to meticulously understand and interpret the diverse and complex spatial interactions amongst varying vessels. Lastly, the ξ-Regularized LSTM (RegLSTM) layer is implemented for predicting vessel trajectories accurately, based on the unraveled spatio-temporal patterns. Extensive and meticulous experiments reveal that our proposed ST-MGT method transcends other state-of-the-art prediction models in robustness and accuracy. The model's capability to facilitate multi-vessel and multi-step prediction showcases its immense potential and adaptability in intricate and multifaceted navigation environments, underscoring its practical applicability and significance in enhancing maritime navigational safety. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Liu2024Spatio-temporal
ER  -

TY  - JOUR
AU  - Shaik, N.S.
AU  - Cherukuri, T.K.
TI  - Gated contextual transformer network for multi-modal retinal image clinical description generation
PY  - 2024
T2  - Image and Vision Computing
VL  - 143
C7  - 104946
DO  - 10.1016/j.imavis.2024.104946
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185198598&doi=10.1016%2fj.imavis.2024.104946&partnerID=40&md5=63a904aa763bbed2019a6436fa4b2693
AB  - Generating semantically meaningful and coherent clinical description for the diagnosis of retinal images has been a challenging task for both Computer Vision and Natural Language Processing domains. This is mainly due to the fact that the clinical descriptions generated by the language model are completely dependent on the type of retinal image representations learned by the vision model. This work investigates and proposes a unified approach to integrate multi-modal retinal image visual representations with corresponding clinical keyword embeddings which can aid the language model to learn the clinical semantics and generate lengthy, coherent clinical descriptions accurately. Our proposed approach, named the Gated Contextual Transformer Network, comprises two attention-based encoders that learn semantically discriminative attention-based representations from retinal images and clinical keywords, along with a Transformer Network for clinical description generation. The first encoder leverages a pre-trained Convolutional Neural Network (VGG19) and a Gated Contextual Attention module to learn discriminative attention-based representations from the multi-modal retinal images. The second encoder incorporates an Embedding layer and an Attention module to learn attention-based clinical keyword embeddings. The Transformer network consists of a fusion encoder that attentively integrates retinal image visual features with clinical keyword embeddings and a decoder that is responsible for generating semantically meaningful and coherent clinical descriptions. Our experimental studies on the benchmark DeepEyeNet dataset demonstrate that the proposed approach successfully generates clinical descriptions from multi-modal retinal images, meeting the standards of ophthalmologists. To support our claim, we provide qualitative and quantitative evaluations of the proposed approach. This includes reporting BLUE, CIDEr, and ROUGE scores for the predicted descriptions, as well as employing Visual Explanation for Clinical Description Generation. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Shaik2024Gated
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Shao, Y.
AU  - Wang, L.
AU  - Li, H.
AU  - Liu, Y.
TI  - IDBNet: Improved differentiable binarisation network for natural scene text detection
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 2
SP  - 224
EP  - 235
DO  - 10.1049/cvi2.12241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173935764&doi=10.1049%2fcvi2.12241&partnerID=40&md5=852a2a148613014e4cad532b31fb9814
AB  - The text in the natural scene can express rich semantic information, which helps people understand and analyse daily things. This paper focuses on the problems of discrete text spatial distribution and variable text geometric size in natural scenes with complex backgrounds and proposes an end-to-end natural scene text detection method based on DBNet. The authors first use IResNet as the backbone network, which does not increase network parameters while retaining more text features. Furthermore, a module with Transformer is introduced in the feature extraction stage to strengthen the correlation between high-level feature pixels. Then, the authors add a spatial pyramid pooling structure in the end of feature extraction, which realises the combination of local and global features, enriches the expressive ability of feature maps, and alleviates the detection limitations caused by the geometric size of features. Finally, to better integrate the features of each level, a dual attention module is embedded after multi-scale feature fusion. Extensive experiments on the MSRA-TD500, CTW1500, ICDAR2015, and MLT2017 data set are conducted. The results showed that IDBNet can improve the average precision, recall, and F-measure of a text compared with the state of art text detection methods and has higher predictive ability and practicability. © 2023 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhang2024IDBNet
ER  -

TY  - JOUR
AU  - Zeng, F.
AU  - Li, Y.
AU  - Xiao, J.
AU  - Yang, D.
TI  - DDHCN: Dual decoder Hyperformer convolutional network for Downstream-Adaptable user representation learning on app usage
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121564
DO  - 10.1016/j.eswa.2023.121564
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171616126&doi=10.1016%2fj.eswa.2023.121564&partnerID=40&md5=94b4a6222f2f124bdc0e14279b229931
AB  - In mobile scenarios, there is a need for general user representations to solve multiple target tasks. However, there are some challenges in the related research (e.g., difficulty in learning a representation that satisfies both great generalization and performance). To address these problems, we proposed a network for downstream-adaptable mobile user modeling, which employed a novel fine-tuning strategy for optimizing the performance of several downstream tasks. Additionally, we designed a time-difference module to eliminate the impact of low-frequency and non-uniform app usage behavior over time. A parallel decoder structure was developed to incorporate multi-type features by minimizing information loss. We evaluated our method on a real-world dataset of 100,000 mobile users and three downstream tasks (i.e., age prediction, gender prediction, and app recommendation). The experimental results showed that our method could outperform existing methods significantly. It achieved 96.5% ACC on gender prediction, 68.1% ACC on age prediction, and 64.2% Recall@5 on app recommendation. These results imply that our method performs well on both generalization and performance. It could be anticipated promising to the unseen tasks inference. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zeng2024DDHCN
ER  -

TY  - JOUR
AU  - Kour, H.
AU  - Gupta, M.K.
TI  - Hybrid evolutionary intelligent network for sentiment analysis using Twitter data during COVID-19 pandemic
PY  - 2024
T2  - Expert Systems
VL  - 41
IS  - 3
C7  - e13489
DO  - 10.1111/exsy.13489
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175373600&doi=10.1111%2fexsy.13489&partnerID=40&md5=937d6c928b783b669d8dce9d31c2f20b
AB  - COVID-19 pandemic has impacted many nations, causing physical as well as mental health concerns globally. In most countries, governments enforced strict lockdowns and social distancing, thus affecting people's daily lives. People usually tweet their views on online platforms that is unstructured text with implicit meaning. With the evolution of artificial intelligence in the natural language processing domain, the prediction of sentiments accurately has become a challenge. To contribute as a solution to this, a hybrid approach is proposed for sentiment prediction with the use of an evolutionary-based approach, transfer-based learning and machine learning. The proposed approach uses bidirectional encoder representations from transformers (BERT) with genetic algorithm (GA) and support vector machine (SVM), namely, hybrid evolutionary intelligent model (GA-BERT-SVM). These approaches aid in extracting important features considering semantics and context present in the text. To avoid the limitations of the backpropagation approach, such as trapping in local minima and overfitting the data, the initial parameters (weights and biases) of the dense layers has been optimized using GA. Additionally, the pretrained BERT layers are utilized without any modification, following a standard transfer learning approach. The BERT embeddings are concatenated with the SVM for training and classification. GridSearchCV and GeneticSearchCV is used for obtaining optimal parameters of SVM. A multi-classification problem is tackled using a benchmark COVID-19 dataset, which comprises of Twitter data and is categorized into COVIDSENTI-A, COVIDSENTI-B, COVIDSENTI-C and a combined dataset called COVIDSENTI. Experimental evaluation demonstrates promising results of the proposed model in terms of accuracy, F1-score, precision and recall, surpassing state-of-the-art approaches. © 2023 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Kour2024Hybrid
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Wu, C.
AU  - Huang, J.
AU  - Zhang, Y.
AU  - Ye, M.
AU  - Huang, Y.
TI  - Blockchain-Based Interpretable Electric Vehicle Battery Life Prediction in IoV
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 4
SP  - 7214
EP  - 7227
DO  - 10.1109/JIOT.2023.3315483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171537463&doi=10.1109%2fJIOT.2023.3315483&partnerID=40&md5=ff3e3fd10836a05956b8c6d2a413e723
AB  - The remarkable success of deep learning (DL) in predicting battery health has prompted interest in its application in recent years. While state-of-the-art DL models have achieved high accuracy in battery health prediction, they have not been widely adopted in industrial workflows, primarily due to their lack of interpretability and security. To address this issue, we propose a blockchain-based interpretable prediction algorithm for battery health prediction in electric vehicles (EVs) within the Internet of Vehicles (IoV). Specifically, the proposed method includes a platform architecture for a blockchain-based DL system, ensuring secure storage of user data during the prediction process. Notably, we develop a novel battery life prediction algorithm called BLP-Transformer, which leverages short-term relationships between degraded data and explains the impact of feature extraction on predicted results through the contribution of aggregated features based on a feature focusing mechanism. Experimental results demonstrate that the system is feasible for security and can provide accurate battery life prediction. In addition, the comparison study further highlights the superiority of the proposed algorithm in terms of robustness, prediction accuracy, and model interpretability.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Liu2024Blockchain-Based
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Zhang, L.
AU  - Cheng, H.
AU  - Lu, H.
AU  - Chen, Z.
TI  - A Lifelong Learning Method Based on Event-Triggered Online Frozen-EWC Transformer Encoder for Equipment Digital Twin Dynamic Evolution
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 4
SP  - 5708
EP  - 5717
DO  - 10.1109/JIOT.2023.3307819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168748271&doi=10.1109%2fJIOT.2023.3307819&partnerID=40&md5=4a645429ebe4b56b399b1229834dc1fa
AB  - Digital twin (DT) has become a widely discussed emerging topic in last few years, which is expected to bring a new revolution to the whole life cycle of complex equipment, including Research and Development design, optimization control, and predictive maintenance. Using online real-time sensor data to realize model dynamic evolution, so as to map the state change of physical equipment faithfully, is the most significant feature of DT and is also one of the most important key technologies of DT. Lifelong learning is a feasible way to realize DT dynamic evolution. By using offline historical data and online real-time data, the DT model built in a data-driven modeling manner can evolve continuously, therefore, the accuracy of predictive simulation can be guaranteed and improved. Simultaneously, to make a balance between the computation cost and dynamic evolution performance, we introduce the event-triggered scheme during the online lifelong learning process. To sum up, a lifelong learning method based on event-triggered online Frozen-EWC Transformer Encoder for equipment DT dynamic evolution has been proposed in this article and the real flight data set of quadrotor aircraft is used to verify the effectiveness of the proposed method. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2024Lifelong
ER  -

TY  - JOUR
AU  - Hajiakhondi-Meybodi, Z.
AU  - Mohammadi, A.
AU  - Abouei, J.
AU  - Plataniotis, K.N.
TI  - CLSA: Contrastive-Learning-Based Survival Analysis for Popularity Prediction in MEC Networks
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 4
SP  - 6352
EP  - 6367
DO  - 10.1109/JIOT.2023.3314667
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172985029&doi=10.1109%2fJIOT.2023.3314667&partnerID=40&md5=653f656b27f5afdeab7c0380c0c959d1
AB  - Mobile-edge caching (MEC) integrated with deep neural networks (DNNs) is an innovative technology with significant potential for the future generation of wireless networks, resulting in a considerable reduction in users' latency. The mobile-edge caching (MEC) network's effectiveness, however, heavily relies on its capacity to predict and dynamically update the storage of caching nodes with the most popular contents. To be effective, a DNN-based popularity prediction model needs to have the ability to understand the historical request patterns of content, including their temporal and spatial correlations. Existing state-of-the-art time-series DNN models capture the latter by simultaneously inputting the sequential request patterns of multiple contents to the network, considerably increasing the size of the input sample. This motivates us to address this challenge by proposing a DNN-based popularity prediction framework based on the idea of contrasting input samples against each other, designed for the unmanned aerial vehicle (UAV)-aided MEC networks. Referred to as the contrastive learning-based survival analysis (CLSA), the proposed architecture consists of a self-supervised contrastive learning (CL) model, where the temporal information of sequential requests is learned using a long short-term memory (LSTM) network as the encoder of the CL architecture. Followed by a survival analysis (SA) network, the output of the proposed CLSA architecture is probabilities for each content's future popularity, which are then sorted in descending order to identify the Top- $K$ popular contents. Based on the simulation results, the proposed CLSA architecture outperforms its counterparts across the classification accuracy and cache-hit ratio.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hajiakhondi-Meybodi2024CLSA
ER  -

TY  - JOUR
AU  - Khan, H.
AU  - Hussain, T.
AU  - Ullah Khan, S.
AU  - Ahmad Khan, Z.
AU  - Baik, S.W.
TI  - Deep multi-scale pyramidal features network for supervised video summarization
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121288
DO  - 10.1016/j.eswa.2023.121288
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171612054&doi=10.1016%2fj.eswa.2023.121288&partnerID=40&md5=2c89b41ab89b403410a7767849a3ab31
AB  - Video data are witnessing exponential growth, and extracting summarized information is challenging. It is always necessary to reduce the load of video traffic for the efficient video storage, transmission, and retrieval requirements. The aim of video summarization (VS) is to extract the most important contents from video repositories effectively. Recent attempts have used fewer representative features, which have been fed to recurrent networks to achieve VS. However, generating the desired summaries can become challenging due to the limited representativeness of extracted features and a lack of consideration for feature refinement. In this article, we introduce a vision transformer (ViT)-assisted deep pyramidal refinement network that can extract and refine multi-scale features and can predict an importance score for each frame. The proposed network comprises four main modules; initially, a dense prediction transformer with a ViT backbone is applied for the first time in this domain to acquire the optimal representations from the input frames. Then, feature maps are obtained from various layers separately and processed individually to support multi-scale progressive feature fusion and refinement before the data are passed to the ultimate prediction module. Next, a customized pyramidal refinement block is employed to refine the multi-level feature set before predicting the importance scores. Finally, video summaries are produced by selecting keyframes based on the predictions. To explore the performance of the proposed network, extensive experiments are conducted on the TVSum and SumMe datasets, and our network is found to achieve F1-scores of 62.4% and 51.9%, respectively, outperforming state-of-the-art alternatives by 0.9% and 0.5%. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Khan2024Deep
ER  -

TY  - JOUR
AU  - Zhang, W.
AU  - Wang, J.
AU  - Tang, M.
AU  - Ma, H.
AU  - Wang, L.
AU  - Zhang, Q.
AU  - Fan, S.
TI  - 2-D Transformer-Based Approach for Process Monitoring of Metal 3-D Printing via Coaxial High-Speed Imaging
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 3
SP  - 3767
EP  - 3777
DO  - 10.1109/TII.2023.3314071
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172999677&doi=10.1109%2fTII.2023.3314071&partnerID=40&md5=d987d0885be94612f00ff181a2997469
AB  - Defects in the metal 3-D printing process exhibit randomness and low frequency, making them difficult to predict and control. This severely hinders the application of this technology in critical industrial fields. Extracting useful features from massive process monitoring data to ensure forming quality has become a popular research direction for intelligent additive manufacturing practitioners. In this study, a coaxial machine vision monitoring system is utilized to monitor the entire forming process of the melt track. More importantly, this study constructed a high-speed video dataset of typical metal 3-D printing working conditions by changing the powder layer thickness, which can serve actual industrial production. To promptly recognize unhealthy melt tracks from massive process monitoring data, a 2-D transformer-based framework named super frame feature pyramid transformer (SFFPT) is designed for video classification. This framework transforms the video understanding task into a 2-D feature map processing task, allowing the video classification task to be completed directly using only an image classifier. In comparison to state-of-the-art methods, SFFPT achieves the best classification accuracy in this study.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhang20242-D
ER  -

TY  - JOUR
AU  - Zhu, Y.
AU  - Guo, J.
AU  - Li, H.
AU  - Liu, S.
AU  - Li, Y.
TI  - TSAGNN: Temporal link predict method based on two stream adaptive graph neural network
PY  - 2024
T2  - Intelligent Data Analysis
VL  - 28
IS  - 1
SP  - 77
EP  - 97
DO  - 10.3233/IDA-237367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186115354&doi=10.3233%2fIDA-237367&partnerID=40&md5=9c9a53449d0ea0aa4af42a07716696c0
AB  - Temporal link prediction based on graph neural networks has become a hot spot in the field of complex networks. To solve the problems of the existing temporal link prediction methods based on graph neural networks do not consider the future time-domain features and spatial-domain features are limited used, this paper proposes a novel temporal link prediction method based on two streams adaptive graph neural networks. Firstly, the network topology features are extracted from the micro, meso, and middle perspectives. Combined with the adaptive mechanism of convolution and self-attention, the preprocessing of the feature extraction is more effective; Secondly, an extended bi-directional long short-term memory network is proposed, which uses graph convolution to process topological features, and recursively learns the state vectors of the target snapshot by using the future time-domain information and the past historical information; Thirdly, the location coding is replaced by the time-coding for the transformer mechanism, so that past information and future information can be learned from each other, and the time-domain information of the network can be further mined; Finally, a novel two-stream network framework is proposed, which combines the processing results of point features and edge features. The experimental results on 9 data sets show that the proposed method has a better prediction effect and better robustness than the classical graph neural network methods.  © 2024 - IOS Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhu2024TSAGNN
ER  -

TY  - JOUR
AU  - Cao, B.
AU  - Wu, X.
AU  - Zhang, X.
AU  - Wang, Y.
AU  - Ma, Z.
TI  - Discriminative target predictor based on temporal-scene attention context enhancement and candidate matching mechanism
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121400
DO  - 10.1016/j.eswa.2023.121400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171758503&doi=10.1016%2fj.eswa.2023.121400&partnerID=40&md5=81668000529a51089edb9af92bacf9f5
AB  - Visual tracking is a fundamental task in computer vision, which extracts the target context descriptions and features from the first image frame and tracks the target in subsequent frames with the updated target appearance models and the updated tracking models accordingly. The existing deficiencies of deep learning based visual tracker are: precision-speed dilemma, inadequate context usage and spawning tracking noises. To achieve real-time and accurate tracking with deep learning modules under tracking-by-detection framework, this paper introduced a discriminative target predictor based on temporal-scene attention context enhancement and candidate matching mechanism (ACDP). The contributions of ACDP include: 1) a vision transformer based temporal context enhancer is suggested by formulating the temporal context enhanced feature extractor via multi-head attention mechanism; 2) a target state propagation scheme based scene context enhancer is proposed via constructing the target state matrix and corresponding state forward propagation techniques; 3) a joint prediction method is provided to take full usage of the enhanced context through candidate selection and matching mechanism based on dust-bin conception network; 4) theoretical proofs for vision transformer acceleration scheme and the error bounds under successive tracking failure circumstances are given. In addition, the extensive experiments under OTB100, UAV123, NFS, AVisT and VOT2018 benchmarks evaluate the favorable performances of ACDP and indicate that: 1) the proposed modules in ACDP can achieve comparable tracking results even under difficult sequences and scenarios against other 21 state-of-the-art trackers; 2) the ACDP performs 35 FPS tracking speed on the 5 benchmarks averagely. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Cao2024Discriminative
ER  -

TY  - JOUR
AU  - Zhao, A.
AU  - Zhang, Y.
TI  - Evota: an enhanced visual object tracking network with attention mechanism
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 8
SP  - 24939
EP  - 24960
DO  - 10.1007/s11042-023-16149-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168091025&doi=10.1007%2fs11042-023-16149-4&partnerID=40&md5=ccd6c2145dd6b1beffba2968d3306140
AB  - Transformer architecture has made breakthrough in various downstream computer vision tasks and has shown its great potential in visual object tracking. However, existing transformer-based approaches adopt pixel-to-pixel attention strategy to integrate the domain knowledge, but fail to explore the channel and location information from object features, which limits the expressivity of the tracker. To address the above problems, we propose a novel tracking framework, where we propose 2 attention blocks that fuses with Transformer (dubbed EVOTA). It has 4 modules: the feature extraction module, the enhanced attention module, a transformer module and a model predictor. Specifically, a channel-wise attention module re-calibrates the channel-wise feature responses in an adaptive way by modelling interdependencies explicitly between channels. A local cross-channel interaction scheme learns strong channel context information. Meanwhile, an energy function is developed to analyze the importance of each neuron and infers their 3D weights. Extensive experiments have been carried out on 5 prevalent tracking benchmarks to testify the effectiveness of our model, in which EVOTA outperforms several state-of-the-art methods. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2024Evota
ER  -

TY  - JOUR
AU  - Kang, H.
AU  - Xu, Q.
AU  - Chen, D.
AU  - Ren, S.
AU  - Xie, H.
AU  - Wang, L.
AU  - Gao, Y.
AU  - Gong, M.
AU  - Chen, X.
TI  - Assessing the performance of fully supervised and weakly supervised learning in breast cancer histopathology
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121575
DO  - 10.1016/j.eswa.2023.121575
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171618045&doi=10.1016%2fj.eswa.2023.121575&partnerID=40&md5=a5d84b77b20686a00878d7205d739ccf
AB  - Fully supervised learning (FSL) and weakly supervised learning based on multiple instance learning (WSLMIL) have become two mainstream paradigms for performing computer-aided pathological diagnosis (CAPD). It is well known that the high-intensity annotation burden of FSL and the performance degradation due to poor training constraints of WSLMIL are stumbling blocks for clinical translation. Even more unfortunate is the lack of comprehensive experimental analysis to help researchers make content-specific trade-offs between FSL and WSLMIL. In this work, we systematically compare the performances of FSL and WSLMIL on lymph node metastasis in breast cancer using a publicly available dataset. By analyzing the results of 16 backbone networks in the FSL paradigm, we find that emerging networks based on transformer (PVTv2-B2) and multi-layer perceptron (CycleMLP-B3) are more advantageous for performing patch-level classification task than convolution-based structure (ResNet50); combining their output with morphological feature extraction can be better used to universally perform slide-level classification task. However, the slight improvement brought by the evolution of the backbone network may be overshadowed by the aggregation operation in 6 WSLMIL algorithms, whereas relying on the in-domain backbone network can achieve a stable and excellent prediction performance in both quantitative analysis and interpretability comparisons. All the experimental results ultimately illustrate that the combination of in-domain backbone network and emergent aggregation operation becomes an economical and efficient technical tool for CAPD, which can be regarded as a compromise between FSL and WSLMIL. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kang2024Assessing
ER  -

TY  - JOUR
AU  - Xue, B.
AU  - Gao, X.
AU  - Zhang, S.
AU  - Wang, N.
AU  - Fu, S.
AU  - Yu, J.
AU  - Zhang, G.
AU  - Huang, Z.
TI  - A feature-level mask self-supervised assisted learning approach based on transformer for remaining useful life prediction
PY  - 2024
T2  - Intelligent Data Analysis
VL  - 28
IS  - 1
SP  - 217
EP  - 237
DO  - 10.3233/IDA-227099
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186122816&doi=10.3233%2fIDA-227099&partnerID=40&md5=c6c065de6dacbd14442b766d6630c741
AB  - Nowadays, the massive industrial data has effectively improved the performance of the data-driven deep learning Remaining Useful Life (RUL) prediction method. However, there are still problems of assigning fixed weights to features and only coarse-grained consideration at the sequence level. This paper proposes a Transformer-based end-to-end feature-level mask self-supervised learning method for RUL prediction. First, by proposing a fine-grained feature-level mask self-supervised learning method, the data at different time points under all features in a time window is sent to two parallel learning streams with and without random masks. The model can learn more fine-grained degradation information by comparing the information extracted by the two parallel streams. Instead of assigning fixed weights to different features, the abstract information extracted through the above process is invariable correlations between features, which has a good generalization to various situations under different working conditions. Then, the extracted information is encoded and decoded again using an asymmetric structure, and a fully connected network is used to build a mapping between the extracted information and the RUL. We conduct experiments on the public C-MAPSS datasets and show that the proposed method outperforms the other methods, and its advantages are more obvious in complex multi-working conditions.  © 2024 - IOS Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xue2024feature-level
ER  -

TY  - JOUR
AU  - Ziembicki, D.
AU  - Seweryn, K.
AU  - Wróblewska, A.
TI  - Polish natural language inference and factivity: An expert-based dataset and benchmarks
PY  - 2024
T2  - Natural Language Engineering
VL  - 30
IS  - 2
SP  - 385
EP  - 416
DO  - 10.1017/S1351324923000220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162109403&doi=10.1017%2fS1351324923000220&partnerID=40&md5=fde7fd49cd34f4ff18f379cdf7c577b8
AB  - Despite recent breakthroughs in Machine Learning for Natural Language Processing, the Natural Language Inference (NLI) problems still constitute a challenge. To this purpose, we contribute a new dataset that focuses exclusively on the factivity phenomenon; however, our task remains the same as other NLI tasks, that is prediction of entailment, contradiction, or neutral (ECN). In this paper, we describe the LingFeatured NLI corpus and present the results of analyses designed to characterize the factivity/non-factivity opposition in natural language. The dataset contains entirely natural language utterances in Polish and gathers 2432 verb-complement pairs and 309 unique verbs. The dataset is based on the National Corpus of Polish (NKJP) and is a representative subcorpus in regard to syntactic construction [V][że][cc]. We also present an extended version of the set (3035 sentences) consisting more sentences with internal negations. We prepared deep learning benchmarks for both sets. We found that transformer BERT-based models working on sentences obtained relatively good results (F1 score on base dataset). Even though better results were achieved using linguistic features (F1 score on base dataset), this model requires more human labor (humans in the loop) because features were prepared manually by expert linguists. BERT-based models consuming only the input sentences show that they capture most of the complexity of NLI/factivity. Complex cases in the phenomenon-for example, cases with entitlement (E) and non-factive verbs-still remain an open issue for further research.  © The Author(s), 2023. Published by Cambridge University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Ziembicki2024Polish
ER  -

TY  - JOUR
AU  - Zhao, F.
AU  - Ai, Q.
AU  - Li, X.
AU  - Wang, W.
AU  - Gao, Q.
AU  - Liu, Y.
TI  - TLC-XML: Transformer with Label Correlation for Extreme Multi-label Text Classification
PY  - 2024
T2  - Neural Processing Letters
VL  - 56
IS  - 1
C7  - 25
DO  - 10.1007/s11063-024-11460-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187221660&doi=10.1007%2fs11063-024-11460-z&partnerID=40&md5=b9078f47c8ab0bcd3dd122d6c09957da
AB  - Extreme multi-label text classification (XMTC) annotates related labels for unknown text from large-scale label sets. Transformer-based methods have become the dominant approach for solving the XMTC task due to their effective text representation capabilities. However, the existing Transformer-based methods fail to effectively exploit the correlation between labels in the XMTC task. To address this shortcoming, we propose a novel model called TLC-XML, i.e., a Transformer with label correlation for extreme multi-label text classification. TLC-XML comprises three modules: Partition, Matcher and Ranker. In the Partition module, we exploit the semantic and co-occurrence information of labels to construct the label correlation graph, and further partition the strongly correlated labels into the same cluster. In the Matcher module, we propose cluster correlation learning, which uses the graph convolutional network (GCN) to extract the correlation between clusters. We then introduce these valuable correlations into the classifier to match related clusters. In the Ranker module, we propose label interaction learning, which aggregates the raw label prediction with the information of the neighboring labels. The experimental results on benchmark datasets show that TLC-XML significantly outperforms state-of-the-art XMTC methods. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhao2024TLC-XML
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Li, M.
AU  - Guo, Q.
AU  - Xiao, Y.
AU  - Yang, Z.
TI  - Road network pixelization: A traffic flow imputation method based on image restoration techniques
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121468
DO  - 10.1016/j.eswa.2023.121468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171751219&doi=10.1016%2fj.eswa.2023.121468&partnerID=40&md5=6e48b2f959d14f50882b64fd89898f11
AB  - The complete traffic network data is crucial for accurate traffic data prediction in intelligent transportation systems. Inspired by the success of Generative Adversarial Networks (GANs) in image restoration, this study proposes a traffic flow imputation method by employing image restoration techniques. First, we propose a trajectory data representation method called Trajectory2Matrix, that converts the trajectory data into a two-dimensional spatiotemporal relation feature map. Consequently, the data imputation scale and scope are increased. Second, a spatiotemporal feature map generation module based on a graph convolutional network is designed to optimize the GAN generator, thus utilizing its advantages for non-Euclidean data and dynamic spatiotemporal correlation. Finally, a heterogeneous multisource data fusion module based on a channel attention mechanism is proposed to merge dynamic/static external attributes and multimode characteristics in time. The proposed method improved imputation accuracy and robustness for multitype missing data patterns, especially in high missing rate situations. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wang2024Road
ER  -

TY  - JOUR
AU  - Hossain, S.
AU  - Chakrabarty, A.
AU  - Gadekallu, T.R.
AU  - Alazab, M.
AU  - Piran, M.J.
TI  - Vision Transformers, Ensemble Model, and Transfer Learning Leveraging Explainable AI for Brain Tumor Detection and Classification
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 3
SP  - 1261
EP  - 1272
DO  - 10.1109/JBHI.2023.3266614
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153394956&doi=10.1109%2fJBHI.2023.3266614&partnerID=40&md5=d4afdaff74c878a2b9c6668b331acf32
AB  - The abnormal growth of malignant or nonmalignant tissues in the brain causes long-term damage to the brain. Magnetic resonance imaging (MRI) is one of the most common methods of detecting brain tumors. To determine whether a patient has a brain tumor, MRI filters are physically examined by experts after they are received. It is possible for MRI images examined by different specialists to produce inconsistent results since professionals formulate evaluations differently. Furthermore, merely identifying a tumor is not enough. To begin treatment as soon as possible, it is equally important to determine the type of tumor the patient has. In this paper, we consider the multiclass classification of brain tumors since significant work has been done on binary classification. In order to detect tumors faster, more unbiased, and reliably, we investigated the performance of several deep learning (DL) architectures including Visual Geometry Group 16 (VGG16), InceptionV3, VGG19, ResNet50, InceptionResNetV2, and Xception. Following this, we propose a transfer learning(TL) based multiclass classification model called IVX16 based on the three best-performing TL models. We use a dataset consisting of a total of 3264 images. Through extensive experiments, we achieve peak accuracy of 95.11%, 93.88%, 94.19%, 93.88%, 93.58%, 94.5%, and 96.94% for VGG16, InceptionV3, VGG19, ResNet50, InceptionResNetV2, Xception, and IVX16, respectively. Furthermore, we use Explainable AI to evaluate the performance and validity of each DL model and implement recently introduced Vison Transformer (ViT) models and compare their obtained output with the TL and ensemble model.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:C期刊; 
LB  - Hossain2024Vision
ER  -

TY  - JOUR
AU  - Xie, T.
AU  - Dai, K.
AU  - Wang, K.
AU  - Li, R.
AU  - Zhao, L.
TI  - DeepMatcher: A deep transformer-based network for robust and accurate local feature matching
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121361
DO  - 10.1016/j.eswa.2023.121361
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170579857&doi=10.1016%2fj.eswa.2023.121361&partnerID=40&md5=ab0b89cd00280e95d0a35d5ec54c792a
AB  - Local feature matching constitutes the cornerstone of multiple computer vision applications (e.g., 3D reconstruction and long-term visual localization), and has been successfully resolved by detector-free methods. To further improve the matching performance, more recent research has focused on designing sophisticated architectures but endures additional computational overhead. In this study, with a different perspective from previous studies, we aim to develop a deep and compact matching network to improve performance while reducing computing cost. The key insight is that a local feature matcher with deep layers can capture more human-intuitive and simpler-to-match features. To this end, we propose DeepMatcher, a deep transformer-based network that tackles the inherent obstacles of not being able to build a deep local feature matcher with current methods. DeepMatcher consists of: (1) a local feature extractor (LFE), (2) a feature-transition module (FTM), (3) a slimming transformer (SlimFormer), (4) a coarse matches module (CMM), and (5) a fine matches module (FMM). The LFE is utilized to generate dense keypoints with enriched features from the images. We then introduce the FTM to ensure a smooth transition of feature scopes from LFE to the subsequent SlimFormer because of their different receptive fields. Subsequently, we develop SlimFormer dedicated to DeepMatcher, which leverages vector-based attention to model the relevance among all keypoints, enabling the network to construct a deep Transformer architecture with less computational cost. Relative position encoding is applied to each SlimFormer to explicitly disclose the relative distance information, thereby improving the representation of the keypoints. A layer-scale strategy is also employed in each SlimFormer to enable the network to adaptively assimilate message exchange, thus endowing it to simulate human behavior, in which humans can acquire different matching cues each time they scan an image pair. By interleaving the self- and cross-SlimFormers multiple times, DeepMatcher can easily establish pixel-wise dense matches at the coarse level using the CMM. Finally, we consider match refinement as a combination of classification and regression problems and design an FMM to predict confidence and offset concurrently, thus generating robust and accurate matches. Compared with our baseline LoFTR in indoor/outdoor pose estimation, DeepMatcher surpasses it by 3.32%/2.91% in AUC@5∘. Besides, DeepMatcher and DeepMatcher-L significantly reduce computational cost and only consume 77.89% and 92.46% GFLOPs of LoFTR. Large DeepMatcher considerably outperforms state-of-the-art methods on several benchmarks, including outdoor pose estimation (MegaDepth dataset), indoor pose estimation (ScanNet dataset), homography estimation (HPatches dataset), and image matching (HPatches dataset), demonstrating the superior matching capability of a deep local feature matcher. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Xie2024DeepMatcher
ER  -

TY  - JOUR
AU  - R, R.
AU  - A, C.
TI  - GTSO: Gradient tangent search optimization enabled voice transformer with speech intelligibility for aphasia
PY  - 2024
T2  - Computer Speech and Language
VL  - 84
C7  - 101568
DO  - 10.1016/j.csl.2023.101568
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174536605&doi=10.1016%2fj.csl.2023.101568&partnerID=40&md5=aa48679926459a6459fb5c5cca067635
AB  - A frequent neurological condition known as aphasia is brought on by injury to language-related brain regions as well as possibly other regions of the brain involved in executive, memory, and attention functions. Due to a lack of speech-language pathologists and the vast expense of treatment, traditional therapy is difficult for aphasia-affected people to access. In this research work, speech intelligibility for aphasia is done by the proposed Gradient Tangent Search Optimization (GTSO) algorithm-enabled voice transformer. Here, the median filter is used for pre-processing the signal to reduce noise. The pre-processed voice signal is allowed for feature extraction and voice enhancement stages. Moreover, nonlinear spectral subtraction is used for voice enhancement and voice transformer is used for voice recognition. Also, the voice transformer is trained by GTSO, which is devised by hybridizing Gradient Descent (GD) Optimization and Tangent Search Algorithm (TSA). Then, the output obtained is fed to the language and pronunciation model for recognizing speech, and at last, the speech recognized is converted to text. Furthermore, the GTSO- enabled voice transformer is analyzed for its performance by three metrics, namely recognition accuracy, Positive Predictive Value (PPV), and Negative Predictive Value (NPV), with superior values of 0.919, 0.919, and 0.915. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - R2024GTSO
ER  -

TY  - JOUR
AU  - Tao, Z.
AU  - Wu, W.
AU  - Wang, J.
TI  - Series decomposition Transformer with period-correlation for stock market index prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 237
C7  - 121424
DO  - 10.1016/j.eswa.2023.121424
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171437349&doi=10.1016%2fj.eswa.2023.121424&partnerID=40&md5=4c7d97ab12f539495dd76be2d53d3ad5
AB  - Stock price forecasting has been always a difficult and crucial undertaking in the field of finance. In the last few decades, deep learning models based on RNNs and LSTMs have dominated the research, where the stock price data are modeled as time series data. However, the high volatility of stock prices and the decay of information learned from historical data prevented these models from achieving more accurate predictions in this problem. Recently, Transformer has been gradually applied in time series prediction, but the methods aim to feed the highly-uncertain social media information as the additional auxiliary information into Transformer, rather than improving the ability to extract features from historical series. In this paper, we propose a Series Decomposition Transformer with Period-correlation (SDTP), which uses the period-correlation mechanism and series decomposition layers to further discover relation between historical series and learn the changing trends in the stock market for high forecasting accuracy and generalizability. The extensive experimental results show that the proposed SDTP model generally outperforms the state-of-the-art methods on a collection of datasets. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Tao2024Series
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Long, H.
AU  - Zheng, L.
AU  - Shang, J.
TI  - Graphformer: Adaptive graph correlation transformer for multivariate long sequence time series forecasting
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 285
C7  - 111321
DO  - 10.1016/j.knosys.2023.111321
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181769903&doi=10.1016%2fj.knosys.2023.111321&partnerID=40&md5=612cdc3d2356e15dd90adecfa876b91d
AB  - Accurate long sequence time series forecasting (LSTF) remains a key challenge due to its complex time-dependent nature. Multivariate time series forecasting methods inherently assume that variables are interrelated and that the future state of each variable depends not only on its history but also on other variables. However, most existing methods, such as Transformer, cannot effectively exploit the potential spatial correlation between variables. To cope with the above problems, we propose a Transformer-based LSTF model, called Graphformer, which can efficiently learn complex temporal patterns and dependencies between multiple variables. First, in the encoder's self-attentive downsampling layer, Graphformer replaces the standard convolutional layer with an dilated convolutional layer to efficiently capture long-term dependencies between time series at different granularity levels. Meanwhile, Graphformer replaces the self-attention mechanism with a graph self-attention mechanism that can automatically infer the implicit sparse graph structure from the data, showing better generality for time series without explicit graph structure and learning implicit spatial dependencies between sequences. In addition, Graphformer uses a temporal inertia module to enhance the sensitivity of future time steps to recent inputs, and a multi-scale feature fusion operation to extract temporal correlations at different granularity levels by slicing and fusing feature maps to improve model accuracy and efficiency. Our proposed Graphformer can improve the long sequence time series forecasting accuracy significantly when compared with that of SOTA Transformer-based models. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; FMS:C; 
LB  - Wang2024Graphformer
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Tan, F.
AU  - He, C.
AU  - Wang, Z.
AU  - Song, H.
AU  - Hu, P.
AU  - Luo, X.
TI  - Saliency-Aware Dual Embedded Attention Network for Multivariate Time-Series Forecasting in Information Technology Operations
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 3
SP  - 4206
EP  - 4217
DO  - 10.1109/TII.2023.3315369
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174855346&doi=10.1109%2fTII.2023.3315369&partnerID=40&md5=18e016ea089765c3a89d2a88e9f8f3f7
AB  - In the field of artificial intelligence for information technology operations, operational data are often modeled as aperiodic multivariate time series, which contain rich multidimensional and nonlinear patterns. However, the existing approaches are unable to effectively acquire knowledge and recognize patterns due to their reliance on processing and modeling periodic patterns. To address this issue, this article proposes a novel deep-saliency-aware dual embedded attention network for aperiodic multivariate time-series forecasting. Our network consists of three main components: 1) a convolutional-neural-network- and transformer-based component for saliency representation of the aperiodic patterns; 2) a lightweight recurrent neural network component for capturing long-term dependence features; and 3) an attention mechanism for fusing the latent representations from the former components. Extensive empirical studies are conducted on a real-world dataset and five other public datasets to evaluate the proposed network against four state-of-the-art models. The results show that our method achieves impressive high performance on most evaluation metrics. Furthermore, the data and code used in this study are publicly available, which can facilitate progress in the community.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Li2024Saliency-Aware
ER  -

TY  - JOUR
AU  - Khandaker, F.
AU  - Senderovich, A.
AU  - Zhao, J.
AU  - Cohen, E.
AU  - Yu, E.
AU  - Carbajales, S.
AU  - Chan, A.
TI  - Transformer models for mining intents and predicting activities from emails in knowledge-intensive processes
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 128
C7  - 107450
DO  - 10.1016/j.engappai.2023.107450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177866367&doi=10.1016%2fj.engappai.2023.107450&partnerID=40&md5=510a6923d6f20cc5f4fdc3e61f4ec620
AB  - Process mining is an interdisciplinary field that combines Artificial Intelligence and Business Process Management to extract insights from historical event data. Knowledge-intensive processes, which predominantly involve knowledge work, are often inadequately monitored by process-aware information systems. Consequently, the event data necessary for applying process mining techniques are frequently unavailable. Emails are widely used in knowledge-intensive processes for scheduling meetings, sharing documents, and reporting on the completion of outstanding tasks, which makes them suitable candidates for replacing event logs as the primary data source. In this work, we focus on the task of extracting the set of next recommended activities from incoming emails. Yet, we face two major challenges. Firstly, emails do not express process information explicitly but rather contain subtext that implies what the next best actions would be. Secondly, email data lacks domain-specific labels that would enable the use of machine learning. We overcome these limitations by utilizing an email taxonomy to represent user intents, thus bridging the gap between textual information and process semantics, as well as leveraging pre-trained transformer models applied in zero-shot and few-shot settings that require little to no labeled email data. An evaluation of our method on real-world unlabeled email communications demonstrates its effectiveness in recognizing intents and extracting activities. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Khandaker2024Transformer
ER  -

TY  - JOUR
AU  - Mohammed, S.K.
AU  - Singh, S.
AU  - Mizouni, R.
AU  - Otrok, H.
TI  - TRACE: Transformer-based continuous tracking framework using IoT and MCS
PY  - 2024
T2  - Journal of Network and Computer Applications
VL  - 222
C7  - 103793
DO  - 10.1016/j.jnca.2023.103793
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178333260&doi=10.1016%2fj.jnca.2023.103793&partnerID=40&md5=46557e5050ea84601cbf0d89b106745d
AB  - Target tracking, a critical application in the Internet of Things (IoT) and Mobile Crowd Sensing (MCS) domains, is a complex task that involves the continuous estimation of the positions of an object by using efficient and accurate algorithms. Some potential applications of target tracking include surveillance systems, asset tracking, wildlife monitoring, and cross-border security. The existing target tracking solutions are either energy-inefficient or are only effective for fixed-length trajectories, making them impractical for real-world applications. For robust predictive tracking, with irregular trajectory lengths, energy efficiency and accuracy are vital to ensure system's longevity and reliability. In this work, using a combination of trajectory prediction and path correction techniques, a novel approach, TRACE, is proposed for continuously tracking a target in an environment. TRACE uses locations offered by IoT/MCS localization systems to make predictions about the target's future movement. A transformer neural network is implemented to learn mobility patterns to predict the target's future trajectory. To ensure accurate predictions, a path correction mechanism is devised, by updating the predicted trajectory using polynomial regression. Experiments are conducted using a real-world GeoLife dataset to evaluate the performance of the proposed approach. The results demonstrate that TRACE performs better than existing tracking techniques with an improvement in accuracy of about 50% while using 85% less energy, supporting the potential of the proposed approach for enhancing target tracking in IoT/MCS applications. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Mohammed2024TRACE
ER  -

TY  - JOUR
AU  - Niu, H.
AU  - Omitaomu, O.A.
AU  - Langston, M.A.
AU  - Olama, M.
AU  - Ozmen, O.
AU  - Klasky, H.B.
AU  - Laurio, A.
AU  - Ward, M.
AU  - Nebeker, J.
TI  - EHR-BERT: A BERT-based model for effective anomaly detection in electronic health records
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 150
C7  - 104605
DO  - 10.1016/j.jbi.2024.104605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184153295&doi=10.1016%2fj.jbi.2024.104605&partnerID=40&md5=e192316dbf88803746e9e4acc4de9218
AB  - Objective: Physicians and clinicians rely on data contained in electronic health records (EHRs), as recorded by health information technology (HIT), to make informed decisions about their patients. The reliability of HIT systems in this regard is critical to patient safety. Consequently, better tools are needed to monitor the performance of HIT systems for potential hazards that could compromise the collected EHRs, which in turn could affect patient safety. In this paper, we propose a new framework for detecting anomalies in EHRs using sequence of clinical events. This new framework, EHR-Bidirectional Encoder Representations from Transformers (BERT), is motivated by the gaps in the existing deep-learning related methods, including high false negatives, sub-optimal accuracy, higher computational cost, and the risk of information loss. EHR-BERT is an innovative framework rooted in the BERT architecture, meticulously tailored to navigate the hurdles in the contemporary BERT method; thus, enhancing anomaly detection in EHRs for healthcare applications. Methods: The EHR-BERT framework was designed using the Sequential Masked Token Prediction (SMTP) method. This approach treats EHRs as natural language sentences and iteratively masks input tokens during both training and prediction stages. This method facilitates the learning of EHR sequence patterns in both directions for each event and identifies anomalies based on deviations from the normal execution models trained on EHR sequences. Results: Extensive experiments on large EHR datasets across various medical domains demonstrate that EHR-BERT markedly improves upon existing models. It significantly reduces the number of false positives and enhances the detection rate, thus bolstering the reliability of anomaly detection in electronic health records. This improvement is attributed to the model's ability to minimize information loss and maximize data utilization effectively. Conclusion: EHR-BERT showcases immense potential in decreasing medical errors related to anomalous clinical events, positioning itself as an indispensable asset for enhancing patient safety and the overall standard of healthcare services. The framework effectively overcomes the drawbacks of earlier models, making it a promising solution for healthcare professionals to ensure the reliability and quality of health data. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Niu2024EHR-BERT
ER  -

TY  - JOUR
AU  - Jiang, Z.
AU  - Liu, J.
AU  - Chen, Z.
AU  - Luo, W.
AU  - Zhang, C.
AU  - Gui, W.
TI  - Overall particle size distribution estimation method based on kinetic modeling and transformer prediction
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 128
C7  - 107517
DO  - 10.1016/j.engappai.2023.107517
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181684433&doi=10.1016%2fj.engappai.2023.107517&partnerID=40&md5=b8f8db6cc925c5310703ac6cb75b25c9
AB  - Estimating the overall particle size distribution (PSD) on the conveyor is one of the most important means of monitoring blast furnace production. Due to the harsh production environment and limited detection conditions, existing online detection methods can only estimate part of the PSD, but it is difficult to predict the overall PSD. Unlike segmentation methods that can only obtain surface PSD, we propose an overall PSD estimation method based on mechanistic modeling and local–global fused prediction networks. First, we constructed a kinetic mechanism model of particle accumulation, from which global field distribution features such as coordination number, moment of inertia, and spatial distribution were extracted. Then, a particle segmentation model is trained using surface images collected by detection means such as cameras to obtain surface PSDs as local surface features. Next, to predict the overall PSD, we propose a Local surface and Global field distribution feature Fusion-based Transformer network (LGFT). Among them, in order to better aggregate local and global features, we introduce orthogonal fusion and point cloud extractors in the encoder. Finally, we verify the accuracy and efficiency of our method through extensive ablation experiments. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Jiang2024Overall
ER  -

TY  - JOUR
AU  - Guo, J.
AU  - Lei, S.
AU  - Du, B.
TI  - MHT: A multiscale hourglass-transformer for remaining useful life prediction of aircraft engine
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 128
C7  - 107519
DO  - 10.1016/j.engappai.2023.107519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181653851&doi=10.1016%2fj.engappai.2023.107519&partnerID=40&md5=e7c983a504c43208351d13d3e974ecbe
AB  - Remaining useful life (RUL) prediction of aircraft engines is significant in the health monitoring, operation, and maintenance of aircraft. Capturing more comprehensive device degradation trends at different time scales and extracting long-term dependencies effectively among elements in long time series are two challenges in the field of aircraft engine RUL estimation. To address the aforementioned challenges, this paper proposes a novel multiscale Hourglass-Transformer (MHT) aircraft engine RUL prognostics. Specifically, an hourglass-shaped multiscale feature extractor (HME) is designed based on one-dimensional convolutional neural network, which can scale the time sequence into multi-time scales for feature fusion. Then, a transformer network is employed to further extract features from the fused feature map and output the RUL. To enhance inter-scale data attention, a pyramid self-attention mechanism is employed in both the encoder and decoder. Finally, the superiority and effectiveness of this approach are verified on the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dataset. Furthermore, the robustness and generalization capability of this method are further validated on New Commercial Modular Aero-Propulsion System Simulation (N-CMAPSS) dataset. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Guo2024MHT
ER  -

TY  - JOUR
AU  - Islam, M.K.
AU  - Rahman, M.M.
AU  - Ali, M.S.
AU  - Mahim, S.M.
AU  - Miah, M.S.
TI  - Enhancing lung abnormalities diagnosis using hybrid DCNN-ViT-GRU model with explainable AI: A deep learning approach
PY  - 2024
T2  - Image and Vision Computing
VL  - 142
C7  - 104918
DO  - 10.1016/j.imavis.2024.104918
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183205497&doi=10.1016%2fj.imavis.2024.104918&partnerID=40&md5=3d8086341bb0ba6120131611d743a637
AB  - In this study, we propose a novel approach called DCNN-ViT-GRU, which combines deep Convolutional Neural Networks (CNNs) with Gated Recurrent Units (GRUs) and the Vision Transformer (ViT) model for the accurate detection and classification of lung abnormalities. By leveraging the strengths of both CNNs and the ViT model, our architecture automatically extracts meaningful features from lung images, leading to improved diagnostic capabilities. The DCNN-ViT-GRU model utilizes a combination of deep CNN and GRU layers, allowing it to effectively capture local and global patterns. This comprehensive feature representation enhances the model's ability to identify various abnormalities in lung images, including lung cancer, COVID-19, and pneumonia. To further enhance the interpretability and transparency of our model, we integrate Explainable Artificial Intelligence (XAI) techniques, including LIME and SHAP. This integration provides valuable insights into the decision-making process of the DCNN-ViT-GRU model, enabling clinicians to understand and validate the predictions made by the model. We evaluated the performance of our proposed approach on diverse datasets containing cases of lung abnormalities. Through cross-validation, our DCNN-ViT-GRU model achieved impressive weighted mean accuracy of 99% and 99.86% for two distinct datasets, demonstrating its superior performance. Furthermore, in hold-out validation on separate datasets, the model achieved accuracies of 99.09% and 99.87%, respectively. Integrating the XAI techniques enhances the interpretability of the DCNN-ViT-GRU model and provides clinicians with valuable insights regarding the factors contributing to the diagnosis of lung abnormalities. This approach presents a promising solution for accurate and interpretable lung abnormalities detection and classification, with potential implications for improved patient care and treatment planning. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Islam2024Enhancing
ER  -

TY  - JOUR
AU  - Chen, M.
AU  - Wang, Y.
AU  - Shi, Y.
AU  - Feng, J.
AU  - Feng, R.
AU  - Guan, X.
AU  - Xu, X.
AU  - Zhang, Y.
AU  - Jin, C.
AU  - Wei, H.
TI  - Brain Age Prediction Based on Quantitative Susceptibility Mapping Using the Segmentation Transformer
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 2
SP  - 1012
EP  - 1021
DO  - 10.1109/JBHI.2023.3341629
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180305822&doi=10.1109%2fJBHI.2023.3341629&partnerID=40&md5=ea80d6bcc04c6f8ed801aa1ce4f7309f
AB  - The process of brain aging is intricate, encompassing significant structural and functional changes, including myelination and iron deposition in the brain. Brain age could act as a quantitative marker to evaluate the degree of the individual's brain evolution. Quantitative susceptibility mapping (QSM) is sensitive to variations in magnetically responsive substances such as iron and myelin, making it a favorable tool for estimating brain age. In this study, we introduce an innovative 3D convolutional network named Segmentation-Transformer-Age-Network (STAN) to predict brain age based on QSM data. STAN employs a two-stage network architecture. The first-stage network learns to extract informative features from the QSM data through segmentation training, while the second-stage network predicts brain age by integrating the global and local features. We collected QSM images from 712 healthy participants, with 548 for training and 164 for testing. The results demonstrate that the proposed method achieved a high accuracy brain age prediction with a mean absolute error (MAE) of 4.124 years and a coefficient of determination (R2) of 0.933. Furthermore, the gaps between the predicted brain age and the chronological age of Parkinson's disease patients were significantly higher than those of healthy subjects (P<0.01). We thus believe that using QSM-based predicted brain age offers a more reliable and accurate phenotype, with the potentiality to serve as a biomarker to explore the process of advanced brain aging.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Chen2024Brain
ER  -

TY  - JOUR
AU  - Yao, S.
AU  - Zhang, H.
AU  - Wang, C.
AU  - Zeng, D.
AU  - Ye, M.
TI  - GSTGAT: Gated spatiotemporal graph attention network for traffic demand forecasting
PY  - 2024
T2  - IET Intelligent Transport Systems
VL  - 18
IS  - 2
SP  - 258
EP  - 268
DO  - 10.1049/itr2.12449
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177421680&doi=10.1049%2fitr2.12449&partnerID=40&md5=a713678b3bb9f3e19dc993b43f12e986
AB  - Urban traffic demand forecasting is an important component in the implementation of intelligent transport systems (ITS). Urban traffic demand data is a spatiotemporal data, describing the amount of traffic demand generated by different areas or stations within a city along the time dimension. Although there has been considerable research work, researchers still face several challenges in predicting accurately, including the capture of hidden features in the temporal dimension of such spatiotemporal data, and the capture of dynamic dependent changes in the spatial dimension. These are even more difficult for long-time series prediction tasks. This paper designs a multivariate temporal forecasting model specifically adapted to traffic demand to address these challenges, called the Gated Spatiotemporal Graph Attention Network (GSTGAT). GSTGAT is based on the Transformer framework and the whole model is used in an end-to-end manner. First of all, it uses the gated self-attention to extract temporal features in the sequence. Secondly, graph attention is used to capture the spatial dependencies among different variables in the unstructured space. Finally, the use of gated recurrent units in combination with hidden spatial states is proposed to capture multiple levels of spatial dependencies. Experimental results on the taxi dataset in New York and the bicycle dataset in San Francisco Bay Area show that the authors’ proposed model outperforms other state-of-the-art models and improves the prediction accuracy. © 2023 The Authors. IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Yao2024GSTGAT
ER  -

TY  - JOUR
AU  - Sui, Y.
AU  - Ding, D.
AU  - Pan, X.
AU  - Xu, X.
AU  - Liu, S.
AU  - Yuan, B.
AU  - Chen, Z.
TI  - Corner-to-Center long-range context model for efficient learned image compression
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 98
C7  - 103990
DO  - 10.1016/j.jvcir.2023.103990
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178663007&doi=10.1016%2fj.jvcir.2023.103990&partnerID=40&md5=12170e5eb6f9761fe01809e213bc97f4
AB  - In the framework of learned image compression, the context model plays a pivotal role in capturing the dependencies among latent representations. To reduce the decoding time resulting from the serial autoregressive context model, the parallel context model has been proposed as an alternative that necessitates only two passes during the decoding phase, thus facilitating efficient image compression in real-world scenarios. However, performance degradation occurs due to its incomplete casual context. To tackle this issue, we conduct an in-depth analysis of the performance degradation observed in existing parallel context models, focusing on two aspects: the Quantity and Quality of information utilized for context prediction and decoding. Based on such analysis, we propose the Corner-to-Center transformer-based Context Model (C3M) designed to enhance context and latent predictions and improve rate–distortion performance. Specifically, we leverage the logarithmic-based prediction order to predict more context features from corner to center progressively. In addition, to enlarge the receptive field in the analysis and synthesis transformation, we use the Long-range Crossing Attention Module (LCAM) in the encoder/decoder to capture the long-range semantic information by assigning the different window shapes in different channels. Extensive experimental evaluations show that the proposed method is effective and outperforms the state-of-the-art parallel methods. Finally, according to the subjective analysis, we suggest that improving the detailed representation in transformer-based image compression is a promising direction to be explored. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Sui2024Corner-to-Center
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Xiang, T.
AU  - Lv, X.
AU  - Li, L.
AU  - Lui, L.M.
AU  - Zeng, T.
TI  - Double Transformer Super-Resolution for Breast Cancer ADC Images
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 2
SP  - 917
EP  - 928
DO  - 10.1109/JBHI.2023.3341250
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180337321&doi=10.1109%2fJBHI.2023.3341250&partnerID=40&md5=8b25dc1f00c22b914ad80d3c2b068782
AB  - Diffusion-weighted imaging (DWI) has been extensively explored in guiding the clinic management of patients with breast cancer. However, due to the limited resolution, accurately characterizing tumors using DWI and the corresponding apparent diffusion coefficient (ADC) is still a challenging problem. In this paper, we aim to address the issue of super-resolution (SR) of ADC images and evaluate the clinical utility of SR-ADC images through radiomics analysis. To this end, we propose a novel double transformer-based network (DTformer) to enhance the resolution of ADC images. More specifically, we propose a symmetric U-shaped encoder-decoder network with two different types of transformer blocks, named as UTNet, to extract deep features for super-resolution. The basic backbone of UTNet is composed of a locally-enhanced Swin transformer block (LeSwin-T) and a convolutional transformer block (Conv-T), which are responsible for capturing long-range dependencies and local spatial information, respectively. Additionally, we introduce a residual upsampling network (RUpNet) to expand image resolution by leveraging initial residual information from the original low-resolution (LR) images. Extensive experiments show that DTformer achieves superior SR performance. Moreover, radiomics analysis reveals that improving the resolution of ADC images is beneficial for tumor characteristic prediction, such as histological grade and human epidermal growth factor receptor 2 (HER2) status.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Double
ER  -

TY  - JOUR
AU  - Zhou, M.
AU  - Zhou, J.
AU  - Gan, J.
AU  - Gao, W.
AU  - Xu, J.
TI  - Clarification question generation diversity and specificity enhancement based on question keyword prediction
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 3
SP  - 2379
EP  - 2396
DO  - 10.1007/s10489-024-05316-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185121263&doi=10.1007%2fs10489-024-05316-1&partnerID=40&md5=5c3fb6763fe87554eeea92a16e1ecac1
AB  - Clarification question generation is used mainly to solve the potential missing product information problem in e-commerce. However, the problem of not being able to better understand contextual semantic information has arisen when studying the diversity and specificity of clarification questions. This further leads to imprecise prediction of question keywords. With the aim of solving the current constraints, we propose the Transformer Encoder of Keyword Predictor Keyword-Conditioned Network (TEKPCNet). First, the transformer encoder has been proven to perform well in predicting external question keywords by encoding context. Then, the Text Convolutional Neural Network (TextCNN) and multilayer perceptron are combined to enhance the input of the encoder-decoder model. The diversity and specificity of the clarification question generation process should be further enhanced. Finally, the decoding process is completed by combining the attention mechanism. The generated clarification questions were evaluated in terms of two datasets using both automatic assessment and human evaluation. The experimental results show that the proposed model outperforms the other models. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhou2024Clarification
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Huang, Y.
AU  - He, N.
AU  - Ma, K.
AU  - Zheng, Y.
TI  - Improving vision transformer for medical image classification via token-wise perturbation
PY  - 2024
T2  - Journal of Visual Communication and Image Representation
VL  - 98
C7  - 104022
DO  - 10.1016/j.jvcir.2023.104022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180596356&doi=10.1016%2fj.jvcir.2023.104022&partnerID=40&md5=52afb0f364674535e831ddedae38b69b
AB  - Transformer has achieved impressive successes for various computer vision tasks. However, most of existing studies require to pretrain the Transformer backbone on a large-scale labeled dataset (e.g., ImageNet) for achieving satisfactory performance, which is usually unavailable for medical images. Additionally, due to the gap between medical and natural images, the improvement generated by the ImageNet pretrained weights significantly degrades while transferring the weights to medical image processing tasks. In this paper, we propose Bootstrap Own Latent of Transformer (BOLT), a self-supervised learning (SSL) approach specifically for medical image classification with the Transformer backbone. Our BOLT consists of two networks, namely online and target branches, for self-supervised representation learning. Concretely, the online network is trained to predict the target network representation of the same patch embedding tokens with a different perturbation. To maximally excavate the impact of Transformer from limited medical data, we propose an auxiliary difficulty ranking task. The Transformer is enforced to identify which branch (i.e., online/target) is processing the more difficult perturbed tokens. Overall, the Transformer endeavours itself to distill the transformation-invariant features from the perturbed tokens to simultaneously achieve difficulty measurement and maintain the consistency of self-supervised representations. The proposed BOLT is evaluated on three medical image processing tasks, i.e., skin lesion classification, knee fatigue fracture grading and diabetic retinopathy grading. The experimental results validate the superiority of our BOLT for medical image classification, compared to ImageNet pretrained weights and state-of-the-art SSL approaches. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2024Improving
ER  -

TY  - JOUR
AU  - Ding, J.
AU  - Zhang, Z.
AU  - Wang, Q.
AU  - Wang, H.
TI  - SCTrans: Self-align and cross-align transformer for few-shot segmentation
PY  - 2024
T2  - Image and Vision Computing
VL  - 142
C7  - 104893
DO  - 10.1016/j.imavis.2023.104893
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181108953&doi=10.1016%2fj.imavis.2023.104893&partnerID=40&md5=b415e2d736e7e40ebba7594cf665a6eb
AB  - Few-shot Semantic Segmentation (FSS) refers to train a segmentation model that can be generalized to novel categories with limited labeled images. One challenge of FSS is spatial inconsistency between support and query images, e.g., appearance and texture. Most existing methods are only committed to utilizing the semantic-level prototypes of support images to guide mask predictions. These methods, nevertheless, only focus on the most discriminate regions of the object rather than holonomic feature representations. Besides, another question exists that the lack of interaction between paired support and query images. In this paper, we propose a self-align and cross-align transformer (SCTrans) to remedy the above limitations. Specifically, we design a feature fusion module (FFM) to incorporate low-level information from the query branch into mid-level semantic features, boosting the semantic representations of query images. In addition, a feature alignment module is designed to bidirectionally propagate semantic information from support to query images conditioned on more representative support and query features, increasing both intra-class similarities and inter-class differences. Extensive experiments on PASCAL-5i and COCO-20i show that our SCTrans significantly advances the state-of-the-art methods. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Ding2024SCTrans
ER  -

TY  - JOUR
AU  - Zang, R.
AU  - Zuo, M.
AU  - Ma, R.
TI  - Joint Gaussian Distribution and Attention for Time-Aware Recommendation Systems
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 1
SP  - 1517
EP  - 1526
DO  - 10.1109/TCSS.2023.3315756
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174812561&doi=10.1109%2fTCSS.2023.3315756&partnerID=40&md5=05d049440089529f873ecbcd5b7c7906
AB  - Sequential models have achieved admirable success in recommendation systems. However, most sequential models typically only consider the chronological order of items through timestamps and ignore the relative distances in the sequence, which weakens the temporal relationships between items. To address this issue, we propose a temporal recommendation system using the Gaussian distribution and attention mechanism, which considers the sequentiality and interaction among items. Technically, we first deploy the word vector space along the time dimension as sequence features. Then, we use the Gaussian process to effectively represent the duration influence of items and the context interaction between items as high-level features. Finally, an innovative attention mechanism is used to capture the hidden correlation relationships between representation subspaces of different levels of features. Experiments conducted on two widely used real public datasets show that our model outperforms the state-of-The-Art recommendation systems.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zang2024Joint
ER  -

TY  - JOUR
AU  - Xie, J.
AU  - Liu, Z.
AU  - Li, G.
AU  - Lu, X.
AU  - Chen, T.
TI  - Global semantic-guided network for saliency prediction
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 284
C7  - 111279
DO  - 10.1016/j.knosys.2023.111279
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179003088&doi=10.1016%2fj.knosys.2023.111279&partnerID=40&md5=3f6bd8d00df7cbdf331718cd87188849
AB  - The human visual system effectively analyzes scenes based on local, global and semantic properties. Deep learning-based saliency prediction models adopted two-stream networks, leveraged prior knowledge of global semantics, or added long-range dependency modeling structures like transformers to incorporate global saliency information. However, they either brought high complexity to learning local and global features or neglected the design for enhancing local features. In this paper, we propose a Global Semantic-Guided Network (GSGNet), which first enriches global semantics through a modified transformer block and then incorporates semantic information into visual features from local and global perspectives in an efficient way. Multi-head self-attention in transformers captures global features, but lacks information communication within and between feature subspaces (heads) when computing the similarity matrix. To learn global representations and enhance interactions of the subspaces, we propose a Channel-Squeeze Spatial Attention (CSSA) module to emphasize channel-relevant information in a compression manner and learn global spatial relationships. To better fuse local and global contextual information, we propose a hybrid CNN-Transformer block called local–global fusion block (LGFB) for aggregating semantic features simply and efficiently. Experimental results on four public datasets demonstrate that our model achieves compelling performance compared with the state-of-the-art saliency prediction models on various evaluation metrics. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; 
LB  - Xie2024Global
ER  -

TY  - JOUR
AU  - Guan, M.
AU  - Li, F.
AU  - Xue, Y.
TI  - Enhanced Syntactic and Semantic Graph Convolutional Network with Contrastive Learning for Aspect-Based Sentiment Analysis
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 1
SP  - 859
EP  - 870
DO  - 10.1109/TCSS.2023.3296476
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166757754&doi=10.1109%2fTCSS.2023.3296476&partnerID=40&md5=6ea61d6271ded40b6d8da749bbec8d53
AB  - Aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarity of a given specific aspect in the sentence. Recent studies focus on leveraging graph convolutional neural networks to encode both syntactic and semantic information. However, current syntactic parsers, which are not specifically for ABSA, introduce noise to the syntactic information. Besides, ongoing studies ignore the distinctiveness of semantics and syntax. To address these issues, we proposed an enhanced syntactic and semantic graph convolutional network (GCN) with contrastive learning in this article. An aspect-oriented syntactic graph is constructed with aspect-specific perturbed masking for reducing the syntactic noise, and a semantic graph is established with self-Attention weights from bidirectional encoder representation from transformers (BERT). The semantic and syntactic representations are further enhanced by both sentiment polarity-based supervised contrastive learning and syntactic reliability-based unsupervised contrastive learning. Furthermore, label embeddings of syntactic reliability are learned to determine the weights of syntactic and semantic information. Extensive experiments on four publicly available datasets demonstrate that our model is more competitive than the state-of-The-Arts.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Guan2024Enhanced
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Guan, S.
AU  - Zou, Q.
AU  - Wu, H.
AU  - Tiwari, P.
AU  - Ding, Y.
TI  - AMDGT: Attention aware multi-modal fusion using a dual graph transformer for drug–disease associations prediction
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 284
C7  - 111329
DO  - 10.1016/j.knosys.2023.111329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181175754&doi=10.1016%2fj.knosys.2023.111329&partnerID=40&md5=4258f563d0b0125f03154265479fc3ab
AB  - Identification of new indications for existing drugs is crucial through the various stages of drug discovery. Computational methods are valuable in establishing meaningful associations between drugs and diseases. However, most methods predict the drug–disease associations based solely on similarity data, neglecting valuable biological and chemical information. These methods often use basic concatenation to integrate information from different modalities, limiting their ability to capture features from a comprehensive and in-depth perspective. Therefore, a novel multimodal framework called AMDGT was proposed to predict new drug associations based on dual-graph transformer modules. By combining similarity data and complex biochemical information, AMDGT understands the multimodal feature fusion of drugs and diseases effectively and comprehensively with an attention-aware modality interaction architecture. Extensive experimental results indicate that AMDGT surpasses state-of-the-art methods in real-world datasets. Moreover, case and molecular docking studies demonstrated that AMDGT is an effective tool for drug repositioning. Our code is available at GitHub: https://github.com/JK-Liu7/AMDGT. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; FMS:C; 
LB  - Liu2024AMDGT
ER  -

TY  - JOUR
AU  - Zhang, W.
AU  - Xu, Z.
AU  - Wang, F.
AU  - Liu, J.
TI  - Proffler: Toward Collaborative and Scalable Edge-Assisted Crowdsourced Livecast
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 2
SP  - 3539
EP  - 3549
DO  - 10.1109/JIOT.2023.3297843
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176341611&doi=10.1109%2fJIOT.2023.3297843&partnerID=40&md5=2c7a89c078a160e6ca969f7e33ec1c5b
AB  - In recent years, crowdsourced livecast has seen remarkable progress due to the interactivity and real-time nature, playing an essential role in multimedia applications in the post-epidemic era. Given the delay sensitivity, large viewing volumes, and heterogeneous viewing patterns, the traditional video streaming methods fail to provide the optimized Quality of Experience (QoE) for viewers using the minimum system cost over an edge-assisted service architecture. The emerging technology of mobile edge computing (MEC) offers a new perspective of reducing user latency and enhancing the quality of dispatched videos in a promising way. In this article, we propose Proffler, an integrated framework that addresses this problem through effective stream caching at the network edge server. We first examine the underlying correlations in viewing patterns across different regions and propose a novel transformer-based algorithm, Chili-TF, that achieves accurate viewer request prediction, even for regions with insufficient data. We then design a scalable algorithm, U2VR, that achieves near-optimal video stream allocation as well as viewer scheduling. Extensive real-data-driven experiments further confirm that Proffler can achieve improvements of 20%-55% in average QoE compared to state-of-the-art solutions.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhang2024Proffler
ER  -

TY  - JOUR
AU  - Qi, M.
AU  - Wang, Q.
AU  - Zhuang, S.
AU  - Zhang, K.
AU  - Li, K.
AU  - Liu, Y.
AU  - Yang, Y.
TI  - Exploring reliable infrared object tracking with spatio-temporal fusion transformer
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 284
C7  - 111234
DO  - 10.1016/j.knosys.2023.111234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178657797&doi=10.1016%2fj.knosys.2023.111234&partnerID=40&md5=a85f175b4049cb01f148aa66c2cdbe39
AB  - Currently, most thermal infrared (TIR) trackers rely on feature matching between the search image and a fixed template cropped from the first frame. Some Siam-based TIR trackers with a template update mechanism introduce historical prediction information in the temporal dimension through correlation filters. However, their feature characterization capability is inadequate to resist target scale variations, appearance changes, and occlusion. To address this challenge, we explore a novel spatio-temporal fusion Transformer (STFT) model to realize robust TIR object tracking. Our approach involves a Transformer-based encoder–decoder that fuses spatio-temporal information. Specifically, we design a dynamic template update strategy based on salient points feature(SPF) representation, which allows the model to leverage the most powerful spatio-temporal information by retrieving multiple salient points on the target image. To further fortify the dynamic template update strategy, we propose an IoU-Aware target state estimation head that utilizes the joint representation of target classification and localization. An IoU-Aware criterion is developed for quality estimation of the dynamic template. The proposed STFT-Net approach has been put to the evaluation on three challenging benchmarks, with extensive experimental results showcasing its superior performance in contrast to acclaimed tracking algorithms. The code is available at https://github.com/qinxin-wh/STFT-Net. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Qi2024Exploring
ER  -

TY  - JOUR
AU  - Li, Y.
TI  - Short Text Semantic Sentiment Analysis Based on Dual Channel Aspect Attention in Intelligent Systems
PY  - 2024
T2  - International Journal on Semantic Web and Information Systems
VL  - 20
IS  - 1
DO  - 10.4018/IJSWIS.336480
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183453461&doi=10.4018%2fIJSWIS.336480&partnerID=40&md5=506f26c2bf8cee9f21a9fe34a1ccf54a
AB  - Traditional deep learning models for text sentiment analysis fail to fully harness the contextual semantic information of aspect nodes or use prior sentiment resources. This paper proposes a dual channel sentiment analysis model named M2BERT-BLSTM AA that is based on an enhanced Bidirectional Encoder Representations from Transformers(BERT)and Bidirectional Long short-term memory(BLSTM) model and incorporates a Dual Attention Mechanism. Firstly, an emotional resource database is constructed using existing emotional resources. Secondly, vectors are concatenated following mean and max pooling along the dimension of sentence length. These semantic features mitigate evaluation imbalance.Then the text and sentiment information are encoded separately, using distinct Attention Mechanism(Att-M) to extract contextual relationships and emotional features. The model’s Aspect-Based multi-class sentiment prediction accuracies on the three Chinese datasets of Meituan ordering, restaurants, and laptops are 75.2%, 87.5%, and 75%, respectively, showing improved performance on sentiment classification. © 2024 IGI Global. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Short
ER  -

TY  - JOUR
AU  - Vo, A.H.
AU  - Nguyen, B.T.
TI  - A framework-based transformer and knowledge distillation for interior style classification
PY  - 2024
T2  - Neurocomputing
VL  - 565
C7  - 126972
DO  - 10.1016/j.neucom.2023.126972
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175715052&doi=10.1016%2fj.neucom.2023.126972&partnerID=40&md5=75600dfd9a380db3fa8faac3e505dabf
AB  - Interior style classification is an interesting problem which has potential applications both commercial and academic communities. This task aims to devise interior design styles automatically. Thus, interior designers will explore customers’ tastes and then precisely provide suggestions for decor inspiration based on their preferences. Recently, Convolutional Neural Networks (CNNs) have been considered the de-facto standard in computer vision tasks. Therefore, several current works have tended to address interior style classification using CNN-based architectures. Moreover, transformer-based architectures and attention-based encoder–decoder models have been proven successfully in computer vision and natural language processing tasks. Sequentially, more studies have been arguing the efficiency of combining CNN-based architectures and transformer-based architectures for normal image classification problems. In this project, we focus on finding an architecture network that is suitable for the interior style classification problem. We propose a robustness method to address interior style design classification, named ISC-DeIT. The proposed method is based on Data-efficient image transformer architectures and knowledge distillation, which can be trained on small datasets effectively. Especially, a proposed additional module is plugged to leverage learning feature representations for improving predictive accuracy. Experiments were carried out on a new curated dataset with five interior styles including Art-Decor, Hitech, Indochina, Industrial, and Scandinavian. Empirical results of ISC- DeiT indicated that the ability of prediction for interior style classification of the proposed method has been increased significantly, compared with other state-of-the-art methods. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Vo2024framework-based
ER  -

TY  - JOUR
AU  - Sharma, S.
AU  - Sharma, R.
AU  - Datta, A.
TI  - (Mis)leading the COVID-19 Vaccination Discourse on Twitter: An Exploratory Study of Infodemic Around the Pandemic
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 1
SP  - 352
EP  - 362
DO  - 10.1109/TCSS.2022.3225216
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144755761&doi=10.1109%2fTCSS.2022.3225216&partnerID=40&md5=3398ab1f994e8c81b94ce31cf5adc9e9
AB  - In this work, we collect a moderate-sized representative corpus of tweets (over 200 000) pertaining to COVID-19 vaccination spanning for a period of seven months (September 2020-March 2021). Following a transfer learning approach, we utilize a pretrained transformer-based XLNet model to classify tweets as misleading or nonmisleading and manually validate the results with random subsets of samples. We leverage this to study and contrast the characteristics of tweets in the corpus that are misleading in nature against non-misleading ones. This exploratory analysis enables us to design features such as sentiments, hashtags, nouns, and pronouns which can, in turn, be exploited for classifying tweets as (non-)misleading using various machine learning (ML) models in an explainable manner. Specifically, several ML models are employed for prediction, with up to 90% accuracy, with the importance of each feature is explained using SHAP Explainable AI (XAI) tool. While the thrust of this work is principally exploratory in nature to obtain insight on the online discourse on COVID-19 vaccination, we conclude the article by outlining how these insights provide the foundations for a more actionable approach to mitigate misinformation. We have made the curated data as well as the accompanying code available so that the research community at large can reproduce, compare against, or build upon this work. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Sharma2024Mis)leading
ER  -

TY  - JOUR
AU  - Xian, R.
AU  - Wang, L.
AU  - Zhang, B.
AU  - Li, J.
AU  - Xian, R.
AU  - Li, J.
TI  - Identification Method of Interturn Short Circuit Fault for Distribution Transformer Based on Power Loss Variation
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 2
SP  - 2444
EP  - 2454
DO  - 10.1109/TII.2023.3292972
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164775410&doi=10.1109%2fTII.2023.3292972&partnerID=40&md5=081c8a6ab380bd2d2c98e34b8cf6eca1
AB  - Interturn short circuit fault of distribution transformer winding occurs frequently and is difficult to accurately real-time monitoring, which seriously affects the reliability of the distribution network power supply. Therefore, the identification method of interturn short circuit faults for distribution transformers based on power loss variation is proposed to realize the online monitoring of winding interturn short circuit faults and early warning of insulation deterioration. First, the 'field-circuit' coupling three-dimensional simulation model is established as consistent with the actual transformer. On the premise of verifying the reliability and accuracy of the model, the variation characteristics of each physical quantity are simulated and analyzed when a single-turn short circuit occurs in different positions in the secondary side inner and outer winding of the distribution transformer. The winding power loss with the most significant change rate and easy to detect is obtained as the sensitive state variable. Then, by changing the winding interturn insulation resistance and the number of short-circuit turns, the gradual altering process of interturn insulation deterioration is simulated, and the variation law of winding current and power loss in the main circuit is explored. Moreover, the relationship between the interturn insulation state and influence factors including the critical resistance value of interturn insulation deterioration and insulation collapse, the power loss rate of change is analyzed. Finally, a method of interturn short circuit's fault identification of distribution transformer is proposed, which can diagnose the interturn insulation state of transformer winding in real-time and predict the interturn short-circuit fault.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Xian2024Identification
ER  -

TY  - JOUR
AU  - Ke, F.
AU  - Wang, W.
AU  - Tan, W.
AU  - Du, L.
AU  - Jin, Y.
AU  - Huang, Y.
AU  - Yin, H.
TI  - HiTSKT: A hierarchical transformer model for session-aware knowledge tracing
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 284
C7  - 111300
DO  - 10.1016/j.knosys.2023.111300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180536062&doi=10.1016%2fj.knosys.2023.111300&partnerID=40&md5=769b24966467dc5848f1ba20b6defa44
AB  - Knowledge tracing (KT) aims to leverage students’ learning histories to estimate their mastery levels on a set of pre-defined skills, based on which the corresponding future performance can be accurately predicted. In practice, a student's learning history comprises answers to sets of massed questions, each known as a session, rather than merely being a sequence of independent answers. Theoretically, within and across these sessions, students’ learning dynamics can be very different. Therefore, how to effectively model the dynamics of students’ knowledge states within and across the sessions is crucial for handling the KT problem. Most existing KT models treat student's learning records as a single continuing sequence, without capturing the sessional shift of students’ knowledge state. To address the above issue, we propose a novel hierarchical transformer model, named HiTSKT, comprises an interaction(-level) encoder to capture the knowledge a student acquires within a session, and a session(-level) encoder to summarize acquired knowledge across the past sessions. To predict an interaction in the current session, a knowledge retriever integrates the summarized past-session knowledge with the previous interactions’ information into proper knowledge representations. These representations are then used to compute the student's current knowledge state. Additionally, to model the student's long-term forgetting behaviour across the sessions, a power-law-decay attention mechanism is designed and deployed in the session encoder, allowing it to emphasize more on the recent sessions. Extensive experiments on four public datasets demonstrate that HiTSKT achieves new state-of-the-art performance on all the datasets compared with seven state-of-the-art KT models. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; 
LB  - Ke2024HiTSKT
ER  -

TY  - JOUR
AU  - Grądzki, P.
AU  - Wójcik, P.
TI  - Is attention all you need for intraday Forex trading?
PY  - 2024
T2  - Expert Systems
VL  - 41
IS  - 2
C7  - e13317
DO  - 10.1111/exsy.13317
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153594621&doi=10.1111%2fexsy.13317&partnerID=40&md5=d55407ab1c24270d3e64a34ed24c27b4
AB  - The main objective of this paper is to analyse whether the Transformer neural network, which has become one of the most influential algorithms in Artificial Intelligence over the last few years, exhibits predictive capabilities for high-frequency Forex data. The prediction task is to classify short-term Forex movements for six currency pairs and five different time intervals from 60 to 720 min. We find that the Transformer exhibits high predictive power in the context of intraday Forex trading. This performance is slightly better than for the carefully selected benchmark – ResNet-LSTM, which currently is a state-of-the-art algorithm. Since intraday Forex trading based on deep learning models is largely unexplored, we offer insight on which currency pair and time interval are amenable to devising a profitable trading strategy. We also show that high predictive accuracy can be misleading in real world trading for short time intervals, as models trained on OHLC data tend to report the highest accuracy when the spread cost is the highest. This renders assessment based on typical machine learning metrics overly optimistic. Therefore, it is critical to backtest frequent intraday Forex trading strategies with realistic cost assumptions, which is rarely the case in empirical literature. Lastly, sensitivity analysis shows that the length of the time interval used for training does not play a critical role in the Transformer's predictive capabilities, whereas features derived from technical analysis are essential. © 2023 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Grądzki2024Is
ER  -

TY  - JOUR
AU  - Ma, J.
AU  - Chen, Y.
AU  - Chen, L.
AU  - Tang, Z.
TI  - Dual-attention pyramid transformer network for No-Reference Image Quality Assessment
PY  - 2024
T2  - Expert Systems with Applications
VL  - 257
C7  - 125008
DO  - 10.1016/j.eswa.2024.125008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200992895&doi=10.1016%2fj.eswa.2024.125008&partnerID=40&md5=c1f400289e7a5e14ae6ee66c97a4bbb5
AB  - No-Reference Image Quality Assessment (NR-IQA) is a fundamental and important task in the field of computer vision. Most NR-IQA methods have limitation in making desirable NR-IQA performance due to the lack of sufficiently rich features. To address this problem, we propose a dual-attention pyramid Transformer network for NR-IQA. In the proposed method, a feature extraction module is firstly used to extract multi-scale features which contain rich distortion and semantic information. Then, a pyramid Transformer network with channel and spatial attentions is designed to learn multi-scale global features from spatial and channel aspects. The combination of pyramid structure and dual attentions enables our network to focus on features in different regions of the image and learn richer and more comprehensive global features. This in turn improves the quality score prediction performance. Finally, the score prediction module predicts the quality scores in different stages of the pyramid Transformer network by channel adaptive prediction branches and determines the final quality score by aggregating these quality scores. Extensive experiments performed on four widely used public databases show that our proposed method is superior to some state-of-the-art NR-IQA methods in perceiving image quality. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ma2024Dual-attention
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Tang, C.
AU  - Luo, H.
AU  - Li, Q.
AU  - Peng, X.
AU  - Zhang, J.
AU  - Li, M.
AU  - Wei, Y.
TI  - Joint spatio-temporal modeling for visual tracking
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 283
C7  - 111206
DO  - 10.1016/j.knosys.2023.111206
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177552413&doi=10.1016%2fj.knosys.2023.111206&partnerID=40&md5=eb4a4daf0354c857a53d558b01b17a07
AB  - Similarity-based approaches have made significant progress in visual object tracking (VOT). Although these methods work well in simple scenes, they ignore the continuous spatio-temporal connection of the object in the video sequence. For this reason, tracking by spatial matching solely can lead to tracking failures because of distractors and occlusion. In this paper, we propose a spatio-temporal joint-modeling tracker named STTrack which implicitly builds continuous connections between the temporal and spatial aspects of the sequence. Specifically, we first design a time-sequence iteration strategy (TSIS) to concentrate on the temporal connection of the object in the video sequence. Then, we propose a novel spatial temporal interaction Transformer network (STIN) to capture the spatio-temporal correlation of the object between frames. The proposed STIN module is robust in object occlusion because it explores the dynamic state change dependencies of the object. Finally, we introduce a spatio-temporal query to suppress distractors by iteratively propagating the target prior. Extensive experiments on six tracking benchmark datasets demonstrate that the proposed STTrack achieves excellent performance while operating in real-time. The code is publicly available at https://github.com/nubsym/STTrack. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; 
LB  - Sun2024Joint
ER  -

TY  - JOUR
AU  - Chen, S.
AU  - Ren, S.
AU  - Wang, G.
AU  - Huang, M.
AU  - Xue, C.
TI  - Interpretable CNN-Multilevel Attention Transformer for Rapid Recognition of Pneumonia from Chest X-Ray Images
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 2
SP  - 753
EP  - 764
DO  - 10.1109/JBHI.2023.3247949
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149372989&doi=10.1109%2fJBHI.2023.3247949&partnerID=40&md5=d3284b7d84826b88cd093b9dbe79bd38
AB  - Chest imaging plays an essential role in diagnosing and predicting patients with COVID-19 with evidence of worsening respiratory status. Many deep learning-based approaches for pneumonia recognition have been developed to enable computer-aided diagnosis. However, the long training and inference time makes them inflexible, and the lack of interpretability reduces their credibility in clinical medical practice. This paper aims to develop a pneumonia recognition framework with interpretability, which can understand the complex relationship between lung features and related diseases in chest X-ray (CXR) images to provide high-speed analytics support for medical practice. To reduce the computational complexity to accelerate the recognition process, a novel multi-level self-attention mechanism within Transformer has been proposed to accelerate convergence and emphasize the task-related feature regions. Moreover, a practical CXR image data augmentation has been adopted to address the scarcity of medical image data problems to boost the model's performance. The effectiveness of the proposed method has been demonstrated on the classic COVID-19 recognition task using the widespread pneumonia CXR image dataset. In addition, abundant ablation experiments validate the effectiveness and necessity of all of the components of the proposed method.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Chen2024Interpretable
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Yang, P.
AU  - Zhang, B.
AU  - Hu, L.
AU  - Lv, W.
AU  - Lin, C.
AU  - Zhang, C.
AU  - Wang, Q.
TI  - Performance Prediction for Deep Learning Models with Pipeline Inference Strategy
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 2
SP  - 2964
EP  - 2978
DO  - 10.1109/JIOT.2023.3294253
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164671057&doi=10.1109%2fJIOT.2023.3294253&partnerID=40&md5=1f4b66c6e07962c28ae3d0b20d06e42f
AB  - For heterogeneous multiprocessor system-on-chips (HMPSoCs), a reasonable pipeline design can significantly improve the inference performance of deep learning (DL) models. The pipeline design optimization can be modeled as a search problem where an accurate prediction model can efficiently speed up the search process. However, the performance prediction of DL models for the pipeline inference strategy is challenging because of the interlayer effect, inference details, and variety of model structures. In this article, we propose TPPNet, a transformer-based model for predicting the inference performance of various DL models with the pipeline inference strategy. TPPNet represents the DL model as an execution sequence with operators and hardware details to extract the hidden factors between layers. Moreover, we apply the multitask learning (MTL) method to accurately predict throughput and latency metrics by constructing a predictive model. To the best of our knowledge, this is the first study dedicated to pipeline inference performance prediction for the DL model on HMPSoCs. We evaluate TPPNet on six well-known DL models using RK3399. The experimental outcomes affirm the high accuracy of TPPNet and its capability to significantly reduce the time overhead associated with pipeline exploration.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Performance
ER  -

TY  - JOUR
AU  - Jovanovic, L.
AU  - Bacanin, N.
AU  - Zivkovic, M.
AU  - Antonijevic, M.
AU  - Jovanovic, B.
AU  - Sretenovic, M.B.
AU  - Strumberger, I.
TI  - Machine learning tuning by diversity oriented firefly metaheuristics for Industry 4.0
PY  - 2024
T2  - Expert Systems
VL  - 41
IS  - 2
C7  - e13293
DO  - 10.1111/exsy.13293
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152248358&doi=10.1111%2fexsy.13293&partnerID=40&md5=3c6ee61edf9989e2ad63db1ad0d4af6a
AB  - The progress of Industrial Revolution 4.0 has been supported by recent advances in several domains, and one of the main contributors is the Internet of Things. Smart factories and healthcare have both benefited in terms of leveraged quality of service and productivity rate. However, there is always a trade-off and some of the largest concerns include security, intrusion, and failure detection, due to high dependence on the Internet of Things devices. To overcome these and other challenges, artificial intelligence, especially machine learning algorithms, are employed for fault prediction, intrusion detection, computer-aided diagnostics, and so forth. However, efficiency of machine learning models heavily depend on feature selection, predetermined values of hyper-parameters and training to deliver a desired result. This paper proposes a swarm intelligence-based approach to tune the machine learning models. A novel version of the firefly algorithm, that overcomes known deficiencies of original method by employing diversification-based mechanism, has been proposed and applied to both feature selection and hyper-parameter optimization of two machine learning models—XGBoost and extreme learning machine. The proposed approach has been tested on four real-world Industry 4.0 data sets, namely distributed transformer monitoring, elderly fall prediction, BoT-IoT, and UNSW-NB 15. Achieved results have been compared to the results of eight other cutting-edge metaheuristics, that have been implemented and tested under the same conditions. The experimental outcomes strongly indicate that the proposed approach significantly outperformed all other competitor metaheuristics in terms of convergence speed and results' quality measured with standard metrics—accuracy, precision, recall, and f1-score. © 2023 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Jovanovic2024Machine
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Piao, Y.
AU  - Qi, N.
TI  - STFT: Spatial and temporal feature fusion for transformer tracker
PY  - 2024
T2  - IET Computer Vision
VL  - 18
IS  - 1
SP  - 165
EP  - 176
DO  - 10.1049/cvi2.12233
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169170464&doi=10.1049%2fcvi2.12233&partnerID=40&md5=be53c7f9883284d5936dc0b16e5b82d8
AB  - Siamese-based trackers have demonstrated robust performance in object tracking, while Transformers have achieved widespread success in object detection. Currently, many researchers use a hybrid structure of convolutional neural networks and Transformers to design the backbone network of trackers, aiming to improve performance. However, this approach often underutilises the global feature extraction capability of Transformers. The authors propose a novel Transformer-based tracker that fuses spatial and temporal features. The tracker consists of a multilayer spatial feature fusion network (MSFFN), a temporal feature fusion network (TFFN), and a prediction head. The MSFFN includes two phases: feature extraction and feature fusion, and both phases are constructed with a Transformer. Compared with the hybrid structure of “CNNs + Transformer,” the proposed method enhances the continuity of feature extraction and the ability of information interaction between features, enabling comprehensive feature extraction. Moreover, to consider the temporal dimension, the authors propose a TFFN for updating the template image. The network utilises the Transformer to fuse the tracking results of multiple frames with the initial frame, allowing the template image to continuously incorporate more information and maintain the accuracy of target features. Extensive experiments show that the tracker STFT achieves state-of-the-art results on multiple benchmarks (OTB100, VOT2018, LaSOT, GOT-10K, and UAV123). Especially, the tracker STFT achieves remarkable area under the curve score of 0.652 and 0.706 on the LaSOT and OTB100 benchmark respectively. © 2023 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhang2024STFT
ER  -

TY  - JOUR
AU  - Song, Y.
AU  - Lu, Y.
AU  - Chen, L.
AU  - Luo, Y.
TI  - Hierarchical Multi-Scale Enhanced Transformer for Medical Image Segmentation
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3515477
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214288069&doi=10.1109%2fJBHI.2024.3515477&partnerID=40&md5=ad92d7112ba996efb2e7fc35334e0791
AB  - Segmentation is an important prerequisite for developing model healthcare systems, particularly for disease diagnosis and treatment planning. In the field of medical image segmentation, the U-shaped architecture, commonly referred to as U-Net, has emerged as the de facto standard and achieved remarkable success. However, due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency. Recent transformer-based models, designed for sequence-to-sequence prediction, have emerged as an alternative to traditional architectures, featuring innate global self-attention mechanisms. Unfortunately, they may sometimes suffer from limited localization abilities due to a lack of sufficient low-level details. To merit both Transformers and U-Net, in this paper, we propose a novel two-channel self-attention mechanism U-network, which performs feature extraction from two channels, CNN and Transformer, respectively. Compared to previous models, we propose two hierarchical feature fusion strategies from both spatial and channel dimensions. Moreover, to further promote the model performance, a loss function that can dynamically adjust the weights according to the output of each layer is constructed. Experimental results on five different datasets show that our method performs consistently outperforms state-of-the-art methods, and it also has an outstanding generalization ability to various medical image modalities.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Song2024Hierarchical
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Song, P.
AU  - Stone, T.
AU  - Weller, A.
AU  - Pattinson, S.
TI  - Ankle Kinematics Estimation using Artificial Neural Network and Multimodal IMU Data
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3514669
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212266136&doi=10.1109%2fJBHI.2024.3514669&partnerID=40&md5=8b4f1b2ad039f16406ac9185d2d256a1
AB  - Inertial measurement units (IMUs) have become attractive for monitoring joint kinematics due to their portability and versatility. However, their limited accuracy, inability to analyze data in real-time, and complex data fusion algorithms requiring precise sensor-to-segment calibrations hinder their clinical and daily use. This paper introduces KEEN (KinEmatics Estimation Network), an innovative framework that exploits lightweight artificial neural networks (ANNs) to provide real-time predictions of multi-plane ankle kinematics using a minimal number of IMUs, without calibration requirements. Five ANN algorithms were developed and evaluated using 42 inputs derived from four IMUs in both intra-subject and inter-subject tasks. Extensive experimental results yielded exciting findings: even a single IMU located at the heel can provide clinically acceptable estimations of ankle kinematics, implying significant potential for cost and energy savings. Statistical analysis demonstrated the superiority of the developed Long Short-Term Memory (LSTM) network over the other models in intra-subject tasks, achieving impressive accuracy (RMSE: 1.88° ± 0.02°, MAE: 1.41° ± 0.01°, and r2 score: 0.93 ± 0.01), indicating strong generalization within the same subject. In inter-subject tasks, the convolutional neural network (CNN) and the CNN-LSTM models showed comparable performance but statistically outperformed the other models in terms of estimation accuracy across various inputs. When using a single IMU, the CNN model achieved the lowest error (RMSE: 4.13° ± 0.55°, MAE: 3.33° ± 0.48°, and r2 score: 0.50 ± 0.21), showcasing its effective generalization to new subjects. Furthermore, deploying the CNN into a microcontroller, with a sinlge IMU at the heel, resulted in promising real-time ankle kinematics estimations (RMSE: 3.34° ± 0.48°, MAE: 2.68° ± 0.46° and r2 score: 0.63 ± 0.07). Overall, this research highlights the potential of combining IMUs with ANNs as reliable and practical tools for early prevention and rehabilitation of ankle injuries.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Ankle
ER  -

TY  - JOUR
AU  - Wan, C.
AU  - Nnamdi, M.C.
AU  - Shi, W.
AU  - Smith, B.
AU  - Purnell, C.
AU  - Wang, M.D.
TI  - Advancing Sleep Disorder Diagnostics: A Transformer-based EEG Model for Sleep Stage Classification and OSA Prediction
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3512616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212248554&doi=10.1109%2fJBHI.2024.3512616&partnerID=40&md5=ddce3eee073d4f78f915869a0f54052f
AB  - Sleep disorders, particularly Obstructive Sleep Apnea (OSA), have a considerable effect on an individual's health and quality of life. Accurate sleep stage classification and prediction of OSA are crucial for timely diagnosis and effective management of sleep disorders. In this study, we develop a sequential network that enhances sleep stage classification by incorporating self-attention mechanisms and Conditional Random Fields (CRF) into a deep learning model comprising multi-kernel Convolutional Neural Networks (CNNs) and Transformer-based encoders. The self-attention mechanism enables the model to focus on the most discriminative features extracted from single-channel electroencephalography (EEG) recordings, while the CRF module captures the temporal dependencies between sleep stages, improving the model's ability to learn more plausible sleep stage sequences. Moreover, we explore the relationship between sleep stages and OSA severity by utilizing the predicted sleep stage features to train various regression models for Apnea-Hypopnea Index (AHI) prediction. Our experiments demonstrate an improved sleep stage classification performance of 78.7%, particularly on datasets with diverse AHI values, and highlight the potential of leveraging sleep stage information for monitoring OSA. By employing advanced deep learning techniques, we thoroughly explore the intricate relationship between sleep stages and sleep apnea, laying the foundation for more precise and automated diagnostics of sleep disorders.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wan2024Advancing
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Liang, Y.
AU  - Wang, J.
AU  - Ye, Q.
AU  - Cai, Y.
TI  - Multibranch Attentive Transformer With Joint Temporal and Social Correlations for Traffic Agents Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3517656
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213206867&doi=10.1109%2fTCSS.2024.3517656&partnerID=40&md5=79009fa2018282f654ff3846f4936238
AB  - Accurately predicting the future trajectories of traffic agents is paramount for autonomous unmanned systems, such as self-driving cars and mobile robotics. Extracting abundant temporal and social features from trajectory data and integrating the resulting features effectively pose great challenges for predictive models. To address these issues, this article proposes a novel multibranch attentive transformer (MBAT) trajectory prediction network for traffic agents. Specifically, to explore and reveal diverse correlations of agents, we propose a decoupled temporal and spatial feature learning module with multibranch to extract temporal, spatial, as well as spatiotemporal features. Such design ensures each branch can be specifically tailored for different types of correlations, thus enhancing the flexibility and representation ability of features. Besides, we put forward an attentive transformer architecture that simultaneously models the complex correlations possibly occurring in historical and future timesteps. Moreover, the temporal, spatial, and spatiotemporal features can be effectively integrated based on different types of attention mechanisms. Empirical results demonstrate that our model achieves outstanding performance on public ETH, UCY, SDD, and INTERACTION datasets. Detailed ablation studies are conducted to verify the effectiveness of the model components. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chen2024Multibranch
ER  -

TY  - JOUR
AU  - Jo, J.
AU  - Chung, H.
AU  - Lee, J.S.
AU  - Wee, D.
AU  - Cho, N.I.
TI  - UPVIS: upsampled video query for offline video instance segmentation
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-20533-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212819971&doi=10.1007%2fs11042-024-20533-z&partnerID=40&md5=4260cf326fa830ff9907ba8ff8f5e01b
AB  - This paper presents a new approach for offline video instance segmentation (VIS) by integrating upsampling layers into the Transformer decoder. Existing offline VIS techniques set the temporal dimension of the video query as either one or the length of the input video, which poses challenges for tracking due to limited query capacity in the former and implementation issues in the latter. To overcome these challenges, we introduce upsampling of video queries along the temporal axis during the decoding process. This eases the induction of association property since the same instance information is expanded along the temporal axis, considering temporal adjacency. Additionally, by representing an instance with a diverse set of queries, more refined predictions become possible. We also address the ambiguity that arises when the input video length is not divisible by the video queries’ temporal length by interpolating the resultant video queries to match the video sequences. To the best of our knowledge, this is the first paper that handles video queries with arbitrary temporal dimensions, neither one nor the length of the input video. We have conducted extensive experiments to validate the effectiveness of the proposed method in the offline scheme on YouTubeVIS-2019/2021/2022, and OVIS benchmarks. In particular, our proposed method exhibited notable performance in handling long and challenging videos. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jo2024UPVIS
ER  -

TY  - JOUR
AU  - Wang, B.
AU  - Li, Z.
AU  - Xu, Z.
AU  - Zhang, J.
TI  - Casformer: Information Popularity Prediction With Adaptive Cascade Sampling and Graph Transformer in Social Networks
PY  - 2024
T2  - IEEE Transactions on Big Data
DO  - 10.1109/TBDATA.2024.3524839
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214127453&doi=10.1109%2fTBDATA.2024.3524839&partnerID=40&md5=c514f27f744f391ad64849c402daca95
AB  - Predicting the popularity of information in social networks is crucial for effective social marketing and recommendation systems. However, accurately comprehending the complex dynamics of information diffusion remains a challenging task. Existing methods, including feature-based approaches, point process models, and deep learning techniques, often fail to capture the fine-grained features of information cascades, such as dynamic diffusion patterns, cascade statistics, and the interplay between spatial and temporal information. To address these limitations, we propose Casformer, a novel graph-based Transformer architecture that effectively learns both micro-level time-aware structural information and macro-level long-term influence along the information propagation process. Casformer employs a cascade attention network (CAT) to capture the micro-level features and a Transformer model to learn the macro-level influence. Furthermore, we introduce an adaptive cascade graph sampling strategy based on the temporal diffusion pattern and cascade statistics of information to obtain the most informative cascade graph sequence. By leveraging multi-level fine-grained evolving features of information cascades, Casformer achieves high accuracy in information popularity prediction. Experimental results on real-world social network and scientific citation network datasets demonstrate the effectiveness and superiority of Casformer compared to state-of-the-art methods in information popularity prediction.  © 2015 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Casformer
ER  -

TY  - JOUR
AU  - Gangan, M.P.
AU  - Kadan, A.
AU  - Lajish, V.L.
TI  - Toward Exploring Fairness in Visual Transformer Based Natural and GAN Image Detection Systems
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3509340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212768031&doi=10.1109%2fTCSS.2024.3509340&partnerID=40&md5=6b5396d416b0ab4267ba6bab61d92661
AB  - Image forensics research has recently witnessed a lot of advancements toward developing computational models capable of accurately detecting natural images captured by cameras and generative adversarial network (GAN) generated images. However, it is also important to ensure whether these computational models are fair enough and do not produce biased outcomes that could eventually harm certain societal groups or cause serious security threats. Exploring fairness in image forensic algorithms is an initial step toward mitigating these biases. This study explores bias in visual transformer based image forensic algorithms that classify natural and GAN images, since visual transformers are recently being widely used in image classification based tasks, including in the area of image forensics. The proposed study procures bias evaluation corpora to analyze bias in gender, racial, affective, and intersectional domains using a wide set of individual and pairwise bias evaluation measures. Since the robustness of the algorithms against image compression is an important factor to be considered in forensic tasks, this study also analyzes the impact of image compression on model bias. Hence, to study the impact of image compression on model bias, a two-phase evaluation setting is followed, where the experiments are carried out in uncompressed and compressed evaluation settings. The study could identify bias existences in the visual transformer based models distinguishing natural and GAN images, and also observes that image compression impacts model biases, predominantly amplifying the presence of biases in class GAN predictions. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Gangan2024Toward
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Chen, J.
AU  - Li, B.
AU  - Zhang, Y.
AU  - Zhang, R.
AU  - Gong, S.
AU  - Ma, X.
AU  - Tian, Z.
TI  - TDG-Mamba: Advanced Spatiotemporal Embedding for Temporal Dynamic Graph Learning via Bidirectional Information Propagation
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3509399
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212545379&doi=10.1109%2fTCSS.2024.3509399&partnerID=40&md5=d6126700574494a73d971dc23908c2e2
AB  - Temporal dynamic graphs (TDGs), representing the dynamic evolution of entities and their relationships over time with intricate temporal features, are widely used in various real-world domains. Existing methods typically rely on mainstream techniques such as transformers and graph neural networks (GNNs) to capture the spatiotemporal information of TDGs. However, despite their advanced capabilities, these methods often struggle with significant computational complexity and limited ability to capture temporal dynamic contextual relationships. Recently, a new model architecture called mamba has emerged, noted for its capability to capture complex dependencies in sequences while significantly reducing computational complexity. Building on this, we propose a novel method, TDG-mamba, which integrates mamba for TDG learning. TDG-mamba introduces deep semantic spatiotemporal embeddings into the mamba architecture through a specially designed spatiotemporal prior tokenization module (SPTM). Furthermore, to better leverage temporal information differences and enhance the modeling of dynamic changes in graph structures, we separately design a bidirectional mamba and a directed GNN for improved spatiotemporal embedding learning. Link prediction experiments on multiple public datasets demonstrate that our method delivers superior performance, with an average improvement of 5.11\% over baseline methods across various settings.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024TDG-Mamba
ER  -

TY  - JOUR
AU  - Wan, Z.
AU  - Hao, X.
AU  - Fan, X.
AU  - Zuo, W.
AU  - Zhao, D.
TI  - Enhancing No-Reference Audio-Visual Quality Assessment via Joint Cross-Attention Fusion
PY  - 2024
T2  - IEEE Signal Processing Letters
DO  - 10.1109/LSP.2024.3522855
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213861184&doi=10.1109%2fLSP.2024.3522855&partnerID=40&md5=c9b299cc158842a6bb5504d18d79ceec
AB  - As the consumption of multimedia content continues to rise, audio and video have become central to everyday entertainment and social interactions. This growing reliance amplifies the demand for effective and objective audio-visual quality assessment (AVQA) to understand the interaction between audio and visual elements, ultimately enhancing user satisfaction. However, existing state-of-the-art AVQA methods often rely on simplistic machine learning models or fully connected networks for audio-visual signal fusion, which limits their ability to exploit the complementary nature of these modalities. In response to this gap, we propose a novel no-reference AVQA method that utilizes joint cross-attention fusion of audio-visual perception. Our approach begins with a dual-stream feature extraction process that simultaneously captures long-range spatiotemporal visual features and audio features. The fusion model then dynamically adjusts the contributions of features from both modalities, effectively integrating them to provide a more comprehensive perception for quality score prediction. Experimental results on the LIVE-SJTU and UnB-AVC datasets demonstrate that our model outperforms state-of-the-art methods, achieving superior performance in audio-visual quality assessment  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wan2024Enhancing
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Wu, J.
AU  - Wang, X.
AU  - Yuan, Y.
AU  - Li, J.
AU  - Chen, G.
AU  - Wang, N.L.
AU  - Heng, P.-A.
TI  - Multi-scale Spatio-temporal Transformer-based Imbalanced Longitudinal Learning for Glaucoma Forecasting from Irregular Time Series Images
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3523298
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213991497&doi=10.1109%2fJBHI.2024.3523298&partnerID=40&md5=f176857c6cd5844baaff77aa2396e547
AB  - Glaucoma is one of the major eye diseases that leads to progressive optic nerve fiber damage and irreversible blindness, afflicting millions of individuals. Glaucoma forecast is a good solution to early screening and intervention of potential patients, which is helpful to prevent further deterioration of the disease. It leverages a series of historical fundus images of an eye and forecasts the likelihood of glaucoma occurrence in the future. However, the irregular sampling nature and the imbalanced class distribution are two challenges in the development of disease forecasting approaches. To this end, we introduce the Multi-scale Spatio-temporal Transformer Network (MSTformer) based on the transformer architecture tailored for sequential image inputs, which can effectively learn representative semantic information from sequential images on both temporal and spatial dimensions. Specifically, we employ a multi-scale structure to extract features at various resolutions, which can largely exploit rich spatial information encoded in each image. Besides, we design a time distance matrix to scale time attention in a non-linear manner, which could effectively deal with the irregularly sampled data. Furthermore, we introduce a temperature-controlled Balanced Softmax Cross-entropy loss to address the class imbalance issue. Extensive experiments on the Sequential fundus Images for Glaucoma Forecast (SIGF) dataset demonstrate the superiority of the proposed MST-former method, achieving an AUC of 96.6% for glaucoma forecasting. Besides, our method shows excellent generalization capability on the Alzheimer's Disease Neuroimaging Initiative (ADNI) MRI dataset, with an accuracy of 88.2% for mild cognitive impairment and Alzheimer's disease prediction, outperforming the compared method by a large margin. A series of ablation studies further verify the contribution of our proposed components in addressing the irregular sampled and class imbalanced problems.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Multi-scale
ER  -

TY  - JOUR
AU  - Zhu, Y.
AU  - Feng, L.
AU  - Zhou, F.
AU  - Li, W.
TI  - An Adaptive Ensemble Learning Paradigm With Spatial-Temporal Feature Extraction for Wireless Traffic Prediction
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
DO  - 10.1109/TNSM.2024.3522115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213433782&doi=10.1109%2fTNSM.2024.3522115&partnerID=40&md5=c6998f4b86f189c16a42caa79c2532bb
AB  - Accurately predicting traffic in a cellular network is challenging since the traffic time series integrated by various wireless services is non-stationary and reveals concealed spatial correlation among different cells. Due to that, the presence of bias in a single forecast model often hinders the ability to generalise under numerous circumstances in wireless traffic data, no particular approach stands out as clearly superior to the others. In this paper, we propose an adaptive ensemble learning paradigm that can benefit from centralizing individual forecast base models. It stacks the prediction outputs of several base learners due to the traffic dynamics characteristic. An improved convolutional neural network (CNN)-based representation learning method is designed to extract the high-order spatial-temporal features in the traffic data and obtain the adaptive weights of participating base learner models for the ensemble. The experimental results verify that the proposed ensemble approach can fully utilize spatial-temporal features and outperform individual statistical and machine-learning models regarding prediction accuracy. Furthermore, the ensemble method via stacking base models with fewer parameters is capable of generating predictions close to the large-parametric spatial-temporal transformer (ST-Tran) model produced.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhu2024Adaptive
ER  -

TY  - JOUR
AU  - Hou, Y.
AU  - Zhang, X.
AU  - Cao, X.
AU  - Lu, Z.
AU  - Yuan, X.
TI  - Vehicle Trajectory Prediction Model for Map-Free Scenes Using the Spatio-temporal Attentional Mechanism
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3506720
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210545272&doi=10.1109%2fJIOT.2024.3506720&partnerID=40&md5=89f8d85e7962a930b7def393c1bfda6f
AB  - The vehicle trajectory prediction is crucial for autonomous driving. The vast majority of existing trajectory prediction schemes depend on high definition (HD) maps. However, the HD knowledge is not invariably valid under many actual traffic scenarios. When map information is unreliable, vehicle trajectory prediction is a fundamental challenge that must be overcome in autonomous driving areas. Over the vehicle-road cooperation, this work has developed a spatio-temporal-attentional-mechanism based prediction model (STAM-P) for vehicle trajectories under map-free scenarios to precisely forecast future trajectories in the case of unreliable map information. Firstly, a temporal transformer encoder was used to capture and encode the state information of the vehicle at different time steps for extracting the vehicle temporal features of the trajectories. Secondly, a spatial encoder layer consisting of the static map convolutional layer and the dynamic spatial transformer in the spatial feature extraction layer was designed to capture and encode the interactions between vehicles to obtain the vehicle spatial features of the trajectories. Finally, the obtained temporal-spatial features were inputted into a multimodal decoding layer to decode and complete the trajectory prediction. Experimental results of the Argoverse dataset revealed that the proposed model outperformed other existing map-free prediction schemes and reached the level of other map-based trajectory prediction models in certain performance metrics.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hou2024Vehicle
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Wang, K.
AU  - Ye, L.
AU  - Yuan, X.
AU  - Wang, Y.
AU  - Yang, C.
AU  - Gui, W.
TI  - A Difference Metric Attention with Position Distance-Based Weighting for Transformer in Data Sequence Modeling of Industrial Processes
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
DO  - 10.1109/TII.2024.3488777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210735670&doi=10.1109%2fTII.2024.3488777&partnerID=40&md5=1c78679027b33bc54904eba240f731fa
AB  - Accurate feature extraction and quality variable prediction are critical problems for time sequences in industrial processes. However, industrial samples often exhibit strong temporal correlations with each other that have different positional distances, making it challenging for conventional data-driven models like long short-term memory (LSTM) and Vanilla transformer to capture these underlying features. In this article, a difference metric attention with position distance-based weighting is proposed for transformer (DMA-trans) in industrial time series modeling. First, the DMA is established to calculate the difference of query-key vector pair in transformer to measure the spatial similarity. In this fashion, the difference can accurately represent the spatial similarity of vectors, compared with the original dot product directly on two vectors. Then, positional distance-based weights are designed to capture the sample relevance that has different positional distances. This may help to extract more potential features because the closer samples tend to have higher relevance while there may be weak correlations if two samples are far in positional distance. The effectiveness of the DMA-trans model is validated in industrial hydrocracking processes for C5 content of the light naphtha and the final boiling point of the jet fuel. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Difference
ER  -

TY  - JOUR
AU  - Yang, S.
AU  - Li, Y.
AU  - Huang, L.
AU  - Liu, J.
AU  - Teng, Y.
AU  - Zou, H.
AU  - Xie, Y.
TI  - Exploring an Innovative Deep Learning Solution for Acupuncture Point Localization on the Weak Feature Body Surface of the Human Back
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3511128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211499186&doi=10.1109%2fJBHI.2024.3511128&partnerID=40&md5=ddeb92c1dd966f97d4199b082554a7a2
AB  - In current clinical practice, the localization of human acupuncture points relies extensively on the subjective experience of physicians. Therefore, despite being a crucial basic content of traditional Chinese medicine (TCM), acupuncture point localization has not been well expanded and promoted through intelligent means. Our goal is to explore an efficient and reliable solution for acupuncture point localization and recognition that addresses the shortcomings of subjectivity and standardization in this task. We focus on the weak feature body surface of the human back and propose an innovative approach that utilizes a deep learning network with a self-attention module for global extraction of image features. This methodology differs from common Convolutional Neural Networks (CNNs) which often lead to classification ambiguous in weak feature image tasks due to excessive cropping and scaling operations during feature extraction. Moreover, our self-constructed dataset of human back acupuncture points provides data support for model training. The localization task for the back acupuncture points of the subjects in the dataset strictly follows the national standard definition and is labelled by professional doctors of TCM to ensure data robustness and quality. Our preliminary experiments validate that our proposed network learns higher-quality global image features, achieving an average accuracy of less than 1cm in the localization and recognition task of 84 acupuncture points on the back of the human body. Access to our method is available at https://github.com/Sohyu1/AL-WFBS.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Exploring
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Li, C.
AU  - Mieghem, P.V.
AU  - Li, X.
TI  - Predicting Higher-Order Dynamics With Unknown Hypergraph Topology
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems I: Regular Papers
DO  - 10.1109/TCSI.2024.3513406
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212247777&doi=10.1109%2fTCSI.2024.3513406&partnerID=40&md5=a763d82a774d9f330dbb9457d6b5a400
AB  - Predicting future dynamics on networks is challenging, especially when the complete and accurate network topology is difficult to obtain in real-world scenarios. Moreover, the higher-order interactions among nodes, which have been found in a wide range of systems in recent years, such as the nets connecting multiple modules in circuits, further complicate accurate prediction of dynamics on hypergraphs. In this work, we proposed a two-step method called the topology-agnostic higher-order dynamics prediction (TaHiP) algorithm. The observations of nodal states of the target hypergraph are used to train a surrogate matrix, which is then employed in the dynamical equation to predict future nodal states in the same hypergraph, given the initial nodal states. TaHiP outperforms three latest Transformer-based prediction models in different real-world hypergraphs. Furthermore, experiments in synthetic and real-world hypergraphs show that the prediction error of the TaHiP algorithm increases with mean hyperedge size of the hypergraph, and could be reduced if the hyperedge size distribution of the hypergraph is known.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhou2024Predicting
ER  -

TY  - JOUR
AU  - Lin, Y.
AU  - Qiao, J.
AU  - Bi, J.
AU  - Yuan, H.
AU  - Wang, M.
AU  - Zhang, J.
AU  - Zhou, M.
TI  - Transformer-Based Water Quality Forecasting with Dual Patch and Trend Decomposition
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3514133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212045614&doi=10.1109%2fJIOT.2024.3514133&partnerID=40&md5=817507f78c438e798bec294588464ac9
AB  - In many fields, time series prediction is gaining more and more attention, e.g., air pollution, geological hazards, and network traffic prediction. Water quality prediction uses historical data to predict future water quality. However, it is difficult to learn a representation map from a time series that captures the trends and fluctuations to effectively remove noise from the time series data and investigate complex nonlinear relationships. To solve these problems, this work proposes a time series prediction model, called DPSGT for short, which integrates Dual Patch Savitsky-Golay filtering and Transformer. First, DPSGT adopts the SG filtering to decompose the time series data and reduce the noise interference to improve long-term prediction capabilities. Second, to tackle the limitation of temporal representation capability, DPSGT adopts dual patches to ravel temporal series into local and global patches, which can tackle local semantic information and enlarge the receptive field. Third, it utilizes a transformer mechanism to address the nonlinear problem of the water quality time series and improve the accuracy of the prediction. Two real-world datasets are utilized to evaluate the proposed DPSGT, and experiments prove that DPSGT improves RMSE, MAE, MAPE, and R2 by 6%, 5%, 8%, and 7%, respectively, compared with other benchmark models.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Lin2024Transformer-Based
ER  -

TY  - JOUR
AU  - Zheng, Y.
AU  - Long, Z.
AU  - Feng, B.
AU  - Cheng, R.
AU  - Vaziri, K.
AU  - Hahn, J.
TI  - D3BT: Dynamic 3D Body Transformer for Body Fat Percentage Assessment
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3510519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211490936&doi=10.1109%2fJBHI.2024.3510519&partnerID=40&md5=363b9cafa680d4eb7bc95f428b8328b9
AB  - 3D body scan has been adopted for body composition assessment due to its ability to accurately capture body shape measurements. However, the complexity of mesh representation and the lack of fine-shape descriptors limit its applications in fat percentage analysis. Most studies rely on algorithms applied to anthropometric values derived from 3D scans, such as multiple girth measurements, which fail to account for the body's detailed shape. To address these issues, we explore the feasibility of using point cloud representation. However, few existing point-based methods are aimed at the human body or regression tasks. In this study, we introduce a new model, D3BT, which utilizes a transformer-based network on the body point cloud to efficiently learn shape information for regional and global fat percentage regression tasks. The model dynamically divides the points into voxels for enhanced transformer training, providing higher density and better alignment across different subjects, which is more suitable for body shape learning. We evaluate different models for predicting body fat percentage from 3D body scans, using ground truth data from dual-energy x-ray absorptiometry (DXA) reports. Compared to traditional methods that depend on anthropometric measurements and other point-based approaches, the proposed model shows superior results. In extensive experiments, the model reduces Root Mean Square Error (RMSE) by an average of 10.30% and achieves an average R-squared score of 0.86. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zheng2024D3BT
ER  -

TY  - JOUR
AU  - Xiao, C.
AU  - Dong, J.
AU  - Dou, H.
AU  - Li, Y.
AU  - Wang, W.
AU  - Ren, F.
TI  - A Transformer network air temperature and humidity inversion method based on ATMS brightness temperature data
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
DO  - 10.1109/LGRS.2024.3507938
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210978065&doi=10.1109%2fLGRS.2024.3507938&partnerID=40&md5=7541458ebcd1115826b3269aa17d0e3d
AB  - Accurately measuring and inverting air parameters, such as air temperature and humidity, is crucial for weather forecasting, climate research, and environmental monitoring. In this paper, we propose an inversion method based on the Transformer model to accurately estimate the spatial distribution of air temperature and humidity. Compared with traditional methods, the Transformer model demonstrates superior ability in capturing nonlinear relationships and spatial dependencies in observational data, thereby improving inversion accuracy. Experiments conducted on real observational data have shown that compared to traditional techniques, the proposed method achieves a reduction of over 4.8% in the root mean square error (RMSE) of air temperature and over 14.2% in humidity estimation, demonstrating its high accuracy and reliability in inverting air temperature and humidity. This method provides a new approach for advancing air parameter inversion technology.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xiao2024Transformer
ER  -

TY  - JOUR
AU  - Salman, M.
AU  - Bolboli, J.
AU  - Ullah, K.
AU  - Chung, W.-Y.
TI  - Machine Learning-Assisted Object Monitoring Supported by UWOC for IoUT
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3515994
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212152740&doi=10.1109%2fJIOT.2024.3515994&partnerID=40&md5=596e742e553c8b7acc5e74b286523c18
AB  - The deployment and maintenance of the underwater sensor network are cumbersome and require a significant amount of manual labor, resulting in reduced efficiency and an increased likelihood of errors. This study presents a compact underwater wireless sensor network that use multiple diversity gain-enabled relays to receive and transmit data from sensor nodes to the gateway. The relay is powered by employing combining techniques such as equal gain combining (EGC), majority logic combining (MLC), and selection combining (SC) to augment its performance. The sensor node is fitted with an underwater optical wireless communication (UWOC) module, which wirelessly transfers the inertial measurement unit (IMU) sensor data to the nearest relay. The EGC, MLC, and SC have achieved packet error rates of 26%, 28%, and 30%, respectively, at a transmission rate of 0.5 Mbps. The accelerometer and gyroscope data collected from multiple fish, including the sensor readings of roll, pitch, yaw, speed, and dynamic acceleration, are utilized to train LSTM, spatial attention, RNN, Transformer, and GRU machine learning models. The models are capable of predicting the particular fish's steady, low, medium, and high acceleration states. The LSTM, spatial attention, RNN, Transformer, and GRU ML models achieved training accuracy rates of 79.06%, 93.86%, 91.07%, 87.38%, and 68.16% respectively.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Salman2024Machine
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Zhou, X.
AU  - Wang, S.
AU  - Zhao, X.
AU  - Deng, X.
AU  - Gong, W.
TI  - Full-Link Delivery Time Prediction in Logistics Using Federated Heterogeneous Graph Transformer
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3497581
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210920626&doi=10.1109%2fJIOT.2024.3497581&partnerID=40&md5=b5e2bbf73c6075f4f2227066aca9c908
AB  - Motivated by the pursuit of greater efficiency, companies such as Amazon and JD are shifting towards a warehouse-distribution integration model to optimize logistics operations. In general full-link logistics scenarios, the collaboration between warehouses and sorting centers managed by different enterprises leads to data silos, posing challenges in securely sharing information and accurately predicting delivery times across the entire logistics network. Current delivery time prediction methods often overlook the heterogeneity of logistics networks and face data sharing constraints. We aim to address these issues by facilitating secure inter-node relationship analysis and leveraging distinct spatio-temporal characteristics to enhance efficiency. However, challenges remain in overcoming data isolation while maintaining protection and integrating diverse node characteristics for optimized modeling. To address these challenges, we propose the Federated Heterogeneous Graph Transformer (Fed-HGT) framework. This framework includes a federated training module that integrates local and central gradients by exchanging node representations and model parameters between logistics nodes and the central server. Additionally, it features a federated prediction module where local nodes compute time representations using their local data and transmit these to the central server. The central server then uses these representations to make accurate full-link delivery time predictions. Our method was evaluated on a dataset from a major e-commerce platform in China, demonstrating significant performance improvements over existing solutions.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Full-Link
ER  -

TY  - JOUR
AU  - Shao, Z.
AU  - Zhang, Y.
AU  - Yang, S.
AU  - Zhao, W.
TI  - Reveling Internal-External Causality for Short-Term Wind Power Prediction: A Temporal Causal Attention Network
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 11
SP  - 13077
EP  - 13089
DO  - 10.1109/TII.2024.3431082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208733366&doi=10.1109%2fTII.2024.3431082&partnerID=40&md5=88bc45560c57e22723f9f4f9b46af3f5
AB  - An accurate short-term prediction of wind power is crucial for grid reliability and optimized power generation allocation. Currently, deep learning-based methods for wind power prediction (WPP) focus excessively on exploiting spatial-temporal correlations of multivariate time series and neglect potential confounding factors. However, these factors can introduce spurious correlations, diminishing the reliability and robustness of the methods solely based on correlations. Specifically, traditional deep learning methods lack generalizability across varied power output scenarios due to the interference from confounding factors, such as spatial distribution differences and turbine disturbances. Therefore, this paper proposes a novel method, called Temporal Causal Attention Network (TCAN) for short-term WPP, leveraging the physically meaningful internal-external causality to model interactions among factors, and enhancing generalizability across power output scenarios. In this method, a multiscale temporal transformer is proposed to capture the internal causality of a dynamic time series, and a causal graphs-based mechanism is introduced to identify the external causal path among different factors. In addition, a causal attention-based information updating method is proposed to measure the impact of cause nodes on effect nodes. The real data of eight wind turbines from Asia's largest wind power producer are used to evaluate the proposed method. Results show that compared to the second-best method in the experiment, the average RMSE, MAAPE, and R-Squared for the proposed method for 10-min WPP are enhanced by 35.34%, 32.73%, and 4.73%, respectively.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Shao2024Reveling
ER  -

TY  - JOUR
AU  - Wang, C.
AU  - Wang, H.
AU  - Zhang, X.
AU  - Liu, Q.
AU  - Liu, M.
AU  - Xu, G.
TI  - A Transformer-Based Industrial Time Series Prediction Model with Multivariate Dynamic Embedding
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
DO  - 10.1109/TII.2024.3488783
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209631604&doi=10.1109%2fTII.2024.3488783&partnerID=40&md5=b4244e432027fe69286d795047b4d189
AB  - Industrial time series prediction (ITSP) is critical to the predictive maintenance system of modern industry. However, time-varying conditions and complex industrial processes cause the distribution drift of industrial time series, raising the difficulty of prediction. This article proposes an ITSP model considering distribution information, namely MDEformer. First, the multivariate dynamic embedding (MDE) is designed to provide the property of the channel-binding dynamic distribution awareness. Specifically, a dynamic mode transition and selection module is adopted to exploit dynamic distribution features of time series, and the bidirectional dynamic residual connection integrates dynamic distribution information into embedding vectors to filter distribution change interference. Then, the vanilla Transformer encoder is used to achieve multivariate prediction. Finally, a generative pretraining and fine-Tuning strategy is used to enhance the generalization ability in real production scenarios. Extensive results on a real-world zinc smelting dataset illustrate the superiority of MDEformer.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Transformer-Based
ER  -

TY  - JOUR
AU  - Zhang, K.
AU  - Ren, H.
AU  - Kang, J.
AU  - Guo, C.
AU  - Chen, W.
AU  - Tao, M.
AU  - Dai, H.-N.
AU  - Wan, S.
AU  - Bao, H.
TI  - TST-Trans: A Transformer Network for Urban Traffic Flow Prediction
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3501294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210020796&doi=10.1109%2fJIOT.2024.3501294&partnerID=40&md5=da0fa4a36f7bb75941c8587373acfb8d
AB  - A critical challenge for predicting urban traffic flows is to simultaneously process time series and spatial features from heterogeneous traffic data collected by diverse Internet of Things (IoT) devices. Despite the advent of Transformer-based models with an advanced network structure and excellent prediction performance, standard Transformer models are still struggling to combine both spatial information and temporal relations of traffic flows. To address these challenges, we design a novel Transformer network, namely TST-Trans, for traffic flow prediction with high accuracy. In particular, we use learnable position encoders to replace traditional fixed position encoders. Meanwhile, we introduce a spatio-temporal embedding method that integrates temporal relationships and spatial information with external inputs, thereby capturing the spatio-temporal dependencies of traffic flows. Experiments with real-world datasets demonstrate that our proposed TST-Trans achieves better prediction accuracy than state-of-the-art methods while requiring fewer parameters.The research results increased by more than 10% compared with tranformer. Compared to STD-NET, there is a 2% to 10% improvement in performance on different datasets. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2024TST-Trans
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Zhu, T.
AU  - Nie, M.
AU  - Ning, H.
AU  - Liu, Z.
AU  - Chen, L.
TI  - P2LHAP:Wearable Sensor-Based Human Activity Recognition, Segmentation and Forecast Through Patch-to-Label Seq2Seq Transformer
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3493380
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208748041&doi=10.1109%2fJIOT.2024.3493380&partnerID=40&md5=c4861e79f2cf74509d572ce4c4191243
AB  - Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data. This limits their usefulness in many fields such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial. This paper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in a efficient single-task model. P2LHAP divides sensor data streams into a sequence of "patches", served as input tokens, and outputs a sequence of patch-level activity labels including the predicted future activities. A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately. Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders. All channels share embedding and Transformer weights across all sequences. Evaluated on three public datasets, P2LHAP significantly outperforms the state-of-the-art in all three tasks, demonstrating its effectiveness and potential for real-world applications. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024P2LHAP:Wearable
ER  -

TY  - JOUR
AU  - Hameed, A.
AU  - Violos, J.
AU  - Santi, N.
AU  - Leivadeas, A.
AU  - Mitton, N.
TI  - FeD-TST: Federated Temporal Sparse Transformers for QoS prediction in Dynamic IoT Networks
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
DO  - 10.1109/TNSM.2024.3493758
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208934064&doi=10.1109%2fTNSM.2024.3493758&partnerID=40&md5=79432407dae442db89a54974e5f4da82
AB  - Internet of Things (IoT) applications generate tremendous amounts of data streams which are characterized by varying Quality of Service (QoS) indicators. These indicators need to be accurately estimated in order to appropriately schedule the computational and communication resources of the access and Edge networks. Nonetheless, such types of IoT data may be produced at irregular time instances, while suffering from varying network conditions and from the mobility patterns of the edge devices. At the same time, the multipurpose nature of IoT networks may facilitate the co-existence of diverse applications, which however may need to be analyzed separately for confidentiality reasons. Hence, in this paper, we aim to forecast time series data of key QoS metrics, such as throughput, delay, packet delivery and loss ratio, under different network configuration settings. Additionally, to secure data ownership while performing the QoS forecasting, we propose the FeDerated Temporal Sparse Transformer (FeD-TST) framework, which allows local clients to train their local models with their own QoS dataset for each network configuration; subsequently, an associated global model can be updated through the aggregation of the local models. In particular, three IoT applications are deployed in a real testbed under eight different network configurations with varying parameters including the mobility of the gateways, the transmission power and the channel frequency. The results obtained indicate that our proposed approach is more accurate than the identified state-of-the-art solutions.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hameed2024FeD-TST
ER  -

TY  - JOUR
AU  - Lei, C.
AU  - Wang, W.
AU  - Fan, W.
AU  - Lu, Z.
AU  - Tang, J.
AU  - Li, M.
TI  - TransScore: A graph model for pose scoring and affinity prediction based on transformer convolution network
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3504851
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210274608&doi=10.1109%2fJBHI.2024.3504851&partnerID=40&md5=c5a1f6db7bb51c0b5fb16373f9181ce5
AB  - Predicting the interaction of protein and compound is an important task in drug discovery. Molecular docking has been a fundamental and vital computer-aid tool for digging potential interaction of the protein-compound pair. With the recent great success of artificial intelligence (AI), the scoring function, as a fundamental part of molecular docking, has been achieving much better performance by incorporating AI-based models. However, the AI-based models usually focus on a single prediction task (e.g., affinity prediction), which is limited by their lack of extensibility. Moreover, the performance of AI-based models usually declines in cold start scenarios, thus compromising the robustness. To this end, we propose a novel deep learning-based graph model based on the transformer convolution network for pose scoring and affinity prediction. TransScore captures the intrinsic characteristics of protein-compound poses by employing the self-attention mechanism, which achieves superior performances in both cold and warm scenarios for the pose-scoring task. The outstanding performance is also shown in imbalanced datasets, which demonstrates the robustness of TransScore. In addition, the gated residual algorithm in TransScore enhances the model to adapt to diverse related tasks. In particular, in the affinity prediction task, we have observed consistent improvements in warm/cold start scenarios. Moreover, it is noticeable that TransScore excels in both accuracy and precision, accurately predicting affinities and their relative ordering. We also conducted an analysis on carbonic anhydrase II, which bears out that TransScore can elaborate the interaction mechanism of the protein-ligand pair, suggesting the potential application of TransScore in drug discovery.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Lei2024TransScore
ER  -

TY  - JOUR
AU  - Zeng, M.
AU  - Lu, J.
AU  - Li, Y.
AU  - Lu, C.
AU  - Kan, S.
AU  - Guo, F.
AU  - Li, M.
TI  - CellCircLoc: Deep Neural Network for Predicting and Explaining Cell Line-Specific CircRNA Subcellular Localization
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3491732
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209075102&doi=10.1109%2fJBHI.2024.3491732&partnerID=40&md5=9ce69374000fc1822cedb346bf54f741
AB  - The subcellular localization of circular RNAs (circRNAs) is crucial for understanding their functional relevance and regulatory mechanisms. CircRNA subcellular localization exhibits variations across different cell lines, demonstrating the diversity and complexity of circRNA regulation within distinct cellular contexts. However, existing computational methods for predicting circRNA subcellular localization often ignore the importance of cell line specificity and instead train a general model on aggregated data from all cell lines. Considering the diversity and context-dependent behavior of circRNAs across different cell lines, it is imperative to develop cell line-specific models to accurately predict circRNA subcellular localization. In the study, we proposed CellCircLoc, a sequence-based deep learning model for circRNA subcellular localization prediction, which is trained for different cell lines. CellCircLoc utilizes a combination of convolutional neural networks, Transformer blocks, and bidirectional long short-term memory to capture both sequence local features and long-range dependencies within the sequences. In the Transformer blocks, CellCircLoc uses an attentive convolution mechanism to capture the importance of individual nucleotides. Extensive experiments demonstrate the effectiveness of CellCircLoc in accurately predicting circRNA subcellular localization across different cell lines, outperforming other computational models that do not consider cell line specificity. Moreover, the interpretability of CellCircLoc facilitates the discovery of important motifs associated with circRNA subcellular localization. The CellCircLoc web server is available at http://csuligroup.com:8000/cellcircloc. The source code can be obtained from https://github.com/CSUBioGroup/CellCircLoc.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zeng2024CellCircLoc
ER  -

TY  - JOUR
AU  - Fan, C.
AU  - Zhang, X.
TI  - Stock price nowcasting and forecasting with deep learning
PY  - 2024
T2  - Journal of Intelligent Information Systems
DO  - 10.1007/s10844-024-00908-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208991745&doi=10.1007%2fs10844-024-00908-2&partnerID=40&md5=61cdfbb24b323e7ebda455eb03b418d6
AB  - Recent studies have improved stock price forecasting with the emerging deep learning models. Despite advancements in deep learning, stock price prediction faces significant challenges. Existing studies predominantly focus on forecasting future prices, with limited attention to nowcasting, which predicts current or near-future market states. Additionally, most methods use univariate data, neglecting the valuable interactions between multiple financial variables. This study addresses these challenges by evaluating both forecasting and nowcasting approaches using deep learning. We incorporate multivariate inputs, including opening price, high, low, close, volume, inday-change and trend, to enhance the predictive power of our models. We implement and compare several deep learning methods: Long Short-Term Memory (LSTM) networks, Gated Recurrent Units (GRU), Convolutional Neural Networks combined with LSTM (CNN-LSTM), and the transformer-based Patch Time Series Transformer (PatchTST). Our experimental results reveal that the standard LSTM model achieves superior performance compared to the more recent PatchTST and CNN-LSTM models. Specifically, models perform better in nowcasting scenarios, likely due to smaller price fluctuations over shorter periods. Furthermore, our analysis shows that including variables such as opening prices, highest prices, and lowest prices enhances predictive accuracy, whereas trading volume tends to reduce performance. These findings suggest that deep learning models are more effective for real-time or near-term stock price prediction and highlight the importance of multivariate inputs in developing robust prediction models. This study provides valuable insights for enhancing the accuracy and reliability of stock price forecasts, with significant implications for financial analysts and investors. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Fan2024Stock
ER  -

TY  - JOUR
AU  - Hu, Y.
AU  - Li, S.
AU  - Xia, D.
AU  - Zhang, W.
AU  - Yuan, P.
AU  - Wu, F.
AU  - Li, H.
TI  - A Multi-view Spatial-temporal Adaptive Transformer-GRU Framework for Traffic Flow Prediction
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3496795
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209726613&doi=10.1109%2fJIOT.2024.3496795&partnerID=40&md5=5a4b23e6029180d0615ea072bd307788
AB  - Accurate traffic flow prediction is a key aspect of building data-driven intelligent transportation systems (ITS) which relies on the Internet of Things (IoT) sensors deployed along roads, and dynamic spatial-temporal dependencies mining is a major area of interest in traffic flow prediction. Existing methods, however, overlook the diversities of traffic flow patterns from the perspectives of temporal and spatial dimensions. To this end, this paper presents a Multi-view Spatial-temporal Adaptive Transformer-GRU (MST-ATG) framework based on the encoder-decoder architecture to capture complex spatial-temporal dependencies from various perspectives. Specifically, a multi-view embedding layer (MEL) containing original traffic data and spatial-temporal correlated features is designed to enrich the feature encoding. Then, based on the inherent characteristics of traffic flow, we introduce a periodicity-trend decomposition (PTD) method to fully consider the periodic and trend-oriented features of time series. Finally, we propose a spatial-temporal adaptive transformer-GRU (ST-ATG) to dynamically extract spatial-temporal dependencies and adaptively choose computation steps in which a Temporal Adaptive stacked-GRU Module (T-AGM) is proposed to extract correlations in temporal dimension and spatial dependencies captured by a Spatial Adaptive Transformer Module (S-ATM). Experimental results on six large-scale real-world datasets demonstrate that our MST-ATG framework outperforms the benchmarks in prediction accuracy. For instance, the average RMSE of MST-ATG on PeMS08 is reduced by 48.3%, 41.09%, 12.95%, 17.67%, 18.64%, 2.4%, 14.67%, 9.15%, 1.1%, 2.4%, 2.51%, and 1.2% compared to that of ARIMA, LSTM, DCRNN, STGCN, ASTGCN, GWNet, STSGCN, AGCRN, Bi-STAT, STAEformer, PDFormer, and STPGNN, respectively.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hu2024Multi-view
ER  -

TY  - JOUR
AU  - Xie, B.
AU  - Ma, X.
AU  - Shan, X.
AU  - Beheshti, A.
AU  - Yang, J.
AU  - Fan, H.
AU  - Wu, J.
TI  - Multiknowledge and LLM-Inspired Heterogeneous Graph Neural Network for Fake News Detection
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3488191
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209878746&doi=10.1109%2fTCSS.2024.3488191&partnerID=40&md5=f2dd87a053d477c1360712825ded5ed4
AB  - The widespread diffusion of fake news has become a critical problem on dynamic social media worldwide, which requires effective strategies for fake news detection to alleviate its hazardous consequences for society. However, most recent efforts only focus on the features of news content and social context without realizing the benefits of large language models (LLMs) and multiple knowledge graphs (KGs), thus failing to improve detection capabilities further. To tackle this issue, we present a multiknowledge and LLM-inspired heterogeneous graph neural network for fake news detection (MiLk-FD), by combining KGs, LLMs, and graph neural networks (GNNs). Specifically, we first model news content as a heterogeneous graph (HG) containing news, entity, and topic nodes and then fuse the knowledge from three KGs to augment the factual basis of news articles. Meanwhile, we leverage TransE to initialize the knowledge features and employ LLaMa2-7B to obtain the initial feature vectors of news articles. After that, we utilize the devised HG transformer to learn news embeddings with specific feature distribution in high-dimensional spaces by aggregating neighborhood information according to metapaths. Finally, a classifier based on multilayer perceptron (MLP) is trained to predict each news article as fake or true. Through experiments, we demonstrate that our proposed framework surpasses ten baselines according to accuracy, precision, F1-score, recall, and ROC in four public real-world benchmarks (i.e., COVID-19, FakeNewsNet, PAN2020, Liar).  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xie2024Multiknowledge
ER  -

TY  - JOUR
AU  - Wan, Q.
AU  - Li, Z.
AU  - Wang, Y.
AU  - Lv, R.
AU  - Cheng, H.
AU  - Wu, D.
TI  - A Fast Tracking Network for Pedestrian Following of Mobile Robot in Unknown Complex Scenes
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 11
SP  - 12726
EP  - 12735
DO  - 10.1109/TII.2024.3424329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208757580&doi=10.1109%2fTII.2024.3424329&partnerID=40&md5=6e33b6f3be79d83a3bb9efc9cdcfa3ba
AB  - The pedestrian-following robot aims to robustly maintain a standard distance from a specific pedestrian in an unknown complex environment, which is challenging when facing the limited field of view (FOV) and the computing resource constraints. However, the pedestrian-following robot commonly utilizes the long range dependence of targets to construct tracking models via the transformer tracking method, which is often insufficient to achieve real-time following. To address this important issue, we propose a new fast tracking network for the following robot, including a lightweight target detector, a target state prediction decoder, and an adaptive visual servo controller. First, in the lightweight target detector, a dense feature extraction process is designed by stacking depthwise group-separable convolutions. A context encoder is also developed, and is coupled with the proposed person re-identification (Re-ID) branch to detect multiple targets with high precision and speed. Second, in the target state prediction decoder, we introduce a flexible multiattention mechanism to obtain target Re-ID features from the previous frame for predicting the target's position in the current frame. Third, in the adaptive visual servo controller, we design a six-parameter dynamic model for the proportional integral derivative (PID) controller to stably follow the pedestrian under the limited FOV. Extensive experimental results demonstrate that the proposed method is efficient and accurate. Moreover, it also exhibits strong robustness and high real-time performance in unknown complex environments.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wan2024Fast
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Zhu, H.
AU  - Liu, Q.
AU  - Liu, Q.
TI  - Fusing Micro- and Macro-Scale Information to Predict Anticancer Synergistic Drug Combinations
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3500789
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210093348&doi=10.1109%2fJBHI.2024.3500789&partnerID=40&md5=f9e0de35be58b5c2fb44424c5a2561e8
AB  - Drug combination therapy is highly regarded in cancer treatment. Computational methods offer a time- and cost-effective opportunity to explore the vast combination space. Although deep learning-based prediction methods lead the field, their generalization ability remains unsatisfactory. Few previous studies have the ability to finely characterize drugs and cell lines at both the micro-scale and macro-scale. Furthermore, the interaction of cross-scale information is often overlooked. These two points limit models' ability of predicting the synergism of drug combinations in cell lines. To address the issues, we propose a novel anticancer synergistic drug combination prediction method termed MMFSynergy in this article. The construction of MMFSynergy involves three phases. Firstly, MMFSynergy pretrains two micro encoders and a macro graph encoder, which can capture micro- or macro-scale information from large volumes of unlabeled data and generate generic features for drugs and proteins. Secondly, it represents drugs and proteins by fusing cross-scale information through a self-supervised task. Finally, it employs a Transformer Encoder-based model to predict synergy scores, taking representations of drugs in the combinations and the associated proteins of cell lines as input. We compared our method with eight advanced methods across three typical scenarios based on two public datasets. The results consistently demonstrated that the proposed method's generalization ability outperforms six advanced methods'. We also conducted experiments including but not limited to ablation study and case study to further exhibit the effectiveness of MMFSynergy.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Fusing
ER  -

TY  - JOUR
AU  - Bai, J.
AU  - Zhang, Z.
AU  - Yin, Y.
AU  - Jin, W.
AU  - Ali, T.A.A.
AU  - Xiong, Y.
AU  - Xiao, Z.
TI  - LGG-NeXt: A Next Generation CNN and Transformer Hybrid Model for the Diagnosis of Alzheimer's Disease Using 2D Structural MRI
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3495835
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209666299&doi=10.1109%2fJBHI.2024.3495835&partnerID=40&md5=96e2f2e7bc41fa1d9f3a02830c1a75ab
AB  - Incurable Alzheimer's disease (AD) plagues many elderly people and families. It is important to accurately diagnose and predict it at an early stage. However, the existing methods have shortcomings, such as inability to learn local and global information and the inability to extract effective features. In this paper, we propose a lightweight classification network Local and Global Graph ConvNeXt. This model has a hybrid architecture of convolutional neural network and Transformers. We build the Global NeXt Block and the Local NeXt Block to extract the local and global features of the structural magnetic resonance imaging (sMRI). These two blocks are optimized by adding global multilayer perceptron and locally grouped attention, respectively. Then, the features are fed into the pixel graph neural network to aggregate the valid pixel features using mask attention. In addition, we decoupled the loss by category to optimize the calculation of the loss. This method was tested on slices of the processed sMRI datasets from ADNI and achieved excellent performance. Our model achieves 95.81% accuracy with fewer parameters and floating point operations per second (FLOPS) than other classical efficient models in the diagnosis of AD. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Bai2024LGG-NeXt
ER  -

TY  - JOUR
AU  - Chu, J.
AU  - Liu, W.
AU  - Tian, Q.
AU  - Lu, W.
TI  - PFPRNet: A Phase-Wise Feature Pyramid with Retention Network for Polyp Segmentation
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3500026
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210074717&doi=10.1109%2fJBHI.2024.3500026&partnerID=40&md5=321edb4076be071907c31efec060b422
AB  - Early detection of colonic polyps is crucial for the prevention and diagnosis of colorectal cancer. Currently, deep learning-based polyp segmentation methods have become mainstream and achieved remarkable results. Acquiring a large number of labeled data is time-consuming and labor-intensive, and meanwhile the presence of numerous similar wrinkles in polyp images also hampers model prediction performance. In this paper, we propose a novel approach called Phase- wise Feature Pyramid with Retention Network (PFPRNet), which leverages a pre-trained Transformer-based Encoder to obtain multi-scale feature maps. A Phase- wise Feature Pyramid with Retention Decoder is designed to gradually integrate global features into local features and guide the model's attention towards key regions. Additionally, our custom Enhance Perception module enables capturing image information from a broader perspective. Finally, we introduce an innovative Low-layer Retention module as an alternative to Transformer for more efficient global attention modeling. Evaluation results on several widely-used polyp segmentation datasets demonstrate that our proposed method has strong learning ability and generalization capability, and outperforms the state-of-the-art approaches.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chu2024PFPRNet
ER  -

TY  - JOUR
AU  - Xin, Z.
AU  - Liu, Y.
AU  - Xing, J.
AU  - Huang, J.
AU  - Bian, J.
AU  - Zhang, Y.
TI  - A Novel Multi-modal Fusion Sensing Based Channel Prediction Method for UAV Communications
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3482410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207307101&doi=10.1109%2fJIOT.2024.3482410&partnerID=40&md5=49d711bdd25bb8402918a4ebfbdb3db8
AB  - Unmanned aerial vehicle (UAV) communications, as a critical application scenario in the sixth generation (6G) wireless communication field, has garnered widespread attention. During UAV-to-ground communication, channel data plays a pivotal role. Analyzing channel data enables an understanding of communication environments' diversity and temporal variability, thereby facilitating the construction of more efficient communication systems. This paper proposes a novel UAV-to-ground channel prediction method based on multi-modal fusion. The method aims to achieve real-time and precise prediction of UAV-to-ground channel data from UAVs in the three-dimensional airspace by integrating various sources of information, including UAV-captured images, location data of transmitters and receivers, and communication settings. The network uses a fused architecture combining convolutional neural network (CNN) and transformer architecture to extract and integrate features from diverse information sources. This fusion strategy significantly enhances the accuracy of UAV-to-ground channel prediction. Incorporating image information enables the network better to comprehend the complexity and dynamics of communication environments, thereby assisting in achieving more precise UAV-to-ground channel prediction. Experimental results demonstrate that the proposed method achieves real-time prediction of ground channels across various flight altitudes and communication frequency bands. This provides robust technical support for advancing UAV communication and offers new insights for optimizing and upgrading future wireless communication systems.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xin2024Novel
ER  -

TY  - JOUR
AU  - Kim, M.
AU  - Kim, J.H.
AU  - Jang, B.
TI  - Forecasting Epidemic Spread with Recurrent Graph Gate Fusion Transformers
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3488274
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208222491&doi=10.1109%2fJBHI.2024.3488274&partnerID=40&md5=db69aadb5dd569f61bebc064995c980d
AB  - Predicting the unprecedented, nonlinear nature of COVID-19 presents a significant public health challenge. Recent advances in deep learning, such as Graph Neural Networks, Recurrent Neural Networks (RNNs), and Transformers, have enhanced predictions by modeling regional interactions, managing autoregressive time series, and identifying long-term dependencies. However, prior works often feature shallow integration of these models, leading to simplistic graph embeddings and inadequate analysis across different graph types. Additionally, excessive reliance on historical COVID-19 data limits the potential of utilizing time-lagged data, such as intervention policy information. To address these challenges, we introduce ReGraFT, a novel Sequence-to-Sequence model designed for robust long-term forecasting of COVID-19. ReGraFT integrates Multigraph-Gated Recurrent Units (MGRUs) with adaptive graphs, leveraging data from individual states, including infection rates, policy changes, and interstate travel. First, ReGraFT employs adaptive MGRU cells within an RNN framework to capture inter-regional dependencies, dynamically modeling complex transmission dynamics. Second, the model features a Self-Normalizing Priming layer using SELUs to enhance stability and accuracy across short, medium, and long-term forecasts. Lastly, ReGraFT systematically compares and integrates various graph types derived from fully connected layers, pooling, and attention-based mechanisms to provide a nuanced representation of inter-regional relationships. By incorporating lagged COVID-19 policy data, ReGraFT refines forecasts, demonstrating RMSE reductions of 2.39-35.92% compared to state-of-the-art models. This work provides accurate long-term predictions, aiding in better public health decisions. Our code is available at https://github.com/mfriendly/ReGraFT.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Kim2024Forecasting
ER  -

TY  - JOUR
AU  - Hao, S.
AU  - Liu, S.
AU  - Jia, X.
AU  - Lu, H.
AU  - He, Y.
TI  - Efficient Adaptive Feature Fusion Network for Remote-Sensing Image Super-Resolution
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 3089
EP  - 3093
DO  - 10.1109/LSP.2024.3488524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208270010&doi=10.1109%2fLSP.2024.3488524&partnerID=40&md5=0efc9a2f11145a14fac7ae7734f3fff7
AB  - Image super-resolution is a fundamental low-level vision task aimed at recovering high-resolution images with fine details. Deep learning has significantly enhanced the performance of super-resolution techniques for remote sensing imagery. However, increasing the depth of networks and the size of their parameters has resulted in substantial computational and storage burdens. To address this challenge, we propose an adaptive approach that learns both local and global information for each region. We introduce a lightweight hybrid model named the Efficient Adaptive Feature Fusion Network, which combines CNNs and Transformers to fully exploit the texture information in remote sensing images. This model leverages local details and long-range dependencies within images in an adaptive manner to achieve superior super-resolution. Specifically, a set of Transformers is employed to model the self-similarity between pixels and perform dense texture pattern predictions at each pixel, while a set of CNNs captures local details within the images. The computed global and local features serve as inputs to the proposed Adaptive Contextual Fusion Block, which learns to fuse local and global information across different regions to generate robust image super-resolution features. We conduct extensive experimental evaluations of the proposed method on the UCMerced and AID datasets, demonstrating its outstanding performance in terms of PSNR and SSIM metrics. Comprehensive experiments validate the effectiveness of our approach, showing that the proposed method achieves an excellent balance between performance and complexity.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hao2024Efficient
ER  -

TY  - JOUR
AU  - Shao, J.
AU  - Wang, J.
AU  - Pan, X.
AU  - Wang, R.
AU  - Liu, S.
AU  - Jin, Z.
AU  - Wang, Z.
TI  - Probabilistic Modeling of Dissolved Gas Concentration for Predicting Operating Status of Oil-Immersed Transformers
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
DO  - 10.1109/TII.2024.3476550
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207463873&doi=10.1109%2fTII.2024.3476550&partnerID=40&md5=87fc70173b62cb0a9dc98682115086d1
AB  - Accurate prediction of dissolved gas concentration is vital for status assessment and fault diagnosis in oil-immersed transformers. Most current methods for predicting dissolved gas concentration produce deterministic results without providing any information on prediction uncertainty. This study presents for the first time a prediction model based on probability density, which integrates with interval estimation to assess the operating status of transformers. First, the quantile regression-long short term memory networks-Kernel density estimation model is developed to predict dissolved gas concentration and calculate the corresponding probability density function. The assessment of transformer status is then conducted using interval estimation, which includes a decision base consisting of prediction interval, attention value, and interval width. Experimental results illustrate that the proposed model achieves accurate predictions of gas concentration and probability density with excellent stability and applicability under various operating conditions, achieving the highest accuracy. Additionally, the findings reveal that the false alarm rate of the suggested criterion driven by uncertain information is 5.3% during normal operations and 0% under defective conditions. This article makes a contribution to the field by investigating uncertainty prediction models as valuable tools for predicting dissolved gas concentration and evaluating the condition of transformers.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Shao2024Probabilistic
ER  -

TY  - JOUR
AU  - Jia, M.
AU  - Wang, G.
AU  - Wang, Z.
AU  - Yang, S.
AU  - Ke, Y.
AU  - Wang, K.
TI  - Self-Supervised Image Aesthetic Assessment Based on Transformer
PY  - 2024
T2  - International Journal of Computational Intelligence and Applications
C7  - 2450029
DO  - 10.1142/S1469026824500299
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208052599&doi=10.1142%2fS1469026824500299&partnerID=40&md5=792904bd293a4d767b1a3c70a32eedbb
AB  - Visual aesthetics has always been an important area of computational vision, and researchers have continued exploring it. To further improve the performance of the image aesthetic evaluation task, we introduce a Transformer into the image aesthetic evaluation task. This paper pioneers a novel self-supervised image aesthetic evaluation model founded upon Transformers. Meanwhile, we expand the pretext task to capture rich visual representations, adding a branch for inpainting the masked images in parallel with the tasks related to aesthetic quality degradation operations. Our model's refinement employs the innovative uncertainty weighting method, seamlessly amalgamating three distinct losses into a unified objective. On the AVA dataset, our approach surpasses the efficacy of prevailing self-supervised image aesthetic assessment methods. Remarkably, we attain results approaching those of supervised methods, even while operating with a limited dataset. On the AADB dataset, our approach improves the aesthetic binary classification accuracy by roughly 16% compared to other self-supervised image aesthetic assessment methods and improves the prediction of aesthetic attributes.  © 2024 World Scientific Publishing Europe Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jia2024Self-Supervised
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Dong, D.
AU  - Fang, M.
AU  - He, B.
AU  - Liu, S.
AU  - Hu, C.
AU  - Liu, Z.
AU  - Wang, H.
AU  - Tang, L.
AU  - Tian, J.
TI  - ContraSurv: Enhancing Prognostic Assessment of Medical Images via Data-Efficient Weakly Supervised Contrastive Learning
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3484991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207410218&doi=10.1109%2fJBHI.2024.3484991&partnerID=40&md5=e8531a391e25b11ced291b1a3c8989f8
AB  - Prognostic assessment remains a critical challenge in medical research, often limited by the lack of well-labeled data. In this work, we introduce ContraSurv, a weakly-supervised learning framework based on contrastive learning, designed to enhance prognostic predictions in 3D medical images. ContraSurv utilizes both the self-supervised information inherent in unlabeled data and the weakly-supervised cues present in censored data, refining its capacity to extract prognostic representations. For this purpose, we establish a Vision Transformer architecture optimized for our medical image datasets and introduce novel methodologies for both self-supervised and supervised contrastive learning for prognostic assessment. Additionally, we propose a specialized supervised contrastive loss function and introduce SurvMix, a novel data augmentation technique for survival analysis. Evaluations were conducted across three cancer types and two imaging modalities on three real-world datasets. The results confirmed the enhanced performance of ContraSurv over competing methods, particularly in data with a high censoring rate.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2024ContraSurv
ER  -

TY  - JOUR
AU  - Turnbull, R.
AU  - Mannix, E.
TI  - Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR
PY  - 2024
T2  - International Journal on Document Analysis and Recognition
DO  - 10.1007/s10032-024-00504-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207333066&doi=10.1007%2fs10032-024-00504-8&partnerID=40&md5=5773141a9fd6e0862dfd499293f5d1f9
AB  - The capacity to isolate and recognize individual characters from facsimile images of papyrus manuscripts yields rich opportunities for digital analysis. For this reason the ‘ICDAR 2023 Competition on Detection and Recognition of Greek Letters on Papyri’ was held as part of the 17th International Conference on Document Analysis and Recognition. This paper discusses our submission to the competition. We used an ensemble of YOLOv8 models to detect and classify individual characters and employed two different approaches for refining the character predictions, including a transformer based DeiT approach and a ResNet-50 model trained on a large corpus of unlabeled data using SimCLR, a self-supervised learning method. Our submission won the recognition challenge with a mAP of 42.2%, and was runner-up in the detection challenge with a mean average precision of 51.4%. At a more relaxed intersection over union threshold of 0.5, we achieved the highest precision and recall for both detection and classification. The results demonstrate the potential of these techniques for automated character recognition on historical manuscripts. We ran the prediction pipeline on more than 4500 images from the Oxyrhynchus Papyri to illustrate the utility of our approach and release the results publicly in multiple formats. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Turnbull2024Detecting
ER  -

TY  - JOUR
AU  - Horawalavithana, S.
AU  - Ayton, E.
AU  - Usenko, A.
AU  - Cosbey, R.
AU  - Volkova, S.
TI  - Anticipating Technical Expertise and Capability Evolution in Research Communities Using Dynamic Graph Transformers
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 5
SP  - 6982
EP  - 7001
DO  - 10.1109/TCSS.2024.3416837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206179372&doi=10.1109%2fTCSS.2024.3416837&partnerID=40&md5=1e937888aab5b339937ca209d4b82740
AB  - The ability to anticipate global technical expertise and capability evolution trends is essential for national and global security, especially in safety-critical domains such as nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI). In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations. We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields. We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by: 1) forecasting heterogeneous (rather than homogeneous) nodes and edges; and 2) relying on both discrete- and continuous-time inputs. We demonstrate that our DGT models predict collaboration, partnership, and expertise patterns with 0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and 0.22 for NN domains. DGT model performance exceeds the best-performing static graph baseline models by 30%-80% across AI and NN domains. Our findings demonstrate that DGT models boost inductive task performance when previously unseen nodes appear in the test data for the domains with emerging collaboration patterns (e.g., AI). Specifically, models accurately predict which established scientists will collaborate with early career scientists and vice versa in the AI domain. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Horawalavithana2024Anticipating
ER  -

TY  - JOUR
AU  - Zou, M.
AU  - Zeng, Q.
AU  - Liu, C.
AU  - Cao, R.
AU  - Chen, S.
AU  - Zhao, Z.
TI  - Prediction of Remaining Execution Time of Business Processes with Multiperson Collaboration in Assembly Line Production
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3455418
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205794597&doi=10.1109%2fTCSS.2024.3455418&partnerID=40&md5=6289d65efeae1a0d65604fdd96065881
AB  - The prediction of remaining execution time is a critical area of research in business process monitoring. However, limited data availability and deficiencies in existing models have hindered progress in this area. To address these challenges, we introduce two production log datasets, coarse-grained log for television (CGL-TV) and fine-grained log for television (FGL-TV), collected from a semiautomated assembly line for television manufacturing. These datasets aim to address the issue of data scarcity in monitoring, analyzing, and optimizing the manufacturing process. Then, we investigate the significance of role information in semiautomated production processes and propose a novel feature selection strategy. That strategy replaces the traditional activity attributes with role attributes as the basis for prediction, resulting in a significant improvement in prediction accuracy. Furthermore, existing recurrent neural network (RNN)-based prediction methods have two major drawbacks: limited ability to capture long-term dependencies and the inability to parallelize computations. To address these issues, we propose a novel transformer-based remaining time prediction (TRTP) model. This model utilizes the self-attention mechanism instead of hidden state passing, which effectively incorporates global contextual information and enables potential parallel computing. The experimental results across four datasets demonstrate that our proposed method achieves state-of-the-art performance, e.g., a 5.2% performance gain on FGL-TV. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zou2024Prediction
ER  -

TY  - JOUR
AU  - Magalhaes Albuquerque, A.
AU  - Debiasi, P.
AU  - Lourenco De Lima, T.V.
AU  - Hirokawa Higa, G.T.
AU  - Pistori, H.
AU  - Ferraco Scolforo, H.
AU  - Ferreira Silva, T.C.
AU  - De Andrade Porto, J.V.
AU  - Stape, J.L.
TI  - Qualitative Forest Inventory in Eucalyptus Plantations Using Unmanned Aerial Vehicles, Multispectral Sensors, and Deep Learning
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 2505905
DO  - 10.1109/LGRS.2024.3465892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205498414&doi=10.1109%2fLGRS.2024.3465892&partnerID=40&md5=141751094214974c17d4d95eb6cb1c57
AB  - Forest inventory is an important activity for planning and decision-making in forest management. It is usually carried out in the field using different sampling methods and processes, which are usually limited by its high costs and by the scarcity of manpower. In this work, we evaluate deep learning methods in qualitative forest inventory of Eucalyptus plantations using unmanned aerial vehicles (UAVs), multispectral sensors, and deep learning. For evaluation, we present a dataset collected in two study areas located in different municipalities in the State of Mato Grosso do Sul, including field measurements collected by occasion of the qualitative forest inventory at four months (QFI 4m) and aerophotogrammetric coverage of 36 plots represented by 124 sampling units. State-of-the-art neural networks were then used to predict four variables, collected through traditional QFI 4m and approximated by two models: PB50 and PC50, which are adaptations of the PV50 index, and the total and average biomass in the sampling unit. The results show that the transformer-based architecture multiaxis vision transformer (MaxViT) presented the lowest errors in predicting all the variables. For example, for the PB50 variable, it achieved a root mean square error (RMSE) of 7.5 (±1.85) and a mean absolute percentage error (MAPE) of 0.33 (±0.23).  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Magalhaes Albuquerque2024Qualitative
ER  -

TY  - JOUR
AU  - Wu, H.
AU  - Xu, Z.
TI  - Multi-Energy Load Forecasting in Integrated Energy Systems: A Spatial-Temporal Adaptive Personalized Federated Learning Approach
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 10
SP  - 12262
EP  - 12274
DO  - 10.1109/TII.2024.3417297
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206517008&doi=10.1109%2fTII.2024.3417297&partnerID=40&md5=d098da1702a6583ca73c5eaadacc9954
AB  - Short-term forecasting of multienergy loads is of paramount significance for integrated energy systems operation. The central forecasting framework is confronted with the privacy disclosure issue. Besides, the intricate interdependencies among diverse energy loads present an opportunity to improve prediction accuracy. To this end, a privacy-preserving spatial-temporal adaptive personalized federated learning model is proposed in this article. Specifically, the proposed federated learning-based decentralized framework enables the sharing of local model weights while ensuring the confidentiality of raw measurement data. Besides, the spatial-temporal transformer leverages the self-attention mechanism to synchronously capture the complex dynamic dependencies among different types of energy load demand. Furthermore, the adaptive local aggregation mechanism is proposed to personalize the local model to address the data heterogeneity and subsequently improve forecasting accuracy. The proposed model is applied to a publicly available dataset. The results show that the proposed model can achieve highly efficient and effective forecasting accuracy.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Wu2024Multi-Energy
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Yuan, M.
AU  - Wang, T.
AU  - Jia, X.
AU  - Yan, D.-M.
TI  - HeightFormer: Single-Imagery Height Estimation Transformer With Bilateral Feature Pyramid Fusion
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 6016205
DO  - 10.1109/LGRS.2024.3461791
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204797955&doi=10.1109%2fLGRS.2024.3461791&partnerID=40&md5=b90bae5d0bf07be2316dd2e76915ceb9
AB  - Despite their ill-posedness and inherent ambiguity, recent deep learning approaches have demonstrated promising capability to estimate plausible height information from single spaceborne and airborne imagery. However, accurately predicting the height and preserving the rich geometric detailing of aerial images with limited resolution and complex structural variations remains a challenge. To address these issues, we introduce a novel transformer-based architecture for single-imagery height estimation (SIHE) dubbed as HeightFormer. Specifically, the building-block multiscale vision transformer (MViT) constitutes the encoder and decoder of HeightFormer to facilitate the capturing of long-range dependencies across a feature pyramid. Furthermore, we propose the bilateral feature pyramid fusion scheme, which consists of step-by-step and one-stop decoder feature map augmentation, to enhance global and local information reconstruction. The stepwise fusion module (SFM) iteratively fuses encoder and decoder features, while the multiscale fusion module (MFM) combines the final decoder feature with multiscale encoder features. In the end, the Heightbins module is designed to generate the attention map and the adaptive bin width. Then, the bin centers at each pixel are linearly combined as the final estimated height. Extensive experiments validate the effectiveness of HeightFormer on the Vaihingen dataset, the Potsdam dataset, and the DFC2019 dataset. Compared with the state-of-the-art, our method improves accuracy metrics and provides the ability to preserve structure and details. Building height estimation, transformer, attention, progressive refinement. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2024HeightFormer
ER  -

TY  - JOUR
AU  - Yang, C.
AU  - Jin, Q.
AU  - Wang, Y.
AU  - Zhou, Y.
AU  - Lan, D.
AU  - Yang, Y.
TI  - EHAPZero: Ensemble Hierarchical Attribute Prompting Based Zero-Shot Learning for Pest Recognition
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3472079
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207136194&doi=10.1109%2fJIOT.2024.3472079&partnerID=40&md5=c524ef6ac3b36d1908c5fb7f83932814
AB  - Pest recognition is of great significance for achieving sustainable development in agriculture. Nevertheless, due to the wide variety of pest species, subtle inter-species differences, and significant intra-species variations, existing artificial intelligence and Internet of Things (IoT) technologies can only recognize a small number of known pests effectively. In this paper, we propose a zero-shot learning pest recognition framework based on ensemble hierarchical attribute prompting, termed EHAPZero. EHAPZero can identify pest images collected by IoT devices, and then transmit the recognition results to the IoT platform for terminal display. Specifically, the image recognition function is implemented by an attribute generation module (AGM), a hierarchical prompting module (HPM), and a semantic-visual interaction module (SVIM). AGM utilizes large language models to construct a knowledge graph of pests. It employs both node importance evaluation algorithms and manual methods to perform dual filtering on attribute nodes within the graph. Inspired by human knowledge reasoning, HPM dynamically predicts different hierarchical attributes of input images within the Transformer intermediate blocks. These predicted attributes are subsequently injected into the intermediate layer features of the Transformer as prompts. To achieve semantic disambiguation and knowledge transfer, SVIM employs a visual-guided semantic representation method and a semantic-guided visual representation method to strengthen cross-domain interaction between semantics and vision. Finally, the final prediction score is derived through ensemble of prediction results across different levels. Extensive experiments show that EHAPZero achieves the new state-of-theart results on the real-word pest recognition benchmark. The codes are available at: https://github.com/jinqiwen/EHAPZero.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024EHAPZero
ER  -

TY  - JOUR
AU  - Kang, N.
AU  - Min, D.
AU  - Cho, Y.
AU  - Ko, D.-W.
AU  - Kim, H.H.
AU  - Choeh, J.Y.
AU  - Im, J.
TI  - Online News-Based Economic Sentiment Index
PY  - 2024
T2  - IEEE Transactions on Big Data
DO  - 10.1109/TBDATA.2024.3474211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207119348&doi=10.1109%2fTBDATA.2024.3474211&partnerID=40&md5=73bf2f90be1edb163a3820b7b4f16d33
AB  - The accurate prediction of industry trends has become increasingly challenging because of unforeseen events. To address this challenge, this study proposes a deep learning approach to generate an economic sentiment index by integrating Natural Language Processing (NLP) models and image-clustering techniques. We first employ sampling techniques to create standardized online news datasets. Feature engineering techniques from the Korean Bidirectional Encoder Representations from Transformers (KoBERT) model are then used to generate relevance and sentiment scores for the textual data. Further, to enhance visualization and clustering, we transform the textual data into joint plot images, which are grouped into distinct clusters based on news categories. Finally, using Multi-criteria Decision Analysis, the various scores and cluster information are synthesized to generate the final economic sentiment index. This approach improves visualization and enhances the interpretability of the generated index. The proposed algorithm is applied to construct a new economic sentiment index for the Information and Communications Technology (ICT) industry in South Korea.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Kang2024Online
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Guo, J.
AU  - Li, X.
AU  - Wang, H.
AU  - Xu, Z.
AU  - Gong, Z.
AU  - Zhang, L.
AU  - Leung, V.C.M.
TI  - CGraphNet: Contrastive Graph Context Prediction for Sparse Unlabeled Short Text Representation Learning on Social Media
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3452695
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205833043&doi=10.1109%2fTCSS.2024.3452695&partnerID=40&md5=ee943b82e9f2d79e3df2a8544184ad00
AB  - Unlabeled text representation learning (UTRL), encompassing static word embeddings such as Word2Vec and contextualized word embeddings such as bidirectional encoder representations from transformer (BERT), aims to capture semantic word relationships in a low-dimensional space without the need for manual labeling. These word embeddings are invaluable for downstream tasks such as document classification and clustering. However, the surge of short texts generated daily on social media platforms results in sparse word cooccurrences, compromising UTRL outcomes. Contextualized models such as recurrent neural network (RNN) and BERT, while impressive, often struggle with predicting the next word due to sparse word sequences in short texts. To address this, we introduce CGraphNet, a contrastive graph context prediction model designed for UTRL. This approach converts short texts into graphs, establishing links between sequentially occurring words. Information from the next word and its neighbors informs the target prediction, a process referred to as graph context prediction, mitigating sparse word cooccurrence issues in brief sentences. To minimize noise, an attention mechanism assigns importance to neighbors, while a contrastive objective encourages more distinctive representations by comparing the target word with its neighbors. Our experiments demonstrate CGraphNet's superior performance over other baselines, particularly in classification and clustering tasks on real-world datasets. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chen2024CGraphNet
ER  -

TY  - JOUR
AU  - Tian, X.
AU  - Ma, H.
AU  - Guan, Y.
AU  - Xu, L.
AU  - Liu, J.
AU  - Tian, L.
TI  - Transformer3: A Pure Transformer Framework for fMRI-Based Representations of Human Brain Function
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
DO  - 10.1109/JBHI.2024.3471186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206346894&doi=10.1109%2fJBHI.2024.3471186&partnerID=40&md5=5960e5165e8cfc89f397a52e1cc0d3f2
AB  - Effective representation learning is essential for neuroimage-based individualized predictions. Numerous studies have been performed on fMRI-based individualized predictions, leveraging sample-wise, spatial, and temporal interdependencies hidden in fMRI data. However, these studies failed to fully utilize the effective information hidden in fMRI data, as only one or two types of the interdependencies were analyzed. To effectively extract representations of human brain function through fully leveraging the three types of the interdependencies, we establish a pure transformer-based framework, Transformer3, leveraging transformer's strong ability to capture interdependencies within the input data. Transformer3 consists mainly of three transformer modules, with the Batch Transformer module used for addressing sample-wise similarities and differences, the Region Transformer module used for handling complex spatial interdependencies among brain regions, and the Time Transformer module used for capturing temporal interdependencies across time points. Experiments on age, IQ, and sex predictions based on two public datasets demonstrate the effectiveness of the proposed Transformer3. As the only hypothesis is that sample-wise, spatial, and temporal interdependencies extensively exist within the input data, the proposed Transformer3 can be widely used for representation learning based on multivariate time-series. Furthermore, the pure transformer framework makes it quite convenient for understanding the driving factors underlying the predictive models based on Transformer3. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tian2024Transformer3
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Chen, J.
AU  - Zhang, Y.
AU  - Sun, R.
AU  - Xia, S.
AU  - Pan, Z.
AU  - Luo, J.
TI  - MSGFormer: Revolutionizing Traffic Flow Prediction with Multi-Scale and Gated Transformer Architecture
PY  - 2024
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2024.3465559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205021550&doi=10.1109%2fJIOT.2024.3465559&partnerID=40&md5=0504248ef0bb714377d3c917378d3f2f
AB  - Traffic flow prediction has emerged as a critical component in advancing smart cities. Nevertheless, precisely forecasting traffic flow remains a formidable challenge, attributable to the intricate and dynamic spatiotemporal interdependencies inherent within traffic data. Contemporary methodologies often overlook the different impacts exerted at each timestamp and treat temporal correlations, rendering them incapable of extracting temporal patterns at multiple scales. Furthermore, these approaches fail to account for the neighboring and functional relationships among nodes within the spatial module. In this work, we introduce an innovative Multi-Scale and Gated transFormer architecture, MSGFormer, to overcome the inherent limitations for accurate traffic flow estimation. We have introduced a multi-scale sampling strategy wherein we sample from the original data at three scales: recent, daily, and weekly. This approach enables the generation of corresponding subsequences that encapsulate temporal information across different granularities. Subsequently, each generated subsequence is projected into a latent space and systematically combined with positional, temporal, and spatial embeddings. The positional embedding comprises relative positional embedding and time stamp embedding corresponding to days and weeks, aiming at capturing the sequential and cyclical characteristics of the data. Furthermore, at the inception of the transformer encoder, a gated unit, composed of a neighboring mask and a functioning mask, is employed to capture both static and dynamic spatial correlations effectively. Comprehensive experiments have been conducted on four real-world traffic datasets. The experimental results robustly validate that our model attains significantly higher predictive accuracy in comparison to other baseline models. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024MSGFormer
ER  -

TY  - JOUR
AU  - Nguyen, V.-L.
AU  - Tsai, H.-P.
AU  - Shin, H.
AU  - Duong, T.Q.
TI  - Spatial Data Transformation and Vision Learning for Elevating Intrusion Detection in IoT Networks
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 24
SP  - 41261
EP  - 41272
DO  - 10.1109/JIOT.2024.3459015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204405215&doi=10.1109%2fJIOT.2024.3459015&partnerID=40&md5=d55efebca6591a5e9dcd1c3197c1cb77
AB  - Network intrusion detection systems (NIDSs) are vital for identifying security attacks and predicting early invasion attempts, which is essential for protecting the Internet. Recently, deep learning (DL) has made significant achievements in enhancing intrusion detection accuracy. Nevertheless, the practical implementation of high-complexity DL models is limited by the constrained computational capabilities of the Internet of Things (IoT) devices, e.g., home routers and IoT gateways. This article introduces a novel NIDS approach explicitly tailored for IoT networks, leveraging a lightweight DL model. During the data preprocessing phase, we use a spatially enriched data conversion technique to decrease the dimensionality of high-dimensional raw traffic variables. This helps to offset the problem of increased model complexity. Furthermore, when spatial relationships often exist in the data, we can simplify the learning architecture by utilizing state-of-the-art vision transformer techniques in the computer vision field that can substantially reduce model complexity. The experimental results indicate that the proposed method achieves outstanding accuracy up to 99.57% with high-volume traffic input. Moreover, the proposed method reaches substantial reductions in learnable parameters by 55.35% and 82.07%, along with a remarkable decrease in floating point operations (FLOPs) by 93.56% and 99.28% compared to existing studies. The outstanding achievement highlights the proposed method's ability to balance model complexity and accuracy performance, making it extremely appropriate for deployment on IoT gateways with limited resources.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Nguyen2024Spatial
ER  -

TY  - JOUR
AU  - Ren, L.
AU  - Li, S.
AU  - Wang, X.
AU  - Wang, H.
AU  - Laili, Y.
TI  - BTFormer: A BNN-Based Trend-Aware Time-Series Prediction Model for Industrial Intelligence
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 12
SP  - 14381
EP  - 14390
DO  - 10.1109/TII.2024.3452181
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204203390&doi=10.1109%2fTII.2024.3452181&partnerID=40&md5=a0f417722a4a6fcf88e177e39dc6cd39
AB  - Prediction of industrial time-series is crucial for various Industrial Internet of Things applications. Despite the high accuracy of deep learning methods for time-series prediction, the significant memory requirements of deep learning models pose a challenge for the limited computational resources of industrial edge devices. To address this issue, this work proposes BTFormer, which achieves a high compression rate while maintaining competitive performance. First, a binary adaptive attention module is proposed to mitigate the loss of attention information caused by binarization. Second, a trend information soft-link is proposed to propagate trend information between layers and improve the representation ability of the model. Finally, a distribution-guided distillation strategy is proposed to optimize the training process. The experiments demonstrate that BTFormer effectively reduces model memory usage by 31.0 times and improves computational efficiency by 32.8 times while maintaining competitive performance.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Ren2024BTFormer
ER  -

TY  - JOUR
AU  - Wang, D.
AU  - Han, S.
AU  - Xu, Y.
AU  - Wu, Z.
AU  - Zhou, L.
AU  - Morovati, B.
AU  - Yu, H.
TI  - LoMAE: Simple Streamlined Low-Level Masked Autoencoders for Robust, Generalized, and Interpretable Low-Dose CT Denoising
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 11
SP  - 6815
EP  - 6827
DO  - 10.1109/JBHI.2024.3454979
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203409742&doi=10.1109%2fJBHI.2024.3454979&partnerID=40&md5=8d100db8683fa4485cecfe296ea8eced
AB  - Low-dose computed tomography (LDCT) offers reduced X-ray radiation exposure but at the cost of compromised image quality, characterized by increased noise and artifacts. Recently, transformer models emerged as a promising avenue to enhance LDCT image quality. However, the success of such models relies on a large amount of paired noisy and clean images, which are often scarce in clinical settings. In computer vision and natural language processing, masked autoencoders (MAE) have been recognized as a powerful self-pretraining method for transformers, due to their exceptional capability to extract representative features. However, the original pretraining and fine-tuning design fails to work in low-level vision tasks like denoising. In response to this challenge, we redesign the classical encoder-decoder learning model and facilitate a simple yet effective streamlined low-level vision MAE, referred to as LoMAE, tailored to address the LDCT denoising problem. Moreover, we introduce an MAE-GradCAM method to shed light on the latent learning mechanisms of the MAE/LoMAE. Additionally, we explore the LoMAE's robustness and generability across a variety of noise levels. Experimental findings show that the proposed LoMAE enhances the denoising capabilities of the transformer and substantially reduce their dependency on high-quality, ground-truth data. It also demonstrates remarkable robustness and generalizability over a spectrum of noise levels. In summary, the proposed LoMAE provides promising solutions to the major issues in LDCT including interpretability, ground truth data dependency, and model robustness/generalizability.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024LoMAE
ER  -

TY  - JOUR
AU  - Xie, S.
AU  - Cheng, W.
AU  - Xing, J.
AU  - Nie, Z.
AU  - Chen, X.
AU  - Gao, L.
AU  - Huang, Q.
AU  - Zhang, R.
TI  - Incremental Contrast Hybrid Model for Online Remaining Useful Life Prediction With Uncertainty Quantification in Machines
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 12
SP  - 14308
EP  - 14320
DO  - 10.1109/TII.2024.3450003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204244542&doi=10.1109%2fTII.2024.3450003&partnerID=40&md5=21c3cddaaf228821a4abf4178c6eff3c
AB  - Real-time and accurate prediction of remaining useful life (RUL) is important to safe operation and maintenance (O&M) planning of mechanical equipment. However, the uncertainty of online RUL prediction is difficult to predict with most current deep learning (DL)-based methods, making the prediction results difficult to convince. Furthermore, the offline-trained DL model is unable to adaptively update the network parameters online when acquiring new data, leading to a decrease in RUL prediction accuracy. To overcome these problems, an innovative approach based on the incremental contrast hybrid model is proposed for online RUL prediction with uncertainty quantification, which combines the contrastive learning transformer (CLformer) with the enhanced generalized Wiener process (EGWP) to describe trends in mechanical degradation. First, a CLformer is developed for online trend prediction, and an incremental contrastive learning strategy is designed for online adaptive updating of CLformer parameters to reduce prediction offset errors. Then, the degradation increments within the EGWP state-space equations are predicted online by the proposed CLformer network for online updating of EGWP parameters. Finally, online prediction of the machine RUL is provided by the CLformer, whereas the hybrid model provides the probability density function of RUL. The effectiveness of the proposed method is verified using two publicly available datasets and the journal-bearing dataset of the nuclear-circulating water pump. The results demonstrate the ability of the proposed method to dynamically update model parameters when new data are acquired online while giving the RUL prediction values and uncertainties.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Xie2024Incremental
ER  -

TY  - JOUR
AU  - Mao, C.
AU  - Zhao, L.
AU  - Liu, Z.
AU  - Min, G.
AU  - Hawbani, A.
AU  - Yu, K.
TI  - Empowering C-V2X Through Advanced Joint Traffic Prediction in Urban Networks
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 24
SP  - 39780
EP  - 39793
DO  - 10.1109/JIOT.2024.3447046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201772632&doi=10.1109%2fJIOT.2024.3447046&partnerID=40&md5=78e5ed4245e5110192114f239b038bb0
AB  - Cellular vehicle-to-everything (C-V2X) can provide ubiquitous mobile computing and communication services for vehicles, acting as a key technology to realize future urban intelligent transportation systems (ITS). Due to the lack of long-term insight into complex and dynamic urban road states, the existing historical road information-based strategies for C-V2X applications are inadequate to satisfy their high-performance requirements. Fortunately, it is feasible to provide fine-grained future road states for C-V2X decision-making by predicting traffic states to address this issue. To this end, this article proposes a fine-grained joint traffic prediction method in the urban road network with high-spatial complexity (ROUTE). ROUTE uniquely forecasts both micro-level (individual vehicle states) and macro-level traffic, thus supporting the diverse requirements of C-V2X applications. ROUTE is comprised of three key parts, including a vehicle coordinate transformation model, a spatial interaction-based turning model, and a micro-traffic prediction model. First, the complex spatial topology of the urban regional road network is normalized in ROUTE using the coordinate transformation model. Second, the turning model calculates the next road that the vehicle chooses after leaving the current one. Third, a transformer and generative adversarial network-based model (FORMERGAN) predicts future micro-traffic states. Extensive experimental results demonstrate that ROUTE surpasses its competitors in accurately predicting fine-grained long-term micro-traffic and macro-traffic states. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Mao2024Empowering
ER  -

TY  - JOUR
AU  - Rezayi, S.
AU  - Liu, Z.
AU  - Wu, Z.
AU  - Dhakal, C.
AU  - Ge, B.
AU  - Dai, H.
AU  - Mai, G.
AU  - Liu, N.
AU  - Zhen, C.
AU  - Liu, T.
AU  - Li, S.
TI  - Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications
PY  - 2024
T2  - IEEE Transactions on Big Data
SP  - 1
EP  - 12
DO  - 10.1109/TBDATA.2024.3442542
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201463745&doi=10.1109%2fTBDATA.2024.3442542&partnerID=40&md5=f956c592ec44b749f90f6155572cd6d4
AB  - This paper explores new frontiers in agricultural natural language processing (NLP) by investigating the effectiveness of food-related text corpora for pretraining transformer-based language models. Specifically, we focus on semantic matching, establishing mappings between food descriptions and nutrition data through fine-tuning AgriBERT with the FoodOn ontology. Our work introduces an expanded comparison with state-of-the-art language models such as GPT-4, Mistral-large, Claude 3 Sonnet, and Gemini 1.0 Ultra. This exploratory investigation, rather than a direct comparison, aims to understand how AgriBERT, a domain-specific, fine-tuned, open-source model, complements the broad knowledge and generative abilities of these advanced LLMs in addressing the unique challenges of the agricultural sector. We also experiment with other applications, such as cuisine prediction from ingredients, expanding our research to include various NLP tasks beyond semantic matching. Overall, this paper underscores the potential of integrating domain-specific models like AgriBERT with advanced LLMs to enhance the performance and applicability of agricultural NLP applications. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Rezayi2024Exploring
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Wang, Y.
AU  - Xiang, X.
AU  - Jin, D.
AU  - Ren, Y.
AU  - Zhang, Y.
AU  - Pan, Z.
AU  - Chen, Y.
TI  - TXL-Fuzz: A Long Attention Mechanism-Based Fuzz Testing Model for Industrial IoT Protocols
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 23
SP  - 38238
EP  - 38245
DO  - 10.1109/JIOT.2024.3444893
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201610410&doi=10.1109%2fJIOT.2024.3444893&partnerID=40&md5=564d1bc12d937210f64539c1e44ad02c
AB  - In recent years, industrial control systems (ICSs) security incidents have revealed vulnerabilities in the system hardware, user programs, and communication protocols. The various components of the ICS are connected by the Industrial Internet of Things (IIoT) protocol. Nevertheless, malicious attackers can exploit vulnerabilities in IIoT protocol to manipulate the ICS, potentially causing damage to the associated ICS equipment. This work focuses on the challenge of identifying vulnerabilities in IIoT protocols, aiming to enhance the system security through advanced fuzz testing techniques. To address the limitations of current fuzz testing in IIoT protocols, such as short prediction sequence lengths and low recognition rates, this work proposes a novel fuzz testing model based on the long attention mechanism, named TXL-Fuzz. This model is capable of handling longer protocol sequences and improving the diversity of the generated test cases. Experimental results demonstrate that the model outperforms the existing fuzz testers in test case recognition rate (TCRR) for the protocols of different lengths. Notably, TXL-Fuzz achieves a bits-per-character (BPC) of approximately 0.5, significantly lower by nearly 0.3 compared to the Anti-Sample Fuzzer, the long short-term memory network (LSTM)-based model, and GRU-based model. Furthermore, it exhibits a TCRR that is 5% to 15% higher than Peach Fuzzer, Anti-Sample Fuzzer, and BLSTM-DCNNFuzz under similar conditions. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Chen2024TXL-Fuzz
ER  -

TY  - JOUR
AU  - Yang, Q.
AU  - Li, C.
AU  - Ou, C.
AU  - Li, K.
AU  - Liao, X.
AU  - Duan, C.
AU  - Yu, L.
AU  - Si, W.
TI  - Synthesizing Feature-Aligned and Category-Aware Electronic Medical Records for Intracranial Aneurysm Rupture Prediction
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 12
SP  - 7420
EP  - 7433
DO  - 10.1109/JBHI.2024.3448459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201789196&doi=10.1109%2fJBHI.2024.3448459&partnerID=40&md5=0b1324b3a33b38594690bc3b80bc85ea
AB  - Rupture prediction is crucial for precise treatment and follow-up management of patients with intracranial aneurysms (IAs). Considerable machine learning (ML) methods have been proposed to improve rupture prediction by leveraging electronic medical records (EMRs), however, data scarcity and category imbalance strongly influence performance. Thus, we propose a novel data synthesis method i.e., Transformer-based conditional GAN (TransCGAN), to synthesize highly authentic and category-aware EMRs to address above challenges. Specifically, we first align feature-wise context relationship and distribution between synthetic and original data to enhance synthetic data quality. To achieve this, we first integrate the Transformer structure into GAN to match the contextual relationship by processing the long-range dependencies among clinical factors and introduce a statistical loss to maintain distributional consistency by constraining the mean and variance of the synthesis features. Additionally, a conditional module is designed to assign the category of the synthesis data, thereby addressing the challenge of category imbalance. Subsequently, the synthetic data are merged with the original data to form a large-scale and category-balanced training dataset for IAs rupture prediction. Experimental results show that using TransCGAN's synthetic data enhances classifier performance, achieving AUC of 0.89 and outperforming state-of-the-art resampling methods by 5%-33% in F1 score.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Synthesizing
ER  -

TY  - JOUR
AU  - Li, T.
AU  - Zhang, Y.
AU  - Li, Q.
TI  - Appearance-Based Driver 3-D Gaze Estimation Using GRM and Mixed Loss Strategies
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 23
SP  - 38410
EP  - 38424
DO  - 10.1109/JIOT.2024.3449409
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202761500&doi=10.1109%2fJIOT.2024.3449409&partnerID=40&md5=6f7881d420b35496132256323cb6163c
AB  - Driver gaze estimation is a key technology in advanced intelligent vehicles, and it is crucial for ensuring road safety by monitoring driver visual attention. Previously, attention detection through head pose or saliency map integration only offered rudimentary estimation and was insufficient for the advanced driver assistance systems (ADASs), which require more precise gaze data. This work introduces an appearance-based method for driver 3-D gaze estimation. Initially, the Swin Transformer was used to enhance global image information processing, which enabled accurate gaze direction prediction. Furthermore, the method incorporates a gaze refinement module (GRM) as a postbackbone to optimize feature mapping, thus ensuring stable gaze direction estimation. Finally, a mixed loss function was used to improve the accuracy. This mixed loss function combines pinball loss, mean-squared error (MSE), and bias penalty. The experimental results demonstrated angular errors of 3.76° and 10.62° in the MPIIGazeFace and Gaze360 gaze estimation data sets. We inferenced the proposed method to the driver monitoring data set (DMD), and the results demonstrate the effectiveness of this work. Our code is publicly available at github.com/Rocky1salady-killer/DGE-GM.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Appearance-Based
ER  -

TY  - JOUR
AU  - Zhu, X.
AU  - Shen, D.
AU  - Wang, H.
AU  - Hao, Y.
TI  - FCNet: Fully Complex Network for Time Series Forecasting
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 24
SP  - 40127
EP  - 40139
DO  - 10.1109/JIOT.2024.3449903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202727973&doi=10.1109%2fJIOT.2024.3449903&partnerID=40&md5=da91a387dde7aa7535ca7a5405a3de0e
AB  - Time series forecasting (TSF) has extensive applications in domains, such as energy, traffic, and weather prediction. Currently, existing literature has designed many architectures that combine deep learning models in the frequency domain, and effective results have been achieved. However, handling complex-valued arithmetic poses a challenge for most frequency domain-based models. Additionally, features extracted solely in either the time or frequency domain are not comprehensive enough. To solve these problems, we propose a fully complex network (FCNet) in this work, where all network layers are adapted to handle complex-valued computations to simultaneously learn the information in the real and imaginary parts. First, we utilize time-frequency conversion to obtain time-frequency domain signals. And then we design the time-frequency filter-enhanced block to effectively capture global features from time-frequency signals. Finally, we design the complex-valued time-frequency Transformers Block, which separately extracts information from the time and frequency domains. Experimental evaluations on eight data sets from five benchmark domains demonstrate that our model significantly outperforms state-of-the-art methods in TSF. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhu2024FCNet
ER  -

TY  - JOUR
AU  - Jiang, Y.
AU  - Yu, Z.
AU  - Zheng, H.
TI  - Short-Term Earthquake Forecasting via Self-Supervised Learning
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 3003905
DO  - 10.1109/LGRS.2024.3448623
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201750926&doi=10.1109%2fLGRS.2024.3448623&partnerID=40&md5=572fb395494ba8e8bd1cc9bd09a88978
AB  - Due to the infrequency of major earthquakes (magnitude 5 or above) and the highly nonlinear nature of seismic activities, short-term earthquake forecasting (hours to weeks) faces the challenge of lacking seismic samples and struggling with acquiring seismic-related knowledge. To address these issues, we propose a novel self-supervised learning for earthquake forecasting (SSL-EF) approach, namely, self-supervised learning (SSL) for earthquake forecasting, which has two distinctive characteristics: 1) an efficient pretext task leveraging temporal signal patterns for knowledge acquisition and 2) the knowledge transfer mitigating the constraints posed by limited seismic samples. Specifically, we first design the prediction task as a pretext task, leveraging the past week's observational data to predict the coming week's data. Subsequently, we set the classification task as a downstream task, focusing on whether a major earthquake occurs in the coming week. Moreover, transferring knowledge from the prediction task facilitates training the classification model on a small-scale and balanced dataset obtained through undersampling. Compared with ten competing methods, our SSL-EF yields state-of-the-art area under the curve (AUC), with a 21.98% relative improvement on the real-world dataset. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jiang2024Short-Term
ER  -

TY  - JOUR
AU  - Zou, Q.
AU  - Shang, J.
AU  - Liu, J.
AU  - Gao, R.
TI  - BIGFormer: A Graph Transformer with Local Structure Awareness for Diagnosis and Pathogenesis Identification of Alzheimer&#x0027;s Disease Using Imaging Genetic Data
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 1
EP  - 12
DO  - 10.1109/JBHI.2024.3442468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202763675&doi=10.1109%2fJBHI.2024.3442468&partnerID=40&md5=f0811e24a5633ed06e58828c4aff4d64
AB  - Alzheimer&#x0027;s disease (AD) is a highly inheritable neurological disorder, and brain imaging genetics (BIG) has become a rapidly advancing field for comprehensive understanding its pathogenesis. However, most of the existing approaches underestimate the complexity of the interactions among factors that cause AD. To take full appreciate of these complexity interactions, we propose BIGFormer, a graph Transformer with local structural awareness, for AD diagnosis and identification of pathogenic mechanisms. Specifically, the factors interaction graph is constructed with lesion brain regions and risk genes as nodes, where the connection between nodes intuitively represents the interaction between nodes. After that, a perception with local structure awareness is built to extract local structure around nodes, which is then injected into node representation. Then, the global reliance inference component assembles the local structure into higher-order structure, and multi-level interaction structures are jointly aggregated into a classification projection head for disease state prediction. Experimental results show that BIGFormer demonstrated superiority in four classification tasks on the AD neuroimaging initiative dataset and proved to identify biomarkers closely intimately related to AD IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zou2024BIGFormer
ER  -

TY  - JOUR
AU  - Zhao, Y.
AU  - Yang, J.
AU  - Wang, W.
AU  - Yang, H.
AU  - Niyato, D.
TI  - TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 21
SP  - 35432
EP  - 35444
DO  - 10.1109/JIOT.2024.3436110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200240920&doi=10.1109%2fJIOT.2024.3436110&partnerID=40&md5=8e822cb95b0943f4c8fb8a4fdef34a1e
AB  - Industrial systems require reliable predictive maintenance strategies to enhance operational efficiency and reduce downtime. Existing studies rely on the heuristic models which may struggle to capture complex temporal dependencies. This article introduces an integrated framework that leverages the capabilities of the Transformer and deep reinforcement learning (DRL) algorithms to optimize the system maintenance actions. Our approach employs the Transformer model to effectively capture complex temporal patterns in IoT sensor data, thus accurately predicting the remaining useful life (RUL) of equipment. Additionally, the DRL component of our framework provides cost-effective and timely maintenance recommendations. Numerous experiments conducted on the NASA C-MPASS data set demonstrate that our approach has a performance similar to the ground truth results and could be obviously better than the baseline methods in terms of RUL prediction accuracy as the time cycle increases. Additionally, the experimental results demonstrate the effectiveness of optimizing maintenance actions.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2024TranDRL
ER  -

TY  - JOUR
AU  - Muthulakshmi, P.
AU  - Suthendran, K.
AU  - Ravi, V.
TI  - CAST2-Zone Wise Disease Outbreak Control Model for SARS-Cov 2
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19918-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200976377&doi=10.1007%2fs11042-024-19918-x&partnerID=40&md5=1eb9be60bc9f9318f135bf2ffa4b69b5
AB  - Disease spread is necessary to be controlled so that there is a chance to increase the survival rate of the people in particular zones. The outbreak of SARS-CoV-2 presents critical challenges exacerbated by atmospheric conditions and high population density. Existing time series methodologies for disease outbreak prediction lack spatial detail, hindering effective local-scale control measures. Addressing this gap, the Concomitant Automation of Space and Time Transformer encoder is proposed, which utilizing a Hybrid Aquila Genetic autoencoder to enhance image quality and spatial details. The accompanying Wide Window Lain Transformer extracts microclimate and microhabitat contextual characteristics from images. Furthermore, conventional statistical models fail to accurately determine reproductive indices for disease-prone areas. To overcome this limitation, the Particularly Prone Infected Relieve Model is introduced. In this employing the Susceptible-Infected-Recovered equation and transmission plot neural network to estimate stable reproductive numbers without demographic biases. Implemented in Python, this novel approach yields highly accurate epidemic predictions and timely warnings, surpassing existing time-series methods. When compared with the existing techniques, the proposed model has a high accuracy of 97%, a precision of 92%, a recall of 92%, and an F1-Score of 92%. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Muthulakshmi2024CAST2-Zone
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Yang, Z.
AU  - Yang, Z.
TI  - Gated Spatial–Temporal Merged Transformer Inspired by Multimask and Dual Branch for Traffic Forecasting
PY  - 2024
T2  - IET Signal Processing
VL  - 2024
IS  - 1
C7  - 8639981
DO  - 10.1049/2024/8639981
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199427362&doi=10.1049%2f2024%2f8639981&partnerID=40&md5=0d7cfc6903ba0f77e8c4421231d5859d
AB  - As an essential part of intelligent transportation system (ITS), traffic forecasting has provided crucial role for traffic management and risk assessment. However, complex spatial–temporal dependencies, heterogeneity, dynamicity, and periodicity of traffic data influence the traffic forecasting performance. Consequently, we propose a novel effective gated spatial–temporal merged transformer (GSTMT) inspired by multimask and dual branch for accurate traffic forecasting in this paper. Specifically, we first conduct a concatenation of gated spatial static mask transformer (GSSMT) and gated spatial dynamic mask transformer (GSDMT) with residual network. The GSSMT and GSDMT evolve from the traditional transformer by making preferable modifications that include gated linear unit (GLU), multimask mechanism including static mask matrix (SMM) and dynamic mask matrix (DMM), and spatial attention (SA). Among them, GLU is to promote the performance of capturing spatial dependency, dynamicity, and heterogeneity due to advanced performance for controlling information flow through layers. Additionally, by developing multimask mechanism including two novel SMM and DMM, the proposed GSTMT can precisely model the static and dynamic spatial structure for effectively highlighting static dependency and dynamicity. And SA is injected for enhancing the ability of capturing spatial dependency of GSSMT and GSDMT. Secondly, we develop a dual-branch gated temporal transformer (DBGTT) for capturing temporal dependency, heterogeneity, dynamicity, and periodicity via incorporating the GLU and mixed time series decomposition (MTD) into traditional transformer. Similarly, we also introduce the GLU for empowering DBGTT with capability of capturing temporal dependency, dynamicity, and heterogeneity. In addition, MTD, which brings dual-branch mechanism, can enhance the DBGTT for capturing more detailed temporal information via exploiting global and periodic profile of traffic data. At last, some experiments, which are performed on several real-world traffic datasets, demonstrate the better results over classic traffic forecasting methods. Copyright © 2024 Yongpeng Yang et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024Gated
ER  -

TY  - JOUR
AU  - Zhou, H.
AU  - Wang, L.
AU  - Yao, W.
AU  - Li, W.
AU  - Zhou, H.
AU  - Zeng, H.
TI  - Generating Biomedical Hypothesis With Spatiotemporal Transformers
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 11
SP  - 6897
EP  - 6905
DO  - 10.1109/JBHI.2024.3435011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200229262&doi=10.1109%2fJBHI.2024.3435011&partnerID=40&md5=fdd1cf6f1d5d1f01446f3145d01d256b
AB  - Generating biomedical hypotheses is a difficult task as it requires uncovering the implicit associations between massive scientific terms from a large body of published literature. A recent line of Hypothesis Generation (HG) approaches - temporal graph-based approaches - have shown great success in modeling temporal evolution of term-pair relationships. However, these approaches model the temporal evolution of each term or term-pair with Recurrent Neural Network (RNN) independently, which neglects the rich covariation among all terms or term-pairs while ignoring direct dependencies between any two timesteps in a temporal sequence. To address this problem, we propose a Spatiotemporal Transformer-based Hypothesis Generation (STHG) method to interleave spatial covariation and temporal progression in a unified framework for constructing direct connections between any two term-pairs while modeling the temporal relevance between any two timesteps. Experiments on three biomedical relationship datasets show that STHG outperforms the state-of-the-art methods.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhou2024Generating
ER  -

TY  - JOUR
AU  - Wen, L.
AU  - Hu, Q.
AU  - Guo, C.
AU  - Hu, A.
AU  - Zhang, M.
TI  - Cross-Scale Attention for Long-Term Time Series Forecasting
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 2675
EP  - 2679
DO  - 10.1109/LSP.2024.3439103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200824970&doi=10.1109%2fLSP.2024.3439103&partnerID=40&md5=06909ab5838502ba80fd6ec012ecc456
AB  - Transformer-based models, especially PatchTST, have demonstrated remarkable success in time series forecasting tasks. However, the unique nature of time series data, which often contains jitter, and noise, and has inherently lower information density compared to images and texts, poses significant challenges. Specifically, the ViT-inspired patching design is suboptimal for time series data due to the sparse semantic relationships in such data. Moreover, modelling these sparse semantic relationships requires more resources and longer processing times. To overcome these limitations, we introduce a novel approach that leverages cross-scale attention interaction via a multi-scale patching technique. Our method initially treats the entire sequence as a single patch, then progressively divides it into increasing patches, doubling each time. This strategy improves the information density within each patch and reduces the total number of patches needed to model the time series to typically just seven effectively. We design a single layer of attention to model the cross-scale relationships among patches. These qualities significantly enhance computational efficiency. Extensive experiments have shown that our method surpasses or closely approaches existing methods in time-series forecasting benchmarks. Additionally, it achieves a speed that is 12x times faster than PatchTST on the large dataset.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wen2024Cross-Scale
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Kou, L.
AU  - Jiao, P.
AU  - Zhang, J.
AU  - Miao, C.
AU  - Lin, Y.
TI  - GAGNN: Generative Adversarial Network and Graph Neural Network for Prognostic and Health Management
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 24
SP  - 39448
EP  - 39463
DO  - 10.1109/JIOT.2024.3435917
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200220210&doi=10.1109%2fJIOT.2024.3435917&partnerID=40&md5=dbc8e6dd46686276e07517e76fc8f18f
AB  - Thanks to the development of the Internet of Things, a large number of sensors have been deployed, resulting in the collection of abundant time series data. These data series contain potential space-time connection and noise at the same time. Prediction and health management (PHM) aim to provide decision support based on the health state of an entire engineering system. Additionally, the predicting future values also contribute to decision making and fall under the category of time series forecasting. While the existing methods focus on capturing the correlation between the data and reducing the impact of noise, they often fail to fully utilize the noise present in the time series data. In this article, we propose a framework for multivariate time series forecasting called GAGNN. This framework integrates the idea of a generative adversarial network and a graph neural network organically. It adopts the graph neural network as the generator and a multilayer perceptron as the discriminator. Finally, the prediction module is used to obtain the prediction results. The generator, discriminator, and prediction module are trained jointly. Our experimental results demonstrate that our model outperforms the original model on most benchmark data sets and achieves the best results on three out of six benchmark data sets. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2024GAGNN
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Song, X.
AU  - Zhang, S.
AU  - Li, L.
AU  - Jianqiao Yu, J.
TI  - GT-TTE: Modeling Trajectories as Graphs for Travel Time Estimation
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 19
SP  - 30965
EP  - 30977
DO  - 10.1109/JIOT.2024.3417432
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199563327&doi=10.1109%2fJIOT.2024.3417432&partnerID=40&md5=423a34e6a449a697d6d486468da6855e
AB  - Travel time estimation (TTE) aims to predict travel duration and provide reliable planning for residential travel schedules. Trajectories naturally contain sequential features in form of GPS points with temporal precedence, which can be leveraged to improve prediction performance. Besides, the spatial information, i.e., the graph structure of the road network, can well represent the road highly and is commonly used to capture spatial information in traffic networks. However, extracting regional spatial information from trajectory data, in addition to its latitude and longitude information, poses a significant challenge due to the inherent format in which the trajectory data is recorded. In light of this, we propose a graph-transformer for TTE (GT-TTE) to utilize a Graph Transformer to adapt effectively to trajectories' sequential and spatial characteristics for improved TTE performance. By traversing the trajectory nodes with GT-TTE, we construct a graph structure for all trajectory points, thereby obtaining the relative spatial information of each point. Further, we obtain a region adjacency empirically more feature-rich over the sequential data. We evaluate GT-TTE on three real-world representative data sets and observe improvement by approximately 17% compared to the state-of-the-art baselines.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Huang2024GT-TTE
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Bai, X.
AU  - Nie, R.
AU  - Liu, Y.
AU  - Zhang, L.
AU  - You, Z.
TI  - Predicting miRNA-Disease Associations Based on Spectral Graph Transformer with Dynamic Attention and Regularization
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 12
SP  - 7611
EP  - 7622
DO  - 10.1109/JBHI.2024.3438439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200819131&doi=10.1109%2fJBHI.2024.3438439&partnerID=40&md5=8d78fa053966877e1f02d4a0c73c0df7
AB  - Extensive research indicates that microRNAs (miRNAs) play a crucial role in the analysis of complex human diseases. Recently, numerous methods utilizing graph neural networks have been developed to investigate the complex relationships between miRNAs and diseases. However, these methods often face challenges in terms of overall effectiveness and are sensitive to node positioning. To address these issues, the researchers introduce DARSFormer, an advanced deep learning model that integrates dynamic attention mechanisms with a spectral graph Transformer effectively. In the DARSFormer model, a miRNA-disease heterogeneous network is constructed initially. This network undergoes spectral decomposition into eigenvalues and eigenvectors, with the eigenvalue scalars being mapped into a vector space subsequently. An orthogonal graph neural network is employed to refine the parameter matrix. The enhanced features are then input into a graph Transformer, which utilizes a dynamic attention mechanism to amalgamate features by aggregating the enhanced neighbor features of miRNA and disease nodes. A projection layer is subsequently utilized to derive the association scores between miRNAs and diseases. The performance of DARSFormer in predicting miRNA-disease associations (MDAs) is exemplary. It achieves an AUC of 94.18% in a five-fold cross-validation on the HMDD v2.0 database. Similarly, on HMDD v3.2, it records an AUC of 95.27%. Case studies involving colorectal, esophageal, and prostate tumors confirm 27, 28, and 26 of the top 30 associated miRNAs against the dbDEMC and miR2Disease databases, respectively.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li2024Predicting
ER  -

TY  - JOUR
AU  - Guo, J.
AU  - Xu, P.
AU  - Wu, Y.
AU  - Tao, Y.
AU  - Han, C.
AU  - Lin, J.
AU  - Zhao, K.
AU  - Liu, Z.
AU  - Liu, W.
AU  - Lu, C.
TI  - CroMAM: A Cross-Magnification Attention Feature Fusion Model for Predicting Genetic Status and Survival of Gliomas Using Histological Images
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 12
SP  - 7345
EP  - 7356
DO  - 10.1109/JBHI.2024.3431471
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199072676&doi=10.1109%2fJBHI.2024.3431471&partnerID=40&md5=375b8e85865e093cdda840c08aa6939d
AB  - Predicting the gene mutation status in whole slide images (WSIs) is crucial for the clinical treatment, cancer management, and research of gliomas. With advancements in CNN and Transformer algorithms, several promising models have been proposed. However, existing studies have paid little attention on fusing multi-magnification information, and the model requires processing all patches from a whole slide image. In this paper, we propose a cross-magnification attention model called CroMAM for predicting the genetic status and survival of gliomas. The CroMAM first utilizes a systematic patch extraction module to sample a subset of representative patches for downstream analysis. Next, the CroMAM applies Swin Transformer to extract local and global features from patches at different magnifications, followed by acquiring high-level features and dependencies among single-magnification patches through the application of a Vision Transformer. Subsequently, the CroMAM exchanges the integrated feature representations of different magnifications and encourage the integrated feature representations to learn the discriminative information from other magnification. Additionally, we design a cross-magnification attention analysis method to examine the effect of cross-magnification attention quantitatively and qualitatively which increases the model's explainability. To validate the performance of the model, we compare the proposed model with other multi-magnification feature fusion models on three tasks in two datasets. Extensive experiments demonstrate that the proposed model achieves state-of-the-art performance in predicting the genetic status and survival of gliomas.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Guo2024CroMAM
ER  -

TY  - JOUR
AU  - Wei, L.
AU  - Liu, Y.
AU  - Wang, F.
AU  - Wang, D.
TI  - FewVV: Few-Shot Adaptive Bitrate Volumetric Video Streaming With Prompted Online Adaptation
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 19
SP  - 32055
EP  - 32066
DO  - 10.1109/JIOT.2024.3424977
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198257753&doi=10.1109%2fJIOT.2024.3424977&partnerID=40&md5=c60c8c3d07857d23ac0acc9f4236d2df
AB  - In recent years, volumetric videos have brought immersive experiences to users. Existing viewport-based volumetric video streaming (VVS) systems prune the point cloud according to visibility to reduce bandwidth consumption, leading to a better responsiveness. They also predict bandwidth and allocate bitrate to different parts of the video to enhance Quality-of-Experience (QoE). However, such designs sometimes result in drastic quality fluctuations in real-world deployment, due to limited generalization performance. Our measurement notes that these systems tend to have a significant accuracy loss under an unseen Out-of-Distribution (OoD) environments. On the other hand, open world prediction/adaptation problem have been addressed in the recent reinforcement learning advances, particularly through prompt-based few-shot and zero-shot learning. Inspired by this development, in this work, we first reformulate the volumetric bitrate adaptation (volumetric ABR) into a sequence prediction problem, then we design a volumetric causal transformer algorithm to solve it. We train our model on a large action trajectory data set, then evaluate it on various OoD scenarios. The result show that FewVV consistently outperforms the existing systems on both performance and generalization. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wei2024FewVV
ER  -

TY  - JOUR
AU  - Zhao, H.
AU  - Yuan, R.
AU  - Zheng, W.
AU  - Zhang, Z.
AU  - Wang, C.
AU  - Li, L.
TI  - PST-Transformer: A Two-Stage Model for 3-D Driving Pose Estimation
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 19
SP  - 32272
EP  - 32283
DO  - 10.1109/JIOT.2024.3425483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198295403&doi=10.1109%2fJIOT.2024.3425483&partnerID=40&md5=d27853194ac5a683d302cf36b33ce7bf
AB  - Driver monitoring systems are becoming more common in modern cars, and they are crucial as autonomous vehicles depend on the driver's continued attention. The increasing application of the deep learning techniques in in-car driver monitoring systems can be attributed to their success in estimating the human body position. In the 3-D human posture estimation, recent transformer-based methods have demonstrated remarkable effectiveness. However, as the number of joints increases, the computing cost to generate the joint-to-joint affinity matrix grows quadratically. To this end, this research develops a pretrained spatial-temporal transformer (PST-Transformer) model to facilitate the issue. In the pretrained phase, a masking module is used to randomly mask the joints. An autoencoder is employed to rebuild the distorted 2-D poses. During the training process, a temporal downsampling approach is advised to cut down on the duplicate data. To forecast the 3-D driving poses, an aggregator is paired with the fine tuned pretrained encoder. Prior to extracting 3-D spatial and temporal characteristics, the encoder in the PST-Transformer could learn the 2-D spatial-temporal relationships. To test the suggested approach, a new driving posture data set named human driving in vehicle (HDIV) is also created, which includes a variety of driving behaviors. Extensive experiments on the HDIV and the widely used Human3.6M data set show that our technique beats the state-of-the-art methods in terms of accuracy and computing complexity.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2024PST-Transformer
ER  -

TY  - JOUR
AU  - Fu, J.
AU  - Zhou, W.
AU  - Jiang, Q.
AU  - Liu, H.
AU  - Zhai, G.
TI  - Vision-Language Consistency Guided Multi-Modal Prompt Learning for Blind AI Generated Image Quality Assessment
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 1820
EP  - 1824
DO  - 10.1109/LSP.2024.3420083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197627371&doi=10.1109%2fLSP.2024.3420083&partnerID=40&md5=2dcb4bbf25d1ad06beef02ae2c5c3f08
AB  - Recently, textual prompt tuning has shown inspirational performance in adapting Contrastive Language-Image Pre-training (CLIP) models to natural image quality assessment. However, such uni-modal prompt learning method only tunes the language branch of CLIP models. This is not enough for adapting CLIP models to AI generated image quality assessment (AGIQA) since AGIs visually differ from natural images. In addition, the consistency between AGIs and user input text prompts, which correlates with the perceptual quality of AGIs, is not investigated to guide AGIQA. In this letter, we propose vision-language consistency guided multi-modal prompt learning for blind AGIQA, dubbed CLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in language and vision branches of CLIP models, respectively. Moreover, we design a text-to-image alignment quality prediction task, whose learned vision-language consistency knowledge is used to guide the optimization of the above multi-modal prompts. Experimental results on two public AGIQA datasets demonstrate that the proposed method outperforms state-of-the-art quality assessment models. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Fu2024Vision-Language
ER  -

TY  - JOUR
AU  - An, J.
AU  - Wang, Y.
AU  - Cai, Q.
AU  - Zhao, G.
AU  - Dooper, S.
AU  - Litjens, G.
AU  - Gao, Z.
TI  - Transformer-Based Weakly Supervised Learning for Whole Slide Lung Cancer Image Classification
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 1
EP  - 14
DO  - 10.1109/JBHI.2024.3425434
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198244819&doi=10.1109%2fJBHI.2024.3425434&partnerID=40&md5=3ab1112c062573960ab86e9170318948
AB  - Image analysis can play an important role in supporting histopathological diagnoses of lung cancer, with deep learning methods already achieving remarkable results. However, due to the large scale of whole-slide images (WSIs), creating manual pixel-wise annotations from expert pathologists is expensive and time-consuming. In addition, the heterogeneity of tumors and similarities in the morphological phenotype of tumor subtypes have caused inter-observer variability in annotations, which limits optimal performance. Effective use of weak labels could potentially alleviate these issues. In this paper, we propose a two-stage transformer-based weakly supervised learning framework called Simple Shuffle-Remix Vision Transformer (SSRViT). Firstly, we introduce a Shuffle-Remix Vision Transformer (SRViT) to retrieve discriminative local tokens and extract effective representative features. Then, the token features are selected and aggregated to generate sparse representations of WSIs, which are fed into a simple transformer-based classifier (SViT) for slide-level prediction. Experimental results demonstrate that the performance of our proposed SSRViT is significantly improved compared with other state-of-the-art methods in discriminating between adenocarcinoma, pulmonary sclerosing pneumocytoma and normal lung tissue (accuracy of 96.9&#x0025; and AUC of 99.6&#x0025;). IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - An2024Transformer-Based
ER  -

TY  - JOUR
AU  - Zhu, T.
AU  - Afentakis, I.
AU  - Li, K.
AU  - Armiger, R.
AU  - Hill, N.
AU  - Oliver, N.
AU  - Georgiou, P.
TI  - Multi-Horizon Glucose Prediction Across Populations with Deep Domain Generalization
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 1
EP  - 14
DO  - 10.1109/JBHI.2024.3428921
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198734801&doi=10.1109%2fJBHI.2024.3428921&partnerID=40&md5=5f5f5e1f84c37970e4ddb13cada296ae
AB  - Real-time continuous glucose monitoring (CGM), augmented with accurate glucose prediction, offers an effective strategy for maintaining blood glucose levels within a therapeutically appropriate range. This is particularly crucial for individuals with type 1 diabetes (T1D) who require long-term self-management. However, with extensive glycemic variability, developing a prediction algorithm applicable across diverse populations remains a significant challenge. Leveraging meta-learning for domain generalization, we propose GPFormer, a Transformer-based zero-shot learning method designed for multi-horizon glucose prediction. We developed GPFormer on the REPLACE-BG dataset, comprising 226 participants with T1D, and proceeded to evaluate its performance using three external clinical datasets with CGM data. These included the OhioT1DM dataset, a publicly available dataset including 12 T1D participants, as well as two proprietary datasets. The first proprietary dataset included 22 participants, while the second contained 45 participants, encompassing a diverse group with T1D, type 2 diabetes, and those without diabetes, including patients admitted to hospitals. These four datasets include both outpatient and inpatient settings, various intervention strategies, and demographic variability, which effectively reflect real-world scenarios of CGM usage. When compared with a group of machine learning baseline methods, GPFormer consistently demonstrated superior performance and achieved the lowest root mean square error for all the evaluated datasets up to a prediction horizon of two hours. These experimental results highlight the effectiveness and generalizability of the proposed model across a variety of populations, demonstrating its substantial potential to enhance glucose management in a wide range of practical clinical settings. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhu2024Multi-Horizon
ER  -

TY  - JOUR
AU  - Azadravesh, H.
AU  - Sheibani, R.
AU  - Forghani, Y.
TI  - Predicted consumer buying behavior in neural marketing based on convolutional neural network and short-term long-term memory
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19742-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197280557&doi=10.1007%2fs11042-024-19742-3&partnerID=40&md5=5072ea436b23b980d9d489052dc942f6
AB  - Neuromarketing has received attention as a means to bridge the gap between conventional marketing studies and research on brain-computer interfaces based on electroencephalography (EEG). Through priority prediction, it aims to accurately determine customers' true desires. The performance of EEG-based priority detection systems relies on selecting appropriate feature extraction techniques and machine learning algorithms. Current methods do not focus on effective preprocessing techniques and the classification of EEG signals. In this study, preference detection of neuromarketing data is carried out using a combination of different EEG indicators and various algorithms for feature extraction and classification. EEG features are extracted using the discrete wavelet transform (DWT), which enhances the accuracy of priority detection for preference-based EEG indicators. Moreover, a one-dimensional convolutional neural network (CNN1D) in combination with a Long Short-Term Memory (LSTM) network is used. This study compares the proposed method with classifiers such as Support Vector Machines (SVM), Random Forest (RF) and CNN-Transformer. The results obtained demonstrate the high potential of the proposed model in the field of neuromarketing and its improvement over traditional marketing methods. This innovative approach allows us to more accurately identify unconscious consumer buying behaviors and gain a better understanding of their decision-making patterns in real purchasing situations. This study contributes to the field by demonstrating the effective use of EEG and machine learning to enhance neuromarketing strategies. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Azadravesh2024Predicted
ER  -

TY  - JOUR
AU  - Hu, X.
AU  - Zhang, P.
AU  - Zhang, J.
AU  - Deng, L.
TI  - DeepFusionCDR: Employing Multi-Omics Integration and Molecule-Specific Transformers for Enhanced Prediction of Cancer Drug Responses
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 10
SP  - 6248
EP  - 6258
DO  - 10.1109/JBHI.2024.3417014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197656320&doi=10.1109%2fJBHI.2024.3417014&partnerID=40&md5=c7e9b46a51335ed9129137f44f6c86ec
AB  - Deep learning approaches have demonstrated remarkable potential in predicting cancer drug responses (CDRs), using cell line and drug features. However, existing methods predominantly rely on single-omics data of cell lines, potentially overlooking the complex biological mechanisms governing cell line responses. This paper introduces DeepFusionCDR, a novel approach employing unsupervised contrastive learning to amalgamate multi-omics features, including mutation, transcriptome, methylome, and copy number variation data, from cell lines. Furthermore, we incorporate molecular SMILES-specific transformers to derive drug features from their chemical structures. The unified multi-omics and drug signatures are combined, and a multi-layer perceptron (MLP) is applied to predict IC50 values for cell line-drug pairs. Moreover, this MLP can discern whether a cell line is resistant or sensitive to a particular drug. We assessed DeepFusionCDR's performance on the GDSC dataset and juxtaposed it against cutting-edge methods, demonstrating its superior performance in regression and classification tasks. We also conducted ablation studies and case analyses to exhibit the effectiveness and versatility of our proposed approach. Our results underscore the potential of DeepFusionCDR to enhance CDR predictions by harnessing the power of multi-omics fusion and molecular-specific transformers. The prediction of DeepFusionCDR on TCGA patient data and case study highlight the practical application scenarios of DeepFusionCDR in real-world environments. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hu2024DeepFusionCDR
ER  -

TY  - JOUR
AU  - Qin, Y.
AU  - Xu, W.
AU  - Yao, Y.
AU  - Huang, X.
TI  - SAR-3DTR: A Novel Feature Hybrid Transformer Network for End-to-End 3-D Target Reconstruction From SAR Images
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 4017905
DO  - 10.1109/LGRS.2024.3421250
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197481368&doi=10.1109%2fLGRS.2024.3421250&partnerID=40&md5=8d43e9712a7d5744870120d676766808
AB  - Recovering the 3-D representation of anisotropic targets from synthetic aperture radar (SAR) images is an intractable difficulty in the field of SAR target image interpretation. Recently, deep learning-based approaches have made significant progress in classical 2-D vision tasks, such as SAR target recognition and detection. However, due to the lack of spatial and depth information in SAR images, as well as the more complex task modeling and data requirements for 3-D vision tasks, it is difficult to apply deep learning-based approaches to 3-D reconstruction from SAR images. To address these challenges, we reformulate the SAR images 3-D reconstruction as a sequence-to-sequence prediction problem and propose an end-to-end deep learning framework based on a feature hybrid Transformer network, called SAR-3DTR. The proposed method first extracts visual features from SAR image sequences. In addition, considering the unique scattering imaging properties of SAR images, we also extract and construct scattering features, which represent rich physical structure information of target by introducing a novel vector of electromagnetic scattering features (VESFs) module. Finally, Transformer network learns 3-D features and generates model prediction by exploring global correlations in visual, scattering, and 3-D spatial feature domains. Experiments conducted on the synthesized aircraft target dataset and the MSTAR ground target dataset show that our method has superior quantitative and qualitative results and reaches state-of-the-art performance on SAR 3-D reconstruction.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Qin2024SAR-3DTR
ER  -

TY  - JOUR
AU  - Dui, Y.
AU  - Hu, H.
TI  - Social Media Public Opinion Detection Using Multimodal Natural Language Processing and Attention Mechanisms
PY  - 2024
T2  - IET Information Security
VL  - 2024
IS  - 1
C7  - 8880804
DO  - 10.1049/2024/8880804
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198626972&doi=10.1049%2f2024%2f8880804&partnerID=40&md5=fcfdc306934b6b0db715f94c3b11522c
AB  - The fast dissemination speed and wide range of information dissemination on social media also enable false information and rumors to spread rapidly on public social media. Attackers can use false information to trigger public panic and disrupt social stability. Traditional multimodal sentiment analysis methods face challenges due to the suboptimal fusion of multimodal features and consequent diminution in classification accuracy. To address these issues, this study introduces a novel emotion classification model. The model solves the problem of interaction between modalities, which is neglected by the direct fusion of multimodal features, and improves the model’s ability to understand and generalize the semantics of emotions. The Transformer’s encoding layer is applied to extract sophisticated sentiment semantic encodings from audio and textual sequences. Subsequently, a complex bimodal feature interaction fusion attention mechanism is deployed to scrutinize intramodal and intermodal correlations and capture contextual dependencies. This approach enhances the model’s capacity to comprehend and extrapolate sentiment semantics. The cross-modal fused features are incorporated into the classification layer, enabling sentiment prediction. Experimental testing on the IEMOCAP dataset demonstrates that the proposed model achieves an emotion recognition classification accuracy of 78.5% and an F1-score of 77.6%. Compared to other mainstream multimodal emotion recognition methods, the proposed model shows significant improvements in all metrics. The experimental results demonstrate that the proposed method based on the Transformer and interactive attention mechanism can more fully understand the information of discourse emotion features in the network model. This research provides robust technical support for social network public sentiment security monitoring. Copyright © 2024 Yanxia Dui and Hongchun Hu.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Dui2024Social
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Wang, L.
AU  - Wu, H.
AU  - Xiao, G.
AU  - Xu, K.
TI  - Parametric Primitive Analysis of CAD Sketches With Vision Transformer
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 10
SP  - 12041
EP  - 12050
DO  - 10.1109/TII.2024.3413358
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197604727&doi=10.1109%2fTII.2024.3413358&partnerID=40&md5=b5395bb5330440e0b5778b97f8ea5a2c
AB  - The design and analysis of computer-aided design (CAD) sketches play a crucial role in industrial product design, primarily involving CAD primitives and their interprimitive constraints. To address challenges related to error accumulation in autoregressive models and the complexities associated with self-supervised model design for this task, we propose a two-stage network framework. This framework consists of a primitive network and a constraint network, transforming the sketch analysis task into a set prediction problem to enhance the effective handling of primitives and constraints. By decoupling target types from parameters, the model gains increased flexibility and optimization while reducing complexity. In addition, the constraint network incorporates a pointer module to explicitly indicate the relationship between constraint parameters and primitive indices, enhancing interpretability and performance. Qualitative and quantitative analyzes on two publicly available datasets demonstrate the superiority of this method.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2024Parametric
ER  -

TY  - JOUR
AU  - Kothala, L.P.
AU  - Guntur, S.R.
TI  - GEL-TTA Net: a Global ensemble learning network for the localization of small-scale and mixed intracranial hemorrhages through test time augmentations
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19393-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195374388&doi=10.1007%2fs11042-024-19393-4&partnerID=40&md5=c1061140970b1d606e4848f295eb5b1c
AB  - State-of-the-art deep learning models can accurately perform multi-class classification of intracranial hemorrhages (ICH). However, two main challenges such as the localization of multiple hemorrhages and the visualization of small-scale or subtle hemorrhages have not been addressed yet. This study proposed an optimal object detection framework to solve both issues. First, a YOLOv5l architecture was used as model 1 to localize multiple hemorrhages. Second, a vision transformer (ViT) based on multi-head-self-attention (MHSA) was used in YOLOv5x as model 2 to visualize small-scale ICH. The main advantage of the transformer module is that it performs dense prediction task using a queue, key, and value information. To achieve both objectives in a single network, the two proposed models were ensembled using a non-max-suppression (NMS) algorithm. Furthermore, a concept known as test time augmentations (TTA) was used in the proposed (GEL-TTA Net) model to promote the test time results. To improve the quality of predictions in the proposed model, we pooled the feature maps at various scales in the YOLO backbone using a spatial pyramid pooling-faster module (SPPF), whereas a path-aggregated network (PANet) was used as a neck to hold the spatial information. The proposed model was trained and validated using the brain hemorrhage extended (BHX) dataset, and testing was conducted using separate segmentation data. The experimental result shows that the proposed model outperformed by existing model (YOLOv4) in terms of precision by 1.6%, recall by 12.4%, F1 score by 7.5%, and mean average precision (mAP@.5) by 16%. The proposed model achieved an overall precision, recall, F1 score, and mAP@.5 of 93.6%, 93.4%, 93.5%, and 95.6%, respectively, during training and 85.7%, 84.9%, 85.3%, and 90.3% during validation. The results of GEL-TTA Net were outperformed in the validation and testing phases, but the only limitation was that the prediction time increased. The code is publicly available at https://github.com/ionedatasolutions/GEL-TTA-Net.git © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Kothala2024GEL-TTA
ER  -

TY  - JOUR
AU  - Burukanli, M.
AU  - Yumuşak, N.
TI  - TfrAdmCov: a robust transformer encoder based model with Adam optimizer algorithm for COVID-19 mutation prediction
PY  - 2024
T2  - Connection Science
VL  - 36
IS  - 1
C7  - 2365334
DO  - 10.1080/09540091.2024.2365334
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196093371&doi=10.1080%2f09540091.2024.2365334&partnerID=40&md5=8fa4f467a5a2b6082e3db86d7037bcf2
AB  - The development of vaccines and drugs is very important in combating the coronavirus disease 2019 (COVID-19) virus. The effectiveness of these developed vaccines and drugs has decreased as a result of the mutation of the COVID-19 virus. Therefore, it is very important to combat COVID-19 mutations. The majority of studies published in the literature are studies other than COVID-19 mutation prediction. We focused on this gap in this study. This study proposes a robust transformer encoder based model with Adam optimizer algorithm called TfrAdmCov for COVID-19 mutation prediction. Our main motivation is to predict the mutations occurring in the COVID-19 virus using the proposed TfrAdmCov model. The experimental results have shown that the proposed TfrAdmCov model outperforms both baseline models and several state-of-the-art models. The proposed TfrAdmCov model reached accuracy of 99.93%, precision of 100.00%, recall of 97.38%, f1-score of 98.67% and MCC of 98.65% on the COVID-19 testing dataset. Moreover, to evaluate the performance of the proposed TfrAdmCov model, we carried out mutation prediction on the influenza A/H3N2 HA dataset. The results obtained are promising for the development of vaccines and drugs. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Burukanli2024TfrAdmCov
ER  -

TY  - JOUR
AU  - Tariq, S.
AU  - Arfeto, B.E.
AU  - Khalid, U.
AU  - Kim, S.
AU  - Duong, T.Q.
AU  - Shin, H.
TI  - Deep Quantum-Transformer Networks for Multimodal Beam Prediction in ISAC Systems
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 18
SP  - 29387
EP  - 29401
DO  - 10.1109/JIOT.2024.3420455
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197078914&doi=10.1109%2fJIOT.2024.3420455&partnerID=40&md5=98b633e6a6ef50edfc2c3575a280d1a4
AB  - In this article, we propose hybrid deep quantum-transformer networks (QTNs) to predict the optimal beam in integrated sensing and communication (ISAC) systems employing millimeter-wave (mmWave) band. In mobile applications, vehicle-to-infrastructure (V2I) communications at high frequency require large antenna arrays and narrow beams, which is associated with high-beam training overhead. In such a scenario, selecting an optimal beam to maximize the signal power at the receiver can be learned from the sensory data collected at the base station and guided by the position-based data provided by the user equipment. Such multimodal sensory data can be utilized by deep learning frameworks to create situational awareness for intelligently predicting optimal beams. We evaluate the proposed learning models in real-world V2I scenarios provided by the multimodal deepsense sixth generation data set and compare them with the existing works. The experimental results show a distance-based accuracy (DBA) score of 0.9124 for multimodal and 0.8832 for position-based data, respectively. Moreover, the hybrid QTN achieve the best DBA scores and the highest accuracy compared to other models on zero-shot testing. These QTN models exhibit low complexity and high performance, demonstrating their potential to address the challenges of beam management in mmWave ISAC systems.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Tariq2024Deep
ER  -

TY  - JOUR
AU  - Wang, G.
AU  - Zhao, H.
AU  - Chang, Q.
AU  - Lyu, S.
AU  - Cheng, G.
AU  - Chen, H.
TI  - WEA-DINO: An Improved DINO with Word Embedding Alignment for Remote Scene Zero-Shot Object Detection
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 6011005
DO  - 10.1109/LGRS.2024.3408875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195381229&doi=10.1109%2fLGRS.2024.3408875&partnerID=40&md5=4e4c81b91e2ef5c6cafe88872c661fc3
AB  - Remote sensing scene zero-shot object detection (ZSD) aims to detect and recognize both seen and unseen categories of landscape elements with the guidance of the word embeddings. In this task, two primary challenges are identified. First, there exists considerable variability within categories of landscape elements, causing a misalignment between visual features and word embeddings, particularly noticeable for unseen categories. Second, the existing detection models struggle to provide accurate localization predictions, greatly impacting overall performance. To address these two issues, we propose word embedding alignment-DINO (WEA-DINO). Based on the original DINO structure, our WEA-DINO-Head is specifically designed to align the hidden features of 'matching queries' with word embedding features, effectively addressing the misalignment issue between visual features and word embeddings. Furthermore, aligning the hidden features of 'denoising queries' with word embedding features enables the translation of localization capabilities from known categories to previously unseen ones. Through extensive experimentation on the DIOR benchmark dataset, our method demonstrates state-of-the-art (SOTA) performance. The code is available at https://github.com/cv516Buaa/WEA-DINO.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024WEA-DINO
ER  -

TY  - JOUR
AU  - Zhang, Q.
AU  - Wang, P.
AU  - Wu, Z.
AU  - Yang, B.
AU  - Yuan, J.
TI  - ABC-Trans: a novel adaptive border-augmented cross-attention transformer for object detection
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19405-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196674941&doi=10.1007%2fs11042-024-19405-3&partnerID=40&md5=8b11a90fa15637372c0cc429f3991323
AB  - Transformer-based vision object detection has demonstrated superior performance due to its effective removal of the need for many hand-designed components like anchor generation or a non-maximum suppression procedure. This paper presents a novel Adaptive Border-augmented Cross-attention Transformer (ABC-Trans) for vision-based object detection. By integrating the classic DETR and Deformable DETR, we design an adaptive cross-attention module to simultaneously perform global and local point sampling strategies to generate fusion features according to an estimated weight, well-capturing representative features for both small and large objects. On this basis, we further introduce a border-augmented cross-attention module to incorporate notable border features for object detection. Border features could well represent objects as well as distinguish from them backgrounds, thereby helping our model to accurately predict objects. Extensive experiments are conducted on MSCOCO and Pascal VOC datasets, and the results demonstrate the effectiveness of the proposed components, achieving promising performance as compared to the classic transformer-based detection approaches. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2024ABC-Trans
ER  -

TY  - JOUR
AU  - C, N.
AU  - M, B.
TI  - Attention enabled viewport selection with graph convolution for omnidirectional visual quality assessment
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19457-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195302094&doi=10.1007%2fs11042-024-19457-5&partnerID=40&md5=84df9cb2f8b68972aad4868b242adeac
AB  - Omnidirectional images provide an immersive viewing experience in a Virtual Reality (VR) environment, surpassing the limitations of traditional 2D media beyond the conventional screen. This VR technology allows users to interact with visual information in an exciting and engaging manner. However, the storage and transmission requirements for 360-degree panoramic images are substantial, leading to the establishment of compression frameworks. Unfortunately, these frameworks introduce projection distortion and compression artifacts. With the rapid growth of VR applications, it becomes crucial to investigate the quality of the perceptible omnidirectional experience and evaluate the extent of visual degradation caused by compression. In this regard, viewport plays a significant role in omnidirectional image quality assessment (OIQA), as it directly affects the user’s perceived quality and overall viewing experience. Extracting viewports compatible with users viewing behavior plays a crucial role in OIQA. Different users may focus on different regions, and the model’s performance may be sensitive to the chosen viewport extraction strategy. Improper selection of viewports could lead to biased quality predictions. Instead of assessing the entire image, attention can be directed to areas that are more importance to the overall quality. Feature extraction is vital in OIQA as it plays a significant role in representing image content that aligns with human perception. Taking this into consideration, the proposed ATtention enabled VIewport Selection (ATVIS-OIQA) employs attention based view port selection with Vision Transformers(ViT) for feature extraction. Furthermore, the spatial relationship between the viewports is established using graph convolution, enabling intuitive prediction of the objective visual quality of omnidirectional images. The effectiveness of the proposed model is demonstrated by achieving state-of-the-art results on publicly available benchmark datasets, namely OIQA and CVIQD. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - C2024Attention
ER  -

TY  - JOUR
AU  - Kong, X.
AU  - Chen, Z.
AU  - Li, J.
AU  - Bi, J.
AU  - Shen, G.
TI  - KGNext: Knowledge-Graph-Enhanced Transformer for Next POI Recommendation with Uncertain Check-Ins
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 5
SP  - 6637
EP  - 6648
DO  - 10.1109/TCSS.2024.3396506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194897061&doi=10.1109%2fTCSS.2024.3396506&partnerID=40&md5=53ad62762b2f4b2f101e83e3f12322f8
AB  - The next point-of-interest (POI) recommendation aims to predict users' future movements based on their historical trajectories. However, in reality, users may provide uncertain check-in records, resulting in uploaded data that lack precise location information and is instead ambiguous. Despite this challenge, only a limited number of studies have addressed this issue, often overlooking the intricate interactions among users, POIs, and POI categories. To that end, we propose a novel model called knowledge-graph-enhanced transformer (KGNext). KGNext leverages transition and interaction graphs derived from our constructed transitional-interactive knowledge graph (TIKG) to uncover both general movement patterns and varied user preferences regarding POIs and POI categories. Furthermore, KGNext integrates comprehensive contextual information from historical trajectories with TIKG to generate user trajectory embeddings. These encoded features are then utilized by a transformer model to provide fine-grained predictions of the next POI. Experimental results on three real-world datasets demonstrate the superiority of KGNext.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Kong2024KGNext
ER  -

TY  - JOUR
AU  - Zhao, F.
AU  - Song, X.
AU  - Zhang, J.
AU  - Liu, H.
TI  - Semi-Supervised Co-Training Model Using Convolution and Transformer for Hyperspectral Image Classification
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 5506705
DO  - 10.1109/LGRS.2024.3409351
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195400283&doi=10.1109%2fLGRS.2024.3409351&partnerID=40&md5=9fb21c8866dc9992bbbc33f06d48151b
AB  - Deep learning algorithms have shown significant advantages in hyperspectral image (HSI) classification. However, these algorithms usually require a large number of labeled samples and the annotation of these samples consumes massive time and resource costs. To achieve effective classification results in situations with small samples, a semi-supervised co-training model using convolution and transformer (SCM-CT) is proposed. First, two different networks, namely, multiscale parallel convolutional neural network (MPCNN) and global and local transformer fusion network (GLTFN), are designed as co-training learners to extract multiscale spectral-spatial features and global-local combined features in HSIs, respectively. Second, to ensure that two learners generate reliable predictions and utilize more unlabeled samples with low-confidence pseudo-labels, a self-adaptive threshold and conflict pseudo-labeling (SATCP) strategy is proposed to facilitate the model to learn more valuable spectral-spatial information from conflict predictions and improve the convergence speed and model performance. Finally, to prevent the learners from stepping into the collapse, the discrepancy loss is computed to reduce the similarity between the features extracted by the two learners, forcing them to learn different information from the same input. The experimental results on University of Pavia, Salinas Valley, and Houston 2013 datasets show that SCM-CT achieves overall accuracies of 97.42%, 95.60%, and 95.20%, respectively, outperforming the state-of-the-art methods.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhao2024Semi-Supervised
ER  -

TY  - JOUR
AU  - Liang, A.
AU  - Chai, X.
AU  - Sun, Y.
AU  - Guizani, M.
TI  - GTformer: Graph-Based Temporal-Order-Aware Transformer for Long-Term Series Forecasting
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 19
SP  - 31467
EP  - 31478
DO  - 10.1109/JIOT.2024.3419768
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197085861&doi=10.1109%2fJIOT.2024.3419768&partnerID=40&md5=46b4f33b53e2c5f1ebaf598d95371bd0
AB  - In the production environment of the Internet of Things (IoT), sensors of various qualities generate a large amount of multivariate time series (MTS) data. The long-term prediction of time series data generated by various IoT devices provides longer foresight and helps execute necessary resource scheduling or fault alarms in advance, thus improving the efficiency of system operation and ensuring system security. In recent years, deep learning models like Transformers have achieved advanced performance in multivariate long-term time series forecasting (MLTSF) tasks. However, many previous research attempts either overlooked the interseries dependencies or ignored the need to model the strict temporal order of MTS data. In this article, we introduce GTformer, a graph-based temporal-order-aware transformer model. We propose an adaptive graph learning method specifically designed for MTS data to capture both uni-directional and bi-directional relations. In addition, we generate positional encoding in a sequential way to emphasize the strict temporal order of time series. By adopting these two components, our model can have a better understanding of the interseries and intraseries dependencies of MTS data. We conducted extensive experiments on eight real-world data sets, and the results show that our model achieves better predictions compared with state-of-the-art methods. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Liang2024GTformer
ER  -

TY  - JOUR
AU  - Wu, D.
AU  - Li, S.
AU  - Yang, J.
AU  - Sawan, M.
TI  - Neuro-BERT: Rethinking Masked Autoencoding for Self-Supervised Neurological Pretraining
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 1
EP  - 11
DO  - 10.1109/JBHI.2024.3415959
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196719630&doi=10.1109%2fJBHI.2024.3415959&partnerID=40&md5=c6a4cfcd2b280c54730750ce2d1fdf9b
AB  - Deep learning associated with neurological signals is poised to drive major advancements in diverse fields such as medical diagnostics, neurorehabilitation, and brain-computer interfaces. The challenge in harnessing the full potential of these signals lies in the dependency on extensive, high-quality annotated data, which is often scarce and expensive to acquire, requiring specialized infrastructure and domain expertise. To address the appetite for data in deep learning, we present <bold>Neuro-BERT</bold>, a self-supervised pre-training framework of neurological signals based on masked autoencoding in the Fourier domain. The intuition behind our approach is simple: frequency and phase distribution of neurological signals can reveal intricate neurological activities. We propose a novel pre-training task dubbed <bold>Fourier Inversion Prediction (FIP)</bold>, which randomly masks out a portion of the input signal and then predicts the missing information using the Fourier inversion theorem. Pre-trained models can be potentially used for various downstream tasks such as sleep stage classification and gesture recognition. Unlike contrastive-based methods, which strongly rely on carefully hand-crafted augmentations and siamese structure, our approach works reasonably well with a simple transformer encoder with no augmentation requirements. By evaluating our method on several benchmark datasets, we show that <bold>Neuro-BERT</bold> improves downstream neurological-related tasks by a large margin. Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wu2024Neuro-BERT
ER  -

TY  - JOUR
AU  - Zhao, Q.
AU  - Fan, X.
AU  - Chen, M.
AU  - Xiao, Y.
AU  - Wang, X.
AU  - Yeung, E.H.K.
AU  - Tsui, K.L.
AU  - Zhao, Y.
TI  - MSS-Former: Multiscale Skeletal Transformer for Intelligent Fall Risk Prediction in Older Adults
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 20
SP  - 33040
EP  - 33052
DO  - 10.1109/JIOT.2024.3420789
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197060609&doi=10.1109%2fJIOT.2024.3420789&partnerID=40&md5=2532437ace7636a48b8daa87755fcb45
AB  - Fall, a leading cause of accidental death and injury in older adults aged 65 and above, has become a rapidly growing health concern in aging populations worldwide. Data-driven methods integrating depth imaging technology have received growing attention in automated fall risk assessment owing to their noninvasiveness and less dependence on healthcare professionals. However, most existing depth image data-based models neglect the inherent physiological and potential functional connections and lack sufficient real-world data validation. To fill the research gap, we developed a novel approach named multiscale skeletal transformer (MSS-Former), leveraging depth image technology and deep-learning models for effective fall risk prediction. Our contributions mainly consist of four parts. First, we introduced a multimodel output feature fusion transformer in fall risk prediction, enabling output merging and weighting from multiple model streams dynamically. Second, we developed an innovative scheme to construct interjoint skeletal topology, systematically focusing on joints' intrinsic physiological and potential functional connections. Third, we constructed a ResNet-FPN, greatly enhancing multiscale feature extraction capabilities. Fourth, we conducted a field study in a local hospital and performed a comprehensive validation of our developed approach. The comparison results show that our approach achieved outstanding predictive performance, surpassing state-of-the-art methods on the real-world data set, with accuracy, precision, recall, and F1 scores of 97.84%, 97.33%, 96.97%, and 96.92%, respectively. In practice, the proposed approach would be of great value in the timely identification for individuals at high fall risk and facilitate decision making to take appropriate interventions.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2024MSS-Former
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Liu, X.
AU  - Wang, H.
AU  - Zhang, Z.
AU  - Chen, T.
AU  - Fu, X.
AU  - Liu, G.
TI  - Seeing Through the Mask: Recognition of Genuine Emotion Through Masked Facial Expression
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 6
SP  - 7159
EP  - 7172
DO  - 10.1109/TCSS.2024.3404611
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196120575&doi=10.1109%2fTCSS.2024.3404611&partnerID=40&md5=d5ff578f3f8f5817b444859ee574cc29
AB  - The purpose of facial expression recognition is to recognize the corresponding emotions. However, people tend to hide their emotions by displaying facial expressions that differ from those evoked by emotions. These inconsistent facial expressions are referred to as masked facial expressions (MFEs). The automatic recognition of hidden emotions within an MFE using image data is challenging. In this study, we find distinctive movement patterns in the facial action units (AUs) of MFE sequences through a detailed analysis. Considering our findings, we propose handcrafted features called dynamic AU intensity features (DAIFs) to represent AU movement. Furthermore, we develop a decoupled AU transformer (DAUT) model for recognition, where the decoupled convolution operators ensure that the temporal information in the DAIF is not damaged. To further improve the recognition performance, we design self-supervised clip prediction for pretraining of DAUT. Experimental results demonstrate that our proposed method performs exceptionally well across all tasks in the MFE dataset, particularly improving accuracy by nearly double on the most challenging 36-class task. This suggests that leveraging temporal information from facial AU movements is a reliable and effective technique for recognizing MFEs. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhou2024Seeing
ER  -

TY  - JOUR
AU  - Tan, R.
AU  - Sun, M.
AU  - Liang, Y.
TI  - Transformer-based multi-level attention integration network for video saliency prediction
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19404-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194479902&doi=10.1007%2fs11042-024-19404-4&partnerID=40&md5=bcdf5664ec49c9c12a9a3810dd21c4e0
AB  - Most existing models for video saliency prediction heavily rely on 3D convolutional operations to extract spatio-temporal features. However, it is worth noting that 3D convolution produces a local receptive field, which may struggle to capture long-range spatio-temporal dependencies effectively. To compensate for such shortage, this paper introduces a novel approach called the Transformer-based Multi-level Attention Integration Network (TMAI-Net) for video saliency prediction. TMAI-Net is designed as a two-stream encoder-decoder model, carefully integrating multi-level features of semantic information. Our model incorporates a Multi-level Interactive Attention(MLIA) module and a Transformer, both implemented based on self-attention mechanism, which are placed at different levels of the model to capture long-range spatio-temporal feature dependencies. Additionally, our model operates on input video frames and attentional patches, allowing the Transformer module to capture structural similarities between related objects in global features and attention features. This, in turn, enables the model to allocate increased attention to salient areas. The efficacy of our proposed approach is validated through extensive experiments conducted on three widely recognized benchmark datasets. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Tan2024Transformer-based
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Liu, J.
AU  - Wang, C.
AU  - Xie, X.
AU  - Shi, G.
TI  - Graph Transformer and LSTM Attention for VNF Multi-Step Workload Prediction in SFC
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
VL  - 21
IS  - 4
SP  - 4480
EP  - 4493
DO  - 10.1109/TNSM.2024.3403714
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194033704&doi=10.1109%2fTNSM.2024.3403714&partnerID=40&md5=689ce84e6ac269917976e37712e4f5ca
AB  - The knowledge on a Service Function Chain's (SFC's) resource requirements is an indispensable prerequisite for proactive resource provisioning and run-time management of the SFC. However, due to the intrinsic dynamics in network environment, accurate resource requirements and workloads prediction for the Virtual Network Functions (VNFs) of a SFC, especially in a large time scale, is a non-trivial challenge. In the literature, existing works largely neglect the application-level relationship of VNFs in improving prediction accuracy, and few work investigates the multi-step prediction. In this work, we propose a deep-learning-based multi-step prediction model for accurate workload prediction for SFC VNFs in a dynamic network environment. We first demonstrate that predictability can be improved by taking into account application-level dependency by calculating the spatial conditional entropy of adjacent VNFs workloads. Then, the prediction model, named Graph Transformer Networks and sequence-to-sequence LSTM with Attention (GTN-LA) is introduced, which utilizes the Graph Transformer as the encoder to capture the application-level dependencies among VNFs, and the LSTM with attention as the decoder to extract the temporal dependencies within the time varying load information. Finally, GTN-LA is validated through intensive evaluation with a real SFC workload dataset by comparing towards several baselines.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wu2024Graph
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Hu, Z.
AU  - Lin, R.
AU  - Zhu, X.
AU  - Chen, X.
TI  - Direction-Aware and Foreground-Guided Remote Sensing Road Detection
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 6008405
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3397702
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192978459&doi=10.1109%2fLGRS.2024.3397702&partnerID=40&md5=be9f775356e0825b7cdd0d558a6b4a13
AB  - Road detection in remote sensing images holds significant application value in urban planning and autonomous driving. However, due to the complex background and the strip-like distribution of roads, road detection remains a challenging task. In this letter, we propose an innovative method for remote sensing road detection called direction-aware and foreground-guided (DAFG). First, direction-aware trans bridge (DATB) is formulated, which uses a dual-branch structure encompassing vertical and horizontal dimensions to capture the global-local context, effectively mitigating interference from nonroad area features. Next, foreground guidance module (FGM) is constructed, with the help of prediction maps derived from high-level semantic features, enhancing the encoding of low-level road features and suppressing background and noise. Finally, a dense aggregation module (DAM) is introduced to enhance feature representation and augment the capacity of classic decoding blocks (several cascaded convolutions). Experiments show that DAFG achieves higher intersection over union (IoU) than other methods on the Munich Road dataset (89.22%) and the WHU Road dataset (70.78%).  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2024Direction-Aware
ER  -

TY  - JOUR
AU  - Wang, M.
AU  - Qin, Y.
AU  - Li, R.
AU  - Liu, Z.
AU  - Tang, Z.
AU  - Li, K.
TI  - AWDepth: Monocular Depth Estimation for Adverse Weather via Masked Encoding
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 9
SP  - 10873
EP  - 10882
DO  - 10.1109/TII.2024.3397355
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194058492&doi=10.1109%2fTII.2024.3397355&partnerID=40&md5=cc1a337ecfa8a99209899f6fe2da5127
AB  - Monocular depth estimation has made considerable advances under clear weather conditions. However, how to learn accurate scene depth under rain and fog conditions and alleviate the negative influence of occlusion, light, visibility, etc., is an open problem. To address this problem, in this article, we split the adverse weather depth estimation network into two subbranches: the depth prediction branch and the masked encoding branch. The depth prediction branch is used for depth estimation. The masked encoding branch, inspired by masked image modeling, uses random masks to simulate occlusion or low visibility often seen in rain and fog, forcing this branch to learn to infer the prediction of masked regions from the context. In order to make the masked encoding better enhance the depth prediction, we designed the mask feature fusion module, which can fuse the depth and spatial context features of the two branches to produce a fine-level depth map. The experimental results on the Foggy Cityscapes and RainCityscapes datasets demonstrate that our method achieves state-of-the-art performance, significantly outperforming previous methods across all evaluation metrics. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2024AWDepth
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Lu, Y.
AU  - Long, S.
AU  - Campello, V.M.
AU  - Bai, J.
AU  - Lekadir, K.
TI  - Fetal Head and Pubic Symphysis Segmentation in Intrapartum Ultrasound Image Using a Dual-Path Boundary-Guided Residual Network
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 8
SP  - 4648
EP  - 4659
DO  - 10.1109/JBHI.2024.3399762
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193269199&doi=10.1109%2fJBHI.2024.3399762&partnerID=40&md5=1af476e398a01f9b83efb794fad9027f
AB  - —Accurate segmentation of the fetal head and pubic symphysis in intrapartum ultrasound images and measurement of fetal angle of progression (AoP) are critical to both outcome prediction and complication prevention in delivery. However, due to poor quality of perinatal ultrasound imaging with blurred target boundaries and the relatively small target of the public symphysis, fully automated and accurate segmentation remains challenging. In this paper, we propse a dual-path boundary-guided residual network (DBRN), which is a novel approach to tackle these challenges. The model contains a multi-scale weighted module (MWM) to gather global context information, and enhance the feature response within the target region by weighting the feature map. The model also incorporates an enhanced boundary module (EBM) to obtain more precise boundary information. Furthermore, the model introduces a boundary-guided dual-attention residual module (BDRM) for residual learning. BDRM leverages boundary information as prior knowledge and employs spatial attention to simultaneously focus on background and foreground information, in order to capture concealed details and improve segmentation accuracy. Extensive comparative experiments have been conducted on three datasets. The proposed method achieves average Dice score of 0.908±0.05 and average Hausdorff distance of 3.396±0.66 mm. Compared with state-of-the-art competitors, the proposed DBRN achieves better results. In addition, the average difference between the automatic measurement of AoPs based on this model and the manual measurement results is 6.157◦, which has good consistency and has broad application prospects in clinical practice. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Chen2024Fetal
ER  -

TY  - JOUR
AU  - Fan, J.
AU  - Zhuang, W.
AU  - Xia, M.
AU  - Fang, W.
AU  - Liu, J.
TI  - Optimizing Attention in a Transformer for Multihorizon, Multienergy Load Forecasting in Integrated Energy Systems
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 8
SP  - 10238
EP  - 10248
DO  - 10.1109/TII.2024.3392278
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192994835&doi=10.1109%2fTII.2024.3392278&partnerID=40&md5=9c2dc4d09e25cc6bbff00f1e3315543d
AB  - Accurate forecasting of multienergy loads is essential for designing, operating, scheduling, and managing integrated energy systems (IESs). Recent research suggests that transformer models have the potential to improve long-sequence predictions. However, existing transformer models often emphasize capturing temporal dependencies while neglecting crucial dependencies among different variables necessary for multienergy load forecasting. Moreover, transformer models encounter challenges related to quadratic time complexity and significant memory usage, which hinder their direct applicability to tasks involving long-sequence, multienergy load forecasting. To tackle these challenges, we propose a model called DTformer and apply it to the task of multihorizon, multienergy load forecasting in IES. Within DTformer, we employ patch embedding to convert the input multienergy load sequences into a 3-D vector array, preserving both temporal and variable information. Subsequently, we propose the temporal top windowed attention (TWA) module and the dual variable attention module to handle extended temporal dependencies and intervariable dependencies. Importantly, the computational complexity and memory requirements of the TWA model are regulated at a level of O(N_43). Through extensive experimentation, we found that our DTformer surpasses baseline models in terms of performance using the IES dataset sourced from Arizona State University's Tempe campus.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Fan2024Optimizing
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Liu, T.
AU  - Feng, F.
AU  - Yu, S.
AU  - Wang, H.
AU  - Sun, Y.
TI  - BTSSPro: Prompt-Guided Multimodal Co-Learning for Breast Cancer Tumor Segmentation and Survival Prediction
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 12
SP  - 7322
EP  - 7331
DO  - 10.1109/JBHI.2024.3407772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194826650&doi=10.1109%2fJBHI.2024.3407772&partnerID=40&md5=949bce76af16bf8281da87a3f2a3c39b
AB  - Early detection significantly enhances patients' survival rates by identifying tumors in their initial stages through medical imaging. However, prevailing methodologies encounter challenges in extracting comprehensive information from diverse modalities, thereby exacerbating semantic disparities and overlooking critical task correlations, consequently compromising the accuracy of prognosis predictions. Moreover, clinical insights emphasize the advantageous sharing of parameters between tumor segmentation and survival prediction for enhanced prognostic accuracy. This paper proposes a novel model, BTSSPro, designed to concurrently address Breast cancer Tumor Segmentation and Survival prediction through a Prompt-guided multi-modal co-learning framework. Technologically, our approach involves the extraction of tumor-specific discriminative features utilizing shared dual attention (SDA) blocks, which amalgamate spatial and channel information from breast MR images. Subsequently, we employ a guided fusion module (GFM) to seamlessly integrate the Electronic Health Record (EHR) vector into the extracted tumor-related discriminative feature representations. This integration prompts the model's feature selection to align more closely with real-world scenarios. Finally, a feature harmonic unit (FHU) is introduced to coordinate the transformer encoder and CNN decoder, thus reducing semantic differences. Remarkably, BTSSPro achieved a C-index of 0.968 and Dice score of 0.715 on the Breast MRI-NACT-Pilot dataset and a C-index of 0.807 and Dice score of 0.791 on the ISPY1 dataset, surpassing the previous state-of-the-art methods.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2024BTSSPro
ER  -

TY  - JOUR
AU  - Han, W.
AU  - Zhu, T.
AU  - Chen, L.
AU  - Ning, H.
AU  - Luo, Y.
AU  - Wan, Y.
TI  - MCformer: Multivariate Time Series Forecasting with Mixed-Channels Transformer
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 17
SP  - 28320
EP  - 28329
DO  - 10.1109/JIOT.2024.3401697
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193478923&doi=10.1109%2fJIOT.2024.3401697&partnerID=40&md5=039304f1d0ad0a4ceee4c92b7baa845b
AB  - The massive generation of time-series data by large-scale Internet of Things (IoT) devices necessitates the exploration of more effective models for multivariate time-series forecasting. In previous models, there was a predominant use of the channel dependence (CD) strategy (where each channel represents a univariate sequence). Current state-of-the-art (SOTA) models primarily rely on the channel independence (CI) strategy. The CI strategy treats channel multichannel series as separate single-channel series, expanding the data set to improve generalization performance and avoiding interchannel correlation that disrupts long-term features. However, the CI strategy faces the challenge of interchannel correlation forgetting. To address this issue, we propose an innovative Mixed Channels strategy, combining the data expansion advantages of the CI strategy with the ability to mitigate interchannel correlation forgetting. Based on this strategy, we introduce MCformer, a multivariate time-series forecasting model with mixed channel features. The model blends a specific number of channels, leveraging an attention mechanism to effectively capture interchannel correlation information when modeling long-term features. Experimental results demonstrate that the Mixed Channels strategy outperforms pure CI strategy in multivariate time-series forecasting tasks.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Han2024MCformer
ER  -

TY  - JOUR
AU  - Cheng, J.
AU  - Zhang, Y.
AU  - Zhang, H.
AU  - Ji, S.
AU  - Lu, M.
TI  - TransFOL: A Logical Query Model for Complex Relational Reasoning in Drug-Drug Interaction
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 8
SP  - 4975
EP  - 4985
DO  - 10.1109/JBHI.2024.3401035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193275875&doi=10.1109%2fJBHI.2024.3401035&partnerID=40&md5=337e3720ad400a53d5e769bb490be792
AB  - —Predicting drug-drug interaction (DDI) plays a crucial role in drug recommendation and discovery. However, wet lab methods are prohibitively expensive and time-consuming due to drug interactions. In recent years, deep learning methods have gained widespread use in drug reasoning. Although these methods have demonstrated effectiveness, they can only predict the interaction between a drug pair and do not contain any other information. However, DDI is greatly affected by various other biomedical factors (such as the dose of the drug). As a result, it is challenging to apply them to more complex and meaningful reasoning tasks. Therefore, this study regards DDI as a link prediction problem on knowledge graphs and proposes a DDI prediction model based on Cross-Transformer and Graph Convolutional Networks (GCNs) in first-order logical query form, TransFOL. In the model, a biomedical query graph is first built to learn the embedding representation. Subsequently, an enhancement module is designed to aggregate the semantics of entities and relations. Cross-Transformer is used for encoding to obtain semantic information between nodes, and GCN is used to gather neighbour information further and predict inference results. To evaluate the performance of TransFOL on common DDI tasks, we conduct experiments on two benchmark datasets. The experimental results indicate that our model outperforms state-of-the-art methods on traditional DDI tasks. Additionally, we introduce different biomedical information in the other two experiments to make the settings more realistic. Experimental results verify the strong drug reasoning ability and generalization of TransFOL in complex settings. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cheng2024TransFOL
ER  -

TY  - JOUR
AU  - Jam, Z.
AU  - Albadvi, A.
AU  - Atashi, A.
TI  - Deep learning application in diagnosing breast cancer recurrence
PY  - 2024
T2  - Multimedia Tools and Applications
DO  - 10.1007/s11042-024-19423-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194767655&doi=10.1007%2fs11042-024-19423-1&partnerID=40&md5=53476aa04d9de4c7677f65b2e87118fc
AB  - Patients' lives can always be saved when diseases, especially special diseases, are detected early. The chances of a patient surviving can be increased by early detection. Breast cancer is one of the deadliest and common cancers. After recovering from breast cancer, patients are always worried about recurrence and return. The use of modern technology, however, can help predict disease recurrence at an early stage, allowing patients to receive treatment sooner. Significant strides have been achieved in deep learning, demonstrating strong performance in handling unstructured data challenges. However, when it comes to predicting tabular data, deep learning hasn't quite matched its success with unstructured data. Presently, ensemble models relying on gradient-boosted decision trees (GBDT) are frequently favored for tabular data prediction tasks. Typically, these GBDT-based models outshine deep learning approaches. Many novel deep learning techniques are emerging for handling tabular data. TabNet, for instance, mirrors decision tree feature selection within a neural network framework. AutoInt addresses high dimensionality by condensing data through embedding layers. Tab Transformer adapts the transformer model, generating text representations for categorical attributes. Despite their innovation, these methods remain less recognized compared to those for image and text data processing. In this study, 158 different characteristics of 5142 breast cancer patients from 1997 to 2019 were examined. We aim to evaluate deep learning techniques effectiveness in detecting breast cancer recurrence. Through examination of evaluation metrics, it becomes evident that deep learning approaches applied to tabular data surpass traditional machine learning algorithms, even when dealing with imbalanced datasets. Ultimately, the results derived from each algorithm analyzed and concluded with a review and comparison of the findings. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Jam2024Deep
ER  -

TY  - JOUR
AU  - Pan, C.
AU  - Zhang, C.
AU  - Ngai, E.C.H.
AU  - Liu, J.
AU  - Li, B.
TI  - HALO: HVAC Load Forecasting with Industrial IoT and Local-Global-Scale Transformer
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 17
SP  - 28307
EP  - 28319
DO  - 10.1109/JIOT.2024.3401236
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193221173&doi=10.1109%2fJIOT.2024.3401236&partnerID=40&md5=7515d4a3a60d3f923da3cb5f845ace0f
AB  - The evolution of Internet of Things (IoT) is fostering the use of intelligent controls for energy conservation. Yet, the efficacy of these strategies is largely tied to diverse load forecasting algorithms. Given the significant contribution of heating, ventilation, and air-conditioning (HVAC) systems to global energy consumption, accurate forecasting of HVAC power usage is crucial for improving overall energy efficiency. However, real-world HVAC load forecasting, bolstered by various IoT devices, is complicated by multiple factors: data variability, power load fluctuations, electronic phenomena (e.g., zero drifts), and the increased time complexity and larger model sizes required to manage accumulating historical data. To address these challenges, we first present an in-depth measurement study on the characteristics of HVAC load at a minute scale based on the HVAC data collected in six locations. We propose HALO, a transformer-based framework specifically designed for forecasting HVAC load. HALO incorporates an adaptive data preprocessing stage and a local-global-scale transformer-based load forecasting stage, enabling precise forecasting of HVAC load and optimization of energy utilization. Evaluation based on real-world data traces from a prototype application demonstrates that the proposed framework significantly outperforms existing models. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Pan2024HALO
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Long, Z.
AU  - Dong, H.
AU  - El Saddik, A.
TI  - MADRL-Based Rate Adaptation for 360° Video Streaming With Multiviewpoint Prediction
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 15
SP  - 26503
EP  - 26517
DO  - 10.1109/JIOT.2024.3398548
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192962184&doi=10.1109%2fJIOT.2024.3398548&partnerID=40&md5=3bef013f56c0fa14fcefdefc3eaa7683
AB  - Over the last few years, 360° video traffic on the network has grown significantly. A key challenge of 360° video playback is ensuring a high Quality of Experience (QoE) with limited network bandwidth. Currently, most studies focus on tile-based adaptive bitrate (ABR) streaming based on single viewport prediction to reduce bandwidth consumption. However, the performance of models for single-viewpoint prediction is severely limited by the inherent uncertainty in head movement, which can not cope with the sudden movement of users very well. This article first presents a multimodal spatial-temporal attention transformer to generate multiple viewpoint trajectories with their probabilities given a historical trajectory. The proposed method models viewpoint prediction as a classification problem and uses attention mechanisms to capture the spatial and temporal characteristics of input video frames and viewpoint trajectories for multiviewpoint prediction. After that, a multiagent deep reinforcement learning (MADRL)-based ABR algorithm utilizing multiviewpoint prediction for 360° video streaming is proposed for maximizing different QoE objectives under various network conditions. We formulate the ABR problem as a decentralized partially observable Markov decision process (Dec-POMDP) problem and present a multiagent proximal policy optimization algorithm based on the centralized training and decentralized execution (CTDE) framework to solve the problem. The experimental results show that our proposed method improves the defined QoE metric by up to 85.5% compared to the existing ABR methods.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2024MADRL-Based
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Chung, A.C.S.
TI  - Retinal Vessel Segmentation by a Transformer-U-Net Hybrid Model With Dual-Path Decoder
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 9
SP  - 5347
EP  - 5359
DO  - 10.1109/JBHI.2024.3394151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192150046&doi=10.1109%2fJBHI.2024.3394151&partnerID=40&md5=df37e1f410b637e37aef59e98a4e1c87
AB  - This paper introduces an effective and efficient framework for retinal vessel segmentation. First, we design a Transformer-CNN hybrid model in which a Transformer module is inserted inside the U-Net to capture long-range interactions. Second, we design a dual-path decoder in the U-Net framework, which contains two decoding paths for multi-task outputs. Specifically, we train the extra decoder to predict vessel skeletons as an auxiliary task which helps the model learn balanced features. The proposed framework, named as TSNet, not only achieves good performances in a fully supervised learning manner but also enables a rough skeleton annotation process. The annotators only need to roughly delineate vessel skeletons instead of giving precise pixel-wise vessel annotations. To learn with rough skeleton annotations plus a few precise vessel annotations, we propose a skeleton semi-supervised learning scheme. We adopt a mean teacher model to produce pseudo vessel annotations and conduct annotation correction for roughly labeled skeletons annotations. This learning scheme can achieve promising performance with fewer annotation efforts. We have evaluated TSNet through extensive experiments on five benchmarking datasets. Experimental results show that TSNet yields state-of-the-art performances on retinal vessel segmentation and provides an efficient training scheme in practice. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhang2024Retinal
ER  -

TY  - JOUR
AU  - Wang, D.
AU  - Zhang, J.
AU  - Liu, S.
AU  - Lyu, F.
AU  - Huang, W.
AU  - Xu, B.
TI  - KD-ViT: A Lightweight Method for Online Wear State Recognition of Key Friction Pairs in Axial Piston Pump
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 7
SP  - 9621
EP  - 9632
DO  - 10.1109/TII.2024.3384610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191348218&doi=10.1109%2fTII.2024.3384610&partnerID=40&md5=6b655b0d344aa05f5311f9f308f737b1
AB  - —Online wear state recognition of key friction pairs in the axial piston pump is of great significance for stable operation and predictive maintenance of the whole hydraulic system. Edge computing (EC) meets the real-time and low-cost requirements of online wear state recognition whereas two challenges limit its application. One is that current fault diagnosis methods only focus on local fault information, causing inaccuracy and poor generalization ability in different working conditions. The other is that the computing power and storage of EC devices are limited. Therefore, a lightweight knowledge-distilled vision transformer (ViT) is proposed for online wear state recognition. A novel time-frequency domain stacked and channel-weighted pooling structure is proposed to directly process raw time series. To realize high accuracy and high generalization ability, a ViT-based teacher model is pretrained to learn local and global information. To narrow model capacity gap and adapt to the limited resource of the edge node, a novel student model with a simplified self-attention mechanism is proposed to mimic the structure of the ViT and learn from the pretrained teacher model through knowledge distillation. An edge node with functions of signal acquisition, data preprocessing, and wear state recognition is designed and the distilled student model is deployed into it. Comparison with other state-of-the-art methods, ablation experiment, and online verification experiment demonstrate that the proposed method trades off wear state recognition performance and hardware limitations. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024KD-ViT
ER  -

TY  - JOUR
AU  - Kumar, S.
AU  - Chattopadhyay, S.
AU  - Adak, C.
TI  - TPMCF: Temporal QoS Prediction Using Multi-Source Collaborative Features
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
VL  - 21
IS  - 4
SP  - 3945
EP  - 3955
DO  - 10.1109/TNSM.2024.3395428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192162305&doi=10.1109%2fTNSM.2024.3395428&partnerID=40&md5=9782b1962d97c7f5fa0087a1bbab2329
AB  - —The e-commerce industry has seen significant growth in recent years due to the introduction of new Web service APIs. Quality-of-Service (QoS) parameters, which are fundamental for assessing service performance, have become crucial in evaluating services in the competitive market. Since QoS parameters can vary among users and change over time, accurate QoS predictions have become essential for users when selecting the most suitable services. Existing methods for predicting temporal QoS have hardly achieved the desired accuracy, beset by challenges like data sparsity, the presence of anomalies, and the inability to capture intricate temporal user-service interactions. Although some recent approaches, particularly those founded on recurrent neural network-based sequential architectures, endeavor to model temporal relationships in QoS data, they grapple with performance degradation due to the omission of other pivotal features, such as collaborative relationships and spatial characteristics of users and services. Furthermore, the uniform attention among features across all time-steps can thwart progress in predictive accuracy. This paper addresses these challenges and proffers a scalable strategy for temporal QoS prediction using multi-source collaborative features that not only furnishes heightened responsiveness but also engenders enhanced prediction accuracy. The method amalgamates collaborative features stemming from both users and services, capitalizing on the user-service relationship. Additionally, it integrates spatio-temporal auto-extracted features through the orchestration of graph convolution and a specialized variant of the transformer encoder equipped with multi-head self-attention. The proposed approach has been validated on the WSDREAM-2 benchmark datasets, and the results of these extensive experiments demonstrate that our framework surpasses major state-of-the-art methods in terms of predictive accuracy, all the while upholding robust scalability and reasonable responsiveness. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Kumar2024TPMCF
ER  -

TY  - JOUR
AU  - Pu, Y.
AU  - Zhu, C.
AU  - Yang, K.
AU  - Lu, Z.
AU  - Yang, Q.
TI  - A Novel Multiscale Transformer Network Framework for Natural Gas Consumption Forecasting
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 8
SP  - 10040
EP  - 10053
DO  - 10.1109/TII.2024.3388089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192152293&doi=10.1109%2fTII.2024.3388089&partnerID=40&md5=ad6382cfafb7649c1c2cc31a626bfaa5
AB  - Accurate and timely natural gas consumption forecasts are essential for energy policy formulation, natural gas scheduling, and pipeline network design. However, it remains a significant challenge because natural gas consumption is highly nonlinear and irregular with complex cycles. In this article, we propose a new spatial-temporal multiscale transformer network framework that exploits dynamic spatial dependence among users and temporal support of historical multivariate data to improve the accuracy of short-term natural gas consumption forecasting. A novel graph neural network model is developed to capture the spatial dependencies relationships among users by considering the fixed and dynamic connectivity. Compared with other approaches, we validate the effectiveness of the proposed model and its ability to capture fine-grained and spatial-temporal dependencies on a real dataset. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Pu2024Novel
ER  -

TY  - JOUR
AU  - Huang, J.
AU  - Yang, B.
AU  - Yin, K.
AU  - Xu, J.
TI  - DNA-T: Deformable Neighborhood Attention Transformer for Irregular Medical Time Series
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 7
SP  - 4224
EP  - 4237
DO  - 10.1109/JBHI.2024.3395446
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192180153&doi=10.1109%2fJBHI.2024.3395446&partnerID=40&md5=8431edc9142be63817e75c890752edd6
AB  - The real-world Electronic Health Records (EHRs) present irregularities due to changes in the patient's health status, resulting in various time intervals between observations and different physiological variables examined at each observation point. There have been recent applications of Transformer-based models in the field of irregular time series. However, the full attention mechanism in Transformer overly focuses on distant information, ignoring the short-term correlations of the condition. Thereby, the model is not able to capture localized changes or short-term fluctuations in patients' conditions. Therefore, we propose a novel end-to-end Deformable Neighborhood Attention Transformer (DNA-T) for irregular medical time series. The DNA-T captures local features by dynamically adjusting the receptive field of attention and aggregating relevant deformable neighborhoods in irregular time series. Specifically, we design a Deformable Neighborhood Attention (DNA) module that enables the network to attend to relevant neighborhoods by drifting the receiving field of neighborhood attention. The DNA enhances the model's sensitivity to local information and representation of local features, thereby capturing the correlation of localized changes in patients' conditions. We conduct extensive experiments to validate the effectiveness of DNA-T, outperforming existing state-of-the-art methods in predicting the mortality risk of patients. Moreover, we visualize an example to validate the effectiveness of the proposed DNA.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Huang2024DNA-T
ER  -

TY  - JOUR
AU  - Hu, R.
AU  - Yi, J.
AU  - Chen, A.
AU  - Chen, L.
TI  - Multichannel Cross-Modal Fusion Network for Multimodal Sentiment Analysis Considering Language Information Enhancement
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 7
SP  - 9814
EP  - 9824
DO  - 10.1109/TII.2024.3388670
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191864750&doi=10.1109%2fTII.2024.3388670&partnerID=40&md5=66694428790924c6a781717f9009f26b
AB  - With the popularity of short videos, analyzing human emotions is crucial for understanding individual attitudes and guiding social public opinions. Consequently, multimodal sentiment analysis (MSA) has garnered significant attention in the field of human-computer interaction. The main challenge of MSA is to explore a high-quality multimodal fusion framework, as multiple modalities contribute inconsistently to sentiment prediction. However, most of the existing methods assume equal importance among different modalities, resulting in inadequate expression of the main modality. In addition, auxiliary modalities often contain redundant information, which hinders the multimodal fusion process. Therefore, we propose the multichannel cross-modal fusion network (MCFNet) to promote the multimodal fusion procedure by constructing a multichannel various modality fusion framework comprising three channels: obtaining multimodal representation through the first channel; eliminating information redundancy from auxiliary modalities via the second channel; and enhancing significance attributed to the main modality adopting the third channel. Subsequently, we design a multichannel information fusion gate to integrate feature representations from these three channels for downstream sentiment classification tasks. Numerous experiments on three benchmark datasets, CMU-multimodal opinion sentiment intensity (MOSI), CMU-multimodal opinion sentiment and emotion intensity (MOSEI), and Twitter2019, show that the MCFNet has made a significant progress compared to recent state-of-the-art methods. 1551-3203  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Hu2024Multichannel
ER  -

TY  - JOUR
AU  - Bi, J.
AU  - Ma, H.
AU  - Yuan, H.
AU  - Buyya, R.
AU  - Yang, J.
AU  - Zhang, J.
AU  - Zhou, M.
TI  - Multivariate Resource Usage Prediction With Frequency-Enhanced and Attention-Assisted Transformer in Cloud Computing Systems
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 15
SP  - 26419
EP  - 26429
DO  - 10.1109/JIOT.2024.3395610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192210405&doi=10.1109%2fJIOT.2024.3395610&partnerID=40&md5=f54d63458f3675205f74613756cc5e9c
AB  - Resource usage prediction in cloud data centers is critically important. It can improve providers' service quality and avoid resource wastage and insufficiency. However, the time series of resource usage in cloud environments is characterized by multidimensional, nonlinear, and high-volatility characteristics. Achieving high-accuracy prediction for time series with such characteristics is necessary but difficult. Traditional prediction methods based on regression algorithms and recurrent neural networks cannot effectively extract nonlinear features from data sets. Besides, many deep learning models suffer from gradient explosion or gradient vanishing during the training stage. Current commonly used prediction methods fail to uncover some vital information about the frequency domain features in the time series. To resolve these challenges, we design a Forecasting method based on the Integration of a Savitzky-Golay (SG) filter, a frequency enhanced decomposed transformer (FEDformer) model, and a frequency-enhanced channel attention mechanism (FECAM), named FISFA. It adopts the SG filter to reduce noise and smooth sequences in the raw sequences of resources. Then, we develop a hybrid transformer-based model integrating FEDformer and the FECAM, effectively capturing the frequency domain patterns. Besides, a meta-heuristic optimization algorithm, i.e., genetic simulated annealing-based particle swarm optimizer, is proposed to optimize key hyperparameters of FISFA. Then, FISFA predicts the future needs for multidimensional resources in highly fluctuating traces in real-life cloud environments. Experimental results demonstrate that FISFA achieves higher accuracy and performs more efficient prediction than several benchmark forecasting methods with realistic data sets collected from Alibaba and Google cluster traces. FISFA improves the prediction accuracy on average by 32.14%, 25.49%, and 27.71% over vanilla long short-term memory, transformer, and Informer methods, respectively. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Bi2024Multivariate
ER  -

TY  - JOUR
AU  - Wang, Q.
AU  - Tao, Z.
AU  - Ning, J.
AU  - Jiang, Z.
AU  - Guo, L.
AU  - Luo, H.
AU  - Wang, H.
AU  - Men, A.
AU  - Cheng, X.
AU  - Zhang, Z.
TI  - Pedestrian Navigation Activity Recognition Based on Segmentation Transformer
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 15
SP  - 26020
EP  - 26032
DO  - 10.1109/JIOT.2024.3394050
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192164925&doi=10.1109%2fJIOT.2024.3394050&partnerID=40&md5=668b67298c971764e6092dd16567b8bd
AB  - In the context of the Internet of Things, utilizing the inherent inertial sensors in smartphones for human activity recognition (HAR) has garnered considerable attention owing to its wide-ranging applications. However, prevailing HAR approaches primarily treat activity identification as a single-label classification task, focusing solely on discerning pedestrian motion modes or device usage modes, while disregarding their interrelatedness. Additionally, HAR methods employing sliding windows encounter challenges associated with the multiclass window problem, wherein certain sample labels differ from the label assigned to the window. This article aims to address these issues. This article presents a novel approach for simultaneously recognizing pedestrian motion and device usage modes by utilizing the segmentation Transformer. The proposed joint recognition framework effectively annotates sensor data at each timestamp and achieves dense prediction of time-series data through the encoding and decoding of the annotated data. To optimize the utilization of information extracted from each Transformer layer, a global up-sampling decoder based on the pyramid attention module is introduced, enabling dense decoding of features obtained from each Transformer layer. We performed experiments on two publicly available data sets to comprehensively assess the effectiveness of the proposed methodology. The results demonstrate that our approach achieves an accuracy of 99.79% and a weighted F-score of 99.77%, surpassing the performance of existing state-of-the-art methods. Furthermore, we constructed heterogeneous data sets to validate the robustness of our method. The extensive experimental findings indicate that the joint recognition framework effectively uncovers the inherent correlations between pedestrian motion and device usage modes, leading to enhanced accuracy in recognition and addressing the challenges posed by the multiclass window problem. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2024Pedestrian
ER  -

TY  - JOUR
AU  - Hu, K.
AU  - Li, L.
AU  - Tao, X.
AU  - Zhang, J.
TI  - Semantics and Geography Aware Hierarchical Learning for Sequential Crime Prediction
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 1234
EP  - 1238
DO  - 10.1109/LSP.2024.3393863
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191879124&doi=10.1109%2fLSP.2024.3393863&partnerID=40&md5=a3df273b9708f992975a1ec07d17697c
AB  - Sequential Crime Prediction (SCP) aims to analyze future criminal intents within historical event transitions and predict next crime event. A problem lies in the correlations among different event features (e.g., time, locations, and categories), posing challenges to capture a comprehensive criminal intent. Most existing methods are hard to fully exploit event descriptions and locations in raw crime records to model such correlations. To this end, this letter proposes a Semantics and Geography aware hierarchical learning framework (SaGCrime). First, we employ BERT to encode semantic representations from descriptions and a proposed geography encoder to learn geographical representations from exact GPS-based locations, respectively. Then, these representations are fed into a stacked Transformer encoder to learn multi-modal interactive intent representation of next crime event. Experiments on real-world crime datasets show that our SaGCrime achieves relatively 4.70% and 3.64% improvements in terms of NDCG@5, compared with state-of-the-art methods.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Hu2024Semantics
ER  -

TY  - JOUR
AU  - Zhao, Y.
AU  - Zong, Y.
AU  - Wang, J.
AU  - Lian, H.
AU  - Lu, C.
AU  - Zhao, L.
AU  - Zheng, W.
TI  - Layer-Adapted Implicit Distribution Alignment Networks for Cross-Corpus Speech Emotion Recognition
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 4
SP  - 5419
EP  - 5430
DO  - 10.1109/TCSS.2024.3362690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189183211&doi=10.1109%2fTCSS.2024.3362690&partnerID=40&md5=894ef05c9ba2ef3e541fba7299a7f517
AB  - In this article, we propose a new unsupervised domain adaptation (DA) method called layer-adapted implicit distribution alignment networks (LIDANs) to address the challenge of cross-corpus speech emotion recognition (SER). LIDAN extends our previous ICASSP work, deep implicit distribution alignment networks (DIDANs), whose key contribution lies in the introduction of a novel regularization term called implicit distribution alignment (IDA). This term allows DIDAN trained on source (training) speech samples to remain applicable to predicting emotion labels for target (testing) speech samples, regardless of corpus variance in cross-corpus SER. To further enhance this method, we extend IDA to layer-adapted IDA (LIDA), resulting in LIDAN. This layer-adapted extension consists of three modified IDA terms that consider emotion labels at different levels of granularity. These terms are strategically arranged within different fully connected layers in LIDAN, aligning with the increasing emotion-discriminative abilities with respect to the layer depth. This arrangement enables LIDAN to more effectively learn emotion-discriminative and corpus-invariant features for SER across various corpora compared to DIDAN. It is also worthy to mention that unlike most existing methods that rely on estimating statistical moments to describe preassumed explicit distributions, both IDA and LIDA take a different approach. They utilize an idea of target sample reconstruction to directly bridge the feature distribution gap without making assumptions about their distribution type. As a result, DIDAN and LIDAN can be viewed as implicit cross-corpus SER methods. To evaluate LIDAN, we conducted extensive cross-corpus SER experiments on EmoDB, eNTERFACE, and CASIA corpora. The experimental results demonstrate that LIDAN surpasses recent state-of-the-art explicit unsupervised DA methods in tackling cross-corpus SER tasks. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhao2024Layer-Adapted
ER  -

TY  - JOUR
AU  - Gormez, A.
AU  - Koyuncu, E.
TI  - Class Based Thresholding in Early Exit Semantic Segmentation Networks
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
C7  - 3386110
SP  - 1184
EP  - 1188
DO  - 10.1109/LSP.2024.3386110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190172721&doi=10.1109%2fLSP.2024.3386110&partnerID=40&md5=93f19d36826c03458ba0ff3c12b1cb05
AB  - We consider semantic segmentation of images using deep neural networks. To reduce the computational cost, we incorporate the idea of early exit, where different pixels can be classified earlier in different layers of the network. In this context, existing work utilizes a common threshold to determine the class confidences for early exit purposes. In this work, we propose Class Based Thresholding (CBT) for semantic segmentation. CBT assigns different threshold values to each class, so that the computation can be terminated sooner for pixels belonging to easy-To-predict classes. CBT does not require hyperparameter tuning; in fact, the threshold values are automatically determined by exploiting the naturally-occurring neural collapse phenomenon. We show the effectiveness of CBT on Cityscapes, ADE20K and COCO-Stuff-10K datasets using both convolutional neural networks and vision transformers. CBT can reduce the computational cost by up to 23% compared to the previous state-of-The-Art early exit semantic segmentation models, while preserving the mean intersection over union (mIoU) performance. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Gormez2024Class
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Wang, K.
AU  - Hou, X.
AU  - Lan, D.
AU  - Wu, Y.
AU  - Wang, H.
AU  - Liu, L.
AU  - Mumtaz, S.
TI  - A Dual-Scale Transformer-Based Remaining Useful Life Prediction Model in Industrial Internet of Things
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 16
SP  - 26656
EP  - 26667
DO  - 10.1109/JIOT.2024.3376706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188459865&doi=10.1109%2fJIOT.2024.3376706&partnerID=40&md5=e1e186e0c1ac4f8234c4bb3c15f3ef4f
AB  - With recent advances of Industrial Internet of Things (IIoT), the connectivity and data collection capabilities of industrial equipment have be significantly enhanced, yet bringing new challenges for the remaining useful life (RUL) prediction. To fulfill the RUL predicting demand in multivariate time series, this work proposes an encoder-decoder model termed as dual-scale transformer model (DSFormer), built upon the Transformer architecture. First, in the encoder part, a dual-attention module is designed for the weight feature extraction from both dimensions of the sensor and time series, aiming to compensate for the diverse impacts of different sensors on the prediction. Next, a temporal convolutional network (TCN) module is introduced to capture sequence features and alleviate the loss of positional information incurred by stacking blocks. Then, the feature decomposition module is integrated into the decoder for trend feature extraction from sequences, providing the model with additional sequence information. Finally, compared to existing models, the proposed method can obtain the superior performance in terms of the root mean square error (RMSE) and Score metrics on the FD001, FD002 and FD003 subsets of the C-MAPSS data set, with an average improvement of 3.2% and 2.5%, respectively. In particular, the ablation experiment further validates the effectiveness of proposed modules in handling multivariate time series and extracting features.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Li2024Dual-Scale
ER  -

TY  - JOUR
AU  - Zao, Y.
AU  - Zou, Z.
AU  - Shi, Z.
TI  - Road Graph Extraction via Transformer and Topological Representation
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 2502205
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3380593
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188903350&doi=10.1109%2fLGRS.2024.3380593&partnerID=40&md5=10372ae89545198a23ffadee76118847
AB  - Road graph extraction from remote sensing images aims at extracting topological maps composed of road vertices and edges, which has broad prospects in urban planning, traffic management, and other applications. However, existing methods are easily affected by complex remote sensing scenes, and also have shortcomings such as poor continuity and slow processing speed. In this letter, we propose a novel end-to-end road extraction method named 'Road2Graph', which encodes road graphs into topological representations for prediction. We proposed a transformer-based model to encode the deep convolutional features, and then fuse them with the output of the feature extractor to make the network pay more attention to the global multiscale road topology context. We also design an efficient topological representation that encodes attributes such as road segmentation, midpoint map, vertex map, and connection relationships with few parameters and low redundancy. The obtained topological representation can be decoded to obtain the road extraction result in graph format. We conduct experiments on two public datasets - CityScale dataset and SpaceNet dataset. The results show that our method achieves the state-of-art and improves both accuracy (TOPO-F1 +1.55% on CityScale dataset and +2.23% on SpaceNet dataset) and continuity (APLS +7.03% on CityScale dataset and +3.05% on SpaceNet dataset) compared to the other methods.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zao2024Road
ER  -

TY  - JOUR
AU  - Son, Y.-H.
AU  - Shin, D.-H.
AU  - Kam, T.-E.
TI  - FTMMR: Fusion Transformer for Integrating Multiple Molecular Representations
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 7
SP  - 4361
EP  - 4372
DO  - 10.1109/JBHI.2024.3383221
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189553878&doi=10.1109%2fJBHI.2024.3383221&partnerID=40&md5=8f39ff5966154a71241305681abd31cb
AB  - Molecular property prediction has gained substantial attention due to its potential for various bio-chemical applications. Numerous attempts have been made to enhance the performance by combining multiple molecular representations (1D, 2D, and 3D). However, most prior works only merged a limited number of representations or tried to embed multiple representations through a single network without using representation-specific networks. Furthermore, the heterogeneous characteristics of each representation made the fusion more challenging. Addressing these challenges, we introduce the Fusion Transformer for Multiple Molecular Representations (FTMMR) framework. Our strategy employs three distinct representation-specific networks and integrates information from each network using a fusion transformer architecture to generate fused representations. Additionally, we use self-supervised learning methods to align heterogeneous representations and to effectively utilize the limited chemical data available. In particular, we adopt a combinatorial loss function to leverage the contrastive loss for all three representations. We evaluate the performance of FTMMR using seven benchmark datasets, demonstrating that our framework outperforms existing fusion and self-supervised methods.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Son2024FTMMR
ER  -

TY  - JOUR
AU  - Ji, J.
AU  - He, J.
AU  - Lei, M.
AU  - Wang, M.
AU  - Tang, W.
TI  - Spatio-Temporal Transformer Network for Weather Forecasting
PY  - 2024
T2  - IEEE Transactions on Big Data
SP  - 1
EP  - 16
DO  - 10.1109/TBDATA.2024.3378061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188425942&doi=10.1109%2fTBDATA.2024.3378061&partnerID=40&md5=3d7582f99a65614881043ad875806567
AB  - Spatio-temporal neural networks have been successfully applied to weather forecasting tasks recently. The key notion is to learn spatio-temporal features concurrently from spatial and temporal dependencies. Existing methods are mainly based on local smoothness assumptions where the features are learned by accumulating information in local spatio-temporal regions. However, the weather conditions in a certain spatio-temporal region are usually influenced by global meteorological changes and long-range historical weather conditions. Therefore, these methods that ignore the large-scale spatio-temporal effects can hardly learn effective features. In this paper, we propose a novel spatio-temporal Transformer network in weather forecasting to address the above challenges. The main idea is to leverage the Transformer architecture to carefully capture the multi-scale spatial and long-range temporal information in weather data. First, we propose to combine the global and local position encodings based on absolute geographic locations and relative geodesic distances and insert them into the spatial Transformer to extract the multi-scale spatial information in meteorological graphs. Then, we further capture the long-range temporal dependencies by a temporal Transformer where the attention mechanism is used to improve the representation ability and scalability of the models. Extensive experiments over real weather datasets demonstrate the effectiveness of our framework. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Ji2024Spatio-Temporal
ER  -

TY  - JOUR
AU  - Lin, J.
AU  - Ge, M.
AU  - Wang, W.
AU  - Li, H.
AU  - Feng, M.
TI  - Selective HuBERT: Self-Supervised Pre-Training for Target Speaker in Clean and Mixture Speech
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 1014
EP  - 1018
DO  - 10.1109/LSP.2024.3383794
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189614561&doi=10.1109%2fLSP.2024.3383794&partnerID=40&md5=cbbb207e57637dd9080f715b712ae3dc
AB  - Self-supervised pre-trained speech models were shown effective for various downstream speech processing tasks. Since they are mainly pre-trained to map input speech to pseudo-labels, the resulting representations are only effective for the type of pre-train data used, either clean or mixture speech. With the idea of selective auditory attention, we propose a novel pre-training solution called Selective-HuBERT, or SHuBERT, which learns the selective extraction of target speech representations from either clean or mixture speech. Specifically, SHuBERT is trained to predict pseudo labels of a target speaker, conditioned on an enrolment speech from the target speaker. By doing so, SHuBERT is expected to selectively attend to the target speaker in a complex acoustic environment, thus benefiting various downstream tasks. We further introduce a dual-path training strategy and use the cross-correlation constraint between the two branches to encourage the model to generate noise-invariant representation. Experiments on SUPERB benchmark and LibriMix dataset demonstrate the universality and noise-robustness of SHuBERT. Furthermore, we find that our high-quality representation can be easily integrated with conventional supervised learning methods to achieve significant performance, even under extremely low-resource labeled data.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Lin2024Selective
ER  -

TY  - JOUR
AU  - Fang, W.
AU  - Fu, Y.
AU  - Sheng, V.S.
TI  - Dual Backbone Interaction Network for Burned Area Segmentation in Optical Remote Sensing Images
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 6008805
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3369619
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186966542&doi=10.1109%2fLGRS.2024.3369619&partnerID=40&md5=acbb2cd643345bc9c0e739befff8cb91
AB  - The existing methods for burned area segmentation (BAS) in optical remote sensing images (ORSIs) mainly adopt convolution neural network (CNN) as the backbone, which has limited receptive filed and suffers from long-term dependencies problem. To address this issue, we propose a novel salient object detection (SOD) network (DBINet) based on dual interactive convolution-transformer backbone for BAS in ORSIs. DBINet combines the benefits of CNN and transformer: CNN is good at extracting local spatial information, while transformer does well in modeling long-term dependencies. The core component of DBINet is three newly designed modules: dual-feature fusion module (DFM), convertor, and a novel decoder. Specifically, DFM is proposed to bridge two different backbones. Convertor is designed to fuse the multiscale coarse features from the main encoder and produce the fined feature for the decoder. The decoder has a multilevel feature aggregating process and a self-refining process, which restores the resolution and generates the prediction results. Experiments on three datasets demonstrate that our DBINet outperforms the state-of-the-art methods and achieves the best S-measure on three datasets: 0.847, 0.888, and 0.883. Code is available at: https://github.com/Voruarn/DBINet.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Fang2024Dual
ER  -

TY  - JOUR
AU  - Guo, S.
AU  - Xia, M.
AU  - Xue, H.
AU  - Wang, S.
AU  - Liu, C.
TI  - OceanCrowd: Vessel Trajectory Data-Based Participant Selection for Mobile Crowd Sensing in Ocean Observation
PY  - 2024
T2  - IEEE Transactions on Sustainable Computing
VL  - 9
IS  - 6
SP  - 889
EP  - 901
DO  - 10.1109/TSUSC.2024.3369092
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186086568&doi=10.1109%2fTSUSC.2024.3369092&partnerID=40&md5=a3ff7aa159d95c4ca25ba58c5ac00788
AB  - With the in-depth study of the internal process mechanism of the global ocean by oceanographers, traditional ocean observation methods have been unable to meet the new observation requirements. In order to achieve a low-cost ocean observation mechanism with high spatio-temporal resolution, this paper introduces mobile crowd sensing technology into the field of ocean observation. First, a Transformer-based vessel trajectory prediction algorithm is proposed, which can monitor the location and movement trajectory of vessel in real time. Second, the participant selection algorithm in mobile crowd sensing is studied, and based on the trajectory prediction algorithm, a dynamic participant selection algorithm for ocean mobile crowd sensing is proposed by combining it with the discrete particle swarm optimization (DPSO) algorithm. Third, a coverage estimation algorithm is designed to estimate the coverage of the selection scheme. Finally, the spatio-temporal resolution of the vessel's driving trajectory is analyzed through experiments, which verifies the effectiveness of the algorithm and comprehensively confirms the feasibility of mobile crowd sensing in the field of ocean observation.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Guo2024OceanCrowd
ER  -

TY  - JOUR
AU  - Liang, P.
AU  - Yang, L.
AU  - Xiong, Z.
AU  - Zhang, X.
AU  - Liu, G.
TI  - Multilevel Intrusion Detection Based on Transformer and Wavelet Transform for IoT Data Security
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 15
SP  - 25613
EP  - 25624
DO  - 10.1109/JIOT.2024.3369034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186107100&doi=10.1109%2fJIOT.2024.3369034&partnerID=40&md5=98f54a690699b57bf805db39ace7c454
AB  - The Internet of Things (IoT) technology and systems have penetrated every aspect of our lives and generated enormous economic benefits. At the same time, research on the data security of IoT systems has been one of the key topics in IoT fields. Network attacks and intrusions have become the main threats to the data security of the IoTs, which have become the main obstacles to the development and application of the IoTs. In this article, we propose an intrusions and attack detection model to ensure the data security of IoT systems by using the Transformer model and multiwavelets learning. Based on the architecture of IoT systems, we first proposed a multilevel intrusion detection model to detect attack data in the cloud layer and edge terminal layer. In this detection model, a Transformer model and discrete wavelet transform (DWT)-based approach are proposed to ensure the effectiveness and accuracy of the model. To extract and make full use of frequency information of traffic data in an IoT network, we embed DWT technique and multiwavelets learning into the Transformer model to propose a novel DWT-based Transformer architecture, which achieves outstanding performance in detecting intrusion actions. Simulating on IoT system in the laboratory environment, the proposed security prediction model achieves pretty good performance in predicting intrusion actions. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Liang2024Multilevel
ER  -

TY  - JOUR
AU  - Pan, X.
AU  - Wang, S.
AU  - Liu, Y.
AU  - Wen, L.
AU  - Lu, M.
TI  - iPCa-Former: A Multi-Task Transformer Framework for Perceiving Incidental Prostate Cancer
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 785
EP  - 789
DO  - 10.1109/LSP.2024.3372787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187397953&doi=10.1109%2fLSP.2024.3372787&partnerID=40&md5=881b829a09fa049020abf15fe0ef8da8
AB  - Despite significant progress in medical image analysis using deep learning, predicting incidental prostate cancer (iPCa) remains challenging due to subtle differences in multiparametric magnetic resonance imaging (mpMRI) and a lower incidence rate. To address these challenges, we propose iPCa-Former, a transformer-based framework designed to enhance iPCa prediction within prostate mpMRI slices. Firstly, built on an encoder-decoder architecture, our iPCa-Former facilitates the simultaneous optimization of two tasks through mutual learning: prostate transition zone segmentation and iPCa prediction. Secondly, we introduce a joint optimization function that combines focal loss and boundary-based mutual information (BMI) loss, effectively addressing the imbalance of positive and negative samples in classification and the challenge posed by a small proportion of the foreground region in segmentation. Moreover, we construct an iPCa mpMRI dataset comprising 10,276 prostate mpMRI slices from 485 patients clinically diagnosed with benign prostatic hyperplasia; however, 27 out of these patients are identified as iPCa. When evaluated on this benchmark dataset, our iPCa-Former outperforms state-of-the-art methods, demonstrating the superior performance of our approach.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Pan2024iPCa-Former
ER  -

TY  - JOUR
AU  - Ge, K.
AU  - Wang, C.
AU  - Guo, Y.-T.
AU  - Tang, Y.-S.
AU  - Fan, J.-S.
TI  - A Multitask Fourier Transformer Network for Seismic Source Characterization Estimation From a Single-Station Waveform
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 7503805
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3369108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186073306&doi=10.1109%2fLGRS.2024.3369108&partnerID=40&md5=df2894af3778649545c951bc9f2dd03f
AB  - This study introduces a novel approach for the estimation of seismic source parameters using a multitask learning network that incorporates a Fourier Transformer architecture. The Fourier Transformer is designed to extract information from both the time and frequency domains, which reduces the time complexity by utilizing a fast Fourier transform (FFT) in place of the traditional attention mechanism in the Transformer encoder. The network consists of a shared encoder for general feature extraction and four task-specific decoders for parameter estimation. The model is both lightweight and accurate, capable of simultaneously estimating magnitude, epicentral distance, p travel time, and depth based on a 30-s single-station waveform. The proposed approach was validated using the Stanford Earthquake dataset (STEAD) and compared with the state-of-the-art techniques. The results show standard deviations of 0.19 for magnitude, 3.77 km for epicentral distance, 0.46 s for p travel time, and 5.77 km for depth, with a lower error and a faster response compared to the existing prediction framework. The code is available at https://github.com/KG-TSI-Civil/MFTnet. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Ge2024Multitask
ER  -

TY  - JOUR
AU  - Wei, P.
AU  - Liu, X.
AU  - Luo, J.
AU  - Pu, H.
AU  - Huang, X.
AU  - Wang, S.
AU  - Cao, H.
AU  - Yang, S.
AU  - Zhuang, X.
AU  - Wang, J.
AU  - Yue, H.
AU  - Ji, C.
AU  - Zhou, M.
TI  - Transformer with a Parallel Decoder for Image Captioning
PY  - 2024
T2  - International Journal of Pattern Recognition and Artificial Intelligence
VL  - 38
IS  - 1
C7  - 2354029
DO  - 10.1142/S0218001423540290
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186913362&doi=10.1142%2fS0218001423540290&partnerID=40&md5=ba5dc183205c96887a34290eac1700ca
AB  - In this paper, a parallel decoder and a word group prediction module are proposed to speed up decoding and improve the effect of captions. The features of the image extracted by the encoder are linearly projected to different word groups, and then a unique relaxed mask matrix is designed to improve the decoding speed and the caption effect. First, since image captioning is composed of many words, sentences can also be broken down into word groups or words according to their syntactic structure, and we achieve this function through constituency parsing. Second, we make full use of the extracted features to predict the size of word groups. Then, a new embedding representing the information of the word is proposed based on word embedding. Finally, with the help of word groups, we design a mask matrix to modify the decoding process so that each step of the model can produce one or more words in parallel. Experiments on public datasets demonstrate that our method can reduce the time complexity while maintaining competitive performance.  © 2024 World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wei2024Transformer
ER  -

TY  - JOUR
AU  - Cai, Z.
AU  - Ning, J.
AU  - Ding, Z.
AU  - Duo, B.
TI  - Additional Self-Attention Transformer with Adapter for Thick Haze Removal
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 6004705
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3368430
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186082831&doi=10.1109%2fLGRS.2024.3368430&partnerID=40&md5=250a87d9feba50b0b7ae42d7a7fcab04
AB  - Remote sensing images (RSIs) are widely used in the fields of geological resources monitoring, earthquake relief, and weather forecasting, but they are easily nullified due to haze cover. Transformer-based image dehazing model can better remove the haze in RSIs and improve the clarity of RSIs. However, due to the insufficient ability to extract detailed information, the model performs poorly in the case of thick haze. To solve this problem, this letter introduces an additional self-attention (AS) mechanism to help the model acquire more detailed information based on the existing Transformer-based image dehazing model and introduces an adapter module to improve the model's fitting capacity with newly added content. Experimental results on benchmark RSIs indicate that the proposed method yields an average improvement of 0.95 in peak signal-to-noise ratio (PSNR) and 0.6% in structural similarity index metrices (SSIM) for light haze removal. Notably, the method exhibits a significant enhancement of 1.34 in PSNR and 1.9% in SSIM for the removal of thick haze, underscoring its advantage in heavy haze conditions. The source code can be accessed via https://github.com/Eric3200C/ASTA.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Cai2024Additional
ER  -

TY  - JOUR
AU  - Koc, E.
AU  - Alikasifoglu, T.
AU  - Aras, A.C.
AU  - Koc, A.
TI  - Trainable Fractional Fourier Transform
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 751
EP  - 755
DO  - 10.1109/LSP.2024.3372779
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187370210&doi=10.1109%2fLSP.2024.3372779&partnerID=40&md5=3b416a1013ae904a4b97d82fe8a46f31
AB  - Recently, the fractional Fourier transform (FrFT) has been integrated into distinct deep neural network (DNN) models such as transformers, sequence models, and convolutional neural networks (CNNs). However, in previous works, the fraction order a is merely considered a hyperparameter and selected heuristically or tuned manually to find the suitable values, which hinders the applicability of FrFT in deep neural networks. We extend the scope of FrFT and introduce it as a trainable layer in neural network architectures, where a is learned in the training stage along with the network weights. We mathematically show that a can be updated in any neural network architecture through backpropagation in the network training phase. We also conduct extensive experiments on benchmark datasets encompassing image classification and time series prediction tasks. Our results show that the trainable FrFT layers alleviate the need to search for suitable a and improve performance over time and Fourier domain approaches. We share our publicly available source codes for reproducibility.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Koc2024Trainable
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Pang, S.
AU  - Zhang, Y.
TI  - Application of Adaboost-Transformer Algorithm for Lithology Identification Based on Well Logging Data
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 7502605
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3372513
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187006056&doi=10.1109%2fLGRS.2024.3372513&partnerID=40&md5=0d9e3e74b9bead570afb7e9b644e60f3
AB  - In the field of oil and gas exploration, accurately predicting lithology during well logging is crucial. This research introduces a novel approach, the Adaboost-Transformer method, which utilizes data mining techniques to enhance logging lithology prediction. The first step involves applying the Adaboost algorithm for selecting features, which develops a strong classifier by focusing on weighted observations and particularly challenging samples. This approach not only boosts accuracy and durability but also lessens the likelihood of overfitting. Following this, we implement the Transformer as the principal classifier in creating the Adaboost-Transformer model. The Transformer is specifically designed for sequential data and is highly efficient in modeling sequences, especially in capturing temporal links within well logging data. When tested on two separate well logging datasets, this innovative model exhibited superior lithology identification capabilities, achieving accuracy rates of 95.20% and 95.50%. These figures notably surpass those of the standalone Transformer model, which scored 91.50% and 91.10% in accuracy. In comparison, the random forest (RF) model displayed more limited performance with accuracy rates of 88.80% and 87.10%.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Sun2024Application
ER  -

TY  - JOUR
AU  - Cargan, T.R.
AU  - Landa-Silva, D.
AU  - Triguero, I.
TI  - Local-global methods for generalised solar irradiance forecasting
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 2
SP  - 2225
EP  - 2247
DO  - 10.1007/s10489-024-05273-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184246425&doi=10.1007%2fs10489-024-05273-9&partnerID=40&md5=e960415d2bdee84b5ba5d4c599068949
AB  - For efficient operation, solar power operators often require generation forecasts for multiple sites with varying data availability. Many proposed methods for forecasting solar irradiance / solar power production formulate the problem as a time-series, using current observations to generate forecasts. This necessitates a real-time data stream and enough historical observations at every location for these methods to be deployed. In this paper, we propose the use of Global methods to train generalised models. Using data from 20 locations distributed throughout the UK, we show that it is possible to learn models without access to data for all locations, enabling them to generate forecasts for unseen locations. We show a single Global model trained on multiple locations can produce more consistent and accurate results across locations. Furthermore, by leveraging weather observations and measurements from other locations we show it is possible to create models capable of accurately forecasting irradiance at locations without any real-time data. We apply our approaches to both classical and state-of-the-art Machine Learning methods, including a Transformer architecture. We compare models using satellite imagery or point observations (temperature, pressure, etc.) as weather data. These methods could facilitate planning and optimisation for both newly deployed solar farms and domestic installations from the moment they come online. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Cargan2024Local-global
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Yang, X.
AU  - Zhao, M.
AU  - Wang, Z.
AU  - Yao, Y.
AU  - Qian, W.
AU  - Qi, S.
TI  - FPT-Former: A Flexible Parallel Transformer of Recognizing Depression by Using Audiovisual Expert-Knowledge-Based Multimodal Measures
PY  - 2024
T2  - International Journal of Intelligent Systems
VL  - 2024
C7  - 1564574
DO  - 10.1155/2024/1564574
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185181315&doi=10.1155%2f2024%2f1564574&partnerID=40&md5=72f8dd42fed0b28130d7cd8dd05f992f
AB  - Background and Objective. Currently, depression is a widespread global issue that imposes a significant burden and disability on individuals, families, and society. Deep learning (DL) has emerged as a valuable approach for automatically detecting depression by extracting cues from audiovisual data and making a diagnosis. PHQ-8 is considered a validated diagnostic tool for depressive disorders in clinical studies, and the objective of this experiment is to improve the accuracy of PHQ-8 prediction. Furthermore, this paper aims to demonstrate the effectiveness of expert knowledge in depression diagnosis and discuss a novel multimodal network architecture. Methods. This research paper focuses on multimodal depression analysis, proposing a flexible parallel transformer (FPT) model capable of extracting data from three distinct modalities (i.e., one video and two audio descriptors). The FPT-Former model incorporates three paths, each using expert-knowledge-based descriptors from one modality as inputs. These descriptors are represented into 32 features by the encoder part of a transformer module, and these features are fused to realize the final regression of PHQ-8 score. The extended distress analysis interview corpus (E-DAIC) is an expansion of WOZ-DAIC which comprises semiclinical interviews intended to assist in the diagnosis of psychological distress conditions. It encompasses a sample size of 275 participants, and in this study, it was utilized to test the model in a way of 10-fold cross-validation. Results. The FPT presented herein achieved comparable performance to the state-of-the-art works, with a root mean square error (RMSE) of 4.80 and a mean absolute error (MAE) of 4.58. The ablation experiments demonstrate that the three-modality-fused model outperforms other two-modality-fused and single-modality models. While using a PHQ-8 score threshold of 10, the accuracy of the depression classification is 0.79. Conclusions. Leveraging the strength of expert-knowledge-based multimodal measures and parallel transformer structure, the FPT model exhibits promising performance in depression detection. This model improved the accuracy of depression diagnosis through audio and video, and it also proved the effectiveness of using expert-knowledge in the diagnosis of depression. The traits of flexible structure, high predictive efficiency, and secure privacy protection make our model a promotable intelligent system in mental healthcare. © 2024 Yifu Li et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Li2024FPT-Former
ER  -

TY  - JOUR
AU  - Pan, Y.
AU  - Zhou, W.
AU  - Fang, M.
AU  - Qiang, F.
TI  - Graph Enhancement and Transformer Aggregation Network for RGB-Thermal Crowd Counting
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 3000705
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3362820
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184796896&doi=10.1109%2fLGRS.2024.3362820&partnerID=40&md5=92aaccaf3cc8cd6061eac09e269ae132
AB  - Crowd counting has received significant attention in recent years due to its practical applications. In order to address the specific characteristics of RGB and thermal images, we have developed the graph enhancement and transformer aggregation network (GETANet) for generating representative density maps. Our approach incorporates several innovative modules to enhance accuracy. First, we introduced a position-adaptive module (PAM) that effectively counts individuals' positions and integrates features extracted from the main framework. Furthermore, we leveraged the advantages of graph convolutional networks (GCNs), which integrate spatial information and exploit relationships between nodes. Specifically, we designed a dual GCN module that further improves the model's performance by considering the spatial context and relationships among individuals in the crowd. To capture global image information and improve overall performance, we integrated a vision transformer into our model architecture. The vision transformer effectively captures global dependencies and enhances the model's ability to understand complex crowd scenes. Additionally, we designed a transformer information aggregation module (TIAM) that integrates information from multiple levels, resulting in a highly precise prediction map. Through comprehensive experiments on benchmark datasets, such as RGBT-CC and DroneRGBT, our GETANet demonstrated its effectiveness in RGB-thermal crowd counting tasks. Moreover, GETANet showcased remarkable generalization results on the ShanghaiTech-RGBD dataset. Our code has been made publicly available on GitHub at https://github.com/panyi95/GETANet.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Pan2024Graph
ER  -

TY  - JOUR
AU  - Liao, H.
AU  - Jiang, N.
AU  - Chen, W.
AU  - Wei, H.
AU  - Zhao, T.
TI  - Distillation-Based Utility Assessment for Compacted Underwater Information
PY  - 2024
T2  - IEEE Signal Processing Letters
VL  - 31
SP  - 481
EP  - 485
DO  - 10.1109/LSP.2024.3358108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184004023&doi=10.1109%2fLSP.2024.3358108&partnerID=40&md5=01531a2c2250a77fa66f27579f821784
AB  - The limited bandwidth of underwater acoustic channels poses a challenge to the efficiency of multimedia information transmission. To improve efficiency, the system aims to transmit less data while maintaining image utility at the receiving end. Although assessing utility within compressed information is essential, the current methods exhibit limitations in addressing utility-driven quality assessment. Therefore, this letter built a Utility-oriented compacted Image Quality Dataset (UCIQD) that contains utility qualities of reference images and their corresponding compcated information at different levels. The utility score is derived from the average confidence of various object detection models. Then, based on UCIQD, we introduce a Distillation-based Compacted Information Quality assessment metric (DCIQ) for utility-oriented quality evaluation in the context of underwater machine vision. In DCIQ, utility features of compacted information are acquired through transfer learning and mapped using a Transformer. Besides, we propose a utility-oriented cross-model feature fusion mechanism to address different detection algorithm preferences. After that, a utility-oriented feature quality measure assesses compacted feature utility. Finally, we utilize distillation to compress the model by reducing its parameters by 55%. Experiment results effectively demonstrate that our proposed DCIQ can predict utility-oriented quality within compressed underwater information.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Liao2024Distillation-Based
ER  -

TY  - JOUR
AU  - Ren, B.
AU  - Liu, B.
AU  - Hou, B.
AU  - Wang, Z.
AU  - Yang, C.
AU  - Jiao, L.
TI  - SwinTFNet: Dual-Stream Transformer With Cross Attention Fusion for Land Cover Classification
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 2501505
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2024.3358899
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184004738&doi=10.1109%2fLGRS.2024.3358899&partnerID=40&md5=1bc2d6b300d62ee700105bb51505b47f
AB  - Land cover classification (LCC) is an important application in remote sensing data interpretation. As two common data sources, synthetic aperture radar (SAR) images can be regarded as an effective complement to optical images, which will reduce the influence caused by single-modal data. However, common LCC methods focus on designing advanced network architectures to process single-modal remote sensing data. Few works have been oriented toward improving segmentation performance through fusing multimodal data. In order to deeply integrate SAR and optical features, we propose SwinTFNet, a dual-stream deep fusion network. Through the global context modeling capability of Transformer structure, SwinTFNet models teleconnections between pixels in other regions and pixels in cloud regions for better prediction in cloud regions. In addition, a cross-attention fusion module (CAFM) is proposed to fuse features from optical and SAR data. Experimental results show that our method improves greatly in the classification of clouded images compared with other excellent segmentation methods and achieves the best performance on multimodal data. The source code of SwinTFNet is publicly available at https://github.com/XD-MG/SwinTFNet.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Ren2024SwinTFNet
ER  -

TY  - JOUR
AU  - Dimitrovski, I.
AU  - Kitanovski, I.
AU  - Simidjievski, N.
AU  - Kocev, D.
TI  - In-Domain Self-Supervised Learning Improves Remote Sensing Image Scene Classification
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 8000805
DO  - 10.1109/LGRS.2024.3352926
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182927430&doi=10.1109%2fLGRS.2024.3352926&partnerID=40&md5=ef9b059b7f31048643a76eb9df24db1f
AB  - We investigate the utility of in-domain self-; supervised pretraining of vision models in the analysis of remote sensing imagery. Self-supervised learning (SSL) has emerged as a promising approach for remote sensing image classification due to its ability to exploit large amounts of unlabeled data. Unlike traditional supervised learning, SSL aims to learn representations of data without the need for explicit labels. This is achieved by formulating auxiliary tasks that can be used for pretraining models before fine-tuning them on a given downstream task. A common approach in practice to SSL pretraining is utilizing standard pretraining datasets, such as ImageNet. While relevant, such a general approach can have a suboptimal influence on the downstream performance of models, especially on tasks from challenging domains such as remote sensing. In this letter, we analyze the effectiveness of SSL pretraining by employing the image bidirectional encoder representations from transformers (BERT) pretraining with online tokenizer (iBOT) framework coupled with Vision transformers (ViTs) trained on million aerial image dataset (Million-AID), a large and unlabeled remote sensing dataset. We present a comprehensive study of different self-supervised pretraining strategies and evaluate their effect across 14 downstream datasets with diverse properties. Our results demonstrate that leveraging large in-domain datasets for self-supervised pretraining consistently leads to improved predictive downstream performance, compared to the standard approaches found in practice. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Dimitrovski2024In-Domain
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Jiang, X.
AU  - Zhang, K.
TI  - A transformer-based deep learning approach for fairly predicting post-liver transplant risk factors
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 149
C7  - 104545
DO  - 10.1016/j.jbi.2023.104545
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179127507&doi=10.1016%2fj.jbi.2023.104545&partnerID=40&md5=837da6f8b07190bf1831772acafdfdf8
AB  - Liver transplantation is a life-saving procedure for patients with end-stage liver disease. There are two main challenges in liver transplant: finding the best matching patient for a donor and ensuring transplant equity among different subpopulations. The current MELD scoring system evaluates a patient's mortality risk if not receiving an organ within 90 days. However, the donor-patient matching should also consider post-transplant risk factors, such as cardiovascular disease, chronic rejection, etc., which are all common complications after transplant. Accurate prediction of these risk scores remains a significant challenge. In this study, we used predictive models to solve the above challenges. Specifically, we proposed a deep learning model to predict multiple risk factors after a liver transplant. By formulating it as a multi-task learning problem, the proposed deep neural network was trained to simultaneously predict the five post-transplant risks and achieve equal good performance by exploiting task-balancing techniques. We also proposed a novel fairness-achieving algorithm to ensure prediction fairness across different subpopulations. We used electronic health records of 160,360 liver transplant patients, including demographic information, clinical variables, and laboratory values, collected from the liver transplant records of the United States from 1987 to 2018. The model's performance was evaluated using various performance metrics such as AUROC and AUPRC. Our experiment results highlighted the success of our multi-task model in achieving task balance while maintaining accuracy. The model significantly reduced the task discrepancy by 39 %. Further application of the fairness-achieving algorithm substantially reduced fairness disparity among all sensitive attributes (gender, age group, and race/ethnicity) in each risk factor. It underlined the potency of integrating fairness considerations into the task-balancing framework, ensuring robust and fair predictions across multiple tasks and diverse demographic groups. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Li2024transformer-based
ER  -

TY  - JOUR
AU  - Xie, Y.
AU  - Wu, J.
TI  - HGTHP: a novel hyperbolic geometric transformer hawkes process for event prediction
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 1
SP  - 357
EP  - 374
DO  - 10.1007/s10489-023-05169-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179317544&doi=10.1007%2fs10489-023-05169-0&partnerID=40&md5=78d4be788f215eaa57b7babe449d60f9
AB  - Event sequences with spatiotemporal characteristics have been rapidly produced in various domains, such as earthquakes in seismology, electronic medical records in health care, and transactions in the financial market. These data are discrete events that are continuous and often continue for weeks, months, or years, and past events may trigger subsequent events. In this context, modeling spatiotemporal event sequences and forecasting the occurrence time and marker of the next event has become a hot topic. However, existing models either fail to capture the long-term temporal dependencies or ignore the essential spatial information between sequences. Moreover, existing models learn the influence of past events and predicted future events in Euclidean space, which has been shown to cause a significant distortion in hierarchical structure data. To correctly predict future events from historical events and design interventions and controls to guide the event dynamics to the desired results and inspired by the high capacity of modeling data in hyperbolic space, we proposed a novel hyperbolic graph transformer Hawkes process (HGTHP) model to capture the long-term temporal dependencies and spatial information from historical events with a hierarchical structure. The core concept of the HGTHP is to integrate the learned spatial information into the event embedding as auxiliary information and capture long-short term temporal dependencies from event sequences in non-Euclidean space by a hyperbolic self-attention mechanism. Numerous experiments on synthetic and real-world datasets proved that the proposed model obtains spatiotemporal information from hyperbolic space, and its predictions outperform those of state-of-the-art baselines in both time and marker, proving the proposed model’s effectiveness. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Xie2024HGTHP
ER  -

TY  - JOUR
AU  - Xiao, X.
AU  - Kong, Y.
AU  - Li, R.
AU  - Wang, Z.
AU  - Lu, H.
TI  - Transformer with convolution and graph-node co-embedding: An accurate and interpretable vision backbone for predicting gene expressions from local histopathological image
PY  - 2024
T2  - Medical Image Analysis
VL  - 91
C7  - 103040
DO  - 10.1016/j.media.2023.103040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180010614&doi=10.1016%2fj.media.2023.103040&partnerID=40&md5=0ed5873ca6f19ea9c3899c6dbd78bc54
AB  - Inferring gene expressions from histopathological images has long been a fascinating yet challenging task, primarily due to the substantial disparities between the two modality. Existing strategies using local or global features of histological images are suffering model complexity, GPU consumption, low interpretability, insufficient encoding of local features, and over-smooth prediction of gene expressions among neighboring sites. In this paper, we develop TCGN (Transformer with Convolution and Graph-Node co-embedding method) for gene expression estimation from H&E-stained pathological slide images. TCGN comprises a combination of convolutional layers, transformer encoders, and graph neural networks, and is the first to integrate these blocks in a general and interpretable computer vision backbone. Notably, TCGN uniquely operates with just a single spot image as input for histopathological image analysis, simplifying the process while maintaining interpretability. We validate TCGN on three publicly available spatial transcriptomic datasets. TCGN consistently exhibited the best performance (with median PCC 0.232). TCGN offers superior accuracy while keeping parameters to a minimum (just 86.241 million), and it consumes minimal memory, allowing it to run smoothly even on personal computers. Moreover, TCGN can be extended to handle bulk RNA-seq data while providing the interpretability. Enhancing the accuracy of omics information prediction from pathological images not only establishes a connection between genotype and phenotype, enabling the prediction of costly-to-measure biomarkers from affordable histopathological images, but also lays the groundwork for future multi-modal data modeling. Our results confirm that TCGN is a powerful tool for inferring gene expressions from histopathological images in precision health applications. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Xiao2024Transformer
ER  -

TY  - JOUR
AU  - Zhao, L.
AU  - Tan, G.
AU  - Pu, B.
AU  - Wu, Q.
AU  - Ren, H.
AU  - Li, K.
TI  - TransFSM: Fetal Anatomy Segmentation and Biometric Measurement in Ultrasound Images Using a Hybrid Transformer
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 1
SP  - 285
EP  - 296
DO  - 10.1109/JBHI.2023.3328954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177068297&doi=10.1109%2fJBHI.2023.3328954&partnerID=40&md5=b041cf07ad70cb3ebd0b7aaa811afc35
AB  - Biometric parameter measurements are powerful tools for evaluating a fetus's gestational age, growth pattern, and abnormalities in a 2D ultrasound. However, it is still challenging to measure fetal biometric parameters automatically due to the indiscriminate confusing factors, limited foreground-background contrast, variety of fetal anatomy shapes at different gestational ages, and blurry anatomical boundaries in ultrasound images. The performance of a standard CNN architecture is limited for these tasks due to the restricted receptive field. We propose a novel hybrid Transformer framework, TransFSM, to address fetal multi-anatomy segmentation and biometric measurement tasks. Unlike the vanilla Transformer based on a single-scale input, TransFSM has a deformable self-attention mechanism, so it can effectively process multi-scale information to segment fetal anatomy with irregular shapes and different sizes. We devised a boundary-aware decoder (BAD) to capture more intrinsic local details using boundary-wise prior knowledge, which compensates for the defects of the Transformer in extracting local features. In addition, a Transformer auxiliary segment head is designed to improve mask prediction by learning the semantic correspondence of the same pixel categories and feature discriminability among different pixel categories. Extensive experiments were conducted on clinical cases and benchmark datasets for anatomy segmentation and biometric measurement tasks. The experiment results indicate that our method achieves state-of-the-art performance in seven evaluation metrics compared with CNN-based, Transformer-based, and hybrid approaches. By knowledge distillation, the proposed TransFSM can create a more compact and efficient model with high deploying potential in resource-constrained scenarios. Our study serves as a unified framework for biometric estimation across multiple anatomical regions to monitor fetal growth in clinical practice.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Zhao2024TransFSM
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Peng, J.
AU  - Wang, X.
AU  - Zhang, Z.
AU  - Duan, J.
TI  - Replacing self-attentions with convolutional layers in multivariate long sequence time-series forecasting
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 1
SP  - 522
EP  - 543
DO  - 10.1007/s10489-023-05205-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179696991&doi=10.1007%2fs10489-023-05205-z&partnerID=40&md5=21590b0a21636f645451548ed3c535a8
AB  - Abstract: Transformers have attracted increasing interest in time-series forecasting. However, there are two issues for Multi-Head Self-Attention (MHSA) layers in Multivariate Long Sequence Time-series Forecasting (MLSTF): the massive computation resource consumption and the lack of inductive bias for learning the seasonal and trend pattern of time-series sequences. To address these issues, a systematic method is proposed to replace part of the MHSA layers in Transformers with convolutional layers. Specifically, the self-attention patterns are categorized into four types, i.e., diagonal, vertical, block and heterogeneous patterns. The relationships are explored between convolutional layers and MHSA layers exhibiting different self-attention patterns. Based on which, the evaluation metrics are proposed to decide whether to replace MHSA layers with convolutional layers or not. The experimental results on two representative Transformer-based forecasting models show that our method can achieve competitive results with the original Transformer-based forecasting models and greatly reduce their number of parameters and flops. The performance of models on small data sets has also been greatly improved due to the introduction of convolutional operations. Further, this method is adapted to Transformer-based models for other time series tasks and achieves similar results. Graphical abstract: [Figure not available: see fulltext.]. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2024Replacing
ER  -

TY  - JOUR
AU  - Amador, K.
AU  - Gutierrez, A.
AU  - Winder, A.
AU  - Fiehler, J.
AU  - Wilms, M.
AU  - Forkert, N.D.
TI  - Providing clinical context to the spatio-temporal analysis of 4D CT perfusion to predict acute ischemic stroke lesion outcomes
PY  - 2024
T2  - Journal of Biomedical Informatics
VL  - 149
C7  - 104567
DO  - 10.1016/j.jbi.2023.104567
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179853476&doi=10.1016%2fj.jbi.2023.104567&partnerID=40&md5=60af7e5e541cf122fa3eb61f470261f3
AB  - Acute ischemic stroke is a leading cause of mortality and morbidity worldwide. Timely identification of the extent of a stroke is crucial for effective treatment, whereas spatio-temporal (4D) Computed Tomography Perfusion (CTP) imaging is playing a critical role in this process. Recently, the first deep learning-based methods that leverage the full spatio-temporal nature of perfusion imaging for predicting stroke lesion outcomes have been proposed. However, clinical information is typically not integrated into the learning process, which may be helpful to improve the tissue outcome prediction given the known influence of various factors (i.e., physiological, demographic, and treatment factors) on lesion growth. Cross-attention, a multimodal fusion strategy, has been successfully used to combine information from multiple sources, but it has yet to be applied to stroke lesion outcome prediction. Therefore, this work aimed to develop and evaluate a novel multimodal and spatio-temporal deep learning model that utilizes cross-attention to combine information from 4D CTP and clinical metadata simultaneously to predict stroke lesion outcomes. The proposed model was evaluated using a dataset of 70 acute ischemic stroke patients, demonstrating significantly improved volume estimates (mean error = 19 ml) compared to a baseline unimodal approach (mean error = 35 ml, p < 0.05). The proposed model allows generating attention maps and counterfactual outcome scenarios to investigate the relevance of clinical variables in predicting stroke lesion outcomes at a patient level, helping to provide a better understanding of the model's decision-making process. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Amador2024Providing
ER  -

TY  - JOUR
AU  - Zheng, W.
AU  - Chen, J.
AU  - Zhang, K.
AU  - Yan, J.
AU  - Wang, J.
AU  - Cheng, Y.
AU  - Du, B.
AU  - Chen, D.Z.
AU  - Gao, H.
AU  - Wu, J.
AU  - Xu, H.
TI  - Polygonal Approximation Learning for Convex Object Segmentation in Biomedical Images with Bounding Box Supervision
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 8
SP  - 4522
EP  - 4533
DO  - 10.1109/JBHI.2023.3341699
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180309620&doi=10.1109%2fJBHI.2023.3341699&partnerID=40&md5=cadb113a49e750624b7d19918644bbd8
AB  - As a common and critical medical image analysis task, deep learning based biomedical image segmentation is hindered by the dependence on costly fine-grained annotations. To alleviate this data dependence, in this article, a novel approach, called Polygonal Approximation Learning (PAL), is proposed for convex object instance segmentation with only bounding-box supervision. The key idea behind PAL is that the detection model for convex objects already contains the necessary information for segmenting them since their convex hulls, which can be generated approximately by the intersection of bounding boxes, are equivalent to the masks representing the objects. To extract the essential information from the detection model, a repeated detection approach is employed on biomedical images where various rotation angles are applied and a dice loss with the projection of the rotated detection results is utilized as a supervised signal in training our segmentation model. In biomedical imaging tasks involving convex objects, such as nuclei instance segmentation, PAL outperforms the known models (e.g., BoxInst) that rely solely on box supervision. Furthermore, PAL achieves comparable performance with mask-supervised models including Mask R-CNN and Cascade Mask R-CNN. Interestingly, PAL also demonstrates remarkable performance on non-convex object instance segmentation tasks, for example, surgical instrument and organ instance segmentation.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zheng2024Polygonal
ER  -

TY  - JOUR
AU  - Sahw, P.
AU  - Maity, T.
AU  - Yadav, R.K.
TI  - Cooperative approach for electric vehicle charging: a multi-polynomial regression-based model predictive controller with advanced techniques
PY  - 2024
T2  - Soft Computing
DO  - 10.1007/s00500-023-09469-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181462265&doi=10.1007%2fs00500-023-09469-y&partnerID=40&md5=e72c6542e159cd6b6ce3040381ed6464
AB  - The market share of Electric Vehicles (EVs) is steadily increasing, benefiting the environment and energy crisis. However, the widespread adoption of EVs can negatively impact the smart grid, leading to stress, frequency swings, and power variations. To address this, a multi-polynomial regression-based model predictive controller using the XGBOOST + Relief + AOA technique is developed. It enhances the performance of dispersion frameworks while managing Energy and Voltage Control (EVC) for EV coordination. Initial information outlines input data, including harmonic distortion, unbalanced grids, transformer lifespan, voltage swings, and power loss. Data processing resolves issues, such as improper scaling, missing data, and imbalance. An oversampling technique based on aggregative clustering handles imbalanced data, and independent features are standardized using the concordance correlation coefficient-based power transform (CCC–PT). The proposed EV charging model utilizes an optimization objective function, incorporating XGBOOST, Relief, and AOA techniques. The resulting optimization maintains a balance between exploration and exploitation, minimizing errors and time complexity. The multipolynomial regression-based model predictive controller focuses on voltage and energy control to ensure charge balance. Overall, this implementation optimizes distributed state functioning by considering the impact of EV coordination on EVC. The effectiveness and applicability of this methodology are evaluated across three separate scenarios. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Sahw2024Cooperative
ER  -

TY  - JOUR
AU  - Tong, G.
AU  - Ge, Z.
AU  - Peng, D.
TI  - RSMformer: an efficient multiscale transformer-based framework for long sequence time-series forecasting
PY  - 2024
T2  - Applied Intelligence
VL  - 54
IS  - 2
SP  - 1275
EP  - 1296
DO  - 10.1007/s10489-023-05250-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181525410&doi=10.1007%2fs10489-023-05250-8&partnerID=40&md5=d7e05ec7bfa11c9c5e82cd3654cf54ce
AB  - Long sequence time-series forecasting (LSTF) is a significant and challenging task. Many real-world applications require long-term forecasting of time series. In recent years, Transformer-based models have emerged as a promising solution for addressing LSTF tasks. Nevertheless, the model’s performance is constrained by several issues, including the single time scale, the quadratic calculation complexity of the self-attention mechanism, and the high memory occupation. Based on the limitations mentioned above, we propose a novel approach in this paper, namely the multiscale residual sparse attention model RSMformer, built upon the Transformer architecture. Firstly, a residual sparse attention (RSA) mechanism is devised to select dominant queries for computation, utilizing the attention sparsity criterion. This approach effectively reduces the computational complexity to O(LlogL). Secondly, we employ a multiscale forecasting strategy to iteratively refine the accuracy of prediction results at multiple scales by utilizing up-and-down sampling techniques and cross-scale centralization schemes, which effectively capture the temporal dependencies at different time scales. Extensive experiments on six publicly available datasets show that RSMformer performs significantly better than the compared state-of-the-art benchmarks and excels in the LSTF tasks. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Tong2024RSMformer
ER  -

TY  - JOUR
AU  - Yu, T.
AU  - Zhang, L.
AU  - Liu, H.
AU  - Liu, H.
AU  - Wang, J.
TI  - Service recommendation based on contrastive learning and multi-task learning
PY  - 2024
T2  - Computer Communications
VL  - 213
SP  - 285
EP  - 295
DO  - 10.1016/j.comcom.2023.11.018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177620434&doi=10.1016%2fj.comcom.2023.11.018&partnerID=40&md5=06a110b5546d7006f19297834ce9aca2
AB  - Service recommendation is an efficient method for service-oriented software that can improve software quality. Applications often require the integration of multiple services to create more powerful and complex functionality while saving software development time. However, the vast number of available candidate Web services can impose a heavy burden on software developers’ selection decisions. The existing service recommendation challenges are mainly come from: (1) the development requirements entered by users are too arbitrary (2) the extreme sparsity of invocation records. To address the above challenges, in this paper, we propose a Service Recommendation method based on Contrastive Learning and Multi-task Learning (SRCLML). Specifically, we utilize the Transformer model to extract the development requirements of users, conduct in-depth mining of text descriptions, and extract features of applications. Next, the features are fed into the DNN model to predict the probability that the service will be selected. Moreover, we add a tag judgment task to make it capable of multi-task learning, through which, the training signal information implied can be used as an inductive bias to improve service recommendation capabilities. Additionally, we build three subgraphs based on the global graph, conduct in-depth mining of historical invocation records based on contrastive learning and graph neural network to extract features of applications and services and calculate application preferences for each service. Finally, we combined the above two to obtain the final recommendation service list. Extensive experiments on real-world datasets demonstrate that our method, SRCLML, outperforms several state-of-the-art comparison methods in the domain of service recommendation. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Yu2024Service
ER  -

TY  - JOUR
AU  - Gheewala, S.
AU  - Xu, S.
AU  - Yeom, S.
AU  - Maqsood, S.
TI  - Exploiting deep transformer models in textual review based recommender systems
PY  - 2024
T2  - Expert Systems with Applications
VL  - 235
C7  - 121120
DO  - 10.1016/j.eswa.2023.121120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175622319&doi=10.1016%2fj.eswa.2023.121120&partnerID=40&md5=6287a384f6db1a7f42f4fbb8fef0acfb
AB  - Textual reviews contain fine-grained information that can effectively infer user preferences over the items. Accordingly, the latest studies in the field of recommender systems exploit content-rich review texts to complement user and item representations and improve the ability to make personalized recommendations. Furthermore, the interactive deep learning mechanism can better model the user-item interaction from fine-grained textual reviews compared to traditional recommendation approaches improving the predictive performances. Therefore, it becomes important to investigate the design of existing deep learning methods for review-based recommender systems and innovate to make them capable of meeting desired recommendation schemes. The purpose of this research is to explore the performance of deep learning networks and deep transformer models in review-based recommender systems. In this paper, we conduct a compendious survey of the latest deep learning techniques in review-based recommender systems. Then investigation calls to employ and analyze deep transformer models for the review-based recommender systems. The wide range of experiments shows that deep transformer models can extract interpretable and relevant user/item representations than traditional deep learning networks. The findings indicate that the best deep transformer performance gains the maximum relative improvement (RMSE = 4.6%, MAE = 7.4%) with Amazon electronics, compared to the best outcome from traditional deep learning networks. In the end, this article highlights research gaps and outlines research opportunities for future research in this field. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Gheewala2024Exploiting
ER  -

TY  - JOUR
AU  - Yang, D.
AU  - Li, R.
AU  - Yang, Q.
AU  - Peng, Y.
AU  - Huang, X.
AU  - Zou, J.
TI  - 3D head-talk: speech synthesis 3D head movement face animation
PY  - 2024
T2  - Soft Computing
VL  - 28
IS  - 1
SP  - 363
EP  - 379
DO  - 10.1007/s00500-023-09292-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174163274&doi=10.1007%2fs00500-023-09292-5&partnerID=40&md5=583228609b4f966fe9b87c0625345388
AB  - Speech-driven 3D human face animation has made admirable progress. However, synthesizing 3D facial speakers with head motion is still an unsolved problem. This is because head motion, as a speech-independent appearance representation, is difficult to model by a speech-driven approach. To solve this problem, we propose 3D head-talk, which generates 3D face animations combined with extreme head motion. In this work, we face a key challenge to generate natural head movements that match the speech rhythm. We first form an end-to-end autoregressive model by combining a dual-tower and single-tower Transformer, with a speech encoder encoding the long-term audio environment, a facial grid encoder encoding subtle changes in the vertices of the 3D facial grid, and a single-tower decoder automatically regressing to predict a series of 3D facial animation grids. Next, the predicted 3D facial animation sequence is edited by a motion field generator containing head motion to obtain an output sequence containing extreme head motion. Finally, the natural 3D face animation under extreme head motion is presented in combination with the input audio. The quantitative and qualitative results show that our method outperforms current state-of-the-art methods, and stabilizes the non-area region while maintaining the appearance of extreme head motion. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Yang20243D
ER  -

TY  - JOUR
AU  - Zhao, H.
AU  - Ma, Y.
AU  - Han, Y.
AU  - Tian, C.
AU  - Huang, X.
TI  - T-HSER: Transformer Network Enabling Heart Sound Envelope Signal Reconstruction Based on Low Sampling Rate Millimeter Wave Radar
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 1
SP  - 1616
EP  - 1628
DO  - 10.1109/JIOT.2023.3291051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163512822&doi=10.1109%2fJIOT.2023.3291051&partnerID=40&md5=932220f0dfef4e0b06b6310b8fb8f5d8
AB  - The four stages (first heart sound (S1), systole, second heart sound (S2), and diastole) of heartbeat sounds recorded by contact seismocardiogram (SCG) reflect the health of the heart, but these stages are challenging to measure by noncontact millimeter wave radar. If the sampling rate of millimeter wave radar is increased, this will increase the amount of data storage needed for the long-term monitoring of human vital signs. This article presents an algorithm for reconstructing the envelope of high-frequency heart sound signals using low-frequency millimeter wave radar signals, as well as a heart sound envelope segmentation algorithm based on peak points. Its design principle is a combination of signal processing and a transformer network, which is called T-HSER. This technique maps the low-frequency radar signal into a high-frequency heart sound envelope signal through the transformer network and determines the four different stages of the heart sound using appropriate thresholds. Based on the training of more than 30000 heartbeats of 25 healthy subjects and the prediction evaluation of six subjects, the T-HSER algorithm is shown to reconstruct the high-frequency heart sound envelope signal with high correlation. Moreover, the mean correlation can reach 0.85 on one minute of data, which is higher than that of the bidirectional long short-term memory algorithm, and can effectively distinguish the four stages of the heart sound so that the mean absolute error (MAE) between the predicted value and the ground truth of S1 and S2 is within a tolerable range (70 ms). At the same time, the algorithm is suitable for low sampling rate radar, which greatly reduces the amount of data storage required.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhao2024T-HSER
ER  -

TY  - JOUR
AU  - Benzenati, T.
AU  - Kallel, A.
AU  - Kessentini, Y.
TI  - STF-Trans: A two-stream spatiotemporal fusion transformer for very high resolution satellites images
PY  - 2024
T2  - Neurocomputing
VL  - 563
C7  - 126868
DO  - 10.1016/j.neucom.2023.126868
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174399006&doi=10.1016%2fj.neucom.2023.126868&partnerID=40&md5=70094aa4cc4197b000b5b05f95dfa504
AB  - Spatiotemporal satellite image fusion is regarded as an effective approach to address the limitations of a single optical sensor and generate data with high spatial and temporal resolutions. Thanks to the recent advances of Deep Learning, spatiotemporal fusion has gained a significant performance improvement. However, most models require at least three inputs, including a high resolution one at a prior date, to make the prediction at the desired date. Such a requirement is not always guaranteed in practice, in particular due to the high cost of high resolution image and bad atmospheric conditions. In the last few years, Transformers have achieved tremendous performance on several computer vision tasks compared to convolutional neural networks. Inspired by the new trend, we proposed an end-to-end two-stream SpatioTemporal fusion technique based on encoder–decoder transformer architecture, termed STF-Trans. To deal with a complexity and high-cost of data preparation, the proposed approach aims to fuse a coarse-resolution image with high temporal resolution, and a very high resolution Google Earth image, to produce a very high resolution image at the desired date. The proposed technique employs a two-stream convolutional network to capture both temporal and spatial features from the inputs, and then the encoder–decoder transformer captures long-range dependency of the latter and generates a more efficient image representation from the shallow features. Finally, a shallow network maps the features into the desired fused image. The experimental results show that the proposed method outperforms the current state-of-the-art techniques at both quantitative and qualitative evaluations. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Benzenati2024STF-Trans
ER  -

TY  - JOUR
AU  - Blinov, P.
AU  - Kokh, V.
TI  - Medical Profile Model: Scientific and Practical Applications in Healthcare
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 1
SP  - 450
EP  - 458
DO  - 10.1109/JBHI.2023.3321132
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174848989&doi=10.1109%2fJBHI.2023.3321132&partnerID=40&md5=c9666f3de4dd7643474ed68d2726e2e3
AB  - The article researches the problem of representation learning for electronic health records. We present the patient histories as temporal sequences of diseases for which embeddings are learned in an unsupervised setup with a transformer-based neural network model. Additionally the embedding space includes demographic parameters which allow the creation of generalized patient profiles and successful transfer of medical knowledge to other domains. The training of such a medical profile model has been performed on a dataset of more than one million patients. Detailed model analysis and its comparison with the state-of-the-art method show its clear advantage in the diagnosis prediction task. Further, we show two applications based on the developed profile model. First, a novel Harbinger Disease Discovery method allowing to reveal disease associated hypotheses and potentially are beneficial in the design of epidemiological studies. Second, the patient embeddings extracted from the profile model applied to the insurance scoring task allow significant improvement in the performance metrics.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Blinov2024Medical
ER  -

TY  - JOUR
AU  - Huo, J.
AU  - Wang, L.
AU  - Lu, Z.
AU  - Wen, X.
TI  - Vehicular Crowdsensing Inference and Prediction With Multi Training Graph Transformer Networks
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 1
SP  - 217
EP  - 227
DO  - 10.1109/JIOT.2023.3305006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168727174&doi=10.1109%2fJIOT.2023.3305006&partnerID=40&md5=d024ced952f64ce5c540a2ea0cffb245
AB  - Vehicular crowdsensing has emerged as a prominent sensing paradigm in the Internet of Things (IoT), and its powerful sensing and computing capabilities can provide sufficient data for various applications. To reduce the cost while ensuring the sensing quality, sparse mobile crowdsensing has been proposed, which only requires data from some sensing areas and utilizes spatiotemporal correlation to infer data for other unsensed areas. In real vehicular crowdsensing scenarios, not only the current period sensing data is required to be inferred but also the prediction of the future whole sensing map is of great significance. In this article, we propose multitask pretraining graph transformer networks (MT-PTGTN) that incorporate graph neural networks (GNNs) and transformer to support both data inference and prediction for vehicular crowdsensing. Comprehensively considering the surface and underlying patterns among the sensing grids, MT-PTGTN utilizes pre-training topological mining GNNs and graph attention networks to model two patterns, respectively, which contributes to improving inference accuracy. The transformer with the multilayer attention mechanism is incorporated to capture the temporal correlation of the sensing data and predict the future complete sensing map. Furthermore, to prevent the error propagation from the inference task to the subsequent prediction task, we propose a dynamic multi-task learning framework that dynamically adjusts the weights of tasks during training. The experimental evaluation on the real-world dataset demonstrates the superiority of MT-PTGTN in data inference and prediction. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Huo2024Vehicular
ER  -

TY  - JOUR
AU  - Zhang, Q.
AU  - Zhang, Y.
AU  - Bao, F.
AU  - Liu, Y.
AU  - Zhang, C.
AU  - Liu, P.
TI  - Incorporating stock prices and text for stock movement prediction based on information fusion
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 127
C7  - 107377
DO  - 10.1016/j.engappai.2023.107377
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175422416&doi=10.1016%2fj.engappai.2023.107377&partnerID=40&md5=c1ebfc3802e7aa263403b70911dd271f
AB  - Forecasting stock market via historical financial data is an important issue for market participants because even if the prediction accuracy is only slightly improved, better trading decisions can be made. Historical financial data has evolved from the initial single text or stock price to the fusion of multisource information. However, how to adopt a method that adaptively fuses numerical data and text so that the prediction model can learn time series information in parallel remains a challenging problem. In this paper, we propose a collaborative attention Transformer fusion model for stock movement prediction (CoATSMP), including parallel extraction of text and prices features, parameter-level fusion and a joint feature processing module, that can successfully deeply fuse text and stock prices in view of the soft fusion method. The experiments show that (1) the proposed approach outperforms the baselines, (2) the soft fusion method proposed in this paper has better modeling performance under the CoATSMP framework, which brings greater improvement in the prediction performance, (3) models containing prices and text are better than those using only one data source, and (4) quantitative analysis of experimental results indicates that text plays a relatively more critical role in the CoATSMP framework. Real simulation trading shows that the trading strategy based on CoATSMP can significantly improve profits; thus, the model has practical application value. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhang2024Incorporating
ER  -

TY  - JOUR
AU  - Wu, R.
AU  - Wen, X.
AU  - Yuan, L.
AU  - Xu, H.
AU  - Liu, Y.
TI  - Visual Tracking based on deformable Transformer and spatiotemporal information
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 127
C7  - 107269
DO  - 10.1016/j.engappai.2023.107269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173287233&doi=10.1016%2fj.engappai.2023.107269&partnerID=40&md5=99b4901b00393ee02eba2d52823a5d98
AB  - At present, the Transformer-based Siamese network visual tracking method has shown strong influence and achieved remarkable results on various experimental sets. Especially on the premise of training on large-scale datasets, attention-based Transformer structures have been widely used. However, many trackers ignore the fusion enhancement of local and global features, and lack the extraction of spatiotemporal information. At the same time, the original Transformer structural features are redundant and will be affected by irrelevant parts beyond the region of interest. To address these issues, we propose a new method (DTS) based on deformable Transformer and spatiotemporal information. As a Siamese structure, it contains multiple modules. The template frame gets local to global important features through 2D CNN and Self-Attention. The search frame gets spatiotemporal information of interest through 3D CNN and SFM and DAM and then uses Cross-Attention to establish the correlation between them, and finally predict the bounding box of the target through the corner points. In order to verify the effectiveness of our method, we conduct experiments on the LaSOT, GOT-10K, TrackingNet, VOT2018, OTB100 and VAU123 benchmark datasets, the result index is 2%–3% higher than the baseline method. The model structure is simplified without affecting the performance, and the FPS reaches 50. The results show that our proposed tracker is very competitive compared with other state-of-the-art methods. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wu2024Visual
ER  -

TY  - JOUR
AU  - Liao, J.
AU  - Hu, J.
AU  - Chen, P.
AU  - Zhu, L.
AU  - Wu, Y.
AU  - Cai, Z.
AU  - Wu, H.
AU  - Wang, M.
TI  - Prediction of the transient emission characteristics from diesel engine using temporal convolutional networks
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 127
C7  - 107227
DO  - 10.1016/j.engappai.2023.107227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173216270&doi=10.1016%2fj.engappai.2023.107227&partnerID=40&md5=f4dca4fbd609b62d409707e20bf5a892
AB  - In order to predict the transient emission characteristics from diesel engine accurately and quickly, a novel prediction model, based on temporal convolutional networks (TCN) that incorporates the dilated convolutions and residual connections, was presented in the paper. Firstly, 1800 samples from the World Harmonized Transient Cycle (WHTC) were employed to train and validate the model. A Random Forest algorithm was used to select six top important variables as inputs to reduce the data dimensionality. Then the effect of model hyperparameters on the prediction performance was discussed and the optimal hyperparameter combination was obtained by a particle swarm optimization (PSO) algorithm. The optimized TCN model showed a coefficient of determination value (R2) above 0.972 for training dataset and 0.941 for validation dataset, respectively. The root mean squared error (RMSE) and the mean absolute error (MAE) were relatively low. Finally, the measured data from World Harmonized Steady Cycle (WHSC) was used to test model, and the average R2 value of 0.936 demonstrated that TCN model has excellent robustness and generalization. Moreover, a comparative investigation between TCN model and other advanced algorithms, including BP, GBRT, XGBoost, RNN, LSTM and Transformer, was also conducted. The result showed that TCN model has not only higher accuracy, but also has less computing time. This demonstrates that it is a promising method to predict the emission characteristics of diesel engine. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Liao2024Prediction
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Li, X.
AU  - Li, X.
AU  - Chen, W.
AU  - Shen, L.
AU  - Li, X.
AU  - Deng, Y.
TI  - Two-stream regression network for dental implant position prediction
PY  - 2024
T2  - Expert Systems with Applications
VL  - 235
C7  - 121135
DO  - 10.1016/j.eswa.2023.121135
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168551875&doi=10.1016%2fj.eswa.2023.121135&partnerID=40&md5=9392d51d3a06ee25214a6c808354728e
AB  - In implant prosthesis treatment, the design of the surgical guide heavily relies on the manual location of the implant position, which is subjective and prone to doctor's experiences. When deep learning based methods has started to be applied to address this problem, the space between teeth are various and some of them might present similar texture characteristic with the actual implant region. Both problems make a big challenge for the implant position prediction. In this paper, we develop a two-stream implant position regression framework (TSIPR), which consists of an implant region detector (IRD) and a multi-scale patch embedding regression network (MSPENet), to address this issue. For the training of IRD, we extend the original annotation to provide additional supervisory information, which contains much more rich characteristic and do not introduce extra labeling costs. A multi-scale patch embedding module is designed for the MSPENet to adaptively extract features from the images with various tooth spacing. The global–local feature interaction block is designed to build the encoder of MSPENet, which combines the transformer and convolution for enriched feature representation. During inference, the RoI mask extracted from the IRD is used to refine the prediction results of the MSPENet. Extensive experiments on a dental implant dataset through five-fold cross-validation demonstrated that the proposed TSIPR achieves superior performance than existing methods. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Yang2024Two-stream
ER  -

TY  - JOUR
AU  - Han, I.
AU  - Kim, K.-J.
TI  - Deep ensemble learning of tactics to control the main force in a real-time strategy game
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 4
SP  - 12059
EP  - 12087
DO  - 10.1007/s11042-023-15742-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163153207&doi=10.1007%2fs11042-023-15742-x&partnerID=40&md5=f7e5c36d65a6228c2ce69b975c12b8ca
AB  - Professional StarCraft game players are likely to focus on the management of the most important group of units (called the main force) during gameplay. Although macro-level skills have been observed in human game replays, there has been little study of the high-level knowledge used for tactical decision-making, nor exploitation thereof to create AI modules. In this paper, we propose a novel tactical decision-making model that makes decisions to control the main force. We categorized the future movement direction of the main force into six classes (e.g., toward the enemy’s main base). The model learned to predict the next destination of the main force based on the large amount of experience represented in replays of human games. To obtain training data, we extracted information from 12,057 replay files produced by human players and obtained the position and movement direction of the main forces through a novel detection algorithm. We applied convolutional neural networks and a Vision Transformer to deal with the high-dimensional state representation and large state spaces. Furthermore, we analyzed human tactics relating to the main force. Model learning success rates of 88.5%, 76.8%, and 56.9% were achieved for the top-3, -2, and -1 accuracies, respectively. The results show that our method is capable of learning human macro-level intentions in real-time strategy games. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Han2024Deep
ER  -

TY  - JOUR
AU  - Jin, Q.
AU  - Zhang, X.
AU  - Xiao, X.
AU  - Wang, Y.
AU  - Xiang, S.
AU  - Pan, C.
TI  - Preformer: Simple and Efficient Design for Precipitation Nowcasting With Transformers
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 21
C7  - 1000205
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2023.3325628
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174860394&doi=10.1109%2fLGRS.2023.3325628&partnerID=40&md5=d446d06f7a7548b79e529b5d389405c8
AB  - The primary objective of precipitation nowcasting is to predict precipitation patterns several hours in advance. Recent studies have emphasized the potential of deep learning methods for this task. To harness the correlations among various meteorological elements, existing frameworks project multiple meteorological elements into a latent space and then utilize convolutional-recurrent networks for future precipitation prediction. Although effective, the escalating model complexity may impede practical applications. This letter develops the Preformer, a streamlined Transformer framework for precipitation nowcasting that efficiently captures global spatiotemporal dependencies among multiple meteorological elements. The Preformer implements an encoder-translator-decoder architecture, where the encoder integrates spatial features of multiple elements, the translator models spatiotemporal dynamics, and the decoder combines spatiotemporal information to forecast future precipitation. Without introducing complex structures or strategies, the Preformer achieves state-of-the-art performance even with the least parameters.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Jin2024Preformer
ER  -

TY  - JOUR
AU  - Guan, Y.
AU  - Ding, W.
AU  - Liao, S.
AU  - Yang, W.
TI  - CycMixer: A simplified and rapidly converging object detection network of query based on cycle mixing
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 127
C7  - 107220
DO  - 10.1016/j.engappai.2023.107220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173541138&doi=10.1016%2fj.engappai.2023.107220&partnerID=40&md5=484d6a088c491157384f4e35c376df57
AB  - The query-based object detection models are improvement of transformer. Using the learnable query, they complete the transition from traditional dense detection to sparse detection. However, such models have the weaknesses of slow convergence speed, poor adaptability to target changes, and additional networks. The CycMixer proposed in this paper uses multi-scale granule cluster sampling for encoding, avoiding a large number of parameters brought by the explicit structure. It adopts the cycle mixing module to improve the adaptability and increase the receptive field to cope with the change in detection targets by means of adaptive channel sampling and cycle spatial sampling. Firstly, the query extracted by backbone is decoupled into content vector and positional vector. Then the multi-head attention mechanism generates offsets. Secondly, the multi-scale feature map obtained by backbone and the transformed position enter the multi-scale granule cluster sampling stage. The stage consists of multi-scale feature space generation and granule cluster sampling. In addition, offsets and original positional vectors are converted to a new positional vector, which is decoded to get the bounding box. Finally, the content vector and the sampled matrix enter the cycle mixing. Cycle mixing consists of adaptive channel mixing and cycle spatial mixing. The mixed content vector is updated by the post feed-forward network (FFN) to receive a new content vector. Another FFN outputs the predicted categories. Compared with the existing detectors, the AP of our method on MS COCO dataset can reach 44.0 in 12 epochs and 46.0 in 36 epochs of training, which has obvious advantages in the convergence speed and the simplicity of the model. Experimental results on the cityscapes dataset also demonstrated the superiority of the method. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Guan2024CycMixer
ER  -

TY  - JOUR
AU  - Zhao, S.
AU  - Li, W.
AU  - Liu, Z.
AU  - Pang, T.
AU  - Yang, Y.
AU  - Qiang, N.
AU  - Zhao, J.
AU  - Li, B.
AU  - Lei, B.
AU  - Han, J.
TI  - End-to-End Prediction of EGFR Mutation Status with Denseformer
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 1
SP  - 54
EP  - 65
DO  - 10.1109/JBHI.2023.3307295
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168736596&doi=10.1109%2fJBHI.2023.3307295&partnerID=40&md5=7a8beda739d649809eedeb6fbcb4e108
AB  - Accurate genotyping of the epidermal growth factor receptor (EGFR) is critical for the treatment planning of lung adenocarcinoma. Currently, clinical identification of EGFR genotyping highly relies on biopsy and sequence testing which is invasive and complicated. Recent advancements in the integration of computed tomography (CT) imagery with deep learning techniques have yielded a non-invasive and straightforward way for identifying EGFR profiles. However, there are still many limitations for further exploration: 1) most of these methods still require physicians to annotate tumor boundaries, which are time-consuming and prone to subjective errors; 2) most of the existing methods are simply borrowed from computer vision field which does not sufficiently exploit the multi-level features for final prediction. To solve these problems, we propose a Denseformer framework to identify EGFR mutation status in a real end-to-end fashion directly from 3D lung CT images. Specifically, we take the 3D whole-lung CT images as the input of the neural network model without manually labeling the lung nodules. This is inspired by the medical report that the mutational status of EGFR is associated not only with the local tumor nodules but also with the microenvironment surrounded by the whole lung. Besides, we design a novel Denseformer network to fully explore the distinctive information across the different level features. The Denseformer is a novel network architecture that combines the advantages of both convolutional neural network (CNN) and Transformer. Denseformer directly learns from the 3D whole-lung CT images, which preserves the spatial location information in the CT images. To further improve the model performance, we designed a combined Transformer module. This module employs the Transformer Encoder to globally integrate the information of different levels and layers and use them as the basis for the final prediction. The proposed model has been tested on a lung adenocarcinoma dataset collected at the Affiliated Hospital of Zunyi Medical University. Extensive experiments demonstrated the proposed method can effectively extract meaningful features from 3D CT images to make accurate predictions. Compared with other state-of-the-art methods, Denseformer achieves the best performance among current methods using deep learning to predict EGFR mutation status based on a single modality of CT images.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhao2024End-to-End
ER  -

TY  - JOUR
AU  - Zhao, X.
AU  - Qi, Z.
AU  - Wang, S.
AU  - Wang, Q.
AU  - Wu, X.
AU  - Mao, Y.
AU  - Zhang, L.
TI  - RCPS: Rectified Contrastive Pseudo Supervision for Semi-Supervised Medical Image Segmentation
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 1
SP  - 251
EP  - 261
DO  - 10.1109/JBHI.2023.3322590
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174859318&doi=10.1109%2fJBHI.2023.3322590&partnerID=40&md5=b877c4169aa3e8f30b4b48aa0f76cc9b
AB  - Medical image segmentation methods are generally designed as fully-supervised to guarantee model performance, which requires a significant amount of expert annotated samples that are high-cost and laborious. Semi-supervised image segmentation can alleviate the problem by utilizing a large number of unlabeled images along with limited labeled images. However, learning a robust representation from numerous unlabeled images remains challenging due to potential noise in pseudo labels and insufficient class separability in feature space, which undermines the performance of current semi-supervised segmentation approaches. To address the issues above, we propose a novel semi-supervised segmentation method named as Rectified Contrastive Pseudo Supervision (RCPS), which combines a rectified pseudo supervision and voxel-level contrastive learning to improve the effectiveness of semi-supervised segmentation. Particularly, we design a novel rectification strategy for the pseudo supervision method based on uncertainty estimation and consistency regularization to reduce the noise influence in pseudo labels. Furthermore, we introduce a bidirectional voxel contrastive loss in the network to ensure intra-class consistency and inter-class contrast in feature space, which increases class separability in the segmentation. The proposed RCPS segmentation method has been validated on two public datasets and an in-house clinical dataset. Experimental results reveal that the proposed method yields better segmentation performance compared with the state-of-the-art methods in semi-supervised medical image segmentation.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhao2024RCPS
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Luo, X.
AU  - Zhou, H.
TI  - A ship-radiated noise classification method based on domain knowledge embedding and attention mechanism
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 127
C7  - 107320
DO  - 10.1016/j.engappai.2023.107320
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174704783&doi=10.1016%2fj.engappai.2023.107320&partnerID=40&md5=5348808750a85769794ddc83d1e4f4a0
AB  - Ship classification based on machine learning (ML) has proven to be a significant underwater acoustic research direction. One of the critical challenges rests with how to embed domain signal knowledge into ML models to obtain suitable features that highly correlate with the classification and create better predictors. In this paper, a novel ML-based ship classification model, Hierarchical Underwater Acoustic Transformer (HUAT), is proposed to improve the classification performance. Firstly, the Detection of Envelope Modulation on Noise (DEMON) spectra of ship-radiated noise signals are estimated by cyclostationary analysis. The motivation for using a DEMON-based preprocessing scheme is that valuable propeller information can be revealed by exploiting the second-order cyclostationarity of ship-radiated noise signals. Secondly, the useful features of DEMON spectra are enhanced using a multi-head self-attention module, and the potential features of the Mel spectrograms are extracted employing a Convolutional Neural Network (CNN) module. The two kinds of features are fused to provide ship classification patterns. The challenge of feature learning in the deep classification model is reduced by leveraging domain-related classification knowledge. Finally, the Swin Transformer, based on shifted window self-attention mechanism, is used to learn high-level feature representations and conduct ship classification. Experimental results show that the HUAT model achieves excellent classification performance on ship-radiated noise datasets, ShipsEar and DeepShip. And its classification efficiency is better than the model based on traditional Transformer architecture. In addition, the proposed method provides technical support for the underwater intelligent system capable of automatically sensing sailing vessels and recognizing vessel types. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Chen2024ship-radiated
ER  -

TY  - JOUR
AU  - Zhang, Q.
AU  - Liu, Q.
AU  - Ye, Q.
TI  - An attention-based temporal convolutional network method for predicting remaining useful life of aero-engine
PY  - 2024
T2  - Engineering Applications of Artificial Intelligence
VL  - 127
C7  - 107241
DO  - 10.1016/j.engappai.2023.107241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174048104&doi=10.1016%2fj.engappai.2023.107241&partnerID=40&md5=adbd2fd840318a5989e0b0d39bfae52a
AB  - Researches on Remaining Useful Life (RUL) prediction of aero-engine could help to make maintenance plans, improve operation reliabilities and reduce maintenance costs. While deep learning methods have been widely used in RUL prediction research, most deep learning-based RUL prediction methods tend to treat input features as equally important. Contributions of different channels and time steps from input features are not considered simultaneously, which will inevitably affect efficiencies and accuracies of RUL prediction. Therefore, a novel deep learning-based RUL prediction method named attention-based temporal convolutional network (ATCN) is proposed in this article. First, an improved self-attention mechanism is used to weight contributions of different time steps from input features. Input features of time steps closely related to RUL are enhanced by the improved self-attention mechanism, which could improve efficiencies of feature extraction in a network. Then, a temporal convolutional network is constructed to capture long-term dependent information and extract feature representations from weighted features of the improved self-attention mechanism. Next, a squeeze-and-excitation mechanism is adopted to weight contributions of different channels from feature representations, which could help to improve prediction accuracies of the network. Finally, a fully connected layer is constructed to fuse weighted features to output RUL values. A commercial modular aero-propulsion system simulation (C-MAPSS) dataset from NASA is applied to verify effects of the proposed method. Performances of the proposed method are compared with those based on different neural network architectures, such as CNN, RNN, LSTM, DCNN, TCN, BiGRU-TSAM, AGCNN and channel attention plus Transformer. Results show that the proposed method could yield results with higher accuracy for RUL prediction of aero-engine than other methods. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Zhang2024attention-based
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Liu, D.
AU  - Zhao, L.
AU  - Zhang, J.
AU  - Liu, J.
TI  - Evidence Mining for Interpretable Charge Prediction via Prompt Learning
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 4
SP  - 4556
EP  - 4566
DO  - 10.1109/TCSS.2022.3178551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131732207&doi=10.1109%2fTCSS.2022.3178551&partnerID=40&md5=c63bcb80910e324643bb0d58d49d45b6
AB  - Nowadays, more and more researchers are committed to applying artificial intelligence technology to the legal field to support decision-making. Charge prediction is a subtask of legal judgment prediction (LJP). Its purpose is to analyze the fact description of natural language text and predict a charge corresponding to a case. At present, most of the research takes charge prediction as a multiclass classification task, which leads to unsatisfactory interpretation due to the weak semantic correlation between the fact descriptions and charge labels. In order to solve this problem, we propose a method of generative evidence mining based on prompt learning. Specifically, in the training phase, we reformulate the charge labels into the prompt template that we design to enhance the semantic correlation between the charge labels and the fact descriptions. In the testing phase, the charge labels are generated via the model based on prompt learning. Meanwhile, we calculate the attention score of each sentence from the multihead self-attention in the transformer encoder and choose the sentence with the highest attention score as the evidence. Our experimental results on a real dataset show that our method is better than the traditional fine-tuning-based classification method. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Li2024Evidence
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Yu, C.
AU  - Yan, M.
AU  - Sangaiah, A.K.
AU  - Wu, Y.
TI  - Dark-Side Avoidance of Mobile Applications with Data Biases Elimination in Socio-Cyber World
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 4
SP  - 4955
EP  - 4964
DO  - 10.1109/TCSS.2023.3264696
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153092040&doi=10.1109%2fTCSS.2023.3264696&partnerID=40&md5=f0df4f13d84d1cb16b0ab2b047a03d22
AB  - The accessibility of mobile apps takes into account the rights and interests of various social groups, which is vital for the millions of smartphone users who are visually impaired given the variety of mobile applications available on Google Play and the App Store. Most application icons, however, lack natural language labels. It is challenging for these users to engage with mobile phones utilizing screen readers featured in mobile operating systems. Millions of visually impaired smartphone Internet users' inability to communicate with mobile applications have become the socio-cyber world's dark side. COALA is a pilot work that solves this issue by generating the textual label from the imaging icon automatically. However, most icon datasets have imbalance distributions in the real-world scenario that only a few categories have rich-resource labeled samples, and the major rest categories have very limited samples. To address the data imbalance problem in the icon label generation task, we provide an interconnected two-stream language model with mean teacher learning, which learns a generalized feature representation from divergent data distributions. Extensive experiments demonstrate the superiority of our two-stream language model over previous single-language models on different low-resource datasets. More experimental results reveal that our method outperforms the COALA model by a wide margin in decreasing the dark side of the socio-cyber world. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Ma2024Dark-Side
ER  -

TY  - JOUR
AU  - Yu, F.
AU  - Wang, X.
AU  - Sali, R.
AU  - Li, R.
TI  - Single-Cell Heterogeneity-Aware Transformer-Guided Multiple Instance Learning for Cancer Aneuploidy Prediction From Whole Slide Histopathology Images
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 1
C7  - 3262454
SP  - 134
EP  - 144
DO  - 10.1109/JBHI.2023.3262454
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151561309&doi=10.1109%2fJBHI.2023.3262454&partnerID=40&md5=22375eaf68e950999d56700ff198bdf2
AB  - Aneuploidy is a hallmark of aggressive malignancies associated with therapeutic resistance and poor survival. Measuring aneuploidy requires expensive specialized techniques that are not clinically applicable. Deep learning analysis of routine histopathology slides has revealed associations with genetic mutations. However, existing studies focus on image tiles, and there is no prior work that predicts aneuploidy using single-cell analysis. Here, we present a single-cell heterogeneity-aware and transformer-guided deep learning framework to predict aneuploidy from whole slide histopathology images. First, we perform nuclei segmentation and classification to obtain individual cancer cells, which are clustered into multiple subtypes. The cell subtype distributions are computed to measure cancer cell heterogeneity. Additionally, morphological features of different cell subtypes are extracted. Further, we leverage a multiple instance learning module with Transformer, which encourages the network to focus on the most informative cancer cells. Lastly, a hybrid network is built to unify cell heterogeneity, morphology, and deep features for aneuploidy prediction. We train and validate our method on two public datasets from TCGA: lung adenocarcinoma (LUAD) and head and neck squamous cell carcinoma (HNSC), with 339 and 245 patients. Our model achieves promising performance with AUC of 0.818 (95% CI: 0.718-0.919) and 0.827 (95% CI: 0.704-0.949) on the LUAD and HNSC test sets, respectively. Through extensive ablation and comparison studies, we demonstrate the effectiveness of each component of the model and superior performance over alternative networks. In conclusion, we present a novel deep learning approach to predict aneuploidy from histopathology images, which could inform personalized cancer treatment. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Yu2024Single-Cell
ER  -

TY  - JOUR
AU  - Naseem, U.
AU  - Khushi, M.
AU  - Kim, J.
AU  - Dunn, A.G.
TI  - Hybrid Text Representation for Explainable Suicide Risk Identification on Social Media
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
VL  - 11
IS  - 4
SP  - 4663
EP  - 4672
DO  - 10.1109/TCSS.2022.3184984
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134270060&doi=10.1109%2fTCSS.2022.3184984&partnerID=40&md5=165a462900fc536c6674601459f79210
AB  - Social media data that characterize users can provide mental health signals, including suicide risks. Existing methods for suicide risk identification on social media have demonstrated promising results; however, the limitation of existing methods is that they are unable to capture low- and high-level features with complex structured data on social media and are incapable of explaining the predicted labels. Explainable models are more useful when translated, so we aimed to evaluate a novel method that would produce explainable models. This article presents a hybrid text representation method that integrates word and document-level text representations to explain suicide risk identification on social media. The proposed method is then fed to a transformer-based encoder with ordinal classification to determine suicide risk. Our results show that our method outperforms state-of-the-art baselines with an FScore of 0.79 (an absolute increase of 15%) on a public suicide dataset. Our method shows that an explainable model can perform at a comparable level to the best nonexplainable models but has advantages if translated for use in clinical and public health practice. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Naseem2024Hybrid
ER  -

TY  - JOUR
AU  - Ye, W.
AU  - Zhang, W.
AU  - Lei, W.
AU  - Zhang, W.
AU  - Chen, X.
AU  - Wang, Y.
TI  - Remote sensing image instance segmentation network with transformer and multi-scale feature representation
PY  - 2023
T2  - Expert Systems with Applications
VL  - 234
C7  - 121007
DO  - 10.1016/j.eswa.2023.121007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165869213&doi=10.1016%2fj.eswa.2023.121007&partnerID=40&md5=f6af60b78936adf0f5fe1fcad63ea5b3
AB  - The goal of remote sensing image (RSI) instance segmentation is to perform instance-level semantic parsing of its contents. Aside from classifying and locating regions of interest (RoI), it also requires assigning finer pixel-wise annotations to objects. However, RSI often suffers from cluttered backgrounds, variable object scales, and complex object edge contours, making the instance segmentation task more challenging. In this work, we analytically customize an instance segmentation model that is more suitable for RSI. Specifically, we propose three novel modules for a region-based instance segmentation framework, namely Channel-Spatial Attention Module (CSA), Multi-Scale Aware Module (MSA), and Semantic Relation Learning Module (SRL). Among them, feature calibration performed by CSA can alleviate the semantic gap between low-level features and high-level semantics in both channel and spatial dimensions. Inheriting the capabilities of both the convolutional neural network (CNN) and the Transformer, SRL can help the network integrate both neighborhood features and long-range dependencies for instance semantic prediction. The MSA module designs a cascaded residual structure with different receptive fields to model the scale variation of objects in RSI. Experimental results on challenging ISAID, NWPU VHR-10, SSDD, BITTC and HRSID datasets demonstrate the superiority of our method, achieving mask APs of 40.2%, 68.2%, 68.4%, 50.4% and 55.8% respectively. Code and pretrained models are available at https://github.com/Sherlock1018/RSIISN. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ye2023Remote
ER  -

TY  - JOUR
AU  - Guo, T.
AU  - Wang, H.
AU  - Zhang, M.
AU  - Liu, Y.
AU  - Zhang, F.
TI  - Fast and highly coupled model for time series forecasting
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 1
SP  - 2123
EP  - 2143
DO  - 10.1007/s11042-023-15787-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159116646&doi=10.1007%2fs11042-023-15787-y&partnerID=40&md5=ea27fde625ace40e36a4c862493cc6da
AB  - Transformer-based methods have shown great potential for time series forecasting problems. However, they are difficult to use for long sequence time-series forecasting (LSTF) owing to high computational costs and memory requirements. In this paper, we propose a fast and highly coupled model that builds a feature mapping module (F-Map) to adjust the sequence feature distribution. It generates more feature information revealing the intrinsic association through low-cost linear operations on the time series, reduce the redundancy of the feature sequence to reduce the encoder computation. Then, a conditional convolutional network (ConNet) is built to learn a specific convolutional kernel for each input sequence. It can increase the capacity of the network while maintaining efficient inference and improve model performance while maintaining the coupling between sequences. The results of the experiments on five real datasets reveal that, compared to the state-of-the-art model, the proposed model exhibits 10.91% and 9.26% reduction in the mean squared error on multivariate and univariate time-series predictions, respectively. Furthermore, it outperforms other transformer-based models. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Guo2024Fast
ER  -

TY  - JOUR
AU  - Lu, P.
AU  - Xue, J.
TI  - Combining transformer-based model and GCN to predict ICD codes from clinical records
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 282
C7  - 111113
DO  - 10.1016/j.knosys.2023.111113
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175483105&doi=10.1016%2fj.knosys.2023.111113&partnerID=40&md5=4d7ea09ac63eec7661a78ea74cb92517
AB  - Automatic International Classification of Diseases (ICD) coding is a method of automatically classifying diseases through a computer program based on rules of etiology and clinical presentation, and representing them through codes, which are widely used to assist in medical reimbursement and reporting of patient health status. With the application of machine learning and deep learning, the accuracy of automatic ICD coding methods has improved considerably. However, this has been accompanied by problems such as insufficient pre-training of text in the models and increased computational complexity along with improved prediction accuracy. In this work we propose an approach called TF-GCN to counter this problem. Firstly, a more accurate and concise feature representation is obtained by feature extraction of both clinical records and ICD codes through the transformer-based model. Secondly, the node features, document features, and relationships between them in the obtained clinical records are input to the GCN for training. Next, a pseudo labeling attention mechanism is added to eliminate the noise generated in the feature extraction process. Finally, the features of the clinical records are compared with the features of the ICD codes for similarity to obtain the classification results. This can not only reduce computational redundancy, but also obtain more accurate classification features. In the real-world MIMIC-III dataset, we compare the proposed algorithm with 11 automatic ICD coding methods to validate the performance of TF-GCN. According to experimental findings, our suggested strategy outperforms the standard evaluation metrics Mif (0.589), MiAUC (0.989), and P@8 (0.758). © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Lu2023Combining
ER  -

TY  - JOUR
AU  - Bui, V.T.
AU  - Luong, T.C.
AU  - Tran, O.T.
TI  - Transformer-Based Joint Learning Approach for Text Normalization in Vietnamese Automatic Speech Recognition Systems
PY  - 2024
T2  - Cybernetics and Systems
VL  - 55
IS  - 7
SP  - 1614
EP  - 1630
DO  - 10.1080/01969722.2022.2145654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142264378&doi=10.1080%2f01969722.2022.2145654&partnerID=40&md5=a151da396f278632683ae004d53f9ad7
AB  - In this article, we investigate the task of normalizing transcribed texts in Vietnamese Automatic Speech Recognition (ASR) systems in order to improve user readability and the performance of downstream tasks. This task usually consists of two main sub-tasks: predicting and inserting punctuation (i.e., period, comma); and detecting and standardizing named entities (i.e., numbers, person names) from spoken forms to their appropriate written forms. To achieve these goals, we introduce a complete corpus including of 87,700 sentences and investigate conditional joint learning approaches which globally optimize two sub-tasks simultaneously. The experimental results are quite promising. Overall, the proposed architecture outperformed the conventional architecture which trains individual models on the two sub-tasks separately. The joint models are furthered improved when integrated with the surrounding contexts (SCs). Specifically, we obtained 81.13% for the first sub-task and 94.41% for the second sub-task in the F1 scores using the best model. © 2022 Taylor & Francis Group, LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; AJG:1; zdy:1; 
LB  - Bui2024Transformer-Based
ER  -

TY  - JOUR
AU  - Zhan, C.
AU  - Liu, Y.
AU  - Wu, Z.
AU  - Zhao, M.
AU  - Chow, T.W.S.
TI  - A hybrid machine learning framework for forecasting house price
PY  - 2023
T2  - Expert Systems with Applications
VL  - 233
C7  - 120981
DO  - 10.1016/j.eswa.2023.120981
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166468174&doi=10.1016%2fj.eswa.2023.120981&partnerID=40&md5=37f3b914d7187a66c81a8f69b639bd72
AB  - House price prediction is one of the most important factors affecting national real estate policies. However, developing an accurate housing price prediction model is a significant challenge for the real estate market. This study presents a framework of house price prediction models that address this issue by improving forecasting performance, explicitly demonstrating the novelty in the Hybrid Bayesian Optimization (HBO) models combined with Stacking (HBOS), Bagging (HBOB), and Transformer (HBOT) techniques. These hybrid models employ Bayesian Optimization for hyperparameter tuning, leading to superior prediction accuracy and stability. Additionally, the proposed framework can assess a statistical and accurate assessment of the predictive performance of house price forecasting models in different scenarios. Furthermore, we constructed a multi-source dataset containing 1,898,175 transactions of the Hong Kong real estate market covering a period from January 2, 1996, to May 13, 2021. This dataset, another major contribution to the field, enables comprehensive model testing and could be a valuable resource for future research. Then, the proposed hybrid models are compared with 18 benchmark models. Thirteen evaluation metrics are used to evaluate the predictive performance, while the non-parametric testing, including Friedman, Iman–Davenport, and Nemenyi post-hoc tests methods, are adopted to assess the significance of differences in the predictive performance of each model. The experimental results show that the HBOS models are superior to the other benchmark models for application in the house price prediction problem. The HBOS-CatBoost model showed superior performance in terms of RMSE compared to both the HBOB-XGBoost and HBOT-ConvLSTM models, with relative RMSE reductions of 5.11% and 25.56%, respectively. The main contributions of this work are the creation of a rich multi-source dataset, the proposal of novel hybrid models for improved house price prediction, and a comprehensive performance evaluation framework. These findings offer a significant step forward in the housing price prediction field. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhan2023hybrid
ER  -

TY  - JOUR
AU  - Zhou, C.
AU  - Che, C.
AU  - Wang, P.
AU  - Zhang, Q.
TI  - Diformer: A dynamic self-differential transformer for new energy power autoregressive prediction
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 281
C7  - 111061
DO  - 10.1016/j.knosys.2023.111061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174348924&doi=10.1016%2fj.knosys.2023.111061&partnerID=40&md5=13d96d3679d9215994f31b904b078c4c
AB  - Power prediction is important as a technical support mechanism in the global carbon neutrality initiative. Existing artificial intelligence methodologies frequently grapple with the challenge of excessive dependence on numerical space mapping. This reliance often results in sacrificing the precision of power prediction trends to achieve smoother prediction outcomes. Therefore, to address this issue, we propose a dynamic self-differential transformer (Diformer) tailored explicitly for univariate power time series forecasting to address this issue. Diformer incorporates two unique constructions: (i) a novel self-differential attention mechanism that enhances the importance of sequence trends through bidirectional difference features, resolving the issue of excessive reliance on token mapping in the numerical space in the transformer-based model during extracting features. (ii) a loss function called trade-loss, intensifying error loss by dynamically adjusting weights when the sequence trend changes. This formula mode significantly improves the model's ability to discern the direction of the sequence trend. Extensive experiments on six power time series datasets and publicly available power-related datasets demonstrate that Diformer significantly outperforms existing models and is better suited for power time series forecasting. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; 
LB  - Zhou2023Diformer
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Lin, Y.
AU  - Xu, Y.
AU  - Hu, J.
AU  - Dong, S.
TI  - Interpretable Disease Prediction via Path Reasoning over medical knowledge graphs and admission history
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 281
C7  - 111082
DO  - 10.1016/j.knosys.2023.111082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174721301&doi=10.1016%2fj.knosys.2023.111082&partnerID=40&md5=6c016e21d14a2f09ef6f5df8b6fccfbe
AB  - Disease prediction based on patients’ historical admission records is an essential task in the medical field, but current predictive models often lack interpretability, which is a critical aspect in clinical practice. In this paper, we propose a Knowledge Guided Interpretable Disease Prediction method (KGxDP) via Path Reasoning over Medical Knowledge Graphs and Admission History. In KGxDP, the representation of a patient is formulated via a personalized medical knowledge graph, which is then combined with the patient's admission sequence embedding to form an inclusive subgraph. This admission sequence embedding is modeled by a Transformer based on the patient's admission history, capturing the time-based variations of each diagnosis. Furthermore, the subgraph is updated via graph reasoning by using a node-type and edge-type specified Graph Attention Network (GAT) and subsequently combined with admission sequence embedding for disease prediction. This process also facilitates interpretability by extracting critical paths within the subgraphs. Empirical evaluations on public MIMIC-III, MIMIC-IV and eICU datasets demonstrate that KGxDP outperforms state-of-arts models in predicting patients’ future diseases while also providing convincing explanations. The extracted paths are used as prompts for ChatGPT to generates user friendly, understandable Natural Language Explanations (NLE) for the prediction results, which also shows that the extracted paths by KGxDP have strong interpretability. This augmentation in predictive accuracy and explanation reliability holds significant potential to positively impact clinical decision-making. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; 
LB  - Yang2023Interpretable
ER  -

TY  - JOUR
AU  - Wang, F.
AU  - Wang, B.
TI  - Boundary-guided feature integration network with hierarchical transformer for medical image segmentation
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 3
SP  - 8955
EP  - 8969
DO  - 10.1007/s11042-023-15948-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162054508&doi=10.1007%2fs11042-023-15948-z&partnerID=40&md5=7c517e8bcc1439eacaa59091a792cad3
AB  - A variety of convolutional neural network (CNN) based methods for medical image segmentation have achieved outstanding performance, however, inherently suffered from a limited ability to capture long-range dependencies. In addition, some of the features integrated by complex strategy may be used repeatedly, resulting in more redundant information. To solve this problem, we propose a novel feature integration network by conducting hierarchical transformer under both explicit label and boundary guidance for accurate medical image segmentation. First, the encoder hierarchically extracts multiscale features by each hybrid attention module consisting of residual and Transformer blocks. Second, the parallel features from adjacent layers are integrated via cross fusion block to complement semantics to low-level features. Then, both deep boundary and label supervision are deployed for layer-wise decoders. Finally, the output features are fused by each layer instead of a top-to-down way to integrate multiscale semantic representation for prediction. The proposed method was evaluated on Synapse dataset with Dice of 81.63% and Promise12 dataset with Dice of 92.47%, 95HD of 2.06mm, and aRVD of 4.09%. Extensive experiments demonstrate that our proposed method achieves promising performance on multi-organ CT and prostate MR image segmentation. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2024Boundary-guided
ER  -

TY  - JOUR
AU  - Zhao, Z.
AU  - Li, W.
AU  - Liu, P.
AU  - Zhang, A.
AU  - Sun, J.
AU  - Xu, L.X.
TI  - Survival Analysis for Multimode Ablation Using Self-Adapted Deep Learning Network Based on Multisource Features
PY  - 2024
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 28
IS  - 1
C7  - 3260776
SP  - 19
EP  - 30
DO  - 10.1109/JBHI.2023.3260776
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153396558&doi=10.1109%2fJBHI.2023.3260776&partnerID=40&md5=c1c952965003cb0250ddfcf978e243a2
AB  - Novel multimode thermal therapy by freezing before radio-frequency heating has achieved a desirable therapeutic effect in liver cancer. Compared with surgical resection, ablation treatment has a relatively high risk of tumor recurrence. To monitor tumor progression after ablation, we developed a novel survival analysis framework for survival prediction and efficacy assessment. We extracted preoperative and postoperative MRI radiomics features and vision transformer-based deep learning features. We also combined the immune features extracted from peripheral blood immune responses using flow cytometry and routine blood tests before and after treatment. We selected features using random survival forest and improved the deep Cox mixture (DCM) for survival analysis. To properly accommodate multitype input features, we proposed a self-adapted fully connected layer for locally and globally representing features. We evaluated the method using our clinical dataset. Of note, the immune features rank the highest feature importance and contribute significantly to the prediction accuracy. The results showed a promising C$^{\mathit{td}}$-index of 0.885 $\pm$ 0.040 and an integrated Brier score of 0.041 $\pm$ 0.014, which outperformed state-of-the-art method combinations of survival prediction. For each patient, individual survival probability was accurately predicted over time, which provided clinicians with trustable prognosis suggestions. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhao2024Survival
ER  -

TY  - JOUR
AU  - Djeddi, W.E.
AU  - Hermi, K.
AU  - Ben Yahia, S.
AU  - Diallo, G.
TI  - Advancing drug–target interaction prediction: a comprehensive graph-based approach integrating knowledge graph embedding and ProtBert pretraining
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 488
DO  - 10.1186/s12859-023-05593-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180134225&doi=10.1186%2fs12859-023-05593-6&partnerID=40&md5=b7977fde8c2b245bd08ba788e4b3619c
AB  - Background: The pharmaceutical field faces a significant challenge in validating drug target interactions (DTIs) due to the time and cost involved, leading to only a fraction being experimentally verified. To expedite drug discovery, accurate computational methods are essential for predicting potential interactions. Recently, machine learning techniques, particularly graph-based methods, have gained prominence. These methods utilize networks of drugs and targets, employing knowledge graph embedding (KGE) to represent structured information from knowledge graphs in a continuous vector space. This phenomenon highlights the growing inclination to utilize graph topologies as a means to improve the precision of predicting DTIs, hence addressing the pressing requirement for effective computational methodologies in the field of drug discovery. Results: The present study presents a novel approach called DTIOG for the prediction of DTIs. The methodology employed in this study involves the utilization of a KGE strategy, together with the incorporation of contextual information obtained from protein sequences. More specifically, the study makes use of Protein Bidirectional Encoder Representations from Transformers (ProtBERT) for this purpose. DTIOG utilizes a two-step process to compute embedding vectors using KGE techniques. Additionally, it employs ProtBERT to determine target–target similarity. Different similarity measures, such as Cosine similarity or Euclidean distance, are utilized in the prediction procedure. In addition to the contextual embedding, the proposed unique approach incorporates local representations obtained from the Simplified Molecular Input Line Entry Specification (SMILES) of drugs and the amino acid sequences of protein targets. Conclusions: The effectiveness of the proposed approach was assessed through extensive experimentation on datasets pertaining to Enzymes, Ion Channels, and G-protein-coupled Receptors. The remarkable efficacy of DTIOG was showcased through the utilization of diverse similarity measures in order to calculate the similarities between drugs and targets. The combination of these factors, along with the incorporation of various classifiers, enabled the model to outperform existing algorithms in its ability to predict DTIs. The consistent observation of this advantage across all datasets underlines the robustness and accuracy of DTIOG in the domain of DTIs. Additionally, our case study suggests that the DTIOG can serve as a valuable tool for discovering new DTIs. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Djeddi2023Advancing
ER  -

TY  - JOUR
AU  - Shin, I.
AU  - Kang, K.
AU  - Kim, J.
AU  - Sel, S.
AU  - Choi, J.
AU  - Lee, J.-W.
AU  - Kang, H.Y.
AU  - Song, G.
TI  - AptaTrans: a deep neural network for predicting aptamer-protein interaction using pretrained encoders
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 447
DO  - 10.1186/s12859-023-05577-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177891829&doi=10.1186%2fs12859-023-05577-6&partnerID=40&md5=b5b9b6f162d52cd59ccd6722cad8f2fc
AB  - Background: Aptamers, which are biomaterials comprised of single-stranded DNA/RNA that form tertiary structures, have significant potential as next-generation materials, particularly for drug discovery. The systematic evolution of ligands by exponential enrichment (SELEX) method is a critical in vitro technique employed to identify aptamers that bind specifically to target proteins. While advanced SELEX-based methods such as Cell- and HT-SELEX are available, they often encounter issues such as extended time consumption and suboptimal accuracy. Several In silico aptamer discovery methods have been proposed to address these challenges. These methods are specifically designed to predict aptamer-protein interaction (API) using benchmark datasets. However, these methods often fail to consider the physicochemical interactions between aptamers and proteins within tertiary structures. Results: In this study, we propose AptaTrans, a pipeline for predicting API using deep learning techniques. AptaTrans uses transformer-based encoders to handle aptamer and protein sequences at the monomer level. Furthermore, pretrained encoders are utilized for the structural representation. After validation with a benchmark dataset, AptaTrans has been integrated into a comprehensive toolset. This pipeline synergistically combines with Apta-MCTS, a generative algorithm for recommending aptamer candidates. Conclusion: The results show that AptaTrans outperforms existing models for predicting API, and the efficacy of the AptaTrans pipeline has been confirmed through various experimental tools. We expect AptaTrans will enhance the cost-effectiveness and efficiency of SELEX in drug discovery. The source code and benchmark dataset for AptaTrans are available at https://github.com/pnumlb/AptaTrans . © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Shin2023AptaTrans
ER  -

TY  - JOUR
AU  - Kumar, A.
AU  - Grüning, B.
AU  - Backofen, R.
TI  - Transformer-based tool recommendation system in Galaxy
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 446
DO  - 10.1186/s12859-023-05573-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178469524&doi=10.1186%2fs12859-023-05573-w&partnerID=40&md5=d97fa9b430fdce61e59916f5b0edd6d1
AB  - Background: Galaxy is a web-based open-source platform for scientific analyses. Researchers use thousands of high-quality tools and workflows for their respective analyses in Galaxy. Tool recommender system predicts a collection of tools that can be used to extend an analysis. In this work, a tool recommender system is developed by training a transformer on workflows available on Galaxy Europe and its performance is compared to other neural networks such as recurrent, convolutional and dense neural networks. Results: The transformer neural network achieves two times faster convergence, has significantly lower model usage (model reconstruction and prediction) time and shows a better generalisation that goes beyond training workflows than the older tool recommender system created using RNN in Galaxy. In addition, the transformer also outperforms CNN and DNN on several key indicators. It achieves a faster convergence time, lower model usage time, and higher quality tool recommendations than CNN. Compared to DNN, it converges faster to a higher precision@k metric (approximately 0.98 by transformer compared to approximately 0.9 by DNN) and shows higher quality tool recommendations. Conclusion: Our work shows a novel usage of transformers to recommend tools for extending scientific workflows. A more robust tool recommendation model, created using a transformer, having significantly lower usage time than RNN and CNN, higher precision@k than DNN, and higher quality tool recommendations than all three neural networks, will benefit researchers in creating scientifically significant workflows and exploratory data analysis in Galaxy. Additionally, the ability to train faster than all three neural networks imparts more scalability for training on larger datasets consisting of millions of tool sequences. Open-source scripts to create the recommendation model are available under MIT licence at https://github.com/anuprulez/galaxy_tool_recommendation_transformers. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Kumar2023Transformer-based
ER  -

TY  - JOUR
AU  - Ming, Z.
AU  - Chen, X.
AU  - Wang, S.
AU  - Liu, H.
AU  - Yuan, Z.
AU  - Wu, M.
AU  - Xia, H.
TI  - HostNet: improved sequence representation in deep neural networks for virus-host prediction
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 455
DO  - 10.1186/s12859-023-05582-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178236489&doi=10.1186%2fs12859-023-05582-9&partnerID=40&md5=9c1bffb2f34773c6f036eef5119e1576
AB  - Background: The escalation of viruses over the past decade has highlighted the need to determine their respective hosts, particularly for emerging ones that pose a potential menace to the welfare of both human and animal life. Yet, the traditional means of ascertaining the host range of viruses, which involves field surveillance and laboratory experiments, is a laborious and demanding undertaking. A computational tool with the capability to reliably predict host ranges for novel viruses can provide timely responses in the prevention and control of emerging infectious diseases. The intricate nature of viral-host prediction involves issues such as data imbalance and deficiency. Therefore, developing highly accurate computational tools capable of predicting virus-host associations is a challenging and pressing demand. Results: To overcome the challenges of virus-host prediction, we present HostNet, a deep learning framework that utilizes a Transformer-CNN-BiGRU architecture and two enhanced sequence representation modules. The first module, k-mer to vector, pre-trains a background vector representation of k-mers from a broad range of virus sequences to address the issue of data deficiency. The second module, an adaptive sliding window, truncates virus sequences of various lengths to create a uniform number of informative and distinct samples for each sequence to address the issue of data imbalance. We assess HostNet's performance on a benchmark dataset of “Rabies lyssavirus” and an in-house dataset of “Flavivirus”. Our results show that HostNet surpasses the state-of-the-art deep learning-based method in host-prediction accuracies and F1 score. The enhanced sequence representation modules, significantly improve HostNet's training generalization, performance in challenging classes, and stability. Conclusion: HostNet is a promising framework for predicting virus hosts from genomic sequences, addressing challenges posed by sparse and varying-length virus sequence data. Our results demonstrate its potential as a valuable tool for virus-host prediction in various biological contexts. Virus-host prediction based on genomic sequences using deep neural networks is a promising approach to identifying their potential hosts accurately and efficiently, with significant impacts on public health, disease prevention, and vaccine development. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Ming2023HostNet
ER  -

TY  - JOUR
AU  - Hu, H.
AU  - Jiang, Y.
AU  - Yang, Y.
AU  - Chen, J.X.
TI  - BiG2S: A dual task graph-to-sequence model for the end-to-end template-free reaction prediction
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 24
SP  - 29620
EP  - 29637
DO  - 10.1007/s10489-023-05048-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175376794&doi=10.1007%2fs10489-023-05048-8&partnerID=40&md5=7baf877855f7a47a30cae0fab597de52
AB  - Abstract: Retrosynthesis and reaction outcome prediction are fundamental problems in organic chemistry and computer-aided synthesis planning (CASP), which are also crucial parts of computer-aided drug design. In recent years, deep learning has spawned a branch of methods which use machine translation frameworks with SMILES data representation to solve these problems. With the successive introduction of additional inverted reaction data as well as the molecular graph representation, the accuracy and validity of machine-transaction-based approaches have been further improved. In this work, we propose a bidirectional graph-to-sequence model (BiG2S) that combines the benefits of inverted reaction training and graph representation. The proposed approach has the ability to provide high-quality retrosynthesis and forward synthesis prediction simultaneously on various datasets, which achieves 5.5 % top-1 accuracy with only 0.1 % invalid results on USPTO-50k retrosynthesis task, and maintain 85.0 % top-1 accuracy for outcome prediction with the same model. Graphical abstract: [Figure not available: see fulltext.] © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Hu2023BiG2S
ER  -

TY  - JOUR
AU  - AlShami, A.
AU  - Boult, T.
AU  - Kalita, J.
TI  - Pose2Trajectory: Using transformers on body pose to predict tennis player's trajectory
PY  - 2023
T2  - Journal of Visual Communication and Image Representation
VL  - 97
C7  - 103954
DO  - 10.1016/j.jvcir.2023.103954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174940006&doi=10.1016%2fj.jvcir.2023.103954&partnerID=40&md5=c8774d0b6e688920ba9f38fa021f8e85
AB  - Tracking the trajectory of tennis players can help camera operators in production. Predicting future movement enables cameras to automatically track and predict a player's future trajectory without human intervention. It is also intellectually satisfying to predict future human movement in the context of complex physical tasks. Swift advancements in sports analytics and the wide availability of videos for tennis have inspired us to propose a novel method called Pose2Trajectory, which predicts a tennis player's future trajectory as a sequence derived from their body joints’ data and ball position. Demonstrating impressive accuracy, our approach capitalizes on body joint information to provide a comprehensive understanding of the human body's geometry and motion, thereby enhancing the prediction of the player's trajectory. We use encoder–decoder Transformer architecture trained on the joints and trajectory information of the players with ball positions. The predicted sequence can provide information to help close-up cameras to keep tracking the tennis player, following centroid coordinates. We generate a high-quality dataset from multiple videos to assist tennis player movement prediction using object detection and human pose estimation methods. It contains bounding boxes and joint information for tennis players and ball positions in singles tennis games. Our method shows promising results in predicting the tennis player's movement trajectory with different sequence prediction lengths using the joints and trajectory information with the ball position. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - AlShami2023Pose2Trajectory
ER  -

TY  - JOUR
AU  - Lin, S.
AU  - Xu, Y.
AU  - Zhao, S.
AU  - Wang, Y.
AU  - Xu, J.
TI  - TransETA: transformer networks for estimated time of arrival with local congestion representation
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 24
SP  - 30384
EP  - 30399
DO  - 10.1007/s10489-023-05139-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176929088&doi=10.1007%2fs10489-023-05139-6&partnerID=40&md5=4c1d0bbede041fa3c6effc3abab14090
AB  - Estimated time of arrival (ETA) is an estimate of the vehicle travel time from the origin to destination in the roadworks. From the perspective of travel planning or resource allocation, accurate ETA is significantly important. In recent years, deep learning-based methods represented by recurrent neural networks has been widely used in travel time prediction tasks, but such methods cannot effectively learn data association at different moments. At the same time, the existing methods do not effectively leverage local traffic information. Targeting these challenges, this paper proposes a new model TransETA to predict vehicle travel time. The model includes three modules: the input feature transformation module uses graph convolutional network (GCN) to extract the local congestion feature, the deep forest module mainly deals with static trajectory data, and ETA-Transformer module processes the feature extraction of dynamic trajectory data. Finally, we conducted experiments on two large trajectory datasets. The experimental results show that the proposed hybrid deep learning method, TransETA, outperforms the state-of-the-art models. On the Chengdu and Porto datasets, our proposed method shows an improvement of 6s and 9s in mean absolute error compared to the current best performing method, respectively. Also the average absolute percentage error is reduced by 2.34% and 3.64% respectively. The effectiveness of each module was approved through ablation experiments. Specifically, local congestion information representation can effectively improve the accuracy of the prediction. ETA-Transformer module is more effective in extracting spatio-temporal feature correlation than the LSTM-based method. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Lin2023TransETA
ER  -

TY  - JOUR
AU  - Gao, L.
AU  - Lan, Y.
AU  - Yu, Z.
AU  - Zhu, J.-M.
TI  - A personalized paper recommendation method based on knowledge graph and transformer encoder with a self-attention mechanism
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 24
SP  - 29991
EP  - 30008
DO  - 10.1007/s10489-023-05108-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175861249&doi=10.1007%2fs10489-023-05108-z&partnerID=40&md5=36b5c50a45f7532b2925a6f1e0b814ad
AB  - Paper recommendation with personalized methods helps researchers to track the latest academic trends and master cutting-edge academic trends efficiently. Meanwhile, the methods of previous paper recommendation suffer from three problems: data sparsity of content-based and collaborative filtering methods; Graph-based recommendations do not fully consider the personalized information of authors and their articles; Cold start based on deep learning. To overcome those difficulties, we propose a personalized paper recommendation method based on a knowledge graph and Transformer encoder (KGTE) with a self-attention mechanism. Firstly, we add auxiliary information (article title, publication year, citation times, and abstract) as attributes to the nodes of knowledge graph(KG), which contain author, digital object unique identifier(DOI) and keywords. Secondly, BERT is used to represent the semantic information features of the article and Transformer is introduced to fully integrate the feature context. After that, by using RippleNet, we traverse the knowledge graph, filter the user preference distribution and form a set of pre recommended nodes with multi_hop nodes. Finally, the prediction layer sorts the set and gets a Top_n paper recommendation. In the experiments on the DBLP and Aminer datasets, the precision value of KGTE improved by an average of 2.59% over the existing baseline methods DER and 4.23% improvement in NDCG. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Gao2023personalized
ER  -

TY  - JOUR
AU  - Tang, G.
AU  - Yu, F.
AU  - Li, H.
AU  - Shi, Y.
AU  - Liu, L.
AU  - Peng, T.
AU  - Hu, X.
AU  - Jiang, M.
TI  - ClothSeg: semantic segmentation network with feature projection for clothing parsing
PY  - 2023
T2  - Journal of Visual Communication and Image Representation
VL  - 97
C7  - 103980
DO  - 10.1016/j.jvcir.2023.103980
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177884668&doi=10.1016%2fj.jvcir.2023.103980&partnerID=40&md5=447149e29dd20eab4ff156d62bd492b4
AB  - Semantic segmentation of clothing presents a formidable challenge owing to the non-rigid geometric deformation properties inherent in garments. In this paper, we use the Transformer as the encoder to better learn global information for clothing semantic segmentation. In addition, we propose a Feature Projection Fusion (FPF) module to better utilize local information. This module facilitates the integration of deep feature maps with shallow local details, thereby enabling the network to capture both high-level abstractions and fine-grained details of features. We also design a pixel distance loss in training to emphasize the impact of edge features. This loss calculates the mean of the shortest distances between all predicted clothing edges and the true clothing edges during the training process. We perform extensive experiments and our method achieves 56.30% and 74.97% mIoU on the public dataset CFPD and our self-made dataset LIC, respectively, demonstrating a competitive performance when compared to the state-of-the-art. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Tang2023ClothSeg
ER  -

TY  - JOUR
AU  - Zhu, P.
AU  - Liu, S.
AU  - Liu, Y.
AU  - Yap, P.-T.
TI  - METER: Multi-task efficient transformer for no-reference image quality assessment
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 24
SP  - 29974
EP  - 29990
DO  - 10.1007/s10489-023-05104-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175795814&doi=10.1007%2fs10489-023-05104-3&partnerID=40&md5=6d2fd9c2af89b1cfd9162c3a593dce5a
AB  - Abstract: No-reference image quality assessment (NR-IQA) is a fundamental yet challenging task in computer vision. Current NR-IQA methods based on convolutional neural networks typically employ deeply-stacked convolutions to learn local features pertinent to image quality, neglecting the importance of non-local information and distortion types. As a remedy, we introduce in this paper an end-to-end multi-task efficient transformer (METER) for the NR-IQA task, consisting of a multi-scale semantic feature extraction (MSFE) backbone module, a distortion type identification (DTI) module, and an adaptive quality prediction (AQP) module. METER identifies the distortion type using the DTI module to facilitate extraction of distortion-specific features via the MSFE module. METER scores image quality in an adaptive manner by adjusting the weights and biases of adaptive fully-connected (AFC) layers in the AQP module, increasing generalizability to images captured in different natural environments. Experimental results demonstrate that METER significantly outperforms existing methods for accuracy and efficiency across five public datasets: LIVEC, BID, KonIQ, LIVE, and CSIQ, and exhibits remarkable performance with Pearson’s linear correlation coefficients: 0.923, 0.912, 0.937, 0.978, and 0.982 on respective datasets when compared to human subjective scores. Additionally, METER also attains higher efficiency (-53.9% Params and -87.7% FLOPs) compared to the existing transformer-based methods, making it valuable for real-world applications. Graphical Abstract: METER: Multi-task Efficient Transformer for No-Reference Image Quality Assessment. Pengli Zhu,Siyuan Liu,Yancheng Liu,Pew-Thian Yap[Figure not available: see fulltext.] © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhu2023METER
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Li, P.
TI  - GPDRP: a multimodal framework for drug response prediction with graph transformer
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 484
DO  - 10.1186/s12859-023-05618-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179964308&doi=10.1186%2fs12859-023-05618-0&partnerID=40&md5=ac3759e71fad05ab7f26d88a8033aa95
AB  - Background: In the field of computational personalized medicine, drug response prediction (DRP) is a critical issue. However, existing studies often characterize drugs as strings, a representation that does not align with the natural description of molecules. Additionally, they ignore gene pathway-specific combinatorial implication. Results: In this study, we propose drug Graph and gene Pathway based Drug response prediction method (GPDRP), a new multimodal deep learning model for predicting drug responses based on drug molecular graphs and gene pathway activity. In GPDRP, drugs are represented by molecular graphs, while cell lines are described by gene pathway activity scores. The model separately learns these two types of data using Graph Neural Networks (GNN) with Graph Transformers and deep neural networks. Predictions are subsequently made through fully connected layers. Conclusions: Our results indicate that Graph Transformer-based model delivers superior performance. We apply GPDRP on hundreds of cancer cell lines’ bulk RNA-sequencing data, and it outperforms some recently published models. Furthermore, the generalizability and applicability of GPDRP are demonstrated through its predictions on unknown drug-cell line pairs and xenografts. This underscores the interpretability achieved by incorporating gene pathways. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Yang2023GPDRP
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Deng, J.
AU  - Lin, X.
AU  - Tang, W.
AU  - Wang, S.
TI  - CDS-Net: Cooperative dual-stream network for image manipulation detection
PY  - 2023
T2  - Pattern Recognition Letters
VL  - 176
SP  - 167
EP  - 173
DO  - 10.1016/j.patrec.2023.11.005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176245782&doi=10.1016%2fj.patrec.2023.11.005&partnerID=40&md5=f5548c4bfb2720bf50d382a8e8ab1d6e
AB  - To accurately locate manipulated regions, many existing approaches employ a dual-stream framework to extract a wide range of manipulation clues, including local noise, edge artifacts, and global inconsistency. However, these approaches treat each stream in isolation and fail to consider the complementary and mutual guidance ability between the streams. Moreover, we notice the use of vanilla vision transformers in previous approaches can result in disruptions of object semantics, causing incomplete predictions. To address these challenges, we introduce the cooperative dual-stream network (CDS-Net) comprising an RGB Stream and a Noise Stream. In the Noise Stream, we propose a K-means Transformer (KT) that encourages both inter-patch and intra-patch information transmission to mitigate the semantic fragmentation phenomenon caused by patch partitioning. Additionally, we introduce a novel Feature Interaction Block (FIB) that explicitly encourages cross-stream collaboration at each encoding stage. Comprehensive experiments on publicly available datasets demonstrate the effectiveness and robustness of CDS-Net. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wang2023CDS-Net
ER  -

TY  - JOUR
AU  - Sun, W.
AU  - Cheng, R.
AU  - Jiao, Y.
AU  - Gao, J.
AU  - Zheng, Z.
AU  - Lu, N.
TI  - Transformer network with decoupled spatial–temporal embedding for traffic flow forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 24
SP  - 30148
EP  - 30168
DO  - 10.1007/s10489-023-05126-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176334256&doi=10.1007%2fs10489-023-05126-x&partnerID=40&md5=d8e742d036773095c1ac733ad7a13d87
AB  - Over the past few years, there has been significant research on applying Transformer models to time series prediction, yielding promising results. Simultaneously, researchers have begun exploring the utilization of Transformers for traffic prediction in order to mitigate the nonlinear spatial–temporal correlation inherent in traffic data. Some of these studies have attempted to characterize spatial–temporal features by incorporating embedding structures, with the goal of improving performance of the model. However, existing methods have not adequately addressed the issue of spatial–temporal correlation. To address these limitations, we propose the Transformer Network with Decoupled Spatial–Temporal Embedding (DSTET) model for traffic flow prediction. The key aspect of our model is its ability to effectively decouple the spatial and temporal embedding through the implementation of the Decoupled Spatial–Temporal Embedding structure. This structure enhances the characterization of spatial–temporal features, ultimately improving the performance of traffic prediction based on the Transformer model. Through experiments conducted on six real-world traffic datasets, our model consistently outperforms multiple baseline models, demonstrating its capability to address the identified problems. Moreover, we substantiate the efficacy of the suggested components via ablation experiments and furnish a thorough analysis of the attention weight matrix to clarify the functioning of the model. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Sun2023Transformer
ER  -

TY  - JOUR
AU  - Liu, P.
AU  - Chen, L.
AU  - Zhang, H.
AU  - Zhang, Y.
AU  - Liu, C.
AU  - Li, C.
AU  - Wang, Z.
TI  - PEAR: Positional-encoded Asynchronous Autoregression for satellite anomaly detection
PY  - 2023
T2  - Pattern Recognition Letters
VL  - 176
SP  - 96
EP  - 101
DO  - 10.1016/j.patrec.2023.10.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175354588&doi=10.1016%2fj.patrec.2023.10.007&partnerID=40&md5=0936d4fa2a5cf3dbaa7cd0c87015038f
AB  - This paper proposes a Positional-Encoded Asynchronous AutoRegression (PEAR) method for satellite anomaly detection. We empirically observe that a single classification model can hardly detect unknown anomalous situations and neglect the Markov nature of temporal satellite data. To address this, we adopt an autoregressive model to deal with the prediction of unknown anomaly for satellite data. We further propose a non-uniform temporal encoding method for asynchronous data and a median filtering method for more accurate detection. To reduce the effect of outliers, we employ an adaptive threshold selection method to achieve a more robust classification boundary. We test the proposed method on the time series prediction models including LSTM and transformers and we further employ the positional encoding strategy to improve the modeling capabilities of the Transformer model on high-frequency information. Experiments on real satellite data demonstrate that the proposed PEAR method outperforms the baseline method by 55.79%. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Liu2023PEAR
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Zhang, P.
AU  - Huang, Y.
AU  - Chao, G.
AU  - Xie, X.
AU  - Fu, Y.
TI  - Oriented transformer for infectious disease case prediction
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 24
SP  - 30097
EP  - 30112
DO  - 10.1007/s10489-023-05101-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176246077&doi=10.1007%2fs10489-023-05101-6&partnerID=40&md5=de0a4d1dfcd40e8f98958d7bcbf75c93
AB  - Accurate prediction of infectious disease cases plays a crucial role in achieving effective infection prevention and control. However, the inherent variability of incubation periods and progression dynamics of infectious diseases pose significant challenges to the accuracy of predicting multiple diseases. Multiple representation fusion (MRF) methods would improve the performance of prediction models, due to their capability to capture diverse temporal dependencies that reflect potential disease transmission patterns. But the traditional fusion approach for infectious disease prediction still faces many challenges, including the requirement of auxiliary data, vulnerability to disease evolution, and lack of intuitive explanation. To address these challenges, this paper proposes an oriented transformer (ORIT) for infectious diseases case prediction. Contrary to traditional MRF structures that integrate representations from multiple data sources, the MRF in the proposed ORIT combines multi-orientation context vectors solely by capturing multi-dimensional temporal relationships within disease case data. Furthermore, this paper considers the heterogeneity of the incubation period in the prediction of different infectious disease cases. Lastly, this paper conducts comprehensive experiments to evaluate the proposed method using two real datasets of infectious diseases, and compares it with 21 well-known prediction methods. The experimental results verify the effectiveness of the proposed method. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Wang2023Oriented
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Tang, H.
TI  - STRFormer: Spatial–Temporal–ReTemporal Transformer for 3D human pose estimation
PY  - 2023
T2  - Image and Vision Computing
VL  - 140
C7  - 104863
DO  - 10.1016/j.imavis.2023.104863
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178939495&doi=10.1016%2fj.imavis.2023.104863&partnerID=40&md5=28ca70c1b175d5035d4e1bcb783792ab
AB  - Transformer-based methods have emerged as the golden standard in 2D-3D human pose estimation from video sequences, largely thanks to their powerful spatial–temporal feature encoders. In the past, researchers have made concerted efforts to engineer spatial and temporal encoders using transformer blocks. This approach involved a dramatic reshaping of the input, transforming it from mere joint information to dynamic joint trajectories. Despite this, the inherent limitations of the spatial–temporal structure have resulted in an inadequate acquisition and subsequent utilization of temporal information. In an attempt to rectify this prevalent issue, our paper proposes a new model, dubbed Spatial–Temporal-ReTemporal Transformer (i.e., STRFormer). This model ingeniously employs two separate temporal transformer blocks to extract the essential temporal motion information from video sequences. Intriguingly, one temporal transformer block is dedicated to the original video sequence, while the other concerns itself with the reversed order video. This novel approach allows for a more thorough investigation and utilization of temporal information from the video sequences. In order to alternate the processing of these two blocks effectively with the spatial block, we focus on maximizing the extraction of temporal domain information. This method leads to a more comprehensive understanding of the pose estimation and its evolution over time. Furthermore, we introduce a novel error metric, Mean Per-Joint Position Acceleration Error (i.e., MPJAE). This advanced metric takes into account the body part velocity in adjacent predicted frames, allowing for a more detailed evaluation of the predicted poses. We conduct extensive experiments on various open benchmarks to evaluate the effectiveness of our proposed model. The results demonstrate that our STRFormer, coupled with the MPJAE loss, achieves highly competitive results when compared with other state-of-the-art models. This illustrates its promising potential and practical applicability in 2D-3D human pose estimation tasks. We plan to release our code publicly for further research. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Liu2023STRFormer
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Zhang, Z.
AU  - Liang, Y.
AU  - Shen, F.
AU  - Gao, W.
AU  - Xu, D.
TI  - Navigation Sensor Data Reliability Model-Based on Self-Evaluation and Mutual Evaluation
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 23
SP  - 20735
EP  - 20745
DO  - 10.1109/JIOT.2023.3304753
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168287207&doi=10.1109%2fJIOT.2023.3304753&partnerID=40&md5=899e569863d04a4a97bf4caa0bdda75f
AB  - Multisource navigation involves using multiple available sensors to achieve high-precision location services, but navigation devices and data are susceptible to various environments and attacks, emphasizing the need for pervasive security measures like data reliability evaluation. Common reliability estimation methods for Internet of Things data are weak for highly dynamic navigation data, which are invalid when sensor motion is considered. We proposed a method combining self-evaluation and mutual evaluation to assess the reliability of real-time navigation sensor data. Our approach introduces an innovative transformer-based model for numerical-based sensors and a feature point prediction consistency test for digit image-based sensors. We also proposed a reconstruction consistency check method for mutual evaluation of multiple digital images. By combining self-assessment and mutual assessment, we determine the final reliability of the sensor data. To enable mutual evaluation of multiple digital images, we proposed a reconstruction consistency check method. By combining the results of self-assessment and mutual assessment, we determined the final reliability of the sensor data. The performance of our method was evaluated using both trustworthy and untrustworthy data. We have observed significant improvements in average absolute errors for UWB positioning and visual odometry positioning through experimentation, utilizing reliability-based weighted fusion, resulting in a reduction of 0.28 m for UWB positioning and 0.044 m for visual odometry positioning.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2023Navigation
ER  -

TY  - JOUR
AU  - Qin, Y.
AU  - Xia, H.
AU  - Song, S.
TI  - RT-Net: Region-Enhanced Attention Transformer Network for Polyp Segmentation
PY  - 2023
T2  - Neural Processing Letters
VL  - 55
IS  - 9
SP  - 11975
EP  - 11991
DO  - 10.1007/s11063-023-11405-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170257871&doi=10.1007%2fs11063-023-11405-y&partnerID=40&md5=9433376d47e076a8c9133ad37eae7112
AB  - Colonic polyps are highly correlated with colorectal cancer. Prevention of colorectal cancer is the detection and removal of polyps in the early stages of the disease. But the detection process relies on the physician’s experience and is prone to missed diagnoses. The drawbacks motivate us to design an algorithm to automatically assist physicians in detection to reduce the rate of missed polyps. However, polyp segmentation encounters challenges due to the variable appearance and blurred borders with the surrounding mucosa. And it is difficult for existing CNN-based polyp segmentation algorithms to learn long-range dependencies. Therefore, we propose a region-enhanced attention transformer network (RT-Net) for polyp segmentation. Unlike existing CNN-based approaches, it employs a pyramid Transformer encoder to promote the learning ability and robustness of the network. In addition, we introduce three modules, including the residual multiscale (RMS) module, the region-enhanced attention (REA) module and the feature aggregation (FA) module. Specifically, the RMS module learns multiscale information from the features of the encoder. The REA module adopts the prediction maps of each decoder layer to guide the network in building target regions and boundary cues to compensate for the missing local fields of view in the encoder. The role of the FA module is to efficiently aggregate the features from REA with those from the decoding layer to achieve better segmentation performance. RT-Net is evaluated on five benchmark polyp datasets. Extensive experiments demonstrate that our proposed RT-Net exhibits excellent performance compared to other state-of-the-art methods. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Qin2023RT-Net
ER  -

TY  - JOUR
AU  - Zhao, F.
AU  - Wang, Z.
AU  - Du, H.
AU  - He, X.
AU  - Cao, X.
TI  - Self-Supervised Triplet Contrastive Learning for Classifying Endometrial Histopathological Images
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 12
SP  - 5970
EP  - 5981
DO  - 10.1109/JBHI.2023.3314663
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171744890&doi=10.1109%2fJBHI.2023.3314663&partnerID=40&md5=89bfc609b317d2d914b5cd66958e042f
AB  - Early identification of endometrial cancer or precancerous lesions from histopathological images is crucial for precise endometrial medical care, which however is increasing hampered by the relative scarcity of pathologists. Computer-aided diagnosis (CAD) provides an automated alternative for confirming endometrial diseases with either feature-engineered machine learning or end-to-end deep learning (DL). In particular, advanced self-supervised learning alleviates the dependence of supervised learning on large-scale human-annotated data and can be used to pre-train DL models for specific classification tasks. Thereby, we develop a novel self-supervised triplet contrastive learning (SSTCL) model for classifying endometrial histopathological images. Specifically, this model consists of one online branch and two target branches. The second target branch includes a simple yet powerful augmentation module named random mosaic masking (RMM), which functions as an effective regularization by mapping the features of masked images close to those of intact ones. Moreover, we add a bottleneck Transformer (BoT) model into each branch as a self-attention module to learn the global information by considering both content information and relative distances between features at different locations. On public endometrial dataset, our model achieved four-class classification accuracies of 77.31 ± 0.84, 80.87 ± 0.48 and 83.22 ± 0.87% using 20, 50 and 100% labeled images, respectively. When transferred to the in-house dataset, our model obtained a three-class diagnostic accuracy of 96.81% with 95% confidence interval of 95.61-98.02%. On both datasets, our model outperformed state-of-the-art supervised and self-supervised methods. Our model may help pathologists to automatically diagnose endometrial diseases with high accuracy and efficiency using limited human-annotated histopathological images.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhao2023Self-Supervised
ER  -

TY  - JOUR
AU  - Fu, X.
AU  - Ren, Q.
AU  - Wu, H.
AU  - Xiang, F.
AU  - Luo, Q.
AU  - Yue, J.
AU  - Chen, Y.
AU  - Zhang, F.
TI  - P3 ViT: A CIM-Based High-Utilization Architecture With Dynamic Pruning and Two-Way Ping-Pong Macro for Vision Transformer
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems I: Regular Papers
VL  - 70
IS  - 12
SP  - 4938
EP  - 4948
DO  - 10.1109/TCSI.2023.3315060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173318525&doi=10.1109%2fTCSI.2023.3315060&partnerID=40&md5=8239195c5cbb6f3e9554c8bde54b0272
AB  - Transformers have made remarkable contributions to natural language processing (NLP) and many other fields. Recently, transformer-based models have achieved state-of-the-art (SOTA) performance on computer vision tasks compared with traditional convolutional neural networks (CNNs). Unfortunately, existing CNN accelerators cannot efficiently support transformer due to the high computational overhead and redundant data accesses associated with the 'KQV' matrix operations in the transformer models. If the recently-developed NLP transformer accelerators are applied to the vision transformer (ViT) models, their efficiency would decrease due to three challenges. 1) Redundant data storage and access still exist in ViT data flow scheduling. 2) For matrix transposition in transformer models, the previous transpose-operation schemes lack flexibility, resulting in extra area overhead. 3) The sparse acceleration schemes for NLP in prior transformer accelerators cannot efficiently accelerate ViT with relatively fewer tokens. To overcome these challenges, we propose P3 ViT, a computing-in-memory (CIM)-based architecture, to efficiently accelerate ViT, achieving high utilization on data flow scheduling. There are three key contributions: 1) P3ViT architecture supports three ping-pong pipeline scheduling modes, involving inter-core parallel and intra-core ping-pong pipeline mode (IEP-IAP3), inter-core pipeline and parallel mode (IEP2), and full parallel mode, to eliminate redundant memory accesses. 2) A two-way ping-pong CIM macro is proposed, which can be configured to regular calculation mode and transpose calculation mode to adapt to both Q×KT and A×V tasks. 3) P3ViT also runs a small prediction network. It prunes redundant tokens to be a standard number hierarchically and dynamically, enabling high-throughput and high-utilization attention computation. Measurements show that P3ViT achieves 1.13× higher energy efficiency than the state-of-the-art transformer accelerator and achieves 30.8× and 14.6× speedup compared to CPU and GPU.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Fu2023P3
ER  -

TY  - JOUR
AU  - Ma, S.
AU  - Zhang, T.
AU  - Zhao, Y.-B.
AU  - Kang, Y.
AU  - Bai, P.
TI  - TCLN: A Transformer-based Conv-LSTM network for multivariate time series forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 23
SP  - 28401
EP  - 28417
DO  - 10.1007/s10489-023-04980-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173075364&doi=10.1007%2fs10489-023-04980-z&partnerID=40&md5=76f8d4a9d68e08add4f860c87daaf464
AB  - The study of multivariate time series forecasting (MTSF) problems has high significance in many areas, such as industrial forecasting and traffic flow forecasting. Traditional forecasting models pay more attention to the temporal features of variables and lack depth in extracting spatial and spatiotemporal features between variables. In this paper, a novel model based on the Transformer, convolutional neural network (CNN), and long short-term memory (LSTM) network is proposed to address the issues. The model first extracts the spatial feature vectors through the proposed Multi-kernel CNN. Then it fully extracts the temporal information by the Encoder layer that consists of the Transformer encoder layer and the LSTM network, which can also obtain the potential spatiotemporal correlation. To extract more feature information, we stack multiple Encoder layers. Finally, the output is decoded by the Decoder layer composed of the ReLU activation function and the Linear layer. To further improve the model’s robustness, we also integrate an autoregressive model. In model evaluation, the proposed model achieves significant performance improvements over the current benchmark methods for MTSF tasks on four datasets. Further experiments demonstrate that the model can be used for long-horizon forecasting and achieve satisfactory results on the yield forecasting of test items (our private dataset, TIOB). © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Ma2023TCLN
ER  -

TY  - JOUR
AU  - Bao, H.
AU  - Zhao, J.
AU  - Zhao, X.
AU  - Zhao, C.
AU  - Lu, X.
AU  - Xu, G.
TI  - Prediction of plant secondary metabolic pathways using deep transfer learning
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 348
DO  - 10.1186/s12859-023-05485-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171625257&doi=10.1186%2fs12859-023-05485-9&partnerID=40&md5=eb6ff83b1821c79adacbbc8eb9d104a2
AB  - Background: Plant secondary metabolites are highly valued for their applications in pharmaceuticals, nutrition, flavors, and aesthetics. It is of great importance to elucidate plant secondary metabolic pathways due to their crucial roles in biological processes during plant growth and development. However, understanding plant biosynthesis and degradation pathways remains a challenge due to the lack of sufficient information in current databases. To address this issue, we proposed a transfer learning approach using a pre-trained hybrid deep learning architecture that combines Graph Transformer and convolutional neural network (GTC) to predict plant metabolic pathways. Results: GTC provides comprehensive molecular representation by extracting both structural features from the molecular graph and textual information from the SMILES string. GTC is pre-trained on the KEGG datasets to acquire general features, followed by fine-tuning on plant-derived datasets. Four metrics were chosen for model performance evaluation. The results show that GTC outperforms six other models, including three previously reported machine learning models, on the KEGG dataset. GTC yields an accuracy of 96.75%, precision of 85.14%, recall of 83.03%, and F1_score of 84.06%. Furthermore, an ablation study confirms the indispensability of all the components of the hybrid GTC model. Transfer learning is then employed to leverage the shared knowledge acquired from the KEGG metabolic pathways. As a result, the transferred GTC exhibits outstanding accuracy in predicting plant secondary metabolic pathways with an average accuracy of 98.30% in fivefold cross-validation and 97.82% on the final test. In addition, GTC is employed to classify natural products. It achieves a perfect accuracy score of 100.00% for alkaloids, while the lowest accuracy score of 98.42% for shikimates and phenylpropanoids. Conclusions: The proposed GTC effectively captures molecular features, and achieves high performance in classifying KEGG metabolic pathways and predicting plant secondary metabolic pathways via transfer learning. Furthermore, GTC demonstrates its generalization ability by accurately classifying natural products. A user-friendly executable program has been developed, which only requires the input of the SMILES string of the query compound in a graphical interface. © 2023, BioMed Central Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Bao2023Prediction
ER  -

TY  - JOUR
AU  - Tang, W.
AU  - Qing, L.
AU  - Li, L.
AU  - Guo, L.
AU  - Peng, Y.
TI  - Principal relation component reasoning-enhanced social relation recognition
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 23
SP  - 28099
EP  - 28113
DO  - 10.1007/s10489-023-05003-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171746139&doi=10.1007%2fs10489-023-05003-7&partnerID=40&md5=f310434d0ab3a95d6511491fbc710b09
AB  - Abstract: Social relationships (SRs) are the basis of human life. Hence, the ability to accurately recognize interpersonal relations in public spaces based on visual observations helps policymakers improve mental health programs and address social challenges. The key to image-based computer-vision research on SR recognition (SRR) is a deep-learning mechanism that can predict SRs based on the contents of visual scenery images. Current methods explore logical constraints using relatively simple scenes with small groups of people. However, this is insufficient when desiring to form relation graphs of multiple groups simultaneously from complex scenes. Generally, complex scenes contain a principal relationship that applies to the largest proportion of people, and secondary relationships apply to smaller proportions. To effectively explore relational situations in complex scenes, we propose a new distributed reasoning strategy that accounts for principal and secondary SRs. First, our novel model enhances principal relation component reasoning, and a new contrastive learning algorithm supplements the principal relationship with secondary types. A shifted-window transformer is applied to extract interactive human relation features and local-global features to support more accurate and comprehensive relation prediction. Extensive experiments demonstrate that each part of the proposed model improves the accuracy of SRR and that the whole model outperforms state-of-the-art methods on public datasets. Graphical abstract: [Figure not available: see fulltext.] © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Tang2023Principal
ER  -

TY  - JOUR
AU  - Yu, X.
AU  - Yang, Q.
AU  - Zhou, Y.
AU  - Cai, L.Y.
AU  - Gao, R.
AU  - Lee, H.H.
AU  - Li, T.
AU  - Bao, S.
AU  - Xu, Z.
AU  - Lasko, T.A.
AU  - Abramson, R.G.
AU  - Zhang, Z.
AU  - Huo, Y.
AU  - Landman, B.A.
AU  - Tang, Y.
TI  - UNesT: Local spatial representation learning with hierarchical transformer for efficient medical segmentation
PY  - 2023
T2  - Medical Image Analysis
VL  - 90
C7  - 102939
DO  - 10.1016/j.media.2023.102939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171612126&doi=10.1016%2fj.media.2023.102939&partnerID=40&md5=1c45673d470d5993a7e59eb022715065
AB  - Transformer-based models, capable of learning better global dependencies, have recently demonstrated exceptional representation learning capabilities in computer vision and medical image analysis. Transformer reformats the image into separate patches and realizes global communication via the self-attention mechanism. However, positional information between patches is hard to preserve in such 1D sequences, and loss of it can lead to sub-optimal performance when dealing with large amounts of heterogeneous tissues of various sizes in 3D medical image segmentation. Additionally, current methods are not robust and efficient for heavy-duty medical segmentation tasks such as predicting a large number of tissue classes or modeling globally inter-connected tissue structures. To address such challenges and inspired by the nested hierarchical structures in vision transformer, we proposed a novel 3D medical image segmentation method (UNesT), employing a simplified and faster-converging transformer encoder design that achieves local communication among spatially adjacent patch sequences by aggregating them hierarchically. We extensively validate our method on multiple challenging datasets, consisting of multiple modalities, anatomies, and a wide range of tissue classes, including 133 structures in the brain, 14 organs in the abdomen, 4 hierarchical components in the kidneys, inter-connected kidney tumors and brain tumors. We show that UNesT consistently achieves state-of-the-art performance and evaluate its generalizability and data efficiency. Particularly, the model achieves whole brain segmentation task complete ROI with 133 tissue classes in a single network, outperforming prior state-of-the-art method SLANT27 ensembled with 27 networks. Our model performance increases the mean DSC score of the publicly available Colin and CANDI dataset from 0.7264 to 0.7444 and from 0.6968 to 0.7025, respectively. Code, pre-trained models, and use case pipeline are available at: https://github.com/MASILab/UNesT. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; 
LB  - Yu2023UNesT
ER  -

TY  - JOUR
AU  - Chen, G.
AU  - Shi, T.
AU  - Xie, B.
AU  - Zhao, Z.
AU  - Meng, Z.
AU  - Huang, Y.
AU  - Dong, J.
TI  - SwinDAE: Electrocardiogram Quality Assessment Using 1D Swin Transformer and Denoising AutoEncoder
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 12
SP  - 5779
EP  - 5790
DO  - 10.1109/JBHI.2023.3314698
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171791725&doi=10.1109%2fJBHI.2023.3314698&partnerID=40&md5=f3bef06e69387b5203f139d4a776efe0
AB  - Objective: Electrocardiogram (ECG) signals have wide-ranging applications in various fields, and thus it is crucial to identify clean ECG signals under different sensors and collection scenarios. Despite the availability of a variety of deep learning algorithms for ECG quality assessment, these methods still lack generalization across different datasets, hindering their widespread use. Methods: In this paper, an effective model named Swin Denoising AutoEncoder (SwinDAE) is proposed. Specifically, SwinDAE uses a DAE as the basic architecture, and incorporates a 1D Swin Transformer during the feature learning stage of the encoder and decoder. SwinDAE was first pre-trained on the public PTB-XL dataset after data augmentation, with the supervision of signal reconstruction loss and quality assessment loss. Specially, the waveform component localization loss is proposed in this paper and used for joint supervision, guiding the model to learn key information of signals. The model was then fine-tuned on the finely annotated BUT QDB dataset for quality assessment. Results: SwinDAE achieved 0.02-0.13 mean F1 score improvement on the BUT QDB dataset compared to multiple deep learning methods, and demonstrated applicability on two other datasets. Conclusion: The proposed SwinDAE shows strong generalization ability on different datasets, and surpasses other state-of-the-art deep learning methods on multiple evaluation metrics. In addition, the statistical analysis for SwinDAE prove the significance of the performance and the rationality of the prediction. Significance: SwinDAE can learn the commonality between high-quality ECG signals, exhibiting excellent performance in the application of cross-sensors and cross-collection scenarios.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Chen2023SwinDAE
ER  -

TY  - JOUR
AU  - Graham, M.S.
AU  - Tudosiu, P.-D.
AU  - Wright, P.
AU  - Pinaya, W.H.L.
AU  - Teikari, P.
AU  - Patel, A.
AU  - U-King-Im, J.-M.
AU  - Mah, Y.H.
AU  - Teo, J.T.
AU  - Jäger, H.R.
AU  - Werring, D.
AU  - Rees, G.
AU  - Nachev, P.
AU  - Ourselin, S.
AU  - Cardoso, M.J.
TI  - Latent Transformer Models for out-of-distribution detection
PY  - 2023
T2  - Medical Image Analysis
VL  - 90
C7  - 102967
DO  - 10.1016/j.media.2023.102967
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173555884&doi=10.1016%2fj.media.2023.102967&partnerID=40&md5=ee2c7dbd6b2a3f7d60bda0d12fd9bfcc
AB  - Any clinically-deployed image-processing pipeline must be robust to the full range of inputs it may be presented with. One popular approach to this challenge is to develop predictive models that can provide a measure of their uncertainty. Another approach is to use generative modelling to quantify the likelihood of inputs. Inputs with a low enough likelihood are deemed to be out-of-distribution and are not presented to the downstream predictive model. In this work, we evaluate several approaches to segmentation with uncertainty for the task of segmenting bleeds in 3D CT of the head. We show that these models can fail catastrophically when operating in the far out-of-distribution domain, often providing predictions that are both highly confident and wrong. We propose to instead perform out-of-distribution detection using the Latent Transformer Model: a VQ-GAN is used to provide a highly compressed latent representation of the input volume, and a transformer is then used to estimate the likelihood of this compressed representation of the input. We demonstrate this approach can identify images that are both far- and near- out-of-distribution, as well as provide spatial maps that highlight the regions considered to be out-of-distribution. Furthermore, we find a strong relationship between an image's likelihood and the quality of a model's segmentation on it, demonstrating that this approach is viable for filtering out unsuitable images. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Graham2023Latent
ER  -

TY  - JOUR
AU  - Chen, H.-Y.
AU  - Wang, H.-M.
AU  - Lin, C.-H.
AU  - Yang, R.
AU  - Lee, C.-C.
TI  - Lung Cancer Prediction Using Electronic Claims Records: A Transformer-Based Approach
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 12
SP  - 6062
EP  - 6073
DO  - 10.1109/JBHI.2023.3324191
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174812653&doi=10.1109%2fJBHI.2023.3324191&partnerID=40&md5=7071bb43788fe9ebc2b0bd67dfbaa8df
AB  - Electronic claims records (ECRs) are large scale and longitudinal collections of individual's medical service seeking actions. Compared to in-hospital medical records (EMRs), ECRs are more standardized and cross-sites. Recently, there has been studies showing promising results on modeling claims data for a wide range of medical applications. However, few of them address the exclusion criteria on cohort selection to extract new incidence without prior signs and also often lack of emphasis on predicting cancer in early stages. In this work, we aim to design a lung cancer prediction framework using ECRs with rigorous exclusion design using state-of-the-art sequence-based transformer. Furthermore, this work presents one of the first results by applying disease prediction model to the entire population in Taiwan. The result shows over 2.1 predictive power, 5 average positive predictive value (PPV), and 0.668 area under curve (AUC) in all-stage lung cancer and around 2.0 predictive power, 1 average PPV and 0.645 AUC in early-stage in our dataset. Sub-cohort analysis could funnel high precision selective group into prioritized clinical examination. Onset analysis validates the effect of our exclusion criteria. This work presents comprehensive analyses on lung cancer prediction, and the proposed approach can serve as a state-of-the-art disease risk prediction framework on claims data.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Chen2023Lung
ER  -

TY  - JOUR
AU  - Tuli, S.
AU  - Casale, G.
AU  - Jennings, N.R.
TI  - CILP: Co-Simulation-Based Imitation Learner for Dynamic Resource Provisioning in Cloud Computing Environments
PY  - 2023
T2  - IEEE Transactions on Network and Service Management
VL  - 20
IS  - 4
SP  - 4448
EP  - 4460
DO  - 10.1109/TNSM.2023.3268250
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153519528&doi=10.1109%2fTNSM.2023.3268250&partnerID=40&md5=db7d62d95a0c10a1421c51a768ad1fba
AB  - Intelligent Virtual Machine (VM) provisioning is central to cost and resource efficient computation in cloud computing environments. As bootstrapping VMs is time-consuming, a key challenge for latency-critical tasks is to predict future workload demands to provision VMs proactively. However, existing AI-based solutions tend to not holistically consider all crucial aspects such as provisioning overheads, heterogeneous VM costs and Quality of Service (QoS) of the cloud system. To address this, we propose a novel method, called CILP, that formulates the VM provisioning problem as two sub-problems of prediction and optimization, where the provisioning plan is optimized based on predicted workload demands. CILP leverages a neural network as a surrogate model to predict future workload demands with a co-simulated digital-twin of the infrastructure to compute QoS scores. We extend the neural network to also act as an imitation learner that dynamically decides the optimal VM provisioning plan. A transformer based neural model reduces training and inference overheads while our novel two-phase decision making loop facilitates in making informed provisioning decisions. Crucially, we address limitations of prior work by including resource utilization, deployment costs and provisioning overheads to inform the provisioning decisions in our imitation learning framework. Experiments with three public benchmarks demonstrate that CILP gives up to 22% higher resource utilization, 14% higher QoS scores and 44% lower execution costs compared to the current online and offline optimization based state-of-the-art methods.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Tuli2023CILP
ER  -

TY  - JOUR
AU  - Chen, G.
AU  - Wang, H.
AU  - Liu, Y.
AU  - Zhang, M.
AU  - Zhang, F.
TI  - Resformer: Combine quadratic linear transformation with efficient sparse Transformer for long-term series forecasting
PY  - 2023
T2  - Intelligent Data Analysis
VL  - 27
IS  - 6
SP  - 1557
EP  - 1572
DO  - 10.3233/IDA-227006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178589245&doi=10.3233%2fIDA-227006&partnerID=40&md5=b43e8c4961183f7e5cf65c30f50d4876
AB  - With the continuous development of deep learning, long sequence time-series forecasting (LSTF) has attracted more and more attention in power consumption prediction, traffic prediction and stock prediction. In recent studies, various improved models of Transformer are favored. While these models have made breakthroughs in reducing the time and space complexity of Transformer, there are still some problems, such as the predictive power of the improved model being slightly lower than that of Transformer. And these models ignore the importance of special values in the time series. To solve these problems, we designed a more concise network named Resformer, which has four significant characteristics: (1) The fully sparse self-attention mechanism achieves O(LlogL) time complexity. (2) The AMS module is used to process the special values of time series and has comparable performance on sequences dependency alignment. (3) Using quadratic linear transformation, a simple LT module is designed to replace the self-attention mechanism. It effectively reduces redundant information. (4) The DistPooling method based on data distribution is proposed to suppress redundant information and noise. A large number of experiments on real data sets show that the Resformer method is superior to the existing improved model and standard Transformer method. © 2023 IOS Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Chen2023Resformer
ER  -

TY  - JOUR
AU  - Oliveira, G.B.
AU  - Pedrini, H.
AU  - Dias, Z.
TI  - TEMPROT: protein function annotation using transformers embeddings and homology search
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 242
DO  - 10.1186/s12859-023-05375-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161277950&doi=10.1186%2fs12859-023-05375-0&partnerID=40&md5=271b54f530e857d46884c6112bda8f44
AB  - Background: Although the development of sequencing technologies has provided a large number of protein sequences, the analysis of functions that each one plays is still difficult due to the efforts of laboratorial methods, making necessary the usage of computational methods to decrease this gap. As the main source of information available about proteins is their sequences, approaches that can use this information, such as classification based on the patterns of the amino acids and the inference based on sequence similarity using alignment tools, are able to predict a large collection of proteins. The methods available in the literature that use this type of feature can achieve good results, however, they present restrictions of protein length as input to their models. In this work, we present a new method, called TEMPROT, based on the fine-tuning and extraction of embeddings from an available architecture pre-trained on protein sequences. We also describe TEMPROT+, an ensemble between TEMPROT and BLASTp, a local alignment tool that analyzes sequence similarity, which improves the results of our former approach. Results: The evaluation of our proposed classifiers with the literature approaches has been conducted on our dataset, which was derived from CAFA3 challenge database. Both TEMPROT and TEMPROT+ achieved competitive results on Fmax , Smin , AuPRC and IAuPRC metrics on Biological Process (BP), Cellular Component (CC) and Molecular Function (MF) ontologies compared to state-of-the-art models, with the main results equal to 0.581, 0.692 and 0.662 of Fmax on BP, CC and MF, respectively. Conclusions: The comparison with the literature showed that our model presented competitive results compared the state-of-the-art approaches considering the amino acid sequence pattern recognition and homology analysis. Our model also presented improvements related to the input size that the model can use to train compared to the literature methods. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Oliveira2023TEMPROT
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Xu, J.
TI  - Graph transformer-based self-adaptive malicious relation filtering for fraudulent comments detection in social network
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 280
C7  - 111005
DO  - 10.1016/j.knosys.2023.111005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172216090&doi=10.1016%2fj.knosys.2023.111005&partnerID=40&md5=8b26000df7deab16121b55d7854e874e
AB  - In recent years, Graph Neural Networks (GNNs) have proven to be effective in detecting fraud within social networks by gathering information from neighboring nodes to predict fraudulent actions. However, the continuous evolution and camouflaging tactics of fraudsters, such as establishing malicious connections with legitimate users and mimicking their behaviors, can often elude GNN-based detection methods. To tackle this issue, we propose a multi-order moments graph transformer, named MMGT, to effectively learn node representations through an attention mechanism that captures information of different orders of moments. Building upon this foundation, we further introduce a self-adaptive malicious relation filtering model for fraud detection, denoted as SFGT. Initially, we form a multi-relational graph that encapsulates complex relations within a given social network and derive node representations by accumulating neighbor node and edge data based on an enhanced graph transformer. Subsequently, a threshold-based malicious relation filter mechanism is proposed to eliminate malicious links by assessing the distance between nodes. Furthermore, an adaptive threshold learning policy is developed to bolster the model's performance and its ability to generalize. Finally, extensive experiments are carried out on two public datasets, Amazon and YelpChi, which underscores the effectiveness of our proposed model. The experimental results indicate that our model achieves state-of-the-art performance. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Li2023Graph
ER  -

TY  - JOUR
AU  - Fang, G.
AU  - Chen, J.
AU  - Liang, D.
AU  - Asim, M.
AU  - Van Reeth, F.
AU  - Claesen, L.
AU  - Yang, Z.
AU  - Liu, W.
TI  - Feature Correlation Transformer for Estimating Ambiguous Optical Flow
PY  - 2023
T2  - Neural Processing Letters
VL  - 55
IS  - 6
SP  - 7543
EP  - 7559
DO  - 10.1007/s11063-023-11273-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158077733&doi=10.1007%2fs11063-023-11273-6&partnerID=40&md5=1a38a295395258f2327bdedb6cfc89d8
AB  - Cost volume is widely used to establish correspondences in optical flow estimation. However, when dealing with low-texture and occluded areas, it is difficult to estimate the cost volume correctly. Therefore, we propose a replacement: feature correlation transformer (FCTR), a transformer with self- and cross-attention alternations for obtaining global receptive fields and positional embedding for establishing correspondences. With global context and positional information, FCTR can produce more accurate correspondences for ambiguous areas. Using position-embedded feature allows the removal of the context network; the positional information can be aggregated within ambiguous motion boundaries, and the number of model parameters can be reduced. To speed up network convergence and strengthen robustness, we introduce a smooth L1 loss with exponential weights in the pre-training step. At the time of submission, our method achieves competitive performance with all published optical flow methods on both the KITTI-2015 and MPI-Sintel benchmarks. Moreover, it outperforms all optical flow and scene flow methods in KITTI-2015 foreground-region prediction. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Fang2023Feature
ER  -

TY  - JOUR
AU  - Wang, S.
AU  - Hu, C.
AU  - Yi, W.
AU  - Cai, Z.
AU  - Zhai, M.
AU  - Yang, W.
TI  - Flow Learning Based Dual Networks for Low-Light Image Enhancement
PY  - 2023
T2  - Neural Processing Letters
VL  - 55
IS  - 6
SP  - 8115
EP  - 8130
DO  - 10.1007/s11063-023-11303-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160911261&doi=10.1007%2fs11063-023-11303-3&partnerID=40&md5=0dfca98f4c5b59f824b026cced3970bc
AB  - The deep learning-based low-light image enhancement task aims to learn a mapping that converts low-light images to normally exposed images by training with paired or unpaired datasets. Most of these existing methods are based on convolutional neural networks, which largely limits the network’s ability to learn global information. Meanwhile, the reconstruction loss or adversarial loss they adopt often cannot accurately measure the visual distance between the prediction and the target, resulting in blurred regions in the enhancement results. In this paper, we propose a novel flow learning based dual networks (FDN), which consists of a dual network and a flow learning based model. The dual network is mainly composed of a reidual-based Unet encoder and a residual-based Swin Transformer encoder, which can make up for the lack of global information processing and has more advantages in processing deep and shallow information. Moreover, we use a single loss function named negative log-likelihood to train the entire network, which enables the flow models to adequately learn the complex conditional distribution of normally exposed images and avoid blurry outputs. Experimental results on two benchmark datasets show that the proposed FDN method can achieve the sate-of-the-art performances on low-light image enhancement task. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2023Flow
ER  -

TY  - JOUR
AU  - Dai, D.
AU  - Sun, Y.
AU  - Dong, C.
AU  - Yan, Q.
AU  - Li, Z.
AU  - Xu, S.
TI  - Effectively fusing clinical knowledge and AI knowledge for reliable lung nodule diagnosis
PY  - 2023
T2  - Expert Systems with Applications
VL  - 230
C7  - 120634
DO  - 10.1016/j.eswa.2023.120634
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161305069&doi=10.1016%2fj.eswa.2023.120634&partnerID=40&md5=9d16cbc6df93f7833a476bb59d5d61e5
AB  - Clinicians typically use semantic features to judge the malignant status of nodules, while artificial intelligence systems (AI) tend to extract unknown features to diagnose nodules. The former relies on clinical knowledge, while the latter explores AI knowledge. Although many studies indicate that fusing clinical and AI knowledge can help computer-aided diagnosis (CAD) systems improve diagnostic accuracy and gain clinician approval, how to effectively fuse them is still an open question. This paper proposes a simple and effective pipeline (abbreviated as CKAK), which fuses clinical and AI knowledge at both feature and decision levels for accurate lung nodule malignancy classification and semantic attributes characterization. The feature-level fusion can retain rich information in high-dimensional features and improve the model's accuracy; the decision-level fusion can provide some interpretability for the model's decision-making process, which is expected in clinical applications. Specifically, the proposed CKAK consists of two sequential stages: (i) the initial prediction stage (IPS); and (ii) the prediction refine stage (PRS). The IPS predicts eight radiologist-interpreted semantic attributes and an initial malignancy diagnosis in parallel. Then, these results are fed to the subsequent PRS to refine the diagnosis further by fully fusing them at feature and decision levels. Besides, to enhance the ability of feature learning, we propose a novel scale-aware feature extraction block (SAFE). It integrates multi-scale contextual features with a lightweight Transformer rather than adding or concatenating them roughly. Extensive experiments at the LIDC-IDRI data set show that the proposed CKAK can achieve superior benign-malignant classification accuracy with minor radiologist-interpreted semantic scores error, meeting the need for a reliable CAD system. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Dai2023Effectively
ER  -

TY  - JOUR
AU  - Du, H.
AU  - Zhang, Q.
AU  - Li, K.
AU  - Zhao, F.
AU  - Wang, G.
TI  - Multi-transformer based on prototypical enhancement network for few-shot relation classification with domain adaptation
PY  - 2023
T2  - Neurocomputing
VL  - 559
C7  - 126796
DO  - 10.1016/j.neucom.2023.126796
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172893478&doi=10.1016%2fj.neucom.2023.126796&partnerID=40&md5=ea9ed6bc0e7ee0e8ba4ba0c0a609dabe
AB  - Few-shot relation classification aims to predict the relation between entity pairs in unseen sentences with a few labeled sentences. In real-world scenarios, the target domains often have limited data and could differ significantly from the source domains. Existing studies focus on the representation of entity pairs, ignoring the relation between the sentences and the entity pairs. Some researchers use feature-adaptive methods that do not consider that features contribute differently to relation classification. To solve these challenges, a multi-transformer based on a prototypical enhancement network (MTPEnet) is presented for few-shot relation classification with domain adaptation in this study. Specifically, for MTPEnet, two main parts are conducted. First, in the calculation of the prototype, a local and global representations (LGR) module is established to improve the representation of sentences. LGR considers not only the head and tail entities in a sentence but also the relation between the entity pair and the entire sentence. Second, a multi-transformer (MT) feature transformation module is introduced to address the cross-domain problem. Different weights are assigned to the target domain features according to the degree of fusion between the features in the target and source domains. Finally, the experimental results on the datasets FewRel 2.0 and FewTAC demonstrate the superiority of MTPEnet over several baseline models. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Du2023Multi-transformer
ER  -

TY  - JOUR
AU  - Zeng, C.
AU  - Kwong, S.
AU  - Ip, H.
TI  - Dual Swin-transformer based mutual interactive network for RGB-D salient object detection
PY  - 2023
T2  - Neurocomputing
VL  - 559
C7  - 126779
DO  - 10.1016/j.neucom.2023.126779
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172300594&doi=10.1016%2fj.neucom.2023.126779&partnerID=40&md5=fcc92c6d53cc282d225b40fb5026eca2
AB  - Depth information for RGB-D Salient Object Detection(SOD) is important and conventional deep models are usually relied on the CNN feature extractors. The long-range contextual dependencies, dense modeling on the saliency decoder, and multi-task learning assistance are usually ignored. In this work, we propose a Dual Swin-Transformer-based Mutual Interactive Network (DTMINet), aiming to learn contextualized, dense, and edge-aware features for RGB-D SOD. We adopt the Swin-Transformer as the visual backbone to extract contextualized features. A self-attention-based Cross-Modality Interaction module is proposed to strengthen the visual backbone for cross-modal interaction. In addition, a Gated Modality Attention module is designed for cross-modal fusion. At different decoding stages, enhanced with dense connections and progressively merge the multi-level encoding features with the proposed Dense Saliency Decoder. Considering the depth quality issue, a Skip Convolution module is introduced to provide guidance to the RGB modality for the saliency prediction. In addition, we add the edge prediction to the saliency predictor to regularize the learning process. Comprehensive experiments on five standard RGB-D SOD benchmark datasets over four evaluation metrics demonstrate the superiority of the proposed method. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Zeng2023Dual
ER  -

TY  - JOUR
AU  - Zhu, J.
AU  - Bai, W.
AU  - Zhao, J.
AU  - Zuo, L.
AU  - Zhou, T.
AU  - Li, K.
TI  - Variational mode decomposition and sample entropy optimization based transformer framework for cloud resource load prediction
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 280
C7  - 111042
DO  - 10.1016/j.knosys.2023.111042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173545586&doi=10.1016%2fj.knosys.2023.111042&partnerID=40&md5=e805c6789a372e8912b6a339e3151ffc
AB  - The efficient prediction of cloud resource demand plays a crucial role in resource allocation and scheduling in cloud data centers, helping to optimize resource utilization and improve service quality. However, accurately predicting cloud resource demand poses challenges due to the failure of prediction models in real-world scenarios, such as extreme load peaks, and the limitation of computation burden on the global characterization capability. To effectively handle single-variable cloud resource load time series with multidimensional hidden factors, we propose a sample entropy-optimized variational model decomposition transformer (VMDSE-Tformer) for cloud resource scheduling. Hereby, we decompose the time series through variational model decomposition, and then reconstruct the subsequence collection using sample entropy calculation. Then, we use a class Transformer framework with a multi-head self-attention mechanism to learn deep features and obtain encoding representations of each component sequence. We conduct sufficient experiments on three benchmark datasets by comparing them with five state-of-the-art models. Notably, the MAPE of VMDSE-Tformer is improved by about 60% compared to LSTNet. The results demonstrate the superior performance of our VMDSE-Tformer in terms of predicting task sequence intensity, CPU, and RAM resource demand. Therefore, VMDSE-Tformer can serve as a powerful and efficient tool to predict resource demand in cloud data centers, with implications for more effective resource management and service delivery. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; FMS:C; 
LB  - Zhu2023Variational
ER  -

TY  - JOUR
AU  - Jung, J.
AU  - Lee, S.
AU  - Shin, J.
AU  - Kim, Y.
TI  - Self-Attention-Based Uplink Radio Resource Prediction in 5G Dual Connectivity
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 22
SP  - 19925
EP  - 19936
DO  - 10.1109/JIOT.2023.3283490
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162642786&doi=10.1109%2fJIOT.2023.3283490&partnerID=40&md5=7c48127c90674a93b8aa8957d1e06a16
AB  - Mobile communication technology is evolving rapidly and becoming increasingly ubiquitous, thereby increasing the demand for uplink data-intensive applications (e.g., personal broadcasting and live augmented/virtual reality videos). Recently, to facilitate a cost-effective and smooth transition from 4G to 5G networks, most carriers leverage existing 4G infrastructures using a dual connectivity (DC) feature. DC increases uplink throughput and mobility robustness; however, it also causes unprecedented dynamic fluctuations in radio channels due to the coverage discrepancy between 4G and 5G networks. Thus, in this article, we propose a self-attention-based deep learning model to predict uplink radio resources in 5G DC. We trained the proposed model on commercial 5G DC traffic data from three major carriers in South Korea and obtained an average prediction accuracy of 95.08% under various mobility and cell-load conditions. The proposed model explains the rationale for the obtained predictions by highlighting the parts of the input time-series data that are important to realize accurate prediction. We also demonstrate the usability of the proposed model using a network emulator based on real-world 5G trace data. Extensive evaluations demonstrate that the existing congestion control algorithms can achieve excellent performance when used with the proposed model.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Jung2023Self-Attention-Based
ER  -

TY  - JOUR
AU  - Yang, M.
AU  - Liu, Z.
AU  - Dong, W.
AU  - Wu, Y.
TI  - SSTNet: Saliency sparse transformers network with tokenized dilation for salient object detection
PY  - 2023
T2  - IET Image Processing
VL  - 17
IS  - 13
SP  - 3759
EP  - 3776
DO  - 10.1049/ipr2.12895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166436957&doi=10.1049%2fipr2.12895&partnerID=40&md5=324a6a76997de20f5de1ef596008314b
AB  - The vision Transformer structure performs better in salient object detection than the convolutional neural network (CNN)-based approach. Vision Transformer predicts saliency by modelling long-range dependencies from sequence to sequence with convolution-free. It is challenging to distinguish the salient objects' location and obtain structural details for the influence of extracting irrelevant contextual information. A novel saliency sparse Transformer network is proposed to exploit sparse attention to guide saliency prediction. The convolution-like with dilation in the token to token (T2T) module is replaced to achieve relationships in larger regions and to improve contextual information fusion. An adaptive position bias module is designed for the Vision Transformer to make position bias suitable for variable-sized RGB images. A saliency sparse Transformer module is designed to improve the concentration of attention on the global context by selecting the Top-k of the most relevant segments to improve the detection results further. Besides, cross-modality to exploit the complementary RGB and depth modality fusion module (CMF) is used to take advantage of the complementary RGB image features and spatial depth information to enhance the feature fusion performance. Extensive experiments on multiple benchmark datasets demonstrate this method's effectiveness and superiority that it is suitable for saliency prediction comparable to state-of-the-art RGB and RGB-D saliency methods. © 2023 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Yang2023SSTNet
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Wang, J.
AU  - Xing, J.
TI  - Attribute-guided transformer for robust person re-identification
PY  - 2023
T2  - IET Computer Vision
VL  - 17
IS  - 8
SP  - 977
EP  - 992
DO  - 10.1049/cvi2.12215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162621434&doi=10.1049%2fcvi2.12215&partnerID=40&md5=fb86c542db1b849f45d9491ad1f2fa3f
AB  - Recent studies reveal the crucial role of local features in learning robust and discriminative representations for person re-identification (Re-ID). Existing approaches typically rely on external tasks, for example, semantic segmentation, or pose estimation, to locate identifiable parts of given images. However, they heuristically utilise the predictions from off-the-shelf models, which may be sub-optimal in terms of both local partition and computational efficiency. They also ignore the mutual information with other inputs, which weakens the representation capabilities of local features. In this study, the authors put forward a novel Attribute-guided Transformer (AiT), which explicitly exploits pedestrian attributes as semantic priors for discriminative representation learning. Specifically, the authors first introduce an attribute learning process, which generates a set of attention maps highlighting the informative parts of pedestrian images. Then, the authors design a Feature Diffusion Module (FDM) to iteratively inject attribute information into global feature maps, aiming at suppressing unnecessary noise and inferring attribute-aware representations. Last, the authors propose a Feature Aggregation Module (FAM) to exploit mutual information for aggregating attribute characteristics from different images, enhancing the representation capabilities of feature embedding. Extensive experiments demonstrate the superiority of our AiT in learning robust and discriminative representations. As a result, the authors achieve competitive performance with state-of-the-art methods on several challenging benchmarks without any bells and whistles. © 2023 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wang2023Attribute-guided
ER  -

TY  - JOUR
AU  - Zhu, N.
AU  - Dai, Z.
AU  - Wang, Y.
AU  - Zhang, K.
TI  - A contrastive learning-based framework for wind power forecast
PY  - 2023
T2  - Expert Systems with Applications
VL  - 230
C7  - 120619
DO  - 10.1016/j.eswa.2023.120619
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161701206&doi=10.1016%2fj.eswa.2023.120619&partnerID=40&md5=3b405e3ce0d7b139f4cada34bee0e786
AB  - The feature representation of wind power sequences is crucial in the modeling of short-tern wind power forecast, but the existing feature representation methods mostly depend on the end-to-end model based on supervised learning, ignoring the superiority of self-supervised learning in the feature distribution of similar and non-similar sequences in the feature space. Therefore, this paper applies contrastive learning that is a type of self-supervised learning for the feature representation of wind power sequences, and proposes a two-stage framework for the wind power forecast (CLFNet). Specifically, the proposed framework is composed of the pre-training stage and the regression stage. The pre-training stage uses contrastive learning to supply a support for the optimization of the parameters of the network architectures, allowing the trend consistency sequences to obtain more correlated feature representations; the regression stage takes a projection layer, connected after the well-trained network architecture in the pre-training stage, to output wind power, and then fine-tunes the parameter of this network architecture using MSE loss. The proposed framework is applied for various network architectures including LSTM, CNN, and Transformer, and the results of RMSE, MAE, R2 confirm that the proposed framework is widely suitable for various basis network architectures and can outperform the initial basis network architectures by a mean increase rate of 8.94%, 8.5%, and 8.5%, respectively, among forecast steps. In addition, compared the proposed method with state-of-the-art schemes in the wind power forecasting system, the results show that the proposed framework can generate improved performance with accuracy and robustness. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhu2023contrastive
ER  -

TY  - JOUR
AU  - Kim, Y.
AU  - Kwon, J.
TI  - AttSec: protein secondary structure prediction by capturing local patterns from attention map
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 183
DO  - 10.1186/s12859-023-05310-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158034168&doi=10.1186%2fs12859-023-05310-3&partnerID=40&md5=43e4996434c93937727f24922a2fdb78
AB  - Background: Protein secondary structures that link simple 1D sequences to complex 3D structures can be used as good features for describing the local properties of protein, but also can serve as key features for predicting the complex 3D structures of protein. Thus, it is very important to accurately predict the secondary structure of the protein, which contains a local structural property assigned by the pattern of hydrogen bonds formed between amino acids. In this study, we accurately predict protein secondary structure by capturing the local patterns of protein. For this objective, we present a novel prediction model, AttSec, based on transformer architecture. In particular, AttSec extracts self-attention maps corresponding to pairwise features between amino acid embeddings and passes them through 2D convolution blocks to capture local patterns. In addition, instead of using additional evolutionary information, it uses protein embedding as an input, which is generated by a language model. Results: For the ProteinNet DSSP8 dataset, our model showed 11.8% better performance on the entire evaluation datasets compared with other no-evolutionary-information-based models. For the NetSurfP-2.0 DSSP8 dataset, it showed 1.2% better performance on average. There was an average performance improvement of 9.0% for the ProteinNet DSSP3 dataset and an average of 0.7% for the NetSurfP-2.0 DSSP3 dataset. Conclusion: We accurately predict protein secondary structure by capturing the local patterns of protein. For this objective, we present a novel prediction model, AttSec, based on transformer architecture. Although there was no dramatic accuracy improvement compared with other models, the improvement on DSSP8 was greater than that on DSSP3. This result implies that using our proposed pairwise feature could have a remarkable effect for several challenging tasks that require finely subdivided classification. Github package URL is https://github.com/youjin-DDAI/AttSec . © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Kim2023AttSec
ER  -

TY  - JOUR
AU  - Bajaj, A.
AU  - Kumar Vishwakarma, D.
TI  - Evading text based emotion detection mechanism via adversarial attacks
PY  - 2023
T2  - Neurocomputing
VL  - 558
C7  - 126787
DO  - 10.1016/j.neucom.2023.126787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172986167&doi=10.1016%2fj.neucom.2023.126787&partnerID=40&md5=3bb05c63e622f2ea4b2ef80084ded0ab
AB  - Textual Emotion Analysis (TEA) seeks to extract and assess the emotional states of users from the text. Various Deep Learning (DL) algorithms have emerged rapidly and demonstrated success in numerous disciplines, including audio, image, and natural language processing. The trend has shifted a growing number of researchers from standard machine learning to DL for scientific study. Using DL approaches, we offer an overview of TEA in this paper. After introducing the background for emotion analysis, including the definition of emotion, emotion classification methods, and application domains of emotion analysis, we demonstrated that, despite the immense success of deep learning models in NLP-related tasks, they are susceptible to adversarial attacks, which can lead to incorrect emotion classification. An adversarial text is constructed by altering a few words or characters so as to keep the overall semantic similarity of emotion for a human reader while tricking the machine into making erroneous predictions. This study demonstrates the vulnerability of emotion categorization by generating adversarial text using a variety of cutting-edge attack techniques. Comprehensive experiments are performed to assess the effectiveness of the attack methods against several widely-used models, such as Word-CNN, Bi-LSTM, and four powerful transformer models, namely BERT, DistilBERT, ALBERT, and RoBERTa. These models were trained on an emotion dataset utilized for the purpose of emotion classification. We evaluated and analyzed the behavior of different models under a variety of attack conditions to determine which is the most and least vulnerable. Also, we determine which perturbation technique affects transformer models the most. Using Attack Success Rates (ASR) as our evaluation metric, we have assessed the potential outcomes. The findings reveal that methodologies for classifying emotion prediction can be circumvented, which has implications for existing policy measures. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Bajaj2023Evading
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Li, Z.
AU  - Yang, X.
AU  - Ma, H.
TI  - Causal-ViT: Robust Vision Transformer by causal intervention
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 107123
DO  - 10.1016/j.engappai.2023.107123
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171471359&doi=10.1016%2fj.engappai.2023.107123&partnerID=40&md5=2e507631c627650da4faa0fb0a55aa71
AB  - Artificial intelligence based on deep learning is better at improving the representation ability of models from data. However, due to the limitation of fixed receptive field, these agents are not able to provide a correct response outside the fixed receptive field. To address this problem, this paper provides a new perspective with improving the Image Recognition tasks. This study firstly constructs two extended receptive fields using structural causal model. Then, an approximate intervention method that changes the traditional likelihood prediction to predict the result of causal intervention is proposed. Finally, this study formulates the objective function to adapt the proxy training, which makes the whole model work well. Above all of these, a new Vision Transformer variant named Causal-ViT is proposed. Furthermore, rich experimental results of different tasks are reported. These results show that the proposed perspective makes a significant improvement in Image Recognition tasks. By simply plugging Causal-ViT to different sub-tasks, all of them bring the new benchmarks of themselves field, which proves our method is flexible. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Li2023Causal-ViT
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Xiao, T.
AU  - Wang, Z.
AU  - Lv, H.
AU  - Wang, S.
AU  - Feng, H.
AU  - Zhao, S.
AU  - Zhao, Y.
TI  - Hybrid Network for Patient-Speci¯c Seizure Prediction from EEG Data
PY  - 2023
T2  - International Journal of Neural Systems
VL  - 33
IS  - 11
C7  - 2350056
DO  - 10.1142/S0129065723500569
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175404799&doi=10.1142%2fS0129065723500569&partnerID=40&md5=6fa7ed4e6314b58ade5b4d396d92ec71
AB  - Seizure prediction can improve the quality of life for patients with drug-resistant epilepsy. With the rapid development of deep learning, lots of seizure prediction methods have been proposed. However, seizure prediction based on single convolution models is limited by the inherent defects of convolution itself. Convolution pays attention to the local features while underestimates the global features. The long-term dependence of the electroencephalogram (EEG) data cannot be captured. In view of these defects, a hybrid model called STCNN based on Swin transformer (ST) and 2D convolutional neural network (2DCNN) is proposed. Time-frequency features extracted by short-term Fourier transform (STFT) are taken as the input of STCNN. ST blocks are used in STCNN to capture the global information and long-term dependencies of EEGs. Meanwhile, the 2DCNN blocks are adopted to capture the local information and short-term dependent features. The combination of the two blocks can fully exploit the seizure-related information thus improve the prediction performance. Comprehensive experiments are performed on the CHB-MIT scalp EEG dataset. The average seizure prediction sensitivity, the area under the ROC curve (AUC) and the false positive rate (FPR) are 92.94%, 95.56% and 0.073, respectively. © World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zhang2023Hybrid
ER  -

TY  - JOUR
AU  - Deng, R.
AU  - Chen, Z.-M.
AU  - Chen, H.
AU  - Hu, J.
TI  - Learning to refine object boundaries
PY  - 2023
T2  - Neurocomputing
VL  - 557
C7  - 126742
DO  - 10.1016/j.neucom.2023.126742
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169030336&doi=10.1016%2fj.neucom.2023.126742&partnerID=40&md5=499964a492511059ef9e9d508c864699
AB  - Existing Deep-Learning-based contour detectors suffer from the issues of the sharpness and the correctness of their predictions, which often need offline post-processing to sharpen the results as well as improve model performance. In this work, we present a novel method that can learn to refine object contour in training and directly output crisp object boundaries in inference. To this end, we first introduce a keypoint-focal loss that draws point-based attention to the isolated contour annotations. It allows an edge detector to jointly optimize the appearance thickness and the localization accuracy of predictions in the training procedure. Moreover, we present a regularization loss to further improve the performance of an edge detector. Lastly, we present the Contour Transformer model for precisely localizing object boundaries in images. We repurpose and integrate a Transformer-style hyper module into an encoder–decoder network, effectively aggregating global contextual information on high-level features and significantly enhancing the discriminative power for classifying foreground/background pixels. We train and test our Attention and Contour Transformer detector (ACTD) on four widely adopted datasets, i.e., BSDS500, NYUD, Multi-Cue, and RoadNet. The proposed method achieves an ODS F-score of 0.826 on BSDS500 and an ODS F-score of 0.783 on NYUD, outperforming previous top detectors. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Deng2023Learning
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Xie, J.
AU  - Zhao, X.
AU  - He, Q.
AU  - Wang, R.
TI  - Screening out potentially defective products in micro-transformer production by intelligently integrating mechanical and electronic signals
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 107186
DO  - 10.1016/j.engappai.2023.107186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172085689&doi=10.1016%2fj.engappai.2023.107186&partnerID=40&md5=f95927d144ad2dc1a235b0253f403ca9
AB  - Along with unstable mechanical status, the critical uncertainty of micro-transformer at electronic specification boundary leads to potentially defective products (PDPs) in qualified products. Hence, an intelligent prediction of PDPs is proposed by integrating mechanical and electronic signals and tracing defective product information. The objective is to screen out the PDPs by the relationship between critical state of normal test equipment and the defective ex-factory products in actual production. On the base of time and frequency domain eigenvalues, Artificial Neural Network (ANN) and Naïve Bayes (NB) were firstly employed to process the vibration signal of equipment testing probe for network training and prior probability, respectively. Then, the various electronic signals related to quality performance parameters were categorized to screen out the PDPs by K-Nearest Neighbor (KNN) and Support Vector Machine (SVM) along with spatial distance and hyperplane databases, respectively. Finally, the screen-out threshold was introduced to evaluate the reasonableness with reference to the phase-out divergence. It is shown that the NB more precisely recognizes the equipment status by timely updating small and incomplete samples than the ANN. Compared to the SVM, the KNN validly screens out the PDPs due to its superior processing capability of electronic signals. As a result, the screen-out threshold is set as 5–6% to balance the screen-out number and precision. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2023Screening
ER  -

TY  - JOUR
AU  - Khoshsirat, S.
AU  - Kambhamettu, C.
TI  - A transformer-based neural ODE for dense prediction
PY  - 2023
T2  - Machine Vision and Applications
VL  - 34
IS  - 6
C7  - 113
DO  - 10.1007/s00138-023-01465-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173095977&doi=10.1007%2fs00138-023-01465-4&partnerID=40&md5=722614766a426c23a41c3bb1139f061a
AB  - Neural ordinary differential equations (ODEs) represent an emergent class of deep learning models exhibiting continuous depth. While they have shown promising results across various machine learning tasks, existing methods for dense prediction tasks have not fully harnessed their potential, often due to employing sub-optimal architectural components and limited dataset studies. To address this, our paper introduces a robust neural ODE architecture specifically tailored for dense prediction tasks and performs an extensive evaluation across a broad range of datasets. Our approach draws upon proven design elements from top-performing networks, integrating transformer blocks as core building blocks. Unique to our design is the retention of multiple concurrent representations at varying resolutions throughout the network. These representations continually exchange information, ensuring they remain updated. Our network achieves unrivaled performance in tasks such as image classification, semantic segmentation, and answer grounding. We conduct several ablation studies to shed light on the impacts of various design parameters. Our results affirm the effectiveness of our approach and its potential for further advancements in dense prediction tasks. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Khoshsirat2023transformer-based
ER  -

TY  - JOUR
AU  - Cui, J.
AU  - Xiao, J.
AU  - Hou, Y.
AU  - Wu, X.
AU  - Zhou, J.
AU  - Peng, X.
AU  - Wang, Y.
TI  - Unsupervised Domain Adaptive Dose Prediction via Cross-Attention Transformer and Target-Specific Knowledge Preservation
PY  - 2023
T2  - International Journal of Neural Systems
VL  - 33
IS  - 11
C7  - 2350057
DO  - 10.1142/S0129065723500570
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173209584&doi=10.1142%2fS0129065723500570&partnerID=40&md5=be47fedecd589d72faf7d9a726d374a5
AB  - Radiotherapy is one of the leading treatments for cancer. To accelerate the implementation of radiotherapy in clinic, various deep learning-based methods have been developed for automatic dose prediction. However, the effectiveness of these methods heavily relies on the availability of a substantial amount of data with labels, i.e.The dose distribution maps, which cost dosimetrists considerable time and effort to acquire. For cancers of low-incidence, such as cervical cancer, it is often a luxury to collect an adequate amount of labeled data to train a well-performing deep learning (DL) model. To mitigate this problem, in this paper, we resort to the unsupervised domain adaptation (UDA) strategy to achieve accurate dose prediction for cervical cancer (target domain) by leveraging the well-labeled high-incidence rectal cancer (source domain). Specifically, we introduce the cross-Attention mechanism to learn the domain-invariant features and develop a cross-Attention transformer-based encoder to align the two different cancer domains. Meanwhile, to preserve the target-specific knowledge, we employ multiple domain classifiers to enforce the network to extract more discriminative target features. In addition, we employ two independent convolutional neural network (CNN) decoders to compensate for the lack of spatial inductive bias in the pure transformer and generate accurate dose maps for both domains. Furthermore, to enhance the performance, two additional losses, i.e. a knowledge distillation loss (KDL) and a domain classification loss (DCL), are incorporated to transfer the domain-invariant features while preserving domain-specific information. Experimental results on a rectal cancer dataset and a cervical cancer dataset have demonstrated that our method achieves the best quantitative results with ΔD98, ΔD95, and HI of 1.446, 1.231, and 0.082, respectively, and outperforms other methods in terms of qualitative assessment. © 2023 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Cui2023Unsupervised
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Dong, Y.
AU  - Zhu, W.
AU  - Zhang, J.
AU  - Liu, S.
AU  - Lu, D.
AU  - Zeng, N.
AU  - Li, Y.
TI  - CLformer: Constraint-based Locality enhanced Transformer for anomaly detection of ancient building structures
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 107072
DO  - 10.1016/j.engappai.2023.107072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171161602&doi=10.1016%2fj.engappai.2023.107072&partnerID=40&md5=61fa4b72d2d135eb583f97827e6e0c48
AB  - Ancient buildings are valuable heritage and non-renewable resources. Existing warning mechanisms typically rely on degradation causation analysis. However, it has limitations of complex research, poor generalization, and inadequate warnings. To address these challenges, we propose a novel algorithm, the core component is the constraint-based locality enhanced transformer (CLformer), leveraging multi-scale causal convolution (MSCC) to enhance the local features extraction. Utilizing a generative prediction to reduce error accumulation and improve accuracy. Additionally, a block recurrent prediction strategy is introduced to further optimize the model, reducing the time complexity to [Formula presented] and the space complexity to O(k2), accelerating the inference speed and run efficiency. Then, CLformer is compared with five other models using two ancient building cases. The results show that the root mean square error (RMSE) and mean absolute error (MAE) of CLformer have significantly improved, and the area under the receiver operating characteristic curve (AUC) value is the largest, which proves its superiority and effectiveness. The generalization and robustness are validated through ablation experiments and six additional real cases. Finally, the algorithm is implemented in engineering and employed in practice, providing valuable guidelines and applications for the conservation of ancient buildings worldwide. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wu2023CLformer
ER  -

TY  - JOUR
AU  - Qu, H.
AU  - Di, L.
AU  - Liang, J.
AU  - Liu, H.
TI  - U-SMR: U-SwinT & multi-residual network for fabric defect detection
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 107094
DO  - 10.1016/j.engappai.2023.107094
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171626540&doi=10.1016%2fj.engappai.2023.107094&partnerID=40&md5=556da8127e794abb5c90c807e026afce
AB  - Fabric defect detection methods based on deep networks are widely used in the textile industry, but they often suffer from poor model generalization and blurry edge detection. To resolve these challenges, we propose a novel network called “U-SMR Net”, which integrates global contextual features, defect detail features, and high-level semantic features through the combination of ResNet-50 and Swin Transformer modules. Our U-SMR network includes a lightweight multiscale feature extraction module, the dual-branch pyramid Module (DBPM), which is nested to preserve high-resolution, shallow semantic information. We propose a recursive multi-level residual decoding block for multiscale fusion to refine, filter, and enhance input characteristics, generating prediction maps at multiple stages, and by employing an improved binary cross entropy loss function to supervise saliency mapping. The experimental results based on four groups from ZJU-Leaper dataset demonstrate the superior performance of our approach compared to other competitive methods by achieving an average fmeasure score of 75.33%, and finally testing results from both ZJU-Leaper-Total dataset and the HKU-Fabric dataset further support our U-SMR Net's validity and generalization ability. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Qu2023U-SMR
ER  -

TY  - JOUR
AU  - Memarzadeh, H.
AU  - Ghadiri, N.
AU  - Samwald, M.
AU  - Lotfi Shahreza, M.
TI  - Applying unsupervised keyphrase methods on concepts extracted from discharge sheets
PY  - 2023
T2  - Pattern Analysis and Applications
VL  - 26
IS  - 4
SP  - 1715
EP  - 1727
DO  - 10.1007/s10044-023-01198-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173033783&doi=10.1007%2fs10044-023-01198-0&partnerID=40&md5=fe18437f836af207ef78a16aeac2ad05
AB  - Clinical notes contain valuable patient information. These notes are written by health care providers with various scientific levels and writing styles. It might be helpful for clinicians and researchers to understand what information is essential when dealing with extensive electronic medical records. Entities recognizing them and mapping them to standard terminologies is crucial to reducing ambiguity in processing clinical notes. Although named entity recognition and entity linking are critical steps in clinical natural language processing, they can produce repetitive and low-value concepts. On the other hand, all parts of a clinical text do not share the same importance or content in predicting the patient's condition. As a result, it is necessary to identify the section in which each content item is recorded and critical concepts to extract meaning from clinical texts. In this study, these challenges have been addressed by using clinical natural language processing techniques. In addition, a set of unsupervised essential phrase extraction methods has been verified and evaluated to identify key concepts. Considering that most clinical concepts are in the form of multi-word expressions and their accurate identification requires the user to specify an n-gram range, we have proposed a shortcut method to preserve the structure of the term based on TF-IDF (Term Frequency Inverse Document Frequency). To evaluate, we have designed two types of downstream tasks (multiple and binary classification) using the capabilities of transformer-based models. The results show the proposed method's superiority in combination with the SciBERT model. Also, they offer an insight into the efficacy of general methods for extracting essential phrases from clinical notes. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Memarzadeh2023Applying
ER  -

TY  - JOUR
AU  - Ning, Z.
AU  - Wu, J.
AU  - Ding, Y.
AU  - Wang, Y.
AU  - Peng, Q.
AU  - Fu, L.
TI  - BertNDA: A Model Based on Graph-Bert and Multi-Scale Information Fusion for ncRNA-Disease Association Prediction
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 11
SP  - 5655
EP  - 5664
DO  - 10.1109/JBHI.2023.3311808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171589004&doi=10.1109%2fJBHI.2023.3311808&partnerID=40&md5=4127e9fa1280474e15260910d0df1c78
AB  - Non-coding RNAs (ncRNAs) are a class of RNA molecules that lack the ability to encode proteins in human cells, but play crucial roles in various biological process. Understanding the interactions between different ncRNAs and their impact on diseases can significantly contribute to diagnosis, prevention, and treatment of diseases. However, predicting tertiary interactions between ncRNAs and diseases based on structural information in multiple scales remains a challenging task. To address this challenge, we propose a method called BertNDA, aiming to predict potential relationships between miRNAs, lncRNAs, and diseases. The framework identifies the local information through connectionless subgraph, which aggregate neighbor nodes' feature. And global information is extracted by leveraging Laplace transform of graph structures and WL (Weisfeiler-Lehman) absolute role coding. Additionally, an EMLP (Element-wise MLP) structure is designed to fuse pairwise global information. The transformer-encoder is employed as the backbone of our approach, followed by a prediction-layer to output the final correlation score. Extensive experiments demonstrate that BertNDA outperforms state-of-the-art methods in prediction assignment and exhibits significant potential for various biological applications. Moreover, we develop an online prediction platform that incorporates the prediction model, providing users with an intuitive and interactive experience. Overall, our model offers an efficient, accurate, and comprehensive tool for predicting tertiary associations between ncRNAs and diseases.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Ning2023BertNDA
ER  -

TY  - JOUR
AU  - Zhu, W.
AU  - Xu, L.
AU  - Meng, J.
TI  - Consistency-based self-supervised visual tracking by using query-communication transformer
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 278
C7  - 110849
DO  - 10.1016/j.knosys.2023.110849
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167436461&doi=10.1016%2fj.knosys.2023.110849&partnerID=40&md5=45f33fee6e0cfb47d1960994efe31c99
AB  - Self-supervised learning (SSL) performs remarkably in visual tracking since it enables the extraction of general representations from unlabeled data and alleviates the need for expensive human annotations. SSL models usually achieve frame-to-frame communications during training by predicting each object location of intermediate frames, however, the possible prediction errors may accumulate and mislead the forward–backward tracking procedure. A novel query-communication transformer (QCT) architecture is proposed in this work to enable more reliable frame-to-frame communications via propagating query information, avoiding the above-mentioned tracking errors on intermediate frames tactfully. Specifically, we introduce the transformer into self-supervised tracking to handle the object template and search frames, i.e., the encoder encodes spatio-temporal context of template and search frames, while the decoder takes the query embedding of previous frame to retrieve the template object information from the encoder output. To further enhance the query embedding, a query interaction module is devised to promote information passing between frames. Moreover, we employ inter-frame correspondence and intra-frame correspondence to construct different views and transformations for better learning the representation from palindromic sequences. We validate our method on the seven challenging benchmarks. The results demonstrate considerable improvements over recent self-supervised algorithms and even some fully-supervised deep trackers. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; 
LB  - Zhu2023Consistency-based
ER  -

TY  - JOUR
AU  - Gu, F.
AU  - Lu, J.
AU  - Cai, C.
TI  - A robust attention-enhanced network with transformer for visual tracking
PY  - 2023
T2  - Multimedia Tools and Applications
VL  - 82
IS  - 26
SP  - 40761
EP  - 40782
DO  - 10.1007/s11042-023-15168-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151446667&doi=10.1007%2fs11042-023-15168-5&partnerID=40&md5=eeba246833c224960fb3010be2982393
AB  - Recently, Siamese-based trackers have become particularly popular. The correlation module in these trackers is responsible for fusing the feature information from the template and the search region, to obtain the response results. However, there are very rich contextual information and feature dependencies among video sequences, and it is difficult for a simple correlation module to efficiently integrate useful information. Therefore, the tracker encounters the challenges of information loss and local optimal solutions. In this work, we propose a novel attention-enhanced network with a Transformer variant for robust visual tracking. The proposed method carefully designs the local feature information association module (LFIA) and the global feature information fusion module (GFIF) based on the attention mechanism, which can effectively utilize contextual information and feature dependencies to enhance feature information. Our approach transforms the visual tracking problem into a bounding box prediction problem, using only a simple prediction network for object localization, without any prior knowledge. Ultimately, we propose a robust tracker called RANformer. Experiments show that the proposed tracker achieves state-of-the-art performance on 7 popular tracking benchmarks while meeting real-time requirements with a speed exceeding 40FPS. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Gu2023robust
ER  -

TY  - JOUR
AU  - Goyal, R.
AU  - Kumar, P.
AU  - Singh, V.P.
TI  - A Systematic survey on automated text generation tools and techniques: application, evaluation, and challenges
PY  - 2023
T2  - Multimedia Tools and Applications
VL  - 82
IS  - 28
SP  - 43089
EP  - 43144
DO  - 10.1007/s11042-023-15224-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153076079&doi=10.1007%2fs11042-023-15224-0&partnerID=40&md5=ae036668938a10e22edf5eaf0bdc431a
AB  - Automatic text generation is the generation of natural language text by machines. Enabling machines to generate readable and coherent text is one of the most vital yet challenging tasks. Traditionally, text generation has been implemented either by using production rules of a predefined grammar or performing statistical analysis of existing human-written texts to predict sequences of words. Recently a paradigm change has emerged in text generation, induced by technological advancements, including deep learning methods and pre-trained transformers. However, many open challenges in text generation need to be addressed, including the generation of fluent, coherent, diverse, controllable, and consistent human-like text. This survey aims to provide a comprehensive overview of current advancements in automated text generation and introduce the topic to researchers by offering pointers and synthesis to pertinent studies. This paper studied the relevant twelve years of articles from 2011 onwards in the field of text generation and observed a total of 146 prime studies relevant to the objective of this survey that has been thoroughly reviewed and discussed. It covers core text generation applications, including text summarization, question–answer generation, story generation, machine translation, dialogue response generation, paraphrase generation, and image/video captioning. The most commonly used datasets for text generation and existing tools with their application domain have also been mentioned. Various text decoding and optimization methods have been provided with their strengths and weaknesses. For evaluating the effectiveness of the generated text, automatic evaluation metrices have been discussed. Finally, the article discusses the main challenges and notable future directions in the field of automated text generation for potential researchers. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Goyal2023Systematic
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Jiao, H.
AU  - Yang, Z.
TI  - Ship trajectory prediction based on machine learning and deep learning: A systematic review and methods analysis
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 107062
DO  - 10.1016/j.engappai.2023.107062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169794312&doi=10.1016%2fj.engappai.2023.107062&partnerID=40&md5=002818425ce5fe4ca1551b301bc9ae7c
AB  - Ship trajectory prediction based on Automatic Identification System (AIS) data has attracted increasing interest as it helps prevent collision accidents and eliminate potential navigational conflicts. Therefore, it is necessary and urgent to conduct a systematic analysis of all the prediction methods to help reveal their advantages to ensure safety at sea in different scenarios. It is particularly important and significant within the context of unmanned ships forming a new hybrid maritime traffic together with manned ships in the future. This paper aims to conduct a comparative analysis of the up-to-date ship trajectory prediction algorithms based on machine learning and deep learning methods. To do so, five classical machine learning methods (i.e., Kalman Filter, Gaussian Process Regression, Support Vector Regression, Random Forest, and Back Propagation Network) and eight deep learning methods (i.e., Recurrent Neural Networks, Long Short-Term Memory, Bi-directional Long Short-Term Memory, Gate Recurrent Unit, Bi-directional Gate Recurrent Unit, Sequence to Sequence, Spatio-Temporal Graph Convolutional Network, and Transformer) are thoroughly analysed and compared from the algorithm essence and applications to excavate their features and adaptability for manned and unmanned ships. The findings reveal the characteristics of various prediction methods and provide valuable implications for different stakeholders to guide the best-fit choice of a particular method as the solution under a specific circumstance. It also makes contributions to the extraction of the research difficulties of ship trajectory prediction and the corresponding solutions that are put forward to guide the development of future research. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - CCF:C期刊; 
LB  - Li2023Ship
ER  -

TY  - JOUR
AU  - Haugsdal, E.
AU  - Aune, E.
AU  - Ruocco, M.
TI  - Persistence Initialization: a novel adaptation of the Transformer architecture for time series forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 22
SP  - 26781
EP  - 26796
DO  - 10.1007/s10489-023-04927-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168995690&doi=10.1007%2fs10489-023-04927-4&partnerID=40&md5=20fa3ab75ad1bcdaf94b87fc22bfa6a8
AB  - Time series forecasting is an important problem, with many real world applications. Transformer models have been successfully applied to natural language processing tasks, but have received relatively little attention for time series forecasting. Motivated by the differences between classification tasks and forecasting, we propose PI-Transformer, an adaptation of the Transformer architecture designed for time series forecasting, consisting of three parts: First, we propose a novel initialization method called Persistence Initialization, with the goal of increasing training stability of forecasting models by ensuring that the initial outputs of an untrained model are identical to the outputs of a simple baseline model. Second, we use ReZero normalization instead of Layer Normalization, in order to further tackle issues related to training stability. Third, we use Rotary positional encodings to provide a better inductive bias for forecasting. Multiple ablation studies show that the PI-Transformer is more accurate, learns faster, and scales better than regular Transformer models. Finally, PI-Transformer achieves competitive performance on the challenging M4 dataset, both when compared to the current state of the art, and to recently proposed Transformer models for time series forecasting. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Haugsdal2023Persistence
ER  -

TY  - JOUR
AU  - Yin, Y.
AU  - Di, Q.
AU  - Wan, J.
AU  - Liang, T.
TI  - Time-Aware Smart City Services Based on QoS Prediction: A Contrastive Learning Approach
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 21
SP  - 18745
EP  - 18753
DO  - 10.1109/JIOT.2023.3281869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162652359&doi=10.1109%2fJIOT.2023.3281869&partnerID=40&md5=2defe6159f45a850f4292eed5a1f7bc1
AB  - Smart cities are designed to satisfy the needs of residents and improve their quality of life by providing a wide range of smart city services. One of the keys to the efficient operation of smart city services is the accurate forecast of the missing Quality of Service (QoS). Presently, many approaches utilize the context information of users and services, such as geographic location and network location, to somewhat increase the prediction accuracy and forecast the missing QoS values. However, because the network conditions and server status are unpredictable, time is also considered as one of the important factors affecting QoS prediction, which brings more challenges as follows: higher data dimension, more complex data characteristics, and higher data sparsity. To overcome these challenges, we propose an approach for time-aware Web service QoS prediction based on contrastive learning (named CLpred). CLpred utilizes a sequential data input format for QoS data and models these QoS sequences through transformer encoder with CLpred framework. Therefore, it can downscale QoS data and extract a more efficient representation in complex QoS data. Furthermore, it makes it possible to apply data augmentation methods to address the problems of data sparsity. In order to prove the superiority of the proposed approach, particularly inside the presence of extremely high-data sparsity, extensive experiments are conducted on the well-known service QoS data set WSDREAM.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Yin2023Time-Aware
ER  -

TY  - JOUR
AU  - Kumar, T.
AU  - Mahrishi, M.
AU  - Sharma, G.
TI  - Emotion recognition in Hindi text using multilingual BERT transformer
PY  - 2023
T2  - Multimedia Tools and Applications
VL  - 82
IS  - 27
SP  - 42373
EP  - 42394
DO  - 10.1007/s11042-023-15150-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152458372&doi=10.1007%2fs11042-023-15150-1&partnerID=40&md5=c1112e9e7dc3e4994fda227b21f2decf
AB  - Emotions are a vital and fundamental part of our existence. Whatever we do, say, or do not say somehow reflects our feelings, however not immediately. To comprehend human’s most fundamental behaviour, we must examine these feelings using emotional data. According to the extensive literature review, categorising speech text into multiple classes is now undergoing extensive investigation. The application of this research is very limited in local and regional languages such as Hindi. This study focuses on text emotion analysis, specifically for the Hindi language. In our study, BHAAV Dataset is used, which consists of 20,304 sentences, where every other sentence has been manually annotated into one of the five emotion categories (Anger, Suspense, Joy, Sad, Neutral). Comparison of multiple machine learning and deep learning techniques with word embedding is used to demonstrate accuracy. And then, the trained model is used to predict the emotions of Hindi text. The best performance were observed in case of mBERT model with loss- 0.1689 ,balanced_accuracy- 93.88%, recall- 93.44%, auc- 99.55% and precision- 94.39 % on training data, while loss- 0.3073, balanced_accuracy- 91.84%, recall- 91.74%, auc- 98.46% and precision- 92.01% on testing data. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Kumar2023Emotion
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Wu, Y.
AU  - Yang, J.
AU  - Chen, J.
AU  - Li, T.
TI  - Improving rating predictions with time-varying attention and dual-optimizer
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 21
SP  - 26098
EP  - 26109
DO  - 10.1007/s10489-023-04943-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168126990&doi=10.1007%2fs10489-023-04943-4&partnerID=40&md5=6c529a71e5b0a108c4ec5ab0da7caa41
AB  - Due to the rapid expansion of online platforms, review-based recommender systems have become the standard way to determine consumers’ preferences for various goods. The purpose of this study is to address three significant issues with review-based approaches. First, these techniques suffer from a class-imbalance problem, where rating levels with lower proportions are partially neglected. As a result, their rating performance for such rare levels is unsatisfactory. To address this drawback, this paper proposes a flexible dual-optimizer network that enhances performance by utilizing classification and regression losses in the first attempt to solve this problem. Second, the typical review-based approach of preprocessing review texts with word embeddings will result in inadequate contextual information extraction. Thus, the bidirectional encoder representations from the transformers (BERT) method is introduced as the preprocessing technique to fully extract semantic information. Third, existing techniques make recommendations without considering that the user preferences may change over time. We suggest a time-varying feature extraction scheme that includes a multiscale convolutional neural network and bidirectional long short-term memory to solve this problem. We then develop an interactive component that summarizes the contextual information associated with the user-item pairings. The efficiency of the proposed time-varying attention with dual-optimizer (TADO) model is demonstrated through extensive tests on 12 benchmark datasets derived from Amazon Product Reviews. Regarding the existing state-of-the-art techniques, the proposed model attains a substantial performance increase of 22.69%, 8.75%, and 17.35%, respectively, over the Aspect-aware Latent Factor Model (ALFM), Multi-Pointer Co-Attention Networks for recommendation (MPCN), and Aspect-based Neural Recommender (ANR). Moreover, an ablation study demonstrates the importance of jointly employing the components developed for TADO. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Li2023Improving
ER  -

TY  - JOUR
AU  - Liang, T.
AU  - Sun, N.
AU  - Wang, Q.
AU  - Bu, J.
AU  - Li, L.
AU  - Chen, Y.
AU  - Cao, M.
AU  - Ma, J.
AU  - Liu, T.
TI  - sEMG-Based End-to-End Continues Prediction of Human Knee Joint Angles Using the Tightly Coupled Convolutional Transformer Model
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 11
SP  - 5272
EP  - 5280
DO  - 10.1109/JBHI.2023.3304639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167791647&doi=10.1109%2fJBHI.2023.3304639&partnerID=40&md5=ebc4ea95f01786e939752ae21781843b
AB  - Wearable exoskeleton robots can promote the rehabilitation of patients with physical dysfunction. And improving human-computer interaction performance is a significant challenge for exoskeleton robots. The traditional feature extraction process based on surface Electromyography(sEMG) is complex and requires manual intervention, making real-time performance difficult to guarantee. In this study, we propose an end-to-end method to predict human knee joint angles based on sEMG signals using a tightly coupled convolutional transformer (TCCT) model. We first collected sEMG signals from 5 healthy subjects. Then, the envelope was extracted from the noise-removed sEMG signal and used as the input to the model. Finally, we developed the TCCT model to predict the knee joint angle after 100 ms. For the prediction performance, we used the Root Mean Square Error(RMSE), Pearson Correlation Coefficient(CC), and Adjustment R2 as metrics to evaluate the error between the actual knee angle and the predicted knee angle. The results show that the model can predict the human knee angle quickly and accurately. The mean RMSE, Adjustment R2, and (CC) values of the model are 3.79°, 0.96, and 0.98, respectively, which are better than traditional deep learning models such as Informer (4.14, 0.95, 0.98), CNN (5.56, 0.89, 0.96) and CNN-BiLSTM (3.97, 0.95, 0.98). In addition, the prediction time of our proposed model is only 11.67 ± 0.67 ms, which is less than 100 ms. Therefore, the real-time and accuracy of the model can meet the continuous prediction of human knee joint angle in practice.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Liang2023sEMG-Based
ER  -

TY  - JOUR
AU  - Huang, L.
AU  - Huang, J.
AU  - Chen, P.
AU  - Li, H.
AU  - Cui, J.
TI  - Long-term sequence dependency capture for spatiotemporal graph modeling
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 278
C7  - 110818
DO  - 10.1016/j.knosys.2023.110818
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167616407&doi=10.1016%2fj.knosys.2023.110818&partnerID=40&md5=8f5bbf93c203e5e2a5158a03140ea083
AB  - Long term dependency capture is essentially important for time series prediction and spatial–temporal forecasting. In recent years, many deep learning-based forecasting methods have been proposed, leading to rapid development in this area. We systematically reviewed long-term dependency capture methods, including temporal dependency in sequence (named intra-sequence temporal dependency), temporal dependency out of sequence (named inter-sequence temporal dependency, in this scenario the long-term dependencies are split by many subsequences). Because the batch technique is widely adopted in machine learning and deep learning, the range of temporal capturing ability for many proposed methods is intra-sequence temporal dependency, which limits the capacity of long-term dependency capture. Aiming at the above problems, we designed three type memory mechanisms (i.e., a temporal encoding memory mechanism, a cross-sequence memory mechanism and a query-key based memory mechanism) to solve those long term dependency problems. Moreover, based on the cross-sequence memory mechanism and query-key architecture, an Attention-based Long-Term Dependency Capture model (ALTDC) is proposed for long-term dependency modeling and further solves the temporal dependency coherence problem. ALTDC includes temporal Transformer and spatial Transformer. The temporal Transformer adopts multi-head attention mechanism in temporal dimension and takes into consideration the relative position encoding. The spatial Transformer leverages attention mechanism in spatial dimension, and utilizes learnable position encoding and graph convolution to capture spatial relationships. Experiments demonstrate that the proposed model outperforms the state-of-art baselines on real world time-series datasets and spatial–temporal datasets. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; 
LB  - Huang2023Long-term
ER  -

TY  - JOUR
AU  - Huang, D.
AU  - Zhang, Z.
AU  - Fang, X.
AU  - He, M.
AU  - Lai, H.
AU  - Mi, B.
TI  - STIF: A Spatial-Temporal Integrated Framework for End-to-End Micro-UAV Trajectory Tracking and Prediction With 4-D MIMO Radar
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 21
SP  - 18821
EP  - 18836
DO  - 10.1109/JIOT.2023.3244655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149399290&doi=10.1109%2fJIOT.2023.3244655&partnerID=40&md5=d09be6dc66e3700cf1a5a93b2214661a
AB  - The early trajectory prediction of micro unmanned aerial vehicles (micro-UAVs) with random behavior intentions facilitates the elimination of potential safety hazards. However, due to the property of a small radar cross Section (RCS), the backscattered radar signals from micro-UAVs may be submerged under strong background clutters, leading to distorted tracking and false prediction. To this end, this article presents a spatial-temporal integrated framework (STIF) for end-to-end micro-UAV trajectory tracking and prediction based on a 4-D multiple-input-multiple-output (MIMO) radar. Especially, to obtain accurate trajectories in low signal-to-noise ratio (SNR) conditions, the target detection and tracking are considered to be interdependent and addressed jointly in this work, rather than treating them as two separate processes in conventional methods. The advantage is that with the assistance of tracking, all consecutive spatial information encoded in raw radar streams can be incorporated to enhance the continuous detection performance, avoiding information loss using only one single scan. Subsequently, to accommodate high maneuvering scenarios, an intention-aware end-to-end transformer-based prediction framework is presented to simultaneously discover both spatial and temporal dependencies hiding in long-term estimated trajectories. Consequently, a 4-D frequency modulated continuous wave (FMCW) radar is utilized to evaluate the proposed system. Numerous simulation and experimental results indicate that STIF outperforms competing state-of-the-art methods and achieve superior prediction performance with the accuracy of 0.3851 m in low SNR conditions.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:C期刊; 
LB  - Huang2023STIF
ER  -

TY  - JOUR
AU  - Guo, Q.
AU  - Wang, C.
AU  - Xiao, D.
AU  - Huang, Q.
TI  - A novel multi-label pest image classifier using the modified Swin Transformer and soft binary cross entropy loss
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 107060
DO  - 10.1016/j.engappai.2023.107060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169881038&doi=10.1016%2fj.engappai.2023.107060&partnerID=40&md5=03fc36c00ef746da905652e6a6a787f4
AB  - As pests can cause heavy crop losses, integrated pest management is a vital aspect of agriculture. In general, pest recognition is essential to the integrated pest management. Many studies have explored how to achieve automatic pest recognition using computer vision and artificial intelligence techniques. However, most existing methods did not consider the class ambiguity problem. That is, a pest image may belong to multiple possibly true categories, but only one possible class label is assigned to the pest image. To close the above gap, this study converted the conventional one-label pest classification task into a multi-label one. In detail, the state-of-the-art deep network, Swin Transformer, was first modified to enable the predicted scores of possible classes to approximate one simultaneously by replacing the fully connected soft-max layer with a sigmoid activation layer. Then, a two-stage supervised learning algorithm using the binary cross entropy loss and the novel soft binary cross entropy loss was designed to train the Swin-Transformer-based multi-label classification model with single-label images. Experiments on the IP102 image dataset showed that the proposed method obtained the highest F1-score value of 60.83%. It outperformed the second-best one by a margin of 7.52%. In conclusion, the proposed method can tackle the pest class ambiguity problem on IP102 better. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Guo2023novel
ER  -

TY  - JOUR
AU  - Hu, C.
AU  - Wu, J.
AU  - Sun, C.
AU  - Chen, X.
AU  - Yan, R.
TI  - Intelligent temporal detection network for boundary-sensitive flight regime recognition
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 106949
DO  - 10.1016/j.engappai.2023.106949
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168115467&doi=10.1016%2fj.engappai.2023.106949&partnerID=40&md5=720afcb26e8732ae211041a2a005dd6b
AB  - Flight regime recognition is critical in guaranteeing flight safety, making informed maintenance decisions for key components, and evaluating flight quality. However, previous methods take flight data points/segments as inputs to make point-wise/segment-wise prediction, which results in imprecise regime boundary localization, poor recognition accuracy or low efficiency. To this end, an intelligent temporal detection network is proposed from a brand-new perspective of regime detection, which directly handles long flight sequences and concurrently generates multiple regime boxes with corresponding categories. Moreover, specific model structures are designed for flight data, including an adaptive graph embedding to explore spatial relations of multi-modal flight parameters, a multi-scale Transformer encoder to recognize regimes of different durations, and a balanced joint loss to mitigate negative impact on imbalanced flight regimes. To validate the superiority of the proposed method, various parameters of real-world flight sorties are collected. Then flight regime dataset is constructed via manual annotation. Extensive experiments and ablation studies show that our method can achieve accurate and boundary-sensitive regime recognition simultaneously. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Hu2023Intelligent
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Jin, X.
AU  - Kong, Z.
AU  - Wang, F.
AU  - Xu, Z.
TI  - Global and local information integrated network for remaining useful life prediction
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 106956
DO  - 10.1016/j.engappai.2023.106956
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168407518&doi=10.1016%2fj.engappai.2023.106956&partnerID=40&md5=b2229b88492902c45c962355c8e88275
AB  - Data-driven methods routinely achieve promising results on remaining useful life prediction, but under a window-manner end-to-end paradigm, they suffer from unsatisfying generalization ability and low interpretability, as the consequence of neglecting diverse modes among the entire degradation processes of different entities. This article proposes a novel Transformer-based network, to tackle the problem by integration of global and local information. During offline training, the paired inputs containing full life and piece data are constructed, and then using cross-attention between the encoder and the decoder, the consistent position of the piece data in the full life is derived, which is directly associated with the degradation state. The designed paired inputs and model architecture ensures the strong generalization because the prediction result considering global information is adaptive to diverse degradation modes. Further, the designed cross-attention discrepancy utilizes prior knowledge of the consistent position such that similar degradation states are aligned more properly. Such a consistent position, visualized by the cross-attention distribution, is supposed to represent the intuitive relationship between degradation level and monitoring data, thus provides inherent interpretability about the prediction process. Finally, predictions of the online monitoring piece data with respect to all historical full lives with different degradation modes are aggregated to the final prediction. Extensive experiments on two datasets of turbofan and bearing show that our model provides competitive performance, especially under complicated working conditions and fault modes, achieving averagely 5.9% score reduction compared with the state-of-the-art method. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Chen2023Global
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Huang, P.
AU  - Wen, C.
AU  - Li, J.
AU  - Rodrigues, F.
TI  - Prediction of departure delays at original stations using deep learning approaches: A combination of route conflicts and rolling stock connections
PY  - 2023
T2  - Expert Systems with Applications
VL  - 229
C7  - 120500
DO  - 10.1016/j.eswa.2023.120500
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160205653&doi=10.1016%2fj.eswa.2023.120500&partnerID=40&md5=6103981763d9a64a07834b5c87eaa0b5
AB  - Rolling stock connections and route conflicts of trains at terminal stations are critical to train delay propagation and prediction on the railway networks. Previous studies primarily focused on delay prediction/propagation from a macro perspective, without considering the two factors. To address this problem, a hybrid neural network architecture, called TLF-net, is proposed to predict departure delays at original stations (DDOSs), considering the rolling-stock connection and potential route conflicts in the railway network. TLF-net consists of a transformer, a long short-term memory (LSTM), and a fully-connected neural network (FCNN) block, to separately address variables with different characteristics. Based on the real-world data from two terminal stations in China, the experimental results show that the consideration of the potential route conflicts from the network can considerably improve TLF-net's prediction performance over the model that only considers train interactions on a single railway line. Also, it is proven that arrival/departure routes of consecutive trains are crucial for delay prediction, while using the transformer block can efficiently reveal the route conflict severity between arrival/departure routes. The sensitivity analysis to influence factors demonstrates the significance of considering the rolling stock connection and potential route conflicts. Finally, to support real-time railway traffic management, a train arrival delay prediction model from our previous study is integrated to predict the input of TLF-net (i.e., train arrival delays), enabling the proposed model to dynamically predict the DDOSs. This dynamic updating lengthens the prediction horizon (the prediction time ahead), making it better support real-time train traffic control and management. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Li2023Prediction
ER  -

TY  - JOUR
AU  - Bajaj, A.
AU  - Vishwakarma, D.K.
TI  - HOMOCHAR: A novel adversarial attack framework for exposing the vulnerability of text based neural sentiment classifiers
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 126
C7  - 106815
DO  - 10.1016/j.engappai.2023.106815
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166344330&doi=10.1016%2fj.engappai.2023.106815&partnerID=40&md5=04398f653a04b2a91b920999f0149f11
AB  - State-of-the-art deep learning algorithms have demonstrated remarkable proficiency in the task of text classification. Despite the widespread use of deep learning-based language models, there remains much work to be done in order to improve the security of these models. This is particularly concerning for their growing use in sensitive applications, such as sentiment analysis. This study demonstrates that language models possess inherent susceptibility to textual adversarial attacks, wherein a small number of words or characters are modified to produce an adversarial text that deceives the machine into producing erroneous predictions while maintaining its true meaning for human readers. The current study offers HOMOCHAR, a novel textual adversarial attack that operates within a black box setting. The proposed method generates more robust adversarial examples by considering the task of perturbing a text input with transformations at the character level. The objective is to deceive a target NLP model while adhering to specific linguistic constraints in a way such that the perturbations are imperceptible to humans. Comprehensive experiments are performed to assess the effectiveness of the proposed attack method against several popular models, including Word-CNN, Word-LSTM along with five powerful transformer models on two benchmark datasets, i.e., MR & IMDB utilized for sentiment analysis task. Empirical findings indicate that the proposed attack model consistently attains significantly greater attack success rates (ASR) and generates high-quality adversarial examples when compared to conventional methods. The results indicate that text-based sentiment prediction techniques can be circumvented, leading to potential consequences for existing policy measures. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Bajaj2023HOMOCHAR
ER  -

TY  - JOUR
AU  - Gan, J.
AU  - Xie, X.
AU  - He, G.
AU  - Luo, H.
TI  - TransBLS: transformer combined with broad learning system for facial beauty prediction
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 21
SP  - 26110
EP  - 26125
DO  - 10.1007/s10489-023-04931-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168343222&doi=10.1007%2fs10489-023-04931-8&partnerID=40&md5=cebf88d7f5c778fb3ca27aed9be985c3
AB  - Facial beauty prediction (FBP) is a frontier topic in the fields of machine learning and computer vision, focusing on how to enable computers to judge facial beauty like humans. The existing FBP methods are mainly based on deep neural networks (DNNs). However, DNNs lack global characteristics and only build local dependencies, so FBP still suffers from insufficient supervision information, low accuracy and overfitting. A transformer is a self-attention-based architecture that possesses better global characteristics than DNNs and can build long-term dependencies. Transformers have been widely used to solve some computer vision problems in recent years and have produced better results. In this paper, we propose an adaptive transformer with global and local multihead self-attention for FBP, called GLAFormer. However, GLAFormer does not converge and is prone to overfitting when the training samples are insufficient. The broad learning system (BLS) can accelerate the model convergence process and reduce overfitting. Therefore, we further combine GLAFormer with the BLS to form TransBLS, in which a GLAFormer block is designed as a feature extractor, the features extracted by it are transferred to the BLS for further refining and fitting, and the results are output. Experimental results indicate that TransBLS achieves state-of-the-art FBP performance on several datasets with different scales, better solving the low accuracy and overfitting problems encountered in FBP. It can also be widely applied in pattern recognition and object detection tasks. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Gan2023TransBLS
ER  -

TY  - JOUR
AU  - Zhou, Q.
AU  - Lai, Y.
AU  - Yu, H.
AU  - Zhang, R.
AU  - Jing, X.
AU  - Luo, L.
TI  - Multi-modal fusion for millimeter-wave communication systems: A spatio-temporal enabled approach
PY  - 2023
T2  - Neurocomputing
VL  - 555
C7  - 126604
DO  - 10.1016/j.neucom.2023.126604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169936012&doi=10.1016%2fj.neucom.2023.126604&partnerID=40&md5=ccdd0ef0632eb4c54373205c427881f0
AB  - In millimeter-wave (mmWave) massive multi-input multi-output (MIMO) systems, beam selection can enhance channel capacity and reduce error rate. However, existing beam selection methods for MIMO systems rely on traditional optimization techniques, which may not be feasible for real-time data transmission. Hence, this paper proposes a novel beam prediction approach via multi-modal fusion and spatio-temporal-enabled features. Specifically, the proposed method can improve MIMO system performance by integrating information from multiple perspectives, such as temporal, spatial, and frequency domains. Moreover, the proposed approach is based on a deep learning framework utilizing 3-dimensional convolutional neural networks (3DCNNs) and transformer module to capture spatio-temporal data correlations. Extensive simulation results show that the proposed mechanism outperforms massive benchmarks in terms of beam prediction accuracy from 2.63% to 11%. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhou2023Multi-modal
ER  -

TY  - JOUR
AU  - Shi, L.
AU  - Zhang, J.
AU  - Yang, B.
AU  - Gao, Y.
TI  - Lung Sound Recognition Method Based on Multi-Resolution Interleaved Net and Time-Frequency Feature Enhancement
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 10
SP  - 4768
EP  - 4779
DO  - 10.1109/JBHI.2023.3306911
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168738059&doi=10.1109%2fJBHI.2023.3306911&partnerID=40&md5=f18d93b8f8e52d56c25c88b873e98fe8
AB  - Air pollution and aging population have caused increasing rates of lung diseases and elderly lung diseases year by year. At the same time, the outbreak of COVID-19 has brought challenges to the medical system, which placed higher demands on preventing lung diseases and improving diagnostic efficiency to some extent. Artificial intelligence can alleviate the burden on the medical system by analyzing lung sound signals to help to diagnose lung diseases. The existing models for lung sound recognition have challenges in capturing the correlation between time and frequency information. It is difficult for convolutional neural network to capture multi-scale features across different resolutions, and the fusion of features ignores the difference of influences between time and frequency features. To address these issues, a lung sound recognition model based on multi-resolution interleaved net and time-frequency feature enhancement was proposed, which consisted of a heterogeneous dual-branch time-frequency feature extractor (TFFE), a time-frequency feature enhancement module based on branch attention (FEBA), and a fusion semantic classifier based on semantic mapping (FSC). TFFE independently extracts the time and frequency information of lung sounds through a multi-resolution interleaved net and Transformer, which maintains the correlation between time-frequency features. FEBA focuses on the differences in the influence of time and frequency information on prediction results by branch attention. The proposed model achieved an accuracy of 91.56% on the combined dataset, by an improvement of over 2.13% compared to other models. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Shi2023Lung
ER  -

TY  - JOUR
AU  - Hu, G.
AU  - Wang, B.
AU  - Hu, B.
AU  - Chen, D.
AU  - Hu, L.
AU  - Li, C.
AU  - An, Y.
AU  - Hu, G.
AU  - Jia, G.
TI  - From WSI-level to patch-level: Structure prior-guided binuclear cell fine-grained detection
PY  - 2023
T2  - Medical Image Analysis
VL  - 89
C7  - 102931
DO  - 10.1016/j.media.2023.102931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170111106&doi=10.1016%2fj.media.2023.102931&partnerID=40&md5=a685d1ae170452a4d023f8ffa6fffb28
AB  - Accurate and quick binuclear cell (BC) detection plays a significant role in predicting the risk of leukemia and other malignant tumors. However, manual counting of BCs using microscope images is time consuming and subjective. Moreover, traditional image processing approaches perform poorly due to the limitations in staining quality and the diversity of morphological features in binuclear cell (BC) microscopy whole-slide images (WSIs). To overcome this challenge, we propose a multi-task method inspired by the structure prior of BCs based on deep learning, which cascades to implement BC coarse detection at the WSI level and fine-grained classification at the patch level. The coarse detection network is a multitask detection framework based on circular bounding boxes for cell detection and central key points for nucleus detection. Circle representation reduces the degrees of freedom, mitigates the effect of surrounding impurities compared to usual rectangular boxes and can be rotation invariant in WSIs. Detecting key points in the nucleus can assist in network perception and be used for unsupervised color layer segmentation in later fine-grained classification. The fine classification network consists of a background region suppression module based on color layer mask supervision and a key region selection module based on a transformer due to its global modeling capability. Additionally, an unsupervised and unpaired cytoplasm generator network is first proposed to expand the long-tailed distribution dataset. Finally, experiments are performed on BC multicenter datasets. The proposed BC fine detection method outperforms other benchmarks in almost all evaluation criteria, providing clarification and support for tasks such as cancer screenings. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Hu2023From
ER  -

TY  - JOUR
AU  - Huang, J.
AU  - Zhao, P.
AU  - Wang, G.
AU  - Yang, S.
AU  - Lin, J.
TI  - Self-attention-based long temporal sequence modeling method for temporal action detection
PY  - 2023
T2  - Neurocomputing
VL  - 554
C7  - 126617
DO  - 10.1016/j.neucom.2023.126617
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166905132&doi=10.1016%2fj.neucom.2023.126617&partnerID=40&md5=9911911d5d16722cef2195c4dd2343cd
AB  - Temporal Action Detection (TAD) is a basic and complex task in video understanding. It aims at detecting both the localization and category of actions in a video. The anchor-free TAD methods directly predict the action classes at each location and regress the distances to the boundaries. However, current anchor-free models based on convolutional neural network encode spatiotemporal sequences by 3D convolution networks. Due to the limited receptive field and the basic prior of the translation invariance, effective long temporal sequence modeling cannot be achieved. As a result, these methods cannot effectively detect temporal boundaries. To solve this problem, we design a novel end-to-end self-attention temporal enhancement TAD model, which introduces the Temporal Enhancement module to enhance the temporal feature encoding of the videos and expand the receptive field. Extensive experiments demonstrate that the self-attention Temporal Enhancement model yields an effective improvement on previous work, which improves the performance on THUMOS14 by 1.2%, reaching 53.2% on average mAP. Meanwhile, a competitive result of 34.7% average mAP is achieved on ActivityNet-1.3. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Huang2023Self-attention-based
ER  -

TY  - JOUR
AU  - Jia, W.
AU  - Ma, S.
TI  - Query Preference Analysis on Cascade Inference Human–Object Interaction Detection Transformer
PY  - 2023
T2  - International Journal of Pattern Recognition and Artificial Intelligence
VL  - 37
IS  - 13
C7  - 235602
DO  - 10.1142/S0218001423560219
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176287735&doi=10.1142%2fS0218001423560219&partnerID=40&md5=9a4e329ff4603b2e0471f1be9841d6ab
AB  - Detection transformers (DETR) have provided a novel solution to human–object interaction detection in a set-prediction manner, thanks to expressive learnable queries. However, few studies covered how queries implicitly affect model behaviors, which might contain clues for model improvement. Therefore, we propose two dataset-based analysis tools: score state space and query preference map. They provide data on the distribution of model predictions, which can reveal overall-level and query-level model properties. Starting with our baseline model, we find the model naturally regresses object boxes to overlap human boxes in the edge case of no-object verbs (stand, etc.), even without a related loss. We encourage this by patching the supervision with virtual objects, resulting in more stable query preference. Moreover, we show that two-stage decoders designed for cascade inference do not decouple tasks as intended. We infer this is caused by the empty instances used as negative samples, which suggests a redesign in the matching scheme. Further, we reveal how adding an oracle-query-based teacher model affects query roles with a tiny gain, indicating room for refinement. Our findings demonstrate how a simple focus on query behaviors can provide insights for improving models. © 2023 World Scientific Publishing Co. Pte Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Jia2023Query
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Wang, X.
AU  - Liu, Z.
AU  - Huang, M.
AU  - Sun, S.
AU  - Zhu, Q.
TI  - Detection of multi-size peach in orchard using RGB-D camera combined with an improved DEtection Transformer model
PY  - 2023
T2  - Intelligent Data Analysis
VL  - 27
IS  - 5
SP  - 1539
EP  - 1554
DO  - 10.3233/IDA-220449
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174313646&doi=10.3233%2fIDA-220449&partnerID=40&md5=043832ca2588a564573d2714f49162ca
AB  - The first major contribution of the paper is the proposal of using an improved DEtection Transformer network (named R2N-DETR) and Kinect-V2 camera for detecting multiple-size peaches under orchards with varied illumination and fruit occlusion. R2N-DETR model first employed Res2Net-50 to extract a fused low-high level feature map containing fine spatial features and precise semantic information of multi-size peaches from Red-Green-Blue-Depth (RGB-D) images. Second, the encoder-decoder was performed on the feature map to obtain the global context. Finally, all detected objects were detected according to each object's global context. For the detection of 1101 RGB-D images (imaged from two orchards over three years), the R2N-DETR model achieves an average precision of 0.944 and an average detecting time of 53 ms for each image. The developed system could provide precise visual guidance for robotic picking and contribute to improving yield prediction by providing accurate fruit counting.  © 2023 - IOS Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yang2023Detection
ER  -

TY  - JOUR
AU  - Zhang, F.
AU  - Guo, T.
AU  - Wang, H.
TI  - DFNet: Decomposition fusion model for long sequence time-series forecasting
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 277
C7  - 110794
DO  - 10.1016/j.knosys.2023.110794
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165905582&doi=10.1016%2fj.knosys.2023.110794&partnerID=40&md5=9b08a727bd09d9f450e08dd8ae09c4fb
AB  - The study of time series forecasting is of great significance, particularly as accurate forecasting under long time-series is critical to data-driven decision-making. Although existing deep learning models (such as recurrent neural networks, long short-term memory, time convolutional networks, and transformers) exhibit excellent forecasting performances, they do not consider the unique properties of time series, particularly the trend and seasonality. To address this issue, this study proposes a DFNet model with the following characteristics. (1) A three-branch decomposition method is designed to obtain the trend, seasonal, and irregular components, and the least squares method is adopted to correct the seasonal data and process different serial patterns separately to accurately obtain the internal regularity and periodicity, thereby improve model performance. (2) A segmented polynomial activation function is adopted to effectively handle problems associated with negative data loss and slow operation speed, and reduce the amount of model computation. (3) Based on the information fusion transfer mechanism, the extracted long-term dependencies are passed to each other and aggregated to enhance the coupling between sequences. Experiments on nine datasets demonstrated the effectiveness of the proposed model for long time-series prediction. The model showed a significantly superior prediction performance compared with existing prediction models. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; FMS:C; 
LB  - Zhang2023DFNet
ER  -

TY  - JOUR
AU  - Jiao, Z.
AU  - Peng, X.
AU  - Wang, Y.
AU  - Xiao, J.
AU  - Nie, D.
AU  - Wu, X.
AU  - Wang, X.
AU  - Zhou, J.
AU  - Shen, D.
TI  - TransDose: Transformer-based radiotherapy dose prediction from CT images guided by super-pixel-level GCN classification
PY  - 2023
T2  - Medical Image Analysis
VL  - 89
C7  - 102902
DO  - 10.1016/j.media.2023.102902
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165428877&doi=10.1016%2fj.media.2023.102902&partnerID=40&md5=9fa4a64b22c34a3fa076f25bf6aa4653
AB  - Radiotherapy is a mainstay treatment for cancer in clinic. An excellent radiotherapy treatment plan is always based on a high-quality dose distribution map which is produced by repeated manual trial-and-errors of experienced experts. To accelerate the radiotherapy planning process, many automatic dose distribution prediction methods have been proposed recently and achieved considerable fruits. Nevertheless, these methods require certain auxiliary inputs besides CT images, such as segmentation masks of the tumor and organs at risk (OARs), which limits their prediction efficiency and application potential. To address this issue, we design a novel approach named as TransDose for dose distribution prediction that treats CT images as the unique input in this paper. Specifically, instead of inputting the segmentation masks to provide the prior anatomical information, we utilize a super-pixel-based graph convolutional network (GCN) to extract category-specific features, thereby compensating the network for the necessary anatomical knowledge. Besides, considering the strong continuous dependency between adjacent CT slices as well as adjacent dose maps, we embed the Transformer into the backbone, and make use of its superior ability of long-range sequence modeling to endow input features with inter-slice continuity message. To our knowledge, this is the first network that specially designed for the task of dose prediction from only CT images without ignoring necessary anatomical structure. Finally, we evaluate our model on two real datasets, and extensive experiments demonstrate the generalizability and advantages of our method. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; 
LB  - Jiao2023TransDose
ER  -

TY  - JOUR
AU  - Han, Y.
AU  - Tian, Y.
AU  - Yu, L.
AU  - Gao, Y.
TI  - Economic system forecasting based on temporal fusion transformers: Multi-dimensional evaluation and cross-model comparative analysis
PY  - 2023
T2  - Neurocomputing
VL  - 552
C7  - 126500
DO  - 10.1016/j.neucom.2023.126500
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164717200&doi=10.1016%2fj.neucom.2023.126500&partnerID=40&md5=4d37591fc9ce537202c34d32af84f9f9
AB  - Although helpful in reducing the uncertainty associated with economic activities, economic forecasting often suffers from low accuracy. Recognizing the high compatibility between deep learning and the nonlinear characteristics of socioeconomic systems, in this paper, we introduce state-of-the-art temporal fusion transformers (TFTs) into the field of economic system forecasting and predict the performance of the Chinese macroeconomic system. Based on an extended analysis of gross final product (GFP) and the intertemporal dynamic relationship between demand-side indicators and output indicators, we establish a scientific economic forecasting framework. To summarize the forecasting characteristics of the TFT algorithm, we compare its one-step and three-step modeling effects in forecasting output indicators with a series of representative benchmark models. According to our proposed four-dimensional evaluation system, the forecasts for China's macroeconomic system provided by the TFT model have obvious advantages in terms of overall stability, forecasting efficiency, reduction of numerical and timing errors, direction accuracy, and turning point accuracy. The forecast results show that China's economy faces a risk of slowing growth in the post-pandemic period. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Han2023Economic
ER  -

TY  - JOUR
AU  - Tejashwini, S.G.
AU  - D., A.
TI  - Revolutionizing sentiment classification: A deep learning approach using self-attention based encoding–decoding transformers with feature fusion
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 125
C7  - 106730
DO  - 10.1016/j.engappai.2023.106730
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164212808&doi=10.1016%2fj.engappai.2023.106730&partnerID=40&md5=2cedfa7b4ec799a49375271b4f0afa3c
AB  - In recent times, the growth of human computer interaction and Artificial Intelligence attains more interest especially in facial expression detection. Though the field has attained tremendous progress, still many issues are pertained as the facial expressions are complex. Therefore the present study aims to increase the efficiency in classifying the emotions of humans from the images of FER-2013 dataset and strives to attain optimal accuracy. Most of the studies have averted multi-modal parameters like a video for emotion detection. Moreover, existing studies lacked a detection rate due to ineffective feature extraction that negatively impacted the classification rate. For avoiding such pitfalls, this study proposes suitable data mining-based algorithms with the main intention to attain high accuracy. The present study proposes Deep Location Attention Forest method for emotion detection with higher accuracy. To accomplish this, DLFAT (Deep Location Feed Attention Transformers) is used for feature extraction from various sub-space representation at different position of the image. CK-PCA (Canonical Kernel-Principal Component Analysis) is performed feature fusion to improve the performance of the classifier. MRF (Modified Random Forest) is proposed to perform classification and predicts the emotions based on the facial expressions. The main intention of RF relies on learning all the data subset weights that alleviate loss amongst the predicted value for accomplishing better input classification to the related label. The proposed system is validated by the performance metrics in which the outcome is found to be 0.96197 as accuracy, 0.96 as F1-Score, 0.97 as recall and 0.96 as precision and the outcomes reveal the efficacy of the system in emotion detection. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Tejashwini2023Revolutionizing
ER  -

TY  - JOUR
AU  - Fang, Z.
AU  - Fan, J.
AU  - Yu, J.
TI  - LPR: learning point-level temporal action localization through re-training
PY  - 2023
T2  - Multimedia Systems
VL  - 29
IS  - 5
SP  - 2545
EP  - 2562
DO  - 10.1007/s00530-023-01128-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165892297&doi=10.1007%2fs00530-023-01128-4&partnerID=40&md5=eec081e7b9281c9ed3e16a5de2f9d380
AB  - Point-level temporal action localization (PTAL) aims to locate action instances in untrimmed videos with only one timestamp annotation for each action instance. Existing methods adopt the localization-by-classification paradigm to locate action boundaries in the temporal class activation map (TCAM) by thresholding, also known as TCAM-based method. However, TCAM-based methods are limited by the gap between classification and localization tasks, since TCAM is generated by a classification network. To address this issue, we propose a re-training framework for the PTAL task, also known as LPR. This framework consists of two stages: pseudo-label generation and re-training. In the pseudo-label generation stage, we propose a feature embedding module based on a transformer encoder to capture global context features and optimize pseudo-labels’ quality by leveraging point-level annotations. In the re-training stage, LPR uses the above pseudo-labels as supervision to locate action instances with a temporal action localization network rather than generating TCAMs. Furthermore, to alleviate the effects of label noise in the pseudo-labels, we propose a joint learning classification module (JLCM) in the re-training stage. This module contains two classification sub-modules that simultaneously predict action categories and are guided by a jointly determined clean set for network training. The proposed framework achieves state-of-the-art localization performance on both the THUMOS’14 and BEOID datasets. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Fang2023LPR
ER  -

TY  - JOUR
AU  - Parvin, H.
AU  - Reza Naghsh-Nilchi, A.
AU  - Mahvash Mohammadi, H.
TI  - Image captioning using transformer-based double attention network
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 125
C7  - 106545
DO  - 10.1016/j.engappai.2023.106545
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166472636&doi=10.1016%2fj.engappai.2023.106545&partnerID=40&md5=69044e2007398c4e15e1bc35bb6ea063
AB  - Image captioning generates a human-like description for a query image, which has attracted considerable attention recently. The most broadly utilized model for image description is an encoder–decoder structure, where the encoder extracts the visual information of the image, and the decoder generates textual descriptions of the image. Transformers have significantly enhanced the performance of image description models. However, a single attention structure in transformers cannot consider more complex relationships between key and query vectors. Furthermore, attention weights are assigned to entire candidate vectors based on the assumption that entire vectors are related. In this paper, a new double-attention framework is presented, which improves the encoder–decoder structure to consider image captioning problems. Hence, a local generator module and a global generator module are designed to predict textual descriptions collaboratively. The proposed approach improves Self-Attention (SA) from two aspects to enhance the performance of image description. First, a Masked Self-Attention module is presented to attend on the most relevant information. Second, to evade a single shallow attention distribution and make deeper internal relations, a Hybrid Weight Distribution (HWD) module is proposed, that develops SA to use the relations between key and query vectors efficiently. Experiments over the Flickr30k and MS-COCO datasets prove that the proposed approach achieves desirable performance on different evaluation measures compared to the state-of-the-art frameworks. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Parvin2023Image
ER  -

TY  - JOUR
AU  - Zhao, L.
AU  - Wu, Z.
AU  - Dai, H.
AU  - Liu, Z.
AU  - Hu, X.
AU  - Zhang, T.
AU  - Zhu, D.
AU  - Liu, T.
TI  - A generic framework for embedding human brain function with temporally correlated autoencoder
PY  - 2023
T2  - Medical Image Analysis
VL  - 89
C7  - 102892
DO  - 10.1016/j.media.2023.102892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165540418&doi=10.1016%2fj.media.2023.102892&partnerID=40&md5=4ccb41e189ae38f485dd30aa6b6b7dc9
AB  - Learning an effective and compact representation of human brain function from high-dimensional fMRI data is crucial for studying the brain's functional organization. Traditional representation methods such as independent component analysis (ICA) and sparse dictionary learning (SDL) mainly rely on matrix decomposition which represents the brain function as spatial brain networks and the corresponding temporal patterns. The correspondence of those brain networks across individuals are built by viewing them as one-hot vectors and then performing the matching. However, those one-hot vectors do not encode the regularity and/or variability of different brains very well, and thus are limited in effectively representing the functional brain activities across individuals and among different time points. To address this problem, in this paper, we formulate the human brain functional representation as an embedding problem, and propose a novel embedding framework based on the Transformer model to encode the brain function in a compact, stereotyped and comparable latent space where the brain activities are represented as dense embedding vectors. We evaluate the proposed embedding framework on the publicly available Human Connectome Project (HCP) task fMRI dataset. The experiments on brain state prediction task indicate the effectiveness and generalizability of the learned embedding. We also explore the interpretability of the learned embedding from both spatial and temporal perspective. In general, our approach provides novel insights on representing the regularity and variability of human brain function in a general, comparable, and stereotyped latent space. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Zhao2023generic
ER  -

TY  - JOUR
AU  - Amin, F.
AU  - Mondal, A.
AU  - Mathew, J.
TI  - Person re-identification using selective transformation learning
PY  - 2023
T2  - Multimedia Tools and Applications
VL  - 82
IS  - 25
SP  - 38993
EP  - 39013
DO  - 10.1007/s11042-023-15116-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151271041&doi=10.1007%2fs11042-023-15116-3&partnerID=40&md5=fa9ccf2db7d3e7e895aff53b1d8316d5
AB  - Applications like video surveillance, anomaly detection, ego-motion, recognition and re-identification (Re-ID), largely depend upon the ability of the models to learn efficient representations of the input data. Applications like re-identification or similarity matching needs the representations which can handle transformations in the input data in a predictable way. Any change in perspective and viewpoint should not change the identity of the person in re-ID systems and also, it must capture the differences accurately to discriminate two different persons correctly. We propose a Selective Transformation Learning (STL) based model which very efficiently learns to transform the image to obtain the right amount of cropping required to generate feature maps which are invariant to affine transformations of the input image. The STL approach selectively trains each of the spatial transformer modules for specific transformation in an end-to-end framework. Proposed model has very low memory footprint compared to state-of-the-art models yet performs substantially. Compared to the ResNet based or other high capacity models it performs substantially better with such a low capacity. To establish the performance quantitatively it has been tested on three publicly available re-identification datasets and on all the datasets it gives an average of 6% improvement in the mean average precision score as compared to the closest sized state-of-the-art model. This approach can be easily adapted to any other model without any special requirements. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Amin2023Person
ER  -

TY  - JOUR
AU  - Ren, Q.
AU  - Li, Y.
AU  - Liu, Y.
TI  - Transformer-enhanced periodic temporal convolution network for long short-term traffic flow forecasting
PY  - 2023
T2  - Expert Systems with Applications
VL  - 227
C7  - 120203
DO  - 10.1016/j.eswa.2023.120203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158022569&doi=10.1016%2fj.eswa.2023.120203&partnerID=40&md5=b4986345c5f62fd733ada15d41cea328
AB  - Recently, Temporal Convolution Networks(TCNs) and Graph Convolution Network(GCN) have been developed for traffic forecasting and obtained promising results as their capability of modeling the spatial and temporal correlations of traffic data. However, few of existing studies are satisfied with both long and short-term prediction tasks. Recent research has shown the superiority of transformer in handling long-range time series forecasting problems. Aimed at the shortcoming of existing solutions, in this paper, we propose a novel Transformer-enhanced Temporal Convolution Network(TE-TCN) to capture spatial, long and short-term periodical dependencies to improve the accuracy of traffic flow forecasting, especially for long-term prediction. TE-TCN integrates transformer multi-head attention mechanism and GRU to discover the long-term periodic patterns. Meanwhile, two paralleled temporal convolution networks are applied to solve the short-term periodic dependencies. The proposed method is evaluated by extensive traffic forecasting experiments on four real-world datasets and the experimental results demonstrate that TE-TCN outperforms the state-of-the-art related methods, especially for long-term traffic flow forecasting. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 39
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ren2023Transformer-enhanced
ER  -

TY  - JOUR
AU  - Hasib, K.M.
AU  - Towhid, N.A.
AU  - Faruk, K.O.
AU  - Al Mahmud, J.
AU  - Mridha, M.F.
TI  - Strategies for enhancing the performance of news article classification in Bangla: Handling imbalance and interpretation
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 125
C7  - 106688
DO  - 10.1016/j.engappai.2023.106688
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164749081&doi=10.1016%2fj.engappai.2023.106688&partnerID=40&md5=b70d9f21aef6a740ac567dc110cfed84
AB  - The rapid increase in obtainable online text data has made text categorization an important tool for data analysts to extract relevant information on the web. However, incorrect or incomplete classification of marginalized groups may result from using biased text data. In order to remedy the disparity in available data, this research suggests a system for classifying and analyzing Bangla news articles. The suggested approach first uses both Random Under-Sampling (RUS) and Synthetic Minority Oversampling Techniques to balance the massive unbalanced Bangla News dataset consisting of 4,37,948 instances (SMOTE). Secondly, the proposed system employs three machine learning models: Logistic Regression, Decision Tree, and Stochastic Gradient Descent along with three deep learning models: Artificial Neural Network (ANN), Convolutional Neural Network (CNN), and Bidirectional Encoder Representations from Transformers (BERT) for Bangla text categorization. The experimental results signify the superior performance of BERT to other classification models of the system as well as other existing methods in this domain. The proposed system achieves the maximum accuracy of 99.04% in balanced dataset and 72.23% in imbalanced dataset using BERT. K-fold cross validation with varied K values is used to determine the performance consistency of BERT. Finally, both LIME (Local Interpretable Model agnostic Explanations and SHAP (SHapley Additive exPlanations) techniques are applied for interpreting each prediction made by BERT. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 39
C2  - CCF:C期刊; 
LB  - Hasib2023Strategies
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Caines, A.
AU  - Pete, I.
AU  - Hutchings, A.
TI  - Automated hate speech detection and span extraction in underground hacking and extremist forums
PY  - 2023
T2  - Natural Language Engineering
VL  - 29
IS  - 5
SP  - 1247
EP  - 1274
DO  - 10.1017/S1351324922000262
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171525146&doi=10.1017%2fS1351324922000262&partnerID=40&md5=8517ee5221792046a05f21e41ace64da
AB  - Hate speech is any kind of communication that attacks a person or a group based on their characteristics, such as gender, religion and race. Due to the availability of online platforms where people can express their (hateful) opinions, the amount of hate speech is steadily increasing that often leads to offline hate crimes. This paper focuses on understanding and detecting hate speech in underground hacking and extremist forums where cybercriminals and extremists, respectively, communicate with each other, and some of them are associated with criminal activity. Moreover, due to the lengthy posts, it would be beneficial to identify the specific span of text containing hateful content in order to assist site moderators with the removal of hate speech. This paper describes a hate speech dataset composed of posts extracted from HackForums, an online hacking forum, and Stormfront and Incels.co, two extremist forums. We combined our dataset with a Twitter hate speech dataset to train a multi-platform classifier. Our evaluation shows that a classifier trained on multiple sources of data does not always improve the performance compared to a mono-platform classifier. Finally, this is the first work on extracting hate speech spans from longer texts. The paper fine-Tunes BERT (Bidirectional Encoder Representations from Transformers) and adopts two approaches-span prediction and sequence labelling. Both approaches successfully extract hateful spans and achieve an F1-score of at least 69%.  © The Author(s), 2022. Published by Cambridge University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Zhou2023Automated
ER  -

TY  - JOUR
AU  - Ang, G.
AU  - Lim, E.-P.
TI  - Learning and Understanding User Interface Semantics from Heterogeneous Networks with Multimodal and Positional Attributes
PY  - 2023
T2  - ACM Transactions on Interactive Intelligent Systems
VL  - 13
IS  - 3
C7  - 12
DO  - 10.1145/3578522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173585902&doi=10.1145%2f3578522&partnerID=40&md5=c4ed02ae49603a0650c7cbbbf0c57feb
AB  - User interfaces (UI) of desktop, web, and mobile applications involve a hierarchy of objects (e.g., applications, screens, view class, and other types of design objects) with multimodal (e.g., textual and visual) and positional (e.g., spatial location, sequence order, and hierarchy level) attributes. We can therefore represent a set of application UIs as a heterogeneous network with multimodal and positional attributes. Such a network not only represents how users understand the visual layout of UIs but also influences how users would interact with applications through these UIs. To model the UI semantics well for different UI annotation, search, and evaluation tasks, this article proposes the novel Heterogeneous Attention-based Multimodal Positional (HAMP) graph neural network model. HAMP combines graph neural networks with the scaled dot-product attention used in transformers to learn the embeddings of heterogeneous nodes and associated multimodal and positional attributes in a unified manner. HAMP is evaluated with classification and regression tasks conducted on three distinct real-world datasets. Our experiments demonstrate that HAMP significantly outperforms other state-of-the-art models on such tasks. To further provide interpretations of the contribution of heterogeneous network information for understanding the relationships between the UI structure and prediction tasks, we propose Adaptive HAMP (AHAMP), which adaptively learns the importance of different edges linking different UI objects. Our experiments demonstrate AHAMP’s superior performance over HAMP on a number of tasks, and its ability to provide interpretations of the contribution of multimodal and positional attributes, as well as heterogeneous network information to different tasks. © 2023 Association for Computing Machinery. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Ang2023Learning
ER  -

TY  - JOUR
AU  - Qu, M.
AU  - Deng, G.
AU  - Di, D.
AU  - Cui, J.
AU  - Su, T.
TI  - Dual attentional transformer for video visual relation prediction
PY  - 2023
T2  - Neurocomputing
VL  - 550
C7  - 126372
DO  - 10.1016/j.neucom.2023.126372
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163489136&doi=10.1016%2fj.neucom.2023.126372&partnerID=40&md5=432fdbe24b06b197be04166f79d24d4f
AB  - Video visual relation detecti on (VidVRD) is to detect visual relations among instances as well as the trajectories of the corresponding subjects and objects in the video. Most current works improve the accuracy of tracking the objects but neglect the other key challenge, predicting the reliable visual relations in the videos, a vital meant for downstream tasks further. In this paper, we propose a dual attentional transformer network (VRD-DAT) for predicting the visual relations, also known as the predicates, in multi-relation videos. Specifically, our network first respectively targets modeling action visual predicates (Act-T) and spatial locating visual relations (Spa-T) via two parallel visual transformer structures simultaneously. Then, an attentional weighting module obtains the final precise merged visual relations. We conduct extensive experiments on two public datasets, ImageNet-VidVRD and VidOR, to demonstrate our model is capable of outperforming other state-of-the-art methods effectively on the task of video visual relation prediction. Quantitative and qualitative results also show that with more accurate visual relations, the performance of the video visual relation detection task can be further boosted. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Qu2023Dual
ER  -

TY  - JOUR
AU  - Zeng, C.
AU  - Kwong, S.
TI  - Combining CNN and transformers for full-reference and no-reference image quality assessment
PY  - 2023
T2  - Neurocomputing
VL  - 549
C7  - 126437
DO  - 10.1016/j.neucom.2023.126437
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163193333&doi=10.1016%2fj.neucom.2023.126437&partnerID=40&md5=13aaee0cc48f4e725ef42b18f1d4a81a
AB  - Most deep learning approaches for image quality assessment use regression from deep features extracted by CNN (Convolutional Neural Networks). However, non-local information is usually neglected in existing methods. Motivated by the recent success of transformers in modeling contextual information, we propose a hybrid framework that utilizes a vision transformer backbone to extract features and a CNN decoder for quality estimation. We propose a shared feature extraction scheme for both FR and NR settings. A two-branch structured attentive quality predictor is devised for quality prediction. Evaluation experiments on various IQA datasets, including LIVE, CSIQ and TID2013, LIVE-Challenge, KADID-10 K, and KONIQ-10 K, show that our proposed models achieve outstanding performance for both FR and NR settings. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Zeng2023Combining
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Liu, J.
AU  - Zhu, X.
AU  - Yang, F.
AU  - Zhang, Q.
AU  - Shah, H.A.
TI  - FragDPI: a novel drug-protein interaction prediction model based on fragment understanding and unified coding
PY  - 2023
T2  - Frontiers of Computer Science
VL  - 17
IS  - 5
C7  - 175903
DO  - 10.1007/s11704-022-2163-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144438602&doi=10.1007%2fs11704-022-2163-9&partnerID=40&md5=2e144fe539d0c499c831e5f27ab19a2c
AB  - Prediction of drug-protein binding is critical for virtual drug screening. Many deep learning methods have been proposed to predict the drug-protein binding based on protein sequences and drug representation sequences. However, most existing methods extract features from protein and drug sequences separately. As a result, they can not learn the features characterizing the drug-protein interactions. In addition, the existing methods encode the protein (drug) sequence usually based on the assumption that each amino acid (atom) has the same contribution to the binding, ignoring different impacts of different amino acids (atoms) on the binding. However, the event of drug-protein binding usually occurs between conserved residue fragments in the protein sequence and atom fragments of the drug molecule. Therefore, a more comprehensive encoding strategy is required to extract information from the conserved fragments. In this paper, we propose a novel model, named FragDPI, to predict the drug-protein binding affinity. Unlike other methods, we encode the sequences based on the conserved fragments and encode the protein and drug into a unified vector. Moreover, we adopt a novel two-step training strategy to train FragDPI. The pre-training step is to learn the interactions between different fragments using unsupervised learning. The fine-tuning step is for predicting the binding affinities using supervised learning. The experiment results have illustrated the superiority of FragDPI. © 2022, Higher Education Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Yang2023FragDPI
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Zheng, C.
AU  - Wang, M.
AU  - Chen, Z.
AU  - Zhao, Z.
AU  - Zhang, L.
TI  - MAT-transformer-based state forecasting method for information devices
PY  - 2023
T2  - Future Generation Computer Systems
VL  - 147
SP  - 360
EP  - 370
DO  - 10.1016/j.future.2023.03.032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161333693&doi=10.1016%2fj.future.2023.03.032&partnerID=40&md5=cd04ab20387693cedb2b834f1b279b7d
AB  - Forecasting the state of information devices is critical to their smooth operation (e.g., smart grids). Transformer-based state forecasting methods have recently shown promising results in modeling sequential data, including time series data in the domain system of information devices. However, conventional Transformers are limited in their ability to handle very long sequences because of the quadratic memory complexity of the self-attention mechanism. This makes them less suitable for forecasting very long time series. In this study, we propose a machine-learning model based on the mean anomaly translating (MAT) Transformer that accurately forecasts the operational state of power information systems while improving the ability to forecast whether the server will fail when processing very long time series data. The proposed MAT algorithm eliminates the influence of local outliers in the time series and makes the distribution of the training data more conducive to mining by preserving its original characteristics and adjusting the forecasting model more efficiently. This improves forecasting accuracy when combined with the screening method for nonlinear correlation variables. A real-world power industry operation data set containing 170,000 information system status records was used to test the proposed method. Accurate forecasting and generation of forecasting intervals for CPU and memory metrics demonstrate the effectiveness of the method. Our proposed MAT-Transformer-based state forecasting method is a promising approach for accurately forecasting the state of information devices and has the potential to be applied in various practical scenarios. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2023MAT-transformer-based
ER  -

TY  - JOUR
AU  - Pellegrini, C.
AU  - Navab, N.
AU  - Kazi, A.
TI  - Unsupervised pre-training of graph transformers on patient population graphs
PY  - 2023
T2  - Medical Image Analysis
VL  - 89
C7  - 102895
DO  - 10.1016/j.media.2023.102895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165228346&doi=10.1016%2fj.media.2023.102895&partnerID=40&md5=3fc3f38a3a5a9988436c4da03d976deb
AB  - Pre-training has shown success in different areas of machine learning, such as Computer Vision, Natural Language Processing (NLP), and medical imaging. However, it has not been fully explored for clinical data analysis. An immense amount of clinical records are recorded, but still, data and labels can be scarce for data collected in small hospitals or dealing with rare diseases. In such scenarios, pre-training on a larger set of unlabeled clinical data could improve performance. In this paper, we propose novel unsupervised pre-training techniques designed for heterogeneous, multi-modal clinical data for patient outcome prediction inspired by masked language modeling (MLM), by leveraging graph deep learning over population graphs. To this end, we further propose a graph-transformer-based network, designed to handle heterogeneous clinical data. By combining masking-based pre-training with a transformer-based network, we translate the success of masking-based pre-training in other domains to heterogeneous clinical data. We show the benefit of our pre-training method in a self-supervised and a transfer learning setting, utilizing three medical datasets TADPOLE, MIMIC-III, and a Sepsis Prediction Dataset. We find that our proposed pre-training methods help in modeling the data at a patient and population level and improve performance in different fine-tuning tasks on all datasets. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Pellegrini2023Unsupervised
ER  -

TY  - JOUR
AU  - Chen, D.
AU  - Zhu, H.
AU  - Yang, S.
TI  - UC-SFDA: Source-free domain adaptation via uncertainty prediction and evidence-based contrastive learning
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 275
C7  - 110728
DO  - 10.1016/j.knosys.2023.110728
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163426951&doi=10.1016%2fj.knosys.2023.110728&partnerID=40&md5=e2b58c3cffd687cce64e5cee03a2d8f0
AB  - Most unsupervised domain adaptation approaches learn domain-invariant features assuming that source and target domain data are available simultaneously. In practice, the availability of source samples is only sometimes possible. This paper establishes a novel source-free domain adaptation (SFDA) framework based on uncertainty prediction and a neighborhood-guided evidence-based contrastive learning scheme. First, we develop an evidence analyzer based on the uncertainty prediction principle of Dempster–Shafer (D–S) evidence theory, which improves the network capability for discriminating different types of samples. The transformer layer with a self-attention module is adopted to capture long-distance feature dependencies such that the proposed network has better generalization ability on multiple domains. Then, we offer a high-confidence target domain sample (HCS) acquisition strategy through evidence theory, entropy criterion, and distance information. A joint confidence enhancement scheme obtains the final HCS that generates pseudo-labels. Finally, we propose an optimization method based on evidence theory, evidence-based comparative learning, and internal neighborhood structure to ensure the separability between classes and compactness within categories. Experimental results show that the proposed framework performs superiorly on two standard datasets on multiple adaptation tasks. The code for this project is available at github.com/oolown/UC-SFDA. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; 
LB  - Chen2023UC-SFDA
ER  -

TY  - JOUR
AU  - Xu, X.
AU  - Wang, Z.
AU  - Zhou, F.
AU  - Huang, Y.
AU  - Zhong, T.
AU  - Trajcevski, G.
TI  - Dynamic transformer ODEs for large-scale reservoir inflow forecasting
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 276
C7  - 110737
DO  - 10.1016/j.knosys.2023.110737
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165216704&doi=10.1016%2fj.knosys.2023.110737&partnerID=40&md5=67181acc008bd838b338ae81dae022ef
AB  - Forecasting incoming water demand is a critical step in efficient reservoir management and revenue optimization in large-scale cascade hydropower stations. It depends on multiple factors, such as weather conditions, grid dispatch, and electricity demand, and, in turn, facilitates a range of downstream decision-making, from natural hazards control and water ecology protection to power generation plans. Current efforts mainly rely on methodologies from statistical machine learning or deep neural networks to model the hydrological patterns from historical time series for inflow forecasting. However, existing models are restricted by short-term temporal dependencies and are prone to error accumulation issues due to the underlying autoregressive architecture. Meanwhile, most recent self-attention time-series models fail to achieve real-time inflow forecasting because of tremendous parameters and computational bottlenecks on learning long time series with fine granularity. We propose a novel framework, called DTODE (Dynamic Transformer Ordinary Differential Equations), for capturing nonlinear and non-stationary evolving patterns inherent in hydrological time series. Specifically, we present the dynamic self-attention mechanism combining transformer and ordinary differential equations that simultaneously captures long-range dependencies of observations from a dynamic system perspective. DTODE exploits a continuum of self-attention layers (instead of discrete counterparts) to learn the dynamics of multivariate time series while paying attention to the co-evolving time-related factors. Besides, our model is flexible in inferring the complex states at any time step, allowing us to forecast inflows at multiple time horizons. Comprehensive evaluations on real-world datasets show that DTODE significantly reduces forecasting errors compared to state-of-the-art inflow prediction systems. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; 
LB  - Xu2023Dynamic
ER  -

TY  - JOUR
AU  - Khan, A.
AU  - Lee, B.
TI  - DeepGene Transformer: Transformer for the gene expression-based classification of cancer subtypes
PY  - 2023
T2  - Expert Systems with Applications
VL  - 226
C7  - 120047
DO  - 10.1016/j.eswa.2023.120047
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153492161&doi=10.1016%2fj.eswa.2023.120047&partnerID=40&md5=62be4cc5658940ebbd7ef18b1723d593
AB  - Cancer and its subtypes constitute approximately 30% of all causes of death globally and display a wide range of heterogeneity in terms of clinical and molecular responses to therapy. Molecular subtyping has enabled the use of precision medicine to overcome these challenges and provide significant biological insights to predict prognosis and improve clinical decision-making. Over the past decade, conventional machine learning (ML) and deep learning (DL) algorithms have been widely espoused for the classification of cancer subtypes from gene expression datasets. However, these methods are potentially biased toward the identification of cancer biomarkers. Hence, an end-to-end deep learning approach, DeepGene Transformer, is proposed which addresses the complexity of high-dimensional gene expression with a multi-head self-attention module by identifying relevant biomarkers across multiple cancer subtypes without requiring feature selection as a pre-requisite for the current classification algorithms. Comparative analysis reveals that the proposed DeepGene Transformer outperformed the commonly used traditional and state-of-the-art classification algorithms and can be considered an efficient approach for classifying cancer and its subtypes, indicating that any improvement in deep learning models in computational biologists can be reflected well in this domain as well. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Khan2023DeepGene
ER  -

TY  - JOUR
AU  - Immanuel, S.A.
AU  - Jeong, C.
TI  - Lightweight recurrent cross-modal encoder for video question answering
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 276
C7  - 110773
DO  - 10.1016/j.knosys.2023.110773
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166028150&doi=10.1016%2fj.knosys.2023.110773&partnerID=40&md5=7d1b2974a22134887135cd2ffe29e16a
AB  - A video question answering task essentially boils down to how to fuse the information between text and video effectively to predict an answer. Most works employ a transformer encoder as a cross-modal encoder to fuse both modalities by leveraging the full self-attention mechanism. Due to the high computational cost of the self-attention and the high dimensional data of video, they either have to settle for: (1) only training the cross-modal encoder on offline-extracted video and text features or (2) training the cross-modal encoder with the video and text feature extractor, but only using sparsely-sampled video frames. Training only from offline-extracted features suffers from the disconnection between the extracted features and the data of the downstream task because the video and text feature extractors are trained independently on different domains, e.g., action recognition for the video feature extractor and semantic classification for the text feature extractor. Training using sparsely-sampled video frames might suffer from information loss if the video contains very rich information or has many frames. To alleviate those issues, we propose Lightweight Recurrent Cross-modal Encoder (LRCE) that replaces the self-attention operation with a single learnable special token to summarize the text and video features. As a result, our model incurs a significantly lower computational cost. Additionally, we perform a novel multi-segment sampling which sparsely samples the video frames from different segments of the video to provide more fine-grained information. Through extensive experiments on three VideoQA datasets, we demonstrate the LRCE achieves significant performance gains compared to previous works. The code of our proposed method is available at https://github.com/Sejong-VLI/VQA-LRCE-KBS-2023. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; 
LB  - Immanuel2023Lightweight
ER  -

TY  - JOUR
AU  - Xue, L.
AU  - Qin, G.
AU  - Chang, S.
AU  - Luo, C.
AU  - Hou, Y.
AU  - Xia, Z.
AU  - Yuan, J.
AU  - Wang, Y.
AU  - Liu, S.
AU  - Liu, K.
AU  - Li, X.
AU  - Wu, S.
AU  - Zhao, Q.
AU  - Gao, W.
AU  - Yang, K.
TI  - Osteoporosis prediction in lumbar spine X-ray images using the multi-scale weighted fusion contextual transformer network
PY  - 2023
T2  - Artificial Intelligence in Medicine
VL  - 143
C7  - 102639
DO  - 10.1016/j.artmed.2023.102639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169998483&doi=10.1016%2fj.artmed.2023.102639&partnerID=40&md5=dba04e0e4dcbab86c76fcb63f70761dd
AB  - Osteoporosis is a bone-related disease characterized by decreased bone density and mass, leading to brittle fractures. Osteoporosis assessment from radiographs using a deep learning algorithm has proven a low-cost alternative to the golden standard DXA. Due to the considerable noise and low contrast, automated diagnosis of osteoporosis in X-ray images still poses a significant challenge for traditional diagnostic methods. In this paper, an end-to-end transformer-style network was proposed, termed FCoTNet, to overcome the shortcoming of insufficient fusion of texture information and local features in the traditional CoTNet. To extract complementary geometric representations at each scale of the transformer module, we integrated parallel multi-scale feature extraction architectures in each unit layer of FCoTNet to utilize convolution to aggregate features from different receptive fields. Moreover, in order to extract small-scale texture features which were more critical to the diagnosis of osteoporosis in radiographs, larger fusion weights were assigned to the feature maps with small-size receptive fields. Afterward, the multi-scale global modeling was conducted by self-attention mechanism. The proposed model was first investigated on a private lumbar spine X-ray dataset with the 5-fold cross-validation strategy, obtaining an average accuracy of 78.29 ± 0.93 %, an average sensitivity of 69.72 ± 2.35 %, and an average specificity of 88.92 ± 0.67 % for the multi-classification of normal, osteopenia, and osteoporosis categories. We then conducted a controlled trial with five orthopedic clinicians to evaluate the clinical value of the model. The average clinician's accuracy improved from 61.50 ± 10.79 % unaided to 80.00 ± 5.92 % aided (18.50 % improvement), sensitivity improved from 64.38 ± 8.07 % unaided to 83.31 ± 5.43 % aided (18.93 % improvement), and specificity improved from 80.11 ± 4.72 % unaided to 89.94 ± 3.82 % aided (9.83 % improvement). Meanwhile, the prediction consistency among clinicians significantly improved with the assistance of FCoTNet. Furthermore, the proposed model showed good robustness on an external test dataset. These investigations indicate that the proposed deep learning model achieves state-of-the-art performance for osteoporosis prediction, which substantially improves osteoporosis screening and reduced osteoporosis fractures. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Xue2023Osteoporosis
ER  -

TY  - JOUR
AU  - Cejudo, A.
AU  - Casillas, A.
AU  - Pérez, A.
AU  - Oronoz, M.
AU  - Cobos, D.
TI  - Cause of Death estimation from Verbal Autopsies: Is the Open Response redundant or synergistic?
PY  - 2023
T2  - Artificial Intelligence in Medicine
VL  - 143
C7  - 102622
DO  - 10.1016/j.artmed.2023.102622
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165539394&doi=10.1016%2fj.artmed.2023.102622&partnerID=40&md5=be983ee2e9acb9f5236646f522b48d2a
AB  - Civil registration and vital statistics systems capture birth and death events to compile vital statistics and to provide legal rights to citizens. Vital statistics are a key factor in promoting public health policies and the health of the population. Medical certification of cause of death is the preferred source of cause of death information. However, two thirds of all deaths worldwide are not captured in routine mortality information systems and their cause of death is unknown. Verbal autopsy is an interim solution for estimating the cause of death distribution at the population level in the absence of medical certification. A Verbal Autopsy (VA) consists of an interview with the relative or the caregiver of the deceased. The VA includes both Closed Questions (CQs) with structured answer options, and an Open Response (OR) consisting of a free narrative of the events expressed in natural language and without any pre-determined structure. There are a number of automated systems to analyze the CQs to obtain cause specific mortality fractions with limited performance. We hypothesize that the incorporation of the text provided by the OR might convey relevant information to discern the CoD. The experimental layout compares existing Computer Coding Verbal Autopsy methods such as Tariff 2.0 with other approaches well suited to the processing of structured inputs as is the case of the CQs. Next, alternative approaches based on language models are employed to analyze the OR. Finally, we propose a new method with a bi-modal input that combines the CQs and the OR. Empirical results corroborated that the CoD prediction capability of the Tariff 2.0 algorithm is outperformed by our method taking into account the valuable information conveyed by the OR. As an added value, with this work we made available the software to enable the reproducibility of the results attained with a version implemented in R to make the comparison with Tariff 2.0 evident. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Cejudo2023Cause
ER  -

TY  - JOUR
AU  - Zheng, G.
AU  - Chai, W.K.
AU  - Zhang, J.
AU  - Katos, V.
TI  - VDGCNeT: A novel network-wide Virtual Dynamic Graph Convolution Neural network and Transformer-based traffic prediction model
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 275
C7  - 110676
DO  - 10.1016/j.knosys.2023.110676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162175610&doi=10.1016%2fj.knosys.2023.110676&partnerID=40&md5=d99cc78c74fd021b7d9e8fda2c82c366
AB  - We address the problem of traffic prediction on large-scale road networks. We propose a novel deep learning model, Virtual Dynamic Graph Convolution Neural Network and Transformer with Gate and Attention mechanisms (VDGCNeT), to comprehensively extract complex, dynamic and hidden spatial dependencies of road networks for achieving high prediction accuracy. For this purpose, we advocate the use of a virtual dynamic road graph that captures the dynamic and hidden spatial dependencies of road segments in real road networks instead of purely relying on the physical road connectivity. We further design a novel framework based on Graph Convolution Neural Network (GCN) and Transformer to analyze dynamic and hidden spatial–temporal features. The gate mechanism is utilized for concatenating learned spatial and temporal features from Spatial and Temporal Transformers, respectively, while the Attention-based Similarity is used to update dynamic road graph. Two real-world traffic datasets from large-scale road networks with different properties are used for training and testing our model. We compare our VDGCNeT against nine other well-known models in the literature. Our results demonstrate that the proposed VDGCNeT is capable of achieving highly accurate predictions — on average 96.77% and 91.68% accuracy on PEMS-BAY and METR-LA datasets respectively. Overall, our VDGCNeT performs the best when compared against other existing models. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; FMS:C; 
LB  - Zheng2023VDGCNeT
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Li, G.
AU  - Li, M.
AU  - Liu, K.
AU  - Mitrouchev, P.
TI  - 3D human body modeling with orthogonal human mask image based on multi-channel Swin transformer architecture
PY  - 2023
T2  - Image and Vision Computing
VL  - 137
C7  - 104795
DO  - 10.1016/j.imavis.2023.104795
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166963946&doi=10.1016%2fj.imavis.2023.104795&partnerID=40&md5=9c1206839448cfbbebb7e0046cfc8e9b
AB  - The reconstruction based on RGB images of dressed human body lacks the shape information of the human body under clothing, while the naked 3D human body scanning will violate the user's privacy. To overcome these limitations, a new method, based on Swin transformer (Swin-T), for reconstructing 3D human body shape from human orthogonal mask image is proposed. Its core is to express the reconstruction problem as solving regression mapping function. A fast body shape type classification method based on the human front mask is proposed. The regression function is innovatively represented as a piecewise function, with the body shape of the human body as the segmentation criterion. A multi-channel Swin-T architecture is designed, which can not only extract features from front and side mask images, but also their mixed features to construct the regression mapping function. Different body types for different genders are predicted with separate regression function to help estimate an accurate human model. Extensive experimental results show that the proposed method effectively achieves visually realistic and accurate body reconstruction, and significantly outperforms the current state-of-the-art methods. In addition, the classification of body types can compensate for the errors caused by partial clothing laxity in practical applications, which is beneficial for users to obtain a more accurate 3D human model. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Li20233D
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Capurro, D.
AU  - Nguyen, A.
AU  - Verspoor, K.
TI  - Attention-based multimodal fusion with contrast for robust clinical prediction in the face of missing modalities
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 145
C7  - 104466
DO  - 10.1016/j.jbi.2023.104466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168560790&doi=10.1016%2fj.jbi.2023.104466&partnerID=40&md5=a5224f6f54b605cbe87cd0fb2ce2f4f2
AB  - Objective: With the increasing amount and growing variety of healthcare data, multimodal machine learning supporting integrated modeling of structured and unstructured data is an increasingly important tool for clinical machine learning tasks. However, it is non-trivial to manage the differences in dimensionality, volume, and temporal characteristics of data modalities in the context of a shared target task. Furthermore, patients can have substantial variations in the availability of data, while existing multimodal modeling methods typically assume data completeness and lack a mechanism to handle missing modalities. Methods: We propose a Transformer-based fusion model with modality-specific tokens that summarize the corresponding modalities to achieve effective cross-modal interaction accommodating missing modalities in the clinical context. The model is further refined by inter-modal, inter-sample contrastive learning to improve the representations for better predictive performance. We denote the model as Attention-based cRoss-MOdal fUsion with contRast (ARMOUR). We evaluate ARMOUR using two input modalities (structured measurements and unstructured text), six clinical prediction tasks, and two evaluation regimes, either including or excluding samples with missing modalities. Results: Our model shows improved performances over unimodal or multimodal baselines in both evaluation regimes, including or excluding patients with missing modalities in the input. The contrastive learning improves the representation power and is shown to be essential for better results. The simple setup of modality-specific tokens enables ARMOUR to handle patients with missing modalities and allows comparison with existing unimodal benchmark results. Conclusion: We propose a multimodal model for robust clinical prediction to achieve improved performance while accommodating patients with missing modalities. This work could inspire future research to study the effective incorporation of multiple, more complex modalities of clinical data into a single model. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Liu2023Attention-based
ER  -

TY  - JOUR
AU  - Malla, S.
AU  - Kumar, L.K.
AU  - Alphonse, P.J.A.
TI  - Novel fuzzy deep learning approach for automated detection of useful COVID-19 tweets
PY  - 2023
T2  - Artificial Intelligence in Medicine
VL  - 143
C7  - 102627
DO  - 10.1016/j.artmed.2023.102627
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166286509&doi=10.1016%2fj.artmed.2023.102627&partnerID=40&md5=3f84a75a0582e4ebd7499c2495096da8
AB  - Coronavirus (COVID-19) is a newly discovered viral disease from the SARS-CoV-2 family. This has caused a moral panic resulting in the spread of informative and uninformative information about COVID-19 and its effects. Twitter is a popular social media platform used extensively during the current outbreak. This paper aims to predict informative tweets related to COVID-19 on Twitter using a novel set of fuzzy rules involving deep learning techniques. This study focuses on identifying informative tweets during the pandemic to provide the public with trustworthy information and forecast how quickly diseases could spread. In this case, we have implemented RoBERTa and CT-BERT models using the fuzzy methodology to identify COVID-19 patient tweets. The proposed architecture combines deep learning transformer models RoBERTa and CT-BERT with the fuzzy technique to categorize posts as INFORMATIVE or UNINFORMATIVE. We performed a comparative analysis of our method with machine learning models and deep learning approaches. The results show that our proposed model can classify informative and uninformative tweets with an accuracy of 91.40% and an F1-score of 91.94% using the COVID-19 English tweet dataset. The proposed model is accurate and ready for real-world application. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Malla2023Novel
ER  -

TY  - JOUR
AU  - Zolnoori, M.
AU  - Zolnour, A.
AU  - Topaz, M.
TI  - ADscreen: A speech processing-based screening system for automatic identification of patients with Alzheimer's disease and related dementia
PY  - 2023
T2  - Artificial Intelligence in Medicine
VL  - 143
C7  - 102624
DO  - 10.1016/j.artmed.2023.102624
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165310119&doi=10.1016%2fj.artmed.2023.102624&partnerID=40&md5=af1aa1223b7812d6beb3e08ff8e5d0c6
AB  - Alzheimer's disease and related dementias (ADRD) present a looming public health crisis, affecting roughly 5 million people and 11 % of older adults in the United States. Despite nationwide efforts for timely diagnosis of patients with ADRD, >50 % of them are not diagnosed and unaware of their disease. To address this challenge, we developed ADscreen, an innovative speech-processing based ADRD screening algorithm for the protective identification of patients with ADRD. ADscreen consists of five major components: (i) noise reduction for reducing background noises from the audio-recorded patient speech, (ii) modeling the patient's ability in phonetic motor planning using acoustic parameters of the patient's voice, (iii) modeling the patient's ability in semantic and syntactic levels of language organization using linguistic parameters of the patient speech, (iv) extracting vocal and semantic psycholinguistic cues from the patient speech, and (v) building and evaluating the screening algorithm. To identify important speech parameters (features) associated with ADRD, we used the Joint Mutual Information Maximization (JMIM), an effective feature selection method for high dimensional, small sample size datasets. Modeling the relationship between speech parameters and the outcome variable (presence/absence of ADRD) was conducted using three different machine learning (ML) architectures with the capability of joining informative acoustic and linguistic with contextual word embedding vectors obtained from the DistilBERT (Bidirectional Encoder Representations from Transformers). We evaluated the performance of the ADscreen on an audio-recorded patients' speech (verbal description) for the Cookie-Theft picture description task, which is publicly available in the dementia databank. The joint fusion of acoustic and linguistic parameters with contextual word embedding vectors of DistilBERT achieved F1-score = 84.64 (standard deviation [std] = ±3.58) and AUC-ROC = 92.53 (std = ±3.34) for training dataset, and F1-score = 89.55 and AUC-ROC = 93.89 for the test dataset. In summary, ADscreen has a strong potential to be integrated with clinical workflow to address the need for an ADRD screening tool so that patients with cognitive impairment can receive appropriate and timely care. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Zolnoori2023ADscreen
ER  -

TY  - JOUR
AU  - Ahmad, T.
AU  - Rizvi, S.T.H.
AU  - Kanwal, N.
TI  - Transforming spatio-temporal self-attention using action embedding for skeleton-based action recognition
PY  - 2023
T2  - Journal of Visual Communication and Image Representation
VL  - 95
C7  - 103892
DO  - 10.1016/j.jvcir.2023.103892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165534464&doi=10.1016%2fj.jvcir.2023.103892&partnerID=40&md5=68be6cd67a64ab299b4927740cd449f6
AB  - Over the past few years, skeleton-based action recognition has attracted great success because the skeleton data is immune to illumination variation, view-point variation, background clutter, scaling, and camera motion. However, effective modeling of the latent information of skeleton data is still a challenging problem. Therefore, in this paper, we propose a novel idea of action embedding with a self-attention Transformer network for skeleton-based action recognition. Our proposed technology mainly comprises of two modules as, (i) action embedding and (ii) self-attention Transformer. The action embedding encodes the relationship between corresponding body joints (e.g., joints of both hands move together for performing clapping action) and thus captures the spatial features of joints. Meanwhile, temporal features and dependencies of body joints are modeled using Transformer architecture. Our method works in a single-stream (end-to-end) fashion, where multiple-layer perceptron (MLP) is used for classification. We carry out an ablation study and evaluate the performance of our model on a small-scale SYSU-3D dataset and large-scale NTU-RGB+D and NTU-RGB+D 120 datasets where the results establish that our method performs better than other state-of-the-art architectures. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Ahmad2023Transforming
ER  -

TY  - JOUR
AU  - Torres, L.H.M.
AU  - Ribeiro, B.
AU  - Arrais, J.P.
TI  - Few-shot learning with transformers via graph embeddings for molecular property prediction
PY  - 2023
T2  - Expert Systems with Applications
VL  - 225
C7  - 120005
DO  - 10.1016/j.eswa.2023.120005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152118151&doi=10.1016%2fj.eswa.2023.120005&partnerID=40&md5=58a3ca9abeb2fa4c38926ba8d7b92bbb
AB  - Molecular property prediction is an essential task in drug discovery. Recently, deep neural networks have accelerated the discovery of compounds with improved molecular profiles for effective drug development. In particular, graph neural networks (GNNs) have played a pivotal role in identifying promising drug candidates with desirable molecular properties. However, it is common for only a few molecules to share the same set of properties, which presents a low-data problem unanswered by regular machine learning (ML) approaches. Transformer networks have also emerged as a promising solution to model the long-range dependence in molecular embeddings and achieve encouraging results across a wide range of molecular property prediction tasks. Nonetheless, these methods still require a large number of data points per task to achieve acceptable performance. In this study, we propose a few-shot GNN-Transformer architecture, FS-GNNTR to face the challenge of low-data in molecular property prediction. The proposed model accepts molecules in the form of molecular graphs to model the local spatial context of molecular graph embeddings while preserving the global information of deep representations. Furthermore, we introduce a two-module meta-learning framework to iteratively update model parameters across few-shot tasks and predict new molecular properties with limited available data. Finally, we conduct multiple experiments on small-sized biological datasets for molecular property prediction, Tox21 and SIDER, and our results demonstrate the superior performance of FS-GNNTR compared to simpler graph-based baselines. The code and data underlying this article are available in the repository, https://github.com/ltorres97/FS-GNNTR. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Torres2023Few-shot
ER  -

TY  - JOUR
AU  - Na, K.-I.
AU  - Kim, U.-H.
AU  - Kim, J.-H.
TI  - SPU-BERT: Faster human multi-trajectory prediction from socio-physical understanding of BERT
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 274
C7  - 110637
DO  - 10.1016/j.knosys.2023.110637
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162746024&doi=10.1016%2fj.knosys.2023.110637&partnerID=40&md5=6ee400c08b47bfc2a3ea8a0b80806791
AB  - Accurately predicting pedestrian trajectories requires a human-like socio-physical understanding of movement, nearby pedestrians, and obstacles. However, traditional methods struggle to generate multiple trajectories in the same situation based on socio-physical understanding and are computationally intensive, making real-time application difficult. To overcome these limitations, we propose SPU-BERT, a fast multi-trajectory prediction model that incorporates two non-recursive BERTs for multi-goal prediction (MGP) and trajectory-to-goal prediction (TGP). First, MGP predicts multiple goals through generative models, followed by TGP generating trajectories that approach the predicted goals. SPU-BERT can simultaneously understand movement, social interaction, and scene context from trajectories and semantic maps using a single Transformer encoder, providing explainable results as evidence of socio-physical understanding. In experiments, SPU-BERT accurately predicted future trajectories (with 0.19 m and 7.54 pixels of ADE20 for the ETH/UCY datasets and SDD) with over 100 times faster computation (0.132 s) than the state-of-the-art method. The code is available at https://github.com/kina4147/SPUBERT. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; 
LB  - Na2023SPU-BERT
ER  -

TY  - JOUR
AU  - Kaddari, Z.
AU  - Bouchentouf, T.
TI  - A novel self-attention enriching mechanism for biomedical question answering
PY  - 2023
T2  - Expert Systems with Applications
VL  - 225
C7  - 120210
DO  - 10.1016/j.eswa.2023.120210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153230893&doi=10.1016%2fj.eswa.2023.120210&partnerID=40&md5=d2631b07896c56dad4434837a32a510a
AB  - The task of biomedical question answering is a subtask of the more general question answering task, that is concerned only with biomedical questions. The current state-of-the-art models in this task like BioBERT, and BioM-ELECTRA are all based on the transformer architecture. The self-attention layer in the transformer plays a central role in the model predictions. Recent studies on the inner-workings of the transformer self-attention layer in the case of question answering hypothesize that context passage tokens with bigger attention scores have a bigger probability of being part of the predicted answer. Starting from this hypothesis, we experimented with a novel self-attention enriching mechanism for biomedical question answering targeting factoid and list type questions. In our approach, we enrich BioBERT's self-attention layer with biomedical and named entity information previously extracted from the question and the context passage. The proposed enriching mechanism increases the attention scores for the biomedical and named entities. Which are in most cases the answer to the question. This increase in attention scores influences the model final prediction as hypothesized. Our proposed method achieves state-of-the-art results on several batches of the BioASQ's 10b, 9b, 8b, and 7b datasets. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kaddari2023novel
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Liu, H.
AU  - Yang, Z.
AU  - Du, J.
AU  - Dong, X.
TI  - CNformer: a convolutional transformer with decomposition for long-term multivariate time series forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 17
SP  - 20191
EP  - 20205
DO  - 10.1007/s10489-023-04496-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151420037&doi=10.1007%2fs10489-023-04496-6&partnerID=40&md5=38559f657bd89b139f21d3d4d78bdeb9
AB  - Improving long-term time series forecasting accuracy and efficiency is of great value for real-world applications. The main challenge in the long-term forecasting of multivariate time series is to accurately capture the local dynamics and long-term dependencies of time series. Currently, most approaches capture temporal dependencies and inter-variable dependencies in intertwined temporal patterns, which are unreliable. Moreover, models based on time series decomposition methods are still unable to capture both short- and long-term dependencies well. In this paper, we propose an efficient multivariate time series forecasting model CNformer with three distinctive features. (1) The CNformer is a fully CNN-based time series forecasting model. (2) In the encoder, the stacked dilated convolution as a built-in block is combined with the time series decomposition to extract the seasonal component of the time series. (3) The convolution-based encoder-decoder attention mechanism refines seasonal patterns in the decoder and captures complex combinations between different related time series. Owing to these features, our CNformer has lower memory and time overhead than models based on self-attention and the Auto-Correlation mechanism. Experimental results show that our model achieves state-of-the-art performance on four real-world datasets, with a relative performance improvement of 20.29%. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Wang2023CNformer
ER  -

TY  - JOUR
AU  - Gunter, K.M.
AU  - Brink-Kjaer, A.
AU  - Mignot, E.
AU  - Sorensen, H.B.D.
AU  - During, E.
AU  - Jennum, P.
TI  - SViT: A Spectral Vision Transformer for the Detection of REM Sleep Behavior Disorder
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 9
SP  - 4285
EP  - 4292
DO  - 10.1109/JBHI.2023.3292231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164386707&doi=10.1109%2fJBHI.2023.3292231&partnerID=40&md5=2d948a6a725723b2628904ffd30a1234
AB  - REM sleep behavior disorder (RBD) is a parasomnia with dream enactment and presence of REM sleep without atonia (RSWA). RBD diagnosed manually via polysomnography (PSG) scoring, which is time intensive. Isolated RBD (iRBD) is also associated with a high probability of conversion to Parkinson's disease. Diagnosis of iRBD is largely based on clinical evaluation and subjective PSG ratings of REM sleep without atonia. Here we show the first application of a novel spectral vision transformer (SViT) to PSG signals for detection of RBD and compare the results to the more conventional convolutional neural network architecture. The vision-based deep learning models were applied to scalograms (30 or 300 s windows) of the PSG data (EEG, EMG and EOG) and the predictions interpreted. A total of 153 RBD (96 iRBD and 57 RBD with PD) and 190 controls were included in the study and 5-fold bagged ensemble was used. Model outputs were analyzed per-patient (averaged), with regards to sleep stage, and the SViT was interpreted using integrated gradients. Models had a similar per-epoch test F1 score. However, the vision transformer had the best per-patient performance, with an F1 score 0.87. Training the SViT on channel subsets, it achieved an F1 score of 0.93 on a combination of EEG and EOG. EMG is thought to have the highest diagnostic yield, but interpretation of our model showed that high relevance was placed on EEG and EOG, indicating these channels could be included for diagnosing RBD.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Gunter2023SViT
ER  -

TY  - JOUR
AU  - Li, C.-J.
AU  - Qu, Z.
AU  - Wang, S.-Y.
TI  - A method of knowledge distillation based on feature fusion and attention mechanism for complex traffic scenes
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 124
C7  - 106533
DO  - 10.1016/j.engappai.2023.106533
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161568911&doi=10.1016%2fj.engappai.2023.106533&partnerID=40&md5=045b502de008fbce0542b90e35ec0828
AB  - Object detectors based on deep learning can run smoothly on a terminal device in complex traffic scenes, and the model compression method has become a research hotspot. Considering student network single learning in the knowledge distillation algorithm, the dependence on loss function design leads to parameter sensitivity and other problems, we propose a new knowledge distillation method with second-order term attention mechanisms and feature fusion of adjacent layers. First, we build a knowledge distillation framework based on YOLOv5 and propose a new attention mechanism in the teacher network backbone to extract the hot map. Then, we combine the hot map features with the next level features through the fusion module. By fusing the useful information of the low convolution layer and the feature map of the high convolution layer to help the student network obtain the final prediction map. Finally, to improve the accuracy of small objects, we add a 160 × 160 detection head and use a transformer encoder block module to replace the convolution network of the head. Sufficient experimental results show that our method achieves state-of-the-art performance. The speed and number of parameters remain unchanged, but the average detection accuracy is 97.4% on the KITTI test set. On the Cityscapes test set, the average detection accuracy reaches 92.7%. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Li2023method
ER  -

TY  - JOUR
AU  - Mamun, M.A.
AU  - Abdullah, H.M.
AU  - Alam, M.G.R.
AU  - Hassan, M.M.
AU  - Uddin, M.Z.
TI  - Affective social anthropomorphic intelligent system
PY  - 2023
T2  - Multimedia Tools and Applications
VL  - 82
IS  - 23
SP  - 35059
EP  - 35090
DO  - 10.1007/s11042-023-14597-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149396805&doi=10.1007%2fs11042-023-14597-6&partnerID=40&md5=011d6e761ec0279564b61f9b19496170
AB  - Human conversational styles are measured by the sense of humor, personality, and tone of voice. These characteristics have become essential for conversational intelligent virtual assistants. However, most of the state-of-the-art intelligent virtual assistants (IVAs) are failed to interpret the affective semantics of human voices. This research proposes an anthropomorphic intelligent system that can hold a proper human-like conversation with emotion and personality. A voice style transfer method is also proposed to map the attributes of a specific emotion. Initially, the frequency domain data (Mel-Spectrogram) is created by converting the temporal audio wave data, which comprises discrete patterns for audio features such as notes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used to predict seven different affective states from voice. The voice is also fed parallelly to the deep-speech, an RNN model that generates the text transcription from the spectrogram. Then the transcripted text is transferred to the multi-domain conversation agent using blended skill talk, transformer-based retrieve-and-generate generation strategy, and beam-search decoding, and an appropriate textual response is generated. The system learns an invertible mapping of data to a latent space that can be manipulated and generates a Mel-spectrogram frame based on previous Mel-spectrogram frames to voice synthesize and style transfer. Finally, the waveform is generated using WaveGlow from the spectrogram. The outcomes of the studies we conducted on individual models were auspicious. Furthermore, users who interacted with the system provided positive feedback, demonstrating the system’s effectiveness. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Mamun2023Affective
ER  -

TY  - JOUR
AU  - Hu, B.
AU  - Wang, S.
AU  - Gao, X.
AU  - Li, L.
AU  - Gan, J.
AU  - Nie, X.
TI  - Reduced-reference image deblurring quality assessment based on multi-scale feature enhancement and aggregation
PY  - 2023
T2  - Neurocomputing
VL  - 547
C7  - 126378
DO  - 10.1016/j.neucom.2023.126378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160538674&doi=10.1016%2fj.neucom.2023.126378&partnerID=40&md5=0f60bf9788f77404429b3574493b29a7
AB  - Image deblurring is a basic task in the field of computer vision, and has attracted much attention because of its application prospects in traffic monitoring and medical imaging, etc. Due to the inherent weakness of the model, it is difficult to obtain well-pleasing deblurred images for all the visual contents so far. Therefore, how to objectively evaluate the quality of these deblurred results is very important for the rapid development of image deblurring. In recent years, numerous convolutional neural networks based quality assessment methods have been proposed to automatically predict the quality of synthetic and authentic distorted images, producing results that are mildly consistent with subjective perception. However, they are limited in Image Deblurring Quality Assessment (IDQA). For IDQA, it is more meaningful to predict the quality difference of blurry-deblurred image (BDI) pair than to make prediction on single deblurred image. Inspired by this, we propose a novel reduced-reference image deblurring quality assessment method based on multi-scale feature enhancement and aggregation. Firstly, the multi-scale features of BDI pair are generated from a versatile vision Transformer. Secondly, the discrepancy information is exploited to implicitly enhance the initial deep features. Finally, the enhanced features of different scales are aggregated and then mapped to the quality difference of BDI pair. Experimental results on four challenging datasets demonstrate that the proposed method is superior to the state-of-the-art quality assessment methods. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Hu2023Reduced-reference
ER  -

TY  - JOUR
AU  - Hu, Y.
AU  - Peng, T.
AU  - Guo, K.
AU  - Sun, Y.
AU  - Gao, J.
AU  - Yin, B.
TI  - Graph transformer based dynamic multiple graph convolution networks for traffic flow forecasting
PY  - 2023
T2  - IET Intelligent Transport Systems
VL  - 17
IS  - 9
SP  - 1835
EP  - 1845
DO  - 10.1049/itr2.12378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159108372&doi=10.1049%2fitr2.12378&partnerID=40&md5=c4d7baa960fb1aa5db16a7762664c0ea
AB  - Traffic prediction is an important part of intelligent transportation system. Recently, graph convolution network (GCN) is introduced for traffic flow forecasting and achieves good performance due to its superiority of representing the graph traffic road structure network. Moreover, the dynamic GCN is put forward to model the temporal property of the traffic flow. Although great progress has been made, most GCN based traffic flow forecasting methods utilize a single graph for convolution, which is considered not enough to reveal the inherent property of traffic graph as it is influenced by many factors, for example weather, season and traffic accidents etc. In this paper, an exotic graph transformer based dynamic multiple graph convolution networks (GTDMGCN) is conceived for traffic flow forecasting. Instead of the single graph, multiple graphs are constructed to modulate the complex traffic network by the proposed graph transformer network. Additionally, a temporal gate convolution is proposed to get the temporal property of traffic flow. The proposed GTDMGCN model is evaluated on four real traffic datasets of PEMS03, PEMS04, PEMS07, PEMS08, and there are average increments of 9.78%, 7.80%, 5.96% under MAE, RMSE, and MAPE metrics compared with the current results. © 2023 The Authors. IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; 
LB  - Hu2023Graph
ER  -

TY  - JOUR
AU  - Kuang, D.
AU  - Michoski, C.
AU  - Li, W.
AU  - Guo, R.
TI  - From gram to attention matrices: a monotonicity constrained method for eeg-based emotion classification
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 18
SP  - 20690
EP  - 20709
DO  - 10.1007/s10489-023-04561-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153057972&doi=10.1007%2fs10489-023-04561-0&partnerID=40&md5=2bedd521f74d6d3105ff991f42ca7fba
AB  - In this work, a parameter efficient attention module is developed for the task of emotion classification as well as improved model interpretability based on EEG source data. Inspired by the self-attention mechanism used in transformers, we propose a Monotonicity Constrained Attention Module (MCAM) that can help incorporate different priors easily on the monotonicity when converting Gram matrices from deep features into attention matrices for better feature refinement. In the subject-dependent classification task, MCAM achieves 95.0% mean prediction accuracy on four classification task with DEAP and 91.1% mean prediction accuracy on three classification task with SEED. On both datasets, MCAM is shown comparable to state-of-the-art attention modules in terms of boosting the backbone network’s predictive performance while requiring significantly fewer parameters. A thorough analysis is also performed on tracking the different effects inserted modules have on the backbone model’s behavior. For example, visualization and analysis techniques are presented to examine changes in spatial attention patterns reflected via kernel weights, change in prediction performance when different frequency information is filtered out, or changes that occur when different amplitude information is suppressed; as well as how different models change their predictions along linear morphisms between two samples belonging to different emotion categories. The results help to reveal what different modules learn and use during prediction, and can also provide guidance when applying them to specific applications. [Figure not available: see fulltext.] © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Kuang2023From
ER  -

TY  - JOUR
AU  - Basabain, S.
AU  - Cambria, E.
AU  - Alomar, K.
AU  - Hussain, A.
TI  - Enhancing Arabic-text feature extraction utilizing label-semantic augmentation in few/zero-shot learning
PY  - 2023
T2  - Expert Systems
VL  - 40
IS  - 8
C7  - e13329
DO  - 10.1111/exsy.13329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158087267&doi=10.1111%2fexsy.13329&partnerID=40&md5=43c4ac06b543e8b707c0ad565cb94df7
AB  - A growing amount of research use pre-trained language models to address few/zero-shot text classification problems. Most of these studies neglect the semantic information hidden implicitly beneath the natural language names of class labels and develop a meta learner from the input texts solely. In this work, we demonstrate how label information can be utilized to extract enhanced feature representation of the input text from a Transformer-based pre-trained language model such as AraBERT. In addition, how this approach can improve performance when the data resources are scarce like in the Arabic language and the input text is short with little semantic information as is the case using tweets. The work also applies zero-shot text classification to predict new classes with no training examples across different domains including sarcasm detection and sentiment analysis using the information in the last layer of a trained classifier in a transfer learning setting. Experiments show that our approach has a better performance for the few-shot sentiment classification compared to baseline models and models trained without augmenting label information. Moreover, the zero-shot implementation achieved an accuracy up to 0.874 in Arabic sarcasm detection from a model trained on a sentiment analysis task. © 2023 The Authors. Expert Systems published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Basabain2023Enhancing
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Cai, T.
AU  - Tang, X.
AU  - Wang, C.
TI  - MRL-Net: Multi-Scale Representation Learning Network for COVID-19 Lung CT Image Segmentation
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 9
SP  - 4317
EP  - 4328
DO  - 10.1109/JBHI.2023.3285936
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162685139&doi=10.1109%2fJBHI.2023.3285936&partnerID=40&md5=1730ea2cdd297c8d66f588b21a51a74a
AB  - Accuracy segmentation of COVID-19 lesions in lung CT images can aid patient screening and diagnosis. However, the blurred, inconsistent shape and location of the lesion area poses a great challenge to this vision task. To tackle this issue, we propose a multi-scale representation learning network (MRL-Net) that integrates CNN with Transformer via two bridge unit: Dual Multi-interaction Attention (DMA) and Dual Boundary Attention (DBA). First, to obtain multi-scale local detailed feature and global contextual information, we combine low-level geometric information and high-level semantic features extracted by CNN and Transformer, respectively. Secondly, for enhanced feature representation, DMA is proposed to fuse the local detailed feature of CNN and the global context information of Transformer. Finally, DBA makes our network focus on the boundary features of the lesion, further enhancing the representational learning. Amounts of experimental results show that MRL-Net is superior to current state-of-the-art methods and achieves better COVID-19 image segmentation performance.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Liu2023MRL-Net
ER  -

TY  - JOUR
AU  - Muhammad, T.
AU  - Aftab, A.B.
AU  - Ibrahim, M.
AU  - Ahsan, M.M.
AU  - Muhu, M.M.
AU  - Khan, S.I.
AU  - Alam, M.S.
TI  - Transformer-Based Deep Learning Model for Stock Price Prediction: A Case Study on Bangladesh Stock Market
PY  - 2023
T2  - International Journal of Computational Intelligence and Applications
VL  - 22
IS  - 3
C7  - 2350013
DO  - 10.1142/S146902682350013X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153953795&doi=10.1142%2fS146902682350013X&partnerID=40&md5=d1714cfaa068599dcdc71ecfb0560535
AB  - In the modern capital market, the price of a stock is often considered to be highly volatile and unpredictable because of various social, financial, political and other dynamic factors. With calculated and thoughtful investment, stock market can ensure a handsome profit with minimal capital investment, while incorrect prediction can easily bring catastrophic financial loss to the investors. This paper introduces the application of a recently introduced machine learning model - the transformer model, to predict the future price of stocks of Dhaka Stock Exchange (DSE), the leading stock exchange in Bangladesh. The transformer model has been widely leveraged for natural language processing and computer vision tasks, but, to the best of our knowledge, has never been used for stock price prediction task task using DSE data. Recently, the introduction of time2vec encoding to represent the time series features has made it possible to employ the transformer model for the stock price prediction. This paper aims to leverage these two effective techniques to discover forecasting ability on the volatile stock market of DSE. We deal with the historical daily and weekly data of eight specific stocks listed in DSE. Our experiments demonstrate promising results and acceptable root-mean-squared error on most of the stocks. We also compare the performance of our model with that of a well-known benchmark stock forecasting model called ARIMA and report satisfactory results.  © 2023 World Scientific Publishing Europe Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; 
LB  - Muhammad2023Transformer-Based
ER  -

TY  - JOUR
AU  - Qi, S.
AU  - Li, Y.
AU  - Gao, C.
AU  - Su, X.
AU  - Gao, S.
AU  - Zheng, Z.
AU  - Liu, C.
TI  - Dynamically Relative Position Encoding-Based Transformer for Automatic Code Edit
PY  - 2023
T2  - IEEE Transactions on Reliability
VL  - 72
IS  - 3
SP  - 1147
EP  - 1160
DO  - 10.1109/TR.2022.3194370
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137567791&doi=10.1109%2fTR.2022.3194370&partnerID=40&md5=2fa842cc4d3b800baaa9ae9b871cdfb3
AB  - Adapting deep learning (DL) techniques to automate nontrivial coding activities, such as code documentation and defect detection, has been intensively studied recently. Learning to predict code changes is one of the popular and essential investigations. Prior studies have shown that DL techniques, such as neural machine translation (NMT), can benefit meaningful code changes, including bug fixing and code refactoring. However, NMT models may encounter bottleneck when modeling long sequences; thus, they are limited in accurately predicting code changes. In this article, we design a Transformer-based approach, considering that the Transformer has proven effective in capturing long-term dependencies. Specifically, we propose a novel model named DTrans. For better incorporating the local structure of code, i.e., statement-level information in this article, DTrans is designed with dynamically relative position encoding in the multihead attention of the Transformer. Experiments on benchmark datasets demonstrate that DTrans can more accurately generate patches than the state-of-the-art methods, increasing the performance by at least 5.45-46.57% in terms of the exact match metric on different datasets. Moreover, DTrans can locate the lines to change with 1.75-24.21% higher accuracy than the existing methods.  © 1963-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Qi2023Dynamically
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Shao, Z.
AU  - Bian, H.
AU  - Fang, Z.
AU  - Wang, Y.
AU  - Cai, Y.
AU  - Wang, H.
AU  - Liu, G.
AU  - Li, X.
AU  - Zhang, Y.
TI  - DMIL-Transformer: Multiple Instance Learning Via Integrating Morphological and Spatial Information for Lymph Node Metastasis Classification
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 9
SP  - 4433
EP  - 4443
DO  - 10.1109/JBHI.2023.3285275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162733836&doi=10.1109%2fJBHI.2023.3285275&partnerID=40&md5=3752f44363d6cefa574a66ea2828bb89
AB  - Automated classification of lymph node metastasis (LNM) plays an important role in the diagnosis and prognosis. However, it is very challenging to achieve satisfactory performance in LNM classification, because both the morphology and spatial distribution of tumor regions should be taken into account. To address this problem, this article proposes a two-stage dMIL-Transformer framework, which integrates both the morphological and spatial information of the tumor regions based on the theory of multiple instance learning (MIL). In the first stage, a double Max-Min MIL (dMIL) strategy is devised to select the suspected top-K positive instances from each input histopathology image, which contains tens of thousands of patches (primarily negative). The dMIL strategy enables a better decision boundary for selecting the critical instances compared with other methods. In the second stage, a Transformer-based MIL aggregator is designed to integrate all the morphological and spatial information of the selected instances from the first stage. The self-attention mechanism is further employed to characterize the correlation between different instances and learn the bag-level representation for predicting the LNM category. The proposed dMIL-Transformer can effectively deal with the thorny classification in LNM with great visualization and interpretability. We conduct various experiments over three LNM datasets, and achieve 1.79%-7.50% performance improvement compared with other state-of-the-art methods.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Chen2023DMIL-Transformer
ER  -

TY  - JOUR
AU  - Chen, Z.-Y.
AU  - Xiao, F.
AU  - Wang, X.-K.
AU  - Hou, W.-H.
AU  - Huang, R.-L.
AU  - Wang, J.-Q.
TI  - An interpretable diagnostic approach for lung cancer: Combining maximal clique and improved BERT
PY  - 2023
T2  - Expert Systems
VL  - 40
IS  - 8
C7  - e13310
DO  - 10.1111/exsy.13310
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153323244&doi=10.1111%2fexsy.13310&partnerID=40&md5=08bd89cc3e8c20ef3ca8a516e1a88a7f
AB  - The lung cancer incidence and mortality in China have always been high. Moreover, due to the limited level of professional technology, misdiagnosis and missed diagnosis of lung cancer often occur. To improve the accuracy of diagnosis, this paper proposes an interpretable diagnostic method for lung cancer based on Chinese electronic medical records (EMRs). First, to overcome the difficulty in word segmentation of clinical texts in Chinese EMRs, a dictionary construction method is proposed based on the idea of maximal clique, and 730 medical professional terms related to lung diseases are identified. Then, the ProbSparse self-attention mechanism and self-attention distilling operation in Informer are used to improve the Bidirectional Encoder Representations from Transformer (BERT) to realize the representation of long clinical texts with lower time complexity and memory consumption. Finally, the convolutional neural network with an attention mechanism is employed to process the representation results to realize the interpretable prediction of lung cancer. This method is applied to the lung cancer diagnosis of inpatients in a tertiary hospital in Hunan Province, obtaining excellent results of about 0.9 for area under the receiver operating characteristic curve (AUROC) and area under the precision-recall curve (AUPRC). In addition, the results of the comparative analysis with existing dictionaries, word embedding methods and diagnostic methods further confirm the superiority of the proposed method. Specifically, the proposed method improves the precision by at least 6%, the recall by at least 2.6%, the F1 score by at least 5.2%, AUROC by at least 7.3% and AUPRC by at least 7.7% compared with all these state-of-the-art methods. © 2023 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Chen2023interpretable
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Yan, L.
AU  - Feng, Z.
AU  - Xia, Y.
AU  - Xiao, B.
TI  - Visual tracking using transformer with a combination of convolution and attention
PY  - 2023
T2  - Image and Vision Computing
VL  - 137
C7  - 104760
DO  - 10.1016/j.imavis.2023.104760
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165055806&doi=10.1016%2fj.imavis.2023.104760&partnerID=40&md5=9281737522737374ea1543d65c4c18f2
AB  - For Siamese-based trackers in the field of single object tracking, cross-correlation operation plays an important role. However, the cross-correlation essentially uses target feature to locally linearly match the search region, which leads to insufficient utilization or even loss of feature information. To effectively employ global context and sufficiently explore the relevance of template and search region, a novel matching operator is designed inspired by Transformer, which uses multi-head attention and embed a designed modulation module across the inputs of operator. Meanwhile, we equip our tracker with a multi-scale encoder/decoder strategy to gradually make more precise tracking. Finally, a complete tracking framework is presented named VTTR. The tracker consists of a feature extractor, a multi-scale encoder based on depth-wise convolution, a modified decoder as the matching operator and a prediction head. The proposed tracker is tested on many benchmarks and achieve excellent performance while running with fast speed. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2023Visual
ER  -

TY  - JOUR
AU  - Liu, D.
AU  - Wang, Y.
AU  - Liu, C.
AU  - Yuan, X.
AU  - Yang, C.
AU  - Gui, W.
TI  - Data Mode Related Interpretable Transformer Network for Predictive Modeling and Key Sample Analysis in Industrial Processes
PY  - 2023
T2  - IEEE Transactions on Industrial Informatics
VL  - 19
IS  - 9
SP  - 9325
EP  - 9336
DO  - 10.1109/TII.2022.3227731
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144800671&doi=10.1109%2fTII.2022.3227731&partnerID=40&md5=36df1e255aad659fbbb3ba65cbb0d32b
AB  - Accurate prediction of quality variables that are difficult to measure is crucial for industrial process control and optimization. However, the fluctuations in raw material quality and production conditions may cause industrial process data to be distributed in multiple working conditions. The data under the same working condition show similar characteristics, which are often defined as one data mode. Hence, the overall process data exhibit multimode characteristics, which brings great challenges in developing a uniform prediction model. Besides, the noninterpretability of the existing data-driven prediction models brings great resistance to their practical application. To address these issues, this article proposes a novel data mode related interpretable transformer network (DMRI-Former) for predictive modeling and key sample analysis in industrial processes. In DMRI-Former, a novel data mode related interpretable self-attention mechanism is designed to enhance the homomode perceptual ability of each individual mode while also capturing cross-mode features of different modes. Moreover, the key samples under different modes can be discovered using DMRI-Former, which further improves the interpretability of the modeling process. Finally, the superiority of the proposed DMRI-Former is verified in two real-world industrial processes compared to other state-of-the-art methods. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 39
C2  - CCF:C期刊; 
LB  - Liu2023Data
ER  -

TY  - JOUR
AU  - Kaya, M.
AU  - Karan, M.B.
AU  - Telatar, E.
TI  - Electricity price estimation using deep learning approaches: An empirical study on Turkish markets in normal and Covid-19 periods
PY  - 2023
T2  - Expert Systems with Applications
VL  - 224
C7  - 120026
DO  - 10.1016/j.eswa.2023.120026
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151734609&doi=10.1016%2fj.eswa.2023.120026&partnerID=40&md5=0156aeaea2f9d0040047ccbdf0055e33
AB  - This study aims to estimate the prices in the next 24 h with deep learning methods in the Turkish electricity market. The model is based on hourly data for the period 2017–2021 using electricity prices. The model's Root Mean Square Error (RMSE) value is 3.14, and the explanatory power R2 is 0.94. Since this model also considers the subgroups in the database, it can make price predictions for the pandemic period. To test the robustness and consistency of the model, twelve RNN-based models were re-estimated with the same data set. Although all models successfully predict the prices, The TEDSE Model performs better than the others. This study will be especially beneficial to electricity market players and policymakers. In further studies, the TEDSE model can be used for price prediction in intraday energy markets. This study's most important contribution is methodology innovation, using the Transformer Encoder-Decoder with Self-Attention (TEDSE) model for the first time to estimate electricity prices. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kaya2023Electricity
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Zhang, H.
AU  - Ma, H.
AU  - Feng, J.
AU  - Jiang, M.
TI  - CSIT: Channel Spatial Integrated Transformer for human pose estimation
PY  - 2023
T2  - IET Image Processing
VL  - 17
IS  - 10
SP  - 3002
EP  - 3011
DO  - 10.1049/ipr2.12850
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161983874&doi=10.1049%2fipr2.12850&partnerID=40&md5=5f7b272cc4e520c9c03818e814d29b0d
AB  - Human keypoints detection is different from general detection tasks and requires networks that can learn visual information and anatomical constraints. Since CNN is excellent in extracting texture features of images and transformer can learn the correlation among keypoints well, many CTPNets (CNN+transformer type human pose estimation networks) have emerged. However, these networks are unconcerned with the processing of the features extracted from the CNN and naturally expand only from the channel dimension, ignoring the spatial features in the visual information that are essential for complex detection tasks like pose estimation. So the channel spatial integrated transformer for human pose estimation, termed CSIT, is proposed. The visual information are summarized as texture and spatial information, and a parallel network is used to expand the feature maps in the channel and spatial dimensions to learn texture features and spatial features respectively. In addition, anatomically constrained information is learned by keypoint embeddings. At the end of the network, the 1D vector representation method with more advanced performance and more compatible with transformer's characteristics is used to predict keypoints. Experiments show that CSIT outperforms the mainstream CTPNets on the COCO test-dev dataset, and also show satisfactory results on the MPII dataset. © 2023 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Li2023CSIT
ER  -

TY  - JOUR
AU  - Lara-Benítez, P.
AU  - Carranza-García, M.
AU  - Luna-Romera, J.M.
AU  - Riquelme, J.C.
TI  - Short-term solar irradiance forecasting in streaming with deep learning
PY  - 2023
T2  - Neurocomputing
VL  - 546
C7  - 126312
DO  - 10.1016/j.neucom.2023.126312
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160548280&doi=10.1016%2fj.neucom.2023.126312&partnerID=40&md5=db16bb8622dfa12481f05f592a270166
AB  - Solar energy is one of the most common and promising sources of renewable energy. In photovoltaic (PV) systems, operators can benefit from future solar irradiance predictions for efficient load balancing and grid stability. Therefore, short-term solar irradiance forecasting plays a crucial role in the transition to renewable energy. Modern PV grids collect large volumes of data that provide valuable information for forecasting models. Although the nature of these data presents an ideal setting for online learning methodologies, research to date has mainly focused on offline approaches. Hence, this work proposes a novel data streaming method for real-time solar irradiance forecasting on days with variable weather conditions and cloud coverage. Our method operates under an asynchronous dual-pipeline framework using deep learning models. For the experimental study, two datasets from a Canadian PV solar plant have been simulated as streams at different data frequencies. The experiments involve an exhaustive parameter grid search to evaluate four state-of-the-art deep learning architectures: multilayer perceptron (MLP), long-short term memory network (LSTM), convolutional network (CNN), and Transformer network. The obtained results demonstrate the suitability of deep learning models for this problem. In particular, MLP and CNN achieved the best accuracy, with a high capacity to adapt to the evolving data stream. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; 
LB  - Lara-Benítez2023Short-term
ER  -

TY  - JOUR
AU  - Lentzen, M.
AU  - Linden, T.
AU  - Veeranki, S.
AU  - Madan, S.
AU  - Kramer, D.
AU  - Leodolter, W.
AU  - Frohlich, H.
TI  - A Transformer-Based Model Trained on Large Scale Claims Data for Prediction of Severe COVID-19 Disease Progression
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 9
SP  - 4548
EP  - 4558
DO  - 10.1109/JBHI.2023.3288768
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163417958&doi=10.1109%2fJBHI.2023.3288768&partnerID=40&md5=2f3041cab7ef8191184df7872d3940ca
AB  - In situations like the COVID-19 pandemic, healthcare systems are under enormous pressure as they can rapidly collapse under the burden of the crisis. Machine learning (ML) based risk models could lift the burden by identifying patients with a high risk of severe disease progression. Electronic Health Records (EHRs) provide crucial sources of information to develop these models because they rely on routinely collected healthcare data. However, EHR data is challenging for training ML models because it contains irregularly timestamped diagnosis, prescription, and procedure codes. For such data, transformer-based models are promising. We extended the previously published Med-BERT model by including age, sex, medications, quantitative clinical measures, and state information. After pre-training on approximately 988 million EHRs from 3.5 million patients, we developed models to predict Acute Respiratory Manifestations (ARM) risk using the medical history of 80,211 COVID-19 patients. Compared to Random Forests, XGBoost, and RETAIN, our transformer-based models more accurately forecast the risk of developing ARM after COVID-19 infection. We used Integrated Gradients and Bayesian networks to understand the link between the essential features of our model. Finally, we evaluated adapting our model to Austrian in-patient data. Our study highlights the promise of predictive transformer-based models for precision medicine.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Lentzen2023Transformer-Based
ER  -

TY  - JOUR
AU  - Ortiz-Perez, D.
AU  - Ruiz-Ponce, P.
AU  - Tomás, D.
AU  - Garcia-Rodriguez, J.
AU  - Vizcaya-Moreno, M.F.
AU  - Leo, M.
TI  - A Deep Learning-Based Multimodal Architecture to predict Signs of Dementia
PY  - 2023
T2  - Neurocomputing
VL  - 548
C7  - 126413
DO  - 10.1016/j.neucom.2023.126413
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161510642&doi=10.1016%2fj.neucom.2023.126413&partnerID=40&md5=fb66adaf3fa08d2aa8a53a494dcca06b
AB  - This paper proposes a multimodal deep learning architecture combining text and audio information to predict dementia, a disease which affects around 55 million people all over the world and makes them in some cases dependent people. The system was evaluated on the DementiaBank Pitt Corpus dataset, which includes audio recordings as well as their transcriptions for healthy people and people with dementia. Different models have been used and tested, including Convolutional Neural Networks (CNN) for audio classification, Transformers for text classification, and a combination of both in a multimodal ensemble. These models have been evaluated on a test set, obtaining the best results by using the text modality, achieving 90.36% accuracy on the task of detecting dementia. Additionally, an analysis of the corpus has been conducted for the sake of explainability, aiming to obtain more information about how the models generate their predictions and identify patterns in the data. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Ortiz-Perez2023Deep
ER  -

TY  - JOUR
AU  - Mao, C.
AU  - Xu, J.
AU  - Rasmussen, L.
AU  - Li, Y.
AU  - Adekkanattu, P.
AU  - Pacheco, J.
AU  - Bonakdarpour, B.
AU  - Vassar, R.
AU  - Shen, L.
AU  - Jiang, G.
AU  - Wang, F.
AU  - Pathak, J.
AU  - Luo, Y.
TI  - AD-BERT: Using pre-trained language model to predict the progression from mild cognitive impairment to Alzheimer's disease
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 144
C7  - 104442
DO  - 10.1016/j.jbi.2023.104442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164685367&doi=10.1016%2fj.jbi.2023.104442&partnerID=40&md5=f7e3bb37e1de487d14f398669f375b9e
AB  - Objective: We develop a deep learning framework based on the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model using unstructured clinical notes from electronic health records (EHRs) to predict the risk of disease progression from Mild Cognitive Impairment (MCI) to Alzheimer's Disease (AD). Methods: We identified 3657 patients diagnosed with MCI together with their progress notes from Northwestern Medicine Enterprise Data Warehouse (NMEDW) between 2000 and 2020. The progress notes no later than the first MCI diagnosis were used for the prediction. We first preprocessed the notes by deidentification, cleaning and splitting into sections, and then pre-trained a BERT model for AD (named AD-BERT) based on the publicly available Bio+Clinical BERT on the preprocessed notes. All sections of a patient were embedded into a vector representation by AD-BERT and then combined by global MaxPooling and a fully connected network to compute the probability of MCI-to-AD progression. For validation, we conducted a similar set of experiments on 2563 MCI patients identified at Weill Cornell Medicine (WCM) during the same timeframe. Results: Compared with the 7 baseline models, the AD-BERT model achieved the best performance on both datasets, with Area Under receiver operating characteristic Curve (AUC) of 0.849 and F1 score of 0.440 on NMEDW dataset, and AUC of 0.883 and F1 score of 0.680 on WCM dataset. Conclusion: The use of EHRs for AD-related research is promising, and AD-BERT shows superior predictive performance in modeling MCI-to-AD progression prediction. Our study demonstrates the utility of pre-trained language models and clinical notes in predicting MCI-to-AD progression, which could have important implications for improving early detection and intervention for AD. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Mao2023AD-BERT
ER  -

TY  - JOUR
AU  - Xu, R.
AU  - Wang, C.
AU  - Xu, S.
AU  - Meng, W.
AU  - Zhang, X.
TI  - Dual-stream Representation Fusion Learning for accurate medical image segmentation
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106402
DO  - 10.1016/j.engappai.2023.106402
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159406037&doi=10.1016%2fj.engappai.2023.106402&partnerID=40&md5=a7acf326efec0c1736d7b21dc7674722
AB  - Accurate segmenting regions of interest in various medical images are essential to clinical research and applications. Although deep learning-based methods have achieved good results, the fully automated segmentation results still need to be refined on the tininess, complexities, and irregularities of lesion shapes. To address this issue, we propose a Dual-stream Representation Fusion Learning (DRFL) paradigm for accurate clinical segmentation, including Dual-stream Fusion Module, Representation Fusion Transformer Module and Peakiness Fusion Attention Module. Specifically, Dual-stream Fusion Module can simultaneously generate binary masks and high-resolution images with segmentation stream and super-resolution stream that share a feature extractor, then both prediction outputs are merged as the input of Fusion Module to further improve the performance of the network for generating the final segmentation result; Representation Fusion Transformer Module is lightweight to fuse high-resolution representation and fine-grained structure representation; Peakiness Fusion Attention Module can capture more salient features while fusing more spatial information to improve the performance of the network. The effectiveness of our dual-stream representation fusion learning is validated on different medical image segmentation tasks, and extensive experiments show that our DRFL outperforms the state-of-the-art methods in segmentation quality of lung nodule segmentation, lung segmentation, cell contour segmentation, and prostate segmentation. Our code is available at https://github.com/Rongtao-Xu/RepresentationLearning/tree/main/DRFL-EAAI2023. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Xu2023Dual-stream
ER  -

TY  - JOUR
AU  - Kamoji, S.
AU  - Kalla, M.
TI  - Effective Flood prediction model based on Twitter Text and Image analysis using BMLP and SDAE-HHNN
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106365
DO  - 10.1016/j.engappai.2023.106365
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159043800&doi=10.1016%2fj.engappai.2023.106365&partnerID=40&md5=ed85621a67649e560f090dfaca780df1
AB  - In recent years, social media platforms such as Twitter have garnered a lot of interest as a new source of text data for quick flood awareness and effective prediction. Hence various types of research were made on flood prediction using Twitter data but it only focuses on classifying the text data as relevant or irrelevant, thereby loss of semantic information from longer phrases while extracting important information from Twitter text data and resulting in low accuracy of text classification. Hence, a novel BMLP and SDAE-HHNN has been proposed. This approach comprises BMLP and SDAE-HHNN techniques has been developed for effective flood prediction based on Twitter text data and image analysis. To classify the text data into two/six different classes, BERT is used to preprocess the text data from Twitter. To achieve high levels of precision, the Rule-Based Matching technique extracts specific place entities from the Named Entity Recognition. To predict the high probability location affected by flood from the place entity, bi-directional MLP (BMLP) is used which is made up of a finite number of sequential layers in its most basic form. Then images are extracted from this particular location and these images are processed to predict flood level but existing techniques cannot provide sufficient information to map the flood area and object detection due to real field data collection. Hence, a novel SDAE with HHNN has been developed in which SDAE removes noise from the specified extracted location and HHNN is used to classify the image into flood or non-flood. Then plot this sufficient predicted information related to flood level in the google map. The proposed model is implemented in the Python platform and the result obtained shows that the proposed has a maximum recall of 96%, maximum precision of 95%, accuracy of 97%, and an F1 score of 96%. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Kamoji2023Effective
ER  -

TY  - JOUR
AU  - Deng, Z.
AU  - Li, C.
AU  - Song, R.
AU  - Liu, X.
AU  - Qian, R.
AU  - Chen, X.
TI  - EEG-based seizure prediction via hybrid vision transformer and data uncertainty learning
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106401
DO  - 10.1016/j.engappai.2023.106401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159585147&doi=10.1016%2fj.engappai.2023.106401&partnerID=40&md5=720c75a2d22997ffe4d4f00e394270c3
AB  - Feature embeddings derived from continuous mapping using the deep neural network are critical for accurate classification in seizure prediction tasks. However, the embeddings of individual electroencephalogram (EEG) samples learned through modern decoding algorithms may contain ambiguous and noisy representations, owing to the susceptibility of weak EEG signals to interference from other signals unrelated to EEG activity. To address this issue, we consider data uncertainty learning (DUL), which models each representation of the EEG sample as a Gaussian or Laplacian distribution to mitigate potential noise interference and enhance model robustness. Moreover, data uncertainty learning for transformer architectures is seldom explored due to the limitation of multi-headed self-attention mechanisms in processing local features and the vanishing of potential top-level gradients. In this study, we introduce a novel hybrid visual transformer (HViT) architecture, which enhances the processing capability of localized features in the transformer through the convolutional neural network (CNN). Concretely, we learn the mean of the distribution using the HViT, and an additional branch is designed to capture the variance of the Gaussian distribution or the scale of the Laplacian distribution during training. We also propose a learnable manner to learn constraint coefficients in the loss functions for different patients, resulting in better optimization across patients. In addition, we introduce a simple uncertainty quantification method for each alarm of the k-of-n continuous prediction strategy by utilizing the continuity of the EEG signals. Empirical evaluations on two publicly available epilepsy datasets demonstrate the superiority of our DUL method and the effectiveness of the proposed HViT architecture. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; 
LB  - Deng2023EEG-based
ER  -

TY  - JOUR
AU  - Jiang, J.
AU  - Li, G.
AU  - Jiang, Y.
AU  - Zhang, L.
AU  - Deng, X.
TI  - TransCFD: A transformer-based decoder for flow field prediction
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106340
DO  - 10.1016/j.engappai.2023.106340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159852435&doi=10.1016%2fj.engappai.2023.106340&partnerID=40&md5=a09359fc1d68506be7a51958b31152e6
AB  - The computational fluid dynamics (CFD) method is computationally intensive and costly, and evaluating aerodynamic performance through CFD is time-consuming and labor-intensive. For the design and optimization of aerodynamic shapes, it is essential to obtain aerodynamic performance efficiently and accurately. This paper proposed TransCFD, a Transformer-based decoding architecture for flow field prediction. The aerodynamic shape is parameterized and used as input to the decoder, which learns an end-to-end mapping between the shape and the flow fields. Compared with the CFD method, the TransCFD was evaluated to have a mean absolute error (MAE) of less than 1%, increase the speed by three orders of magnitude, and perform very well in generalization capability. The method simplifies the input requirements compared to most existing methods. Although the object of this work is a two-dimensional airfoil, the setup of this scheme is very general. TransCFD is promising for rapid aerodynamic performance evaluation, with potential applications in accelerating the aerodynamic design. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; 
LB  - Jiang2023TransCFD
ER  -

TY  - JOUR
AU  - Cai, X.
AU  - Lu, R.
AU  - Cheng, P.
AU  - Yao, J.
AU  - Hu, Y.
TI  - An Extended Labanotation Generation Method Based on 3D Human Pose Estimation for Intangible Cultural Heritage Dance Videos
PY  - 2023
T2  - International Journal of Pattern Recognition and Artificial Intelligence
VL  - 37
IS  - 10
C7  - 2355012
DO  - 10.1142/S0218001423550121
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173215982&doi=10.1142%2fS0218001423550121&partnerID=40&md5=4a64936cc6325fb87a4f1332ff38ec81
AB  - To address the issues of low accuracy in existing 3D human pose estimation (HPE) methods and the limited level of details in Labanotation, we propose an extended Labanotation generation method for intangible cultural heritage dance videos based on 3D HPE. First, a 2D human pose sequence of the performer is inputted along with spatial location embeddings, where multiple spatial transformer modules are employed to extract spatial features of human joints and generate cross-joint multiple hypotheses. Afterward, temporal features are extracted by a self-attentive module and the correlation between different hypotheses is learned using bilinear pooling. Finally, the 3D joint coordinates of the performer are predicted, which are matched with the corresponding extended Labanotation symbols using the Laban template matching method to generate extended Labanotation. Experimental results show that, compared with VideoPose and CrossFormer algorithms, the Mean Per Joint Position Error (MPJPE) of the proposed method is reduced by 3.7mm and 0.6mm, respectively on Human3.6M dataset, and the generated extended Labanotation can better describe the movement details compared with the basic Labanotation.  © 2023 World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Cai2023Extended
ER  -

TY  - JOUR
AU  - Yan, W.
AU  - Ding, Q.
AU  - Chen, J.
AU  - Yan, K.
AU  - Tang, R.S.-Y.
AU  - Cheng, S.S.
TI  - Learning-based needle tip tracking in 2D ultrasound by fusing visual tracking and motion prediction
PY  - 2023
T2  - Medical Image Analysis
VL  - 88
C7  - 102847
DO  - 10.1016/j.media.2023.102847
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161711036&doi=10.1016%2fj.media.2023.102847&partnerID=40&md5=ade975dd105358bd10f1a83b9deeeb00
AB  - Visual trackers are the most commonly adopted approach for needle tip tracking in ultrasound (US)-based procedures. However, they often perform unsatisfactorily in biological tissues due to the significant background noise and anatomical occlusion. This paper presents a learning-based needle tip tracking system, which consists of not only a visual tracking module, but also a motion prediction module. In the visual tracking module, two sets of masks are designed to improve the tracker's discriminability, and a template update submodule is used to keep up to date with the needle tip's current appearance. In the motion prediction module, a Transformer network-based prediction architecture estimates the target's current position according to its historical position data to tackle the problem of target's temporary disappearance. A data fusion module then integrates the results from the visual tracking and motion prediction modules to provide robust and accurate tracking results. Our proposed tracking system showed distinct improvement against other state-of-the-art trackers during the motorized needle insertion experiments in both gelatin phantom and biological tissue environments (e.g. 78% against <60% in terms of the tracking success rate in the most challenging scenario of “In-plane-static” during the tissue experiments). Its robustness was also verified in manual needle insertion experiments under varying needle velocities and directions, and occasional temporary needle tip disappearance, with its tracking success rate being >18% higher than the second best performing tracking system. The proposed tracking system, with its computational efficiency, tracking robustness, and tracking accuracy, will lead to safer targeting during existing clinical practice of US-guided needle operations and potentially be integrated in a tissue biopsy robotic system. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Yan2023Learning-based
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Kong, Q.
AU  - Yong, L.
AU  - Narducci, F.
AU  - Wan, S.
TI  - CDText: Scene text detector based on context-aware deformable transformer
PY  - 2023
T2  - Pattern Recognition Letters
VL  - 172
SP  - 8
EP  - 14
DO  - 10.1016/j.patrec.2023.05.025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163415759&doi=10.1016%2fj.patrec.2023.05.025&partnerID=40&md5=ba731ad74c436e1ed95cf8c957d1aca1
AB  - Scene text detection task aims to precisely locate text regions in natural scenes. However, the existing methods still face challenges in detecting arbitrary-shaped text, due to their limited feature representation capability. To alleviate this problem, we propose a scene text detector, i.e., CDText, based on structure of context-aware deformable transformer. Specifically, CDText firstly adopts different convolution kernel designs for feature extraction, which designs receptive fields with different size for multi-scale feature perception and fusion. Meanwhile, multi-head self-attention mechanism is used to strengthen the reasoning ability of CDText in a global sense, thus enhancing feature maps with abundant context information by extracting implicit relationship between multi-scale text features. Moreover, CDText designs a segmentation head to segment text instances of arbitrary shapes from rectangular detection boxes. Experiments show that CDText is superior to comparative methods in detection accuracy, achieving F-scores of 92.7, 81.9, and 82.9 on ICDAR2013, Total Text, and CTW-1500 datasets, respectively. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Wu2023CDText
ER  -

TY  - JOUR
AU  - Wen, L.
AU  - Xiao, J.
AU  - Tan, S.
AU  - Wu, X.
AU  - Zhou, J.
AU  - Peng, X.
AU  - Wang, Y.
TI  - A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction
PY  - 2023
T2  - International Journal of Neural Systems
VL  - 33
IS  - 8
C7  - 2350043
DO  - 10.1142/S0129065723500430
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165185871&doi=10.1142%2fS0129065723500430&partnerID=40&md5=ecddea0e48118b5b52cfe88861641390
AB  - Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy the clinical requirements, radiologists have to iteratively adjust the radiotherapy plan based on experience, causing it extremely subjective and time-consuming to obtain a clinically acceptable plan. To this end, we introduce a transformer-embedded multi-task dose prediction (TransMTDP) network to automatically predict the dose distribution in radiotherapy. Specifically, to achieve more stable and accurate dose predictions, three highly correlated tasks are included in our TransMTDP network, i.e. a main dose prediction task to provide each pixel with a fine-grained dose value, an auxiliary isodose lines prediction task to produce coarse-grained dose ranges, and an auxiliary gradient prediction task to learn subtle gradient information such as radiation patterns and edges in the dose maps. The three correlated tasks are integrated through a shared encoder, following the multi-task learning strategy. To strengthen the connection of the output layers for different tasks, we further use two additional constraints, i.e. isodose consistency loss and gradient consistency loss, to reinforce the match between the dose distribution features generated by the auxiliary tasks and the main task. Additionally, considering many organs in the human body are symmetrical and the dose maps present abundant global features, we embed the transformer into our framework to capture the long-range dependencies of the dose maps. Evaluated on an in-house rectum cancer dataset and a public head and neck cancer dataset, our method gains superior performance compared with the state-of-the-art ones. Code is available at https://github.com/luuuwen/TransMTDP. © 2023 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Wen2023Transformer-Embedded
ER  -

TY  - JOUR
AU  - Oh, Y.
AU  - Bae, G.E.
AU  - Kim, K.-H.
AU  - Yeo, M.-K.
AU  - Ye, J.C.
TI  - Multi-Scale Hybrid Vision Transformer for Learning Gastric Histology: AI-Based Decision Support System for Gastric Cancer Treatment
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 8
SP  - 4143
EP  - 4153
DO  - 10.1109/JBHI.2023.3276778
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160247198&doi=10.1109%2fJBHI.2023.3276778&partnerID=40&md5=22b47dce53cdfef3b92083a5d48c4163
AB  - Gastric endoscopic screening is an effective way to decide appropriate gastric cancer treatment at an early stage, reducing gastric cancer-associated mortality rate. Although artificial intelligence has brought a great promise to assist pathologist to screen digitalized endoscopic biopsies, existing artificial intelligence systems are limited to be utilized in planning gastric cancer treatment. We propose a practical artificial intelligence-based decision support system that enables five subclassifications of gastric cancer pathology, which can be directly matched to general gastric cancer treatment guidance. The proposed framework is designed to efficiently differentiate multi-classes of gastric cancer through multiscale self-attention mechanism using 2-stage hybrid vision transformer networks, by mimicking the way how human pathologists understand histology. The proposed system demonstrates its reliable diagnostic performance by achieving class-average sensitivity of above 0.85 for multicentric cohort tests. Moreover, the proposed system demonstrates its great generalization capability on gastrointestinal track organ cancer by achieving the best class-average sensitivity among contemporary networks. Furthermore, in the observational study, artificial intelligence-assisted pathologists show significantly improved diagnostic sensitivity within saved screening time compared to human pathologists. Our results demonstrate that the proposed artificial intelligence system has a great potential for providing presumptive pathologic opinion and supporting decision of appropriate gastric cancer treatment in practical clinical settings.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Oh2023Multi-Scale
ER  -

TY  - JOUR
AU  - Tian, X.
AU  - Jin, Y.
AU  - Tang, X.
TI  - TSRN: two-stage refinement network for temporal action segmentation
PY  - 2023
T2  - Pattern Analysis and Applications
VL  - 26
IS  - 3
SP  - 1375
EP  - 1393
DO  - 10.1007/s10044-023-01166-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159272953&doi=10.1007%2fs10044-023-01166-8&partnerID=40&md5=53c7ba42c6c2ba6d23faff4b1a4ecb69
AB  - In high-level video semantic understanding, continuous action segmentation is a challenging task aimed at segmenting an untrimmed video and labeling each segment with predefined labels over time. However, the accuracy of segment predictions is limited by confusing information in video sequences, such as ambiguous frames during action boundaries or over-segmentation errors due to the lack of semantic relations. In this work, we present a two-stage refinement network (TSRN) to improve temporal action segmentation. We first capture global relations over an entire video sequence using a multi-head self-attention mechanism in the novel transformer temporal convolutional network and model temporal relations in each action segment. Then, we introduce a dual-attention spatial pyramid pooling network to fuse features from macroscale and microscale perspectives, providing more accurate classification results from the initial prediction. In addition, a joint loss function mitigates over-segmentation. Compared with state-of-the-art methods, the proposed TSRN substantially improves temporal action segmentation on three challenging datasets (i.e., 50Salads, Georgia Tech Egocentric Activities, and Breakfast). © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Tian2023TSRN
ER  -

TY  - JOUR
AU  - Yan, F.
AU  - Yang, C.
AU  - Zhang, X.
TI  - Stacked Spatial-Temporal Autoencoder for Quality Prediction in Industrial Processes
PY  - 2023
T2  - IEEE Transactions on Industrial Informatics
VL  - 19
IS  - 8
SP  - 8625
EP  - 8634
DO  - 10.1109/TII.2022.3220857
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141643207&doi=10.1109%2fTII.2022.3220857&partnerID=40&md5=1f6dc67a4a5ae129ade2b1ba1be48bd1
AB  - Nowadays, data-driven soft sensors have become mainstream for the key performance indicators prediction, which guarantees the safety and stability of the industrial process. The typical autoencoder (AE) has been widely used to extract potential features through unsupervised pretraining and supervised fine-tuning. However, most existing studies fail to consider both the time-varying features of the process and the differences in the contributions of the hidden features to the target variable. Therefore, in this article, a stacked spatial-temporal autoencoder (S2TAE) is proposed to enhance the representation learning capability for soft sensor modeling by taking the spatial-temporal correlations into consideration. Specifically, to effectively model the temporal dependence from nearby times, a temporal autoencoder is proposed, in which a memory module is devised and integrated to learn valuable historical information. Moreover, a 'feature recalibration' block is developed and embedded into the spatial-temporal autoencoder (STAE) to selectively capture more informative features and suppress the less useful ones in a supervised way. Then, multiple STAEs are stacked to construct the S2TAE network to extract more robust high-level features. Finally, the experimental results on two real-world datasets of a sorbent decontamination system (SDS) desulfurization process and a high-low transformer demonstrate that the S2TAE-based soft sensor is effective and feasible. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Yan2023Stacked
ER  -

TY  - JOUR
AU  - Ding, Y.
AU  - Zhang, Z.
AU  - Zhao, X.
AU  - Hong, D.
AU  - Cai, W.
AU  - Yang, N.
AU  - Wang, B.
TI  - Multi-scale receptive fields: Graph attention neural network for hyperspectral image classification
PY  - 2023
T2  - Expert Systems with Applications
VL  - 223
C7  - 119858
DO  - 10.1016/j.eswa.2023.119858
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151402205&doi=10.1016%2fj.eswa.2023.119858&partnerID=40&md5=b0e903a2b174fedffa9c66e9d6b0b248
AB  - Hyperspectral image (HSI) classification has attracted wide attention in many fields. Applying Graph Neural Network (GNN) to HSI classification is one of the research frontiers, which has improved the HSI classification accuracy greatly. However, GNN-based methods have not been widely applied due to their time-consuming, inefficient information description as well as poor anti-noise robustness. To overcome the deficiencies, a novel multi-scale receptive fields graph attention neural network (MRGAT) is proposed for HSI classification in this paper. In this network, a superpixel segment method is adopted to abstract the original HSI local spatial features. A two-layer one-dimensional convolution neural network (1D CNN) spectral transformer mechanism, is designed to extract the spectral features of superpixels, with which the spectral features can be acquired automatically. Furthermore, graph edges are introduced into Graph Attention Network (GAT) to acquire the local semantic feature of the graph. Moreover, inspired by the transformer network, we design a novel multi-scale receptive field GAT to extract the local-global adjacent node-features and edges-features. Finally, a graph attention network and a softMax function are utilized for multi-receptive feature fusion and pixel-label predicting. On Pavia University, Salinas, and Houston 2013 datasets, the overall accuracies (OAs) of our MRGAT are 71.76%, 82.61%, and 63.82%, respectively. Moreover, the performances with limited labeled samples indicates that the MRGAT contains superior adaptability. Compared with the competitive classifiers, MRGAT achieves high classification efficiency verified by training time comparison experiment. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 82
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ding2023Multi-scale
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Li, H.
AU  - Kong, W.
TI  - Multi-level learning counting via pyramid vision transformer and CNN
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106184
DO  - 10.1016/j.engappai.2023.106184
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150882171&doi=10.1016%2fj.engappai.2023.106184&partnerID=40&md5=6cf041fb16a83ecbdf418c5502972421
AB  - Severe scale variation has become a challenging issue for hindering the improvement of accuracy in crowd counting task. To tackle the problem, we propose a Pyramid Transformer CNN Network (PTCNet), an effective combination of the transformer and the CNN, which possesses both the global receptive fields and the locality to deal with the severe scale variation problems and boost the prediction accuracy. Firstly, we utilize the pyramid vision transformer to extract multi-level global context information of the crowd, aiming at different head scales. And then, the multi-level information is fully fused in the multi-level feature aggregation module where detailed crowd characteristics from all feature spaces are preserved to be further processed. Finally, we design a multi-branch regression head to enrich the crowd features for strong representations and regress the density maps. Extensive experiments on challenging datasets with complex scenarios and multiple scales demonstrate the effectiveness of the our method. The proposed method achieves competitive results comparing with the state-of-the-art approaches and achieves state-of-the-art results(MAE:51.7, RMSE:79.6) on ShanghaiTech Part_A dataset. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Liu2023Multi-level
ER  -

TY  - JOUR
AU  - Ouyang, W.
AU  - Hu, Y.
AU  - Ou, Y.
AU  - Chen, Z.
TI  - Multiple visual relationship forecasting and arrangement in videos
PY  - 2023
T2  - Neurocomputing
VL  - 541
C7  - 126274
DO  - 10.1016/j.neucom.2023.126274
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154589390&doi=10.1016%2fj.neucom.2023.126274&partnerID=40&md5=2ce29f3d6381f0d0721e8f81b77ed5b5
AB  - Visual relationships in videos are often causally connected and time-dependent. The complicated temporal dependency between visual relationships is overlooked in visual relationship modeling. To explore the realistic interactions and model the causality between visual relationships in videos, we propose a new task named Multiple Visual Relation Forecasting and Arrangement (MVRFA). Given a series of frames focusing on a <subject-object> pair, MVRFA aims to forecast the future visual relationships and their arrangement which reflects their temporal interrelationship. To evaluate the MVRFA task, we build a video dataset consisting of 1195 videos with 2666 visual relationships and corresponding arrangements annotated by 5 temporal relational classes. In addition, we present a Multi-task Relationship-centric Transformer model as a baseline, which applies graph convolution to aggregate subject-relationship-object information and uses the relationship multi-query transformer to predict the visual relationships with their arrangement. Experiments on the proposed dataset demonstrate that the proposed baseline achieves superior performance and can better handle the MVRFA task than related models. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Ouyang2023Multiple
ER  -

TY  - JOUR
AU  - Zhang, B.
AU  - Hu, Z.
AU  - Wu, P.
AU  - Huang, H.
AU  - Xiang, J.
TI  - EPT: A data-driven transformer model for earthquake prediction
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106176
DO  - 10.1016/j.engappai.2023.106176
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151778281&doi=10.1016%2fj.engappai.2023.106176&partnerID=40&md5=4a8d9c347f348a1c80fb1ff5921a7507
AB  - The leading causes of earthquakes are crustal movements, plate movements, and collisions. In recent years, many researchers in earthquake prediction have been predicting earthquakes from historical seismic data in local areas. This approach ignores the underlying internal patterns of crustal motion, plate movement, and collisions. This paper proposes a purely data-driven deep learning model called EPT. The model uses gated feature extraction blocks (GFEB) to mine potential crustal motion and plate movement patterns from global historical seismic catalog data. It uses them to aid mainshock prediction in each local, provincial region. Experiments show that this approach improves model prediction accuracy by up to 50 percent. We also use multi-headed self-attention for the first time to capture long-term dependencies within regional time series, highlighting links between focal features and compensating for the difficulty of focusing on longer-term information in long-term time series with long short-term memory networks (LSTM). In addition, we also use the gradient harmonization mechanism classification (GHMC) loss function for the first time in earthquake prediction, effectively addressing the problem of uneven data distribution across different earthquake magnitude ranges. Finally, we validated the effectiveness of the EPT model in five provincial datasets in mainland China, and the experimental results all achieved an accuracy of over 90 percent. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Zhang2023EPT
ER  -

TY  - JOUR
AU  - Kužina, V.
AU  - Petric, A.-M.
AU  - Barišić, M.
AU  - Jović, A.
TI  - CASSED: Context-based Approach for Structured Sensitive Data Detection
PY  - 2023
T2  - Expert Systems with Applications
VL  - 223
C7  - 119924
DO  - 10.1016/j.eswa.2023.119924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151427333&doi=10.1016%2fj.eswa.2023.119924&partnerID=40&md5=4db704585f65a437f635578a8d8d6da1
AB  - The need for sensitive data detection and identification has increased in recent years. Sensitive data detection and identification are necessary steps for privacy protection. The focus in this field has been on unstructured data detection using natural language processing (NLP) approaches, while there has been little progress in the field of structured data. Most of the structured data approaches consider independent feature representations of cells, without taking potentially relevant context into account. In this work, we introduce a novel context-based approach named CASSED, which stands for Context-based Approach for Structured SEnsitive Data Detection. CASSED addresses the problem of sensitive data detection in structured data through the lens of NLP, using the transformer-based BERT method. Our approach aims to actively capture relations both within and between cells in the same column as the assumption is that the data present in the same column in a table are mostly very similar. CASSED works as a classifier for columns in database tables with the task of predicting a label or multiple labels for different types of sensitive data that a column may represent. Since there is no officially recognized dataset for the task, we compared CASSED on datasets used for similar tasks from related work. Furthermore, we created our own dataset focused on sensitive data to evaluate CASSED. Our method outperformed methods from related work both on their datasets and achieved significantly better results on our own dataset compared to our baseline model as well as models from related work. Our research suggests that treating structured data as context-rich is a viable strategy for sensitive data detection and identification. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Kužina2023CASSED
ER  -

TY  - JOUR
AU  - Huang, B.
AU  - Ruan, K.
AU  - Yu, W.
AU  - Xiao, J.
AU  - Xie, R.
AU  - Huang, J.
TI  - ODformer: Spatial–temporal transformers for long sequence Origin–Destination matrix forecasting against cross application scenario
PY  - 2023
T2  - Expert Systems with Applications
VL  - 222
C7  - 119835
DO  - 10.1016/j.eswa.2023.119835
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150066138&doi=10.1016%2fj.eswa.2023.119835&partnerID=40&md5=b0e9cdd933cfce0df6a90289a89654de
AB  - Origin–Destination (OD) matrices record directional flow data between pairs of OD regions. The intricate spatiotemporal dependency in the matrices makes the OD matrix forecasting (ODMF) problem not only intractable but also non-trivial. However, most of the related methods are designed for very short sequence time series forecasting in specific application scenarios, which cannot meet the requirements of the variation in scenarios and forecasting length of practical applications. To address these issues, we propose a Transformer-like model named ODformer, with two salient characteristics: (i) the novel OD Attention mechanism, which captures special spatial dependencies between OD pairs of the same origin (destination), greatly improves the ability of the model to predict cross application scenarios after combining with 2D-GCN that captures spatial dependencies between OD regions. (ii) a PeriodSparse Self-attention that effectively forecasts long sequence OD matrix series while adapting to the periodic differences in different scenarios. Generous experiments in three application backgrounds (i.e., transportation traffic, IP backbone network traffic, crowd flow) show that our method outperforms the state-of-the-art methods. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Huang2023ODformer
ER  -

TY  - JOUR
AU  - Ahmed, U.
AU  - Lin, J.C.-W.
AU  - Srivastava, G.
TI  - Semisupervised Federated Learning for Temporal News Hyperpatism Detection
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 4
SP  - 1758
EP  - 1769
DO  - 10.1109/TCSS.2023.3247602
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149833745&doi=10.1109%2fTCSS.2023.3247602&partnerID=40&md5=ca36ac39712a2a44bb37e48f558dcb72
AB  - The proliferation of false and erroneous information on the Internet has posed a challenge to the accurate exchange of information. To address this issue, a semisupervised system based on self-embedding has been proposed. This system verifies information before it is shared, allowing only reliable and accurate content to be disseminated and protecting individuals from the negative effects of false information. In this article, we present a news article retrieval model based on active learning (AL) in a semisupervised learning setting. This model has the advantages of limited communication requirements, strong scalability, increased data privacy, and a time-dependent retrieval model. We use lexicon expansion, content segmentation, and temporal events to generate a bidirectional encoder representations from transformer (BERT) attention embedding query for the temporal understanding of sequential news articles. To generate pseudo-labels, we combine the partially trained model with the original tagged data. An attention network is used to update pseudo-labels of data samples when the label of a sample is correctly or incorrectly predicted. Finally, the modified classifiers are combined to make predictions. Experimental results indicate that the proposed model has 81% performance, showing that co-training and semisupervised learning can improve the performance of temporal expansion and profiling algorithms.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Ahmed2023Semisupervised
ER  -

TY  - JOUR
AU  - Xu, Y.-H.
AU  - Wang, Z.-H.
AU  - Wang, Z.-R.
AU  - Fan, R.
AU  - Wang, X.
TI  - A Recommendation Algorithm Based on a Self-supervised Learning Pretrain Transformer
PY  - 2023
T2  - Neural Processing Letters
VL  - 55
IS  - 4
SP  - 4481
EP  - 4497
DO  - 10.1007/s11063-022-11053-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140840583&doi=10.1007%2fs11063-022-11053-8&partnerID=40&md5=95e84745f8ff378df1cc933a0d9447c3
AB  - Click-through rate (CTR) prediction is crucial research direction for the recommendation, with the goal of predicting the probability that users will click on candidate items. There are studies indicates that users’ next click behavior is influenced by their last few clicks; therefore, effective modeling of user behavior sequences to extract user interest representations is an important research topic in CTR prediction. Various networks such as RNN, and transformer, have been applied to implicitly extract user interest in the sequence. However, these studies focus on designing complex network structures for better user behavior modeling, while ignoring the fact that the training methods used in current CTR prediction models may limit the model performance. Specifically, owing to the single training objective of the CTR prediction model, the sequence interest extractor component in the model will not be fully trained due to overemphasis on the final prediction effect during the training process. To solve this issue, this paper proposes a recommendation model based on self-supervised learning to pretrain the transformer (SSPT4Rec), which divides the training into two phases: pretraining and fine-tuning. The transformer is trained by a four-classification pretext task in the pretraining phase, and the weights obtained from the pretraining are used to initialize the transformer in the fine-tuning phase and to fine-tune it in the recommendation task. Extensive experiments on four publicly available datasets reveal that the SSPT4Rec method improves the feature extraction capability of transformer as an interest extractor and outperforms the existing model. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Xu2023Recommendation
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Deng, B.
AU  - Zou, C.
AU  - Zeng, B.
AU  - Zhang, W.
AU  - Tan, J.
TI  - Multi-lane detection by combining line anchor and feature shift for urban traffic management
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106238
DO  - 10.1016/j.engappai.2023.106238
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152123251&doi=10.1016%2fj.engappai.2023.106238&partnerID=40&md5=b2f9ef74500fd7b198cce262b5ebf649
AB  - Lane detection is a fundamental task in urban traffic management. Like lane detection for automatic driving, lane detection for traffic management will be faced with common challenges including fog, night, shadow, no line and etc. Meanwhile, it will be faced with new and unique challenges including variable number of lanes, blocked lanes due to oversize vehicles and color interference. In this paper, we propose a multi-lane detection method by combining the line anchor and feature shift (MLD-LAFS) to cope with these challenges. The proposed method features a two-branch neural network structure based on the line anchor. The first branch is the feature shift branch incorporating spatial attention, which is designed to enhance the local features of lanes. The second branch is the global information branch incorporating channel attention and cross attention, which is designed to establish the long-distance connection of lane features. The channel attention can obtain the global channel information. The uncoupled feature shift cross attention can obtain the global spatial information. The feature map containing the global information can be obtained by fusing the feature maps of the first and second branches. The line anchor is used as the supervision information to generate the predicted lane and realize multi-lane detection. The feature shift is used to solve the problems of lane line being blocked and color interference. We perform the performance evaluation on three datasets, including CULane, TuSimple and a newly constructed dataset MonitorLane. Experimental results show that the proposed MLD-LAFS achieves remarkable results on the CULane and the TuSimple dataset. Moreover, the proposed MLD-LAFS achieves the highest grading in F1-score on the MonitorLane dataset, compared to existing solutions, including LaneATT, PolyLaneNet, Lane Shape Prediction with Transformers (LSTR) and etc. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Liu2023Multi-lane
ER  -

TY  - JOUR
AU  - Liu, F.
AU  - Hua, Z.
AU  - Li, J.
AU  - Fan, L.
TI  - MFBGR: Multi-scale feature boundary graph reasoning network for polyp segmentation
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 123
C7  - 106213
DO  - 10.1016/j.engappai.2023.106213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151232514&doi=10.1016%2fj.engappai.2023.106213&partnerID=40&md5=0758379ce29682655fc028890a732b62
AB  - At present, adding Transformer to CNN has promoted the rapid development of colorectal polyp image processing. However, from the perspective of multi-scale feature interaction and boundary coherence, there are mainly some limitations: (1) ignore the local and global correlation within the scale feature, which may cause the missed detection of tiny polyps, (2) lack of multi-scale features to explore the target region, which hinders the learning of multi-variant polyps, and (3) the semantic connection between the target area and the boundary is ignored, cause incoherent segmentation boundaries. In this regard, we design a multi-scale feature boundary graph inference network for polyp segmentation, namely MFBGR. First, the Transformer block captures local–global cues inside the multi-scale information learned by the CNN branches. Second, for the multi-scale global information generated by the Transformer block, we design a cross-scale feature fusion module (CSFM). CSFM performs scale-variation interaction and cascaded fusion to capture the correlation between features across scales and solve the scale-variation problem of segmented objects. Finally, the traditional boundary refinement or enhancement idea is generalized to the graph convolutional reasoning layer (BGRM). BGRM receives CNN's low-level feature information and CSFM's fusion features, or intermediate prediction results, and propagates cross-domain feature information between graph vertices, explores information between target regions and boundary regions, and achieves more accurate boundary segmentation. On the CVC-300, CVC-ClinicDB, CVC-ColonDB, Kvasir-SEG, ETIS datasets, MFBGR and mainstream polyp segmentation networks were compared and tested. MFBGR achieved good results, and Dice, IOU, BAcc, and Haudo were the best. The values reached 94.16%, 89.35% and 97.42%, 3.7442, and the segmentation accuracy of colorectal polyp images has been improved to a certain extent. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Liu2023MFBGR
ER  -

TY  - JOUR
AU  - Niu, K.
AU  - Wu, Y.
AU  - Li, Y.
AU  - Li, M.
TI  - Retrieve and rerank for automated ICD coding via Contrastive Learning
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 143
C7  - 104396
DO  - 10.1016/j.jbi.2023.104396
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161331329&doi=10.1016%2fj.jbi.2023.104396&partnerID=40&md5=ea8a05d03244d177e7e77a0bdc86528f
AB  - Automated ICD coding is a multi-label prediction task aiming at assigning patient diagnoses with the most relevant subsets of disease codes. In the deep learning regime, recent works have suffered from large label set and heavy imbalance distribution. To mitigate the negative effect in such scenarios, we propose a retrieve and rerank framework that introduces the Contrastive Learning (CL) for label retrieval, allowing the model to make more accurate prediction from a simplified label space. Given the appealing discriminative power of CL, we adopt it as the training strategy to replace the standard cross-entropy objective and retrieve a small subset by taking the distance between clinical notes and ICD codes into account. After properly training, the retriever could implicitly capture the code co-occurrence, which makes up for the deficiency of cross-entropy assigning each label independently of the others. Further, we evolve a powerful model via a Transformer variant for refining and reranking the candidate set, which can extract semantically meaningful features from long clinical sequences. Applying our method on well-known models, experiments show that our framework provides more accurate results guaranteed by preselecting a small subset of candidates before fine-level reranking. Relying on the framework, our proposed model achieves 0.590 and 0.990 in terms of Micro-F1 and Micro-AUC on benchmark MIMIC-III. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Niu2023Retrieve
ER  -

TY  - JOUR
AU  - Ta, N.
AU  - Chen, H.
AU  - Lyu, Y.
AU  - Wang, X.
AU  - Shi, Z.
AU  - Liu, Z.
TI  - A complementary and contrastive network for stimulus segmentation and generalization
PY  - 2023
T2  - Image and Vision Computing
VL  - 135
C7  - 104694
DO  - 10.1016/j.imavis.2023.104694
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160511531&doi=10.1016%2fj.imavis.2023.104694&partnerID=40&md5=a4eeb189fcafd027ac80e9c4ce5207b5
AB  - Existing convolutional neural networks (CNNs) have achieved remarkable performance in medical image segmentation tasks. However, they still fail to generalize well to unseen datasets due to the limited size and diversity of training data as well as distribution shifts. Meanwhile, CNN-based methods have inherent limitations in capturing global contexts and suffer semantic dilution issues in the decoder stage, which leads to suboptimal predictions especially under low inter-class discrepancy and complex backgrounds. In this paper, we propose a novel framework named CCNet that learns complementary and contrastive features for accurate segmentation. Firstly, a novel complementary feature extraction module is formulated to learn global–local features by coordinating Transformer and CNN-style parallel branches. Secondly, a global context refinement module is constructed to adaptively generate a set of layer-specific global maps, so as to remedy semantic dilution. Thirdly, a mutual attentive module is designed to alleviate background confusion, in which contrastive cues are mutually captured from the foreground and background view by cascaded dual attention blocks. Moreover, we implement synthetic data augmentation to deal with training data scarcity and distribution shifts, thereby improving the out-of-distribution generalization of our model. Extensive experiments demonstrate that our CCNet achieves outstanding performance in polyp, skin lesion, and nuclei segmentation tasks, outperforming the state-of-the-arts. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Ta2023complementary
ER  -

TY  - JOUR
AU  - Wan, H.
AU  - Zhong, Z.
AU  - Li, T.
AU  - Zhang, H.
AU  - Sun, J.
TI  - Contextual transformer sequence-based recognition network for medical examination reports
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 14
SP  - 17363
EP  - 17380
DO  - 10.1007/s10489-022-04420-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145201667&doi=10.1007%2fs10489-022-04420-4&partnerID=40&md5=e4a71d7d442e1c738ad470449b0bcb7c
AB  - The automatic recognition of the medical examination report table (MERT) is receiving increasing attention in recent years as it is an essential step for intelligent healthcare and medical treatment. However, there are still some challenges in the table prediction when it is applied practically. In this paper, a recognition network (CoT_SRN) for medical examination reports is proposed to improve the recognition accuracy of MERT structure and reconstruct the image into a spreadsheet. The network is based on contextual transformer sequence and consists of CoT encoder and SRN decoder. In the encoder, the CNN backbone is constructed to extract the MERT image structure features based on the Contextual Transformer (CoT) proposed in this paper. In the decoder, an attention head with gated recurrent unit (GRU) was used for feature sequence recognition to obtain the cell location and table structure represented by a structured language. In addition, MERT structure labels are defined as character-level HTML formats, which are added in the training of the table structure recognition. The proposed method can achieve competitive tree-edit-distance-based similarity (TEDS) scores on the English datasets, such as PubTabNet and SciTSR, and Chinese datasets, such as the Chinese medical document dataset (CMDD). It demonstrates that the Cot_SRN is helpful to preserve the good performance across multi-language MERT structure recognition. Additionally, the performance of the proposed method is verified on the practical examples with folds and small angle deflection. The experimental results show that the proposed method is promising in practical application. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wan2023Contextual
ER  -

TY  - JOUR
AU  - Viriyavisuthisakul, S.
AU  - Sanguansat, P.
AU  - Racharak, T.
AU  - Nguyen, M.L.
AU  - Kaothanthong, N.
AU  - Haruechaiyasak, C.
AU  - Yamasaki, T.
TI  - Parametric loss-based super-resolution for scene text recognition
PY  - 2023
T2  - Machine Vision and Applications
VL  - 34
IS  - 4
C7  - 61
DO  - 10.1007/s00138-023-01416-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163754403&doi=10.1007%2fs00138-023-01416-z&partnerID=40&md5=11ea29134a72a9f4d519f2500a45689f
AB  - Scene text image super-resolution (STISR) is regarded as the process of improving the image quality of low-resolution scene text images to improve text recognition accuracy. Recently, a text attention network was introduced to reconstruct high-resolution scene text images; the backbone method involved the convolutional neural network-based and transformer-based architecture. Although it can deal with rotated and curved-shaped texts, it still cannot properly handle images containing improper-shaped texts and blurred text regions. This can lead to incorrect text predictions during the text recognition step. In this study, we propose the application of multiple parametric regularizations and parametric weight parameters to the loss function of the STISR method to improve scene text image quality and text recognition accuracy. We design and extend it into three types of methods: adding multiple parametric regularizations, modifying parametric weight parameters, and combining parametric weights and multiple parametric regularizations. Experiments were conducted and compared with state-of-the-art models. The results showed a significant improvement for every proposed method. Moreover, our methods generated clearer and sharper edges than the baseline with a better-quality image score. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Viriyavisuthisakul2023Parametric
ER  -

TY  - JOUR
AU  - Zou, M.
AU  - An, Y.
AU  - Kuang, H.
AU  - Wang, J.
TI  - LGTRL-DE: Local and Global Temporal Representation Learning with Demographic Embedding for in-hospital mortality prediction
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 143
C7  - 104408
DO  - 10.1016/j.jbi.2023.104408
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162078959&doi=10.1016%2fj.jbi.2023.104408&partnerID=40&md5=b972a533e218b95b41c22fa2c33e28cb
AB  - Predicting the patient's in-hospital mortality from the historical Electronic Medical Records (EMRs) can assist physicians to make clinical decisions and assign medical resources. In recent years, researchers proposed many deep learning methods to predict in-hospital mortality by learning patient representations. However, most of these methods fail to comprehensively learn the temporal representations and do not sufficiently mine the contextual knowledge of demographic information. We propose a novel end-to-end approach based on Local and Global Temporal Representation Learning with Demographic Embedding (LGTRL-DE) to address the current issues for in-hospital mortality prediction. LGTRL-DE is enabled by (1) a local temporal representation learning module that captures the temporal information and analyzes the health status from a local perspective through a recurrent neural network with the demographic initialization and the local attention mechanism; (2) a Transformer-based global temporal representation learning module that extracts the interaction dependencies among clinical events; (3) a multi-view representation fusion module that fuses temporal and static information and generates the final patient's health representations. We evaluate our proposed LGTRL-DE on two public real-world clinical datasets (MIMIC-III and e-ICU). Experimental results show that LGTRL-DE achieves area under receiver operating characteristic curve of 0.8685 and 0.8733 on the MIMIC-III and e-ICU datasets, respectively, outperforming several state-of-the-art approaches. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zou2023LGTRL-DE
ER  -

TY  - JOUR
AU  - Ghaderi, H.
AU  - Foreman, B.
AU  - Nayebi, A.
AU  - Tipirneni, S.
AU  - Reddy, C.K.
AU  - Subbian, V.
TI  - A self-supervised learning-based approach to clustering multivariate time-series data with missing values (SLAC-Time): An application to TBI phenotyping
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 143
C7  - 104401
DO  - 10.1016/j.jbi.2023.104401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160613776&doi=10.1016%2fj.jbi.2023.104401&partnerID=40&md5=21ae8896aaf4336c9ceec6796ca51398
AB  - Self-supervised learning approaches provide a promising direction for clustering multivariate time-series data. However, real-world time-series data often include missing values, and the existing approaches require imputing missing values before clustering, which may cause extensive computations and noise and result in invalid interpretations. To address these challenges, we present a Self-supervised Learning-based Approach to Clustering multivariate Time-series data with missing values (SLAC-Time). SLAC-Time is a Transformer-based clustering method that uses time-series forecasting as a proxy task for leveraging unlabeled data and learning more robust time-series representations. This method jointly learns the neural network parameters and the cluster assignments of the learned representations. It iteratively clusters the learned representations with the K-means method and then utilizes the subsequent cluster assignments as pseudo-labels to update the model parameters. To evaluate our proposed approach, we applied it to clustering and phenotyping Traumatic Brain Injury (TBI) patients in the Transforming Research and Clinical Knowledge in Traumatic Brain Injury (TRACK-TBI) study. Clinical data associated with TBI patients are often measured over time and represented as time-series variables characterized by missing values and irregular time intervals. Our experiments demonstrate that SLAC-Time outperforms the baseline K-means clustering algorithm in terms of silhouette coefficient, Calinski Harabasz index, Dunn index, and Davies Bouldin index. We identified three TBI phenotypes that are distinct from one another in terms of clinically significant variables as well as clinical outcomes, including the Extended Glasgow Outcome Scale (GOSE) score, Intensive Care Unit (ICU) length of stay, and mortality rate. The experiments show that the TBI phenotypes identified by SLAC-Time can be potentially used for developing targeted clinical trials and therapeutic strategies. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Ghaderi2023self-supervised
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Chen, H.
AU  - Ma, Y.
AU  - Wang, J.
AU  - Zheng, N.
TI  - Transformer-Based Approach Via Contrastive Learning for Zero-Shot Detection
PY  - 2023
T2  - International Journal of Neural Systems
VL  - 33
IS  - 7
C7  - 2350035
DO  - 10.1142/S0129065723500351
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163150835&doi=10.1142%2fS0129065723500351&partnerID=40&md5=1315da24ca00bcf9cadc252cefd19613
AB  - Zero-shot detection (ZSD) aims to locate and classify unseen objects in pictures or videos by semantic auxiliary information without additional training examples. Most of the existing ZSD methods are based on two-stage models, which achieve the detection of unseen classes by aligning object region proposals with semantic embeddings. However, these methods have several limitations, including poor region proposals for unseen classes, lack of consideration of semantic representations of unseen classes or their inter-class correlations, and domain bias towards seen classes, which can degrade overall performance. To address these issues, the Trans-ZSD framework is proposed, which is a transformer-based multi-scale contextual detection framework that explicitly exploits inter-class correlations between seen and unseen classes and optimizes feature distribution to learn discriminative features. Trans-ZSD is a single-stage approach that skips proposal generation and performs detection directly, allowing the encoding of long-term dependencies at multiple scales to learn contextual features while requiring fewer inductive biases. Trans-ZSD also introduces a foreground-background separation branch to alleviate the confusion of unseen classes and backgrounds, contrastive learning to learn inter-class uniqueness and reduce misclassification between similar classes, and explicit inter-class commonality learning to facilitate generalization between related classes. Trans-ZSD addresses the domain bias problem in end-to-end generalized zero-shot detection (GZSD) models by using balance loss to maximize response consistency between seen and unseen predictions, ensuring that the model does not bias towards seen classes. The Trans-ZSD framework is evaluated on the PASCAL VOC and MS COCO datasets, demonstrating significant improvements over existing ZSD models.  © 2023 World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Liu2023Transformer-Based
ER  -

TY  - JOUR
AU  - Schäfer, H.
AU  - Idrissi-Yaghir, A.
AU  - Bewersdorff, J.
AU  - Frihat, S.
AU  - Friedrich, C.M.
AU  - Zesch, T.
TI  - Medication event extraction in clinical notes: Contribution of the WisPerMed team to the n2c2 2022 challenge
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 143
C7  - 104400
DO  - 10.1016/j.jbi.2023.104400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160739203&doi=10.1016%2fj.jbi.2023.104400&partnerID=40&md5=ac7a4a6fcdb5a2ea0014d5aa1f3d665b
AB  - In this work, we describe the findings of the ‘WisPerMed’ team from their participation in Track 1 (Contextualized Medication Event Extraction) of the n2c2 2022 challenge. We tackle two tasks: (i) medication extraction, which involves extracting all mentions of medications from the clinical notes, and (ii) event classification, which involves classifying the medication mentions based on whether a change in the medication has been discussed. To address the long lengths of clinical texts, which often exceed the maximum token length that models based on the transformer-architecture can handle, various approaches, such as the use of ClinicalBERT with a sliding window approach and Longformer-based models, are employed. In addition, domain adaptation through masked language modeling and preprocessing steps such as sentence splitting are utilized to improve model performance. Since both tasks were treated as named entity recognition (NER) problems, a sanity check was performed in the second release to eliminate possible weaknesses in the medication detection itself. This check used the medication spans to remove false positive predictions and replace missed tokens with the highest softmax probability of the disposition types. The effectiveness of these approaches is evaluated through multiple submissions to the tasks, as well as with post-challenge results, with a focus on the DeBERTa v3 model and its disentangled attention mechanism. Results show that the DeBERTa v3 model performs well in both the NER task and the event classification task. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Schäfer2023Medication
ER  -

TY  - JOUR
AU  - Guo, Q.
AU  - Fang, X.
AU  - Wang, K.
AU  - Shi, Y.
AU  - Wang, L.
AU  - Zhang, E.
AU  - Liu, Z.
TI  - Parallel matters: Efficient polyp segmentation with parallel structured feature augmentation modules
PY  - 2023
T2  - IET Image Processing
VL  - 17
IS  - 8
SP  - 2503
EP  - 2515
DO  - 10.1049/ipr2.12813
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153480316&doi=10.1049%2fipr2.12813&partnerID=40&md5=b5b7ce27ecc82d96c7b524875903b448
AB  - The large variations of polyp sizes and shapes and the close resemblances of polyps to their surroundings call for features with long-range information in rich scales and strong discrimination. This article proposes two parallel structured modules for building those features. One is the Transformer Inception module (TI) which applies Transformers with different reception fields in parallel to input features and thus enriches them with more long-range information in more scales. The other is the Local-Detail Augmentation module (LDA) which applies the spatial and channel attentions in parallel to each block and thus locally augments the features from two complementary dimensions for more object details. Integrating TI and LDA, a new Transformer encoder based framework, Parallel-Enhanced Network (PENet), is proposed, where LDA is specifically adopted twice in a coarse-to-fine way for accurate prediction. PENet is efficient in segmenting polyps with different sizes and shapes without the interference from the background tissues. Experimental comparisons with state-of-the-arts methods show its merits. © 2023 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Guo2023Parallel
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Zhao, S.
AU  - Cheng, B.
AU  - Yang, H.
TI  - TransAM: Transformer appending matcher for few-shot knowledge graph completion
PY  - 2023
T2  - Neurocomputing
VL  - 537
SP  - 61
EP  - 72
DO  - 10.1016/j.neucom.2023.03.049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151561809&doi=10.1016%2fj.neucom.2023.03.049&partnerID=40&md5=b2f3f7b679ca2eb47f9224fc93cdf77f
AB  - Few-shot knowledge graph completion (FSKGC) refers to predicting new facts for a new relation with only few-shot observed entity pairs (triples) as support set. Existing solutions to FSKGC mainly conduct the matching process over entity pair representations. Although effective, a major concern of these models is that the entity interactions are not fully explored, based on the observation that they usually generate the pair representation before the matching stage. Such a design inherently overlooks the fine-grained information from entity interactions, leading to performance decrements in one or three shot, which require matching models to capture more sufficient semantic meanings for prediction. To remedy this issue, in this paper, we explore the entity interactions within and between different instances, i.e., the co-occurrence of two entities, for FSKGC and propose our model named TransAM, Transformer Appending Matcher. TransAM solves the FSKGC problem by computing the probability of entity sequence with a well-designed transformer matching network. Specifically, TransAM appends query entity pair to serialized reference entity sequence and utilizes transformer to calculate the probability by capturing intra- and inter- triple entity interactions. To bridge the gap between transformer and the triple structure, TransAM introduces rotary operation to preserve the head and tail roles of entity within the triple and distinguishes different triples by a separated triple position encoding. Empirical studies on two public benchmark datasets NELL-One and Wiki-One show that TransAM outperforms existing metric-learning solutions in MRR and Hits@1 with both one- and three- shot settings, and achieves comparable results on five-shot setting. Datasets and code will be public available at https://github.com/gawainx/TransAM. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Liang2023TransAM
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Zhang, X.
AU  - Dong, Z.
TI  - TSF-transformer: a time series forecasting model for exhaust gas emission using transformer
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 13
SP  - 17211
EP  - 17225
DO  - 10.1007/s10489-022-04326-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144705970&doi=10.1007%2fs10489-022-04326-1&partnerID=40&md5=d2c14b685f50db26992b346f9993d76c
AB  - Monitoring and prediction of exhaust gas emissions for heavy trucks is a promising way to solve environmental problems. However, the emission data acquisition is time delayed and the pattern of emission is usually irregular, which makes it very difficult to accurately predict the emission state. To deal with these problems, in this paper, we interpret emission prediction as a time series prediction problem and explore a deep learning model, a time-series forecasting Transformer (TSF-Transformer) for exhaust gas emission prediction. The exhaust emission of the heavy truck is not directly predicted, but indirectly predicted by predicting the temperature and pressure changes of the exhaust pipe under the working state of the truck. The basis of our research is based on real-time data feeds from temperature and pressure sensors installed on the exhaust pipe of approximately 12,000 heavy trucks. Therefore, the task of time series forecasting consists of two key stages: monitoring and prediction. The former utilizes the server to receive the data sent by the sensors in real-time, and the latter uses these data as samples for network training and testing. The training of the network throughout the prediction process is done in an unsupervised manner. Also, to visualize the forecast results, we weight the forecast data with the truck trajectories and present them as heatmaps. To the best of our knowledge, this is the first case of using the Transformer as the core component of the prediction model to complete the task of exhaust emissions prediction from heavy trucks. Experiments show that the prediction model outperforms other state-of-the-art methods in prediction accuracy. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Li2023TSF-transformer
ER  -

TY  - JOUR
AU  - Zhu, L.
AU  - Peng, L.
AU  - Zhou, W.
AU  - Yang, J.
TI  - Dual-decoder transformer network for answer grounding in visual question answering
PY  - 2023
T2  - Pattern Recognition Letters
VL  - 171
SP  - 53
EP  - 60
DO  - 10.1016/j.patrec.2023.04.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159640003&doi=10.1016%2fj.patrec.2023.04.003&partnerID=40&md5=af7bc0e264e5b43e6299b2043a67a472
AB  - Visual Question Answering (VQA) have made stunning advances by exploiting Transformer architecture and large-scale visual-linguistic pretraining. State-of-the-art methods generally require large amounts of data and devices to predict textualized answers and fail to provide visualized evidence of the answers. To mitigate these limitations, we propose a novel dual-decoder Transformer network (DDTN) for predicting the language answer and corresponding vision instance. Specifically, the linguistic features are first embedded by Long Short-Term Memory (LSTM) block and Transformer encoder, which are shared between the Transformer dual-decoder. Then, we introduce object detector to obtain vision region features and grid features for reducing the size and cost of DDTN. These visual features are combined with the linguistic features and are respectively fed into two decoders. Moreover, we design an instance query to guide the fused visual-linguistic features for outputting the instance mask or bounding box. The classification layers aggregate results from decoders and predict answer as well as corresponding instance coordinates at last. Without bells and whistles, DDTN achieves state-of-the-art performance and even competitive to pretraining models on VizWizGround and GQA dataset. The code is available at https://github.com/zlj63501/DDTN. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Zhu2023Dual-decoder
ER  -

TY  - JOUR
AU  - Fan, W.
AU  - Shangguan, W.
AU  - Bouguila, N.
TI  - Continuous image anomaly detection based on contrastive lifelong learning
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 14
SP  - 17693
EP  - 17707
DO  - 10.1007/s10489-022-04401-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146350218&doi=10.1007%2fs10489-022-04401-7&partnerID=40&md5=7f2bf33dbde71878d891636be5c93da6
AB  - With the development of deep learning techniques, an increasing number of anomaly detection methods based on deep neural networks have been proposed during the last decade. Nevertheless, these methods often suffer from catastrophic forgetting when trained on continuously arriving data samples, as deep neural networks quickly forget the knowledge obtained from previous training while adjusting to learning new information. In this work, we propose a contrastive lifelong learning model for image anomaly detection. Rather than adopting CNN-based neural networks as in other anomaly detection approaches to learn representations from training samples, we propose a contrastive learning framework for anomaly detection in which Vision Transformer (VIT) is adopted for extracting promising representations. Two nonlinear structures (projector and predictor) are integrated into our model, which is helpful in improving the performance of anomaly detection. Moreover, a lifelong learning framework that contains teacher and student networks is deployed in our model, which is able to mitigate the problem of catastrophic forgetting in image anomaly detection. By leveraging both lifelong learning and contrastive learning frameworks, our model is able to progressively perform image anomaly detection where the problem of catastrophic forgetting can be greatly mitigated. We demonstrate the effectiveness of the proposed anomaly detection method by conducting experiments on multiple image data sets. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Fan2023Continuous
ER  -

TY  - JOUR
AU  - Fouladvand, S.
AU  - Talbert, J.
AU  - Dwoskin, L.P.
AU  - Bush, H.
AU  - Meadows, A.L.
AU  - Peterson, L.E.
AU  - Mishra, Y.R.
AU  - Roggenkamp, S.K.
AU  - Wang, F.
AU  - Kavuluru, R.
AU  - Chen, J.
TI  - A Comparative Effectiveness Study on Opioid Use Disorder Prediction Using Artificial Intelligence and Existing Risk Models
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 7
SP  - 3589
EP  - 3598
DO  - 10.1109/JBHI.2023.3265920
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153335210&doi=10.1109%2fJBHI.2023.3265920&partnerID=40&md5=555c66f67952f5d3fa3474176d37562e
AB  - Opioid use disorder (OUD) is a leading cause of death in the United States placing a tremendous burden on patients, their families, and health care systems. Artificial intelligence (AI) can be harnessed with available healthcare data to produce automated OUD prediction tools. In this retrospective study, we developed AI based models for OUD prediction and showed that AI can predict OUD more effectively than existing clinical tools including the unweighted opioid risk tool (ORT). Data include 474,208 patients' data over 10 years; 269,748 were females with an average age of 56.78 years. Cases are prescription opioid users with at least one diagnosis of OUD or at least one prescription for buprenorphine or methadone. Controls are prescription opioid users with no OUD diagnoses or buprenorphine or methadone prescriptions. On 100 randomly selected test sets including 47,396 patients, our proposed transformer-based AI model can predict OUD more efficiently (AUC = 0.742 ± 0.021) compared to logistic regression (AUC = 0.651 ± 0.025), random forest (AUC = 0.679 ± 0.026), xgboost (AUC = 0.690 ± 0.027), long short-term memory model (AUC = 0.706 ± 0.026), transformer (AUC = 0.725 ± 0.024), and unweighted ORT model (AUC = 0.559 ± 0.025). Our results show that embedding AI algorithms into clinical care may assist clinicians in risk stratification and management of patients receiving opioid therapy.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Fouladvand2023Comparative
ER  -

TY  - JOUR
AU  - Adishesha, A.S.
AU  - Jakielaszek, L.
AU  - Azhar, F.
AU  - Zhang, P.
AU  - Honavar, V.
AU  - Ma, F.
AU  - Belani, C.
AU  - Mitra, P.
AU  - Huang, S.X.
TI  - Forecasting User Interests Through Topic Tag Predictions in Online Health Communities
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 7
SP  - 3645
EP  - 3656
DO  - 10.1109/JBHI.2023.3271580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159645204&doi=10.1109%2fJBHI.2023.3271580&partnerID=40&md5=add0c2a2321eaea86ecae65aea6b2e02
AB  - The increasing reliance on online communities for healthcare information by patients and caregivers has led to the increase in the spread of misinformation, or subjective, anecdotal and inaccurate or non-specific recommendations, which, if acted on, could cause serious harm to the patients. Hence, there is an urgent need to connect users with accurate and tailored health information in a timely manner to prevent such harm. This article proposes an innovative approach to suggesting reliable information to participants in online communities as they move through different stages in their disease or treatment. We hypothesize that patients with similar histories of disease progression or course of treatment would have similar information needs at comparable stages. Specifically, we pose the problem of predicting topic tags or keywords that describe the future information needs of users based on their profiles, traces of their online interactions within the community (past posts, replies) and the profiles and traces of online interactions of other users with similar profiles and similar traces of past interaction with the target users. The result is a variant of the collaborative information filtering or recommendation system tailored to the needs of users of online health communities. We report results of our experiments on two unique datasets from two different social media platforms which demonstrates the superiority of the proposed approach over the state of the art baselines with respect to accurate and timely prediction of topic tags (and hence information sources of interest).  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Adishesha2023Forecasting
ER  -

TY  - JOUR
AU  - De, A.
AU  - Nandi, A.
AU  - Mallick, A.
AU  - Middya, A.I.
AU  - Roy, S.
TI  - Forecasting chaotic weather variables with echo state networks and a novel swing training approach
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 269
C7  - 110506
DO  - 10.1016/j.knosys.2023.110506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150915159&doi=10.1016%2fj.knosys.2023.110506&partnerID=40&md5=73705f19eacacab6267ef2a1176963b8
AB  - Physical systems like weather variables, the behavior of oceanic bodies, economic variables, and similar systems possess a considerable amount of chaos, and deducing predictive patterns from them is almost not feasible. Forecasting weather parameters has always been a major objective due to several reasons, but observably not all weather variables are equally influential. Parameters like temperature, humidity, and radiation, though easier to predict due to obvious patterns, are found to be less impactful in practical circumstances. But variables that are more turbulent and difficult to model, like wind flow, cloud cover, sea level pressure, etc. are very influential in the context of managing disasters like cyclones, estimating trades, estimating power generation and many other causes. In this study, the aim is to accurately forecast the horizontal wind velocity field which individually considers the longitudinal and latitudinal components of velocity and sea level pressure over a certain region. Initial attempts in this domain used to be purely mathematical with deterministic results, but predicting real phenomena by overpowering the chaos required enormous computational overhead. The results obtained were not satisfactory. With the evolution of statistical modeling, machine learning and deep learning, these systems were majorly formulated as spatiotemporal forecasting problems. Modified deep learning approaches like ConvLSTM, transformer-based models, CNN-GRU models, and others were applied on the spatiotemporal prediction problem producing more accurate results as compared to the primary methods. But the introduction of reservoir computing framework once again invoked the possibilities of improvements in this domain. An instance of reservoir computing, known as the echo state Network (ESN) was found to simulate and learn the complex dynamics of physical systems with significantly less effort. This boiled down to be a major motivation behind this paper. In this study, we have selected two regions over the Indian peninsula and the Mexican gulf and collected hourly data of horizontal wind velocity and sea level pressure with a spatial granularity of 0.25 degrees on these regions. This data has been used to train our proposed model which is an echo state network and convolution-based encoder–decoder architecture. The model forecasts the same parameters over the same spatial zone for some forecast horizons. The results have been rigorously compared with potential baselines where the ESN was replaced by conventional recurrent networks, and it was observed that our proposed approach outperforms all the other baselines. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; 
LB  - De2023Forecasting
ER  -

TY  - JOUR
AU  - Shi, Y.
AU  - Wu, Z.
AU  - Chen, Y.
AU  - Dong, J.
TI  - Siamese tracker with temporal information based on transformer-like feature fusion mechanism
PY  - 2023
T2  - Machine Vision and Applications
VL  - 34
IS  - 4
C7  - 59
DO  - 10.1007/s00138-023-01409-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161363254&doi=10.1007%2fs00138-023-01409-y&partnerID=40&md5=458e10ca012318a74e2d4291fd4a9b01
AB  - The position of the target in video trackers based on the Siamese network is usually obtained by calculating the similarity score of features between the target template and the predicted region. This method performs poorly in complex scenarios due to such problems as the deformation of the target and motion blur. To solve these problems, this paper proposes a transformer-like feature fusion mechanism to fuse the temporal information of consecutive frames of the video. We separate the encoder and decoder into two parallel branches to accommodate the characteristics of Siamese networks. The features of the target template are enhanced by a transformer-like encoder while temporal feature-related information is fused by using a transformer-like decoder. The results of experiments on the standard OTB100, VOT2018, UAV123, and NFS datasets showed that the proposed network outperforms most mainstream algorithms in the area. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Shi2023Siamese
ER  -

TY  - JOUR
AU  - Lado-Roigé, R.
AU  - Pérez, M.A.
TI  - STB-VMM: Swin Transformer based Video Motion Magnification
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 269
C7  - 110493
DO  - 10.1016/j.knosys.2023.110493
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151378111&doi=10.1016%2fj.knosys.2023.110493&partnerID=40&md5=a6c0aa9ad93a8c91b105835a89dfee8d
AB  - The goal of video motion magnification techniques is to magnify small motions in a video to reveal previously invisible or unseen movement. Its uses extend from bio-medical applications and deepfake detection to structural modal analysis and predictive maintenance. However, discerning small motion from noise is a complex task, especially when attempting to magnify very subtle, often sub-pixel movement. As a result, motion magnification techniques generally suffer from noisy and blurry outputs. This work presents a new state-of-the-art model based on the Swin Transformer, which offers better tolerance to noisy inputs as well as higher-quality outputs that exhibit less noise, blurriness, and artifacts than prior-art. Improvements in output image quality will enable more precise measurements for any application reliant on magnified video sequences, and may enable further development of video motion magnification techniques in new technical fields. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; FMS:C; 
LB  - Lado-Roigé2023STB-VMM
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Wang, M.
AU  - Zheng, Z.
AU  - Ma, M.
AU  - Fei, X.
AU  - Wei, L.
AU  - Chen, H.
TI  - Representation of time-varying and time-invariant EMR data and its application in modeling outcome prediction for heart failure patients
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 143
C7  - 104427
DO  - 10.1016/j.jbi.2023.104427
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163221964&doi=10.1016%2fj.jbi.2023.104427&partnerID=40&md5=7292a5427635d29c0d29f2756135e307
AB  - Objective: To represent a patient record with both time-invariant and time-varying features as a single vector using an end-to-end deep learning model, and further to predict the kidney failure (KF) status and mortality of heart failure (HF) patients. Materials and methods: The time-invariant EMR data included demographic information and comorbidities, and the time-varying EMR data were lab tests. We used a Transformer encoder module to represent the time-invariant data, and refined a long short-term memory (LSTM) with a Transformer encoder attached to the top to represent the time-varying data, taking the original measured values and their corresponding embedding vectors, masking vectors, and two types of time intervals as inputs. The proposed representations of patients with time-invariant and time-varying data were used to predict KF status (949 out of 5268 HF patients diagnosed with KF) and mortality (463 in-hospital deaths) for HF patients. Comparative experiments were conducted between the proposed model and some representative machine learning models. Ablation experiments were also performed around the time-varying data representation, including replacing the refined LSTM with the standard LSTM, GRU-D and T-LSTM, respectively, and removing the Transformer encoder and the time-varying data representation module, respectively. The visualization of the attention weights of the time-invariant and time-varying features was used to clinically interpret the predictive performance. We used the area under the receiver operating characteristic curve (AUROC), the area under the precision-recall curve (AUPRC), and the F1-score to evaluate the predictive performance of the models. Results: The proposed model achieved superior performance, with average AUROCs, AUPRCs and F1-scores of 0.960, 0.610 and 0.759 for KF prediction and 0.937, 0.353 and 0.537 for mortality prediction, respectively. Predictive performance improved with the addition of time-varying data from longer time periods. The proposed model outperformed the comparison and ablation references in both prediction tasks. Conclusions: Both time-invariant and time-varying EMR data of patients could be efficiently represented by the proposed unified deep learning model, which shows higher performance in clinical prediction tasks. The way to use time-varying data in the current study is hopeful to be used in other kinds of time-varying data and other clinical tasks. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Huang2023Representation
ER  -

TY  - JOUR
AU  - Callan, D.
AU  - Foster, J.
TI  - How interesting and coherent are the stories generated by a large-scale neural language model? Comparing human and automatic evaluations of machine-generated text
PY  - 2023
T2  - Expert Systems
VL  - 40
IS  - 6
C7  - e13292
DO  - 10.1111/exsy.13292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151401826&doi=10.1111%2fexsy.13292&partnerID=40&md5=0c7753547d67fd071b5b1cf785fc1e1b
AB  - Evaluation of the narrative text generated by machines has traditionally been a challenge, particularly when attempting to evaluate subjective elements such as interest or believability. Recent improvements in narrative machine text generation have been largely driven by the emergence of transformer-based language models, trained on massive quantities of data, resulting in higher quality text generation. In this study, a corpus of stories is generated using the pre-trained GPT-Neo transformer model, with human-written prompts as inputs upon which to base the narrative text. The stories generated through this process are subsequently evaluated through both human evaluation and two automated metrics: BERTScore and BERT Next Sentence Prediction, with the aim of determining whether there is a correlation between the automatic scores and the human judgements. The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans. © 2023 The Authors. Expert Systems published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Callan2023How
ER  -

TY  - JOUR
AU  - Lee, S.-H.
AU  - Kim, S.-W.
TI  - Dual-branch vision transformer for blind image quality assessment
PY  - 2023
T2  - Journal of Visual Communication and Image Representation
VL  - 94
C7  - 103850
DO  - 10.1016/j.jvcir.2023.103850
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159360579&doi=10.1016%2fj.jvcir.2023.103850&partnerID=40&md5=03601f75413021617141541c1a73d006
AB  - Blind image quality assessment (BIQA) has always been a challenging problem due to the absence of reference images. In this paper, we propose a novel dual-branch vision transformer for BIQA, which simultaneously considers both local distortions and global semantic information. It first extracts dual-scale features from the backbone network, and then each scale feature is fed into one of the transformer encoder branches as a local feature embedding to consider the scale-variant local distortions. Each transformer branch obtains the context of global image distortion as well as the local distortion by adopting content-aware embedding. Finally, the outputs of the dual-branch vision transformer are combined by using multiple feed-forward blocks to predict the image quality scores effectively. Experimental results demonstrate that the proposed BIQA method outperforms the conventional methods on the six public BIQA datasets. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Lee2023Dual-branch
ER  -

TY  - JOUR
AU  - Im, J.-E.
AU  - Yoon, S.-A.
AU  - Shin, Y.M.
AU  - Park, S.
TI  - Real-Time Prediction for Neonatal Endotracheal Intubation Using Multimodal Transformer Network
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 6
SP  - 2625
EP  - 2634
DO  - 10.1109/JBHI.2023.3267521
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153524403&doi=10.1109%2fJBHI.2023.3267521&partnerID=40&md5=dadc9e5830712ae27413fc23da47f504
AB  - Neonates admitted to neonatal intensive care units (NICUs) are at risk for respiratory decompensation and may require endotracheal intubation. Delayed intubation is associated with increased morbidity and mortality, particularly in urgent unplanned intubation. By accurately predicting the need for intubation in real-time, additional time can be made available for preparation, thereby increasing the safety margins by avoiding high-risk late intubation. In this study, the probability of intubation in neonatal patients with respiratory problems was predicted using a deep neural network. A multimodal transformer model was developed to simultaneously analyze time-series data (1-3 h of vital signs and FiO2 setting value) and numeric data including initial clinical information. Over a dataset including information of 128 neonatal patients who underwent noninvasive ventilation, the proposed model successfully predicted the need for intubation 3 h in advance (area under the receiver operator characteristic curve = 0.880 pm 0.051, F1-score = 0.864 pm 0.031, sensitivity = 0.886 pm 0.041, specificity = 0.849 pm 0.035, and accuracy = 0.857 pm 0.032). Moreover, the proposed model showed high generalization ability by achieving AUROC 0.890, F1-score 0.893, specificity 0.871, sensitivity 0.745, and accuracy 0.864 with an additional 91 dataset for testing.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Im2023Real-Time
ER  -

TY  - JOUR
AU  - Pramanik, R.
AU  - Sikdar, R.
AU  - Sarkar, R.
TI  - Transformer-based deep reverse attention network for multi-sensory human activity recognition
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 122
C7  - 106150
DO  - 10.1016/j.engappai.2023.106150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150352406&doi=10.1016%2fj.engappai.2023.106150&partnerID=40&md5=7d6cee13f0cf1832d3c3468aaabe6211
AB  - In today's era, one of the important applications of Artificial Intelligence (AI) is Human Activity Recognition (HAR). It has a wide range of applicability in health monitoring for patients with chronic diseases, gaming consoles for gesture recognition, etc. Sensor-based HAR systems use signals collected over a period of time to label an activity. When we design an efficient sensor-based HAR system, a model requires learning an optimal association of spatial and temporal features. In this article, we propose a sensor-based HAR technique using the deep learning approach. We present a deep reverse transformer-based attention mechanism to guide the side residual features Unlike the conventional bottom-up approaches for feature fusion, we exploit a top-down feature fusion approach. The reverse attention is self-calibrated throughout the course of learning, which regularizes the attention modules and dynamically adjusts the learning rate. The overall framework outperforms several state-of-the-art methods and is shown to be statistically significant against these methods on five publicly available sensor-based HAR datasets, namely, MHEALTH, USC-HAD, WHARF, UTD-MHAD1, and UTD-MHAD2. Further, we conduct an ablation study to showcase the importance of each of the components of the proposed framework. Source code of this work is available at https://github.com/rishavpramanik/RevTransformerAttentionHAR. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Pramanik2023Transformer-based
ER  -

TY  - JOUR
AU  - Chen, K.
AU  - Zhu, H.
AU  - Tang, D.
AU  - Zheng, K.
TI  - Future pedestrian location prediction in first-person videos for autonomous vehicles and social robots
PY  - 2023
T2  - Image and Vision Computing
VL  - 134
C7  - 104671
DO  - 10.1016/j.imavis.2023.104671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154610712&doi=10.1016%2fj.imavis.2023.104671&partnerID=40&md5=fc65ecba0c2949d03a3ceb6bc4921209
AB  - Future pedestrian trajectory prediction in first-person videos offers great prospects to help autonomous vehicles and social robots to enable better human-vehicle interactions. Given an egocentric video stream, we aim to predict the location and depth (distance between the observed person and the camera) of his/her neighbors in future frames. To locate their future trajectories, we mainly consider three main factors: a) It is necessary to restore the spatial distribution of pedestrians in 2D image to 3D space, i.e., to extract the distance between the pedestrian and the camera which is often neglected. b) It is critical to utilize neighbors’ poses to recognize their intentions. c) It is important to learn human-vehicle interactions from the pedestrian's historical trajectories. We propose to incorporate these three factors into a multi-channel tensor to represent the main features in real-life 3D space. We then put this tensor into an innovative end-to-end fully convolutional network based on transformer architecture. Experimental results reveal our method outperforms other state-of-the-art methods on public benchmarks MOT15, MOT16 and MOT17. The proposed method will be useful to understand human-vehicle interaction and helpful for pedestrian collision avoidance. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Chen2023Future
ER  -

TY  - JOUR
AU  - Mao, Y.
AU  - Xu, K.
AU  - Miglietta, L.
AU  - Kreitmann, L.
AU  - Moser, N.
AU  - Georgiou, P.
AU  - Holmes, A.
AU  - Rodriguez-Manzano, J.
TI  - Deep Domain Adaptation Enhances Amplification Curve Analysis for Single-Channel Multiplexing in Real-Time PCR
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 6
SP  - 3093
EP  - 3103
DO  - 10.1109/JBHI.2023.3257727
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151372068&doi=10.1109%2fJBHI.2023.3257727&partnerID=40&md5=997fbbc11bc7ae734d0b7ea477bf8e14
AB  - Data-driven approaches for molecular diagnostics are emerging as an alternative to perform an accurate and inexpensive multi-pathogen detection. A novel technique called Amplification Curve Analysis (ACA) has been recently developed by coupling machine learning and real-time Polymerase Chain Reaction (qPCR) to enable the simultaneous detection of multiple targets in a single reaction well. However, target classification purely relying on the amplification curve shapes faces several challenges, such as distribution discrepancies between different data sources (i.e., training vs testing). Optimisation of computational models is required to achieve higher performance of ACA classification in multiplex qPCR through the reduction of those discrepancies. Here, we proposed a novel transformer-based conditional domain adversarial network (T-CDAN) to eliminate data distribution differences between the source domain (synthetic DNA data) and the target domain (clinical isolate data). The labelled training data from the source domain and unlabelled testing data from the target domain are fed into the T-CDAN, which learns both domains' information simultaneously. After mapping the inputs into a domain-irrelevant space, T-CDAN removes the feature distribution differences and provides a clearer decision boundary for the classifier, resulting in a more accurate pathogen identification. Evaluation of 198 clinical isolates containing three types of carbapenem-resistant genes (blaNDM, blaIMP and blaOXA-48) illustrates a curve-level accuracy of 93.1% and a sample-level accuracy of 97.0% using T-CDAN, showing an accuracy improvement of 20.9% and 4.9% respectively. This research emphasises the importance of deep domain adaptation to enable high-level multiplexing in a single qPCR reaction, providing a solid approach to extend qPCR instruments' capabilities in real-world clinical applications.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Mao2023Deep
ER  -

TY  - JOUR
AU  - Zampieri, M.
AU  - Ranasinghe, T.
AU  - Sarkar, D.
AU  - Ororbia, A.
TI  - Offensive language identification with multi-task learning
PY  - 2023
T2  - Journal of Intelligent Information Systems
VL  - 60
IS  - 3
SP  - 613
EP  - 630
DO  - 10.1007/s10844-023-00787-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153726798&doi=10.1007%2fs10844-023-00787-z&partnerID=40&md5=b0052df28f8d633944888fff1f191db2
AB  - The widespread presence of offensive content is a major issue in social media. This has motivated the development of computational models to identify such content in posts or conversations. Most of these models, however, treat offensive language identification as an isolated task. Very recently, a few datasets have been annotated with post-level offensiveness and related phenomena, such as offensive tokens, humor, engaging content, etc., creating the opportunity of modeling related tasks jointly which will help improve the explainability of offensive language detection systems and potentially aid human moderators. This study proposes a novel multi-task learning (MTL) architecture that can predict: (1) offensiveness at both post and token levels in English; and (2) offensiveness and related subjective tasks such as humor, engaging content, and gender bias identification in multilingual settings. Our results show that the proposed multi-task learning architecture outperforms current state-of-the-art methods trained to identify offense at the post level. We further demonstrate that MTL outperforms single-task learning (STL) across different tasks and language combinations. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zampieri2023Offensive
ER  -

TY  - JOUR
AU  - Pan, Q.
AU  - Zhao, F.
AU  - Chen, X.
AU  - Chen, D.
TI  - A method for extracting tumor events from clinical CT examination reports
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 142
C7  - 104371
DO  - 10.1016/j.jbi.2023.104371
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159087716&doi=10.1016%2fj.jbi.2023.104371&partnerID=40&md5=c7b4dbaff855fa8e27b2150d77dabf29
AB  - Accurate and efficient extraction of key information related to diseases from medical examination reports, such as X-ray and ultrasound images, CT scans, and others, is crucial for accurate diagnosis and treatment. These reports provide a detailed record of a patient's health condition and are an important part of the clinical examination process. By organizing this information in a structured way, doctors can more easily review and analyze the data, leading to better patient care. In this paper, we introduce a new technique for extracting useful information from unstructured clinical text examination reports, which we refer to as a medical event extraction (EE) task. Our approach is based on Machine Reading Comprehension (MRC) and involves two sub-tasks: Question Answerability Judgment (QAJ) and Span Selection (SS). We use BERT to build a question answerability discriminator (Judger) that determines whether a reading comprehension question can be answered or not, thereby avoiding the extraction of arguments from unanswerable questions. The SS sub-task first obtains the encoding of each word in the medical text from the final layer of BERT's Transformer, then utilizes the attention mechanism to identify important information related to the answer from these word encodings. This information is then input into a bidirectional LSTM (BiLSTM) module to obtain a global representation of the text, which is used, along with the softmax function, to predict the span of the answer (i.e., the start and end positions of the answer in the text report). We use interpretable methods to calculate the Jensen-Shannon Divergence (JSD) score between various layers of the network and confirm that our model has strong word representation capabilities, enabling it to effectively extract contextual information from medical reports. Our experiments demonstrate that our method outperforms existing medical event extraction methods, achieving state-of-the-art results with a notable F1 score. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Pan2023method
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Duan, L.
AU  - Wang, J.
AU  - He, C.
AU  - Chen, Z.
AU  - Xie, G.
AU  - Deng, S.
AU  - Luo, Z.
TI  - Memory-Enhanced Transformer for Representation Learning on Temporal Heterogeneous Graphs
PY  - 2023
T2  - Data Science and Engineering
VL  - 8
IS  - 2
SP  - 98
EP  - 111
DO  - 10.1007/s41019-023-00207-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150712608&doi=10.1007%2fs41019-023-00207-w&partnerID=40&md5=dd8a105f7ff019ad4b2adef8d9b28cc9
AB  - Temporal heterogeneous graphs can model lots of complex systems in the real world, such as social networks and e-commerce applications, which are naturally time-varying and heterogeneous. As most existing graph representation learning methods cannot efficiently handle both of these characteristics, we propose a Transformer-like representation learning model, named THAN, to learn low-dimensional node embeddings preserving the topological structure features, heterogeneous semantics, and dynamic patterns of temporal heterogeneous graphs, simultaneously. Specifically, THAN first samples heterogeneous neighbors with temporal constraints and projects node features into the same vector space, then encodes time information and aggregates the neighborhood influence in different weights via type-aware self-attention. To capture long-term dependencies and evolutionary patterns, we design an optional memory module for storing and evolving dynamic node representations. Experiments on three real-world datasets demonstrate that THAN outperforms the state-of-the-arts in terms of effectiveness with respect to the temporal link prediction task. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Li2023Memory-Enhanced
ER  -

TY  - JOUR
AU  - Zhang, W.
AU  - Tan, Q.
AU  - Li, P.
AU  - Zhang, Q.
AU  - Wang, R.
TI  - Cross-modal transformer with language query for referring image segmentation
PY  - 2023
T2  - Neurocomputing
VL  - 536
SP  - 191
EP  - 205
DO  - 10.1016/j.neucom.2023.03.011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151372252&doi=10.1016%2fj.neucom.2023.03.011&partnerID=40&md5=eb6d8a226295b9cbb23f6393c607d218
AB  - Referring image segmentation (RIS) aims to predict a segmentation mask for a target specified by a natural language expression. However, the existing methods failed to implement deep interaction between vision and language is needed in RIS, resulting inaccurate segmentation. To address the problem, a cross-modal transformer (CMT) with language queries for referring image segmentation is proposed. First, a cross-modal encoder of CMT is designed for intra-modal and inter-modal interaction, capturing context-aware visual features. Secondly, to generate compact visual-aware language queries, a language-query encoder (LQ) embeds key visual cues into linguistic features. In particular, the combination of the cross-modal encoder and language query encoder realizes the mutual guidance of vision and language. Finally, the cross-modal decoder of CMT is constructed to learn multimodal features of the referent from the context-aware visual features and visual-aware language queries. In addition, a semantics-guided detail enhancement (SDE) module is constructed to fuse the semantic-rich multimodal features with detail-rich low-level visual features, which supplements the spatial details of the predicted segmentation masks. Extensive experiments on four referring image segmentation datasets demonstrate the effectiveness of the proposed method. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhang2023Cross-modal
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Yang, G.
AU  - Wang, S.
AU  - Wang, H.
AU  - Zhang, Y.
AU  - Wang, Y.
TI  - TANet: Transformer-based asymmetric network for RGB-D salient object detection
PY  - 2023
T2  - IET Computer Vision
VL  - 17
IS  - 4
SP  - 415
EP  - 430
DO  - 10.1049/cvi2.12177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148628723&doi=10.1049%2fcvi2.12177&partnerID=40&md5=98fabf71701f44f3e80c9d68b2d8d517
AB  - Existing RGB-D salient object detection methods mainly rely on a symmetric two-stream Convolutional Neural Network (CNN)-based network to extract RGB and depth channel features separately. However, there are two problems with the symmetric conventional network structure: first, the ability of CNN in learning global contexts is limited; second, the symmetric two-stream structure ignores the inherent differences between modalities. In this study, a Transformer-based asymmetric network is proposed to tackle the issues mentioned above. The authors employ the powerful feature extraction capability of Transformer to extract global semantic information from RGB data and design a lightweight CNN backbone to extract spatial structure information from depth data without pre-training. The asymmetric hybrid encoder effectively reduces the number of parameters in the model while increasing speed without sacrificing performance. Then, a cross-modal feature fusion module which enhances and fuses RGB and depth features with each other is designed. Finally, the authors add edge prediction as an auxiliary task and propose an edge enhancement module to generate sharper contours. Extensive experiments demonstrate that our method achieves superior performance over 14 state-of-the-art RGB-D methods on six public datasets. The code of the authors will be released at https://github.com/lc012463/TANet. © 2023 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Liu2023TANet
ER  -

TY  - JOUR
AU  - Rodriguez, M.A.
AU  - Almarzouqi, H.
AU  - Liatsis, P.
TI  - Multi-Label Retinal Disease Classification Using Transformers
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 6
SP  - 2739
EP  - 2750
DO  - 10.1109/JBHI.2022.3214086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139816542&doi=10.1109%2fJBHI.2022.3214086&partnerID=40&md5=878107234e1a41ec3848f07844cc8b83
AB  - Early detection of retinal diseases is one of the most important means of preventing partial or permanent blindness in patients. In this research, a novel multi-label classification system is proposed for the detection of multiple retinal diseases, using fundus images collected from a variety of sources. First, a new multi-label retinal disease dataset, the MuReD dataset, is constructed, using a number of publicly available datasets for fundus disease classification. Next, a sequence of post-processing steps is applied to ensure the quality of the image data and the range of diseases, present in the dataset. For the first time in fundus multi-label disease classification, a transformer-based model optimized through extensive experimentation is used for image analysis and decision making. Numerous experiments are performed to optimize the configuration of the proposed system. It is shown that the approach performs better than state-of-the-art works on the same task by 7.9% and 8.1% in terms of AUC score for disease detection and disease classification, respectively. The obtained results further support the potential applications of transformer-based architectures in the medical imaging field.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Rodriguez2023Multi-Label
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Wang, Y.
AU  - Peng, J.
AU  - Zhang, Z.
AU  - Tang, X.
TI  - A hybrid framework for multivariate long-sequence time series forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 11
SP  - 13549
EP  - 13568
DO  - 10.1007/s10489-022-04110-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139753395&doi=10.1007%2fs10489-022-04110-1&partnerID=40&md5=f0aac6ea60dc5392922372a8442861e0
AB  - Time series forecasting provides insights into the far future by utilizing the available history observations. Recent studies have demonstrated the superiority of transformer-based models in dealing with multivariate long-sequence time series forecasting (MLTSF). However, the data complexity hinders the forecasting accuracy of current deep neural network models. In this article, a hybrid framework - Waveformer - is proposed, which decomposes fluctuated and complex data sequence into multiple stable and more predictable subsequences (components) through the entire forecasting process. Waveformer interactively learns temporal dependencies on each pair of decomposed components, which enhances its ability of learning their temporal dependencies. Moreover, Waveformer treats the implicit and dynamic dependencies among variables as a set of dynamic direct graphs. Based on which, an attention adaptive graph convolution net (AAGCN) is designed, which combines self-attention and adaptive direct graph convolution to capture multivariate dynamic dependencies in a flexible manner. The experimental results on six public datasets show that Waveformer considerably outperforms a varied range of state-of-the-art benchmarks, with at the most 54.3% relative improvement. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Wang2023hybrid
ER  -

TY  - JOUR
AU  - Zeng, P.
AU  - Hu, G.
AU  - Zhou, X.
AU  - Li, S.
AU  - Liu, P.
TI  - Seformer: a long sequence time-series forecasting model based on binary position encoding and information transfer regularization
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 12
SP  - 15747
EP  - 15771
DO  - 10.1007/s10489-022-04263-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142902042&doi=10.1007%2fs10489-022-04263-z&partnerID=40&md5=896cf01b82c0285103d92f74bef8f13d
AB  - Long sequence time-series forecasting (LSTF) problems, such as weather forecasting, stock market forecasting, and power resource management, are widespread in the real world. The LSTF problem requires a model with high prediction accuracy. Recent studies have shown that the transformer model architecture is the most promising model structure for LSTF problems compared with other model architectures. The transformer model has the property of permutation equivalence, which leads to the importance of sequence position encoding, an essential process in model training. Currently, the continuous dynamics models constructed for position encoding using the neural differential equations (neural ODEs) method can model sequence position information well. However, we have found that there are some limitations when neural ODEs are applied to the LSTF problem, including the time cost problem, the baseline drift problem, and the information loss problem; thus, neural ODEs cannot be directly applied to the LSTF problem. To address this problem, we design a binary position encoding-based regularization model for long sequence time-series prediction, named Seformer, which has the following structure: 1) The binary position encoding mechanism, including intrablock and interblock position encoding. For intrablock position encoding, we design a simple ODE method by discretizing the continuum dynamics model, which reduces the time cost required to compute neural ODEs while maintaining their dynamics properties to the maximum extent. In interblock position encoding, a chunked recursive form is adopted to alleviate the baseline drift problem caused by eigenvalue explosion. 2) Information transfer regularization mechanism: By regularizing the model intermediate hidden variables as well as the encoder-decoder connection variables, we can reduce information loss during the model training process while ensuring the smoothness of the position information. Extensive experimental results obtained on six large-scale datasets show a consistent improvement in our approach over the baselines. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zeng2023Seformer
ER  -

TY  - JOUR
AU  - Acs, J.
AU  - Hamerlik, E.
AU  - Schwartz, R.
AU  - Smith, N.A.
AU  - Kornai, A.
TI  - Morphosyntactic probing of multilingual BERT models
PY  - 2023
T2  - Natural Language Engineering
VL  - 1
IS  - 1
DO  - 10.1017/S1351324923000190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161321791&doi=10.1017%2fS1351324923000190&partnerID=40&md5=92981f23f267b885a8052ce234546706
AB  - We introduce an extensive dataset for multilingual probing of morphological information in language models (247 tasks across 42 languages from 10 families), each consisting of a sentence with a target word and a morphological tag as the desired label, derived from the Universal Dependencies treebanks. We find that pre-trained Transformer models (mBERT and XLM-RoBERTa) learn features that attain strong performance across these tasks. We then apply two methods to locate, for each probing task, where the disambiguating information resides in the input. The first is a new perturbation method that masks various parts of context; the second is the classical method of Shapley values. The most intriguing finding that emerges is a strong tendency for the preceding context to hold more information relevant to the prediction than the following context.  © The Author(s), 2023. Published by Cambridge University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Acs2023Morphosyntactic
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Zhang, D.
AU  - Wulamu, A.
TI  - Multi-view improved sequence behavior with adaptive multi-task learning in ranking
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 11
SP  - 13158
EP  - 13177
DO  - 10.1007/s10489-022-04088-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139502548&doi=10.1007%2fs10489-022-04088-w&partnerID=40&md5=29ee2af807f0419a80990013b852d8fc
AB  - Click through rate (CTR) and Conversion Rate (CVR) are core tasks in e-commerce recommender systems. Sequence behavior and multi-task learning have been widely used in CTR and CVR. Based on the concept of a transformer, we develop a technique of time and space feature representation for the prediction, which can capture high-level information better. In order to formulate user’s different interests from historical sequence behavior, we design multi-task learning to improve multiple objectives simultaneously. It is difficult to turn the super parameters as the tasks increasing. In this paper, we propose an adaptive learning mixture-of-experts approach, which tackles this challenge and can learn super parameters among tasks automatically. It not only saves resources but also improves the performance with cognitive of the model. Furthermore, to enhance the flexibility, we improve the loss function with a constrained joint strategy and introduce RESNET mechanism. We design feature-cross-unit module, augment-expert module, and topK-dispatch module, which assist multi-task learning to improve better. Experiments on public dataset and our library dataset demonstrate the superiority of our model over the state-of-art method. Our method achieves + 2.29% AUC gain in the CTR task and + 1.81% AUC gain in the CVR task, which is a significant improvement and demonstrates the effectiveness of proposed approach. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2023Multi-view
ER  -

TY  - JOUR
AU  - Jiang, J.
AU  - Zhang, R.
AU  - Ma, J.
AU  - Liu, Y.
AU  - Yang, E.
AU  - Du, S.
AU  - Zhao, Z.
AU  - Yuan, Y.
TI  - TranGRU: focusing on both the local and global information of molecules for molecular property prediction
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 12
SP  - 15246
EP  - 15260
DO  - 10.1007/s10489-022-04280-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141977189&doi=10.1007%2fs10489-022-04280-y&partnerID=40&md5=02028637377a7be3c7d4470bccd34be8
AB  - Molecular property prediction is an essential but challenging task in drug discovery. The recurrent neural network (RNN) and Transformer are the mainstream methods for sequence modeling, and both have been successfully applied independently for molecular property prediction. As the local information and global information of molecules are very important for molecular properties, we aim to integrate the bi-directional gated recurrent unit (BiGRU) into the original Transformer encoder, together with self-attention to better capture local and global molecular information simultaneously. To this end, we propose the TranGRU approach, which encodes the local and global information of molecules by using the BiGRU and self-attention, respectively. Then, we use a gate mechanism to reasonably fuse the two molecular representations. In this way, we enhance the ability of the proposed model to encode both local and global molecular information. Compared to the baselines and state-of-the-art methods when treating each task as a single-task classification on Tox21, the proposed approach outperforms the baselines on 9 out of 12 tasks and state-of-the-art methods on 5 out of 12 tasks. TranGRU also obtains the best ROC-AUC scores on BBBP, FDA, LogP, and Tox21 (multitask classification) and has a comparable performance on ToxCast, BACE, and ecoli. On the whole, TranGRU achieves better performance for molecular property prediction. The source code is available in GitHub: https://github.com/Jiangjing0122/TranGRU. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Jiang2023TranGRU
ER  -

TY  - JOUR
AU  - Gu, J.
AU  - Tian, F.
AU  - Oh, I.-S.
TI  - Retinal vessel segmentation based on self-distillation and implicit neural representation
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 12
SP  - 15027
EP  - 15044
DO  - 10.1007/s10489-022-04252-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141713788&doi=10.1007%2fs10489-022-04252-2&partnerID=40&md5=b132dd3c72e6a0b8cae35102b4ad31f6
AB  - Segmenting retinal blood vessels from retinal images is a crucial step in ocular disease diagnosis. It is also one of the most important applications and research in ophthalmic image analysis. However, the contrast between the retinal vessels and background in fundus images is low. The size and shape of retinal vessels vary significantly, and the width of some small vessels is often below 10 pixels or even 1 pixel. Moreover, some blood vessels are discontinuous owing to illumination, which complicates the segmentation of retinal blood vessels. To address these problems, this paper innovatively proposes a novel retinal vessel segmentation network framework based on self-distillation and implicit neural representation, which predicts retinal vessels in two stages. First, the self-distillation method extracts the main features of retinal images using the properties of Vision Transformer (ViT) to obtain preliminary images for the blood vessel segmentation. Second, implicit neural representation improves the resolution of the original retinal image, and the details of blood vessels are enhanced through the texture enhancement module to obtain accurate results of the blood vessel segmentation. Furthermore, we adopted an improved centerline dice (clDice) loss function to constrain the topology of blood vessels. We experimented on two benchmark retinal datasets (i.e., Drive and Chase) to quantitatively and qualitatively analyze the proposed method. The results indicate that the proposed outperformed the mainstream baseline. The visual segmentation results also show that this method can segment thin blood vessels more accurately and ensure the continuity of blood vessels. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Gu2023Retinal
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Chen, S.
AU  - Wulamu, A.
AU  - Guo, X.
AU  - Li, Q.
AU  - Zheng, H.
TI  - TransG-net: transformer and graph neural network based multi-modal data fusion network for molecular properties prediction
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 12
SP  - 16077
EP  - 16088
DO  - 10.1007/s10489-022-04351-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143163098&doi=10.1007%2fs10489-022-04351-0&partnerID=40&md5=9b118e26d5552e3473f3ff504f74c7a5
AB  - Molecular properties prediction is an important task in the field of materials, especially in computational drug and materials discovery. Deep learning (DL) is one of the most popular methods for molecular properties prediction due to its ability to establish quantitative relationships between molecular representations and target properties. In order to improve the performance of DL algorithms, it is crucial to select appropriate representation of molecules. Molecular graph has become one of the choices as it can be easily input into graph neural network (GNN)-based DL models for learning. However, model performance is limited if molecular representation is only used because it only contains atomic information, bond information, and adjacency relationships between atoms. Therefore, we use molecular mass spectrum as another representation to provide supplement information which is not contained in the graph data. In this paper, a transformer-based model, named Mass Spectrum Transformer (MST), is proposed to perform quantitative analysis of molecular spectra, then it is combined with the graph neural network to form a multi-modal data fusion model TransG-Net for accurate molecular properties prediction. Several feature fusion methods are adopted and the best method is chosen to further enhance the performance of the model. A multi-modal dataset is collected in this paper which is composed of molecular graph data and spectra. Data augmentation is performed to simulate the experimentally measured molecular spectra for the generalizability of the model. Experimental results show that MST outperforms previous best mass spectrum-based methods for molecular properties prediction. In addition, TransG-Net combining MST and GNN achieves better performance than state-of-the-art well-designed message passing models, which proves the effectiveness of our multi-modal data fusion method. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhang2023TransG-net
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Chen, C.L.P.
AU  - Yuan, H.
AU  - Zhang, T.
TI  - Semantic Learning for Facial Action Unit Detection
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 3
SP  - 1372
EP  - 1380
DO  - 10.1109/TCSS.2022.3166133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128689613&doi=10.1109%2fTCSS.2022.3166133&partnerID=40&md5=57c08a28d96cddf1ed49b2881459544f
AB  - This article proposes semantic embedding for image transformers (SEiTs) to explore semantic features of facial morphology in the action unit (AU) detection task. The conventional approaches typically rely on external information (e.g., facial landmarks) to obtain the location of facial components, whereas the SEiT can learn morphological features intrinsically from the face image. The pre-training task, namely semantic masked facial image modeling (SMFIM), aims to actively obtain facial morphological information. The pixels of the input facial image are randomly erased with semantic masks (e.g., nose, eyes, eyebrows, mouth, and lip). The embedding model tries to predict the presence of facial components for the input image that can learn semantic representations of the face simultaneously. The learned semantic embeddings are fed to transformer blocks, which enable global interaction between semantic elements. The SEiT integrates facial morphological information and global interaction characters, appropriate for AU detection. The experiments are conducted on the Binghamton-Pittsburgh 4D (BP4D) dataset and Denver intensity of spontaneous facial action (DISFA) dataset, and the results demonstrate the effectiveness of the proposed SEiT.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Wang2023Semantic
ER  -

TY  - JOUR
AU  - Khan, P.I.
AU  - Razzak, I.
AU  - Dengel, A.
AU  - Ahmed, S.
TI  - Performance Comparison of Transformer-Based Models on Twitter Health Mention Classification
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 3
SP  - 1140
EP  - 1149
DO  - 10.1109/TCSS.2022.3143768
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125332790&doi=10.1109%2fTCSS.2022.3143768&partnerID=40&md5=87bd01dd055a6981f1d430c6df2681a2
AB  - Health mention classification classifies a given piece of text as a health mention or not. However, figurative usage of disease words makes the classification task challenging. To address this challenge, consideration of emojis and surrounding words of the disease names in the text can be helpful. Transformer-based methods are better at capturing the meaning of a word based on its surrounding words compared to traditional methods. However, there are numerous transformer-based methods available and pretrained on natural language processing (NLP) data that are inherently different from Twitter data. Moreover, the size of these models varies in terms of the number of parameters. Hence, it is challenging to decide and choose one of these methods for fine-tuning it on the downstream tasks such as tweet classification. In this work, we experiment with nine widely used transformer methods and compare their performance on the personal health mention classification of tweet data. Furthermore, we analyze the impact of model size on the classification task and provide a brief interpretation of the classification decision made by the best performing classifier. Experimental results show that RoBERTa outperforms all other models by achieving an F1 score of 93%, while two other models perform similarly by achieving an F1 score of 92.5%.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Khan2023Performance
ER  -

TY  - JOUR
AU  - Singh, G.V.
AU  - Firdaus, M.
AU  - Ekbal, A.
AU  - Bhattacharyya, P.
TI  - Unity in Diversity: Multilabel Emoji Identification in Tweets
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 3
SP  - 1029
EP  - 1038
DO  - 10.1109/TCSS.2022.3162865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128321912&doi=10.1109%2fTCSS.2022.3162865&partnerID=40&md5=a871454e39fa808480715268746eab88
AB  - Emojis or emoticons are not just a modern trend but have become an essential part of our day-to-day interactions. Predicting a suitable emoji for a given tweet is a challenging task because a wrong emoji prediction for a tweet can change the meaning of the message or can amplify the emotion of the message. This task is particularly challenging since it requires selecting an appropriate emoji from a huge list of prospective emojis that may or may not be equivalent to one another. Humans use multiple emojis to convey their emotions, thereby making the task a multilabel classification problem. In this article, we propose a multilabel emoji prediction system that predicts the appropriate emoji for a given tweet by using different state-of-the-art baselines. Due to the unavailability of a multi-emoji dataset, we create a large-scale multilabel emoji dataset named Mu-Emoji that comprises of more than 0.6 million tweets having varied emojis belonging to both positive and negative sentiments. For our proposed task, we employ graph attention network along with bidirectional encoder representations from transformer encoder for the accurate prediction of emojis. Qualitative and quantitative analyses show that our multilabel emoji prediction baselines perform well compared with the single-emoji prediction baselines for our proposed Mu-Emoji dataset. Our proposed framework also outperforms all the baselines for both single and multilabel emoji prediction tasks.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Singh2023Unity
ER  -

TY  - JOUR
AU  - Wu, B.
AU  - Wang, L.
AU  - Zeng, Y.-R.
TI  - Interpretable tourism demand forecasting with temporal fusion transformers amid COVID-19
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 11
SP  - 14493
EP  - 14514
DO  - 10.1007/s10489-022-04254-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140853284&doi=10.1007%2fs10489-022-04254-0&partnerID=40&md5=d6786398162d1b2bca9062d13390681e
AB  - An innovative ADE-TFT interpretable tourism demand forecasting model was proposed to address the issue of the insufficient interpretability of existing tourism demand forecasting. This model effectively optimizes the parameters of the Temporal Fusion Transformer (TFT) using an adaptive differential evolution algorithm (ADE). TFT is a brand-new attention-based deep learning model that excels in prediction research by fusing high-performance prediction with time-dynamic interpretable analysis. The TFT model can produce explicable predictions of tourism demand, including attention analysis of time steps and the ranking of input factors’ relevance. While doing so, this study adds something unique to the literature on tourism by using historical tourism volume, monthly new confirmed cases of travel destinations, and big data from travel forums and search engines to increase the precision of forecasting tourist volume during the COVID-19 pandemic. The mood of travelers and the many subjects they spoke about throughout off-season and peak travel periods were examined using a convolutional neural network model. In addition, a novel technique for choosing keywords from Google Trends was suggested. In other words, the Latent Dirichlet Allocation topic model was used to categorize the major travel-related subjects of forum postings, after which the most relevant search terms for each topic were determined. According to the findings, it is possible to estimate tourism demand during the COVID-19 pandemic by combining quantitative and emotion-based characteristics. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Wu2023Interpretable
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Zhang, C.
AU  - Guo, J.
AU  - Peng, C.
AU  - Niu, Z.
AU  - Wu, X.
TI  - Graph attention network with dynamic representation of relations for knowledge graph completion
PY  - 2023
T2  - Expert Systems with Applications
VL  - 219
C7  - 119616
DO  - 10.1016/j.eswa.2023.119616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147607411&doi=10.1016%2fj.eswa.2023.119616&partnerID=40&md5=4a42651492afc027c0c114d5b1684dca
AB  - Knowledge graph completion (KGC) aims to predict the missing element in a triple based on known triples or facts. Recently, plenty of representation learning methods for KGC have achieved the promising performance, especially ones based on graph neural networks and their variants. Those methods exploit local neighborhood information to update the embedding of target entities. However, the existing works have the following two problems. First, those approaches focus on the representation learning of entities, while the relation representation usually adopts a simple linear transformation, which cannot capture the distinctive semantic intensions of the same relation in different triples. Second, different types of entity information are simply combined together, resulting in the loss of global properties including the type and the global importance of entities, which is prone to cause over-smoothing phenomenon. To address these two problems, we propose a Graph Attention Network with Dynamic Representation of Relations and global information (DRR-GAT) for knowledge graph completion. Specifically, the task of dynamic representation of relations is to learn the distinctive representation of the same relation in different triples. This goal is achieved via a path Transformer. To this end, path Transformer is designed to take the path information as its input, where only those paths from the target entity to the neighborhood relations with the same type as the target relation are considered. Sequentially, the mechanism of global embeddings is incorporated into graph attention network to capture the global information of entities and relations. Experimental performance outperforms the state-of-the-art methods, indicating the effectiveness of our proposed approach. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2023Graph
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Yang, S.
AU  - Song, Y.
AU  - Luo, Y.
AU  - Li, J.
AU  - Zhou, T.
TI  - Spatial dynamic graph convolutional network for traffic flow forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 12
SP  - 14986
EP  - 14998
DO  - 10.1007/s10489-022-04271-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141514192&doi=10.1007%2fs10489-022-04271-z&partnerID=40&md5=10ed611f5ccc63061280fef7b03f1868
AB  - The complex traffic network spatial correlation and the characteristic of high nonlinear and dynamic traffic conditions in the time are the challenges to accurate traffic flow forecasting. Existing spatiotemporal models attempt to utilize the static graph to explore spatial dependency and employ RNN-based model to capture temporal dependency. However, the static graph fails to reflect the dynamic changeable correlation between each node. That is some nodes have a strong connection in a real traffic network, whereas a weak connection is in a static predefined graph. To overcome the above problems, we propose a spatial dynamic graph convolutional network (SDGCN) for traffic flow forecasting. With the support of an attention fusion network in graph learning, SDGCN generates the dynamic graph at each time step, which can model the changeable spatial correlation from traffic data. By embedding dynamic graph diffusion convolution into gated recurrent unit, our model can explore spatio-temporal dependency simultaneously. Moreover, to handle long sequence forecasting, ReZero transformer is utilized to detect the global temporal correlation capturing. The experiments are conducted on two public datasets. The experimental results demonstrate the superior performance of our network. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Li2023Spatial
ER  -

TY  - JOUR
AU  - Wen, Y.
AU  - Xu, P.
AU  - Li, Z.
AU  - Xu, W.
AU  - Wang, X.
TI  - RPConvformer: A novel Transformer-based deep neural networks for traffic flow prediction
PY  - 2023
T2  - Expert Systems with Applications
VL  - 218
C7  - 119587
DO  - 10.1016/j.eswa.2023.119587
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147194747&doi=10.1016%2fj.eswa.2023.119587&partnerID=40&md5=e34d9ce8363e31544dda2013863f4cd0
AB  - Traffic prediction problem is one of the essential tasks of intelligent transportation system (ITS), alleviating traffic congestion effectively and promoting the intelligent development of urban traffic. To accommodate long-range dependencies, Transformer-based methods have been used in traffic prediction tasks due to the parallelizable processing of sequences and explanation of attention matrices compared with recurrent neural units (RNNs). However, the Transformer-based model has two limitations, on the one hand, it ignores the local correlation in the traffic state in its parallel processing of the sequence, on the other hand, the absolute positional embedding is adopted to represent the positional relationship of time nodes is destroyed when it comes to calculate attention score. To address two embarrassing shortcomings, a novel framework called RPConvformer is proposed, where the improved parts are 1D causal convolutional sequence embedding and relative position encoding. In sequence embedding, we develop a sequence embedding layer composed of convolutional units, which consist of origin 1D convolutional and 1D causal convolutional. The size of the receptive field of the convolution can focus on the local region correlation of the sequence. In relative position encoding, we introduce a bias vector to automatically learn the relative position information of time nodes when linearly mapping the feature tensor. We respect the encoding and decoding framework of the Transformer, the encoder is responsible for extracting historical traffic state information, and the decoder autoregressively predicts the future traffic state. The multi-head attention mechanism is adopted by both encoder and decoder aims to focus on rich temporal feature patterns. Moreover, key mask technique is used after computing attention matrix to mask the traffic state at missing moments improving the resilience of the model. Extensive experiments on two real-world traffic flow datasets. The results show that RPConvformer achieves the best performance compared to state-of-the-art time series models. Ablation experiments show that considering the local correlation of time series has a higher gain on prediction performance. Random mask experiments show that the model is robust when the historical data is less than 10% missing. In addition, multi-head attention matrix provides further explanation for the dependence between time nodes. RPConvformer as an improved Transformer-based model can provide new ideas for molding temporal dimension in traffic prediction tasks. Our code has been open-sourced at (https://github.com/YanJieWen/RPConvformer). © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wen2023RPConvformer
ER  -

TY  - JOUR
AU  - Vasilakes, J.
AU  - Georgiadis, P.
AU  - Nguyen, N.T.H.
AU  - Miwa, M.
AU  - Ananiadou, S.
TI  - Contextualized medication event extraction with levitated markers
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 141
C7  - 104347
DO  - 10.1016/j.jbi.2023.104347
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152946025&doi=10.1016%2fj.jbi.2023.104347&partnerID=40&md5=77db0a572ebd7b0b3df813378cec40d0
AB  - Automatic extraction of patient medication histories from free-text clinical notes can increase the amount of relevant information to clinicians for developing treatment plans. In addition to detecting medication events, clinical text mining systems must also be able to predict event context, such as negation, uncertainty, and time of occurrence, in order to construct accurate patient timelines. Towards this goal, we introduce Levitated Context Markers (LCMs), a novel transformer-based model for contextualized event extraction. LCMs are an adaptation of levitated markers —originally developed for relation extraction— that allow pretrained transformer models to utilize global input representations while also focusing on event-related subspans using a sparse attention mechanism. In addition to outperforming a strong baseline model on the Contextualized Medication Event Dataset, we show that LCMs’ sparse attention can provide interpretable predictions by detecting relevant context cues in an unsupervised manner. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Vasilakes2023Contextualized
ER  -

TY  - JOUR
AU  - Lå rincz, B.
AU  - Irimia, E.
AU  - Stan, A.
AU  - Barbu Mititelu, V.
TI  - RoLEX: The development of an extended Romanian lexical dataset and its evaluation at predicting concurrent lexical information
PY  - 2023
T2  - Natural Language Engineering
VL  - 29
IS  - 3
SP  - 720
EP  - 745
DO  - 10.1017/S1351324922000419
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142450713&doi=10.1017%2fS1351324922000419&partnerID=40&md5=8b69017dba710ce6f0f140cd77db1819
AB  - In this article, we introduce an extended, freely available resource for the Romanian language, named RoLEX. The dataset was developed mainly for speech processing applications, yet its applicability extends beyond this domain. RoLEX includes over 330,000 curated entries with information regarding lemma, morphosyntactic description, syllabification, lexical stress and phonemic transcription. The process of selecting the list of word entries and semi-automatically annotating the complete lexical information associated with each of the entries is thoroughly described. The dataset's inherent knowledge is then evaluated in a task of concurrent prediction of syllabification, lexical stress marking and phonemic transcription. The evaluation looked into several dataset design factors, such as the minimum viable number of entries for correct prediction, the optimisation of the minimum number of required entries through expert selection and the augmentation of the input with morphosyntactic information, as well as the influence of each task in the overall accuracy. The best results were obtained when the orthographic form of the entries was augmented with the complete morphosyntactic tags. A word error rate of 3.08% and a character error rate of 1.08% were obtained this way. We show that using a carefully selected subset of entries for training can result in a similar performance to the performance obtained by a larger set of randomly selected entries (twice as many). In terms of prediction complexity, the lexical stress marking posed most problems and accounts for around 60% of the errors in the predicted sequence.  © The Author(s), 2022. Published by Cambridge University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Lå rincz2023RoLEX
ER  -

TY  - JOUR
AU  - Mo, D.
AU  - Zou, X.
AU  - Pang, K.
AU  - Wong, W.K.
TI  - Towards private stylists via personalized compatibility learning
PY  - 2023
T2  - Expert Systems with Applications
VL  - 219
C7  - 119632
DO  - 10.1016/j.eswa.2023.119632
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148058511&doi=10.1016%2fj.eswa.2023.119632&partnerID=40&md5=1046e3115ca79cf14f6c262baad30136
AB  - Personalized outfit compatibility learning is an emerging yet challenging task. Most of the existing methods focus on general outfit compatibility learning. Although a few works have been proposed for personalized fashion compatibility, they either considered user preference on fashion items with specific patterns or design elements or recommended outfits based on the overall visual similarity according to the users’ preferred collections. This paper adopts physical and fashion attributes for effective personalized fashion compatibility evaluation and recommendation. The physical attributes are concluded into seven aspects: body shape, skin color, hairstyle, hair color, height, breast size (breasts), and color contrast. The personalized outfit compatibility problem in this paper is a multi-label classification problem and formulated as an optimization function with outfit images, fashion attributes, and physical attributes as input. It is the first attempt to solve the problem by discovering the correlation between visual image features, fashion attributes, and physical attributes. Specifically, the correlation is learned with two transformer encoders by updating attention weights of different embedding pairs during the training process. The model can not only predict the fashion attributes of the outfit's top, bottom, shoes, and bag items, but also predict the incompatible physical attributes of an individual towards the given outfit. It can be used to recommend outfits that best fit an individual and the predicted fashion attributes can be used for result explanation. The O4U dataset, which contains rich annotations of fashion item attributes and human physical attributes of the outfits, is used to evaluate the performance of the proposed method. The quantitative and qualitative results show that the proposed method outperforms state-of-the-art methods for personalized outfit compatibility evaluation. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Mo2023Towards
ER  -

TY  - JOUR
AU  - Mishra, K.
AU  - Firdaus, M.
AU  - Ekbal, A.
TI  - Predicting Politeness Variations in Goal-Oriented Conversations
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 3
SP  - 1095
EP  - 1104
DO  - 10.1109/TCSS.2022.3156580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126683878&doi=10.1109%2fTCSS.2022.3156580&partnerID=40&md5=1c37fcd8582c9e34a1099d92607f49c2
AB  - Politeness is an expression in language that eases the conversation toward a positive undertone. If there is a display of rudeness, even the finest communication can fall through. In addition, if lathered with politeness, even the most angst-prone scenario can be expressed with far less hurt. In this article, we address the task of identifying politeness in goal-oriented dialog systems. In this regard, we create politeness-annotated conversational data (PACD) utilizing Microsoft Dialogue Challenge and DSTC1 datasets. For correctly identifying the politeness, we employ a hierarchical transformer network that effectively captures the contextual information (i.e., previous utterances) and current input for predicting the politeness in a given utterance of a dialog. Empirical results demonstrate that our proposed approach outperforms all the defined baselines. Furthermore, through in- and cross-domain experiments, we show the necessity of a PACD to mitigate acts such as rude requests or insults for both socially interactive and task-oriented dialog systems.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Mishra2023Predicting
ER  -

TY  - JOUR
AU  - Ding, J.
AU  - Li, W.
AU  - Pei, L.
AU  - Yang, M.
AU  - Ye, C.
AU  - Yuan, B.
TI  - Sw-YoloX: An anchor-free detector based transformer for sea surface object detection
PY  - 2023
T2  - Expert Systems with Applications
VL  - 217
C7  - 119560
DO  - 10.1016/j.eswa.2023.119560
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146434903&doi=10.1016%2fj.eswa.2023.119560&partnerID=40&md5=da062a1a50782e2b6902b41fea4550fd
AB  - To cope with the challenge of blurred images of sea surface objects caused by the complex and undulating sea surface environment, we propose Sw-YoloX, which can utilize the global modeling ability to encode the key semantics of sea surface objects, thereby obtaining global features that cannot be captured by CNN. Then the convolutional block attention module (CBAM) and atrous spatial pyramid pooling (ASPP) module are integrated in the neck of the detector, and the decoupled head is used as the prediction part. In addition, we also integrate multiple training strategies to effectively improve the detector performance, such as simple optimal transport assignment (SimOTA) strategy and multi-model integration. Finally, we construct the XM-10000 dataset for validation based on sea surface monitoring data in Xiamen, China. With end-to-end training, Sw-YoloX achieves higher performance than baseline and mainstream detector, with F1-Score is 78.1, mean average precision (mAP) is 54.4, and average recall (AR) is 72.0. This research, which has now been deployed in the coastal defense department in Xiamen, China, has important implications for searching for survivors and preventing smuggling. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ding2023Sw-YoloX
ER  -

TY  - JOUR
AU  - Nassiri, K.
AU  - Akhloufi, M.
TI  - Transformer models used for text-based question answering systems
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 9
SP  - 10602
EP  - 10635
DO  - 10.1007/s10489-022-04052-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136985600&doi=10.1007%2fs10489-022-04052-8&partnerID=40&md5=5e82229ac8521b1ab677d5e69ef3b290
AB  - The question answering system is frequently applied in the area of natural language processing (NLP) because of the wide variety of applications. It consists of answering questions using natural language. The problem is, in general, solved by employing a dataset that consists of an input text, a query, and the text segment or span from the input text that provides the question’s answer. The ability to make human-level predictions from data has improved significantly thanks to deep learning models, particularly the Transformer architecture, which has been state-of-the-art in text-based models in recent years. This paper reviews studies related to the use of transformer models in the implementation of question-answering (QA) systems. The paper’s first focus is on the attention and transformer models. A brief description of the architectures is presented by classifying them into models based on encoders, decoders, and on both Encoder-Decoder. Following that, we examine the most recent research trends in textual QA datasets by highlighting the architecture of QA systems and categorizing them according to various criteria. We survey also a significant set of evaluation metrics that have been developed in order to evaluate the models’ performance. Finally, we highlight solutions built to simplify the implementation of Transformer models. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 45
C2  - CCF:C期刊; 
LB  - Nassiri2023Transformer
ER  -

TY  - JOUR
AU  - Zhang, H.-B.
AU  - Cheng, D.-J.
AU  - Zhou, K.-L.
AU  - Zhang, S.-W.
TI  - Deep transfer learning-based hierarchical adaptive remaining useful life prediction of bearings considering the correlation of multistage degradation
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 266
C7  - 110391
DO  - 10.1016/j.knosys.2023.110391
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149402610&doi=10.1016%2fj.knosys.2023.110391&partnerID=40&md5=ba4594ba3e4a8a458e9689b562dd12d6
AB  - The multi-stage degradation process of bearings significantly affects the predicted performance of rotating machinery and equipment in long-term operation. However, the inherent correlations between degradation stages, and domain-invariant degradation features of multistage that affect the remaining useful life (RUL) are mostly ignored, leading to RUL prognostics deterioration under cross-working conditions. Therefore, a novel deep transfer learning-based hierarchical adaptive RUL prediction approach is applied to overcome this problem. Firstly, a novel multistage degradation (MD) division method is proposed with a combination of maximum mean discrepancy and statistical process analysis to accurately obtain the varied health indicators (HIs) with MD without setting any threshold. Then, the obtained MD features are fed into the residual network to automatically recognize the HIs and MD in response to multi-variability trend changes. Finally, a novel hierarchical adaptive RUL model based on a deep adaptive-transformer is proposed to transfer the learned domain-invariant degradation features of multistage from one to various working conditions. Meanwhile, hierarchical adaptive tuning (HAT) reduces the RUL model loss to guarantee a more accurate prediction of each degradation stage. To validate the proposed approach, extensive experiments were conducted in seven cross-domain cases on the XJTU-SY dataset to predict RUL. Comparison results indicate that the proposed approach is more accurate than other conventional methods because it considers the RUL of bearing at each stage. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; FMS:C; 
LB  - Zhang2023Deep
ER  -

TY  - JOUR
AU  - Gao, Z.
AU  - Yang, L.
AU  - Dai, Y.
TI  - Fast Adaptive Task Offloading and Resource Allocation via Multiagent Reinforcement Learning in Heterogeneous Vehicular Fog Computing
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 8
SP  - 6818
EP  - 6835
DO  - 10.1109/JIOT.2022.3228246
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144761162&doi=10.1109%2fJIOT.2022.3228246&partnerID=40&md5=3c646747a2a1d816e52f6f547e31c2f5
AB  - In vehicular fog computing, task offloading enables mobile vehicles (MVs) to offer ultralow latency services for computation-intensive tasks. Nevertheless, the edge server (ES) may have a high load when a large number of MVs offload their tasks to it, causing many tasks either experience long processing times or being dropped, particularly for latency-sensitive tasks. Moreover, most existing methods are largely limited to training a model from scratch for new environments. This is because they focus more on model structures with fixed input and output sizes, impeding the transfer of trained models across different environments. To solve these problems, we propose a decentralized task offloading method based on transformer and policy decoupling-based multiagent actor-critic (TPDMAAC). We first introduce a transformer-based long sequence forecasting network (TLSFN) for predicting the current and future queuing delay of ESs to solve uncertain load. Second, we redesign the actor-network using transformer-based temporal feature extraction network (TTFEN) and policy decoupling network (PDN). TTFEN can adapt to various input sizes through a transformer that accepts different tokens we build from the raw input. PDN provides a mapping between the transformer-based embedding features and offloading policies utilizing self-attention mechanism to address various output dimensions. Finally, the experiments on two real-world data sets show that TPDMAAC can quickly adapt to a new environment. And compared to existing algorithms, TPDMAAC reduces the system cost by 11.01%-12.03% as well as improves task completion rates by 10.45%-13.56%.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Gao2023Fast
ER  -

TY  - JOUR
AU  - Gao, J.
AU  - He, S.
AU  - Hu, J.
AU  - Chen, G.
TI  - A hybrid system to understand the relations between assessments and plans in progress notes
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 141
C7  - 104363
DO  - 10.1016/j.jbi.2023.104363
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152479749&doi=10.1016%2fj.jbi.2023.104363&partnerID=40&md5=b8b7a3d77388467b977efe94467abda6
AB  - Objective: The paper presents a novel solution to the 2022 National NLP Clinical Challenges (n2c2) Track 3, which aims to predict the relations between assessment and plan subsections in progress notes. Methods: Our approach goes beyond standard transformer models and incorporates external information such as medical ontology and order information to comprehend the semantics of progress notes. We fine-tuned transformers to understand the textual data and incorporated medical ontology concepts and their relationships to enhance the model's accuracy. We also captured order information that regular transformers cannot by taking into account the position of the assessment and plan subsections in progress notes. Results: Our submission earned third place in the challenge phase with a macro-F1 score of 0.811. After refining our pipeline further, we achieved a macro-F1 of 0.826, outperforming the top-performing system during the challenge phase. Conclusion: Our approach, which combines fine-tuned transformers, medical ontology, and order information, outperformed other systems in predicting the relationships between assessment and plan subsections in progress notes. This highlights the importance of incorporating external information beyond textual data in natural language processing (NLP) tasks related to medical documentation. Our work could potentially improve the efficiency and accuracy of progress note analysis. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Gao2023hybrid
ER  -

TY  - JOUR
AU  - Moscato, V.
AU  - Postiglione, M.
AU  - Sansone, C.
AU  - Sperli, G.
TI  - TaughtNet: Learning Multi-Task Biomedical Named Entity Recognition From Single-Task Teachers
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 5
SP  - 2512
EP  - 2523
DO  - 10.1109/JBHI.2023.3244044
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149408597&doi=10.1109%2fJBHI.2023.3244044&partnerID=40&md5=70bada83e195c8afff448772f137d253
AB  - In Biomedical Named Entity Recognition (BioNER), the use of current cutting-edge deep learning-based methods, such as deep bidirectional transformers (e.g. BERT, GPT-3), can be substantially hampered by the absence of publicly accessible annotated datasets. When the BioNER system is required to annotate multiple entity types, various challenges arise because the majority of current publicly available datasets contain annotations for just one entity type: for example, mentions of disease entities may not be annotated in a dataset specialized in the recognition of drugs, resulting in a poor ground truth when using the two datasets to train a single multi-task model. In this work, we propose TaughtNet, a knowledge distillation-based framework allowing us to fine-tune a single multi-task student model by leveraging both the ground truth and the knowledge of single-task teachers. Our experiments on the recognition of mentions of diseases, chemical compounds and genes show the appropriateness and relevance of our approach w.r.t. strong state-of-the-art baselines in terms of precision, recall and F1 scores. Moreover, TaughtNet allows us to train smaller and lighter student models, which may be easier to be used in real-world scenarios, where they have to be deployed on limited-memory hardware devices and guarantee fast inferences, and shows a high potential to provide explainability. We publicly release both our code on github1 and our multi-task model on the huggingface repository.2. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Moscato2023TaughtNet
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Liu, H.
AU  - Du, J.
AU  - Yang, Z.
AU  - Dong, X.
TI  - CLformer: Locally grouped auto-correlation and convolutional transformer for long-term multivariate time series forecasting
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 121
C7  - 106042
DO  - 10.1016/j.engappai.2023.106042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148698143&doi=10.1016%2fj.engappai.2023.106042&partnerID=40&md5=3689087c54291b38e1aed7d8196d8308
AB  - Improving the performance of long-term time series forecasting is important for real-world applications. Recently, Transformer-based models have achieved significant performance gains in long-term time series prediction. However, these models are memory-intensive and cannot capture temporal patterns at multiple scales. To this end, we propose to integrate the time series decomposition method in the Transformer framework to enable the model to extract short- and long-term time patterns in more predictable seasonal and trend components. In this paper, we propose a Transformer-based model named CLformer. Different from previous methods, we exploit dilated convolutional networks to capture and refine multiple temporally repeated patterns in time series before time series decomposition. To enable the model to capture the dependencies at multiple scales, we propose a local group autocorrelation (LGAC) mechanism. The LGAC mechanism calculates autocorrelation within time series segments, strengthening the model's ability to capture the local temporal dynamics of series. The stacking of multiple LGAC layers enables the model to capture multi-scale dependencies, which in turn improves the model's predictive performance. The CLformer outperforms models using the global autocorrelation mechanism and self-attention in both efficiency and accuracy. Experimental results on six benchmark datasets show that our model obtains a relative performance improvement of 11.75% compared to the state-of-the-art methods. In addition, CLformer achieves a relative performance improvement of 18.89% on two datasets without apparent periodicity, demonstrating the effectiveness of our model on time series without significant periodicity. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; 
LB  - Wang2023CLformer
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Luo, L.
AU  - Dou, Q.
AU  - Heng, P.-A.
TI  - Triplet attention and dual-pool contrastive learning for clinic-driven multi-label medical image classification
PY  - 2023
T2  - Medical Image Analysis
VL  - 86
C7  - 102772
DO  - 10.1016/j.media.2023.102772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148542568&doi=10.1016%2fj.media.2023.102772&partnerID=40&md5=cf9c376a5e18247ead5d82d1e6cbe8c8
AB  - Multi-label classification (MLC) can attach multiple labels on single image, and has achieved promising results on medical images. But existing MLC methods still face challenging clinical realities in practical use, such as: (1) medical risks arising from misclassification, (2) sample imbalance problem among different diseases, (3) inability to classify the diseases that are not pre-defined (unseen diseases). Here, we design a hybrid label to improve the flexibility of MLC methods and alleviate the sample imbalance problem. Specifically, in the labeled training set, we remain independent labels for high-frequency diseases with enough samples and use a hybrid label to merge low-frequency diseases with fewer samples. The hybrid label can also be used to put unseen diseases in practical use. In this paper, we propose Triplet Attention and Dual-pool Contrastive Learning (TA-DCL) for multi-label medical image classification based on the aforementioned label representation. TA-DCL architecture is a triplet attention network (TAN), which combines category-attention, self-attention and cross-attention together to learn high-quality label embeddings for all disease labels by mining effective information from medical images. DCL includes dual-pool contrastive training (DCT) and dual-pool contrastive inference (DCI). DCT optimizes the clustering centers of label embeddings belonging to different disease labels to improve the discrimination of label embeddings. DCI relieves the error classification of sick cases for reducing the clinical risk and improving the ability to detect unseen diseases by contrast of differences. TA-DCL is validated on two public medical image datasets, ODIR and NIH-ChestXray14, showing superior performance than other state-of-the-art MLC methods. Code is available at https://github.com/ZhangYH0502/TA-DCL. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:C期刊; 
LB  - Zhang2023Triplet
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Zhang, P.
AU  - Song, F.
AU  - Sun, Y.
AU  - Fan, G.
AU  - Zhang, T.
AU  - Feng, Y.
AU  - Zhang, G.
TI  - KD-Informer: A Cuff-Less Continuous Blood Pressure Waveform Estimation Approach Based on Single Photoplethysmography
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 5
SP  - 2219
EP  - 2230
DO  - 10.1109/JBHI.2022.3181328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132754889&doi=10.1109%2fJBHI.2022.3181328&partnerID=40&md5=d8a6db235dd19cb9d2da3158b63b6f6c
AB  - Ambulatory blood pressure (BP) monitoring plays a critical role in the early prevention and diagnosis of cardiovascular diseases. However, cuff-based inflatable devices cannot be used for continuous BP monitoring, while pulse transit time or multi-parameter-based methods require more bioelectrodes to acquire electrocardiogram signals. Thus, estimating the BP waveforms only based on photoplethysmography (PPG) signals for continuous BP monitoring has essential clinical values. Nevertheless, extracting useful features from raw PPG signals for fine-grained BP waveform estimation is challenging due to the physiological variation and noise interference. For single PPG analysis utilizing deep learning methods, the previous works depend mainly on stacked convolution operation, which ignores the underlying complementary time-dependent information. Thus, this work presents a novel Transformer-based method with knowledge distillation (KD-Informer) for BP waveform estimation. Meanwhile, we integrate the prior information of PPG patterns, selected by a novel backward elimination algorithm, into the knowledge transfer branch of the KD-Informer. With these strategies, the model can effectively capture the discriminative features through a lightweight architecture during the learning process. Then, we further adopt an effective transfer learning technique to demonstrate the excellent generalization capability of the proposed model using two independent multicenter datasets. Specifically, we first fine-tuned the KD-Informer with a large and high-quality dataset (Mindray dataset) and then transferred the pre-trained model to the target domain (MIMIC dataset). The experimental test results on the MIMIC dataset showed that the KD-Informer exhibited an estimation error of 0.02 ± 5.93 mmHg for systolic BP (SBP) and 0.01 ± 3.87 mmHg for diastolic BP (DBP), which complied with the association for the advancement of medical instrumentation (AAMI) standard. These results demonstrate that the KD-Informer has high reliability and elegant robustness to measure continuous BP waveforms.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:C期刊; 
LB  - Ma2023KD-Informer
ER  -

TY  - JOUR
AU  - Shan, B.
AU  - Shi, Q.
AU  - Yang, F.
TI  - MSRT: multi-scale representation transformer for regression-based human pose estimation
PY  - 2023
T2  - Pattern Analysis and Applications
VL  - 26
IS  - 2
SP  - 591
EP  - 603
DO  - 10.1007/s10044-023-01130-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147281055&doi=10.1007%2fs10044-023-01130-6&partnerID=40&md5=c836c7d1e2d61d1d9db9ef91df859a7e
AB  - In this paper, we are interested in the human pose estimation problem with a focus on leveraging discriminative pose features. Recent pose estimation works concentrate on extracting high-level features but ignore the low-level details, thus reducing the prediction accuracy. To mitigate the above issues, we propose an end-to-end method called multi-scale representation transformer network (MSRT). Our network consists of two key components: feature aggregation module (FAM) and transformers. The FAM splits and stacks feature maps of different scales, then fuses them to achieve multi-scale representation learning. This module makes up for the lack of detailed information in the high-level features. Furthermore, we utilize Transformers to identify long-range interactions among feature maps, and capture implicit body structure information, which allows the proposed network to refine the locations of terminal and occluded joints. Compared with existing regression-based methods, MSRT achieves superior results on the COCO2017 and MPII datasets. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Shan2023MSRT
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Kang, Y.
AU  - Li, H.
AU  - Wang, H.
AU  - Yang, X.
TI  - STGHTN: Spatial-temporal gated hybrid transformer network for traffic flow forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 10
SP  - 12472
EP  - 12488
DO  - 10.1007/s10489-022-04122-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139140366&doi=10.1007%2fs10489-022-04122-x&partnerID=40&md5=82616207d73af7d74ba3c9440dc43ead
AB  - Accurate traffic forecasting is a critical function of intelligent transportation systems, which remains challenging due to the complex spatial and temporal dependence of traffic data. GNN-based traffic forecasting models typically utilize predefined graphical structures based on prior knowledge and do not adapt well to dynamically changing traffic characteristics, which may limit their performance. The transformer is a compelling architecture with an innate global self-attention mechanism, but cannot capture low-level detail very well. In this paper, we propose a novel Spatial-Temporal Gated Hybrid Transformer Network (STGHTN), which leverages local features from temporal gated convolution, spatial gated graph convolution respectively and global features by transformer to further improve the traffic flow forecasting results. First, in the temporal dimension, we take full advantage of the local properties of temporal gated convolution and the global properties of transformer to effectively fuse short-term and long-term temporal dependence. Second, we mutually integrate two modules to complement each representation by utilizing spatial gated graph convolution to extract local spatial dependence and transformer to extract global spatial dependence. Furthermore, we propose a multi-graph model that constructs a road connection graph, a similarity graph, and an adaptive dynamic graph to exploit the static and dynamic associations between road networks. Experiments on four real datasets confirm the proposed method’s state-of-the-art performance. Our implementation of the STGHTN code via PyTorch is available at https://github.com/JianSoL/STGHTN. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; 
LB  - Liu2023STGHTN
ER  -

TY  - JOUR
AU  - Zhao, G.
AU  - Yang, P.
AU  - Yao, Y.
TI  - RERG: Reinforced evidence reasoning with graph neural network for table-based fact verification
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 10
SP  - 12308
EP  - 12323
DO  - 10.1007/s10489-022-04130-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138700341&doi=10.1007%2fs10489-022-04130-x&partnerID=40&md5=a16d4b06c7d6882ce72e88a9b1478d72
AB  - Table-based fact verification aims to check whether a statement is entailed by the content of relevant table. Existing works mainly either parse a statement with logical form or design a table-aware neural network to represent the statement-table pair. However, they fail to directly exploit guidance signals to capture enough evidence from the table, which lead to performance degradation. Thus, to investigate how to select potential key words from the table for fact verification, we propose a Reinforced Evidence Reasoning framework with Graph neural network (RERG), which simulates human inference process of focusing on some words at each step. Specifically, we employ a Transformer-based graph neural network to represent multi-granularity features. Then, we design a monitor node and connect it with some potential key nodes by reinforcement learning on each graph layer, according to the feedback of the reward. In this way, the monitor node can be used to predict the label, which has aggregated various key information through multiple graph layers. Besides, we add secondary updating after the attention mechanism to enhance information aggregation of each graph layer. Experimental results on two benchmark datasets TABFACT and INFOTABS show performance improvements over state-of-the-art baselines and the feasibility of selecting some meaningful evidences during graph reasoning. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhao2023RERG
ER  -

TY  - JOUR
AU  - Zhou, C.
AU  - Zhong, Y.
AU  - Zhou, S.
AU  - Song, J.
AU  - Xiang, W.
TI  - Rice leaf disease identification by residual-distilled transformer
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 121
C7  - 106020
DO  - 10.1016/j.engappai.2023.106020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149405885&doi=10.1016%2fj.engappai.2023.106020&partnerID=40&md5=f58d1600ba08956dc380fce96a0e3e6f
AB  - As the worldwide planting crop, rice feeds nearly half of the world's population. However, the continuous spread of diseases is threatening rice production. It is of great practical value to identify rice diseases precisely. Recent studies suggest that the computational approaches provide an opportunity for rice leaf disease prediction and achieve a series of achievements. However, the existing works for rice leaf disease identification are still unsatisfactory either in identification accuracy or model interpretability. To address these limitations, a residual-distilled transformer architecture is proposed in this study. Inspired by the early success of transformers in computer vision, the distillation strategy is introduced to distill weights and parameters from the pre-trained vision transformer models. The residual concatenation between vision transformer and the distilled transformer are as residual blocks for features extraction, and then fed them into multi-layer perceptron (MLP) for prediction. Experimental results demonstrate that the presented method achieves 0.89 F1-score and 0.92 top-1 accuracy, outperforms the existing state-of-the-art models on the rice leaf disease dataset which collected in paddy fields. In addition, the proposed architecture provides model interpretability to grasp the key features that are significant for positive prediction results. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:C期刊; 
LB  - Zhou2023Rice
ER  -

TY  - JOUR
AU  - Arega, T.W.
AU  - Bricq, S.
AU  - Legrand, F.
AU  - Jacquier, A.
AU  - Lalande, A.
AU  - Meriaudeau, F.
TI  - Automatic uncertainty-based quality controlled T1 mapping and ECV analysis from native and post-contrast cardiac T1 mapping images using Bayesian vision transformer
PY  - 2023
T2  - Medical Image Analysis
VL  - 86
C7  - 102773
DO  - 10.1016/j.media.2023.102773
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148543711&doi=10.1016%2fj.media.2023.102773&partnerID=40&md5=b944bcf537810d14ed1541c811246c93
AB  - Deep learning-based methods for cardiac MR segmentation have achieved state-of-the-art results. However, these methods can generate incorrect segmentation results which can lead to wrong clinical decisions in the downstream tasks. Automatic and accurate analysis of downstream tasks, such as myocardial tissue characterization, is highly dependent on the quality of the segmentation results. Therefore, it is of paramount importance to use quality control methods to detect the failed segmentations before further analysis. In this work, we propose a fully automatic uncertainty-based quality control framework for T1 mapping and extracellular volume (ECV) analysis. The framework consists of three parts. The first one focuses on segmentation of cardiac structures from a native and post-contrast T1 mapping dataset (n=295) using a Bayesian Swin transformer-based U-Net. In the second part, we propose a novel uncertainty-based quality control (QC) to detect inaccurate segmentation results. The QC method utilizes image-level uncertainty features as input to a random forest-based classifier/regressor to determine the quality of the segmentation outputs. The experimental results from four different types of segmentation results show that the proposed QC method achieves a mean area under the ROC curve (AUC) of 0.927 on binary classification and a mean absolute error (MAE) of 0.021 on Dice score regression, significantly outperforming other state-of-the-art uncertainty based QC methods. The performance gap is notably higher in predicting the segmentation quality from poor-performing models which shows the robustness of our method in detecting failed segmentations. After the inaccurate segmentation results are detected and rejected by the QC method, in the third part, T1 mapping and ECV values are computed automatically to characterize the myocardial tissues of healthy and cardiac pathological cases. The native myocardial T1 and ECV values computed from automatic and manual segmentations show an excellent agreement yielding Pearson coefficients of 0.990 and 0.975 (on the combined validation and test sets), respectively. From the results, we observe that the automatically computed myocardial T1 and ECV values have the ability to characterize myocardial tissues of healthy and cardiac diseases like myocardial infarction, amyloidosis, Tako-Tsubo syndrome, dilated cardiomyopathy, and hypertrophic cardiomyopathy. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Arega2023Automatic
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Chen, K.
AU  - Sun, S.
AU  - He, C.
TI  - Multi-scale homography estimation based on dual feature aggregation transformer
PY  - 2023
T2  - IET Image Processing
VL  - 17
IS  - 5
SP  - 1403
EP  - 1416
DO  - 10.1049/ipr2.12722
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145219465&doi=10.1049%2fipr2.12722&partnerID=40&md5=232f6b71e3335c40ddbd467a5e4fb042
AB  - The accuracy of registration in image stitching task directly affects the performance of subsequent stages. Traditional registration methods rely heavily on the quality of the features when calculating the homography matrix, resulting in alignment failures in low-texture or low-overlap scenes due to extracting insufficient features. On the other hand, existing DNN-based methods for homography estimation are more robust in multiple scenes but previous work usually employs an overly simple convolutional network structure to directly regress the homography, ignoring the redundant information contained in the feature maps so that their prediction accuracy is inferior to the traditional methods in simple scenarios. To overcome the disadvantages of the two methods, a Multi-scale structure is proposed to extract feature maps at three scales and design two modules to handle the matrix prediction respectively. The DFA-T module analyzes semantic information on the high-level features to accomplish coarse-grained alignment while the Contextual Correlation module on the bottom level to accomplish more accurate alignment. Experiments demonstrate that this method provides more accurate alignment results than the existing state-of-the-art DNN-based methods and outperforms traditional algorithms with more stable results in some extreme scenarios. © 2022 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Li2023Multi-scale
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Lu, J.
TI  - Foreformer: an enhanced transformer-based framework for multivariate time series forecasting
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 10
SP  - 12521
EP  - 12540
DO  - 10.1007/s10489-022-04100-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139150307&doi=10.1007%2fs10489-022-04100-3&partnerID=40&md5=18f3590d39cbd6fba6bd17449b508a20
AB  - Multivariate time series forecasting (MTSF) has been extensively studied throughout years with ubiquitous applications in finance, traffic, environment, etc. Recent investigations have demonstrated the potential of Transformer to improve the forecasting performance. Transformer, however, has limitations that prohibit it from being directly applied to MTSF, such as insufficient extraction of temporal patterns at different time scales, extraction of irrelevant information in the self-attention, and no targeted processing of static covariates. Motivated by above, an enhanced Transformer-based framework for MTSF is proposed, named Foreformer, with three distinctive characteristics: (i) a multi-temporal resolution module that deeply captures temporal patterns at different scales, (ii) an explicit sparse attention mechanism forces model to prioritize the most contributive components, and (iii) a static covariates processing module for nonlinear processing of static covariates. Extensive experiments on three real-world datasets demonstrate that Foreformer outperforms existing methodologies, making it a reliable approach for MTSF tasks. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Yang2023Foreformer
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Xie, H.
AU  - Wang, F.L.
AU  - Lee, L.-K.
TI  - A transformer–convolution model for enhanced session-based recommendation
PY  - 2023
T2  - Neurocomputing
VL  - 531
SP  - 21
EP  - 33
DO  - 10.1016/j.neucom.2023.01.083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148324123&doi=10.1016%2fj.neucom.2023.01.083&partnerID=40&md5=0f83a7c242c95d3e985808d3d267d0be
AB  - Session-based recommendation aims to predict a user's next action based on a series of anonymous sequences and plays an essential role in various online applications, such as e-commerce and music applications. Recently, transformer-based models have obtained results that are competitive with or even surpass those of recurrent neural networks, because of the good performance of transformer models in capturing long-distance dependencies. However, a transformer has a limited ability to mine local contextual information, which can be regarded as collective features. Researchers are seeking to address this limitation by augmenting the contextual transition to boost session representation learning. Accordingly, in this paper, we enhance the capabilities of a transformer in a session-based recommendation task by introducing convolutional neural networks (CNNs) at the stage of aggregating the item features with long- and short-distance dependencies. We first borrow a self-attention module from the classic transformer model to explore the long-distance dependencies. We next propose horizontal and vertical convolutions for enhancing the local collective information and then obtain a session representation by integrating the two types of features. Extensive experiments on real-world datasets show that our method outperforms those that rely on a transformer or a CNN alone. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Wang2023transformer–convolution
ER  -

TY  - JOUR
AU  - Guo, X.
AU  - Zhang, X.
AU  - Li, L.
AU  - Xia, Z.
TI  - Micro-expression spotting with multi-scale local transformer in long videos
PY  - 2023
T2  - Pattern Recognition Letters
VL  - 168
SP  - 146
EP  - 152
DO  - 10.1016/j.patrec.2023.03.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150921475&doi=10.1016%2fj.patrec.2023.03.012&partnerID=40&md5=bf4da95ab3ef7bac519c5fdbc71b4938
AB  - Micro-expression analysis by computer vision techniques has attracted much attention as it can reveal the human emotions automatically. Among the analysis tasks, the temporal spotting is the most challenging task for achieving expression-aware frames from long video sequences. Compared to the well studied recognition task, more researches need to be devoted to the spotting task for further improving the performance and benefiting the subsequent tasks. So, in this paper, we propose a convolutional transformer based deep model for micro-expression spotting in long video sequences. A 3D convolutional subnetwork is firstly employed to extract the visual features from the temporal frames in a fixed-size sliding window of original video sequence. Then a multi-scale local transformer module is designed based on the visual features to model the correlation between frames in a local window. By leveraging the correlation information, the description of face movement becomes more representative for various-duration micro-expressions. Finally, the multi-head classifier and the corresponding estimator are jointly combined to predict the temporal position for spotting micro-expressions. The proposed method is evaluated on two publicly-available datasets, namely CAS(ME)2 and SAMM-LV, and achieves the promising performance of 0.2770 F1-score on SAMM-LV and 0.1373 F1-score on CAS(ME)2. The code is publicly available on GitHub (https://github.com/xiazhaoqiang/MULT-MicroExpressionSpot). © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; 
LB  - Guo2023Micro-expression
ER  -

TY  - JOUR
AU  - Tian, X.
AU  - Jin, Y.
AU  - Tang, X.
TI  - Local–Global Transformer Neural Network for temporal action segmentation
PY  - 2023
T2  - Multimedia Systems
VL  - 29
IS  - 2
SP  - 615
EP  - 626
DO  - 10.1007/s00530-022-00998-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140210882&doi=10.1007%2fs00530-022-00998-4&partnerID=40&md5=f36cbfb135cd65023e22a5976efe518e
AB  - The temporal action segmentation task is a branch of video understanding that aims to predict what is happening in the action segments (comprising a series of consecutive action frames with identical labels) in an untrimmed video. Recent works have harnessed the Transformer, which is capable of modeling temporal relations in long sequences. However, there are several limitations when utilizing Transformer-based networks for processing video sequences, such as (1) the dramatic changes to the neighboring action segments, (2) the paradox between the loss of fine-grained information in deeper layers and inefficient learning with small receptive fields, and (3) the lack of refinement process to raise the performance. This paper proposes a novel network to address the above difficulties called the Local–Global Transformer Neural Network (LGTNN). LGTNN comprises three main modules. The first two modules are the Local and Global Transformer modules, which efficiently capture multiscale features and solve the paradox of perceiving higher- and lower-level representations at different convolutional layer depths. The third module, called the Boundary Detection Network (BDN), executes a postprocessing procedure and helps to finetune ambiguous action boundaries and generate the final prediction. Our proposed model can be embedded in existing temporal action segmentation models, such as MS-TCN, ASFormer, and ETSN. The results of experiments conducted on three challenging datasets (50Salads, Georgia Tech Egocentric Activities (GTEA), and Breakfast) using LGTNN both singly and embedded in existing segmentation models verify that it outperforms state-of-the-art methods by a large margin. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Tian2023Local–Global
ER  -

TY  - JOUR
AU  - Giannoulidis, A.
AU  - Gounaris, A.
TI  - A context-aware unsupervised predictive maintenance solution for fleet management
PY  - 2023
T2  - Journal of Intelligent Information Systems
VL  - 60
IS  - 2
SP  - 521
EP  - 547
DO  - 10.1007/s10844-022-00744-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138144174&doi=10.1007%2fs10844-022-00744-2&partnerID=40&md5=5513ff2b9301f83ac46a344890cf88bf
AB  - We deal with the problem of predictive maintenance (PdM) in a vehicle fleet management setting following an unsupervised streaming anomaly detection approach. We investigate a variety of unsupervised methods for anomaly detection, such as proximity-based, hybrid (statistical and proximity-based) and transformers. The proposed methods can properly model the context in which each member of the fleet operates. In our case, the context is both crucial for effective anomaly detection and volatile, which calls for streaming solutions that take into account only the recent values. We propose two novel techniques, a 2-stage proximity-based one and context-aware transformers along with advanced thresholding. In addition, to allow for testing PdM techniques for vehicle fleets in a fair and reproducible manner, we build a new fleet-like benchmarking dataset based on an existing dataset of turbofan simulations. Our evaluation results show that our proposals reduce the maintenance costs compared to existing solutions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Giannoulidis2023context-aware
ER  -

TY  - JOUR
AU  - Shankar, V.
AU  - Yousefi, E.
AU  - Manashty, A.
AU  - Blair, D.
AU  - Teegapuram, D.
TI  - Clinical-GAN: Trajectory Forecasting of Clinical Events using Transformer and Generative Adversarial Networks
PY  - 2023
T2  - Artificial Intelligence in Medicine
VL  - 138
C7  - 102507
DO  - 10.1016/j.artmed.2023.102507
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148321334&doi=10.1016%2fj.artmed.2023.102507&partnerID=40&md5=6fc06c7788c1cd645aa4ce4383c253d6
AB  - Predicting the trajectory of a disease at an early stage can aid physicians in offering effective treatment, prompt care to patients, and also avoid misdiagnosis. However, forecasting patient trajectories is challenging due to long-range dependencies, irregular intervals between consecutive admissions, and non-stationarity data. To address these challenges, we propose a novel method called Clinical-GAN, a Transformer-based Generative Adversarial Networks (GAN) to forecast the patients’ medical codes for subsequent visits. First, we represent the patients’ medical codes as a time-ordered sequence of tokens akin to language models. Then, a Transformer mechanism is used as a Generator to learn from existing patients’ medical history and is trained adversarially against a Transformer-based Discriminator. We address the above mentioned challenges based on our data modeling and Transformer-based GAN architecture. Additionally, we enable the local interpretation of the model's prediction using a multi-head attention mechanism. We evaluated our method using a publicly available dataset, Medical Information Mart for Intensive Care IV v1.0 (MIMIC-IV), with more than 500,000 visits completed by around 196,000 adult patients over an 11-year period from 2008–2019. Clinical-GAN significantly outperforms baseline methods and existing works, as demonstrated through various experiments. Source code is at https://github.com/vigi30/Clinical-GAN. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Shankar2023Clinical-GAN
ER  -

TY  - JOUR
AU  - Madhu, H.
AU  - Satapara, S.
AU  - Modha, S.
AU  - Mandl, T.
AU  - Majumder, P.
TI  - Detecting offensive speech in conversational code-mixed dialogue on social media: A contextual dataset and benchmark experiments
PY  - 2023
T2  - Expert Systems with Applications
VL  - 215
C7  - 119342
DO  - 10.1016/j.eswa.2022.119342
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145576108&doi=10.1016%2fj.eswa.2022.119342&partnerID=40&md5=abea29bea8c803920b9ef89a1d139dc7
AB  - The spread of Hate Speech on online platforms is a severe issue for societies and requires the identification of offensive content by platforms. Research has modeled Hate Speech recognition as a text classification problem that predicts the class of a message based on the text of the message only. However, context plays a huge role in communication. In particular, for short messages, the text of the preceding tweets can completely change the interpretation of a message within a discourse. This work extends previous efforts to classify Hate Speech by considering the current and previous tweets jointly. In particular, we introduce a clearly defined way of extracting context. We present the development of the first dataset for conversational-based Hate Speech classification with an approach for collecting context from long conversations for code-mixed Hindi (ICHCL dataset). Overall, our benchmark experiments show that the inclusion of context can improve classification performance over a baseline. Furthermore, we develop a novel processing pipeline for processing the context. The best-performing pipeline uses a fine-tuned SentBERT paired with an LSTM as a classifier. This pipeline achieves a macro F1 score of 0.892 on the ICHCL test dataset. Another KNN, SentBERT, and ABC weighting-based pipeline yields an F1 Macro of 0.807, which gives the best results among traditional classifiers. So even a KNN model gives better results with an optimized BERT than a vanilla BERT model. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Madhu2023Detecting
ER  -

TY  - JOUR
AU  - Nguyen, M.-T.
AU  - Son, N.H.
AU  - Linh, L.T.
TI  - Gain more with less: Extracting information from business documents with small data
PY  - 2023
T2  - Expert Systems with Applications
VL  - 215
C7  - 119274
DO  - 10.1016/j.eswa.2022.119274
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145558549&doi=10.1016%2fj.eswa.2022.119274&partnerID=40&md5=b2fb83532236a217c26f160ccbf198f8
AB  - Information extraction (IE) is a vital step of digitization that reduces paperwork in offices. However, the adaptation of common IE systems to actual business cases faces two issues. First, the number of training samples is small (i.e. 100–200 examples). Second, span extraction models based on question answering formulation require a long time for training and inference. To overcome these issues, we introduce a new query-based model for the extraction of information from business documents. For data limitation, the model employs transfer learning which adapts the knowledge of pre-trained language models (i.e. BERT) to specific domains. To do that, we design a new CNN layer for the adaptation of the model to specific domains. For the speed, different from the encoding of normal span extraction methods (BERT-QA), the proposed model encodes short tags and context documents in two channels in parallel, which speeds up training and inference time. Information from short tags is fused with context documents learned from CNN by using attention to predict start and end positions of extracted spans. Promising results on five domain-specific datasets in English and Japanese indicate that the proposed model produces high-quality outputs and can be applied for business scenarios. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Nguyen2023Gain
ER  -

TY  - JOUR
AU  - Kim, J.
AU  - Kang, H.
AU  - Kang, P.
TI  - Time-series anomaly detection with stacked Transformer representations and 1D convolutional network
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 120
C7  - 105964
DO  - 10.1016/j.engappai.2023.105964
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147857932&doi=10.1016%2fj.engappai.2023.105964&partnerID=40&md5=c9553dba6b7309725a1f4f621f171b94
AB  - Time-series anomaly detection is a task of detecting data that do not follow normal data distribution among continuously collected data. It is used for system maintenance in various industries; hence, studies on time-series anomaly detection are being carried out actively. Most of the methodologies are based on Long Short-Term Memory (LSTM) and Convolution Neural Network (CNN) to model the temporal structure of time-series data. In this study, we propose an unsupervised prediction-based time-series anomaly detection methodology using Transformer, which shows superior performance to LSTM and CNN in learning dynamic patterns of sequential data through a self-attention mechanism. The prediction model consists of an encoder comprising multiple Transformer encoder layers and a decoder that includes a 1D convolution layer. The output representation of each Transformer layer is accumulated in the encoder to obtain a representation with multi-level, rich information. The decoder fuses this representation through a 1d convolution operation. Consequently, the model can perform predictions considering both the global trend and local variability of the input time-series. The anomaly score is defined as the difference between the predicted and the actual value at the corresponding timestamp, assuming that the trained model produces the predictions that follow the normal data distribution. Finally, the data with an anomaly score above the threshold is detected as an anomaly. Experiments on the benchmark datasets show that the proposed method has performance superior to those of the baselines. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 65
C2  - CCF:C期刊; 
LB  - Kim2023Time-series
ER  -

TY  - JOUR
AU  - Ma, X.
AU  - Zhang, S.
AU  - Wang, Y.
AU  - Li, R.
AU  - Chen, X.
AU  - Yu, D.
TI  - ASCAM-Former: Blind image quality assessment based on adaptive spatial & channel attention merging transformer and image to patch weights sharing
PY  - 2023
T2  - Expert Systems with Applications
VL  - 215
C7  - 119268
DO  - 10.1016/j.eswa.2022.119268
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144067492&doi=10.1016%2fj.eswa.2022.119268&partnerID=40&md5=fa367143fc9deaffaee88d8676fa1697
AB  - Blind Image Quality Assessment (BIQA) is a challenging, unsolved research topic which is crucial for analyzing, understanding, and improving visual experience. Recently, transformer-based BIQA models are drawing increasing attention due to their powerful capacity in modeling global dependencies amongst tokens. However, existing works tend to apply self-attention mechanism for exploring the spatial dependencies whilst neglecting the impact of channel-wise self-attention. In this paper, we explore the feasibility of incorporating attention mechanism in a channel-wise manner for BIQA. By systematically studying the interactions between channel-wise and spatial-wise attention, an adaptive spatial and channel attention merging Transformer (ASCAM-Former) is then proposed for aggregating both the spatial-wise and channel-wise attention information. In addition, to accommodate IQA datasets containing both image and patch quality labels, an image to patch weights sharing (I2PWS) scheme is designed to take advantage of local quality learning tasks for reinforcing the learning of global quality, and vice versa. The experimental results indicate that channel-wise attention mechanism is as competitive as spatial-wise for IQA tasks, and the proposed ASCAM-Former yield accurate prediction on both authentically and synthetically distorted image quality datasets. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ma2023ASCAM-Former
ER  -

TY  - JOUR
AU  - Denecke, K.
AU  - Reichenpfader, D.
TI  - Sentiment analysis of clinical narratives: A scoping review
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 140
C7  - 104336
DO  - 10.1016/j.jbi.2023.104336
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151470447&doi=10.1016%2fj.jbi.2023.104336&partnerID=40&md5=362eb642708f9c71fc474981e04ce4f8
AB  - A clinical sentiment is a judgment, thought or attitude promoted by an observation with respect to the health of an individual. Sentiment analysis has drawn attention in the healthcare domain for secondary use of data from clinical narratives, with a variety of applications including predicting the likelihood of emerging mental illnesses or clinical outcomes. The current state of research has not yet been summarized. This study presents results from a scoping review aiming at providing an overview of sentiment analysis of clinical narratives in order to summarize existing research and identify open research gaps. The scoping review was carried out in line with the PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) guideline. Studies were identified by searching 4 electronic databases (e.g., PubMed, IEEE Xplore) in addition to conducting backward and forward reference list checking of the included studies. We extracted information on use cases, methods and tools applied, used datasets and performance of the sentiment analysis approach. Of 1,200 citations retrieved, 29 unique studies were included in the review covering a period of 8 years. Most studies apply general domain tools (e.g. TextBlob) and sentiment lexicons (e.g. SentiWordNet) for realizing use cases such as prediction of clinical outcomes; others proposed new domain-specific sentiment analysis approaches based on machine learning. Accuracy values between 71.5–88.2% are reported. Data used for evaluation and test are often retrieved from MIMIC databases or i2b2 challenges. Latest developments related to artificial neural networks are not yet fully considered in this domain. We conclude that future research should focus on developing a gold standard sentiment lexicon, adapted to the specific characteristics of clinical narratives. Efforts have to be made to either augment existing or create new high-quality labeled data sets of clinical narratives. Last, the suitability of state-of-the-art machine learning methods for natural language processing and in particular transformer-based models should be investigated for their application for sentiment analysis of clinical narratives. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; 
LB  - Denecke2023Sentiment
ER  -

TY  - JOUR
AU  - Heo, Y.-J.
AU  - Yeo, W.-H.
AU  - Kim, B.-G.
TI  - DeepFake detection algorithm based on improved vision transformer
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 7
SP  - 7512
EP  - 7527
DO  - 10.1007/s10489-022-03867-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134994902&doi=10.1007%2fs10489-022-03867-9&partnerID=40&md5=093e87fa6326379327892885607e52f8
AB  - A DeepFake is a manipulated video made with generative deep learning technologies, such as generative adversarial networks or auto encoders that anyone can utilize. With the increase in DeepFakes, classifiers consisting of convolutional neural networks (CNN) that can distinguish them have been actively created. However, CNNs have a problem with overfitting and cannot consider the relation between local regions as global feature of image, resulting in misclassification. In this paper, we propose an efficient vision transformer model for DeepFake detection to extract both local and global features. We combine vector-concatenated CNN feature and patch-based positioning to interact with all positions to specify the artifact region. For the distillation token, the logit is trained using binary cross entropy through the sigmoid function. By adding this distillation, the proposed model is generalized to improve performance. From experiments, the proposed model outperforms the SOTA model by 0.006 AUC and 0.013 f1 score on the DFDC test dataset. For 2,500 fake videos, the proposed model correctly predicts 2,313 as fake, whereas the SOTA model predicts 2,276 in the best performance. With the ensemble method, the proposed model outperformed the SOTA model by 0.01 AUC. For Celeb-DF (v2) dataset, the proposed model achieves a high performance of 0.993 AUC and 0.978 f1 score, respectively. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 41
C2  - CCF:C期刊; 
LB  - Heo2023DeepFake
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Ma, S.
AU  - Shan, L.
TI  - Multi-window Transformer parallel fusion feature pyramid network for pedestrian orientation detection
PY  - 2023
T2  - Multimedia Systems
VL  - 29
IS  - 2
SP  - 587
EP  - 603
DO  - 10.1007/s00530-022-00993-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139623995&doi=10.1007%2fs00530-022-00993-9&partnerID=40&md5=4def421ae5ddf8ecd3b80622707ac0dc
AB  - In complex traffic scenes, the orientation and location of pedestrians are important criteria for judging their intentions. We note that pedestrians are characterized by variability in appearance and small differences among orientations (especially adjacent orientations), thus causing general object detection algorithms to perform poorly in extracting features. So, extracting more discriminative features is an effective way to solve this problem. To this end, we propose a novel framework to enhance feature extraction involving pedestrian orientation detection (orientation classification and location regression). The framework consists of two modules, multi-window Transformer parallel fusion feature pyramid (MTPF) and gated graph (GG). The MTPF module is used for multi-layer feature fusion, which improves the feature representation of the prediction map by extracting high-level semantic information from deep layers and recovering missing contextual information from shallow layers. Specifically, it is achieved by setting a sliding window on multiple prediction maps and fused by the Transformer. The region proposal is abstracted into a graph with six nodes in the GG module, where each node represents a body part. We utilize GG to learn the spatial dependencies among body parts and learn features by aggregating information from neighbors. Finally, pedestrian orientation classification and location regression are performed on a graph containing rich relationships among nodes. According to the survey, there are currently no methods and datasets that can be directly used for pedestrian orientation detection, so we manually annotate pedestrian orientations on three public datasets containing a large number of pedestrian samples, and compare the proposed method with the current state-of-the-art object detection methods by comparison, the results demonstrate the effectiveness of the proposed method. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Li2023Multi-window
ER  -

TY  - JOUR
AU  - Ke, J.
AU  - Lu, Y.
AU  - Shen, Y.
AU  - Zhu, J.
AU  - Zhou, Y.
AU  - Huang, J.
AU  - Yao, J.
AU  - Liang, X.
AU  - Guo, Y.
AU  - Wei, Z.
AU  - Liu, S.
AU  - Huang, Q.
AU  - Jiang, F.
AU  - Shen, D.
TI  - ClusterSeg: A crowd cluster pinpointed nucleus segmentation framework with cross-modality datasets
PY  - 2023
T2  - Medical Image Analysis
VL  - 85
C7  - 102758
DO  - 10.1016/j.media.2023.102758
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147114283&doi=10.1016%2fj.media.2023.102758&partnerID=40&md5=4e02de695c04d139e712b4a9e145d351
AB  - The detection and segmentation of individual cells or nuclei is often involved in image analysis across a variety of biology and biomedical applications as an indispensable prerequisite. However, the ubiquitous presence of crowd clusters with morphological variations often hinders successful instance segmentation. In this paper, nuclei cluster focused annotation strategies and frameworks are proposed to overcome this challenging practical problem. Specifically, we design a nucleus segmentation framework, namely ClusterSeg, to tackle nuclei clusters, which consists of a convolutional-transformer hybrid encoder and a 2.5-path decoder for precise predictions of nuclei instance mask, contours, and clustered-edges. Additionally, an annotation-efficient clustered-edge pointed strategy pinpoints the salient and error-prone boundaries, where a partially-supervised PS-ClusterSeg is presented using ClusterSeg as the segmentation backbone. The framework is evaluated with four privately curated image sets and two public sets with characteristic severely clustered nuclei across a variety range of image modalities, e.g., microscope, cytopathology, and histopathology images. The proposed ClusterSeg and PS-ClusterSeg are modality-independent and generalizable, and superior to current state-of-the-art approaches in multiple metrics empirically. Our collected data, the elaborate annotations to both public and private set, as well the source code, are released publicly at https://github.com/lu-yizhou/ClusterSeg. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; 
LB  - Ke2023ClusterSeg
ER  -

TY  - JOUR
AU  - Thinh, T.N.H.
AU  - Lam, P.D.
AU  - Tran, H.Q.
AU  - Tien, L.H.C.
AU  - Thai, P.H.
TI  - Transformer vibration and noise monitoring system using internet of things
PY  - 2023
T2  - IET Communications
VL  - 17
IS  - 7
SP  - 815
EP  - 828
DO  - 10.1049/cmu2.12585
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149321921&doi=10.1049%2fcmu2.12585&partnerID=40&md5=4dc72f4cb549c67db999f880bd2b492e
AB  - During continuous operation, transformer problems can occur due to various reasons. In reality, the operating parameters of the transformer have been collected and monitored through the supervisory control and data acquisition (SCADA) systems. However, these systems face many challenges when applied to no-human substations. Currently, noise signals have been used to detect transformer errors. Abnormal noise recognition and vibration monitoring can recognize the transformer's potential defects and errors. In this study, the authors built an internet of things (IoT) system that allows remote control centres to monitor the condition of transformers through noise and vibration at non-human substations. The proposed model was equipped with a wireless sensor network node consisting of vibration sensors, audio collectors, Arduino modules, and Lora modules. The authors set up two schemes for the IoT network: one sensor node for a 220-kV transformer and three sensor nodes for all three phases of the 500-kV transformer. The data obtained from the sensor node were sent to LoRa Gateway and displayed on the computer through LabVIEW. The study also enabled monitoring of parameters through IoT devices such as Desktops, Laptops, Smartphones from LabVIEW NXG Web VI platform, ThingSpeak, and Amazon S3 storage cloud. In addition, a Model Predictive Control (MPC) algorithm was applied to predict the deterioration of transformer health to maintain the system stability and, hence, prolong the transformer life and operability. © 2023 The Authors. IET Communications published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Thinh2023Transformer
ER  -

TY  - JOUR
AU  - Vu, Q.D.
AU  - Rajpoot, K.
AU  - Raza, S.E.A.
AU  - Rajpoot, N.
TI  - Handcrafted Histological Transformer (H2T): Unsupervised representation of whole slide images
PY  - 2023
T2  - Medical Image Analysis
VL  - 85
C7  - 102743
DO  - 10.1016/j.media.2023.102743
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146963842&doi=10.1016%2fj.media.2023.102743&partnerID=40&md5=a93614ffa690b1d68a321ead3aca80e1
AB  - Diagnostic, prognostic and therapeutic decision-making of cancer in pathology clinics can now be carried out based on analysis of multi-gigapixel tissue images, also known as whole-slide images (WSIs). Recently, deep convolutional neural networks (CNNs) have been proposed to derive unsupervised WSI representations; these are attractive as they rely less on expert annotation which is cumbersome. However, a major trade-off is that higher predictive power generally comes at the cost of interpretability, posing a challenge to their clinical use where transparency in decision-making is generally expected. To address this challenge, we present a handcrafted framework based on deep CNN for constructing holistic WSI-level representations. Building on recent findings about the internal working of the Transformer in the domain of natural language processing, we break down its processes and handcraft them into a more transparent framework that we term as the Handcrafted Histological Transformer or H2T. Based on our experiments involving various datasets consisting of a total of 10,042 WSIs, the results demonstrate that H2T based holistic WSI-level representations offer competitive performance compared to recent state-of-the-art methods and can be readily utilized for various downstream analysis tasks. Finally, our results demonstrate that the H2T framework can be up to 14 times faster than the Transformer models. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; 
LB  - Vu2023Handcrafted
ER  -

TY  - JOUR
AU  - Naseem, U.
AU  - Khushi, M.
AU  - Kim, J.
TI  - Vision-Language Transformer for Interpretable Pathology Visual Question Answering
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 4
SP  - 1681
EP  - 1690
DO  - 10.1109/JBHI.2022.3163751
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127535492&doi=10.1109%2fJBHI.2022.3163751&partnerID=40&md5=0c5c3ea1fe2183d3af7d455e82f14089
AB  - Pathology visual question answering (PathVQA) attempts to answer a medical question posed by pathology images. Despite its great potential in healthcare, it is not widely adopted because it requires interactions on both the image (vision) and question (language) to generate an answer. Existing methods focused on treating vision and language features independently, which were unable to capture the high and low-level interactions that are required for VQA. Further, these methods failed to offer capabilities to interpret the retrieved answers, which are obscure to humans where the models' interpretability to justify the retrieved answers has remained largely unexplored. Motivated by these limitations, we introduce a vision-language transformer that embeds vision (images) and language (questions) features for an interpretable PathVQA. We present an interpretable transformer-based Path-VQA (TraP-VQA), where we embed transformers' encoder layers with vision and language features extracted using pre-trained CNN and domain-specific language model (LM), respectively. A decoder layer is then embedded to upsample the encoded features for the final prediction for PathVQA. Our experiments showed that our TraP-VQA outperformed the state-of-the-art comparative methods with public PathVQA dataset. Our experiments validated the robustness of our model on another medical VQA dataset, and the ablation study demonstrated the capability of our integrated transformer-based vision-language model for PathVQA. Finally, we present the visualization results of both text and images, which explain the reason for a retrieved answer in PathVQA.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; 
LB  - Naseem2023Vision-Language
ER  -

TY  - JOUR
AU  - Singh, R.K.
AU  - Sachan, M.K.
AU  - Patel, R.B.
TI  - Cross-domain sentiment classification using decoding-enhanced bidirectional encoder representations from transformers with disentangled attention
PY  - 2023
T2  - Concurrency and Computation: Practice and Experience
VL  - 35
IS  - 6
SP  - 1
DO  - 10.1002/cpe.7589
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145295189&doi=10.1002%2fcpe.7589&partnerID=40&md5=abdb6f75379d7e1cfb0051a7a4616beb
AB  - Cross-domain sentiment classification is a significant task of sentiment analysis that objectives to predict the opinion orientation of text documents in the target domain by using the source domain's learned classifier. Most of the existing approaches of domain-adaptation in sentiment classification focus on sharing low-dimensional features across the domain using domain independent and specific features to mitigate the gap between domains. Earlier cross-domain sentiment classification approaches mainly focused on document level and sentence level, they cannot consider the full impact of aspect words, position of the words, and long-term dependencies. To address this concern, we propose a model for cross-domain sentiment classification, which is based on decoding-enhanced BERT with disentangled attention (DeBERTa). DeBERTa is a pretrained language model based on transformer architecture. In this article, we perform sentence and aspect embedding to mine wordpiece information from text document. DeBERTa language-model utilize disentangled attention mechanism and an enhanced mask decoder to understand the expression features. Disentangled attention mechanism is used to encode each word into two vectors (i.e., content and position vector). In order to predict the masked tokens during model pretraining, an enhanced mask decoder is employed, which incorporates absolute positions in the decoding layer. Finally, experiments are conducted on the benchmark dataset that demonstrates the superiority of fine-tuned DeBERTa model for cross-domain sentiment classification tasks. © 2022 John Wiley & Sons, Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Singh2023Cross-domain
ER  -

TY  - JOUR
AU  - Chang, C.-C.
TI  - Reversible Linguistic Steganography with Bayesian Masked Language Modeling
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 2
SP  - 714
EP  - 723
DO  - 10.1109/TCSS.2022.3162233
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128306070&doi=10.1109%2fTCSS.2022.3162233&partnerID=40&md5=6125491f14bb8b29a22523802cce50a1
AB  - Text authentication serves a vital role in the defense of digital identity and content against various types of cybercrime. The use of a digital signature is a common cryptographic technique for text authentication. Linguistic steganography can be applied to further conceal a digital signature within the corresponding text to facilitate data management. However, steganographic distortion lurking in the text, albeit almost imperceptible, has the potential to cause automatic computing machinery to make biased decisions. This has led to an interest in the pursuit of reversibility, the ability to reverse a steganographic process and remove distortion. In this article, we propose a reversible steganographic system for natural language text. We use a pre-trained transformer neural network for masked language modeling and embed messages in a reversible manner via predictive word substitution. Furthermore, we derive an adaptive steganographic route by taking account of predictive uncertainty, which is quantified based on a theoretical framework of Bayesian deep learning. Experimental results show that the proposed steganographic system can attain a proper balance between capacity, imperceptibility, and reversibility with close semantic and sentimental similarities between cover and stego texts.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Chang2023Reversible
ER  -

TY  - JOUR
AU  - López-García, G.
AU  - Jerez, J.M.
AU  - Ribelles, N.
AU  - Alba, E.
AU  - Veredas, F.J.
TI  - Explainable clinical coding with in-domain adapted transformers
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 139
C7  - 104323
DO  - 10.1016/j.jbi.2023.104323
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148858827&doi=10.1016%2fj.jbi.2023.104323&partnerID=40&md5=14312c45d455a719c365ed94c4310748
AB  - Background and Objective: Automatic clinical coding is a crucial task in the process of extracting relevant information from unstructured medical documents contained in Electronic Health Records (EHR). However, most of the existing computer-based methods for clinical coding act as “black boxes”, without giving a detailed description of the reasons for the clinical-coding assignments, which greatly limits their applicability to real-world medical scenarios. The objective of this study is to use transformer-based models to effectively tackle explainable clinical-coding. In this way, we require the models to perform the assignments of clinical codes to medical cases, but also to provide the reference in the text that justifies each coding assignment. Methods: We examine the performance of 3 transformer-based architectures on 3 different explainable clinical-coding tasks. For each transformer, we compare the performance of the original general-domain version with an in-domain version of the model adapted to the specificities of the medical domain. We address the explainable clinical-coding problem as a dual medical named entity recognition (MER) and medical named entity normalization (MEN) task. For this purpose, we have developed two different approaches, namely a multi-task and a hierarchical-task strategy. Results: For each analyzed transformer, the clinical-domain version significantly outperforms the corresponding general domain model across the 3 explainable clinical-coding tasks analyzed in this study. Furthermore, the hierarchical-task approach yields a significantly superior performance than the multi-task strategy. Specifically, the combination of the hierarchical-task strategy with an ensemble approach leveraging the predictive capabilities of the 3 distinct clinical-domain transformers, yields the best obtained results, with f1-score, precision and recall of 0.852, 0.847 and 0.849 on the Cantemist-Norm task and 0.718, 0.566 and 0.633 on the CodiEsp-X task, respectively. Conclusions: By separately addressing the MER and MEN tasks, as well as by following a context-aware text-classification approach to tackle the MEN task, the hierarchical-task approach effectively reduces the intrinsic complexity of explainable clinical-coding, leading the transformers to establish new SOTA performances for the predictive tasks considered in this study. In addition, the proposed methodology has the potential to be applied to other clinical tasks that require both the recognition and normalization of medical entities. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - López-García2023Explainable
ER  -

TY  - JOUR
AU  - Faal, F.
AU  - Schmitt, K.
AU  - Yu, J.Y.
TI  - Reward modeling for mitigating toxicity in transformer-based language models
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 7
SP  - 8421
EP  - 8435
DO  - 10.1007/s10489-022-03944-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134565002&doi=10.1007%2fs10489-022-03944-z&partnerID=40&md5=58feacdb1d95520fe78f697c1b1afca1
AB  - Transformer-based language models can generate fluent text and be efficiently adapted across various natural language generation tasks. However, language models that are pretrained on large unlabeled web text corpora have been shown to suffer from degenerating toxic content and social bias behaviors, consequently hindering their safe deployment. Various detoxification methods have been proposed to mitigate language model toxicity; however, these methods struggle to detoxify language models when conditioned on prompts that contain specific social identities related to gender, race, or religion. In this study, we propose Reinforce-Detoxify, a reinforcement learning-based method for mitigating toxicity in language models. We address the challenge of safety in language models and propose a new reward model that can detect toxic content and mitigate unintended bias towards social identities in toxicity prediction. The experiments demonstrate that the Reinforce-Detoxify method for language model detoxification outperforms existing detoxification approaches in automatic evaluation metrics, indicating that our approach in language model detoxification is less prone to unintended bias toward social identities in generated content. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Faal2023Reward
ER  -

TY  - JOUR
AU  - Lee, S.-M.
AU  - Kim, D.-Y.
AU  - Woo, J.
TI  - Glucose Transformer: Forecasting Glucose Level and Events of Hyperglycemia and Hypoglycemia
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 3
SP  - 1600
EP  - 1611
DO  - 10.1109/JBHI.2023.3236822
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148431951&doi=10.1109%2fJBHI.2023.3236822&partnerID=40&md5=4716a5fc8a444b180555f8c9cd70c799
AB  - To avoid the adverse consequences from abrupt increases in blood glucose, diabetic inpatients should be closely monitored. Using blood glucose data from type 2 diabetes patients, we propose a deep learning model-based framework to forecast blood glucose levels. We used continuous glucose monitoring (CGM) data collected from inpatients with type 2 diabetes for a week. We adopted the Transformer model, commonly used in sequence data, to forecast the blood glucose level over time and detect hyperglycemia and hypoglycemia in advance. We expected the attention mechanism in Transformer to reveal a hint of hyperglycemia and hypoglycemia, and performed a comparative study to determine whether Transformer was effective in the classification and regression of glucose. Hyperglycemia and hypoglycemia rarely occur and this results in an imbalance in the classification. We built a data augmentation model using the generative adversarial network. Our contributions are as follows. First, we developed a deep learning framework utilizing the encoder part of Transformer to perform the regression and classification under a unified framework. Second, we adopted a data augmentation model using the generative adversarial network suitable for time-series data to solve the data imbalance problem and to improve performance. Third, we collected data for type 2 diabetic inpatients for mid-time. Finally, we incorporated transfer learning to improve the performance of regression and classification. © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Lee2023Glucose
ER  -

TY  - JOUR
AU  - Qiao, S.
AU  - Zhou, W.
AU  - Wen, J.
AU  - Wang, H.
AU  - Hu, L.
AU  - Ni, S.
TI  - Multi-perspective enhanced representation for effective session-based recommendation
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 263
C7  - 110284
DO  - 10.1016/j.knosys.2023.110284
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146144919&doi=10.1016%2fj.knosys.2023.110284&partnerID=40&md5=f55778a0168737b55644a4b471e35ed7
AB  - Session-based recommendation uses the click history of anonymous users to recommend the next possible click item for a given point in time. GNN-based models have returned promising results. However, these models still have some limitations. First, when GNN encodes the session data into session graphs, the order of the items is ignored; second, the GNN layer limit makes it impossible to capture some long-term dependencies in the session; third, noise items in the final generated session embedding will interfere with the model's predictions. We propose a new multiperspective enhanced session representation recommendation model (MPER) to address the above problems. First, we introduce learnable position embedding to record the sequential relationships of the items, and propose the SLD-encoder to capture richer global information. Second, we propose an adaptive sparse target attention mechanism to alleviate the effect of the noise items in the traditional target embeddings. Third, a linear integration layer is added to the model to ensure that the session and item embeddings are in the same representation space. We conduct experiments on three real datasets, and the experimental results show that our model outperforms the SOTA baseline studies. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; 
LB  - Qiao2023Multi-perspective
ER  -

TY  - JOUR
AU  - Deshmukh, P.
AU  - Satyanarayana, G.S.R.
AU  - Majhi, S.
AU  - Sahoo, U.K.
AU  - Das, S.K.
TI  - Swin transformer based vehicle detection in undisciplined traffic environment
PY  - 2023
T2  - Expert Systems with Applications
VL  - 213
C7  - 118992
DO  - 10.1016/j.eswa.2022.118992
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140409157&doi=10.1016%2fj.eswa.2022.118992&partnerID=40&md5=d13127dc10f3ab822ea7b196656dbd18
AB  - Intelligent vehicle detection (IVD) plays a prominent role in evolving an intelligent traffic management system (ITMS). It can help to decrease the average waiting time at the traffic post, save fuel consumption, control traffic congestion, decrease accident rates, and build up human safety. Recent developments in the artificial intelligence (AI) domain have increased the demand for IVD in the undisciplined traffic environment, which is a usual condition in developing countries. IVD is a difficult task in an undisciplined traffic environment because different vehicle categories travel very close to each other on the roads and do not follow traffic rules. Previously, several convolutional neural network (CNN) based deep learning (DL), and visual transformer-based techniques for vehicle and object detection have been presented. They are complex and do not accurately extract multi-scale features due to the involvement of existing CNN feature extraction backbones. Also, most techniques failed to account for an undisciplined traffic environment due to the unavailability of labeled vehicle datasets. Therefore, this paper proposes a swin transformer-based vehicle detection (STVD) framework in an undisciplined traffic environment. Swin transformer (ST) wholly exchanges information within and between image patches and provides hierarchical feature maps, effectively alleviating the multi-scale feature extraction problem. A bi-directional feature pyramid network (BIFPN) is presented, which combines low-resolution features with high-resolution features in a bidirectional way and provides robust multi-scale features with different scales and resolutions. A fully connected vehicle detection head (FCVDH) is applied to improve the matching relationship between vehicle sizes and the BIFPN hierarchy. FCVDH predicts the locations and categories of vehicles in the input image. STVD is analyzed, experimented, and measured over realistic traffic data. Also, it is compared with the existing state-of-the-art vehicle detection methods. It achieves 91.32% detection accuracy on diverse traffic labeled dataset (DTLD), 87.4% on IITM-hetra, and 88.45% on KITTI datasets. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 33
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Deshmukh2023Swin
ER  -

TY  - JOUR
AU  - Gao, H.
AU  - Miao, Q.
AU  - Ma, D.
AU  - Liu, R.
TI  - Deep mutual learning for brain tumor segmentation with the fusion network
PY  - 2023
T2  - Neurocomputing
VL  - 521
SP  - 213
EP  - 220
DO  - 10.1016/j.neucom.2022.11.038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144379964&doi=10.1016%2fj.neucom.2022.11.038&partnerID=40&md5=8c8ee7504f913b05e5edbe056a13070c
AB  - Deep learning methods have been successfully applied to Brain tumor segmentation. However, the extreme data imbalance exists in the different sub-regions of tumor, results in training the deep learning methods on these data will reduce the accuracy of segmentation. We introduce the deep mutual learning strategy to address the challenges, the proposed integrates transformer layers in both encoder and decoder of a U-Net architecture. In the network, using the prediction of up-sampled layer is to deep supervise the training process for enlarging the receptive field to extract features, the feature map of the shallowest layer supervises the subsequent feature map of layers to keep more edge information to guide the sub-region segmentation accuracy. the classification logits of the deepest layer supervise the previous layer of logits to get more semantic information for distinguish of tumor sub-regions. Furthermore, the feature map and the classification logits supervise mutually to improve the overall segmentation accuracy. The experimental results on benchmark dataset shows that our method has significant performance gain over existing methods. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Gao2023Deep
ER  -

TY  - JOUR
AU  - Liao, J.
AU  - Li, H.
AU  - Feng, A.
AU  - Wu, X.
AU  - Luo, Y.
AU  - Duan, X.
AU  - Ni, M.
AU  - Li, J.
TI  - Domestic pig sound classification based on TransformerCNN
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 5
SP  - 4907
EP  - 4923
DO  - 10.1007/s10489-022-03581-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132243296&doi=10.1007%2fs10489-022-03581-6&partnerID=40&md5=96c969432c6a6c1143b88c70c18f8732
AB  - Excellent performance has been demonstrated in implementing challenging agricultural production processes using modern information technology, especially in the use of artificial intelligence methods to improve modern production environments. However, most of the existing work uses visual methods to train models that extract image features of organisms to analyze their behavior, and it may not be truly intelligent. Because vocal animals transmit information through grunts, the information obtained directly from the grunts of pigs is more useful to understand their behavior and emotional state, which is important for monitoring and predicting the health conditions and abnormal behavior of pigs. We propose a sound classification model called TransformerCNN, which combines the advantages of CNN spatial feature representation and the Transformer sequence coding to form a powerful global feature perception and local feature extraction capability. Through detailed qualitative and quantitative evaluations and by comparing state-of-the-art traditional animal sound recognition methods with deep learning methods, we demonstrate the advantages of our approach for classifying domestic pig sounds. The scores for domestic pig sound recognition accuracy, AUC and recall were 96.05%, 98.37% and 90.52%, respectively, all higher than the comparison model. In addition, it has good robustness and generalization capability with low variation in performance for different input features. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Liao2023Domestic
ER  -

TY  - JOUR
AU  - Zhou, F.
AU  - Zhang, Q.
AU  - Zhu, Y.
AU  - Li, T.
TI  - T2V_TF: An adaptive timing encoding mechanism based Transformer with multi-source heterogeneous information fusion for portfolio management: A case of the Chinese A50 stocks
PY  - 2023
T2  - Expert Systems with Applications
VL  - 213
C7  - 119020
DO  - 10.1016/j.eswa.2022.119020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140324511&doi=10.1016%2fj.eswa.2022.119020&partnerID=40&md5=3162b6e2806ce532b24f6d0a2633a87d
AB  - The Stock prediction has traditionally been an attractive and challenging topic for investors and researchers. Traditionally, people concern more about predicting stock prices, less effort has been made to recommend stocks for constructing a profitable portfolio. Moreover, in existing methods for stock prediction, most of them construct models based on one or two kinds of features like stock prices, news sentiment, or simple technical indicators, and disregard the importance of multi-source information fusion. In response to this concern, we propose a novel model T2V_TF based on deep learning by combining both Time2Vec and Transformer technologies. To introduce more diverse information into the proposed model, we further conduct an in-depth exploration of the extraction and fusion of multi-source heterogeneous information, which includes the trading data, time–frequency features, Alpha 101 and Alpha 191 technical indicators, and sentiment scores. Moreover, to increase the ranking ability of our model, T2V_TF takes the ranking loss as the loss function instead of the widely used regression loss. Finally, all the technological innovations of this paper are verified on the portfolio constructed based on the A50 stocks from the Chinese stock market. The experimental results demonstrate that our proposed T2V_TF can get better portfolio cumulative return, compared with other models including the multi-layer perceptron, the support vector machine, the gradient boosting decision trees, the long short-term memory model, and the attention-based long short-term memory model, and the Transformer. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhou2023T2V_TF
ER  -

TY  - JOUR
AU  - Ghaleb, E.
AU  - Niehues, J.
AU  - Asteriadis, S.
TI  - Joint modelling of audio-visual cues using attention mechanisms for emotion recognition
PY  - 2023
T2  - Multimedia Tools and Applications
VL  - 82
IS  - 8
SP  - 11239
EP  - 11264
DO  - 10.1007/s11042-022-13557-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135448349&doi=10.1007%2fs11042-022-13557-w&partnerID=40&md5=da9c5c2d7bd30f58da80711eff890d0b
AB  - Emotions play a crucial role in human-human communications with complex socio-psychological nature. In order to enhance emotion communication in human-computer interaction, this paper studies emotion recognition from audio and visual signals in video clips, utilizing facial expressions and vocal utterances. Thereby, the study aims to exploit temporal information of audio-visual cues and detect their informative time segments. Attention mechanisms are used to exploit the importance of each modality over time. We propose a novel framework that consists of bi-modal time windows spanning short video clips labeled with discrete emotions. The framework employs two networks, with each one being dedicated to one modality. As input to a modality-specific network, we consider a time-dependent signal deriving from the embeddings of the video and audio modalities. We employ the encoder part of the Transformer on the visual embeddings and another one on the audio embeddings. The research in this paper introduces detailed studies and meta-analysis findings, linking the outputs of our proposition to research from psychology. Specifically, it presents a framework to understand underlying principles of emotion recognition as functions of three separate setups in terms of modalities: audio only, video only, and the fusion of audio and video. Experimental results on two datasets show that the proposed framework achieves improved accuracy in emotion recognition, compared to state-of-the-art techniques and baseline methods not using attention mechanisms. The proposed method improves the results over baseline methods by at least 5.4%. Our experiments show that attention mechanisms reduce the gap between the entropies of unimodal predictions, which increases the bimodal predictions’ certainty and, therefore, improves the bimodal recognition rates. Furthermore, evaluations with noisy data in different scenarios are presented during the training and testing processes to check the framework’s consistency and the attention mechanism’s behavior. The results demonstrate that attention mechanisms increase the framework’s robustness when exposed to similar conditions during the training and the testing phases. Finally, we present comprehensive evaluations of emotion recognition as a function of time. The study shows that the middle time segments of a video clip are essential in the case of using audio modality. However, in the case of video modality, the importance of time windows is distributed equally. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Ghaleb2023Joint
ER  -

TY  - JOUR
AU  - Zheng, A.
AU  - Wang, H.
AU  - Wang, J.
AU  - Huang, H.
AU  - He, R.
AU  - Hussain, A.
TI  - Diverse features discovery transformer for pedestrian attribute recognition
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 119
C7  - 105708
DO  - 10.1016/j.engappai.2022.105708
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144620495&doi=10.1016%2fj.engappai.2022.105708&partnerID=40&md5=6fe7e4f1e14cdd5e3f3249dde12aa1c4
AB  - Recently, Swin Transformer has been widely explored as a general backbone for computer vision, which helps to improve the performance of vision tasks due to the ability to establish associations for long-range dependencies of different spatial locations. By implementing the pedestrian attribute recognition with Swin Transformer, we observe that Swin Transformer tends to focus on a relatively small number of local regions within which attributes may be correlated with other attributes, which leads Swin Transformer to predict attributes in those neglected regions based on such correlation. In fact, discriminative information may exist within these neglected regions, which is crucial for attribute identification. To address this problem, we propose a novel diverse features discovery transformer (DFDT) which can find more attribute relationship regions for robust pedestrian attribute recognition. First, Swin Transformer is used as a feature extraction network to acquire attribute features with the long-distance association, which predicts the corresponding attribute information. Second, we propose a diverse features suppression module (DFSM) to obtain semantic features directly associated with attributes by suppressing the peak locations of the most discriminative features and randomly selected feature regions to spread the feature regions that Swin Transformer is interested in. Third, we plug the diverse features suppression module into different stages of Swin Transformer to learn detailed texture features to help recognition. In addition, we have divided the attribute features into multiple vertical feature regions to improve the focus on local attribute features. Experiments on three benchmark datasets validate the effectiveness of the proposed algorithm. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zheng2023Diverse
ER  -

TY  - JOUR
AU  - Raj, R.
AU  - Mathew, J.
AU  - Kannath, S.K.
AU  - Rajan, J.
TI  - StrokeViT with AutoML for brain stroke classification
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 119
C7  - 105772
DO  - 10.1016/j.engappai.2022.105772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145260967&doi=10.1016%2fj.engappai.2022.105772&partnerID=40&md5=9806781ee1af134f6196a5268afc6bbe
AB  - Stroke, categorized under cardiovascular and circulatory diseases, is considered the second foremost cause of death worldwide, causing approximately 11% of deaths annually. Stroke diagnosis using a Computed Tomography (CT) scan is considered ideal for identifying whether the stroke is hemorrhagic or ischemic. However, most methods for stroke classification are based on a single slice-level prediction mechanism, meaning that the most imperative CT slice has to be manually selected by the radiologist from the original CT volume. This paper proposes an integration of Convolutional Neural Network (CNN), Vision Transformers (ViT), and AutoML to obtain slice-level predictions as well as patient-wise prediction results. While the CNN with inductive bias captures local features, the transformer captures long-range dependencies between sequences. This collaborative local-global feature extractor improves upon the slice-wise predictions of the CT volume. We propose stroke-specific feature extraction from each slice-wise prediction to obtain the patient-wise prediction using AutoML. While the slice-wise predictions helps the radiologist to verify close and corner cases, the patient-wise predictions makes the outcome clinically relevant and closer to real-world scenario. The proposed architecture has achieved an accuracy of 87% for single slice-level prediction and an accuracy of 92% for patient-wise prediction. For comparative analysis of slice-level predictions, standalone architectures of VGG-16, VGG-19, ResNet50, and ViT were considered. The proposed architecture has outperformed the standalone architectures by 9% in terms of accuracy. For patient-wise predictions, AutoML considers 13 different ML algorithms, of which 3 achieve an accuracy of more than 90%. The proposed architecture helps in reducing the manual effort by the radiologist to manually select the most imperative CT from the original CT volume and shows improvement over other standalone architectures for classification tasks. The proposed architecture can be generalized for volumetric scans aiding in the patient diagnosis of head and neck, lungs, diseases of hepatobiliary tract, genitourinary diseases, women's imaging including breast cancer and various musculoskeletal diseases. Code for proposed stroke-specific feature extraction with the pre-trained weights of the trained model is available at: https://github.com/rishiraj-cs/StrokeViT_With_AutoML. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Raj2023StrokeViT
ER  -

TY  - JOUR
AU  - Tsai, C.-Y.
AU  - Shen, G.-Y.
AU  - Nisar, H.
TI  - Swin-JDE: Joint Detection and Embedding Multi-Object Tracking in Crowded Scenes Based on Swin-Transformer
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 119
C7  - 105770
DO  - 10.1016/j.engappai.2022.105770
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146056783&doi=10.1016%2fj.engappai.2022.105770&partnerID=40&md5=f7179d32c6fe19db2a8ea241ed362099
AB  - Multi-object tracking (MOT) is a highly valued and challenging research topic in computer vision. To achieve more robust tracking performance, recently published MOT methods tend to use anchor-free object detectors, which have the advantage of dealing with the identity ambiguity problem encountered by anchor-based methods in learning appearance features. However, in practical applications, it is found that the detection accuracy of the anchor-free object detector based on classical convolutional neural networks in crowded scenes will be significantly reduced. In order to have better detection and tracking performance in crowded scenes, this paper proposes an anchor-free joint detection and embedding (JDE) MOT method based on Transformer architecture, called Swin-JDE. The proposed method includes a novel Patch-Expanding module, which can improve the spatial information of feature maps by up-sampling processing through neural network learning and Einops Notation-based rearrangement to enhance the detection and tracking performance of the MOT model. In terms of training method, we propose a two-step training method that trains the detection branch separately from the appearance branch to enhance the detection robustness of anchor-free predictors. Furthermore, during the training process, we also propose an examination method to remove occluded targets from the training dataset to improve the accuracy of the appearance embedding layer. In terms of data association, we propose a new post-processing method, which simultaneously considers the three factors of detection confidence, appearance embedding distance, intersection-over-union (IoU) distance to match each tracklet and the detection information to improve the tracking robustness of the MOT model. Experimental results show that the proposed method achieves 70.38% multiple object tracking accuracy (MOTA) and 69.53% identification F1-score (IDF1) results in the MOT20 benchmark dataset, and the identification switch (ID Switch) is reduced to 2026. Compared with FairMOT, the proposed method improves MOTA and IDF1 by 8.58% and 2.23%, respectively. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; 
LB  - Tsai2023Swin-JDE
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Zeng, Y.
AU  - Chen, J.
AU  - Han, N.
AU  - Chen, H.
TI  - Interval-enhanced Graph Transformer solution for session-based recommendation
PY  - 2023
T2  - Expert Systems with Applications
VL  - 213
C7  - 118970
DO  - 10.1016/j.eswa.2022.118970
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140077660&doi=10.1016%2fj.eswa.2022.118970&partnerID=40&md5=7a366f3aea10977de11fa8895b9e5053
AB  - In many online recommendation services (e.g., multimedia streaming, e-commerce), predicting user's next behavior based on anonymous sessions remains a challenging problem, mainly due to the lack of basic user information and limited behavioral information. The existing typical methods either model user behavior sequences based on RNN or capture potential relationships among items based on GNN. However, these pioneers ignore the importance of different time intervals in the behavior sequence, which implies the user preferences and makes the session sequence more distinguishable. Towards this end, we contribute an Interval-enhanced Graph Transformer (IGT) solution for the session-based recommendation, which takes both item relations and corresponding time intervals into consideration. Specifically, IGT consists of three modules: (i) Interval-enhanced session graph, which constructs all session sequences as session graphs with time intervals; (ii) Graph Transformer, which is embedded with time intervals is adopted to learn the complex interaction information among items. Among them, we design various time interval embedding functions, which can be flexibly injected into the framework; (iii) Preference representation and prediction, which uses an attention network to fuse the user's long-term preferences and short-term preferences to predict the next click. By conducting extensive experiments on the DIGINETICA, YOOCHOOSE and Last.FM three real-world datasets, we validate that IGT outperforms state-of-the-art solutions. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wang2023Interval-enhanced
ER  -

TY  - JOUR
AU  - Chauhan, J.
AU  - Bedi, J.
TI  - EffViT-COVID: A dual-path network for COVID-19 percentage estimation
PY  - 2023
T2  - Expert Systems with Applications
VL  - 213
C7  - 118939
DO  - 10.1016/j.eswa.2022.118939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140310446&doi=10.1016%2fj.eswa.2022.118939&partnerID=40&md5=fba16c5cb3b528a561fa65a471cdfa69
AB  - The first case of novel Coronavirus (COVID-19) was reported in December 2019 in Wuhan City, China and led to an international outbreak. This virus causes serious respiratory illness and affects several other organs of the body differently for different patient. Worldwide, several waves of this infection have been reported, and researchers/doctors are working hard to develop novel solutions for the COVID diagnosis. Imaging and vision-based techniques are widely explored for the prediction of COVID-19; however, COVID infection percentage estimation is under explored. In this work, we propose a novel framework for the estimation of COVID-19 infection percentage based on deep learning techniques. The proposed network utilizes the features from vision transformers and CNN (Convolutional Neural Networks), specifically EfficientNet-B7. The features of both are fused together for preparing an information-rich feature vector that contributes to a more precise estimation of infection percentage. We evaluate our model on the Per-COVID-19 dataset (Bougourzi et al., 2021b) which comprises labeled CT data of COVID-19 patients. For the evaluation of the model on this dataset, we employ the most widely-used slice-level metrics, i.e., Pearson correlation coefficient (PC), Mean absolute error (MAE), and Root mean square error (RMSE). The network outperforms the other state-of-the-art methods and achieves 0.9886±0.009, 1.23±0.378, and 3.12±1.56, PC, MAE, and RMSE, respectively, using a 5-fold cross-validation technique. In addition, the overall average difference in the actual and predicted infection percentage is observed to be <2%. In conclusion, the detailed experimental results reveal the robustness and efficiency of the proposed network. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Chauhan2023EffViT-COVID
ER  -

TY  - JOUR
AU  - Chen, N.
AU  - Tu, H.
AU  - Duan, X.
AU  - Hu, L.
AU  - Guo, C.
TI  - Semisupervised anomaly detection of multivariate time series based on a variational autoencoder
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 5
SP  - 6074
EP  - 6098
DO  - 10.1007/s10489-022-03829-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133487247&doi=10.1007%2fs10489-022-03829-1&partnerID=40&md5=ad05804de83196e3a0a91059a8856748
AB  - In a large-scale cloud environment, many key performance indicators (KPIs) of entities are monitored in real time. These multivariate time series consist of high-dimensional, high-noise, random and time-dependent data. As a common method implemented in artificial intelligence for IT operations (AIOps), time series anomaly detection has been widely studied and applied. However, the existing detection methods cannot fully consider the influence of multiple factors and cannot quickly and accurately detect anomalies in multivariate KPIs of entities. Concurrently, fine-grained root cause locations cannot be determined for detected anomalies and often require abundant normal data that are difficult to obtain for model training. To solve these problems, we propose a long short-term memory (LSTM)-based semisupervised variational autoencoder (VAE) anomaly detection strategy called LR-SemiVAE. First, LR-SemiVAE uses VAE to perform feature dimension reduction and reconstruction of multivariate time series data and judges whether the entity is abnormal by calculating the reconstruction probability score. Second, by introducing an LSTM network into the VAE encoder and decoder, the model can fully learn the time dependence of multivariate time series. Then, LR-SemiVAE predicts the data labels by introducing a classifier to reduce the dependence on the original labeled data during model training. Finally, by proposing a new evidence lower bound (ELBO) loss function calculation method, LR-SemiVAE pays attention to the normal pattern and ignores the abnormal pattern during training to reduce the time cost of removing random anomaly and noise data. However, due to the limitations of LSTM in learning the long-term dependence of time series data, based on LR-SemiVAE, we propose a transformer-based semisupervised VAE anomaly detection and location strategy called RT-SemiVAE for cluster systems with complex service dependencies. This method learns the long-term dependence of multivariate time series by introducing a parallel multihead attention mechanism transformer, while LSTM is used to capture short-term dependence, and the introduction of parallel computing also markedly reduces model training time. After RT-SemiVAE detects entity anomalies, it traces the root entities according to the obtained service dependence graph and locates the root causes at the indicator level. We verify the strategies by using public data sets and constructing a system prototype. Experimental results show that compared with existing baseline methods, the LR-SemiVAE and RT-SemiVAE strategies can detect anomalies more quickly and accurately and perform fine-grained and accurate localization of the root causes of anomalies. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; 
LB  - Chen2023Semisupervised
ER  -

TY  - JOUR
AU  - Yuan, J.
AU  - Chen, S.-Z.
AU  - Yu, S.S.
AU  - Zhang, G.
AU  - Chen, Z.
AU  - Zhang, Y.
TI  - A Kernel-Based Real-Time Adaptive Dynamic Programming Method for Economic Household Energy Systems
PY  - 2023
T2  - IEEE Transactions on Industrial Informatics
VL  - 19
IS  - 3
SP  - 2374
EP  - 2384
DO  - 10.1109/TII.2022.3181034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133738792&doi=10.1109%2fTII.2022.3181034&partnerID=40&md5=e520f9517d4bf4af4c59d4ae50519eb9
AB  - Modern home energy management systems (HEMSs) have great flexibility of energy consumption for customers, but at the same time, bear a range of problems, such as the high system complexity, uncertainty and time-varying nature of load consumptions, and renewable sources generation. This has brought great challenges for the real-time control. To solve these problems, we propose an HEMS that integrates a kernel-based real-time adaptive dynamic programming (K-RT-ADP) with a new preprocessing short-term prediction technique. For the preprocessing short-term prediction, we propose a gated recurrent unit-bidirectional encoder representations from the transformer (GRU-BERT) model to improve the forecasting accuracy of electrical loads and renewable energy generation. In particular, we classify household appliances into the temperature-sensitive loads, human activity sensitive loads, and insensitive/constant loads. The GRU-BERT model can incorporate weather and human activity information to predict load consumption and solar generation. For real-time control, we propose and employ the K-RT-ADP HEMS based on the GRU-BERT prediction algorithm. The objective of the K-RT-ADP HEMS is to minimize the electricity cost and maximize the solar energy utilization. To enhance the nonlinear approximation ability and generalization ability of the adaptive dynamic programming (ADP) algorithm, the K-RT-ADP algorithm leverages kernel mapping instead of neural networks. Hardware-in-the-loop experiments demonstrate the superiority of the proposed K-RT-ADP HEMS over the traditional ADP control through comparison.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Yuan2023Kernel-Based
ER  -

TY  - JOUR
AU  - Hu, Y.
AU  - Zhou, Y.
AU  - Song, J.
AU  - Xu, L.
AU  - Zhou, X.
TI  - Citywide Mobile Traffic Forecasting Using Spatial-Temporal Downsampling Transformer Neural Networks
PY  - 2023
T2  - IEEE Transactions on Network and Service Management
VL  - 20
IS  - 1
SP  - 152
EP  - 165
DO  - 10.1109/TNSM.2022.3214483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140741803&doi=10.1109%2fTNSM.2022.3214483&partnerID=40&md5=ca011decfe82eeb70aaabcb842e05265
AB  - The efficient automated network management methods for mobile operators (for example, mobile traffic prediction) are important goals for future mobile networks. Nevertheless, accurately predicting mobile traffic across an entire city is a challenge that requires the consideration of both prediction accuracy and computational complexity, especially in terms of the thousands of regions involved in high-density and complex base station deployment scenarios for 5G/beyond 5G/6G networks. To solve this problem, this study proposed a novel deep learning network based on the transformer, i.e., a spatial-temporal downsampling neural network (STD-Net), which can dynamically and simultaneously exploit the temporal, local, and global spatial dependencies of mobile traffic. To reduce the computational complexity in spatial domains and achieve a balance between generalization (for all regions) and fitness (for each region), the model decomposes a city into patches and focuses on simultaneously exploiting the temporal and local spatial dependencies in each patch via spatial-temporal transformers. This study's downsampling transformer is responsible for exploiting global spatial dependencies by uniformly sampling mobile traffic throughout all the regions of an entire city. Computing spatial correlations among sampled regions reduces the computational complexity even further. The superior prediction accuracy of the proposed STD-Net model over state-of-the-art baselines was confirmed by experiments on real-world mobile traffic datasets. The effectiveness of each module was tested to further validate the rationale and feasibility of the proposed STD-Net. Analyses of the computational complexity of the STD-Net revealed that its computational cost contains the same quadratic complexity as vanilla transformers. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Hu2023Citywide
ER  -

TY  - JOUR
AU  - Zhao, D.
AU  - Shi, Y.
AU  - Cheng, L.
AU  - Li, H.
AU  - Zhang, L.
AU  - Guo, H.
TI  - Time interval uncertainty-aware and text-enhanced based disease prediction
PY  - 2023
T2  - Journal of Biomedical Informatics
VL  - 139
C7  - 104239
DO  - 10.1016/j.jbi.2022.104239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148021531&doi=10.1016%2fj.jbi.2022.104239&partnerID=40&md5=8ab3ac614b3a5229f8db12e7e167df77
AB  - Deep learning methods have achieved success in disease prediction using electronic health records (EHR) data. Most of the existing methods have some limitations. First, most of the methods adopt a homogeneous decay way to deal with the effect of time interval on patient's previous visits information. However, the effect of the time interval between patient's visits is not always negative. For example, although the time interval between visits for patients with chronic diseases is relatively long, the importance of the previous visit to the next visit is high, and we may not be able to consider the effect of the time interval as negative at this point. That is, the effect of the time interval on previous visits is exerted in a nonmonotonic manner, and it is either positive, negative, or neutral. In addition, the effect of text information on prediction results is not taken into account in most of methods. The text in EHR contains a description of the patient's past medical history and current symptoms of the disease, which is important for prediction results. In order to solve these issues, we propose a Time Interval Uncertainty-Aware and Text-Enhanced Based Disease Prediction Model, which utilizes the uncertain effects of time intervals and patient's text information for disease prediction. Firstly, we apply a cross-attention mechanism to generate a global representation of the patient using the patient's disease and text information from the EHR. Then, we use the key–query attention mechanism to obtain the two importance weights of the two visit sequences with and without time intervals, respectively. Furthermore, we achieve disease prediction by making slight adjustments to the encode part of the Transformer, a deep learning model based on a self-attention mechanism. We compare with various state-of-the-art models on two publicly available datasets, MIMIC-III and MIMIC-IV, and select the top 10 diseases with the highest frequency in the dataset as the target diseases. On the MIMIC-III dataset, our model is up to three percent higher than the optimal baseline in terms of evaluation metrics. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Zhao2023Time
ER  -

TY  - JOUR
AU  - Kartal, Y.S.
AU  - Kutlu, M.
TI  - Re-Think Before You Share: A Comprehensive Study on Prioritizing Check-Worthy Claims
PY  - 2023
T2  - IEEE Transactions on Computational Social Systems
VL  - 10
IS  - 1
SP  - 362
EP  - 375
DO  - 10.1109/TCSS.2021.3138642
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123277986&doi=10.1109%2fTCSS.2021.3138642&partnerID=40&md5=a023a6fcb8bfb108f32210afb728107e
AB  - The massive amount of misinformation spreading on the internet on a daily basis has enormous negative impacts on societies. Therefore, we need systems to help fact-checkers to combat misinformation and to raise public awareness of this important problem. In this article, we propose a hybrid model which combines bidirectional encoder representations from transformer (BERT) model with various features to prioritize claims based on their check-worthiness. Features we use include domain-specific controversial topics (CT), word embeddings (WE), part-of-speech (POS) tags, and others. In addition, we explore various ways of increasing labeled data size to effectively train the models, such as increasing positive (IncPos) samples, active learning (AL), and utilizing labeled data in other languages. In our extensive experiments, we show that our model outperforms all state-of-the-art models in test collections of Conference and Labs of Evaluation Forum (CLEF) CheckThat! Lab (CTL) 2018 and 2019. In addition, when positive samples are increased in the training set, our model achieves the best mean average precision (MAP) score reported so far for the test collection of CTL 2020. Furthermore, we show that cross-lingual training is effective for prioritizing Arabic and Turkish claims, but not for English.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Kartal2023Re-Think
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Wang, G.
AU  - Zhang, Y.
AU  - Yang, Q.
TI  - Analysis of user electricity consumption behavior based on density peak clustering with shared neighbors and attractiveness
PY  - 2023
T2  - Concurrency and Computation: Practice and Experience
VL  - 35
IS  - 3
C7  - e7518
DO  - 10.1002/cpe.7518
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142231415&doi=10.1002%2fcpe.7518&partnerID=40&md5=184398d95403815a7a9d4ff7c605614d
AB  - User behavior analysis is the research foundation of power load forecasting and power abnormal detection, and it is the theoretical support for smart grid planning and the construction of energy internet. Aiming at the complex characteristics of high-dimensional, noisy, and multi-redundant of power load data, this article used the principal component analysis (PCA) to reduce the dimensionality of power data. The density peaks clustering algorithm with shared neighbor and attractiveness (DPC-SNA) was then used to cluster the data with reduced dimensionality to extract the user's electricity consumption characteristics. The DPC-SNA algorithm first constructs a sample similarity measurement criterion that shares the similarity of neighbors, on which the local density is defined accordingly. The new local density can effectively distinguish the contributions of local samples and global samples. Incorporating the idea of universal gravitation, a new calculation method of sample attractiveness was defined, and the remaining samples were allocated by the attractiveness matrix. Experiment was performed using the actual load data of special transformer users in a certain area. The results show that there were five typical electricity consumption behavior characteristics in this area, namely, the evening-peak production type, all-day production type, multi-peak production type, daytime production type, and night production type. The corresponding load peak time periods were also obtained. © 2022 John Wiley & Sons, Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Li2023Analysis
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Mamouei, M.
AU  - Salimi-Khorshidi, G.
AU  - Rao, S.
AU  - Hassaine, A.
AU  - Canoy, D.
AU  - Lukasiewicz, T.
AU  - Rahimi, K.
TI  - Hi-BEHRT: Hierarchical Transformer-Based Model for Accurate Prediction of Clinical Events Using Multimodal Longitudinal Electronic Health Records
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 2
SP  - 1106
EP  - 1117
DO  - 10.1109/JBHI.2022.3224727
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144064624&doi=10.1109%2fJBHI.2022.3224727&partnerID=40&md5=1a2bb79036dd6e2226c355a97969a343
AB  - Electronic health records (EHR) represent a holistic overview of patients' trajectories. Their increasing availability has fueled new hopes to leverage them and develop accurate risk prediction models for a wide range of diseases. Given the complex interrelationships of medical records and patient outcomes, deep learning models have shown clear merits in achieving this goal. However, a key limitation of current study remains their capacity in processing long sequences, and long sequence modelling and its application in the context of healthcare and EHR remains unexplored. Capturing the whole history of medical encounters is expected to lead to more accurate predictions, but the inclusion of records collected for decades and from multiple resources can inevitably exceed the receptive field of the most existing deep learning architectures. This can result in missing crucial, long-term dependencies. To address this gap, we present Hi-BEHRT, a hierarchical Transformer-based model that can significantly expand the receptive field of Transformers and extract associations from much longer sequences. Using a multimodal large-scale linked longitudinal EHR, the Hi-BEHRT exceeds the state-of-the-art deep learning models 1% to 5% for area under the receiver operating characteristic (AUROC) curve and 1% to 8% for area under the precision recall (AUPRC) curve on average, and 2% to 8% (AUROC) and 2% to 11% (AUPRC) for patients with long medical history for 5-year heart failure, diabetes, chronic kidney disease, and stroke risk prediction. Additionally, because pretraining for hierarchical Transformer is not well-established, we provide an effective end-to-end contrastive pre-training strategy for Hi-BEHRT using EHR, improving its transferability on predicting clinical events with relatively small training dataset.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:C期刊; 
LB  - Li2023Hi-BEHRT
ER  -

TY  - JOUR
AU  - Zhu, X.
AU  - Zhu, Y.
AU  - Zhang, L.
AU  - Chen, Y.
TI  - A BERT-based multi-semantic learning model with aspect-aware enhancement for aspect polarity classification
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 4
SP  - 4609
EP  - 4623
DO  - 10.1007/s10489-022-03702-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131918728&doi=10.1007%2fs10489-022-03702-1&partnerID=40&md5=7e0c66d784ee4896cb5382c437c022eb
AB  - Aspect-Based Sentiment Classification (ABSA), predicting the sentimental tendency towards given aspects, is an important branch in natural language understanding. However, in the existing deep learning models for ABSA, there is a contradiction between the fine sentiment analysis and the small amount of corpus. To solve this contradiction, we propose a BERT-based Multi-Semantic Learning (BERT-MSL) model with aspect-aware enhancement for aspect polarity classification, which follows the Transformer structure in BERT and uses lightweight multi-head self-attentions for encoding. First, we make full use of the extensive pre-training and post-training of the BERT model to obtain the initialization parameters with rich knowledge for our BERT-MSL model, so that our model can be quickly adapted to the ABSA task only by fine-tuning on a small corpus. Second, to achieve the fine sentiment analysis centered on aspect target, we propose a BERT-based multi-semantic learning model composed of the left-side local semantic, right-side local semantic, aspect target semantic and global semantic learning modules, and propose an aspect-aware enhancement method based on BERT and multi-head attention. Third, we propose two alternative semantic merging methods to generate the final expressive-powerful sentiment semantics for ABSA. Furthermore, to expand the application scope of our model, we design an advanced structure for our model by introducing a CNN-based semantic refinement layer. Experimental results on five SemEval and Twitter datasets demonstrate that our model improves the stability and robustness of ABSA and significantly outperforms some of the state-of-the-art models under the BERT Post-Training (BERT-PT) environment. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Zhu2023BERT-based
ER  -

TY  - JOUR
AU  - Wu, X.
AU  - Tang, B.
AU  - Zhao, M.
AU  - Wang, J.
AU  - Guo, Y.
TI  - STR Transformer: A Cross-domain Transformer for Scene Text Recognition
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 3
SP  - 3444
EP  - 3458
DO  - 10.1007/s10489-022-03728-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131092410&doi=10.1007%2fs10489-022-03728-5&partnerID=40&md5=f373d15fec43b612a8d596a6b88a9695
AB  - Scene text recognition is an indispensable part of computer vision, which aims to extract text information from an image. However, effective extraction of texts following spelling rules remains a challenge for scene text recognition. We propose a cross-domain Transformer, called STR Transformer (STRT), which can not only extract texts from an image but also correct characters effectively according to their spelling rules. Specifically, we propose a Spline Transformer to extract hierarchical features of images without the convolution layers, which has the flexibility to build models with various scales and has linear computational complexity with respect to image size. Furthermore, an iterative Text Transformer is designed to predict the probability distribution of current character in the character sequence, which can effectively reduce the impact of noise. Extensive experiments demonstrate that the proposed STRT outperforms state-of-the-art methods on various benchmark datasets of scene text recognition. The qualitative and quantitative analysis proves the effectiveness and efficiency of the proposed STRT method. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Wu2023STR
ER  -

TY  - JOUR
AU  - Baghershahi, P.
AU  - Hosseini, R.
AU  - Moradi, H.
TI  - Self-attention presents low-dimensional knowledge graph embeddings for link prediction
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 260
C7  - 110124
DO  - 10.1016/j.knosys.2022.110124
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143845192&doi=10.1016%2fj.knosys.2022.110124&partnerID=40&md5=6d0cc89482b4552b8c021b067eeb2881
AB  - A few models have tried to tackle the link prediction problem, also known as knowledge graph completion, by embedding knowledge graphs in comparably lower dimensions. However, the state-of-the-art results are attained at the cost of considerably increasing the dimensionality of embeddings which causes scalability issues in the case of huge knowledge bases. Transformers have been successfully used recently as powerful encoders for knowledge graphs, but available models still have scalability issues. To address this limitation, we introduce a Transformer-based model to gain expressive low-dimensional embeddings. We utilize a large number of self-attention heads as the key to applying query-dependent projections to capture mutual information between entities and relations. Empirical results on WN18RR and FB15k-237 as standard link prediction benchmarks demonstrate that our model has favorably comparable performance with the current state-of-the-art models. Notably, we yield our promising results with a significant reduction of 66.9% in the dimensionality of embeddings compared to the five best recent state-of-the-art competitors on average. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:C期刊; FMS:C; 
LB  - Baghershahi2023Self-attention
ER  -

TY  - JOUR
AU  - Ye, X.
AU  - Bilodeau, G.-A.
TI  - Video prediction by efficient transformers
PY  - 2023
T2  - Image and Vision Computing
VL  - 130
C7  - 104612
DO  - 10.1016/j.imavis.2022.104612
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145215080&doi=10.1016%2fj.imavis.2022.104612&partnerID=40&md5=0163508f65c746d42113700e851f177c
AB  - Video prediction is a challenging computer vision task that has a wide range of applications. In this work, we present a new family of Transformer-based models for video prediction. Firstly, an efficient local spatial–temporal separation attention mechanism is proposed to reduce the complexity of standard Transformers. Then, a full autoregressive model, a partial autoregressive model and a non-autoregressive model are developed based on the new efficient Transformer. The partial autoregressive model has a similar performance with the full autoregressive model but a faster inference speed. The non-autoregressive model not only achieves a faster inference speed but also mitigates the quality degradation problem of the autoregressive counterparts, but it requires additional parameters and loss function for learning. Given the same attention mechanism, we conducted a comprehensive study to compare the proposed three video prediction variants. Experiments show that the proposed video prediction models are competitive with more complex state-of-the-art convolutional-LSTM based models. The source code is available at https://github.com/XiYe20/VPTR. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Ye2023Video
ER  -

TY  - JOUR
AU  - Yao, C.
AU  - Feng, L.
AU  - Kong, Y.
AU  - Xiao, L.
AU  - Chen, T.
TI  - Transformers and CNNs fusion network for salient object detection
PY  - 2023
T2  - Neurocomputing
VL  - 520
SP  - 342
EP  - 355
DO  - 10.1016/j.neucom.2022.10.081
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144068342&doi=10.1016%2fj.neucom.2022.10.081&partnerID=40&md5=3f2fac3f85b4089b063582eb62e4d19d
AB  - Recently, Salient Object Detection (SOD) has achieved promising results thanks to the rapid evolution of CNN architectures. However, those CNN-based methods show limited capacity in modeling long-range interaction among pixels. In this paper, we propose to combine the merits from CNN and Transformer and design a unified model for RGB and RGB-D SOD. First, we represent the image with a sequence-to-sequence perspective and use a Transformer-based branch to express long-distance relationships of image tokens to obtain global semantic information and predict a coarse saliency map. Second, we employ a CNN-based branch to extract multi-scale local detail features to predict contour prediction for auxiliary supervision at each level. Finally, we propose the Bi-enhancement Fusion Module to fuse multi-scale cues from two branches to predict a more accurate saliency map. In addition, for RGB-D SOD, to obtain effective cross-modality features, we propose a Cross-modality Multi-Scale Transformer Module and a Depth-induced Enhancement Module to fuse RGB and depth cues in the Transformers branch and the CNNs branch, respectively. Experiments on both RGB and RGB-D SOD datasets demonstrate that our proposed model achieves satisfactory performance compared with state-of-the-art methods. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Yao2023Transformers
ER  -

TY  - JOUR
AU  - Qiao, Z.
AU  - Fu, Y.
AU  - Wang, P.
AU  - Xiao, M.
AU  - Ning, Z.
AU  - Zhang, D.
AU  - Du, Y.
AU  - Zhou, Y.
TI  - RPT: Toward Transferable Model on Heterogeneous Researcher Data via Pre-Training
PY  - 2023
T2  - IEEE Transactions on Big Data
VL  - 9
IS  - 1
SP  - 186
EP  - 199
DO  - 10.1109/TBDATA.2022.3152386
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125335148&doi=10.1109%2fTBDATA.2022.3152386&partnerID=40&md5=f63f24b327c5b4939be9648abd55c7a4
AB  - With the growth of the academic engines, the mining and analysis acquisition of massive researcher data, such as collaborator recommendation and researcher retrieval, has become indispensable for improving the quality and intelligence of services. However, most of the existing studies for researcher data mining focus on a single task for a particular application scenario and learning a task-specific model, which is usually unable to transfer to out-of-scope tasks. In this paper, we propose a multi-task self-supervised learning-based researcher data pre-training model named RPT, which is efficient to accomplish multiple researcher data mining tasks. Specifically, we divide the researchers' data into semantic document sets and community graph. We design the hierarchical Transformer and the local community encoder to capture information from the two categories of data, respectively. Then, we propose three self-supervised learning objectives to train the whole model. For RPT's main task, we leverage contrastive learning to discriminate whether these captured two kinds of information belong to the same researcher. In addition, two auxiliary tasks, named hierarchical masked language model and community relation prediction for extracting semantic and community information, are integrated to improve pre-training. Finally, we also propose two transfer modes of RPT for fine-tuning in different scenarios. We conduct extensive experiments to evaluate RPT, results on three downstream tasks verify the effectiveness of pre-training for researcher data mining. © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Qiao2023RPT
ER  -

TY  - JOUR
AU  - Lian, J.
AU  - Ren, W.
AU  - Li, L.
AU  - Zhou, Y.
AU  - Zhou, B.
TI  - PTP-STGCN: Pedestrian Trajectory Prediction Based on a Spatio-temporal Graph Convolutional Neural Network
PY  - 2023
T2  - Applied Intelligence
VL  - 53
IS  - 3
SP  - 2862
EP  - 2878
DO  - 10.1007/s10489-022-03524-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132604776&doi=10.1007%2fs10489-022-03524-1&partnerID=40&md5=69efaea13b0af65d746c25a5fc056be3
AB  - It is the prerequisite to ensure the safety of road users in traffic scenes for the application of autonomous vehicles. Pedestrians are the main participants in traffic scenes, and reasonable inference and prediction of their future trajectories are crucial for autonomous driving technology and road safety. Pedestrian trajectories are highly dynamic, apparently random, and complex to interact with traffic environment agents; therefore, selective modeling of spatial interaction and temporal dependence of pedestrians is necessary. To address this challenge, this paper proposes a novel pedestrian trajectory prediction model based on a spatio-temporal graph convolutional network (PTP-STGCN). Specifically, a new crowd interaction attention (CIA) function is defined to quantify the interaction information between adjacent pedestrians better. This function captures the spatial interaction features of pedestrians at each time step by a spatial graph convolution network (S-GCN). Meanwhile, the time-series motion features of each pedestrian are extracted by a temporal transformer network (T-transformer), and a spatio-temporal interaction graph of pedestrian features is constructed by the STGCN composed of the S-GCN and T-transformer. Finally, a time-extrapolator convolutional neural network (TXP-CNN) is used to predict pedestrian trajectories in the time dimension of the STGCN. The experimental results on the ETH and UCY datasets show that the proposed model achieves better performance than the state-of-the-art baselines regarding the average displacement error (ADE) and final displacement error (FDE). Due to the excellent performance in pedestrian trajectory prediction, the proposed network achieves more predictive final planned trajectory of an autonomous vehicle, while avoiding unnecessary trajectory changes and collision risk, thus providing a promising solution for practical pedestrian trajectory prediction applications. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; 
LB  - Lian2023PTP-STGCN
ER  -

TY  - JOUR
AU  - Chellatamilan, T.
AU  - Narayanasamy, S.K.
AU  - Garg, L.
AU  - Srinivasan, K.
AU  - Islam, S.M.N.
TI  - Ensemble Text Summarization Model for COVID-19-Associated Datasets
PY  - 2023
T2  - International Journal of Intelligent Systems
VL  - 2023
C7  - 3106631
DO  - 10.1155/2023/3106631
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180578063&doi=10.1155%2f2023%2f3106631&partnerID=40&md5=569bb0f7a09cafb88b62749f2801b2f7
AB  - The work of text summarization in question-and-answer systems has gained tremendous popularity recently and has influenced numerous real-world applications for efficient decision-making processes. In this regard, the exponential growth of COVID-19-related healthcare records has necessitated the extraction of fine-grained results to forecast or estimate the potential course of the disease. Machine learning and deep learning models are frequently used to extract relevant insights from textual data sources. However, in order to summarize the textual information relevant to coronavirus, we have concentrated on a number of natural language processing (NLP) models in this research, including Bidirectional Encoder Representations of Transformers (BERT), Sequence-to-Sequence, and Attention models. This ensemble model is built on the previously mentioned models, which primarily concentrate on the segmented context terms included in the textual input. Most crucially, this research has concentrated on two key variations: grouping-related sentences using hierarchical clustering approaches and the distributional semantics of the terms found in the COVID-19 dataset. The gist evaluation (ROUGE) score result shows a significant and respectable accuracy of 0.40 average recalls.  © 2023 T. Chellatamilan et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chellatamilan2023Ensemble
ER  -

TY  - JOUR
AU  - Zhou, Q.
AU  - Wang, Z.
TI  - A Network Intrusion Detection Method for Information Systems Using Federated Learning and Improved Transformer
PY  - 2023
T2  - International Journal on Semantic Web and Information Systems
VL  - 20
IS  - 1
DO  - 10.4018/IJSWIS.334845
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180284157&doi=10.4018%2fIJSWIS.334845&partnerID=40&md5=0d63471c2fdf9c8027ec66fca3749c94
AB  - A network intrusion detection method for information systems using federated learning and improved transformer is proposed to address the problems of long detection time and low security and accuracy when analyzing massive data in most existing intrusion detection methods. Firstly, a network intrusion detection system is constructed based on a federated learning framework, and the transformer model is used as its universal detection model. Then, the dataset is divided and an improved generative adversarial network is used for data augmentation to generate a new sample set to overcome the influence of minority class samples. At the same time, the new samples are input into the transformer local model for network attack type detection and analysis. Finally, the authors aggregate the detection results of each local model and input them into the Softmax classifier to obtain the final classification prediction results. © 2023 IGI Global. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Zhou2023Network
ER  -

TY  - JOUR
AU  - Sedona, R.
AU  - Paris, C.
AU  - Ebert, J.
AU  - Riedel, M.
AU  - Cavallaro, G.
TI  - Toward the Production of Spatiotemporally Consistent Annual Land Cover Maps Using Sentinel-2 Time Series
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 2505805
SP  - 1
EP  - 5
DO  - 10.1109/LGRS.2023.3329428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178067066&doi=10.1109%2fLGRS.2023.3329428&partnerID=40&md5=20059174269c4eb6adabc882ba5dd938
AB  - Land cover (LC) maps generated by the classification of remote-sensing (RS) data allow for monitoring Earth processes and the dynamics of objects and phenomena. For accurate LC variability quantification in environmental monitoring, maps need to be spatiotemporally consistent, continually updated, and indicate permanent changes. However, producing frequent and spatiotemporally consistent LC maps is challenging because it involves balancing the need for temporal consistency with the risk of missing real changes. In this work, we propose a scalable and semiautomatic method for generating annual LC maps with labels that are consistently applied from one year to the next. It uses a Transformer deep-learning (DL) model as a classifier, which is trained on satellite time series (TS) of images using high performance computing (HPC). The trained model can generate stable maps by shifting the prediction window along the temporal direction. The effectiveness of the proposed approach is tested qualitatively and quantitatively on a multiannual Sentinel-2 dataset acquired over a three-year period in a study area located in the southern Italian Alps.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Sedona2023Toward
ER  -

TY  - JOUR
AU  - Huang, B.
AU  - Dou, H.
AU  - Luo, Y.
AU  - Li, J.
AU  - Wang, J.
AU  - Zhou, T.
TI  - Adaptive Spatiotemporal Transformer Graph Network for Traffic Flow Forecasting by IoT Loop Detectors
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 2
SP  - 1642
EP  - 1653
DO  - 10.1109/JIOT.2022.3209523
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139442456&doi=10.1109%2fJIOT.2022.3209523&partnerID=40&md5=d99f086996cc94caa1e18bdc9b5d36d2
AB  - Extensive traffic flow data are received from the loop detector networks every second, which requires us to develop an effective and efficient algorithm to predict future traffic flow. However, dynamic traffic conditions on a road are not just influenced by sequential patterns in the temporal dimension, but also by other roadways in the spatial dimension. Although many successful models have been developed in previous studies to forecast future traffic flows, most of them have shortcomings in modeling spatial and temporal dependencies. In this article, we focus on spatial-temporal factors and propose a new adaptive spatial-temporal transformer graph network (ASTTGN) to improve the accuracy of traffic forecasting by jointly modeling the spatial-temporal information of road networks. Specifically, we propose an adaptive spatial-temporal transformer module, which contains two developed adaptive transformer modules for capturing dynamic spatial dependence and temporal dependence across multiple time steps, respectively. Finally, feature fusion is performed through a gated feature aggregation layer to simulate the effect of complex spatial-temporal factors on traffic conditions. In particular, the multihead attention mechanism employed by the transformer can effectively explore the potential spatial-temporal dependence patterns in different subspaces. Experimental results on two real-world traffic data sets demonstrate the superiority of the proposed model compared to existing techniques.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:C期刊; 
LB  - Huang2023Adaptive
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Wang, M.
AU  - Yang, X.
AU  - Chu, D.
TI  - DS-UNet: Dual-Stream U-Net for Oil Spill Detection of SAR Image
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 4014905
DO  - 10.1109/LGRS.2023.3330957
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177063862&doi=10.1109%2fLGRS.2023.3330957&partnerID=40&md5=d950378464feb672ca56d40e9a746894
AB  - The oil spill detection of synthetic aperture radar (SAR) images has had great success. Existing deep-learning-based methods make predictions mainly based on the U-Net structure and Transformer, which fail to blend the local and global information generated by other different feature maps. In this letter, we proposed a dual-stream Unet (DS-Unet) for oil spill detection of SAR images. In particular, the proposed DS-Unet consists of two modules: an edge feature extraction module for extracting the local information and an interscale alignment module for capturing the global information. Moreover, an edge extraction branch is applied to handle the speckle noise of SAR images. Extensive experiments on two real-world datasets (Palsar and Sentinel) have shown that the proposed DS-Unet outperforms many existing state-of-the-art methods.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Li2023DS-UNet
ER  -

TY  - JOUR
AU  - Ba, A.
AU  - Lynch, K.
AU  - Ploennigs, J.
AU  - Schaper, B.
AU  - Lohse, C.
AU  - Lorenzi, F.
TI  - Automated Configuration of Heterogeneous Graph Neural Networks With a Semantic Math Parser for IoT Systems
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 2
SP  - 1042
EP  - 1052
DO  - 10.1109/JIOT.2022.3204889
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137885314&doi=10.1109%2fJIOT.2022.3204889&partnerID=40&md5=4538ce1e74eca472b377c1c3627f2c5e
AB  - Efficient training of deep learning models from time series data for Internet of Things (IoT) systems requires a good understanding of the domain, particularly if the training is automated for large-scale applications. Heterogeneous graph neural networks (HGNNs) are a promising approach for incorporating domain knowledge into the modeling framework and consequently improving model performance. However, encoding domain knowledge into HGNNs is nontrivial for IoT systems and requires substantial manual effort. This complicates the adoption of HGNNs in practical settings. To overcome this drawback, we propose a framework for the automatic derivation of HGNN features by semantically parsing equations present in scientific and dedicated publications. We encode the derived features considering physical causation from these equations into an HGNN using an underlying Transformer for prediction and anomaly detection. We validate our approach using two IoT use cases, namely, the prediction of the remaining energy in the battery of an electric race car and the anomaly detection during pick and place operations in a robot workcell. We demonstrate that our approach significantly outperforms other competitive techniques.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Ba2023Automated
ER  -

TY  - JOUR
AU  - Hu, L.
AU  - Zhang, Y.
AU  - Zhang, J.
AU  - Zhang, T.
AU  - Song, X.
AU  - Ji, X.
AU  - Liu, S.
AU  - Li, Z.
AU  - Li, W.
TI  - STP-Net: A Signal Prediction Method of Laminar Decompression Robot Based on Swin Transformer
PY  - 2023
T2  - International Journal of Intelligent Systems
VL  - 2023
C7  - 7842495
DO  - 10.1155/2023/7842495
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176472863&doi=10.1155%2f2023%2f7842495&partnerID=40&md5=2f90276b80e4196737c33e57573c88b7
AB  - Spinal surgery robots have a great application value in laminar decompression surgery. For a safe surgery, the robot needs to accurately identify the cutting state of the lamina. Therefore, it is very important to deal with various sensing signals in the form of a time series. However, various state recognition algorithms proposed so far cannot completely avoid cutting through the lamina, leaving hidden dangers for nerve thermal damage caused by high-temperature liquid splashing. We propose a long time series prediction algorithm called STP-Net, which combined with the existing algorithms for recognizing the lamina cutting state can stop the lamina cutting in advance, thus preserving a thin inner layer of cortical bone and blocking high-temperature liquid splashing. STP-Net has the following advantages: (1) Dimension reduction is first performed on Swin (shifted window) Transformer to obtain 1D Swin Transformer, which was used to develop STP-Net for long time series prediction, which not only has high accuracy but also shows a linear relationship between computational complexity and input sequence length L, namely, OL. (2) The token merging layer is proposed and applied to the encoder of STP-Net, which reduces the computation cost and improves the global information extraction capability of the algorithm. (3) STP-Net uses a generative decoder to output the prediction sequence directly through a single operation, which not only has high efficiency but also avoids the accumulation of errors. Taking force signals as an example, when 400 numbers are used to predict 100 numbers, the average mean square error (MSE) and mean absolute error (MAE) of standard STP-Net are 1.22 × 10-3 and 2.42 × 10-2, respectively. STP-Net, combined with the existing method for recognizing the lamina cutting status, can stop the robot from cutting in advance in 87.14% of the cases. In addition, the results of practical lamina cutting experiments confirmed the effectiveness of STP-Net. © 2023 Lei Hu et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Hu2023STP-Net
ER  -

TY  - JOUR
AU  - Savner, S.S.
AU  - Kanhangad, V.
TI  - Crowd Counting from Limited Labeled Data Using Active Learning
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 1662
EP  - 1666
DO  - 10.1109/LSP.2023.3330412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177023883&doi=10.1109%2fLSP.2023.3330412&partnerID=40&md5=05fe7b3b938435a6ba7780eb026e2001
AB  - Deep learning models have provided dramatic performance improvement for various computer vision tasks. These models, however, require huge amounts of labeled data to perform well. Collecting and labeling large datasets is often non-trivial and requires significant human effort. Crowd counting is one such task that demands a large amount of labeled training data. This labeling process requires a human annotator to manually mark a dot at the center of the head of each person present in the image, which is a laborious and tedious task, especially in densely crowded scenes. In this work, we investigate an active learning framework for crowd counting. Evaluations on mainstream datasets demonstrate the effectiveness of the proposed framework in reducing the annotation effort significantly with minimal compromise on count performance. Our method surpasses existing methods that focus on counting with limited labeled data.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Savner2023Crowd
ER  -

TY  - JOUR
AU  - Song, Y.-Z.
AU  - Chen, Y.-S.
AU  - Shuai, H.-H.
TI  - Decoupling-Cooperative Framework for Referring Expression Comprehension
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 1542
EP  - 1546
DO  - 10.1109/LSP.2023.3327651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176295363&doi=10.1109%2fLSP.2023.3327651&partnerID=40&md5=c2f0c1fac3a9204ccd9f6dbba031dc61
AB  - Referring Expression Comprehension (REC) aims to locate a specific object within an image by interpreting a referring expression articulated in natural language. This task comprises two essential branches: understanding and localizing. The former entails processing cognitive information from multimodal data, while the latter involves realizing the predictions in the perceptive visual space. Although various advanced approaches have been developed for each of these branches separately, existing REC approaches are unable to effectively leverage them due to the specific designs of architectures or objectives for REC, which bind understanding and localizing inseparably. To overcome this challenge, we propose the Decoupling-Cooperative Framework (DCF). The decoupling scheme in DCF enables us to utilize up-to-date methods for understanding and localizing with minimal constraints. Meanwhile, the proposed cooperative modules enable better integration of the strengths from both branches to achieve further enhancements. Extensive experiments demonstrate that DCF achieves state-of-the-art performance across four benchmarks, thus highlighting the generalizability of DCF.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Song2023Decoupling-Cooperative
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Huang, Z.
AU  - Hu, M.
AU  - Li, D.
AU  - Lu, X.
AU  - Luo, W.
AU  - Yang, D.
TI  - Structure Enhanced Path Reasoning for Knowledge Graph Completion
PY  - 2023
T2  - International Journal of Intelligent Systems
VL  - 2023
C7  - 3022539
DO  - 10.1155/2023/3022539
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176214650&doi=10.1155%2f2023%2f3022539&partnerID=40&md5=72846bcfd801a22b7808b5e2b2d8b203
AB  - Knowledge graphs are crucial foundations for building intelligent systems, such as question answering and recommendation. However, their performance is hampered by the incompleteness of KGs, so the knowledge graph completion arises to infer whether a triple of the form (head entity, relation, tail entity) is a missing fact. The path-based approach that encodes paths from the head entity to the tail entity for reasoning achieves good performance. Previous work suggests that entity type is beneficial for learning path representations. Nevertheless, the semantics of entities are not captured accurately, as many entities are not typed or loosely typed. In addition, previous methods tend to model paths only from the forward direction but fail to capture new path patterns from the reverse direction (i.e., tail entity to head entity). In this paper, we introduce a structure enhanced path reasoning (SPR) framework to address the above-given problems. First, the model uilizes the structure of entities, i.e., their relational contexts (the relations linked from the given entity), to obtain a reliable path representation that captures correct entity semantics. This information is accessible to all nonisolated entities in all KGs, so that it can compensate the semantics for entities or KGs that have no type available. Second, we leverage the structure of paths to derive their reverse paths, so as to enhance the path representation by additionally encoding the new patterns embedded in them through a dual path encoding method. In order to verify the effectiveness of the proposed methods, we design different architectures based on LSTM and Transformer, respectively. Experimental results on two benchmark datasets, WN18RR, and FB15k-237, show that our approach apparently outperforms state-of-the-art methods on fact prediction task and relation prediction task. Furthermore, extensive experiments illustrate the benefits of enhancing path reasoning by exploiting structure information from entity relational contexts and the dual path encoding method.  © 2023 Yilin Wang et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Wang2023Structure
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Sun, Y.
AU  - Xie, Z.
AU  - Zhai, B.
AU  - Jia, Y.
AU  - Du, S.
TI  - Query-guided refinement and dynamic spans network for video highlight detection and temporal grounding in online information systems
PY  - 2023
T2  - International Journal on Semantic Web and Information Systems
VL  - 19
IS  - 1
DO  - 10.4018/IJSWIS.332768
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175796716&doi=10.4018%2fIJSWIS.332768&partnerID=40&md5=0533a6a414ac0ad479a42de6e1dd7d8f
AB  - With the surge in online video content, finding highlights and key video segments have garnered widespread attention. Given a textual query, video highlight detection (HD) and temporal grounding (TG) aim to predict frame-wise saliency scores from a video while concurrently locating all relevant spans. Despite recent progress in DETR-based works, these methods crudely fuse different inputs in the encoder, which limits effective cross-modal interaction. To solve this challenge, the authors design QD-Net (query-guided refinement and dynamic spans network) tailored for HD&TG. Specifically, they propose a query-guided refinement module to decouple the feature encoding from the interaction process. Furthermore, they present a dynamic span decoder that leverages learnable 2D spans as decoder queries, which accelerates training convergence for TG. On QVHighlights dataset, the proposed QD-Net achieves 61.87 HD-HIT@1 and 61.88 TG-mAP@0.5, yielding a significant improvement of +1.88 and +8.05, respectively, compared to the state-of-The-Art method. © 2023 IGI Global. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Xu2023Query-guided
ER  -

TY  - JOUR
AU  - Shahed, S.
AU  - Lin, Y.
AU  - Hong, J.
AU  - Zhou, J.
AU  - Gao, F.
TI  - Explicitly Semantic Guidance for Face Sketch Attribute Recognition With Imbalanced Data
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 1502
EP  - 1506
DO  - 10.1109/LSP.2023.3324579
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174815106&doi=10.1109%2fLSP.2023.3324579&partnerID=40&md5=9a5e50ff5f8945086ed555c69ac374fe
AB  - Current facial attribute recognition (FAR) methods focus exclusively on photographs, and fail when applied to face sketches. Besides, face sketch attribute recognition (FSAR) encounters the following difficulties: the scarcity of labelled instances, the heavily imbalanced data distribution, and the inter-attribute correlations. To combat this challenge, in this letter, we propose a novel FSAR method based on the correlations between facial attributes and semantic regions. Our full model includes a shared feature extraction network, followed by several attribute-specific prediction branches. In each branch, we use the corresponding semantic mask, to select features from the associated region, for attribute prediction. Such explicitly semantic guidance (ESG) reduces the learning space, and thus alleviates the problems of limited data and imbalanced distribution. Besides, ESG decouples inter-attribute correlations, and makes the recognition process credible. Finally, we adopt the balanced cross-entropy loss during training, which further alleviates the problem of imbalanced data distribution. Experiments on the benchmark FS2K dataset demonstrate that our method significantly outperforms advanced visual recognition networks. Our codes have been released at: https://github.com/AiArt-HDU/ESGAR.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Shahed2023Explicitly
ER  -

TY  - JOUR
AU  - Wan, Z.
AU  - Liu, S.
AU  - Ding, F.
AU  - Li, M.
AU  - Srivastava, G.
AU  - Yu, K.
TI  - C2BNet: A Deep Learning Architecture with Coupled Composite Backbone for Parasitic EGG Detection in Microscopic Images
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
SP  - 1
EP  - 13
DO  - 10.1109/JBHI.2023.3318604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173390494&doi=10.1109%2fJBHI.2023.3318604&partnerID=40&md5=ed22f49a1bf8db4b9c087c4b18733c97
AB  - Internet of Medical Things (IoMT) enabled by artificial intelligence (AI) technologies can facilitate automatic diagnosis and management of chronic diseases (e.g., intestinal parasitic infection) based on two-dimensional (2D) microscopic images. To improve the model performance of object detection challenged by microscopic image characteristics (e.g., focus failure, motion blur, and whether zoomed or not), we propose Coupled Composite Backbone Network (C2BNet) to execute the parasitic egg detection task using 2D microscopic images. In particular, the C2BNet backbone adopts a two-path structure-based backbone and leverages model heterogeneity to learn object features from different perspectives. A novel feature composition style is proposed to flow the feature within the coupled composite backbone, and ensure mutual enhancement of feature representation ability among the different paths of the backbone. To further improve the accuracy of the detection results, we propose Multiscale Weighted Box Fusion (WBF) to fuse the location and confidence scores of all bounding boxes predicted from the multiscale feature maps, and iteratively refine the box coordinates to form the final prediction. Experimental results on Chula-ParasiteEgg-11 dataset demonstrate that the C2BNet not only performs satisfactorily compared with state-of-the-art methods, but also can focus more on learning detailed morphology features and abundant semantic features, resulting in more precise detection for parasitic eggs located in the 2D microscopic image. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Wan2023C2BNet
ER  -

TY  - JOUR
AU  - Yang, H.
AU  - Yu, H.
AU  - Zheng, K.
AU  - Hu, J.
AU  - Tao, T.
AU  - Zhang, Q.
TI  - Hyperspectral Image Classification Based on Interactive Transformer and CNN With Multilevel Feature Fusion Network
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 5507905
DO  - 10.1109/LGRS.2023.3303008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167780508&doi=10.1109%2fLGRS.2023.3303008&partnerID=40&md5=e2dabd17c986e960c0a53026945035c2
AB  - Due to the powerful feature information mining ability of deep learning, models such as convolutional neural network (CNN) and Transformer have gained a certain progress in hyperspectral image classification (HSIC). Characteristically, the CNN is good at extracting local information, but it has the limitation of insufficient receptive field. While the Transformer has the advantage of global representation, it ignores local details to some extent. Therefore, this letter proposes an interactive Transformer and CNN with a multilevel feature fusion network (ITCNet) for HSIC. Specifically, in the image-based framework, features with different perceptual fields and depths are extracted interactively by a multilayer Transformer and CNN, then fused through a multilevel feature fusion module for class prediction. Experimental results on two real datasets verify its efficiency, with improvements over other related methods. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; 
LB  - Yang2023Hyperspectral
ER  -

TY  - JOUR
AU  - Zhai, H.
AU  - Pan, X.
AU  - Yang, Y.
AU  - Jiang, J.
AU  - Li, Q.
TI  - Two-Stage Focus Measurement Network with Joint Boundary Refinement for Multifocus Image Fusion
PY  - 2023
T2  - International Journal of Intelligent Systems
VL  - 2023
C7  - 4155948
DO  - 10.1155/2023/4155948
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171329796&doi=10.1155%2f2023%2f4155948&partnerID=40&md5=8717b72b8d264c9d70d4dd0e8307c613
AB  - Focus measurement, one of the key tasks in multifocus image fusion (MFIF) frameworks, identifies the clearer parts of multifocus images pairs. Most of the existing methods aim to achieve disposable pixel-level focus measurement. However, the lack of sufficient accuracy often gives rise to misjudgments in the results. To this end, a novel two-stage focus measurement with joint boundary refinement network is proposed for MFIF. In this work, we adopt a coarse-to-fine strategy to gradually achieve block-level and pixel-level focus measurement for producing more fine-grained focus probability maps, instead of directly predicting at the pixel level. In addition, the joint boundary refinement optimizes the performance on the focused/defocused boundary component (FDB) during the focus measurement. To improve feature extraction capability, both CNN and transformer are employed to, respectively, encode local patterns and capture long-range dependencies. Then, the features from two input branches are legitimately aggregated by modeling the spatial complementary relationship in each pair of multifocus images. Extensive experiments demonstrate that the proposed model achieves state-of-the-art performance in both subjective perception and objective assessment. Copyright © 2023 Hao Zhai et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhai2023Two-Stage
ER  -

TY  - JOUR
AU  - Zou, C.
AU  - Wang, Z.
TI  - A New Semisupervised Method for Detecting Semantic Changes in Remote Sensing Images
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 5509105
DO  - 10.1109/LGRS.2023.3311106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170550256&doi=10.1109%2fLGRS.2023.3311106&partnerID=40&md5=2f574a38705867b18ee0b3696adf8dc8
AB  - The growing availability of high-quality remote sensing imagery has led to increased interest in semantic change detection (SCD). Supervised methods for this task have shown significant performance improvements, but acquiring labeled data is often challenging and expensive. To confront this challenge, we propose a semisupervised approach for SCD in remote sensing images using an innovative teacher-student model. We use a convolutional neural network (CNN) in the teacher model and a fusion design combining CNN and vision transformer in the student model, with the rationale that the CNN requires fewer training samples compared with vision transformer, and fusion network allows us to leverage the advantages of both. To further enhance the model's performance, we propose a novel data augmentation approach by interchanging bitemporal images as well as their labels. The principle for that is the change from one moment to another and vice versa are two different changes and can, therefore, be used to augment the training dataset. More importantly, this method does not reduce its reliability, because no noise is brought to the remote sensing images. By adopting this approach, we are able to better utilize the small labeled dataset to increase the precision of the model while maintaining the robustness. According to the experimental results, the proposed method outperforms several state-of-The-Art methods and achieves an improvement compared with bi-Temporal semantic reasoning network (Bi-SRNet) in mean intersection over union (mIoU)/separated kappa (SeK)/overall accuracy (OA) of 3.25/4.42/1.78, 6.37/11.72/2.91 on the SECOND and Landsat-SCD datasets, respectively.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zou2023New
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Pan, Z.
AU  - Hu, Y.
AU  - Lei, B.
TI  - FRCD: Feature Refine Change Detection Network for Remote Sensing Images
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 2504005
DO  - 10.1109/LGRS.2023.3303200
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167799205&doi=10.1109%2fLGRS.2023.3303200&partnerID=40&md5=5e5951ad783686a42574c4603f11ff09
AB  - Change detection (CD) plays an important role in Earth surface analysis. Current CD methods have achieved good performance in large flat areas, but CD of detailed parts is still a great challenge, and the loss of detail causes many faults around the change boundaries and on small objects. By analyzing the feature map of the widely used U-Net architecture in existing methods, we ascribe the detail loss to the depletion of detailed features during the top-to-down delivery in the U-Net architecture. The feature refine CD (FRCD) model is proposed in which the detection results are predicted directly from the multiscale features instead of the U-Net architecture. By direct prediction, the representation ability of details is enhanced, and thus the detection accuracy (Acc) of boundaries and small objects improves. Moreover, the normal upsampling in direct prediction is replaced with the deformable upsampling, which delivers detailed information from the low-level to the high-level via the deformable convolution, allowing the results to further fit boundaries in the FRCD model. Experimental results on two datasets confirm the effectiveness of FRCD compared to the state-of-the-art methods, and the CD results of boundaries and small objects are improved significantly by the proposed method. Code will be available after the acceptance of the letter in https://github.com/ijnokml/cdfr. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2023FRCD
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Cao, Y.
AU  - Sui, B.
TI  - DTHNet: Dual-Stream Network Based on Transformer and High-Resolution Representation for Shadow Extraction from Remote Sensing Imagery
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 8000905
DO  - 10.1109/LGRS.2023.3290176
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163555873&doi=10.1109%2fLGRS.2023.3290176&partnerID=40&md5=616b7d9983ade7d686897d93a5e665ff
AB  - Shadow extraction from remote sensing images is critical work. However, the interclass similarity of shadows with dark water, trees, and roads and the dependence on other objects make accurate shadow extraction still challenging. This letter proposes a dual-stream network (DTHNet) based on the transformer and high-resolution representation for multiscale shadow extraction. The DTHNet utilizes two streams: the high-resolution representation stream extracts deep features while maintaining detail information, and the clustering representation stream provides clustering feature constraints to enhance the ability to distinguish between foreground and background. Additionally, the designed multiscale auxiliary predictor (MAP) and hybrid loss aid in extracting multiscale shadows. We evaluated our proposed method on the aerial imagery dataset for shadow detection (AISD) dataset and compared it against six state-of-the-art generic semantic segmentation models and shadow extraction methods. The experimental results demonstrate that the DTHNet outperforms the existing methods.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zhang2023DTHNet
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Lv, B.
AU  - Jin, X.
AU  - Chen, X.
AU  - Zhang, X.
TI  - TBFormer: Two-Branch Transformer for Image Forgery Localization
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 623
EP  - 627
DO  - 10.1109/LSP.2023.3279018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161045333&doi=10.1109%2fLSP.2023.3279018&partnerID=40&md5=87183cef46ea9224108a7dbbb78d101e
AB  - Image forgery localization aims to identify forged regions by capturing subtle traces from high-quality discriminative features. In this paper, we propose a Transformer-style network with two feature extraction branches for image forgery localization, and it is named as Two-Branch Transformer (TBFormer). Firstly, two feature extraction branches are elaborately designed, taking advantage of the discriminative stacked Transformer layers, for both RGB and noise domain features. Secondly, an Attention-aware Hierarchical-feature Fusion Module (AHFM) is proposed to effectively fuse hierarchical features from two different domains. Although the two feature extraction branches have the same architecture, their features have significant differences since they are extracted from different domains. We adopt position attention to embed them into a unified feature domain for hierarchical feature investigation. Finally, a Transformer decoder is constructed for feature reconstruction to generate the predicted mask. Extensive experiments on publicly available datasets demonstrate the effectiveness of the proposed model.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Liu2023TBFormer
ER  -

TY  - JOUR
AU  - Flyckt, J.
AU  - Andersson, F.
AU  - Westphal, F.
AU  - Månsson, A.
AU  - Lavesson, N.
TI  - Explaining rifle shooting factors through multi-sensor body tracking
PY  - 2023
T2  - Intelligent Data Analysis
VL  - 27
IS  - 2
SP  - 535
EP  - 554
DO  - 10.3233/IDA-216457
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161187936&doi=10.3233%2fIDA-216457&partnerID=40&md5=5298e7d999e28d62b3031d265f0e2f3a
AB  - There is a lack of data-driven training instructions for sports shooters, as instruction has commonly been based on subjective assessments. Many studies have correlated body posture and balance to shooting performance in rifle shooting tasks, but have mostly focused on single aspects of postural control. This study has focused on finding relevant rifle shooting factors by examining the entire body over sequences of time. A data collection was performed with 13 human participants carrying out live rifle shooting scenarios while being recorded with multiple body tracking sensors. A pre-processing pipeline produced a novel skeleton sequence representation, which was used to train a transformer model. The predictions from this model could be explained on a per sample basis using the attention mechanism, and visualised in an interactive format for humans to interpret. It was possible to separate the different phases of a shooting scenario from body posture with a high classification accuracy (80%). Shooting performance could be detected to an extent by separating participants using their strong and weak shooting hand. The dataset and pre-processing pipeline, as well as the techniques for generating explainable predictions presented in this study have laid the groundwork for future research in the sports shooting domain.  © 2023 - IOS Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Flyckt2023Explaining
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Wu, R.
AU  - Tan, Q.
AU  - Yang, Z.
AU  - Huang, H.
TI  - Masked Spectral Bands Modeling With Shifted Windows: An Excellent Self-Supervised Learner for Classification of Medical Hyperspectral Images
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 543
EP  - 547
DO  - 10.1109/LSP.2023.3273506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159846583&doi=10.1109%2fLSP.2023.3273506&partnerID=40&md5=f822f0978001e1353a03c3abedecb6f3
AB  - Hyperspectral imaging has become a popular imaging technique in the medical field, and the development of algorithms for computer-aided diagnosis (CAD) is urgently required. Traditional deep learning techniques require a lot of annotated data, which is a burden on doctors. Self-supervised learning (SSL) is a solution for extracting feature representations from unlabeled data. However, traditional CNN-based SSL algorithms cannot explore relations between neighboring and long-range spectral bands, which limits classification performance. In this letter, the proposed solution is a novel SSL method using a transformer-based technique called masked spectral bands modeling with shifted windows (MSBMSW). This method predicts masked spectral bands as the pretext task and uses a self-attention mechanism with shifted windows to capture the divergence of neighboring spectral bands and enhance information exchange between long-range spectral bands. Experimental results demonstrate that MSBMSW achieves better classification results than many state-of-the-art methods and has potential clinical value for CAD of MHSIs.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Li2023Masked
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Liang, W.
AU  - Hao, F.
AU  - Xu, J.
TI  - Mask-and-Edge Co-Guided Separable Network for Camouflaged Object Detection
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 748
EP  - 752
DO  - 10.1109/LSP.2023.3286787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163765282&doi=10.1109%2fLSP.2023.3286787&partnerID=40&md5=86257c18132693b6ef98e01221971d41
AB  - Camouflaged object detection (COD) involves segmenting objects that share similar patterns, such as color and texture, with their surroundings. Current methods typically employ multiple well-designed modules or rely on edge cues to learn object feature representations for COD. However, these methods still struggle to capture the discriminative semantics between camouflaged objects (foreground) and background, possibly generating blurry prediction maps. To address these limitations, we propose a novel mask-and-edge co-guided separable network (MECS-Net) for COD that leverages both edge and mask cues to learn more discriminative representations and improve detection performance. Specifically, we design a mask-and-edge co-guided separable attention (MECSA) module, which consists of three flows for separately capturing edge, foreground, and background semantics. In addition, we propose a multi-scale enhancement fusion (MEF) module to aggregate multi-scale features of objects. The predictions are decoded in a top-down manner. Extensive experiments and visualizations demonstrate that our CNN-based and Transformer-based MECS-Net outperform 13 state-of-the-art methods on four popular COD datasets.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Wu2023Mask-and-Edge
ER  -

TY  - JOUR
AU  - Kwon, S.
AU  - Lee, S.
AU  - Ryu, D.
AU  - Baik, J.
TI  - Pre-trained Model-based Software Defect Prediction for Edge-cloud Systems
PY  - 2023
T2  - Journal of Web Engineering
VL  - 22
IS  - 2
SP  - 255
EP  - 278
DO  - 10.13052/jwe1540-9589.2223
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164516945&doi=10.13052%2fjwe1540-9589.2223&partnerID=40&md5=185e60186554e42416dad52c7376dd7c
AB  - Edge-cloud computing is a distributed computing infrastructure that brings computation and data storage with low latency closer to clients. As interest in edge-cloud systems grows, research on testing the systems has also been actively studied. However, as with traditional systems, the amount of resources for testing is always limited. Thus, we suggest a function-level just-in-time (JIT) software defect prediction (SDP) model based on a pre-trained model to address the limitation by prioritizing the limited testing resources for the defect-prone functions. The pre-trained model is a transformer-based deep learning model trained on a large corpus of code snippets, and the fine-tuned pre-trained model can provide the defect proneness for the changed functions at a commit level. We evaluate the performance of the three popular pre-trained models (i.e., CodeBERT, GraphCodeBERT, UniXCoder) on edge-cloud systems in within-project and cross-project environments. To the best of our knowledge, it is the first attempt to analyse the performance of the three pre-trained model-based SDP models for edge-cloud systems. As a result, we can confirm that UniXCoder showed the best performance among the three in the WPDP environment. However, we also confirm that additional research is necessary to apply the SDP models to the CPDP environment. © 2023 River Publishers.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Kwon2023Pre-trained
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Song, T.
AU  - Sun, X.
AU  - Gao, C.
TI  - TransMIN: Transformer-Guided Multi-Interaction Network for Remote Sensing Object Detection
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 6000505
DO  - 10.1109/LGRS.2022.3230973
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148294779&doi=10.1109%2fLGRS.2022.3230973&partnerID=40&md5=b6a72fc7b05250d1f56656b2071c7d63
AB  - Remote sensing (RS) object detectors based on convolutional neural networks (CNNs) are hard to model global context dependencies. Transformer-based detectors can overcome this problem via global pairwise interactions, but more comprehensive information interactions are not systemically investigated to boost the detection performance. In view of this issue, we propose a transformer-guided multi-interaction network (TransMIN), which uses ResNet50-feature pyramid network (FPN) as the backbone for remote sensing object detection (RSOD). Specifically, we implement local-global feature interactions (LGFIs) by combining convolution and transformer in the residual blocks of ResNet50 to learn complementary features. We implement cross-view feature interactions (CVFIs) via transformers in the pyramid layers of FPN to capture the correlation between reference features (spatial edge priors and channel statistics) and pyramid features. This enhances edge information and suppresses background interference. In the detection head, we adopt a task-interactive sample assigner (TISA) by considering the interactions of classification and localization losses to obtain high-quality predictions. Experiments on two benchmark datasets demonstrate the superior detection performance of TransMIN over state-of-the-art methods.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Xu2023TransMIN
ER  -

TY  - JOUR
AU  - Fu, T.
AU  - Yu, Q.
AU  - Lao, H.
AU  - Liu, P.
AU  - Wan, S.
TI  - Traffic Safety Oriented Multi-Intersection Flow Prediction Based on Transformer and CNN
PY  - 2023
T2  - Security and Communication Networks
VL  - 2023
C7  - 1363639
DO  - 10.1155/2023/1363639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149132243&doi=10.1155%2f2023%2f1363639&partnerID=40&md5=9215d17672f2e322a645dab076b88d48
AB  - Intelligent traffic signal control is one of the important means to ensure traffic safety. Effective signal control can make traffic flow fast and smooth, which first needs current and future traffic information. As the control of one intersection may affect adjacent intersections, this paper proposes to predict future traffic flow with consideration of multi-intersections. It can dynamically improve traffic conditions and reduce traffic congestion. Based on various nonlinear spatial relationships at correlated multi-intersections and the potential time-dependent relationship in traffic volume, a traffic flow prediction method named CNNformer which combines transformer with CNN, is proposed. The convolution neural network (CNN) and transformer are used to extract the spatial and temporal features of correlated multiple intersections. The learnable time code is embedded into transformer’s location code, and the location information and time information are injected into the model to help it learn the time characteristics of traffic volume. This study also considers the impact of cyclical traffic flow pattern and proposes CNNformer+. In the method, all of the data from the previous time window, as well as the data from the prior week and month, are correspondingly entered into the network. Finally, the output is generated through average pooling, realizing the learning of cyclical traffic flow characteristics. In the experiment, CNNformer+ and the state-of-the-art traffic flow prediction methods are compared using simulated data. The results show that the proposed model outperforms the existing models in prediction accuracy and efficiency. Copyright © 2023 Tingting Fu et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Fu2023Traffic
ER  -

TY  - JOUR
AU  - Xiao, F.
AU  - Guan, J.
AU  - Zhu, Q.
AU  - Wang, W.
TI  - Graph Attention for Automated Audio Captioning
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 413
EP  - 417
DO  - 10.1109/LSP.2023.3266114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153355423&doi=10.1109%2fLSP.2023.3266114&partnerID=40&md5=6772ad202534cc8bf6c158117c41d6f7
AB  - State-of-the-art audio captioning methods typically use the encoder-decoder structure with pretrained audio neural networks (PANNs) as encoders for feature extraction. However, the convolution operation used in PANNs is limited in capturing the long-time dependencies within an audio signal, thereby leading to potential performance degradation in audio captioning. This letter presents a novel method using graph attention (GraphAC) for encoder-decoder based audio captioning. In the encoder, a graph attention module is introduced after the PANNs to learn contextual association (i.e. the dependency among the audio features over different time frames) through an adjacency graph, and a top-k mask is used to mitigate the interference from noisy nodes. The learnt contextual association leads to a more effective feature representation with feature node aggregation. As a result, the decoder can predict important semantic information about the acoustic scene and events based on the contextual associations learned from the audio signal. Experimental results show that GraphAC outperforms the state-of-the-art methods with PANNs as the encoders, thanks to the incorporation of the graph attention module into the encoder for capturing the long-time dependencies within the audio signal. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Xiao2023Graph
ER  -

TY  - JOUR
AU  - Mehmood, F.
AU  - Chen, E.
AU  - Abbas, T.
AU  - Akbar, M.A.
AU  - Khan, A.A.
TI  - Automatically human action recognition (HAR) with view variation from skeleton means of adaptive transformer network
PY  - 2023
T2  - Soft Computing
DO  - 10.1007/s00500-023-08008-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153031631&doi=10.1007%2fs00500-023-08008-z&partnerID=40&md5=24cbfb856f25f7ec8fc1f440e258232e
AB  - Human action recognition using skeletons has become increasingly appealing to a growing number of researchers in recent years. It is particularly challenging to recognize actions when they are captured from different angles because there are so many variations in their representations. This paper proposes an automatic strategy for determining virtual observation viewpoints that are based on learning and data driven to solve the problem of view variation throughout an act. Our VA-CNN and VA-RNN networks, which use convolutional and recurrent neural networks with long short-term memory, offer an alternative to the conventional method of reorienting skeletons according to a human-defined earlier benchmark. Using the unique view adaption module, each network first identifies the best observation perspectives and then transforms the skeletons for end-to-end detection with the main classification network based on those viewpoints. The suggested view adaptive models can provide significantly more consistent virtual viewpoints using the skeletons of different perspectives. By removing views, the models allow networks to learn action-specific properties more efficiently. Furthermore, we developed a two-stream scheme (referred to as VA-fusion) that integrates the performance of two networks to obtain an improved prediction. Random rotation of skeletal sequences is used to avoid overfitting during training and improve the reliability of view adaption models. An extensive experiment demonstrates that our proposed view adaptive networks outperform existing solutions on five challenging benchmarks. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Mehmood2023Automatically
ER  -

TY  - JOUR
AU  - Zhao, W.
AU  - Wang, Z.
AU  - Xu, L.
TI  - Mandarin Text-to-Speech Front-End With Lightweight Distilled Convolution Network
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 249
EP  - 253
DO  - 10.1109/LSP.2023.3256319
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151482463&doi=10.1109%2fLSP.2023.3256319&partnerID=40&md5=8dcb4cf68ea0e044019b46724bcfebc0
AB  - Mandarin text-to-speech (TTS) systems heavily depend on front-end processing, such as grapheme-to-phoneme conversion and prosodic boundary prediction, to produce expressive, human-like speech. Utilizing a pre-trained language model, such as the bidirectional encoder representations from Transformers (BERT), could significantly improve the TTS front-end's performance. However, the original BERT is too big for edge TTS applications with tight limits on memory costs and inference latency. Although a distilled BERT can alleviate this problem, a considerable efficiency barrier may still exist due to the self-attention module's quadratic complexity and the feed-forward module's enormous computation. To this end, we propose a lightweight distilled convolution network as an alternative to the distilled BERT. Unlike previous knowledge distillation methods, which commonly used the same self-attention network for the teacher and student models, we transfer knowledge from the self-attention network to a convolution network. Experiments on two major Mandarin TTS front-end tasks have shown that our distilled convolution model can achieve comparable results to various distilled BERT variants while drastically reducing the model size and inference latency.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Zhao2023Mandarin
ER  -

TY  - JOUR
AU  - Dai, K.
AU  - Ma, C.
AU  - Wang, Z.
AU  - Long, Y.
AU  - Li, X.
AU  - Feng, S.
AU  - Ye, Y.
TI  - Exploiting Spatial-Temporal Dynamics for Satellite Image Sequence Prediction
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 1001105
DO  - 10.1109/LGRS.2023.3261317
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151545054&doi=10.1109%2fLGRS.2023.3261317&partnerID=40&md5=0e55c3c6827155b1046e60fb971842e1
AB  - Satellite image sequence prediction is a challenging and significant task. The existing deep learning methods for the task make predictions mainly based on low-level pixelwise features, which fail to model the sophisticated spatial-temporal features of satellite image sequences and deliver unsatisfactory performance. In this letter, we present a hierarchical spatial-temporal network (HSTnet) for satellite image sequence prediction. With a carefully designed hierarchical feature extraction mechanism, HSTnet can learn effective spatial-temporal features from both pixel level and patch level. In addition, to better capture patch-level spatial-temporal dynamics, a dual-branch Transformer is proposed to model patch-level spatial and temporal features, respectively. Comprehensive experiments on the Fengyun-4A (FY-4A) satellite dataset demonstrate the superiority and effectiveness of our proposed method HSTnet over state-of-the-art approaches.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Dai2023Exploiting
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Tu, Y.
AU  - Liu, X.
AU  - Tan, H.
AU  - Liu, H.
TI  - Deep Ordinal Regression Framework for No-Reference Image Quality Assessment
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 428
EP  - 432
DO  - 10.1109/LSP.2023.3265569
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153799497&doi=10.1109%2fLSP.2023.3265569&partnerID=40&md5=1b86ceee1d8f813b5311005f0824732d
AB  - Due to the rapid development of deep learning techniques, no-reference image quality assessment (NR-IQA) has achieved significant improvement. NR-IQA aims to predict a real-valued variable for image quality, using the image in question as the sole input. Existing deep learning-based NR-IQA models are formulated as a regression problem and trained by minimising the mean squared error. The error measurement does not consider the relative ordering between different ratings on the quality scale, which consequently affects the efficacy of the model. To account for this problem, we reformulate NR-IQA learning as an ordinal regression problem and propose a simple yet effective framework using deep convolutional neural networks (DCNN) and Transformers. NR-IQA learning is achieved by a deep ordinal loss and using a soft ordinal inference to transform the predicted probabilities to a continuous variable for image quality. Experimental results demonstrate the superiority of our proposed NR-IQA model based on deep ordinal regression. In addition, this framework can be easily extended with various DCNN architectures to build advanced IQA models. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Wang2023Deep
ER  -

TY  - JOUR
AU  - Lee, D.
AU  - Choi, J.-W.
TI  - DeFT-AN: Dense Frequency-Time Attentive Network for Multichannel Speech Enhancement
PY  - 2023
T2  - IEEE Signal Processing Letters
VL  - 30
SP  - 155
EP  - 159
DO  - 10.1109/LSP.2023.3244428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149384907&doi=10.1109%2fLSP.2023.3244428&partnerID=40&md5=0582372ed62ba7cfcbaa5c3426b11dc2
AB  - In this study, we propose a dense frequency-time attentive network (DeFT-AN) for multichannel speech enhancement. DeFT-AN is a mask estimation network that predicts a complex spectral masking pattern for suppressing the noise and reverberation embedded in the short-time Fourier transform (STFT) of an input signal. The proposed mask estimation network incorporates three different types of blocks for aggregating information in the spatial, spectral, and temporal dimensions. It utilizes a spectral transformer with a modified feed-forward network and a temporal conformer with sequential dilated convolutions. The use of dense blocks and transformers dedicated to the three different characteristics of audio signals enables more comprehensive enhancement in noisy and reverberant environments. The remarkable performance of DeFT-AN over state-of-the-art multichannel models is demonstrated based on two popular noisy and reverberant datasets in terms of various metrics for speech quality and intelligibility.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Lee2023DeFT-AN
ER  -

TY  - JOUR
AU  - Shang, J.
AU  - Wei, P.
AU  - Li, H.
AU  - Zheng, N.
TI  - Multi-scale interaction transformer for temporal action proposal generation
PY  - 2023
T2  - Image and Vision Computing
VL  - 129
C7  - 104589
DO  - 10.1016/j.imavis.2022.104589
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144468875&doi=10.1016%2fj.imavis.2022.104589&partnerID=40&md5=39cbb53c87d95a3d78cfc87d2e092153
AB  - Temporal action proposal generation is to localize the time intervals with actions in untrimmed videos. Action instances in untrimmed videos have dramatically varied temporal scales which brings about great challenges for temporal action proposal generation. While temporal action proposal generation has achieved tremendous progress over the past years, multi-scale issue in action proposal generation is still an open problem. In this paper, we propose a Multi-scale Interaction Transformer (MSIT) architecture, which adopts a directly set prediction method to work out the temporal action proposal generation task. MSIT constructs multi-scale feature pyramids and incorporates a novel multi-scale mechanism into Transformer framework. A customized top-down interaction structure is designed to perform self-scale attention and cross-scale attention at different levels of the feature pyramids. Through the top-down interaction, the semantic and location information in each feature level is strengthened and therefore the proposal generation performance can be improved. Furthermore, to model the accurate action locations for each frame, we incorporate an actionness prediction structure to constrain the features output from the encoder. The proposed method was tested on two challenging datasets: THUMOS14 and ActivityNet-1.3. Experiments show that our method achieves comparable performance with state-of-the-art methods. Extensive studies and visualizations also demonstrate the strength of our method. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Shang2023Multi-scale
ER  -

TY  - JOUR
AU  - Nie, H.
AU  - Fu, Z.
AU  - Tang, B.-H.
AU  - Li, Z.
AU  - Chen, S.
TI  - A Multiscale Unsupervised Orientation Estimation Method With Transformers for Remote Sensing Image Matching
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 6000905
DO  - 10.1109/LGRS.2023.3234531
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147294821&doi=10.1109%2fLGRS.2023.3234531&partnerID=40&md5=b62024eed91ada4c1186a84c05ba7a9d
AB  - Estimating the orientations of remote sensing images is a very important step in remote sensing image matching and is now gradually receiving widespread attention. However, due to the inability to explicitly define the standard orientations of feature points, the current methods still produce feature point orientation estimation errors, resulting in reduced matching accuracy. In this letter, we propose a multiscale unsupervised orientation estimation method with transformers, in which we use a multiscale feature extraction module to aggregate rich semantic features and a transformer-based attention mechanism module to address robust feature extraction in weakly textured regions while predicting the orientations of feature points through a carefully designed loss function. We set up image matching experiments on remote sensing images in different scenes for comparison purposes, and the experimental results show that our proposed method achieves substantially improved orientation estimation accuracy and improved image matching performance.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Nie2023Multiscale
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Chen, Y.
AU  - Wen, K.
AU  - Wei, C.
AU  - Dong, B.
AU  - Zheng, Q.
AU  - Qin, Y.
TI  - Cue prompt adapting model for relation extraction
PY  - 2023
T2  - Connection Science
VL  - 35
IS  - 1
C7  - 2161478
DO  - 10.1080/09540091.2022.2161478
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145442640&doi=10.1080%2f09540091.2022.2161478&partnerID=40&md5=1cc836a426d43d162e656c3451c63547
AB  - Prompt-tuning models output relation types as verbalised-type tokens instead of predicting the confidence scores for each relation type. However, existing prompt-tuning models cannot perceive named entities of a relation instance because they are normally implemented on raw input that is too weak to encode the contextual features and semantic dependencies of a relation instance. This study proposes a cue prompt adapting (CPA) model for relation extraction (RE) that encodes contextual features and semantic dependencies by implanting task-relevant cues in a sentence. Additionally, a new transformer architecture is proposed to adapt pre-trained language models (PLMs) to perceive named entities in a relation instance. Finally, in the decoding process, a goal-oriented prompt template is designed to take advantage of the potential semantic features of a PLM. The proposed model is evaluated using three public corpora: ACE, ReTACRED, and Semeval. The performance achieves an impressive improvement, outperforming existing state-of-the-art models. Experiments indicate that the proposed model is effective for learning task-specific contextual features and semantic dependencies in a relation instance. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Wang2023Cue
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Wei, J.
AU  - Huang, F.
AU  - Ma, H.
TI  - Modeling graph-structured contexts for image captioning
PY  - 2023
T2  - Image and Vision Computing
VL  - 129
C7  - 104591
DO  - 10.1016/j.imavis.2022.104591
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143296220&doi=10.1016%2fj.imavis.2022.104591&partnerID=40&md5=951bdd181e001b55930e0d3aeb4658ab
AB  - The performance of image captioning has been significantly improved recently through deep neural network architectures combining with attention mechanisms and reinforcement learning optimization. Exploring visual relationships and interactions between different objects appearing in the image, however, is far from being investigated. In this paper, we present a novel approach that combines scene graphs with Transformer, which we call SGT, to explicitly encode available visual relationships between detected objects. Specifically, we pretrain an scene graph generation model to predict graph representations for images. After that, for each graph node, a Graph Convolutional Network (GCN) is employed to acquire relationship knowledge by aggregating the information of its local neighbors. As we train the captioning model, we feed the potential relation-aware information into the Transformer to generate descriptive sentence. Experiments on the MSCOCO dataset and the Flickr30k dataset validate the superiority of our SGT model, which can realize state-of-the-art results in terms of all the standard evaluation metrics. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Li2023Modeling
ER  -

TY  - JOUR
AU  - Zhang, B.
AU  - Zhang, Y.
AU  - Li, Y.
AU  - Wan, Y.
AU  - Yao, Y.
TI  - CloudViT: A Lightweight Vision Transformer Network for Remote Sensing Cloud Detection
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 5000405
DO  - 10.1109/LGRS.2022.3233122
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147228873&doi=10.1109%2fLGRS.2022.3233122&partnerID=40&md5=c3522a176f96e56409ccfef6a7c51a0a
AB  - Clouds inevitably exist in satellite images, which limit the processing and application of satellite images to a certain extent. Therefore, cloud detection is a preprocessing task in satellite image extraction and analysis processing. However, the existing methods are difficult to mine robust features, and the number of parameters and computation are large, which is not conducive to the deployment of the model. In this letter, cloud vision transformer (CloudViT), a lightweight vision transformer network for cloud detection from satellite imagery, is proposed. In detail, to utilize dark channel priors in multispectral imagery to guide the network to learn features, a multiscale dark channel extractor is used to first predict dark channels, and then, the dark channel features and image features are input to the attention mechanism-based dark channel-guided context aggregation module to enhance image features, which in turn makes cloud detection results more accurate. At the same time, to enhance the transfer ability of the network between different satellite sensors, a plug-and-play channel adaptive module is proposed to deal with the inconsistency of the number of different satellite sensor bands. The experimental results on the Landsat7 dataset show that our network CloudViT outperforms the state-of-the-art methods while keeping the number of parameters and computation small. At the same time, the experimental results on transfer to three other datasets show that using the channel adaptation module can greatly improve the transfer ability of the model.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Zhang2023CloudViT
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Cao, C.
AU  - Feng, Z.
AU  - Xu, X.
AU  - Wu, Z.
AU  - Ye, S.
AU  - Yong, J.
TI  - Remote Sensing Object Detection Based on Strong Feature Extraction and Prescreening Network
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 8000505
DO  - 10.1109/LGRS.2023.3236777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147316419&doi=10.1109%2fLGRS.2023.3236777&partnerID=40&md5=6989ab3964cb083fc57659aa3eef9fa1
AB  - Remote sensing object detection has been an important and challenging research hot spot in computer vision that is widely used in military and civilian fields. Recently, the combined detection model of convolutional neural network (CNN) and transformer has achieved good results, but the problem of poor detection performance of small objects still needs to be solved urgently. This letter proposes a deformable end-to-end object detection with transformers (DETR)-based framework for object detection in remote sensing images. First, multiscale split attention (MSSA) is designed to extract more detailed feature information by grouping. Next, we propose multiscale deformable prescreening attention (MSDPA) mechanism in decoding layer, which achieves the purpose of prescreening, so that the encoder-decoder structure can obtain attention map more efficiently. Finally, the A-D loss function is applied to the prediction layer, increasing the attention of small objects and optimizing the intersection over union (IOU) function. We conduct extensive experiments on the DOTA v1.5 dataset and the HRRSD dataset, which show that the reconstructed detection model is more suitable for remote sensing objects, especially for small objects. The average detection accuracy in DOTA dataset has improved by 4.4% (up to 75.6%), especially the accuracy of small objects has raised by 5%. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Li2023Remote
ER  -

TY  - JOUR
AU  - Wu, H.
AU  - He, Z.
AU  - Gao, M.
TI  - GCEVT: Learning Global Context Embedding for Vehicle Tracking in Unmanned Aerial Vehicle Videos
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 6000705
DO  - 10.1109/LGRS.2022.3228527
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144810488&doi=10.1109%2fLGRS.2022.3228527&partnerID=40&md5=d9316b76cbce45590b9f2dd3d533b092
AB  - Vehicle tracking in the unmanned aerial vehicle (UAV) videos is a fundamental but vital computer vision task. It mainly consists of two key components, that is, detection and reidentification (ReID). Recently, one-shot trackers, which integrate detection and ReID in a unified network, have received significant attention for their fast-tracking speed. However, existing one-shot trackers typically utilize local information to distinguish the detected targets. Due to the lack of global relations, which are key cues for tracking, these methods struggle to identify targets in UAV videos accurately. To alleviate the above issue, we deliberately design an ReID head that combines nonlocal blocks and the transformer layer to capture the global semantic relation in this letter. First, we propose a novel pyramid fusion network (PFN) to obtain the pixel-wise relations of features at multiple levels and aggregate them into features with richer semantic information. Then, we present a channel-wise transformer enhancer (CTE) to model the dependencies among the channels of the feature map and predict fine-grained identity embeddings. Extensive experiments on VisDrone2021 and UAVDT benchmarks demonstrate that our tracker, namely global context embedding for vehicle tracking (GCEVT), achieves state-of-the-art tracking performance.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Wu2023GCEVT
ER  -

TY  - JOUR
AU  - Wang, P.
AU  - Zhang, Y.
AU  - Hu, T.
AU  - Zhang, T.
TI  - Urban traffic flow prediction: a dynamic temporal graph network considering missing values
PY  - 2023
T2  - International Journal of Geographical Information Science
VL  - 37
IS  - 4
SP  - 885
EP  - 912
DO  - 10.1080/13658816.2022.2146120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142205640&doi=10.1080%2f13658816.2022.2146120&partnerID=40&md5=b482617c05c4866a08d641c5ec3ac8d4
AB  - Accurate traffic flow prediction on the urban road network is an indispensable function of Intelligent Transportation Systems (ITS), which is of great significance for urban traffic planning. However, the current traffic flow prediction methods still face many challenges, such as missing values and dynamic spatial relationships in traffic flow. In this study, a dynamic temporal graph neural network considering missing values (D-TGNM) is proposed for traffic flow prediction. First, inspired by the Bidirectional Encoder Representations from Transformers (BERT), we extend the classic BERT model, called Traffic BERT, to learn the dynamic spatial associations on the road structure. Second, we propose a temporal graph neural network considering missing values (TGNM) to mine traffic flow patterns in missing data scenarios for traffic flow prediction. Finally, the proposed D-TGNM model can be obtained by integrating the dynamic spatial associations learned by Traffic BERT into the TGNM model. To train the D-TGNM model, we design a novel loss function, which considers the missing values problem and prediction problem in traffic flow, to optimize the proposed model. The proposed model was validated on an actual traffic dataset collected in Wuhan, China. Experimental results showed that D-TGNM achieved good prediction results under four missing data scenarios (15% random missing, 15% block missing, 30% random missing, and 30% block missing), and outperformed ten existing state-of-the-art baselines. © 2022 Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Wang2023Urban
ER  -

TY  - JOUR
AU  - Klemen, M.
AU  - Krsnik, L.
AU  - Robnik-Šikonja, M.
TI  - Enhancing deep neural networks with morphological information
PY  - 2023
T2  - Natural Language Engineering
VL  - 29
IS  - 2
SP  - 360
EP  - 385
DO  - 10.1017/S1351324922000080
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125658123&doi=10.1017%2fS1351324922000080&partnerID=40&md5=75618ed03193dbd1cbae6c9d5a06655a
AB  - Deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. The two most successful neural architectures are LSTM and transformers, used in large pretrained language models such as BERT. While cross-lingual approaches are on the rise, most current natural language processing techniques are designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, information is conveyed through morphology, for example, through affixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyse the effect of adding morphological features to LSTM and BERT models. As a testbed, we use three tasks available in many less-resourced languages: named entity recognition (NER), dependency parsing (DP) and comment filtering (CF). We construct baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech (POS) tags and universal features. We compare the models across several languages from different language families. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM-based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT-based models, the added morphological features only improve the performance on DP when they are of high quality (i.e., manually checked) while not showing any practical improvement when they are predicted. Even for high-quality features, the improvements are less pronounced in language-specific BERT variants compared to massively multilingual BERT models. As in NER and CF datasets manually checked features are not available, we only experiment with predicted features and find that they do not cause any practical improvement in performance. © The Author(s), 2022. Published by Cambridge University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Klemen2023Enhancing
ER  -

TY  - JOUR
AU  - Pardo-Sixtos, L.F.
AU  - López-Monroy, A.P.
AU  - Shafaei, M.
AU  - Solorio, T.
TI  - Hierarchical attention and transformers for automatic movie rating
PY  - 2022
T2  - Expert Systems with Applications
VL  - 209
C7  - 118164
DO  - 10.1016/j.eswa.2022.118164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135295642&doi=10.1016%2fj.eswa.2022.118164&partnerID=40&md5=f508114da097e7c543a52826f0722be8
AB  - The MPAA rating provides a guide for parents to decide if a movie is suitable for their children, and determines who is allowed into movie screenings. If the assigned rating does not match with that intended by the movie makers, the movie has to go through extra changes. Predicting this rating from the movie scripts would allow for the changes to be done even before the shooting starts, when they are the cheapest. Furthermore, automatizing this reviewing process would allow for cheaper large scale classification of videos from other sources, such as social media and streaming platforms. In this paper we propose RNN and Transformer based hierarchical architecture well suited to analyze movie scripts as large text sequences. The proposed RNN architecture outperforms the State-of-the-art (SOTA) by around 3 points in the F1 score, while our Hierarchical Transformer outperformed the SOTA in around 5 points. Furthermore, we devise a visualization strategy to address the problem of interpretability of transformers, which is particularly hard for large sequences. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Pardo-Sixtos2022Hierarchical
ER  -

TY  - JOUR
AU  - Zheng, Q.
AU  - Yu, T.
AU  - Wang, F.
TI  - Self-supervised monocular depth estimation based on combining convolution and multilayer perceptron
PY  - 2023
T2  - Engineering Applications of Artificial Intelligence
VL  - 117
C7  - 105587
DO  - 10.1016/j.engappai.2022.105587
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141513344&doi=10.1016%2fj.engappai.2022.105587&partnerID=40&md5=9d5fea102af39acfbab5875bfb4deab2
AB  - There are two mainstream approaches currently used for self-supervised monocular depth estimation. One option is to utilize a complete convolution method to construct the encoder and decoder; however, the local linear operation and the pooling method result in the loss of pixel information in each layer of the feature map, limiting the performance. Another way is to use the transformer and other methods for feature extraction on the encoder side, which are processed at a constant resolution at each stage and have a global receptive field. Therefore, more subtle depth features can be captured, and higher accuracy can be obtained. Unfortunately, the computational cost of self-attention is too large, which increases the memory overhead. With the comprehensive analysis of the advantages and disadvantages of the above two methods, this paper employs a combination of decomposed large kernel convolution and a multilayer perceptron (MLP) to design a new framework — CSMHNet (a hybrid of a Convolution, self-attention, and an MLP network). It cannot only compensate for the disadvantages of convolution static weights and locality but also significantly reduce the memory overhead compared to the transformer architecture while obtaining a more accurate and consistent depth. Experiments on the KITTI dataset demonstrate the effectiveness of our method, which significantly improves the depth prediction accuracy compared with other self-supervised methods. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Zheng2023Self-supervised
ER  -

TY  - JOUR
AU  - Ko, D.-K.
AU  - Lee, K.-W.
AU  - Lee, D.H.
AU  - Lim, S.-C.
TI  - Vision-based interaction force estimation for robot grip motion without tactile/force sensor
PY  - 2023
T2  - Expert Systems with Applications
VL  - 211
C7  - 118441
DO  - 10.1016/j.eswa.2022.118441
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136465340&doi=10.1016%2fj.eswa.2022.118441&partnerID=40&md5=ad6196621b11be72af23e7d079b4ad64
AB  - Humans perceive an interaction force through the kinesthetic sense or tactile sense. When viewing the image, they estimate the interaction force on the basis of pseudo-haptics. The interaction force of a robot is traditionally measured using a contact-type tactile sensor or a force/torque (F/T) sensor. In this work, we propose a method for estimating the interaction force between a robot and objects during grasping and picking. The method is based on images, without involving an F/T sensor or a tactile sensor. For undeformable objects, more precise force estimation was achieved by simultaneously using RGB and depth images, the robot position, and electrical current. We propose a deep neural network structure that combines DenseNet and a Transformer encoder/decoder for predicting the interaction force. We verified proposed network with generated DB which has recorded the interaction with 41 objects. Additionally, we compared the results with changing the inputs of the network. Our model could estimate the interaction force from various input modalities for both known objects and unseen objects during its training. The results clearly indicate that the proposed method produces the best results compared with other models, with less than 3% error in estimating the interaction force. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ko2023Vision-based
ER  -

TY  - JOUR
AU  - Wang, Q.
AU  - Wen, Z.
AU  - Ding, K.
AU  - Zhao, Q.
AU  - Yang, M.
AU  - Yu, X.
AU  - Xu, R.
TI  - Improving sequence labeling with labeled clue sentences
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 257
C7  - 109828
DO  - 10.1016/j.knosys.2022.109828
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139077145&doi=10.1016%2fj.knosys.2022.109828&partnerID=40&md5=02dcf52b46b5e7aa2ba68c47c2dc9180
AB  - Pre-trained language models (PLMs) have achieved noticeable success on a variety of natural language processing tasks, such as sequence labeling. In particular, the existing sequence labeling methods fine-tune PLMs on large-scale labeled data, which can avoid training the sequence labeling models from scratch. The fine-tuning process still requires large amounts of labeled training data so as to be effective. However, obtaining rich annotated data for sequence labeling is a time-consuming and expensive process, creating a substantial barrier for directly applying the PLMs trained on general-purpose large-scale text data to sequence labeling. In this paper, we investigate sequence labeling tasks from a novel perspective and propose a general framework that uses labeled clue sentences to mitigate the problem of insufficient annotation data for sequence labeling. Specifically, we first retrieve the labeled clue sentences for each original sentence in the training set based on the semantic (or syntactic) relevance. Here, the number of annotated clue sentences determines the expansion degree of the training set. Then, we modify the transformer's self-attention mechanism to not only exploit the contextual information of the original sentence but also leverage the contextual and label information of the labeled clue sentences. In addition, we devise a mask label strategy to further avoid over-fitting by randomly masking out the labels of certain tokens in the clue sentence and then predicting these mask labels based on the context of the tokens corresponding to the mask labels. We verify the effectiveness and generalizability of the proposed framework on three sequence labeling tasks, including Chinese Named Entity Recognition, English Named Entity Recognition, and Aspect Term Extraction. Extensive experimental results show that our method can yield state-of-the-art or competitive results on the three tasks. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Wang2022Improving
ER  -

TY  - JOUR
AU  - Tong, T.
AU  - Li, D.
AU  - Gu, J.
AU  - Chen, G.
AU  - Bai, G.
AU  - Yang, X.
AU  - Wang, K.
AU  - Jiang, T.
AU  - Tian, J.
TI  - Dual-Input Transformer: An End-to-End Model for Preoperative Assessment of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast Cancer Ultrasonography
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 1
SP  - 251
EP  - 262
DO  - 10.1109/JBHI.2022.3216031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140733128&doi=10.1109%2fJBHI.2022.3216031&partnerID=40&md5=ea89ca6ec6069df67cb43ec3431d7e87
AB  - Neoadjuvant chemotherapy (NAC) is the primary method to reduce the burden of tumor and metastasis; in the treatment of breast cancer, it may provide additional opportunities for breast-conserving surgery. Preoperative assessment of pathological complete response (PCR) to NAC is important for developing individualized treatment approaches and predicting patient prognosis. Compared to magnetic resonance imaging (MRI) and mammography, ultrasonography (US) has the advantages of simplicity, flexibility, and real-time imaging. Moreover, it does not require radiation and can provide multi-time acquisition of the tumor during NAC treatment. Recently, deep learning radiomics models based on multi-time-point US images for the prediction of NAC effectiveness have been proposed. To further improve the prediction performance, we carefully designed four supporting modules for our proposed dual-input transformer (DiT): isolated tokens-to-token patch embedding module, shared position embedding, time embedding, and weighted average pooling feature representation modules. The design of each module considers the characteristics of the US images at multiple time points. We validated our model on our retrospective US dataset composed of 484 cases from two centers whose consistency is not sufficiently high. Patients were allocated to training (n = 297), validation (n = 99), and external test (n = 88) sets. The results show that our model can achieve better performance than the Siamese CNN and the standard tokens-to-token vision transformer without using multi-time-point images. The ablation study also proved the effectiveness of each module designed for DiT.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Tong2023Dual-Input
ER  -

TY  - JOUR
AU  - Wang, S.
AU  - Wang, H.
AU  - She, S.
AU  - Zhang, Y.
AU  - Qiu, Q.
AU  - Xiao, Z.
TI  - Swin-T-NFC CRFs: An encoder–decoder neural model for high-precision UAV positioning via point cloud super resolution and image semantic segmentation
PY  - 2023
T2  - Computer Communications
VL  - 197
SP  - 52
EP  - 60
DO  - 10.1016/j.comcom.2022.10.011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141319485&doi=10.1016%2fj.comcom.2022.10.011&partnerID=40&md5=99aa2405c75c8060acc54e23f19f3772
AB  - 3D point cloud and remote sensing images have been the primary data types for the development of high-precision positioning systems. Equipped with a LiDAR and a camera, an Unmanned Aerial Vehicle (UAV) can explore an uncharted territory and gather both 3D scans and aerial images in real time to dynamically inspect the surroundings. However, the high cost of a high-resolution LiDAR hinders the development of the perception module of an UAV. Also, it is essential to adopt accurate image semantic segmentation (SemSeg) algorithms to better understand the sensing environment. As hardware advancement is ongoing, support from the software side is crucial. A promising strategy for cost control in building a LiDAR-based positioning system is through point cloud super-resolution (SupRes), a technique that improves the point cloud resolution via algorithms. This study investigates a deep learning-based framework that adopts a classic encoder–decoder structure for both point cloud SupRes and image SemSeg. Unlike prior studies that mainly use convolutional neural networks (CNNs) for feature extraction, our model, named Swin-T-NFC CRFs, consists of a Vision Transformer (ViT)-based encoder and a fully connected conditional random fields (FC-CRFs)-based decoder, connected via a pyramid pooling module and multiple skip connections. Moreover, both encoder and decoder are coupled with a shifted window strategy that allows cross-window connection. As such, patches from different windows of the feature map can participate in self-attention computation, leading to more powerful modeling ability. Experimental results demonstrate that our method can effectively boost the prediction accuracy, reduce the error, and consistently outperform the state-of-the-art methods on simulated/real-world point cloud datasets and the urban drone dataset version 6. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Wang2023Swin-T-NFC
ER  -

TY  - JOUR
AU  - Wu, X.
AU  - Li, P.
AU  - Zhao, M.
AU  - Liu, Y.
AU  - Crespo, R.G.
AU  - Herrera-Viedma, E.
TI  - Customer churn prediction for web browsers
PY  - 2022
T2  - Expert Systems with Applications
VL  - 209
C7  - 118177
DO  - 10.1016/j.eswa.2022.118177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135331729&doi=10.1016%2fj.eswa.2022.118177&partnerID=40&md5=3ce96f199a6e9d97763f9f4fa2628ffe
AB  - In the competitive web browser market, identifying potential churners is critical to decreasing the loss of existing customers. Churn prediction based on customer behaviors plays a vital role in customer retention strategies. However, traditional churn prediction algorithms such as Tree-based models cannot exploit the temporal characteristics of browser customers behaviors, while sequence models cannot explicitly extract the information between multiple behaviors. To meet this challenge, we propose a novel model named Multivariate Behavior Sequence Transformer (MBST) with two complementary attention mechanisms to explore the temporal and behavioral information separately. Furthermore, a Tree-based classifier is attached for churn prediction instead of using the multilayer perceptron. Extensive experiments on a real-world Tencent QQ browser dataset with over 600,000 samples demonstrate that the proposed MBST achieves the F-score of 82.72% and the Area Under Curve (AUC) of 93.75%, which significantly outperforms state-of-the-art methods in terms of churn prediction. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wu2022Customer
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Wang, X.
AU  - Hou, Y.
AU  - Li, G.
AU  - Wang, H.
AU  - Xu, H.
AU  - Xiang, Y.
AU  - Tang, B.
TI  - Multimodal Data Matters: Language Model Pre-Training Over Structured and Unstructured Electronic Health Records
PY  - 2023
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 27
IS  - 1
SP  - 504
EP  - 514
DO  - 10.1109/JBHI.2022.3217810
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141530394&doi=10.1109%2fJBHI.2022.3217810&partnerID=40&md5=60e7f2381570563dad035a8fceedab5b
AB  - As two important textual modalities in electronic health records (EHR), both structured data (clinical codes) and unstructured data (clinical narratives) have recently been increasingly applied to the healthcare domain. Most existing EHR-oriented studies, however, either focus on a particular modality or integrate data from different modalities in a straightforward manner, which usually treats structured and unstructured data as two independent sources of information about patient admission and ignore the intrinsic interactions between them. In fact, the two modalities are documented during the same encounter where structured data inform the documentation of unstructured data and vice versa. In this paper, we proposed a Medical Multimodal Pre-trained Language Model, named MedM-PLM, to learn enhanced EHR representations over structured and unstructured data and explore the interaction of two modalities. In MedM-PLM, two Transformer-based neural network components are firstly adopted to learn representative characteristics from each modality. A cross-modal module is then introduced to model their interactions. We pre-trained MedM-PLM on the MIMIC-III dataset and verified the effectiveness of the model on three downstream clinical tasks, i.e., medication recommendation, 30-day readmission prediction and ICD coding. Extensive experiments demonstrate the power of MedM-PLM compared with state-of-the-art methods. Further analyses and visualizations show the robustness of our model, which could potentially provide more comprehensive interpretations for clinical decision-making.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Liu2023Multimodal
ER  -

TY  - JOUR
AU  - Üzen, H.
AU  - Türkoğlu, M.
AU  - Yanikoglu, B.
AU  - Hanbay, D.
TI  - Swin-MFINet: Swin transformer based multi-feature integration network for detection of pixel-level surface defects
PY  - 2022
T2  - Expert Systems with Applications
VL  - 209
C7  - 118269
DO  - 10.1016/j.eswa.2022.118269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135376977&doi=10.1016%2fj.eswa.2022.118269&partnerID=40&md5=f7563b3741d91ba77e21f6ae8220bb15
AB  - Automatic surface defect detection is critical for manufacturing industries, such as steel, fabric, and marble industries. This study proposes a Swin transformer-based model called Multi-Feature Integration Network (Swin-MFINet) for pixel-level surface defect detection. The proposed model consists of an encoder, a Swin transformer-based decoder, and Multi-Feature Integration (MFI) modules. In the encoder module of the proposed model, a pre-trained Inception network is used to extract key features from small-size datasets. In the decoder section, global semantic features are obtained from the initial features by using the Swin-transformer block, which is the newest transformer technology of today. In addition, the convolution layer is used in the last step of the decoder, since transformers are limited in acquiring small spatial details such as edges, colors, and textures, which are important in detecting some small defects. In the last module called MFI, feature maps from different decoder stages are combined, and the channel squeeze-spatial excitation block is applied to reveal important features. Finally, a prediction map is obtained by applying a convolution layer and sigmoid activation function to the MFI module output, respectively. The performance of proposed model is analyzed over MT and MVTec datasets containing surface defect images. The proposed model obtained mIoU scores of 81.37%, and 77.07% respectively, for these two datasets These results outperform the state-of-the-art for the surface defect detection problem. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Üzen2022Swin-MFINet
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Xu, J.
AU  - Chen, W.
AU  - Zhao, L.
TI  - When Research Topic Trend Prediction Meets Fact-Based Annotations
PY  - 2022
T2  - Data Science and Engineering
VL  - 7
IS  - 4
SP  - 316
EP  - 327
DO  - 10.1007/s41019-022-00197-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139642378&doi=10.1007%2fs41019-022-00197-1&partnerID=40&md5=f9d6276c21920b354ad7a7bf583cef3a
AB  - The unprecedented growth of publications in many research domains brings the great convenience for tracing and analyzing the evolution and development of research topics. Despite the significant contributions made by existing studies, they usually extract topics from the titles of papers, instead of obtaining topics from the authoritative sessions provided by venues (e.g., AAAI, NeurIPS, and SIGMOD). To make up for the shortcoming of existing work, we develop a novel framework namely RTTP(Research Topic Trend Prediction). Specifically, the framework contains the following two components: (1) a topic alignment strategy called TAS is designed to obtain the detailed contents of research topics in each year, (2) an enhanced prediction network called EPN is designed to capture the research trend of known years for prediction. In addition, we construct two real-world datasets of specific research domains in computer science, i.e., database and data mining, computer architecture and parallel programming. The experimental results demonstrate that the problem is well solved and our solution outperforms the state-of-the-art methods. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Wang2022When
ER  -

TY  - JOUR
AU  - Aldahdooh, J.
AU  - Vähä-Koskela, M.
AU  - Tang, J.
AU  - Tanoli, Z.
TI  - Using BERT to identify drug-target interactions from whole PubMed
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 245
DO  - 10.1186/s12859-022-04768-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132303874&doi=10.1186%2fs12859-022-04768-x&partnerID=40&md5=ff690fbee985d16b8fba3e1967bf5d10
AB  - Background: Drug-target interactions (DTIs) are critical for drug repurposing and elucidation of drug mechanisms, and are manually curated by large databases, such as ChEMBL, BindingDB, DrugBank and DrugTargetCommons. However, the number of curated articles likely constitutes only a fraction of all the articles that contain experimentally determined DTIs. Finding such articles and extracting the experimental information is a challenging task, and there is a pressing need for systematic approaches to assist the curation of DTIs. To this end, we applied Bidirectional Encoder Representations from Transformers (BERT) to identify such articles. Because DTI data intimately depends on the type of assays used to generate it, we also aimed to incorporate functions to predict the assay format. Results: Our novel method identified 0.6 million articles (along with drug and protein information) which are not previously included in public DTI databases. Using 10-fold cross-validation, we obtained ~ 99% accuracy for identifying articles containing quantitative drug-target profiles. The F1 micro for the prediction of assay format is 88%, which leaves room for improvement in future studies. Conclusion: The BERT model in this study is robust and the proposed pipeline can be used to identify previously overlooked articles containing quantitative DTIs. Overall, our method provides a significant advancement in machine-assisted DTI extraction and curation. We expect it to be a useful addition to drug mechanism discovery and repurposing. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Aldahdooh2022Using
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Guo, F.
AU  - Du, M.
AU  - Wang, G.
AU  - Cao, C.
TI  - A novel method for drug-target interaction prediction based on graph transformers model
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 459
DO  - 10.1186/s12859-022-04812-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141159323&doi=10.1186%2fs12859-022-04812-w&partnerID=40&md5=a8f56b63b74a764a09a39994f8b55af2
AB  - Background: Drug-target interactions (DTIs) prediction becomes more and more important for accelerating drug research and drug repositioning. Drug-target interaction network is a typical model for DTIs prediction. As many different types of relationships exist between drug and target, drug-target interaction network can be used for modeling drug-target interaction relationship. Recent works on drug-target interaction network are mostly concentrate on drug node or target node and neglecting the relationships between drug-target. Results: We propose a novel prediction method for modeling the relationship between drug and target independently. Firstly, we use different level relationships of drugs and targets to construct feature of drug-target interaction. Then, we use line graph to model drug-target interaction. After that, we introduce graph transformer network to predict drug-target interaction. Conclusions: This method introduces a line graph to model the relationship between drug and target. After transforming drug-target interactions from links to nodes, a graph transformer network is used to accomplish the task of predicting drug-target interactions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Wang2022novel
ER  -

TY  - JOUR
AU  - Zhou, C.
AU  - Che, C.
AU  - Zhang, X.S.
AU  - Zhang, Q.
AU  - Zhou, D.
TI  - Harmonized system code prediction of import and export commodities based on Hybrid Convolutional Neural Network with Auxiliary Network
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 256
C7  - 109836
DO  - 10.1016/j.knosys.2022.109836
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138075031&doi=10.1016%2fj.knosys.2022.109836&partnerID=40&md5=a5dcb7a35c304a28c589625c8087b8f3
AB  - China Customs mainly uses manual inspections on the tax rates of import and export commodities, which can only cover a small part of the mass of commodities. Therefore, we investigate the natural language processing technology to determine the tax rate automatically by commodities classification. However, the unique challenge is that the structured commodity text is ambiguous, and has no continuous context and semantics, leading to difficulties for classification. In light of this challenge, we draw on the idea of the deep pyramid convolutional model and propose a Shallow Structured Convolutional Neural Network (SSCNN) with an Auxiliary Network to reduce the semantic fusion in commodity classification. When extracting shallow features, our model uses a structural token to fill in the feature boundary of structured text to prevent the feature fusion problem of adjacent features brought by the convolution operation. Auxiliary Network learns the distinguishing features of each commodity category and integrates the customs-specific knowledge to improve the classification performance of similar goods. In the empirical study on a real-world customs dataset, our model outperforms the mainstream deep learning methods including Transformer, BERT, BART and RoBERTa, which verifies the effectiveness of this method on classifying import and export commodities. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; FMS:C; 
LB  - Zhou2022Harmonized
ER  -

TY  - JOUR
AU  - Duan, B.
AU  - Peng, J.
AU  - Zhang, Y.
TI  - IMSE: interaction information attention and molecular structure based drug drug interaction extraction
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
C7  - 338
DO  - 10.1186/s12859-022-04876-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135952210&doi=10.1186%2fs12859-022-04876-8&partnerID=40&md5=2fbdb145e909c8e899e8c5c7c9530036
AB  - Background: Extraction of drug drug interactions from biomedical literature and other textual data is an important component to monitor drug-safety and this has attracted attention of many researchers in healthcare. Existing works are more pivoted around relation extraction using bidirectional long short-term memory networks (BiLSTM) and BERT model which does not attain the best feature representations. Results: Our proposed DDI (drug drug interaction) prediction model provides multiple advantages: (1) The newly proposed attention vector is added to better deal with the problem of overlapping relations, (2) The molecular structure information of drugs is integrated into the model to better express the functional group structure of drugs, (3) We also added text features that combined the T-distribution and chi-square distribution to make the model more focused on drug entities and (4) it achieves similar or better prediction performance (F-scores up to 85.16%) compared to state-of-the-art DDI models when tested on benchmark datasets. Conclusions: Our model that leverages state of the art transformer architecture in conjunction with multiple features can bolster the performances of drug drug interation tasks in the biomedical domain. In particular, we believe our research would be helpful in identification of potential adverse drug reactions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Duan2022IMSE
ER  -

TY  - JOUR
AU  - Salem, M.
AU  - Keshavarzi Arshadi, A.
AU  - Yuan, J.S.
TI  - AMPDeep: hemolytic activity prediction of antimicrobial peptides using transfer learning
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 389
DO  - 10.1186/s12859-022-04952-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138602005&doi=10.1186%2fs12859-022-04952-z&partnerID=40&md5=2125c41f02770a53515428c6040c8433
AB  - Background: Deep learning’s automatic feature extraction has proven to give superior performance in many sequence classification tasks. However, deep learning models generally require a massive amount of data to train, which in the case of Hemolytic Activity Prediction of Antimicrobial Peptides creates a challenge due to the small amount of available data. Results: Three different datasets for hemolysis activity prediction of therapeutic and antimicrobial peptides are gathered and the AMPDeep pipeline is implemented for each. The result demonstrate that AMPDeep outperforms the previous works on all three datasets, including works that use physicochemical features to represent the peptides or those who solely rely on the sequence and use deep learning to learn representation for the peptides. Moreover, a combined dataset is introduced for hemolytic activity prediction to address the problem of sequence similarity in this domain. AMPDeep fine-tunes a large transformer based model on a small amount of peptides and successfully leverages the patterns learned from other protein and peptide databases to assist hemolysis activity prediction modeling. Conclusions: In this work transfer learning is leveraged to overcome the challenge of small data and a deep learning based model is successfully adopted for hemolysis activity classification of antimicrobial peptides. This model is first initialized as a protein language model which is pre-trained on masked amino acid prediction on many unlabeled protein sequences in a self-supervised manner. Having done so, the model is fine-tuned on an aggregated dataset of labeled peptides in a supervised manner to predict secretion. Through transfer learning, hyper-parameter optimization and selective fine-tuning, AMPDeep is able to achieve state-of-the-art performance on three hemolysis datasets using only the sequence of the peptides. This work assists the adoption of large sequence-based models for peptide classification and modeling tasks in a practical manner. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Salem2022AMPDeep
ER  -

TY  - JOUR
AU  - Zhao, F.
AU  - Li, X.
AU  - Gao, Y.
AU  - Li, Y.
AU  - Feng, Z.
AU  - Zhang, C.
TI  - Multi-layer features ablation of BERT model and its application in stock trend prediction
PY  - 2022
T2  - Expert Systems with Applications
VL  - 207
C7  - 117958
DO  - 10.1016/j.eswa.2022.117958
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134334383&doi=10.1016%2fj.eswa.2022.117958&partnerID=40&md5=4e4223980d58b489bd0549a70e38f2ff
AB  - Stock comments published by experts are important references for accurate stock trends prediction. How to comprehensively and accurately capture the topic of expert stock comments is an important issue which belongs to text classification. The Bidirectional Encoder Representations from Transformers (BERT) pretrained language model is widely used for text classification, due to its high identification accuracy. However, BERT has some limitations. First, it only utilizes fixed length text, leading to suboptimal performance in long text information exploration. Second, it only relies on the features extracted from the last layer, resulting in incomprehensive classification features. To tackle these issues, we propose a multi-layer features ablation study of BERT model for accurate identification of stock comments’ themes. Specifically, we firstly divide the original text to meet the length requirement of the BERT model based on sliding window technology. In this way, we can enlarge the sample size which is beneficial for reducing the over-fitting problem. At the same time, by dividing the long text into multiple short texts, all the information of the long text can be comprehensively captured through the synthesis of the subject information of multiple short texts. In addition, we extract the output features of each layer in the BERT model and apply the ablation strategy to extract more effective information in these features. Experimental results demonstrate that compared with non-intercepted comments, the topic recognition accuracy is improved by intercepting stock comments based on sliding window technology. It proves that intercepting text can improve the performance of text classification. Compared with the BERT, the multi-layer features ablation study we present in the paper further improves the performance in the topic recognition of stock comments, and can provide reference for the majority of investors. Our study has better performance and practicability on stock trend prediction by stock comments topic recognition. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhao2022Multi-layer
ER  -

TY  - JOUR
AU  - Wang, C.
AU  - Chen, Y.
AU  - Zhang, S.
AU  - Zhang, Q.
TI  - Stock market index prediction using deep Transformer model
PY  - 2022
T2  - Expert Systems with Applications
VL  - 208
C7  - 118128
DO  - 10.1016/j.eswa.2022.118128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134615245&doi=10.1016%2fj.eswa.2022.118128&partnerID=40&md5=beb895ae3c5d414574d24334900a78e2
AB  - Applications of deep learning in financial market prediction have attracted widespread attention from investors and scholars. From convolutional neural networks to recurrent neural networks, deep learning methods exhibit superior ability to capture the non-linear characteristics of stock markets and, accordingly, achieve a high performance on stock market index prediction. In this paper, we utilize the latest deep learning framework, Transformer, to predict the stock market index. Transformer was initially developed for the natural language processing problem, and has recently been applied to time series forecasting. Through the encoder–decoder architecture and the multi-head attention mechanism, Transformer can better characterize the underlying rules of stock market dynamics. We implement several back-testing experiments on the main stock market indices worldwide, including CSI 300, S&P 500, Hang Seng Index, and Nikkei 225. All the experiments demonstrate that Transformer outperforms other classic methods significantly and can gain excess earnings for investors. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 112
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Wang2022Stock
ER  -

TY  - JOUR
AU  - Wu, R.
AU  - Wen, X.
AU  - Yuan, L.
AU  - Xu, H.
TI  - DASFTOT: Dual attention spatiotemporal fused transformer for object tracking
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 256
C7  - 109897
DO  - 10.1016/j.knosys.2022.109897
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138996181&doi=10.1016%2fj.knosys.2022.109897&partnerID=40&md5=033db5e0086bd63efb52c25c133e5fcd
AB  - The Siamese network method is widely applied in the field of object tracking. The transformer-based tracker achieves state-of-the-art tracking results. However, these methods cannot effectively fuse local and global features of video images and cannot pay more attention to tracking objects spatiotemporally. In this paper, we proposed a new object tracking method (DASFTOT), which includes a backbone network, transformer mechanism and bounding prediction box. First, we use a 3D CNN to extract motion information. Second, we superimpose important temporal and spatial information through a dual attention spatiotemporal fused transformer (DASFT) to fuse local and global spatiotemporal features and calculate the correlation between templates and search regions. Third, to improve the robustness of tracking, we dynamically update part of the template frame. Finally, we position the tracking object through a bounding prediction box. To verify the effectiveness of the proposed tracker (DASFTOT), experiments on the GOT-10K, LaSOT, TrackingNet, VOT2020 and OTB100 benchmark datasets demonstrated that the proposed tracker was highly comparable to other state-of-the-art methods. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; 
LB  - Wu2022DASFTOT
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Guo, B.
AU  - Shen, Y.
AU  - Zhou, R.
AU  - Lu, W.
AU  - Wang, W.
AU  - Wen, X.
AU  - Suo, X.
TI  - Video summarization with u-shaped transformer
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 15
SP  - 17864
EP  - 17880
DO  - 10.1007/s10489-022-03451-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127618148&doi=10.1007%2fs10489-022-03451-1&partnerID=40&md5=17200ecf4f66de5a378fb7b80264ebd5
AB  - In recent years, supervised video summarization has made tremendous progress with treating it as a sequence-to-sequence learning task. However, traditional recurrent neural networks (RNNs) have limitations in sequence modeling of long sequences, and the use of a transformer for sequence modeling requires a large number of parameters. We propose an efficient U-shaped transformer for video summarization tasks in this paper to address this issue, which we call “Uformer”. Precisely, Uformer consists of three key components: embedding, Uformer block, and prediction head. First of all, the image features sequence is represented by the pre-trained deep convolutional network, then represented by a liner embedding. The image feature sequence differences are also represented by another liner embedding and concatenate together to form a two-stream embedding feature in the embedding component. Secondly, we stack multiple transformer layers into a U-shaped block to integrate the representations learned from the previous layers. Multi-scale Uformer can not only learn longer sequence information but also reduce the number of parameters and calculations. Finally, prediction head regression the localization of the keyframes and learning the corresponding classification scores. Uformer combine with non-maximum suppression (NMS) for post-processing to get the final video summarization. We improved the F-score from 50.2% to 53.9% by 3.7% on the SumMe dataset and improved F-score from 62.1% to 63.0% by 0.9% on the TVSum dataset. Our proposed model with 0.85M parameters which are only 32.32% of DR-DSN’s parameters. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Chen2022Video
ER  -

TY  - JOUR
AU  - Hameed, A.
AU  - Violos, J.
AU  - Leivadeas, A.
AU  - Santi, N.
AU  - Grunblatt, R.
AU  - Mitton, N.
TI  - Toward QoS Prediction Based on Temporal Transformers for IoT Applications
PY  - 2022
T2  - IEEE Transactions on Network and Service Management
VL  - 19
IS  - 4
SP  - 4010
EP  - 4027
DO  - 10.1109/TNSM.2022.3217170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141501602&doi=10.1109%2fTNSM.2022.3217170&partnerID=40&md5=bca36e6630a6dbadee5417e2c5de36f6
AB  - Internet of Things (IoT) devices generate a tremendous amount of time series data that is extremely dynamic, heterogeneous and time dependent. Such types of data introduce significant challenges for the real-time prediction of QoS metrics of IoT applications with different traffic characteristics. To this end, in this paper, we propose a temporal transformer model and a unified system to predict several QoS metrics of heterogeneous IoT applications when they communicate with the Edge of the network. The transformer model also leverages an attention module to provide a solution for both short-term and long-term sequence prediction of QoS metrics that allows to better extract any time dependencies. In particular, in our framework, we firstly generate a set of datasets containing real-time traffic information of five different IoT applications such as Heating, Ventilation, and Air Conditioning (HVAC), lighting, Voice over Internet Protocol (VoIP), surveillance and emergency response using the 802.15.4 access technology and the RPL routing protocol. Following, we perform the data cleaning, downsampling and pre-processing of the datasets and we construct the QoS datasets, which include four QoS metrics, namely throughput, packet delivery ratio, packet loss ratio and latency. Finally, we evaluate the transformer model through extensive experimentation using both short-term and long-term dependencies and we show that our model can guarantee a robust performance and accurate QoS prediction.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Hameed2022Toward
ER  -

TY  - JOUR
AU  - Hong, Y.
AU  - Lee, J.
AU  - Ko, J.
TI  - A-Prot: protein structure modeling using MSA transformer
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 93
DO  - 10.1186/s12859-022-04628-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126333729&doi=10.1186%2fs12859-022-04628-8&partnerID=40&md5=cd2fbb48c4c6729caf6a447776b6c958
AB  - Background: The accuracy of protein 3D structure prediction has been dramatically improved with the help of advances in deep learning. In the recent CASP14, Deepmind demonstrated that their new version of AlphaFold (AF) produces highly accurate 3D models almost close to experimental structures. The success of AF shows that the multiple sequence alignment of a sequence contains rich evolutionary information, leading to accurate 3D models. Despite the success of AF, only the prediction code is open, and training a similar model requires a vast amount of computational resources. Thus, developing a lighter prediction model is still necessary. Results: In this study, we propose a new protein 3D structure modeling method, A-Prot, using MSA Transformer, one of the state-of-the-art protein language models. An MSA feature tensor and row attention maps are extracted and converted into 2D residue-residue distance and dihedral angle predictions for a given MSA. We demonstrated that A-Prot predicts long-range contacts better than the existing methods. Additionally, we modeled the 3D structures of the free modeling and hard template-based modeling targets of CASP14. The assessment shows that the A-Prot models are more accurate than most top server groups of CASP14. Conclusion: These results imply that A-Prot accurately captures the evolutionary and structural information of proteins with relatively low computational cost. Thus, A-Prot can provide a clue for the development of other protein property prediction methods. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Hong2022A-Prot
ER  -

TY  - JOUR
AU  - Zhong, W.
AU  - He, C.
AU  - Xiao, C.
AU  - Liu, Y.
AU  - Qin, X.
AU  - Yu, Z.
TI  - Long-distance dependency combined multi-hop graph neural networks for protein–protein interactions prediction
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 521
DO  - 10.1186/s12859-022-05062-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143320524&doi=10.1186%2fs12859-022-05062-6&partnerID=40&md5=59ed7fe6d2ab8f8a2e8e1316acfb2476
AB  - Background: Protein–protein interactions are widespread in biological systems and play an important role in cell biology. Since traditional laboratory-based methods have some drawbacks, such as time-consuming, money-consuming, etc., a large number of methods based on deep learning have emerged. However, these methods do not take into account the long-distance dependency information between each two amino acids in sequence. In addition, most existing models based on graph neural networks only aggregate the first-order neighbors in protein–protein interaction (PPI) network. Although multi-order neighbor information can be aggregated by increasing the number of layers of neural network, it is easy to cause over-fitting. So, it is necessary to design a network that can capture long distance dependency information between amino acids in the sequence and can directly capture multi-order neighbor information in protein–protein interaction network. Results: In this study, we propose a multi-hop neural network (LDMGNN) model combining long distance dependency information to predict the multi-label protein–protein interactions. In the LDMGNN model, we design the protein amino acid sequence encoding (PAASE) module with the multi-head self-attention Transformer block to extract the features of amino acid sequences by calculating the interdependence between every two amino acids. And expand the receptive field in space by constructing a two-hop protein–protein interaction (THPPI) network. We combine PPI network and THPPI network with amino acid sequence features respectively, then input them into two identical GIN blocks at the same time to obtain two embeddings. Next, the two embeddings are fused and input to the classifier for predict multi-label protein–protein interactions. Compared with other state-of-the-art methods, LDMGNN shows the best performance on both the SHS27K and SHS148k datasets. Ablation experiments show that the PAASE module and the construction of THPPI network are feasible and effective. Conclusions: In general terms, our proposed LDMGNN model has achieved satisfactory results in the prediction of multi-label protein–protein interactions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zhong2022Long-distance
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Xuan, J.
AU  - Yao, C.
AU  - Gao, Q.
AU  - Wang, L.
AU  - Jin, X.
AU  - Li, S.
TI  - A deep learning approach for orphan gene identification in moso bamboo (Phyllostachys edulis) based on the CNN + Transformer model
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 162
DO  - 10.1186/s12859-022-04702-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129379844&doi=10.1186%2fs12859-022-04702-1&partnerID=40&md5=a09179f8bd09c98807e730ce292cb54e
AB  - Background: Orphan gene play an important role in the environmental stresses of many species and their identification is a critical step to understand biological functions. Moso bamboo has high ecological, economic and cultural value. Studies have shown that the growth of moso bamboo is influenced by various stresses. Several traditional methods are time-consuming and inefficient. Hence, the development of efficient and high-accuracy computational methods for predicting orphan genes is of great significance. Results: In this paper, we propose a novel deep learning model (CNN + Transformer) for identifying orphan genes in moso bamboo. It uses a convolutional neural network in combination with a transformer neural network to capture k-mer amino acids and features between k-mer amino acids in protein sequences. The experimental results show that the average balance accuracy value of CNN + Transformer on moso bamboo dataset can reach 0.875, and the average Matthews Correlation Coefficient (MCC) value can reach 0.471. For the same testing set, the Balance Accuracy (BA), Geometric Mean (GM), Bookmaker Informedness (BM), and MCC values of the recurrent neural network, long short-term memory, gated recurrent unit, and transformer models are all lower than those of CNN + Transformer, which indicated that the model has the extensive ability for OG identification in moso bamboo. Conclusions: CNN + Transformer model is feasible and obtains the credible predictive results. It may also provide valuable references for other related research. As our knowledge, this is the first model to adopt the deep learning techniques for identifying orphan genes in plants. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zhang2022deep
ER  -

TY  - JOUR
AU  - Song, L.
AU  - Liu, G.
AU  - Ma, M.
TI  - TD-Net:unsupervised medical image registration network based on Transformer and CNN
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 15
SP  - 18201
EP  - 18209
DO  - 10.1007/s10489-022-03472-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127979598&doi=10.1007%2fs10489-022-03472-w&partnerID=40&md5=f08a34cc6dda8e802105ec7fd8260ac0
AB  - Medical image registration is a fundamental task in computer-aided medical diagnosis. Recently, researchers have begun to use deep learning methods based on convolutional neural networks (CNN) for registration, and have made remarkable achievements in medical image registration. Although CNN based methods can provide rich local information on registration, their global modeling ability is weak to carry out the long distance information interaction and restrict the registration performance. The Transformer is originally used for sequence-to-sequence prediction. Now it also achieves great results in various visual tasks, due to its strong global modeling capability. Compared with CNN, Transformer can provide rich global information, in contrast, Transformer lacks of local information. To address Transformer lacks local information, we propose a hybrid network which is similar to U-Net to combine Transformer and CNN, to extract global and local information (at each level). Specifically, CNN is first used to obtain the feature maps of the image, and the Transformer is used as encoder to extract global information. Then the results obtained by Transformer encoding are connected to the upsampling process. The upsampling uses CNN to integrate local information and global information. Finally, the resolution is restored to the input image, and obtain the displacement field after several convolution layers. We evaluate our method on brain MRI scans. Experimental results demonstrate that our method improves the accuracy by 1% compared with the state-of-the-art approaches. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Song2022TD-Net:unsupervised
ER  -

TY  - JOUR
AU  - Tiwari, D.A.
TI  - RMCL: A deep learning based recursive malicious context learner in social networks
PY  - 2022
T2  - Computational Intelligence
VL  - 38
IS  - 6
SP  - 1956
EP  - 1989
DO  - 10.1111/coin.12552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142394010&doi=10.1111%2fcoin.12552&partnerID=40&md5=f2c604ff7af0d675bf4697b9ab694717
AB  - Propagation of malicious content and its promotion is a recurrent problem prominent in social networks. Detection and interactive labeling of malicious context promotion on-the-fly is a very challenging and difficult task due to the lack of complete knowledge about the underlying context. Modern research in this field use neural networks and text encoders to analyze the information dynamically which is inefficient, in terms of time-space consumed in the overall process. This article proposes an online active learning system to label the data streams on-the-fly by sampling them in the form of tweet-retweet-follow (trf) sequences in social networks. A heuristically pretrained recursive malicious context learner is fixed for knowledge acquisition, data accommodation and pseudonymization in the form of a transformer in the tree structured recursive neural network. The data stream is trained using recursive bidirectional training to capture long-term dependencies. The COVID-19 data streams are selectively sampled on-the-fly using psycho linguistic words in the proposed experiment and are labeled deceptive/nondeceptive based on knowledge learned during pretraining. The proposed recursive malicious context learner successfully resolves the problem of on-the-fly-interactive labeling of a dynamically changing data stream. © 2022 Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Tiwari2022RMCL
ER  -

TY  - JOUR
AU  - Helaly, M.A.
AU  - Rady, S.
AU  - Aref, M.M.
TI  - BERT contextual embeddings for taxonomic classification of bacterial DNA sequences
PY  - 2022
T2  - Expert Systems with Applications
VL  - 208
C7  - 117972
DO  - 10.1016/j.eswa.2022.117972
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134592839&doi=10.1016%2fj.eswa.2022.117972&partnerID=40&md5=56c8953d2289ef4e0bde52ca5a7e0134
AB  - Biological taxonomic classification is an important task needed for the identification and discovery of organisms, as well as the inference of their evolutionary relationships. The order and structure of biological sequence components has an essential and primary role in what the sequence's identity and function is. In order to be able to efficiently differentiate between different bacterial categories, interactions and positions of the biological components in sequences must be known — which is an essential challenge in biological sequence classification. In this light, a considerable amount of recent research has been made to explore efficient representations of biological sequences such as spectral k-mer representation, one-hot encoding, Hilbert space curves and classical word embeddings such as Word2Vec. This paper identifies the taxonomic classification of bacterial 16S rRNA genes at five resolutions mapping hierarchical taxonomic ranks. A Bidirectional Encoder Representations from Transformers (BERT) model is pretrained using biological sequences, which to the best of our knowledge is the first time BERT has been trained with such sequences. A complete prediction model is then proposed – BioSeqBERT-CNN – that initially extracts contextual embeddings representations of DNA sequences using the pretrained BERT model. Extracted representations are further used for taxonomic classification through a Convolutional Neural Network (CNN). For boosting the deep learning classification performance, a data augmentation step is applied. Classification with the original dataset on the most fine-grained rank produced an accuracy of 93.5%, which surpasses that of recent works by 1.5–24.3%. Using data augmentation, an accuracy of 99.9% is achieved, which exceeds values of recent works by a minimum and maximum of 7.9% and 30.7%, respectively on the most fine-grained taxonomic rank. This exhibits promising performance promoting the study of using contextual embeddings to represent biological sequences, with Deep Learning networks. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Helaly2022BERT
ER  -

TY  - JOUR
AU  - Colla, D.
AU  - Delsanto, M.
AU  - Agosto, M.
AU  - Vitiello, B.
AU  - Radicioni, D.P.
TI  - Semantic coherence markers: The contribution of perplexity metrics
PY  - 2022
T2  - Artificial Intelligence in Medicine
VL  - 134
C7  - 102393
DO  - 10.1016/j.artmed.2022.102393
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140886295&doi=10.1016%2fj.artmed.2022.102393&partnerID=40&md5=0f86307e9cf0c348cf9630b4d9fa3449
AB  - Devising automatic tools to assist specialists in the early detection of mental disturbances and psychotic disorders is to date a challenging scientific problem and a practically relevant activity. In this work we explore how language models (that are probability distributions over text sequences) can be employed to analyze language and discriminate between mentally impaired and healthy subjects. We have preliminarily explored whether perplexity can be considered a reliable metrics to characterize an individual's language. Perplexity was originally conceived as an information-theoretic measure to assess how much a given language model is suited to predict a text sequence or, equivalently, how much a word sequence fits into a specific language model. We carried out an extensive experimentation with healthy subjects, and employed language models as diverse as N-grams – from 2-grams to 5-grams – and GPT-2, a transformer-based language model. Our experiments show that irrespective of the complexity of the employed language model, perplexity scores are stable and sufficiently consistent for analyzing the language of individual subjects, and at the same time sensitive enough to capture differences due to linguistic registers adopted by the same speaker, e.g., in interviews and political rallies. A second array of experiments was designed to investigate whether perplexity scores may be used to discriminate between the transcripts of healthy subjects and subjects suffering from Alzheimer Disease (AD). Our best performing models achieved full accuracy and F-score (1.00 in both precision/specificity and recall/sensitivity) in categorizing subjects from both the AD class, and control subjects. These results suggest that perplexity can be a valuable analytical metrics with potential application to supporting early diagnosis of symptoms of mental disorders. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:C期刊; 
LB  - Colla2022Semantic
ER  -

TY  - JOUR
AU  - Fei, Y.
AU  - Zhang, H.
AU  - Wang, Y.
AU  - Liu, Z.
AU  - Liu, Y.
TI  - LTPConstraint: a transfer learning based end-to-end method for RNA secondary structure prediction
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 354
DO  - 10.1186/s12859-022-04847-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136369520&doi=10.1186%2fs12859-022-04847-z&partnerID=40&md5=db480c132e6e1a3d3a5b1b29b7ebc66f
AB  - Background: RNA secondary structure is very important for deciphering cell’s activity and disease occurrence. The first method which was used by the academics to predict this structure is biological experiment, But this method is too expensive, causing the promotion to be affected. Then, computing methods emerged, which has good efficiency and low cost. However, the accuracy of computing methods are not satisfactory. Many machine learning methods have also been applied to this area, but the accuracy has not improved significantly. Deep learning has matured and achieves great success in many areas such as computer vision and natural language processing. It uses neural network which is a kind of structure that has good functionality and versatility, but its effect is highly correlated with the quantity and quality of the data. At present, there is no model with high accuracy, low data dependence and high convenience in predicting RNA secondary structure. Results: This paper designs a neural network called LTPConstraint to predict RNA secondary structure. The network is based on many network structure such as Bidirectional LSTM, Transformer and generator. It also uses transfer learning to train modelso that the data dependence can be reduced. Conclusions: LTPConstraint has achieved high accuracy in RNA secondary structure prediction. Compared with the previous methods, the accuracy improves obviously both in predicting the structure with pseudoknot and the structure without pseudoknot. At the same time, LTPConstraint is easy to operate and can achieve result very quickly. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Fei2022LTPConstraint
ER  -

TY  - JOUR
AU  - Pang, Y.
AU  - Shan, A.
AU  - Wang, Z.
AU  - Wang, M.
AU  - Li, J.
AU  - Zhang, J.
AU  - Huang, T.
AU  - Liu, C.
TI  - Sparse-Dyn: Sparse dynamic graph multirepresentation learning via event-based sparse temporal attention network
PY  - 2022
T2  - International Journal of Intelligent Systems
VL  - 37
IS  - 11
SP  - 8770
EP  - 8789
DO  - 10.1002/int.22967
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134705468&doi=10.1002%2fint.22967&partnerID=40&md5=725446ba80fde8055ac723509d4fdc55
AB  - Dynamic graph neural networks (DGNNs) have been widely used in modeling and representation learning of graph structure data. Current dynamic representation learning focuses on either discrete learning which results in temporal information loss, or continuous learning which involves heavy computation. In this study, we proposed a novel DGNN, sparse dynamic (Sparse-Dyn). It adaptively encodes temporal information into a sequence of patches with an equal amount of temporal-topological structure. Therefore, while avoiding using snapshots which cause information loss, it also achieves a finer time granularity, which is close to what continuous networks could provide. In addition, we also designed a lightweight module, Sparse Temporal Transformer, to compute node representations through structural neighborhoods and temporal dynamics. Since the fully connected attention conjunction is simplified, the computation cost is far lower than the current state-of-the-art. Link prediction experiments are conducted on both continuous and discrete graph data sets. By comparing several state-of-the-art graph embedding baselines, the experimental results demonstrate that Sparse-Dyn has a faster inference speed while having competitive performance. © 2022 Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Pang2022Sparse-Dyn
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Yang, Y.
AU  - Yue, S.
TI  - Air Quality Classification and Measurement Based on Double Output Vision Transformer
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 21
SP  - 20975
EP  - 20984
DO  - 10.1109/JIOT.2022.3176126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130505747&doi=10.1109%2fJIOT.2022.3176126&partnerID=40&md5=d8ad262491933e3bf780c58f19b61234
AB  - The atmospheric quality monitor is an essential component of atmospheric protection. However, using complicated large-scale chemical equipment required by traditional methods is difficult for ordinary people. We are committed to allowing ordinary people to obtain a local air quality index (AQI) and then participate in the air quality monitoring of the entire district quickly and easily. So, we propose a method improved from Transformer in this article. This method processes pictures taken by mobile devices and predicts a more accurate local AQI level. The proposed method performs better than traditional methods in frequency and flexibility. Tokens in the Double Output Vision Transformer (DOViT) proposed in this article will be processed with the multihead self-attention (MSA) mechanism of the model to automatically extract the features in pictures for achieving higher classification accuracy. The application of Transformer makes our model more concise and efficient than previous CNN-based methods.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Wang2022Air
ER  -

TY  - JOUR
AU  - Raza, S.M.
AU  - Jang, B.
AU  - Yang, H.
AU  - Kim, M.
AU  - Choo, H.
TI  - Improved GAN with fact forcing for mobility prediction
PY  - 2022
T2  - Journal of Network and Computer Applications
VL  - 207
C7  - 103488
DO  - 10.1016/j.jnca.2022.103488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136112266&doi=10.1016%2fj.jnca.2022.103488&partnerID=40&md5=ae99bd6f2659734a161a785cd3b848b1
AB  - Mobility prediction based on users movement history is a prerequisite for proactive mobility and several other management operations in wireless networks. Recent Deep Learning (DL) studies for mobility prediction have shown improved accuracies using variety of different models that have high complexity and massive training data requirements. These limitations restrict the viability of mobility prediction driven proactive management of wireless networks. This paper overcomes the mentioned limitations by proposing Improved Generative Adversarial Network with Fact Forcing (iGAN-FF) that enhances the existing improved GAN (iGAN). iGAN-FF architecture consists of generator and discriminator neural networks, where generator predicts mobility (next Point of Attachment (PoA)) and discriminator classifies between the predicted PoA and the ground truth in adversarial learning. The adversarial learning reduces the needed amount of training data and enables use of simplistic models, and novel compounded fact forcing and feature matching method achieves higher accuracy. Moreover, the effects of data representation on performance are evaluated by transforming the Campus Mobility Dataset (CMD) and Operator Mobility Dataset (OMD) to One-hot, Binary, and Embedded vectors representations. The results confirm the merits of iGAN-FF as it outperforms iGAN, GAN-FF, GAN, LSTM based Next PoA (LNP), and Transformer based Next PoA (TNP). In particular, the highest accuracies of 99.57% and 83.3% are achieved with CMD One-hot and OMD Embedded representations, respectively. Notably, iGAN-FF shows robustness under data scarcity and secures ∼98% accuracy with only 20% of CMD data. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Raza2022Improved
ER  -

TY  - JOUR
AU  - Sun, N.
AU  - Zhao, J.
AU  - Wang, G.
AU  - Liu, C.
AU  - Liu, P.
AU  - Tang, X.
AU  - Han, J.
TI  - Transformer-based moving target tracking method for Unmanned Aerial Vehicle
PY  - 2022
T2  - Engineering Applications of Artificial Intelligence
VL  - 116
C7  - 105483
DO  - 10.1016/j.engappai.2022.105483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139594823&doi=10.1016%2fj.engappai.2022.105483&partnerID=40&md5=d9051adca25946cc6e349e2c3dd64253
AB  - Unmanned Aerial Vehicle (UAV) moving target tracking is one of the fundamental implementations in remote sensing and has been widely applied in monitoring, search and rescue, pursuit-escapes, and other fields. Currently, most UAV tracking algorithms merely establish the local relationship between the template and search region without fully using the global context information, leading to problems such as target loss and misclassification, and imprecise bounding boxes. This paper innovatively proposes a UAV tracker, TransUAV, overcoming the above challenge by a feature correlation network based on the self-attention mechanism. The method efficiently combines global features between the search region and the template to reduce the influence of external interference, enhancing the precision and robustness of the tracking algorithm. Moreover, the global spatio-temporal features are acquired by learning query embedding and temporal update strategies to make predictions, enhancing the adaptability to rapid changes in the appearance of target object. There is no proposal or predetermined anchor in this method to satisfy the requirements of onboard operational speed, therefore, no post-processing procedure is required, and the entire approach is end-to-end. The superiority of the proposed TransUAV is verified by an exhaustive evaluation of six challenging target tracking video datasets benchmarks, and the accuracy and robustness of the proposed TransUAV are compared with state-of-the-art methods. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Sun2022Transformer-based
ER  -

TY  - JOUR
AU  - Deng, X.
AU  - Zhang, Y.
AU  - Qi, H.
TI  - Toward Smart Multizone HVAC Control by Combining Context-Aware System and Deep Reinforcement Learning
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 21
SP  - 21010
EP  - 21024
DO  - 10.1109/JIOT.2022.3175728
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130473289&doi=10.1109%2fJIOT.2022.3175728&partnerID=40&md5=57dc3f8e358a477db44bef54a52d667c
AB  - Building energy consumption accounts for a large figure of total energy consumption and keeps a rapid increase. Energy for heating, ventilation, and air conditioning (HVAC) is the main contribution. To save energy with maintaining comfort, control methods have been studied, including rule-based methods, model predictive control, and deep reinforcement learning (DRL). While their performance in real applications can be restricted by the highly nonstationary building environment caused by factors like weather conditions. Especially, for multizone HVAC control with multiple controllers, variation of the controller policy causes potential nonstationarity for each other. Current solutions to the nonstationarity based on model-based methods add complexity for building modeling and decrease the control efficiency. In addition, although massive data are available with the development of the Internet of Things (IoT) in smart buildings, high-level exploitation of data in the context-aware system is not yet explored to detect environment changes for smart building control. To this end, we propose a novel context-aware model-free DRL method called Trans-Context soft actor-critic (SAC) for multizone HVAC control, which combines a transformer-encoder-based context-aware system and the state-of-the-art DRL algorithm SAC. The context-aware system disentangles the nonstationarity by learning context data from IoT sensors. Besides, Trans-Context SAC is a model-free method without the need for building modeling. We evaluate Trans-Context SAC in a simulation-based case study on a multizone commercial building. Results demonstrate that Trans-Context SAC can achieve up to 15.9% of energy saving compared to other baselines with maintaining thermal comfort. Besides, Trans-Context SAC obtains the generalization for unseen environments.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Deng2022Toward
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Du, Y.
AU  - Li, X.
AU  - Chen, X.
AU  - Xie, C.
AU  - Li, H.
AU  - Li, X.
TI  - UD_BBC: Named entity recognition in social network combined BERT-BiLSTM-CRF with active learning
PY  - 2022
T2  - Engineering Applications of Artificial Intelligence
DO  - 10.1016/j.engappai.2022.105460
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139059830&doi=10.1016%2fj.engappai.2022.105460&partnerID=40&md5=46629ad340f5c53f4d5941c766f77f57
AB  - With the rapid growth of Internet penetration, more and more people choose the Internet to express their views on topics of interest. In recent years, named entity recognition (NER) is becoming a popular task for the public to obtain structured information from public opinion text. At present, NER models with good results, such as deep learning model, need a lot of labeled data for training. However, this will give rise to a problem: labeling a large amount of data requires a lot of human resources, which is thankless in some areas. Therefore, in this paper, we propose a NER model combining active learning and deep learning methods. Firstly, the active learning method can solve the above problem. The strategy combines uncertainty-based sampling and diversity-based sampling to estimate the information of data. We use highly informative data as the initial training dataset. Secondly, this paper uses a deep learning model combining bidirectional encoder representations from Transformers, bidirectional long–short-term memory and conditional random field (BERT-BiLSTM-CRF). BERT extracts the semantic features of data, and BiLSTM predicts the probability distribution of entity labels. We use the CRF for decoding the probability distribution into corresponding entity labels. Finally, we use the initial training dataset for training BERT-BiLSTM-CRF. This model predicts the entity labels of the unlabeled data. Then, we judge if the machine-labeled data is highly reliable and expand the highly reliable data to the initial training dataset. The updated dataset retrains the NER model, so that the trained model has higher precision than the previous model. The results show that our model performs well without a large number of labeled datasets. The model achieves a precision value of 70.31%, recall rate of 74.93% and F1 score of 72.55% in the named entity recognition task, which proves the effectiveness of our model. Besides, the F1 score of BERT-BiLSTM-CRF with uncertainty-based sampling and diversity-based sampling (UD_BBC) is higher than the BiLSTM-CRF based on maximum normalized log-probability (MNLP_BiLSTM-CRF) by 9.00%, when recognizing overall entity categories. It provides a solution to the problem of named entity recognition in educational public opinion. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:C期刊; 
LB  - Li2022UD_BBC
ER  -

TY  - JOUR
AU  - Yu, L.
AU  - Xu, X.
AU  - Trajcevski, G.
AU  - Zhou, F.
TI  - Transformer-enhanced Hawkes process with decoupling training for information cascade prediction
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 255
C7  - 109740
DO  - 10.1016/j.knosys.2022.109740
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137153182&doi=10.1016%2fj.knosys.2022.109740&partnerID=40&md5=7193a595c85dde902330f0038d821664
AB  - The ability to model the information diffusion process and predict its size is crucial to understanding information propagation mechanism and is useful for many applications such as popularity prediction and fake news detection. Recent research works have attempted to address the problem of information cascade prediction using two basic paradigms: (1) sequential methods, e.g., recurrent neural networks (RNNs), and (2) graph learning techniques to retain the topological information and enable consideration of structural relationships among diffusion participants. However, existing models consider the topological and temporal features separately, falling short of simulating their entanglement in the diffusion process. As a consequence, since the evolving directed acyclic graph (DAG) of information diffusion is intrinsically coupled with both topological and temporal dependencies, there is a loss of cross-domain information. In this paper, we propose a transformer enhanced Hawkes process (Hawkesformer), which links the hierarchical attention mechanism to Hawkes self-exciting point process for information cascade prediction. Specifically, we extend traditional Hawkes process with a topological horizon and efficiently acquire knowledge from continuous-time domain. A two-level attention architecture is used to parameterize the intensity function of Hawkesformer. At the first-level, we disentangle the primary and non-primary paths to simulate the coupled topological and temporal information for capturing the global dependencies between the nodes in a graph. At the second-level, a local pooling attentive module is proposed to embed the cascade evolution rate for modeling short-term outbreaks. Extensive experiments on two real-world datasets demonstrate the significant performance improvements of Hawkesformer over existing state-of-the-art models. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; FMS:C; 
LB  - Yu2022Transformer-enhanced
ER  -

TY  - JOUR
AU  - Playout, C.
AU  - Duval, R.
AU  - Boucher, M.C.
AU  - Cheriet, F.
TI  - Focused Attention in Transformers for interpretable classification of retinal images
PY  - 2022
T2  - Medical Image Analysis
VL  - 82
C7  - 102608
DO  - 10.1016/j.media.2022.102608
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138129225&doi=10.1016%2fj.media.2022.102608&partnerID=40&md5=7054bd34b22762ad9821957b09415adc
AB  - Vision Transformers have recently emerged as a competitive architecture in image classification. The tremendous popularity of this model and its variants comes from its high performance and its ability to produce interpretable predictions. However, both of these characteristics remain to be assessed in depth on retinal images. This study proposes a thorough performance evaluation of several Transformers compared to traditional Convolutional Neural Network (CNN) models for retinal disease classification. Special attention is given to multi-modality imaging (fundus and OCT) and generalization to external data. In addition, we propose a novel mechanism to generate interpretable predictions via attribution maps. Existing attribution methods from Transformer models have the disadvantage of producing low-resolution heatmaps. Our contribution, called Focused Attention, uses iterative conditional patch resampling to tackle this issue. By means of a survey involving four retinal specialists, we validated both the superior interpretability of Vision Transformers compared to the attribution maps produced from CNNs and the relevance of Focused Attention as a lesion detector. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:C期刊; 
LB  - Playout2022Focused
ER  -

TY  - JOUR
AU  - Xiao, S.
AU  - Wang, S.
AU  - Huang, Z.
AU  - Wang, Y.
AU  - Jiang, H.
TI  - Two-stream transformer network for sensor-based human activity recognition
PY  - 2022
T2  - Neurocomputing
VL  - 512
SP  - 253
EP  - 268
DO  - 10.1016/j.neucom.2022.09.099
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144392900&doi=10.1016%2fj.neucom.2022.09.099&partnerID=40&md5=9df955dc0f46b1d0f087e6c8f0527470
AB  - Human Activity Recognition (HAR) based on wearable devices has always been a hot topic in health applications, human-object interaction, and smart homes. Despite significant improvements achieved by convolutional neural networks, long short-term memory networks, transformer networks and various hybrid models, there are still two fundamental issues. First, the spatial–temporal dependencies of sensor signals are difficult to be effectively modeled. Second, in multimodal environments, sensors placed on various body positions contribute distinctly to the classification results. In this work, we propose a self-attention based Two-stream Transformer Network (TTN). In view of the former issue, we use two streams, named temporal stream and spatial stream, respectively, to extract the readings-over-time and time-over-readings features from sensor signals. These features extracted from two streams are complementary since the time-over-readings features are able to express additional information which cannot be captured from sensor signals directly. To deal with the latter issue, we assign attention weights to each sensor axis in the spatial channel based on their classification scores. It makes sense that different axis-readings with distinct recognition contributions caused by data heterogeneity be treated unequally. Extensive experiments on four available benchmark datasets (PAMAP2, Opportunity, USC–HAD, and Skoda) reveal that our proposed model is better suited for multimodal HAR than previous state-of-the-art methods. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; 
LB  - Xiao2022Two-stream
ER  -

TY  - JOUR
AU  - Xia, M.
AU  - Yang, H.
AU  - Qu, Y.
AU  - Guo, Y.
AU  - Zhou, G.
AU  - Zhang, F.
AU  - Wang, Y.
TI  - Multilevel structure-preserved GAN for domain adaptation in intravascular ultrasound analysis
PY  - 2022
T2  - Medical Image Analysis
VL  - 82
C7  - 102614
DO  - 10.1016/j.media.2022.102614
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138060949&doi=10.1016%2fj.media.2022.102614&partnerID=40&md5=e24c12a8b26715b010a0d4f93066a4e9
AB  - The poor generalizability of intravascular ultrasound (IVUS) analysis methods caused by the great diversity of IVUS datasets is hopefully addressed by the domain adaptation strategy. However, existing domain adaptation models underperform in intravascular structural preservation, because of the complex pathology and low contrast in IVUS images. Losing structural information during the domain adaptation would lead to inaccurate analyses of vascular states. In this paper, we propose a Multilevel Structure-Preserved Generative Adversarial Network (MSP-GAN) for transferring IVUS domains while maintaining intravascular structures. On the generator-discriminator baseline, the MSP-GAN integrates the transformer, contrastive restraint, and self-ensembling strategy, for effectively preserving structures in multi-levels, including global, local, and fine levels. For the global-level pathology maintenance, the generator explores long-range dependencies in IVUS images via an incorporated vision transformer. For the local-level anatomy consistency, a region-to-region correspondence is forced between the translated and source images via a superpixel-wise multiscale contrastive (SMC) constraint. For reducing distortions of fine-level structures, a self-ensembling mean teacher generates the pixel-wise pseudo-label and restricts the translated image via an uncertainty-aware teacher-student consistency (TSC) constraint. Experiments were conducted on 20 MHz and 40 MHz IVUS datasets from different medical centers. Ablation studies illustrate that each innovation contributes to intravascular structural preservation. Comparisons with representative domain adaptation models illustrate the superiority of the MSP-GAN in the structural preservation. Further comparisons with the state-of-the-art IVUS analysis accuracy demonstrate that the MSP-GAN is effective in enlarging the generalizability of diverse IVUS analysis methods and promoting accurate vessel and lumen segmentation and stenosis-related parameter quantification. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Xia2022Multilevel
ER  -

TY  - JOUR
AU  - Jia, X.
AU  - DongYe, C.
AU  - Peng, Y.
TI  - SiaTrans: Siamese transformer network for RGB-D salient object detection with depth image classification
PY  - 2022
T2  - Image and Vision Computing
VL  - 127
C7  - 104549
DO  - 10.1016/j.imavis.2022.104549
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138447827&doi=10.1016%2fj.imavis.2022.104549&partnerID=40&md5=bd17c1fec9fd34beda38467cd4044301
AB  - RGB-D SOD uses depth information to handle challenging scenes and obtain high-quality saliency maps. Existing state-of-the-art RGB-D saliency detection methods overwhelmingly rely on the strategy of directly fusing depth information. Although these methods improve the accuracy of saliency prediction through various cross-modality fusion strategies, misinformation provided by some poor-quality depth images can affect the saliency prediction result. To address this issue, a novel RGB-D salient object detection model (SiaTrans) is proposed in this paper, which allows training on depth image quality classification at the same time as training on SOD. In light of the common information between RGB and depth images on salient objects, SiaTrans uses a Siamese transformer network with shared weight parameters as the encoder and extracts RGB and depth features concatenated on the batch dimension, saving space resources without compromising performance. SiaTrans uses the class token in the backbone network (T2T-ViT) to classify the quality of depth images without preventing the token sequence from going on with the saliency detection task. The greatest benefit of our cross-modality fusion (CMF) and decoder is that they maintain consistency between RGB and RGB-D information decoding. In the test, SiaTrans decides whether to perform an RGB-D or RGB saliency detection task according to the quality classification signal of the depth image. Comprehensive experiments on nine RGB-D SOD benchmark datasets show that SiaTrans has the best overall performance and the least computation compared with recent state-of-the-art methods. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Jia2022SiaTrans
ER  -

TY  - JOUR
AU  - Qu, M.
AU  - Wang, Y.
AU  - Li, H.
AU  - Yang, J.
AU  - Ma, C.
TI  - Automatic identification of septal flash phenomenon in patients with complete left bundle branch block
PY  - 2022
T2  - Medical Image Analysis
VL  - 82
C7  - 102619
DO  - 10.1016/j.media.2022.102619
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140416193&doi=10.1016%2fj.media.2022.102619&partnerID=40&md5=c9f990445613c63ec83ab3da40a34498
AB  - Complete left bundle branch block (cLBBB) is an electrical conduction disorder associated with cardiac disease. Septal flash (SF) involves septal leftward contraction during early systole followed by a lengthening motion toward the right ventricle and affects several patients with cLBBB. It has been revealed that cLBBB patients with SF may be at risk of cardiac function reduction and poor prognosis. Therefore, accurate identification of SF may play a vital role in counseling patients about their prognosis. Generally, Septal flash is identified by echocardiography using visual “eyeballing”. However, this conventional method is subjective as it depends on operator experience. In this study, we build a linear attention cascaded net (LACNet) capable of processing echocardiography to identify SF automatically. The proposed method consists of a cascaded CNN-based encoder and an LSTM-based decoder, which extract spatial and temporal features simultaneously. A spatial transformer network (STN) module is employed to avoid image inconsistency and linear attention layers are implemented to reduce data complexity. Moreover, the left ventricle (LV) area-time curve calculated from segmentation results can be considered as a new independent disease predictor as SF phenomenon leads to transient left ventricle area enlargement. Therefore, we added the left ventricle area-time curve to LACNet to enrich input data diversity. The result shows the possibility of using echocardiography to diagnose cLBBB with SF automatically. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Qu2022Automatic
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Chen, M.
AU  - Bui, A.A.T.
TI  - ADADIAG: Adversarial Domain Adaptation of Diagnostic Prediction with Clinical Event Sequences
PY  - 2022
T2  - Journal of Biomedical Informatics
VL  - 134
C7  - 104168
DO  - 10.1016/j.jbi.2022.104168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138791106&doi=10.1016%2fj.jbi.2022.104168&partnerID=40&md5=7f11598272361a30f9452c07f45fe18b
AB  - Early detection of heart failure (HF) can provide patients with the opportunity for more timely intervention and better disease management, as well as efficient use of healthcare resources. Recent machine learning (ML) methods have shown promising performance on diagnostic prediction using temporal sequences from electronic health records (EHRs). In practice, however, these models may not generalize to other populations due to dataset shift. Shifts in datasets can be attributed to a range of factors such as variations in demographics, data management methods, and healthcare delivery patterns. In this paper, we use unsupervised adversarial domain adaptation methods to adaptively reduce the impact of dataset shift on cross-institutional transfer performance. The proposed framework is validated on a next-visit HF onset prediction task using a BERT-style Transformer-based language model pre-trained with a masked language modeling (MLM) task. Our model empirically demonstrates superior prediction performance relative to non-adversarial baselines in both transfer directions on two different clinical event sequence data sources. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Zhang2022ADADIAG
ER  -

TY  - JOUR
AU  - Zeng, P.
AU  - Hu, G.
AU  - Zhou, X.
AU  - Li, S.
AU  - Liu, P.
AU  - Liu, S.
TI  - Muformer: A long sequence time-series forecasting model based on modified multi-head attention
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 254
C7  - 109584
DO  - 10.1016/j.knosys.2022.109584
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136552906&doi=10.1016%2fj.knosys.2022.109584&partnerID=40&md5=c5eb1664c287e270aee32222cc151fef
AB  - Long sequence time-series forecasting (LSTF) problems are widespread in the real world, such as weather forecasting, stock market forecasting, and power resource management. LSTF demands the model to have a high prediction accuracy. Recent studies have shown that transformers have the potential to improve predictive accuracy. However, we found that Transformer still has severe problems preventing it from directly applying to LSTF, such as redundant input information, which makes it difficult to provide accurate predictions. In order to solve this problem, this paper proposes an efficient transformer-based predictive model called Muformer. The model includes (1) an input multiple perceptual domain (MPD) processing mechanism, which can process a single input data into N outputs of different perceptual domains, thereby playing a role in feature enhancement; (2) a multi-granularity attention head mechanism that can cooperate with the MPD mechanism: the N outputs of MPD are input into different attention heads so that the head information can be fully utilized to reduce the generation of redundant information; and (3) an attention head pruning mechanism, which prunes similar redundant information as that handled by multi-head attention, thereby reducing redundant head information and enhancing model expression. Extensive experimental results obtained on five large-scale datasets show that our approach significantly outperforms existing state-of-the-art methods. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; FMS:C; 
LB  - Zeng2022Muformer
ER  -

TY  - JOUR
AU  - Zuo, S.
AU  - Xiao, Y.
AU  - Chang, X.
AU  - Wang, X.
TI  - Vision transformers for dense prediction: A survey
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 253
C7  - 109552
DO  - 10.1016/j.knosys.2022.109552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135919826&doi=10.1016%2fj.knosys.2022.109552&partnerID=40&md5=031084ca10459495c0d63f93c8ace7f7
AB  - Transformers have demonstrated impressive expressiveness and transfer capability in computer vision fields. Dense prediction is a fundamental problem in computer vision that is more challenging to solve than general image-level prediction tasks. The inherent properties of transformers enable them to process feature representations with stable and relatively high resolution, which precisely satisfies the demands of dense prediction tasks for finer-grained and more globally coherent predictions. Furthermore, compared to convolutional networks, transformer methods require minimal inductive bias and permit long-range information interaction. These strengths have contributed to exciting advancements in dense prediction tasks that apply transformer networks. This survey aims to provide a comprehensive overview of transformer models with a specific focus on dense prediction. In this survey, we provide a well-rounded view of state-of-the-art transformer-based approaches, explicitly emphasizing pixel-level prediction tasks. We generally consider transformer variants from the network architecture perspective. We further propose a novel taxonomy to organize these models according to their constructions. Subsequently, we examine various specific optimization strategies to tackle certain bottleneck problems in dense prediction tasks. We explore the commonalities and differences among these works and provide multiple horizontal comparisons from the experimental point of view. Finally, we summarize several stubborn problems that continue to impact visual transformers and outline some possible development directions. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:C期刊; FMS:C; 
LB  - Zuo2022Vision
ER  -

TY  - JOUR
AU  - Windsor, E.
AU  - Cao, W.
TI  - Improving exchange rate forecasting via a new deep multimodal fusion model
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 14
SP  - 16701
EP  - 16717
DO  - 10.1007/s10489-022-03342-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127255043&doi=10.1007%2fs10489-022-03342-5&partnerID=40&md5=9e8b22ac293cf9ff41f68e6dc24a69da
AB  - Exchange rates are affected by the impact of disparate types of new information as well as the couplings between these modalities. Previous work mainly predicted exchange rates solely based on market indicators and therefore achieved unsatisfactory results. In response to such an issue, this study develops an inventive multimodal fusion-based long short-term memory (MF-LSTM) model to forecast the USD/CNY exchange rate. Our model consists of two parallel LSTM modules that extract abstract features from each modality of information and a shared representation layer that fuses these features. In terms of the text modality, bidirectional encoder representations from transformers (BERT) is applied to conduct a sentiment analysis on social media microblogs. Compared to previous studies, we incorporate not only market indicators but also investor sentiments into consideration, treating the two types of data differently to match their exclusive characteristics. In addition, we apply the multimodal fusion technique and contrive a deep coupled model rather than a shallow and simple model to reflect the couplings between the two modalities. As a consequence, the experimental results obtained over a 15-month period exhibit the superiority of the proposed approach over nine baseline algorithms. The purpose of our study is to demonstrate that it is practicable and effective to incorporate multimodal fusion into financial time series forecasting. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Windsor2022Improving
ER  -

TY  - JOUR
AU  - Wu, J.-L.
AU  - Chung, W.-Y.
TI  - Sentiment-based masked language modeling for improving sentence-level valence–arousal prediction
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 14
SP  - 16353
EP  - 16369
DO  - 10.1007/s10489-022-03384-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126893938&doi=10.1007%2fs10489-022-03384-9&partnerID=40&md5=69b7056c1d8ac1b59662f5865c6531cd
AB  - Sentiment indicator prediction is a crucial task in sentiment analysis or emotion recognition. Through the accurate quantification of sentiments expressed in a text, people’s sentiments can be better understood. Many studies have used mask language modeling to predict sentiment indicators. In this approach, every word has the same masking probability irrespective of its degree of influence on sentiments because a random masking mechanism is adopted. Therefore, the learned features do not strengthen the sentiment vocabulary in a sentence. Consequently, this paper proposes a sentiment-based masked language modeling method to predict sentence-level valence–arousal scores in Chinese. The proposed method is called dimensional valence–arousal based on bidirectional encoder representations from transformers (DVA-BERT), which combines the BERT model with specific sentiment word masking. The proposed method involves two learning tasks: valence–arousal intensity estimation, which is the major task, and random masked sentiment word prediction, which is the auxiliary task modify from mask language modeling, used to enhance the model performance. The experimental results indicate that the proposed DVA-BERT model can identify effective sentiment features by masking sentiment words and can outperform the original BERT model and other word masking methods. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Wu2022Sentiment-based
ER  -

TY  - JOUR
AU  - Du, L.
AU  - Ding, X.
AU  - Xiong, K.
AU  - Liu, T.
AU  - Qin, B.
TI  - Enhancing pretrained language models with structured commonsense knowledge for textual inference
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 254
C7  - 109488
DO  - 10.1016/j.knosys.2022.109488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136681799&doi=10.1016%2fj.knosys.2022.109488&partnerID=40&md5=2d4661a191748fa8c9601038c6ae4df8
AB  - Transformer-based pretrained language models have shown promising performances in various textual inference tasks. However, additional relational knowledge between the semantic units within the input text may also play a critical role in the inference process. To equip the pretrained language models with the relational knowledge, previous methods employ a retrieval-based strategy, which obtain the relational features from prebuilt knowledge bases by a lookup operation. However, the inherent sparsity of part of the knowledge bases would prevent the direct retrieval of the relational features. To address this issue, we propose a MIX-strategy based Structural commonsense integration framework (Mix-Sci). In addition to the traditional retrieval strategy which only adapts to the knowledge bases with high coverage, Mix-Sci introduces an additional generative strategy to incorporate the sparse knowledge bases with the pretrained language models. In specific, in the training process, Mix-Sci learns to generate the structural information of the knowledge base, including the embedding of nodes and the connection relationship between the nodes. So that in the test process, the structural information can be generated to enhance the inference process. Experimental results on two textual inference tasks: machine reading comprehension and event prediction show that Mix-Sci can effectively utilize both the dense and the sparse knowledge bases, to consistently improve the performance of pretrained language models on textual inference tasks. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; FMS:C; 
LB  - Du2022Enhancing
ER  -

TY  - JOUR
AU  - Sun, C.
AU  - Leng, J.
AU  - Sun, F.
TI  - A Fast Optimal Speed Planning System in Arterial Roads for Intelligent and Connected Vehicles
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 20
SP  - 20295
EP  - 20307
DO  - 10.1109/JIOT.2022.3172009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129682707&doi=10.1109%2fJIOT.2022.3172009&partnerID=40&md5=10a6375111d718dfbc73d2bed7d32548
AB  - Speed planning system is generally equipped for intelligent and connected vehicles (ICVs). Under the circumstances of autonomous driving, an energy-optimal speed trajectory is usually desired, particularly on urban arterial roads with complex traffic conditions involved. However, the existing speed planning solutions in the literature have not dealt with the problem of time consuming. Also, the ego vehicle could not perfectly track a precalculated speed reference because of the dynamically varying traffic. Thus, optimal speed planning cannot always be guaranteed. In this article, a fast optimal speed planning system for complex urban driving situations is established through an adaptive hierarchical control framework. In the planning layer, dynamic programming (DP) and the interior-point optimizer are jointly used to compute the global speed trajectory with access to signal phase and timing (SPaT) information. The computational burden is greatly alleviated based on a weighted orientation graph assumption and problem decomposition. The following layer utilizes the Informer, which is a transformer-based model, to predict preceding vehicle speed. Then, a target-switching model-predictive controller (MPC) is adopted for global speed trajectory following and adaption. The proposed approach significantly reduces speed planning computation time compared to previous solutions. Simulation results based on real road traffic scenes manifest that 22.0% of energy is saved compared with human driving.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Sun2022Fast
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Fang, X.
AU  - Fang, H.
TI  - Multi-task prediction method of business process based on BERT and Transfer Learning
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 254
C7  - 109603
DO  - 10.1016/j.knosys.2022.109603
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136482345&doi=10.1016%2fj.knosys.2022.109603&partnerID=40&md5=6c2b611ce97d0a9f8a01eebd8e138e9d
AB  - Predictive Business Process Monitoring (PBPM) is one of the essential tasks in Business Process Management (BPM). It aims to predict the future behavior of an ongoing case using completed cases of a process stored in the event log, such as the prediction of the next activity and outcome of the case, etc. Although various deep learning methods have been proposed for PBPM, none of them consider the simultaneous application to multiple predictive tasks. This paper proposes a multi-task prediction method based on BERT and Transfer Learning. First, the method performs the Masked Activity Model (MAM) of a self-supervised pre-training task on many unlabeled traces using BERT (Bidirectional Encoder Representations from Transformers). The pre-training task MAM captures the bidirectional semantic information of the input traces using the bidirectional Transformer structure in BERT. It obtains the long-term dependencies between activities using the Attention mechanism in the Transformer. Then, the universal representation model of the traces is obtained. Finally, two different models are defined for two prediction tasks of the next activity and the outcome of the case, respectively, and the pre-trained model is transferred to the two prediction models for training using the fine-tuning strategy. Experiments evaluation on eleven real-world event logs shows that the performance of the prediction tasks is affected by different masking tactics and masking probabilities in the pre-training task MAM. This method performs well in the next activity prediction task and the case outcome prediction task. It can be applied to several different prediction tasks faster and with more outstanding performance than the direct training method. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; FMS:C; 
LB  - Chen2022Multi-task
ER  -

TY  - JOUR
AU  - Zhong, C.
AU  - Hu, L.
AU  - Xia, S.
TI  - Spatial–temporal modeling for prediction of stylized human motion
PY  - 2022
T2  - Neurocomputing
VL  - 511
SP  - 34
EP  - 42
DO  - 10.1016/j.neucom.2022.08.075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138821793&doi=10.1016%2fj.neucom.2022.08.075&partnerID=40&md5=88f11393d7192175b78acf528160a2c5
AB  - Human motion prediction refers to forecasting human motion in the future given a past motion sequence, which has significant applications in human tracking, automatic motion generation, autonomous driving, human-robotics interaction, etc. Previous works usually used RNN-based methods, focusing on modeling the temporal dynamics of human motion, which have made great effort on content motions. However, it is unclear for their performance on stylized motion, which is with more expressive emotions and states of the human motion. Different styles within the same motion type have similar motion patterns but also subtle variances. This makes it difficult to be predicted. The main idea of this paper is to learn the spatial characteristic of stylized motion and combine it with the temporal dynamics to achieve accurate prediction. We adopt a transformer-based style encoder to learn the motion representation in the pose space and then maps it to the latent space modeled by the constant variance Gaussian mixture model; meanwhile, we use the hierarchical multi-scale RNN as a temporal encoder to capture the temporal dynamics of human motion; finally, we feed the spatial and temporal features into the prediction decoder to predict the next frame. Our experiments on the Human 3.6 M and Stylized MotionDatasets demonstrate that our model has comparable prediction performance with the state-of-the-art motion prediction works on Human 3.6 M and outperforms previous works on stylized human motion prediction. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Zhong2022Spatial–temporal
ER  -

TY  - JOUR
AU  - Ren, L.
AU  - Jia, Z.
AU  - Wang, X.
AU  - Dong, J.
AU  - Wang, W.
TI  - A T2-Tensor-Aided Multiscale Transformer for Remaining Useful Life Prediction in IIoT
PY  - 2022
T2  - IEEE Transactions on Industrial Informatics
VL  - 18
IS  - 11
SP  - 8108
EP  - 8118
DO  - 10.1109/TII.2022.3166790
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128671372&doi=10.1109%2fTII.2022.3166790&partnerID=40&md5=710ae8b8f0607949010cc9b26fc5210b
AB  - Industrial Internet of Things data incorporate the fundamental elements of industrial processes, providing novel paradigms of predictive maintenance for complex industrial equipment. Remaining useful life prediction is critical in the predictive maintenance task of product lifecycle management, which has attracted increasing research attention. However, most existing prediction methods cannot effectively extract complex multiscale temporal patterns and cannot meet the real-time requirements of industrial sites. To address these issues, we propose a T2-Tensor-aided multiscale transformer for accurate and effective prediction in this article. We defined the T2-tensor to represent the multiscale temporal pattern by reconstructing the time series. Besides, a high-order transformer for multiscale feature extraction is proposed. Particularly, the multiscale characteristics can be captured through intertoken and intratoken. In addition, a transformer parameter lightweighting method with tensor ring decomposition is developed. Experiments demonstrate the accuracy and efficiency of the proposed method.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:C期刊; 
LB  - Ren2022T2-Tensor-Aided
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Wang, X.
AU  - Liu, H.
AU  - Zou, X.
AU  - Cen, S.
AU  - Dai, G.
TI  - Learning to recommend journals for submission based on embedding models
PY  - 2022
T2  - Neurocomputing
VL  - 508
SP  - 242
EP  - 253
DO  - 10.1016/j.neucom.2022.08.043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136026559&doi=10.1016%2fj.neucom.2022.08.043&partnerID=40&md5=78f23f744965cdac063badd887558f52
AB  - Due to the rapid development of electronic journals, selecting appropriate journals to publish research papers has become a significant challenge to researchers. Sometimes, even a high-quality paper may get rejected from the editor due to the mismatch between the topic of the paper and the scope of the journal. To address this issue, we present a framework of learning to recommend journals for submission based on embedding models to assist researchers in journal selection. Specifically, the journal recommendation problem is formulated in the context of multi-class classification, where the Bidirectional Encoder Representations from Transformers (BERT) is deployed to extract the text-level features of representing papers and the AutoEncoder (AE) network is adopted to obtain the feature representation of each journal from the relationship matrix of the paper-journal bipartite graph. The final recommendation of journals is made by using a scoring function and a Softmax classifier. Experimental results obtained on the closed dataset of 10 different journals and the DBLP dataset indicate that we proposed method outperforms several classical approaches in terms of accuracy, F1, MRR, etc. Furthermore, we introduce information entropy as an evaluation index and analyze the model performance from the perspective of prediction uncertainty. This study provides a new approach to the journal recommendation task, and researchers can choose the appropriate embedding methods according to the actual problem. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Liu2022Learning
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Hu, W.
AU  - Cao, D.
AU  - Zhang, Z.
AU  - Huang, Q.
AU  - Chen, Z.
AU  - Blaabjerg, F.
TI  - A Multiagent Deep Reinforcement Learning Based Approach for the Optimization of Transformer Life Using Coordinated Electric Vehicles
PY  - 2022
T2  - IEEE Transactions on Industrial Informatics
VL  - 18
IS  - 11
SP  - 7639
EP  - 7652
DO  - 10.1109/TII.2021.3139650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122592322&doi=10.1109%2fTII.2021.3139650&partnerID=40&md5=cff96f3985bf0f101c7fafcafa0aa823
AB  - The uncertainties of charging behavior of electric vehicle (EV) owners have a negative impact on the loss of life (LOL) of distribution transformer. This article proposes a decentralized EV charging framework for optimization of the LOL of distribution transformer considering the dissatisfactions of EV owners. Specifically, long-short-term memory (LSTM) neural network is first utilized to capture the uncertainties caused by the load demand and electricity price. After that, each EV is modeled as an intelligent agent and a multiagent deep reinforcement learning approach is applied to solve the coordinated charging problem based on the forecasting information by the LSTM network. All the agents are trained in a centralized manner to develop coordinated control strategies while informing decisions based on local information when finishing the training process. The proposed approach can achieve coordinated charging management of EVs based on local information, which helps preserve the privacy of EV owners, reduce the cost induced by the deployment of communication devices, and avoid single-point failure. In addition, the parameter space noise and deep dense architecture in reinforcement learning are introduced to overcome premature convergence, training instability, and inefficiency due to the large action space of multiagent scenario. Comparative tests are carried out among several benchmarks utilizing real-world data to illustrate the effectiveness of the proposed approach.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:C期刊; 
LB  - Li2022Multiagent
ER  -

TY  - JOUR
AU  - Jin, G.
AU  - Xi, Z.
AU  - Sha, H.
AU  - Feng, Y.
AU  - Huang, J.
TI  - Deep multi-view graph-based network for citywide ride-hailing demand prediction
PY  - 2022
T2  - Neurocomputing
VL  - 510
SP  - 79
EP  - 94
DO  - 10.1016/j.neucom.2022.09.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137734881&doi=10.1016%2fj.neucom.2022.09.010&partnerID=40&md5=7cdaeb7ac01cb0835bc15dbadd5d2e28
AB  - Urban ride-hailing demand prediction is a crucial but challenging task for intelligent transportation system construction. Predictable ride-hailing demand can facilitate more reasonable vehicle scheduling and online car-hailing platform dispatch. Conventional deep learning methods with no external structured data can be accomplished via hybrid models of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) by meshing plentiful pixel-level labeled data, but data sparsity of high grid granularity in spatial perspective and limited learning capabilities of long-term dependencies in temporal perspective are still two striking bottlenecks. To address these problems, we propose a novel virtual graph modeling approach to focus on significant demand regions and a novel Deep Multi-View Spatio-temporal Virtual Graph Neural Network (DMVST-VGNN) to strengthen the learning capabilities of spatial dynamics and long-term temporal dependencies. Specifically, DMVST-VGNN integrates structures of 1D CNN, Multi-Graph Attention Neural Network and Transformer Network, which correspond to short-term temporal dynamics view, spatial dynamics view and long-term temporal dynamics view respectively. In this paper, multiple experiments are conducted on two large-scale New York City datasets in higher granularity prediction scenes. And the experimental results demonstrate the effectiveness of DMVST-VGNN framework in ride-hailing demand prediction, no matter in spatial scale or the temporal scale. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Jin2022Deep
ER  -

TY  - JOUR
AU  - Tang, Y.
AU  - Zhang, L.
AU  - Wu, H.
AU  - He, J.
AU  - Song, A.
TI  - Dual-Branch Interactive Networks on Multichannel Time Series for Human Activity Recognition
PY  - 2022
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 26
IS  - 10
SP  - 5223
EP  - 5234
DO  - 10.1109/JBHI.2022.3193148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139572079&doi=10.1109%2fJBHI.2022.3193148&partnerID=40&md5=6776bf60482d8b1dd66c5844eacb8ce0
AB  - The popularity of convolutional architecture has made sensor-based human activity recognition (HAR) become one primary beneficiary. By simply superimposing multiple convolution layers, the local features can be effectively captured from multi-channel time series sensor data, which could output high-performance activity prediction results. On the other hand, recent years have witnessed great success of Transformer model, which uses powerful self-attention mechanism to handle long-range sequence modeling tasks, hence avoiding the shortcoming of local feature representations caused by convolutional neural networks (CNNs). In this paper, we seek to combine the merits of CNN and Transformer to model multi-channel time series sensor data, which might provide compelling recognition performance with fewer parameters and FLOPs based on lightweight wearable devices. To this end, we propose a new Dual-branch Interactive Network (DIN) that inherits the advantages from both CNN and Transformer to handle multi-channel time series for HAR. Specifically, the proposed framework utilizes two-stream architecture to disentangle local and global features by performing conv-embedding and patch-embedding, where a co-attention mechanism is used to adaptively fuse global-to-local and local-to-global feature representations. We perform extensive experiments on three mainstream HAR benchmark datasets including PAMAP2, WISDM, and OPPORTUNITY, which verify that our method consistently outperforms several state-of-the-art baselines, reaching an F1-score of 92.05%, 98.17%, and 91.55% respectively with fewer parameters and FLOPs. In addition, the practical execution time is validated on an embedded Raspberry Pi P3 system, which demonstrates that our approach is adequately efficient for real-time HAR implementations and deserves as a better alternative in ubiquitous HAR computing scenario. Our model code will be released soon.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 33
C2  - CCF:C期刊; 
LB  - Tang2022Dual-Branch
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Chen, M.
AU  - Liang, Z.
AU  - Liu, L.
TI  - Dynamic Voltage Unbalance Constrained Economic Dispatch for Electrified Railways Integrated Energy Storage
PY  - 2022
T2  - IEEE Transactions on Industrial Informatics
VL  - 18
IS  - 11
SP  - 8225
EP  - 8235
DO  - 10.1109/TII.2022.3163540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127468297&doi=10.1109%2fTII.2022.3163540&partnerID=40&md5=fbf9394a24e437d9d61956dae001b861
AB  - The cophase traction power supply system (CTPSS) is a promising solution in the smart electrified railways to effectively eliminate the neutral section, improve regeneration braking energy (RBE) utilization and mitigate voltage unbalance (VU). It works by coordinating the power flow distribution (PFD) among the energy storage (ES), power flow controller, and traction transformer. However, the conventional dispatch considering VU mitigation may result in increasing extra operation costs and accelerating ES aging. Therefore, driven by the day-ahead forecasted information, a dynamic VU regulation strategy is proposed to draw up the VU compensation schedule (VU-CS), which can satisfy the probabilistic limitations of power quality standards. Consequently, a Copula-based VU dependence model is developed to transform the VU-CS into the PFD constraint set of CTPSS. Meanwhile, an ES degradation model is introduced to quantify the system operation cost within different scenarios. Taking the PFD as a VU regulation constraint, an economic dispatch scheme of CTPSS is established to obtain a minimum operation cost and maximum RBE utilization. Finally, case study tests verify the efficiency of the proposed approach. The results show that scheme can improve ES cycle life and decrease cost under the probabilistic limitations of VU.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:C期刊; 
LB  - Chen2022Dynamic
ER  -

TY  - JOUR
AU  - Reza, S.
AU  - Ferreira, M.C.
AU  - Machado, J.J.M.
AU  - Tavares, J.M.R.S.
TI  - A multi-head attention-based transformer model for traffic flow forecasting with a comparative analysis to recurrent neural networks
PY  - 2022
T2  - Expert Systems with Applications
VL  - 202
C7  - 117275
DO  - 10.1016/j.eswa.2022.117275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129433123&doi=10.1016%2fj.eswa.2022.117275&partnerID=40&md5=93f0f197ea5c09910212446ecbd7d79d
AB  - Traffic flow forecasting is an essential component of an intelligent transportation system to mitigate congestion. Recurrent neural networks, particularly gated recurrent units and long short-term memory, have been the state-of-the-art traffic flow forecasting models for the last few years. However, a more sophisticated and resilient model is necessary to effectively acquire long-range correlations in the time-series data sequence under analysis. The dominant performance of transformers by overcoming the drawbacks of recurrent neural networks in natural language processing might tackle this need and lead to successful time-series forecasting. This article presents a multi-head attention based transformer model for traffic flow forecasting with a comparative analysis between a gated recurrent unit and a long-short term memory-based model on PeMS dataset in this context. The model uses 5 heads with 5 identical layers of encoder and decoder and relies on Square Subsequent Masking techniques. The results demonstrate the promising performance of the transform-based model in predicting long-term traffic flow patterns effectively after feeding it with substantial amount of data. It also demonstrates its worthiness by increasing the mean squared errors and mean absolute percentage errors by (1.25−47.8)% and (32.4−83.8)%, respectively, concerning the current baselines. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 137
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Reza2022multi-head
ER  -

TY  - JOUR
AU  - Nandi, A.
AU  - De, A.
AU  - Mallick, A.
AU  - Middya, A.I.
AU  - Roy, S.
TI  - Attention based long-term air temperature forecasting network: ALTF Net
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 252
C7  - 109442
DO  - 10.1016/j.knosys.2022.109442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134893034&doi=10.1016%2fj.knosys.2022.109442&partnerID=40&md5=25cb04fc52e400ac8ca239f086773d37
AB  - Air temperature is one of the most important meteorological parameters related with atmospheric and environmental research. In this context, accurate prediction and forecasting of temperature is crucial due to the current global climate change. Although, the short term temperature forecasting have been more or less conquered in the past by using predictive algorithms, the long-term temperature forecasting is still a challenging task. Long term temperature forecasting is previously attempted by deep learning methods like Recurrent Neural Network (RNN), Long Short Term Memory (LSTM), etc. However, the gradient explosion and gradient vanishing problems of the RNN based networks were the major roadblock in the path of long-term prediction. So, in this paper, an attention-based model called ALTF Net (Attention based Long term Temperature Forecasting Network) approaches this problem using an Encoder–Decoder orientation. The Encoder encodes the relative dependencies of the auto-regressive time-series into an attention tensor which is used by the Decoder to produce the prediction. The Encoder is augmented to incorporate a convolution block to recognize the seasonal patterns. The proposed model ALTF uses a Transformer with an augmented encoder to predict temperature up to 150 days with high accuracy, a feat which would be difficult using RNN and LSTM. The model has been trained with 25+ years of data from 5 cities around the globe and the performance have been rigorously evaluated in terms of RMSE, MAE, R2, and correlation values. It is observed that the proposed model dominated over several baselines (ARIMA, RFR, KNN, MLP, RNN, CNN, LSTM, and Transformer) for long term temperature forecasting. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; FMS:C; 
LB  - Nandi2022Attention
ER  -

TY  - JOUR
AU  - Pereira, J.A.
AU  - Macêdo, D.
AU  - Zanchettin, C.
AU  - de Oliveira, A.L.I.
AU  - Fidalgo, R.D.N.
TI  - PictoBERT: Transformers for next pictogram prediction[Formula presented]
PY  - 2022
T2  - Expert Systems with Applications
VL  - 202
C7  - 117231
DO  - 10.1016/j.eswa.2022.117231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129554856&doi=10.1016%2fj.eswa.2022.117231&partnerID=40&md5=4118d1d99956764e1380fadde2e2bc76
AB  - Augmentative and Alternative Communication (AAC) boards are essential tools for people with Complex Communication Needs (e.g., a person with down's syndrome, autism, or cerebral palsy). These boards allow the construction of messages by arranging pictograms in sequence. In this context, a pictogram is a picture with a label that denotes an action, object, person, animal, or place. Predicting the next pictogram to be set in a sentence in construction is an essential feature for AAC boards to facilitate communication. Previous work in this task used n-gram statistical language models and knowledge bases. However, neural network literature suggests they can cope better with the task, and transformers-based models like BERT (Bidirectional Encoder Representations from Transformers) are revolutionizing this field. In this paper, we present PictoBERT, an adaptation of BERT for the next pictogram prediction task. We changed the BERT's input embeddings to allow word-sense usage instead of words, considering that a word-sense represents a pictogram better than a simple word. The proposed model outperforms the n-gram models and knowledge bases. Besides, PictoBERT can be fine-tuned to adapt to different users’ needs, making transfer learning its main characteristic. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Pereira2022PictoBERT
ER  -

TY  - JOUR
AU  - Pan, Z.
AU  - Wang, Y.
AU  - Tan, B.
TI  - Regressive Pseudo Label for Weakly Supervised Facial Landmark Detection
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 18
SP  - 17979
EP  - 17988
DO  - 10.1109/JIOT.2022.3162403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138790394&doi=10.1109%2fJIOT.2022.3162403&partnerID=40&md5=1996ae755a4cad4a0627dba6846f4f91
AB  - The progress of the deep neural network and visual sensors promote the facial landmark detection. However, faces are easily collected from Internet of Things (IoT) devices worldwide but are hard-labeled facial landmarks in consistent style. Though many weak supervision (WS) algorithms and theories have been proposed to handle the labeling problem, most of them are tailored for classification tasks and fail in regression tasks, especially in facial landmark detection. To tackle this WS regression task, first, we propose a regressive pseudo-labeling method by analyzing the cluster assumption of facial landmark detection, where overlaps are reduced and interval areas are increased among clusters of facial parts for unlabeled faces. Moreover, auxiliary information and domain loss are utilized to adapt model to samples with different styles. Second, we design a generator-regressor network to first estimate facial boundary attentions and then to locate facial landmarks. However, when generating pseudo labels based on predictive models automatically, there are two major issues. One is that the results of the multistage network highly depend on the former-stage accuracy, and another is that jointing different annotation styles always produces ambiguity feature representation. Thus, we propose two ideas. During training, the generator and regressor are decoupled to alleviate the inner dependence of the multistage network, and the heatmap discriminator is introduced to improve the quality of the predicted facial boundary. We design a transformer structure to fuse face image and boundary attentions, so that it can further complement useful features. Based on these ideas, our methods can automatically annotate accurate pseudo facial landmarks for unlabeled faces. Extensive experiments show that our model achieves good performance on different benchmark data sets, both in accuracy and efficiency. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Pan2022Regressive
ER  -

TY  - JOUR
AU  - Kim, D.
AU  - Kang, P.
TI  - Cross-modal distillation with audio–text fusion for fine-grained emotion classification using BERT and Wav2vec 2.0
PY  - 2022
T2  - Neurocomputing
VL  - 506
SP  - 168
EP  - 183
DO  - 10.1016/j.neucom.2022.07.035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135109335&doi=10.1016%2fj.neucom.2022.07.035&partnerID=40&md5=da7174c9bd1194a428f90e80fdd74127
AB  - Fine-grained emotion classification for mood- and emotion-related physical-characteristics detection and its application to computer technology using biometric sensors has been extensively researched in the field of affective computing. Although text modality has achieved a considerably high performance from the perspective of sentiment analysis, which simply classifies a positive or negative label, fine-grained emotion classification requires additional information besides text. An audio feature can be adopted as the additional information as it is closely associated with text, and the characteristics of the changes in sound pulses can be employed in fine-grained emotion classification. However, the multimodal datasets related to fine-grained emotion are limited, and the scalability and efficiency are insufficient for multimodal training to be applied extensively via the self-supervised learning (Self-SL) approach, which can adequately represent modality. To address these limitations, we propose cross-modal distillation (CMD), which induces the feature spaces of student models with a few parameters while receiving those of the teacher models that can adequately express each modality based on Self-SL. The proposed CMD performs the mapping of a feature space between teacher-student models based on contrastive learning, while two attention mechanisms—cross-attention between audio and text features and self-attention for features in modality—are performed during knowledge distillation. Wav2vec 2.0 and BERT, which are already adequately trained for audio and text via Self-SL, were adopted as teacher models; audio–text transformer models were used as student models. Accordingly, the CMD-based representation learning applies a lightweight model for IEMOCAP, MELD, and CMU–MOSEI datasets with the task of multi-class emotion classification, while exhibiting better fine-grained emotion classification performance than benchmark models with a considerably low uncertainty for prediction. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Kim2022Cross-modal
ER  -

TY  - JOUR
AU  - Wu, B.
AU  - Wang, Y.
TI  - Rich global feature guided network for monocular depth estimation
PY  - 2022
T2  - Image and Vision Computing
VL  - 125
C7  - 104520
DO  - 10.1016/j.imavis.2022.104520
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134828622&doi=10.1016%2fj.imavis.2022.104520&partnerID=40&md5=f55ae0038a7693205506bd9e5200d7ea
AB  - Monocular depth estimation is a classical but challenging task in the field of computer vision. In recent years, Convolutional Neural Network (CNN) based models have been developed to estimate high-quality depth map from a single image. Most recently, some Transformer based models have led to great improvements. All the researchers are looking for a better way to handle the global processing of information which is crucial for depth relation inference but of high computational complexity. In this paper, we take advantage of both the Transformer and CNN then propose a novel network architecture, called Rich Global Feature Guided Network (RGFN), with which rich global features are extracted from both encoder and decoder. The framework of the RGFN is the typical encoder-decoder for dense prediction. A hierarchical transformer is implemented as the encoder to capture multi-scale contextual information and model long-range dependencies. In the decoder, the Large Kernel Convolution Attention (LKCA) is adopted to extract global features from different scales and guide the network to recover fine depth maps from low spatial resolution feature maps progressively. What's more, we apply the depth-specific data augmentation method, Vertical CutDepth, to boost the performance. Experimental results on both the indoor and outdoor datasets demonstrate the superiority of the RGFN compared to other state-of-the-art models. Compared with the most recent method AdaBins, RGFN improves the RMSE score by 4.66% on the KITTI dataset and 4.67% on the NYU Depth v2 dataset. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Wu2022Rich
ER  -

TY  - JOUR
AU  - Ma, J.
AU  - Chan, J.
AU  - Rajasegarar, S.
AU  - Leckie, C.
TI  - Multi-attention graph neural networks for city-wide bus travel time estimation using limited data
PY  - 2022
T2  - Expert Systems with Applications
VL  - 202
C7  - 117057
DO  - 10.1016/j.eswa.2022.117057
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129071250&doi=10.1016%2fj.eswa.2022.117057&partnerID=40&md5=f0db5ca03b2e70ed19733b49c8b0df2e
AB  - An important factor that discourages patrons from using bus systems is the long and uncertain waiting times. Therefore, accurate bus travel time prediction is important to improve the serviceability of bus transport systems. Many researchers have proposed machine learning and deep learning-based models for bus travel time predictions. However, most of the existing models focus on predicting the travel times using complete data. Moreover, with the dramatically increasing population, bus systems also expand and upgrade their routes to provide improved coverage. Consequently, predicting the routes with sparse or no historical records becomes vital in this situation, and has not been well addressed in the literature. In particular, the challenges involved in this prediction include discovering routes with sparse records, discovering newly deployed routes, and finding the roads that need new routes. In order to address these, we propose a Multi-Attention Graph neural network for city-wide bus travel time estimation (TTE), especially for the routes with limited data, called MAGTTE. In particular, we first represent the bus network using a novel multi-view graph, which can automatically extract the stations and paths as nodes and weighted edges of bus graphs, respectively. Using inductive learning on dynamic graphs, we propose a multi-attention graph neural network with novel masks to capture the global and local spatial dependencies using limited data, and formulate a framework with LSTM and transformer layers to learn short and long-term temporal dependencies. Evaluation of our model on a real-world bus dataset from Xi'an, China demonstrates that the proposed model is superior compared to nine baselines, and robust to highly sparse data. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Ma2022Multi-attention
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Geng, F.
AU  - Wang, X.
TI  - MTPose: Human Pose Estimation with High-Resolution Multi-scale Transformers
PY  - 2022
T2  - Neural Processing Letters
VL  - 54
IS  - 5
SP  - 3941
EP  - 3964
DO  - 10.1007/s11063-022-10794-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127354876&doi=10.1007%2fs11063-022-10794-w&partnerID=40&md5=1b10ada50784f61f9783a4239e9c75eb
AB  - HRNet (High-Resolution Networks) as reported by Sun et al. (in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR), 2019) has been the state-of-the-art human pose estimation method, benefitting from its parallel high-resolution designed network structures. However, HRNet is still a typical CNN (Convolutional Neural Networks) architecture, with local convolution operations. Recently, Transformers have been successfully applied in many computer vision areas. The main mechanism in Transformers is self-attention, which can learn global or long-range dependencies among different parts. In this paper, we propose a human pose estimation framework built upon High-Resolution Multi-scale Transformers, termed MTPose. We combine the two advantages of high-resolution and Transformers together to improve the performance. Specifically, we design a sub-network, MTNet (Multi-scale Transformers-based high-resolution Networks), which consists of two parallel branches. One is high-resolution with convolutional local operations, named as local branch. The other is the global branch utilizing multi-scale Transformer encoders to learn long-range dependencies of the whole body keypoints. At the end of the networks, the two branches are integrated together to predict the final keypoint heatmaps. Experiments on two benchmark datasets, the MSCOCO keypoint detection dataset and MPII human pose dataset, demonstrate that our method can significantly improve the state-of-the-art human pose estimation methods. Code will be available at: https://github.com/fudiGeng/MTPose. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Wang2022MTPose
ER  -

TY  - JOUR
AU  - Liu, L.
AU  - Perez-Concha, O.
AU  - Nguyen, A.
AU  - Bennett, V.
AU  - Jorm, L.
TI  - Hierarchical label-wise attention transformer model for explainable ICD coding
PY  - 2022
T2  - Journal of Biomedical Informatics
VL  - 133
C7  - 104161
DO  - 10.1016/j.jbi.2022.104161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136531793&doi=10.1016%2fj.jbi.2022.104161&partnerID=40&md5=08dbce4567fb7ccf3c285b0f8a5bfc04
AB  - International Classification of Diseases (ICD) coding plays an important role in systematically classifying morbidity and mortality data. In this study, we propose a hierarchical label-wise attention Transformer model (HiLAT) for the explainable prediction of ICD codes from clinical documents. HiLAT firstly fine-tunes a pretrained Transformer model to represent the tokens of clinical documents. We subsequently employ a two-level hierarchical label-wise attention mechanism that creates label-specific document representations. These representations are in turn used by a feed-forward neural network to predict whether a specific ICD code is assigned to the input clinical document of interest. We evaluate HiLAT using hospital discharge summaries and their corresponding ICD-9 codes from the MIMIC-III database. To investigate the performance of different types of Transformer models, we develop ClinicalplusXLNet, which conducts continual pretraining from XLNet-Base using all the MIMIC-III clinical notes. The experiment results show that the F1 scores of the HiLAT + ClinicalplusXLNet outperform the previous state-of-the-art models for the top-50 most frequent ICD-9 codes from MIMIC-III. Visualisations of attention weights present a potential explainability tool for checking the face validity of ICD code predictions. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; 
LB  - Liu2022Hierarchical
ER  -

TY  - JOUR
AU  - Zhu, W.
AU  - Wang, Z.
AU  - Xu, L.
AU  - Meng, J.
TI  - Exploiting temporal coherence for self-supervised visual tracking by using vision transformer
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 251
C7  - 109318
DO  - 10.1016/j.knosys.2022.109318
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133665767&doi=10.1016%2fj.knosys.2022.109318&partnerID=40&md5=9e05c4a78e5351be1cc39dae534a8823
AB  - Deep learning based fully-supervised visual trackers entail the requirement of large-scale and frame-wise annotation that needs a laborious and tedious data annotation process. To reducing the amount of labeled efforts, a self-supervised learning framework, the ETC, is proposed in this work that exploits temporal coherence as a self-supervised signal and uses visual transformer to capture the relationship among the unlabeled video frames. We design a cycle-consistent transformer architecture to cast self-supervised tracking as cycle prediction problems. With carefully-designed and targeted configurations for cycle-consistent transformer including temporal sampling strategies, tracking initialization and data augmentation, our approach is applicable for two tracking settings, i.e., the unlabeled sample (ULS) scene and the few labeled sample (FLS) scene. To learn richer and more discriminative representations, we not only utilize the inter-frame correspondence, but also conduct the intra-frame correspondence to effectively model the target-to-frame and long-range correspondence. Extensive experiments are conducted on the popular benchmark datasets OTB2015, VOT2018, UAV123, TColor-128, NFS and LaSOT, and the results show that our approach achieves competitive results in the ULS setting, and supplies a trade-off between performance and annotation cost in the FLS setting. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; FMS:C; 
LB  - Zhu2022Exploiting
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Zhang, Y.
AU  - Li, X.
AU  - Cai, L.
AU  - Yin, B.
TI  - Multi-view hypergraph neural networks for student academic performance prediction
PY  - 2022
T2  - Engineering Applications of Artificial Intelligence
VL  - 114
C7  - 105174
DO  - 10.1016/j.engappai.2022.105174
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134616803&doi=10.1016%2fj.engappai.2022.105174&partnerID=40&md5=f347bcb386e1b9ea9b2baeae39175886
AB  - Academic performance prediction is a fundamental and hot issue in educational data mining (EDM). Recently, researchers have proposed a series of effective machine learning (ML) based classification strategies to predict students’ academic performance. However, prior arts are typically concerned about individual models but neglect the association among students, which might considerably have an effect on the integrity of the academic performance-related representations. Meanwhile, students’ multi-viewing behavior contains complex relations among students. Therefore, we propose a Multi-View Hypergraph Neural Network (MVHGNN) for predicting students’ academic performance. MVHGNN uses hypergraphs to construct high-order relations among students. The semantic information implied by multiple behaviors is consolidated through meta-paths. Further, a Cascade Attention Transformer (CAT) module is introduced to mine the weight of different behaviors by the self-attention mechanism. Our method is evaluated on real campus student behavioral datasets. The experimental results demonstrate that our method outperforms the state-of-the-art ones. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Li2022Multi-view
ER  -

TY  - JOUR
AU  - Zhang, Q.
AU  - Qin, C.
AU  - Zhang, Y.
AU  - Bao, F.
AU  - Zhang, C.
AU  - Liu, P.
TI  - Transformer-based attention network for stock movement prediction
PY  - 2022
T2  - Expert Systems with Applications
VL  - 202
C7  - 117239
DO  - 10.1016/j.eswa.2022.117239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129093748&doi=10.1016%2fj.eswa.2022.117239&partnerID=40&md5=5efe733f16fe4e8a7cef9891ff3bcbd9
AB  - Stock movement prediction is an important field of study that can help market traders make better trading decisions and earn more profit. The fusion of text from social media platforms such as Twitter and actual stock prices is an effective but difficult approach for stock movement prediction. Although some previous methods have explored this approach, there are still difficulties with the temporal dependence of financial data and insufficient effectiveness of fusing text and stock prices. To solve these problems, we propose the novel Transformer Encoder-based Attention Network (TEANet) framework, which is based on precise description through small-sample feature engineering and uses a small sample of 5 calendar days to capture the temporal dependence of financial data. In addition, this deep learning framework uses the Transformer model and multiple attention mechanisms to achieve feature extraction and effective analysis of financial data to achieve accurate prediction. Extensive experiments on four datasets demonstrate the effectiveness of our framework. Further simulations show that an actual trading strategy based on our proposed model can significantly increase profit and has practical application value. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 81
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Zhang2022Transformer-based
ER  -

TY  - JOUR
AU  - Tan, M.
AU  - Peng, H.
AU  - Liang, X.
AU  - Xie, Y.
AU  - Xia, Z.
AU  - Xiong, J.
TI  - LSTformer: Long Short-Term Transformer for Real Time Respiratory Prediction
PY  - 2022
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 26
IS  - 10
SP  - 5247
EP  - 5257
DO  - 10.1109/JBHI.2022.3191978
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135247143&doi=10.1109%2fJBHI.2022.3191978&partnerID=40&md5=10e3230b0d5b96bc5b2460ccfafd0cdb
AB  - Since the tumor moves with the patient's breathing movement in clinical surgery, the real-time prediction of respiratory movement is required to improve the efficacy of radiotherapy. Some RNN-based respiratory management methods have been proposed for this purpose. However, these existing RNN-based methods often suffer from the degradation of generalization performance for a long-term window (such as 600 ms) because of the structural consistency constraints. In this paper, we propose an innovative Long Short-term Transformer (LSTformer) for long-term real-time accurate respiratory prediction. Specifically, a novel Long-term Information Enhancement module (LIE) is proposed to solve the performance degradation under a long window by increasing the long-term memory of latent variables. A lightweight Transformer Encoder (LTE) is proposed to satisfy the real-time requirement via simplifying the architecture and limiting the number of layers. In addition, we propose an application-oriented data augmentation strategy to generalize our LSTformer to practical application scenarios, especially robotic radiotherapy. Extensive experiments on our augmented dataset and publicly available dataset demonstrate the state-of-the-art performance of our method on the premise of satisfying the real-time demand.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Tan2022LSTformer
ER  -

TY  - JOUR
AU  - Feng, M.
AU  - Su, J.
TI  - Learning reliable modal weight with transformer for robust RGBT tracking
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 249
C7  - 108945
DO  - 10.1016/j.knosys.2022.108945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130755988&doi=10.1016%2fj.knosys.2022.108945&partnerID=40&md5=1f1e5d5ddb16796d491030771cb16900
AB  - Many Siamese-based RGBT trackers have been prevalently designed in recent years for fast-tracking. However, the correlation operation in them is a local linear matching process, which may easily lose semantic information required inevitably by high-precision trackers. In this paper, we propose a strong cross-modal model based on transformer for robust RGBT tracking. Specifically, a simple dual-flow convolutional network is designed to extract and fuse dual-modal features, with comparably lower complexity. Besides, to enhance the feature representation and deepen semantic features, a modal weight allocation strategy and a backbone feature extracted network based on modified Resnet-50 are designed, respectively. Also, an attention-based transformer feature fusion network is adopted to improve long-distance feature association to decrease the loss of semantic information. Finally, a classification regression subnetwork is investigated to accurately predict the state of the target. Sufficient experiments have been implemented on the RGBT234, RGBT210, GTOT and LasHeR datasets, demonstrating more outstanding tracking performance against the state-of-the-art RGBT trackers. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:C期刊; FMS:C; 
LB  - Feng2022Learning
ER  -

TY  - JOUR
AU  - Pang, Y.
AU  - Zhao, X.
AU  - Hu, J.
AU  - Yan, H.
AU  - Liu, Y.
TI  - Bayesian Spatio-Temporal grAph tRansformer network (B-STAR) for multi-aircraft trajectory prediction
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 249
C7  - 108998
DO  - 10.1016/j.knosys.2022.108998
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130787596&doi=10.1016%2fj.knosys.2022.108998&partnerID=40&md5=65dd2ad5a811218cbfb4ddaae2973d95
AB  - Multi-Agent Trajectory Prediction is a critical and challenging component across different safety–critical engineering applications, e.g., autonomous driving and flight systems. Trajectory prediction tools are required for the next-generation air transportation system (NextGen). In practice, the prediction of aircraft trajectories needs to consider the impact of various sources, such as environmental conditions, pilot/controller behaviors, and potential conflicts with nearby aircraft. Huge uncertainties associated with these factors lead to the untrustworthiness of a deterministic trajectory prediction model. Moreover, the safety assurance in the near-terminal area is of specific interest due to the increased airspace complexity, where the instrument/visual flight rules are applied. In this work, we propose the Bayesian Spatio-Temporal grAph tRansformer (B-STAR) architecture to model the spatial and temporal relationship of multiple agents under uncertainties. It is shown that the proposed B-STAR achieves state-of-the-art performance on the ETH/UCY pedestrian dataset with UQ competence. Then, multi-aircraft near-terminal interactive trajectory prediction model is trained and validated with real-world flight recording data. The sensitivity study on the prediction/observation horizon and the graph neighboring distance threshold are performed. The code is available at https://github.com/ymlasu/para-atm-collection/tree/master/air-traffic-prediction/MultiAircraftTP. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 39
C2  - CCF:C期刊; FMS:C; 
LB  - Pang2022Bayesian
ER  -

TY  - JOUR
AU  - Vallés-Pérez, I.
AU  - Soria-Olivas, E.
AU  - Martínez-Sober, M.
AU  - Serrano-López, A.J.
AU  - Gómez-Sanchís, J.
AU  - Mateo, F.
TI  - Approaching sales forecasting using recurrent neural networks and transformers
PY  - 2022
T2  - Expert Systems with Applications
VL  - 201
C7  - 116993
DO  - 10.1016/j.eswa.2022.116993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129479523&doi=10.1016%2fj.eswa.2022.116993&partnerID=40&md5=22d479a974fa96b7355020bdeb140f1c
AB  - Accurate and fast demand forecast is one of the hot topics in supply chain for enabling the precise execution of the corresponding downstream processes (inbound and outbound planning, inventory placement, network planning, etc.). We develop three alternatives to tackle the problem of forecasting the customer sales at day/store/item level using deep learning techniques and the Corporación Favorita data set, published as part of a Kaggle competition. Our empirical results show how good performance can be achieved by using a simple sequence to sequence architecture with minimal data preprocessing effort. Additionally, we describe a training trick for making the model more time independent and hence improving generalization over time. The proposed solution achieves a RMSLE of around 0.54, which is competitive with other more specific solutions to the problem proposed in the Kaggle competition © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 30
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Vallés-Pérez2022Approaching
ER  -

TY  - JOUR
AU  - Moradi, M.
AU  - Samwald, M.
TI  - Improving the robustness and accuracy of biomedical language models through adversarial training
PY  - 2022
T2  - Journal of Biomedical Informatics
VL  - 132
C7  - 104114
DO  - 10.1016/j.jbi.2022.104114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133252210&doi=10.1016%2fj.jbi.2022.104114&partnerID=40&md5=82417c895000f705406160763d0b78b4
AB  - Deep transformer neural network models have improved the predictive accuracy of intelligent text processing systems in the biomedical domain. They have obtained state-of-the-art performance scores on a wide variety of biomedical and clinical Natural Language Processing (NLP) benchmarks. However, the robustness and reliability of these models has been less explored so far. Neural NLP models can be easily fooled by adversarial samples, i.e. minor changes to input that preserve the meaning and understandability of the text but force the NLP system to make erroneous decisions. This raises serious concerns about the security and trust-worthiness of biomedical NLP systems, especially when they are intended to be deployed in real-world use cases. We investigated the robustness of several transformer neural language models, i.e. BioBERT, SciBERT, BioMed-RoBERTa, and Bio-ClinicalBERT, on a wide range of biomedical and clinical text processing tasks. We implemented various adversarial attack methods to test the NLP systems in different attack scenarios. Experimental results showed that the biomedical NLP models are sensitive to adversarial samples; their performance dropped in average by 21 and 18.9 absolute percent on character-level and word-level adversarial noise, respectively, on Micro-F1, Pearson Correlation, and Accuracy measures. Conducting extensive adversarial training experiments, we fine-tuned the NLP models on a mixture of clean samples and adversarial inputs. Results showed that adversarial training is an effective defense mechanism against adversarial noise; the models’ robustness improved in average by 11.3 absolute percent. In addition, the models’ performance on clean data increased in average by 2.4 absolute percent, demonstrating that adversarial training can boost generalization abilities of biomedical NLP systems. This study takes an important step towards revealing vulnerabilities of deep neural language models in biomedical NLP applications. It also provides practical and effective strategies to develop secure, trust-worthy, and accurate intelligent text processing systems in the biomedical domain. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Moradi2022Improving
ER  -

TY  - JOUR
AU  - Peng, Y.
AU  - Yan, S.
AU  - Liu, Y.
AU  - Liu, Y.
AU  - Zhang, M.
TI  - View graph construction for scenes with duplicate structures via graph convolutional network
PY  - 2022
T2  - IET Computer Vision
VL  - 16
IS  - 5
SP  - 389
EP  - 402
DO  - 10.1049/cvi2.12095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127249074&doi=10.1049%2fcvi2.12095&partnerID=40&md5=572bf4dadfd63d401f7bfcdb5748f8f5
AB  - View graph construction aims to effectively organise disordered image dataset through image retrieval technique before structure from motion (SfM). Existing view graph construction methods usually fail to handle scenes with duplicate structure, because these methods solely treat the construction of view graph as a process of image-pair-wise matching and lack in exploiting images' topological details in dataset. In this paper, we handle this problem from a novel perspective to construct view graph in a global paradigm by introducing an end-to-end graph convolutional network (GCN). First, a location-aware embedding module is introduced to encode images into a feature space that takes into account the feature's location by using Vision Transformer architecture, improving the distinction between features of duplicate structure. Second, graph convolutional network that consists of topological relationship preserving module and feature metric learning module is proposed. Topological relationship preserving network is proposed to help nodes maintain their connected neighbourhood features. By merging the topological connected information into images' embedding, our method can process image matching in a global mode, thus improving the disambiguation ability for images with duplicate scenes. Then a feature metric learning network is embedded into GCN to dynamically compute the linkage prediction among nodes based on their features. Finally, our method combines these three parts to jointly optimise nodes' features and linkage prediction in an end-to-end paradigm. We make qualitative and quantitative comparisons based on three public benchmark datasets and demonstrate that our proposed method performs favourably against other state-of-the-art methods. © 2022 The Authors. IET Computer Vision published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Peng2022View
ER  -

TY  - JOUR
AU  - Huang, K.
AU  - Tian, C.
AU  - Su, J.
AU  - Lin, J.C.-W.
TI  - Transformer-based Cross Reference Network for video salient object detection
PY  - 2022
T2  - Pattern Recognition Letters
VL  - 160
SP  - 122
EP  - 127
DO  - 10.1016/j.patrec.2022.06.006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132790422&doi=10.1016%2fj.patrec.2022.06.006&partnerID=40&md5=e113d2600f04a4c9cc4830f5453c1068
AB  - Video salient object detection is a fundamental computer vision task aimed at highlighting the most conspicuous objects in a video sequence. There are two key challenges presented in video salient object detection: (1) how to extract effective feature representations from appearance and motion cues, and (2) how to combine both of them into robust saliency representation. To handle these challenges, in this paper, we propose a novel Transformer-based Cross Reference Network (TCRN), which fully exploits long-range context dependencies in both feature representation extraction and cross-modal (i.e., appearance and motion) integration. In contrast to existing CNN-based methods, our approach formulates video salient object detection as a sequence-to-sequence prediction task. In the proposed approach, the deep feature extraction is achieved by a pure vision transformer with multi-resolution token representations. Specifically, we design a Gated Cross Reference (GCR) module to effectively integrate appearance and motion into saliency representation. The GCR first propagates global context information between different modalities, and then perform cross-modal fusion by a gate mechanism. Extensive evaluations on five widely-used benchmarks show that the proposed Transformer-based method performs favorably against the existing state-of-the-art methods © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; 
LB  - Huang2022Transformer-based
ER  -

TY  - JOUR
AU  - He, B.
AU  - Li, Y.
TI  - Multi-future Transformer: Learning diverse interaction modes for behaviour prediction in autonomous driving
PY  - 2022
T2  - IET Intelligent Transport Systems
VL  - 16
IS  - 9
SP  - 1249
EP  - 1267
DO  - 10.1049/itr2.12207
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131174700&doi=10.1049%2fitr2.12207&partnerID=40&md5=bef91b89a19aa1780e9aa28ec55767e9
AB  - Predicting the future behaviour of neighbouring agents is crucial for autonomous driving. This task is challenging, largely because of the diverse unobservable intent of each agent which is further complicated by the complex interaction possibilities between them. The authors propose a multi-future Transformer framework that implicitly models the multi-modal joint distribution by capturing the diverse interaction modes of the scene. To this end, a parallel interaction module is constructed, whereby each interaction block learns the joint agent–agent and agent–map interactions for possible future evolution. The model can perform likelihood estimation from the perspective of both the joint distribution of the scene and marginal distribution of each agent. Combined with the proposed scene-level winner-take-all loss strategy complementary to the model architecture, the best performance is achieved for both target agent prediction and scene prediction tasks in a single model. To better utilise the scene context, comprehensive control experiments were conducted highlighting the importance of fine-grained scene representation with content-adaptive aggregation and late fusion of semantic attributes. The method, evaluated on the popular Argoverse forecasting dataset, outperformed previous methods while maintaining low model complexity. © 2022 The Authors. IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; FMS:C; 
LB  - He2022Multi-future
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Wang, Z.
AU  - Yu, X.
AU  - Chen, X.
AU  - Sun, M.
TI  - Memory-based Transformer with shorter window and longer horizon for multivariate time series forecasting
PY  - 2022
T2  - Pattern Recognition Letters
VL  - 160
SP  - 26
EP  - 33
DO  - 10.1016/j.patrec.2022.05.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131959004&doi=10.1016%2fj.patrec.2022.05.010&partnerID=40&md5=f5f6a14cab50be86227f58e52a6b0d43
AB  - Multivariate time series forecasting is an important problem that spans many fields. One challenge of this problem is the complex and non-linear interdependence between time steps and different variables. Recent studies have shown that Transformer has potential in capturing long-term dependencies. However, in the field of time series forecasting, Transformer still has some problems to solve, such as prediction fragmentation and insensitivity to data scale. In addition, traditional forecasting models often require a large amount of input data to support the training of the model when predicting long-term data. However, it is hard to provide sufficient time series input data due to equipment damage or weather situation. To solve these limitations, a memory-based Transformer with shorter window and longer horizon is proposed, called SWLHT. It uses the memory mechanism to make the model no longer only rely on a single input, but can combine the previous forecast results to assist in capturing long-term dependencies, thereby avoiding the requirement of excessively long input sequence. Furthermore, the memory mechanism can alleviate the prediction fragmentation to some extent. The experimental results and comparison of baselines on several real-world multivariate time series datasets have verified the effectiveness of the proposed model. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Liu2022Memory-based
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Song, K.
AU  - Bao, Y.
AU  - Yan, Y.
AU  - Han, Y.
TI  - Unidirectional RGB-T salient object detection with intertwined driving of encoding and fusion
PY  - 2022
T2  - Engineering Applications of Artificial Intelligence
VL  - 114
C7  - 105162
DO  - 10.1016/j.engappai.2022.105162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133933515&doi=10.1016%2fj.engappai.2022.105162&partnerID=40&md5=b62c4aa8e77c40c3baf0bf05e4a0f5c7
AB  - The U-shaped encoder–decoder architecture based on CNNs has been rooted in salient object detection (SOD) tasks, and it have revealed two drawbacks while driving the rapid development of saliency detection. (1) The inherent characteristics of CNNs dictate that it is difficult to learn long-range dependencies and model global correlations. (2) For the common purpose of improving the performance of saliency detection, the encoder and decoder should complement each other and work together. However, the existing encoder–decoder architecture treats encoder and decoder independently of each other. Specifically, the encoder is responsible for extracting features and the decoder fuses multi-level or multi-modal features to produce prediction maps. That is, the encoder alone needs to be responsible for the decoder, while the valuable information after the decoder fusion will not facilitate feature extraction. Therefore, we propose a unidirectional RGB-T salient object detection network with intertwined driving of encoding and fusion to solve the above problems. Firstly, we introduce transformer (SegFormer) as the backbone of the network to deal with the problem that CNNs are difficult to establish long-range dependence. Secondly, we constructed a unidirectional architecture where encoding and fusion are intertwined and mutually driving, which discards the drawbacks of encoder–decoder architecture to make the network more powerful and concise. Based on the unidirectional architecture, the proposed Local Detail-driven Fusion Module (LDFM) uses the fused features of the previous level to drive the cross-modal fusion at the current level. Meanwhile, the proposed Local Detail-driven Weighting Module (LDWM) uses the fused features to drive the cross-modal weighting. They will drive more effective features to be fed into the next level of the encoding block. Comprehensive experiments have verified the superior performance of our method on the RGB-T saliency detection task. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Wang2022Unidirectional
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Chen, T.
AU  - Shen, M.
AU  - Shi, Y.
AU  - Wang, D.
AU  - Zhang, X.
TI  - Gated three-tower transformer for text-driven stock market prediction
PY  - 2022
T2  - Multimedia Tools and Applications
VL  - 81
IS  - 21
SP  - 30093
EP  - 30119
DO  - 10.1007/s11042-022-11908-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127604439&doi=10.1007%2fs11042-022-11908-1&partnerID=40&md5=0d5fc522ecdc0ab867d6536413926012
AB  - Effective stock market prediction can significantly assist individual and institutional investors to make better trading decisions and help government stabilize the market. Therefore, a variety of methods have been proposed to tackle the issue of stock market prediction recently. However, it is still quite challenging to effectively extract the correlations and temporal information from multivariate time series of market data and integrate various kinds of features as well as auxiliary information, which is important for improving the performance of stock market prediction. This paper proposes an entirely Transformer based model, namely Gated Three-Tower Transformer (GT3), to incorporate numerical market information and social text information for accurate stock market prediction. Firstly, we devise a Channel-Wise Tower Encoder (CWTE) to capture the channel-wise features from transposed numerical data embeddings. Secondly, we design a Shifted Window Tower Encoder (SWTE) with Multi-Temporal Aggregation to extract and aggregate the multi-scale temporal features from the original numerical data embeddings. Then we adopt the encoder of vanilla Transformer as a Text Tower Encoder (TTE) to obtain the high-level textual features. Furthermore, we design a Cross-Tower Attention mechanism to assist the model to learn the trend-relevant significance of each daily text representation by leveraging the temporal features from SWTE. Finally, we unify CWTE, SWTE, and TTE as the GT3 model through a self-adaptive gate layer to perform end-to-end text-driven stock market prediction by fusing three types of features effectively and efficiently. Extensive experimental results on a real-world dataset show that the proposed model outperforms state-of-the-art baselines. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:C期刊; 
LB  - Chen2022Gated
ER  -

TY  - JOUR
AU  - Chootong, C.
AU  - Shih, T.K.
TI  - Tech-Talk-Sum: fine-tuning extractive summarization and enhancing BERT text contextualization for technological talk videos
PY  - 2022
T2  - Multimedia Tools and Applications
VL  - 81
IS  - 22
SP  - 31295
EP  - 31312
DO  - 10.1007/s11042-022-12812-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127657769&doi=10.1007%2fs11042-022-12812-4&partnerID=40&md5=1e6f5b31d9f8a3516c280d02affc0c4d
AB  - Automatic summarization is a task to condense the data to a shorter version while preserving key informational components and the meaning of content. In this paper, we introduce Tech-Talk-Sum, which is the combination of BERT (Bidirectional Encoder Representations from Transformers) and the attention mechanism to summarize the technological talk videos. We first introduce the technology talk datasets that were constructed from YouTube including short- and long-talk videos. Second, we explored various sentence representations from BERT’s output. Using the top hidden layer to represent sentences is the best choice for our datasets. The outputs from BERT were fed forward to the Bi-LSTM network to build local context vectors. Besides, we built the document encoder layer that leverages BERT and the self-attention mechanism to express the semantics of a video caption and to form the global context vector. Third, the undirected LSTM was added to bridge the local and global sentence’s contexts to predict the sentence’s salience score. Finally, the video summaries were generated based on the scores. We trained a single unified model on long-talk video datasets. ROUGE was utilized to evaluate our proposed methods. The experimental results demonstrate that our model has generalization ability, and achieves the baselines and state-of-the-art results for both long and short videos. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Chootong2022Tech-Talk-Sum
ER  -

TY  - JOUR
AU  - Ilias, L.
AU  - Askounis, D.
TI  - Explainable Identification of Dementia From Transcripts Using Transformer Networks
PY  - 2022
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 26
IS  - 8
SP  - 4153
EP  - 4164
DO  - 10.1109/JBHI.2022.3172479
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132510873&doi=10.1109%2fJBHI.2022.3172479&partnerID=40&md5=6fe42fa971ad6dae99dafd6cabdf9e2b
AB  - Alzheimer's disease (AD) is the main cause of dementia which is accompanied by loss of memory and may lead to severe consequences in peoples' everyday life if not diagnosed on time. Very few works have exploited transformer-based networks and despite the high accuracy achieved, little work has been done in terms of model interpretability. In addition, although Mini-Mental State Exam (MMSE) scores are inextricably linked with the identification of dementia, research works face the task of dementia identification and the task of the prediction of MMSE scores as two separate tasks. In order to address these limitations, we employ several transformer-based models, with BERT achieving the highest accuracy accounting for 87.50%. Concurrently, we propose an interpretable method to detect AD patients based on siamese networks reaching accuracy up to 83.75%. Next, we introduce two multi-task learning models, where the main task refers to the identification of dementia (binary classification), while the auxiliary one corresponds to the identification of the severity of dementia (multiclass classification). Our model obtains accuracy equal to 86.25% on the detection of AD patients in the multi-task learning setting. Finally, we present some new methods to identify the linguistic patterns used by AD patients and non-AD ones, including text statistics, vocabulary uniqueness, word usage, correlations via a detailed linguistic analysis, and explainability techniques (LIME). Findings indicate significant differences in language between AD and non-AD patients.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Ilias2022Explainable
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Xie, E.
AU  - Li, X.
AU  - Fan, D.-P.
AU  - Song, K.
AU  - Liang, D.
AU  - Lu, T.
AU  - Luo, P.
AU  - Shao, L.
TI  - PVT v2: Improved baselines with Pyramid Vision Transformer
PY  - 2022
T2  - Computational Visual Media
VL  - 8
IS  - 3
SP  - 415
EP  - 424
DO  - 10.1007/s41095-022-0274-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126297803&doi=10.1007%2fs41095-022-0274-8&partnerID=40&md5=d3986a81598aaba44cf2fcd15d50787f
AB  - Transformers have recently lead to encouraging progress in computer vision. In this work, we present new baselines by improving the original Pyramid Vision Transformer (PVT v1) by adding three designs: (i) a linear complexity attention layer, (ii) an overlapping patch embedding, and (iii) a convolutional feed-forward network. With these modifications, PVT v2 reduces the computational complexity of PVT v1 to linearity and provides significant improvements on fundamental vision tasks such as classification, detection, and segmentation. In particular, PVT v2 achieves comparable or better performance than recent work such as the Swin transformer. We hope this work will facilitate state-of-the-art transformer research in computer vision. Code is available at https://github.com/whai362/PVT.[Figure not available: see fulltext.] © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1056
C2  - CCF:C期刊; 
LB  - Wang2022PVT
ER  -

TY  - JOUR
AU  - Yang, G.
AU  - Ouyang, Y.
AU  - Ye, Z.
AU  - Gao, R.
AU  - Zeng, Y.
TI  - Social-path embedding-based transformer for graduation development prediction
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 12
SP  - 14119
EP  - 14136
DO  - 10.1007/s10489-022-03268-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125522262&doi=10.1007%2fs10489-022-03268-y&partnerID=40&md5=95c5db9f0a2cab41bc5806718eb29617
AB  - As the education of students attracts more and more attention, the task of graduation development prediction has gradually become a hot topic in academia and industry. The task of graduation development prediction aims to predict the employment category of students in advance via academic achievement data, which can help administrators understand students’ learning status and set up a reasonable learning plan. However, existing research ignores the potential impact of social relationships on students’ graduation development choices. To fully explore social relationships among students, we propose a Social-path Embedding-based Transformer Neural Network (SPE-TNN) for the task of graduation development prediction in this paper. Specifically, SPE-TNN is divided into the Social-path selection layer, the Social-path embedding layer, the Transformer layer, and the Multi-layer projection layer. Firstly, the Social-path selection layer is designed to find social relationships that impact graduation development and embed them into the student’s performance features through the Social-path embedding layer. Secondly, the Transformer layer is adopted to balance the weights of the students’ features. Finally, the Multi-layer projection layer is used to achieve the student graduation development prediction. Experimental results on the real-world datasets show that SPE-TNN outperforms the existing popular approaches. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Yang2022Social-path
ER  -

TY  - JOUR
AU  - Pang, W.
AU  - He, Q.
AU  - Li, Y.
TI  - Predicting skeleton trajectories using a Skeleton-Transformer for video anomaly detection
PY  - 2022
T2  - Multimedia Systems
VL  - 28
IS  - 4
SP  - 1481
EP  - 1494
DO  - 10.1007/s00530-022-00915-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127426585&doi=10.1007%2fs00530-022-00915-9&partnerID=40&md5=4b7484093fcc4cd6b18c7aeaa7303b15
AB  - Video anomaly detection detects video contents that do not conform to normal patterns offered by the training set. Because appearance-based features are susceptible to background interference, unlike most papers applying appearance-based methods, this paper proposes a novel Skeleton-Transformer (SkT) to predict future pose components in video frames and take errors between predicted pose components and corresponding expected values as anomaly scores. In SkT, we apply the multi-head self-attention (MSA) module and temporal convolutional layer (TCL), which are complementary because they focus on processing information from different viewpoints, to compose a skeleton attention (SkA) block. The MSA module can capture long-range dependencies between arbitrary pairwise pose components on spatial and temporal dimensions from different perspectives, while the TCL concentrates on local temporal information. Finally, multiple SkA blocks are stacked to form the major constituent of the SkT. To the best of our knowledge, the proposed approach is the first work applying Transformer framework to anomaly detection based on pose components, and we conduct experiments to determine the optimal structure. The proposed method achieves a frame-level AUC of 77.65% on the HR-ShanghaiTech dataset, exceeding state-of-the-art methods. Moreover, ablation studies validate each module’s effectiveness in the SkT, further verifying that the Transformer-based method is promising for anomaly detection. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Pang2022Predicting
ER  -

TY  - JOUR
AU  - Qin, C.
AU  - Wu, Y.
AU  - Zeng, J.
AU  - Tian, L.
AU  - Zhai, Y.
AU  - Li, F.
AU  - Zhang, X.
TI  - Joint Transformer and Multi-scale CNN for DCE-MRI Breast Cancer Segmentation
PY  - 2022
T2  - Soft Computing
VL  - 26
IS  - 17
SP  - 8317
EP  - 8334
DO  - 10.1007/s00500-022-07235-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132829543&doi=10.1007%2fs00500-022-07235-0&partnerID=40&md5=58acfff9e5d8f547c38c72443591734d
AB  - Automatic segmentation of breast cancer lesions in dynamic contrast-enhanced magnetic resonance imaging is challenged by low accuracy of delineation of the infiltration area, variable structure and shapes, large intensity heterogeneity changes, and low boundary contrast. This study constructed a two-stage breast cancer image segmentation framework and proposes a novel breast cancer lesion segmentation model (TR-IMUnet). The benchmark U-Net network model enables a rough delineation of the breast area in the acquired images and eliminates the influence of unrelated tissues (chest muscle, fat, and heart) on breast tumor segmentation. Based on the extracted results of the region of interest, the rectified linear unit (ReLU) function of the encoding–decoding structure in the model was replaced by an improved ReLU function to reserve and adjust the data dynamically according to input information. The segmentation accuracy of breast cancer lesions was improved by embedding a multi-scale fusion block and a transformer module in the coding path of the model, thereby obtaining multi-scale and global attention information. The experimental results showed that the breast tumor segmentation indexes Dice coefficient (Dice), Intersection over Union (IoU), Sensitivity (SEN), and Positive Predictive Value (PPV) increased by 4.27, 5.21, 3.37, and 3.68%, respectively, relative to the U-Net reference model. The proposed model improves the segmentation results of breast cancer lesions and reduces small area mis-segmentation and calcification segmentation. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Qin2022Joint
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Zou, Y.
AU  - Yang, X.
AU  - Yang, H.
TI  - A temporal fusion transformer for short-term freeway traffic speed multistep prediction
PY  - 2022
T2  - Neurocomputing
VL  - 500
SP  - 329
EP  - 340
DO  - 10.1016/j.neucom.2022.05.083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131061863&doi=10.1016%2fj.neucom.2022.05.083&partnerID=40&md5=924e9ea6650ea87789f54b9d3b35f21e
AB  - Accurate short-term freeway speed prediction is a key component for intelligent transportation management and can help travelers plan travel routes. However, very few existing studies focus on predicting one-hour ahead or longer freeway speed. In this study, a novel architecture called Temporal Fusion Transformer (TFT) is adopted to predict freeway speed with the prediction horizons from 5 min to 150 min. The TFT can capture short-term and long-term temporal dependence by a multi-head attention mechanism. Moreover, the TFT utilizes the fusion decoder to import various types of inputs which can improve the prediction accuracy. To demonstrate the advantage of the TFT, traffic speed data collected from an interstate freeway in Minnesota are used to train and test the prediction model. The TFT prediction performance is compared with several classic traffic prediction methods, and the results reveal that the TFT performs best in speed prediction when the prediction horizon is longer than 30 min. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 60
C2  - CCF:C期刊; 
LB  - Zhang2022temporal
ER  -

TY  - JOUR
AU  - Ghaffari Laleh, N.
AU  - Muti, H.S.
AU  - Loeffler, C.M.L.
AU  - Echle, A.
AU  - Saldanha, O.L.
AU  - Mahmood, F.
AU  - Lu, M.Y.
AU  - Trautwein, C.
AU  - Langer, R.
AU  - Dislich, B.
AU  - Buelow, R.D.
AU  - Grabsch, H.I.
AU  - Brenner, H.
AU  - Chang-Claude, J.
AU  - Alwers, E.
AU  - Brinker, T.J.
AU  - Khader, F.
AU  - Truhn, D.
AU  - Gaisa, N.T.
AU  - Boor, P.
AU  - Hoffmeister, M.
AU  - Schulz, V.
AU  - Kather, J.N.
TI  - Benchmarking weakly-supervised deep learning pipelines for whole slide classification in computational pathology
PY  - 2022
T2  - Medical Image Analysis
VL  - 79
C7  - 102474
DO  - 10.1016/j.media.2022.102474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130396057&doi=10.1016%2fj.media.2022.102474&partnerID=40&md5=0582070f9d6e309f083fa000ad7ee998
AB  - Artificial intelligence (AI) can extract visual information from histopathological slides and yield biological insight and clinical biomarkers. Whole slide images are cut into thousands of tiles and classification problems are often weakly-supervised: the ground truth is only known for the slide, not for every single tile. In classical weakly-supervised analysis pipelines, all tiles inherit the slide label while in multiple-instance learning (MIL), only bags of tiles inherit the label. However, it is still unclear how these widely used but markedly different approaches perform relative to each other. We implemented and systematically compared six methods in six clinically relevant end-to-end prediction tasks using data from N=2980 patients for training with rigorous external validation. We tested three classical weakly-supervised approaches with convolutional neural networks and vision transformers (ViT) and three MIL-based approaches with and without an additional attention module. Our results empirically demonstrate that histological tumor subtyping of renal cell carcinoma is an easy task in which all approaches achieve an area under the receiver operating curve (AUROC) of above 0.9. In contrast, we report significant performance differences for clinically relevant tasks of mutation prediction in colorectal, gastric, and bladder cancer. In these mutation prediction tasks, classical weakly-supervised workflows outperformed MIL-based weakly-supervised methods for mutation prediction, which is surprising given their simplicity. This shows that new end-to-end image analysis pipelines in computational pathology should be compared to classical weakly-supervised methods. Also, these findings motivate the development of new methods which combine the elegant assumptions of MIL with the empirically observed higher performance of classical weakly-supervised approaches. We make all source codes publicly available at https://github.com/KatherLab/HIA, allowing easy application of all methods to any similar task. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 103
C2  - CCF:C期刊; 
LB  - Ghaffari Laleh2022Benchmarking
ER  -

TY  - JOUR
AU  - Cheng, L.-C.
AU  - Chen, Y.-L.
AU  - Liao, Y.-Y.
TI  - Aspect-based sentiment analysis with component focusing multi-head co-attention networks
PY  - 2022
T2  - Neurocomputing
VL  - 489
SP  - 9
EP  - 17
DO  - 10.1016/j.neucom.2022.03.027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126592567&doi=10.1016%2fj.neucom.2022.03.027&partnerID=40&md5=13b572b3d06ccf41be941d0c33195686
AB  - User-generated content based on customer opinions and experience has become a rich source of valuable information for enterprises. The purpose of aspect-based sentiment analysis is to predict the sentiment polarity of specific targets from user-generated content. This study proposes a component focusing multi-head co-attention network model which contains three modules: extended context, component focusing, and multi-headed co-attention, designed to improve upon problems encountered in the past. The extended context module improves the ability of bidirectional encoder representations from transformers to handle aspect-based sentiment analysis tasks, and the component focusing module improves the weighting of adjectives and adverbs, to alleviate the problem of average pooling, which treats every word as an equally important term. The multi-head co-attention network is applied to learn the important words in a multi-word target before acquiring the context representation and performs the attention mechanism on the sequence data. The performance of the proposed model is evaluated in extensive experiments on publicly available datasets. The results show that the performance of the proposed model is better than that of the recent state-of-the-art models. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:C期刊; 
LB  - Cheng2022Aspect-based
ER  -

TY  - JOUR
AU  - Anbaee Farimani, S.
AU  - Vafaei Jahan, M.
AU  - Milani Fard, A.
AU  - Tabbakh, S.R.K.
TI  - Investigating the informativeness of technical indicators and news sentiment in financial market price prediction
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 247
C7  - 108742
DO  - 10.1016/j.knosys.2022.108742
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129221558&doi=10.1016%2fj.knosys.2022.108742&partnerID=40&md5=5daebc53f5f7a935011fcae25b5b8e9e
AB  - Real-time market prediction tool tracking public opinion in specialized newsgroups and informative market data persuades investors of financial markets. Previous works mainly used lexicon-based sentiment analysis for financial markets prediction, while recently proposed transformer-based sentiment analysis promise good results for cross-domain sentiment analysis. This work considers temporal relationships between consecutive snapshots of informative market data and mood time series for market price prediction. We calculate the sentiment mood time series via the probability distribution of news embedding generated through a BERT-based transformer language model fine-tuned for financial domain sentiment analysis. We then use a deep recurrent neural network for feature extraction followed by a dense layer for price regression. We implemented our approach as an open-source API for real-time price regression. We build a corpus of financial news related to currency pairs in foreign exchange and Cryptocurrency markets. We further augment our model with informative technical indicators and news sentiment scores aligned based on news release timestamp. Results of our experiments show significant error reduction compared to the baselines. Our Financial News and Financial Sentiment Analysis RESTFul APIs are available for public use. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 45
C2  - CCF:C期刊; FMS:C; 
LB  - Anbaee Farimani2022Investigating
ER  -

TY  - JOUR
AU  - Yang, J.
AU  - Ge, H.
AU  - Su, S.
AU  - Liu, G.
TI  - Transformer-based two-source motion model for multi-object tracking
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 9
SP  - 9967
EP  - 9979
DO  - 10.1007/s10489-021-03012-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122682154&doi=10.1007%2fs10489-021-03012-y&partnerID=40&md5=1e867eccd906de845edec05605b85fc5
AB  - Recently, benefit from the development of detection models, the multi-object tracking method based on tracking-by-detection has greatly improved performance. However, most methods still utilize traditional motion models for position prediction, such as the constant velocity model and Kalman filter. Only a few methods adopt deep network-based methods for prediction. Still, these methods only exploit the simplest RNN(Recurrent Neural Network) to predict the position, and the position offset caused by the camera movement is not considered. Therefore, inspired by the outstanding performance of Transformer in temporal tasks, this paper proposes a Transformer-based motion model for multi-object tracking. By taking the historical position difference of the target and the offset vector between consecutive frames as input, the model considers the motion of the target itself and the camera at the same time, which improves the prediction accuracy of the motion model used in the multi-target tracking method, thereby improving tracking performance. Through comparative experiments and tracking results on MOTchallenge benchmarks, the effectiveness of the proposed method is proved. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:C期刊; 
LB  - Yang2022Transformer-based
ER  -

TY  - JOUR
AU  - Lou, J.
AU  - Lin, H.
AU  - Marshall, D.
AU  - Saupe, D.
AU  - Liu, H.
TI  - TranSalNet: Towards perceptually relevant visual saliency prediction
PY  - 2022
T2  - Neurocomputing
VL  - 494
SP  - 455
EP  - 467
DO  - 10.1016/j.neucom.2022.04.080
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129958464&doi=10.1016%2fj.neucom.2022.04.080&partnerID=40&md5=14639c954bec8ee29d0d6921757046f6
AB  - Convolutional neural networks (CNNs) have significantly advanced computational modelling for saliency prediction. However, accurately simulating the mechanisms of visual attention in the human cortex remains an academic challenge. It is critical to integrate properties of human vision into the design of CNN architectures, leading to perceptually more relevant saliency prediction. Due to the inherent inductive biases of CNN architectures, there is a lack of sufficient long-range contextual encoding capacity. This hinders CNN-based saliency models from capturing properties that emulate viewing behaviour of humans. Transformers have shown great potential in encoding long-range information by leveraging the self-attention mechanism. In this paper, we propose a novel saliency model that integrates transformer components to CNNs to capture the long-range contextual visual information. Experimental results show that the transformers provide added value to saliency prediction, enhancing its perceptual relevance in the performance. Our proposed saliency model using transformers has achieved superior results on public benchmarks and competitions for saliency prediction models. The source code of our proposed saliency model TranSalNet is available at: https://github.com/LJOVO/TranSalNet. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 56
C2  - CCF:C期刊; 
LB  - Lou2022TranSalNet
ER  -

TY  - JOUR
AU  - Heo, J.
AU  - Wang, Y.
AU  - Park, J.
TI  - Occlusion-aware spatial attention transformer for occluded object recognition
PY  - 2022
T2  - Pattern Recognition Letters
VL  - 159
SP  - 70
EP  - 76
DO  - 10.1016/j.patrec.2022.05.006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130406003&doi=10.1016%2fj.patrec.2022.05.006&partnerID=40&md5=87f9f49a7dd9772dcb4b02dec7f26780
AB  - Object classification under partial occlusion has been challenging for deep convolutional neural networks due to their innate locality in extracting features. We propose an Occlusion-aware Spatial Attention Transformer (OSAT) architecture based on Vision Transformer (ViT), CutMix augmentation, and Occlusion Mask Predictor (OMP) to solve the occlusion problem. ViT mainly utilizes the self-attention mechanism, which enables the model to capture spatially distant information. In addition, for occluded image augmentation, we combine CutMix augmentation with ViT. OMP is used as a multi-task learning method and for spatial attention on non-occluded region. Our proposed OSAT achieves state-of-the-art performance on occluded vehicle classification datasets from PASCAL3D+ and MS-COCO. Moreover, additional experiments show that OMP outperforms previous approach in occluder localization both quantitatively and qualitatively. According to our ablation studies, ViT is effective at analyzing occluded objects, and our approach of CutMix augmentation and OMP led to further improvements. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Heo2022Occlusion-aware
ER  -

TY  - JOUR
AU  - Fu, Y.
AU  - Liu, Y.
TI  - Contrastive transformer based domain adaptation for multi-source cross-domain sentiment classification
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 245
C7  - 108649
DO  - 10.1016/j.knosys.2022.108649
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127818743&doi=10.1016%2fj.knosys.2022.108649&partnerID=40&md5=404041b59ed49d4232c7ed2d5d456a02
AB  - Cross-domain sentiment classification aims to predict the sentiment tendency in unlabeled target domain data using labeled source-domain data. The wide range of data sources has motivated research into multi-source cross-domain sentiment classification tasks. Conventional domain adaptation methods focus on reducing the domain difference between the source and target domains to realize sentiment migration, which ignores the selection of effective sources and fails to deal with negative transfer, leading to limited performance. To address these problems, we propose a contrastive transformer-based domain adaptation (CTDA) method, which not only develops a multi-source domain selection strategy, but also improves the problem of negative transfer from the perspective of data quality. Specifically, the proposed CTDA includes four stages: (1) designing a mixed selector to weight all related sources or pick out the Top-K sources according to the spatial similarity between both domains, (2) building an adaptor to extract domain-invariant information of features by minimizing the Wasserstein distance between both domains, (3) constructing a discriminator to capture the domain-private information of features by contrastive learning, and (4) performing a weighted classifier to predict the sentiment tendency of the target domain according to multiple trained source classifiers. Extensive experiments were performed on two public benchmarks, and the results demonstrated that our CTDA model significantly outperforms state-of-the-art approaches. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; FMS:C; 
LB  - Fu2022Contrastive
ER  -

TY  - JOUR
AU  - Rao, S.
AU  - Li, Y.
AU  - Ramakrishnan, R.
AU  - Hassaine, A.
AU  - Canoy, D.
AU  - Cleland, J.
AU  - Lukasiewicz, T.
AU  - Salimi-Khorshidi, G.
AU  - Rahimi, K.
TI  - An Explainable Transformer-Based Deep Learning Model for the Prediction of Incident Heart Failure
PY  - 2022
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 26
IS  - 7
SP  - 3362
EP  - 3372
DO  - 10.1109/JBHI.2022.3148820
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124718967&doi=10.1109%2fJBHI.2022.3148820&partnerID=40&md5=a19d66866357b6fb61d6ef49ff28df0d
AB  - Predicting the incidence of complex chronic conditions such as heart failure is challenging. Deep learning models applied to rich electronic health records may improve prediction but remain unexplainable hampering their wider use in medical practice. We aimed to develop a deep-learning framework for accurate and yet explainable prediction of 6-month incident heart failure (HF). Using 100,071 patients from longitudinal linked electronic health records across the U.K., we applied a novel Transformer-based risk model using all community and hospital diagnoses and medications contextualized within the age and calendar year for each patient's clinical encounter. Feature importance was investigated with an ablation analysis to compare model performance when alternatively removing features and by comparing the variability of temporal representations. A post-hoc perturbation technique was conducted to propagate the changes in the input to the outcome for feature contribution analyses. Our model achieved 0.93 area under the receiver operator curve and 0.69 area under the precision-recall curve on internal 5-fold cross validation and outperformed existing deep learning models. Ablation analysis indicated medication is important for predicting HF risk, calendar year is more important than chronological age, which was further reinforced by temporal variability analysis. Contribution analyses identified risk factors that are closely related to HF. Many of them were consistent with existing knowledge from clinical and epidemiological research but several new associations were revealed which had not been considered in expert-driven risk prediction models. In conclusion, the results highlight that our deep learning model, in addition high predictive performance, can inform data-driven risk factor identification.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 52
C2  - CCF:C期刊; 
LB  - Rao2022Explainable
ER  -

TY  - JOUR
AU  - Suman, C.
AU  - Raj, A.
AU  - Saha, S.
AU  - Bhattacharyya, P.
TI  - Authorship Attribution of Microtext Using Capsule Networks
PY  - 2022
T2  - IEEE Transactions on Computational Social Systems
VL  - 9
IS  - 4
SP  - 1038
EP  - 1047
DO  - 10.1109/TCSS.2021.3067736
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103786732&doi=10.1109%2fTCSS.2021.3067736&partnerID=40&md5=fd9f0af2fd0888e112d95f55225e9d92
AB  - Authorship attribution (AA) is an important task, as it identifies the author of a written text from a set of suspect authors. Different methodologies of anonymous writing have been discovered with the rising usage of social media. This anonymous writing leads to an increase in malicious and suspicious activities, and anonymity makes it difficult to find the suspect. AA helps to find the writer of a suspect text from a set of suspects. Different social media platforms, such as Twitter, Facebook, and Instagram, are used regularly by the users for sharing their daily life activities. Finding the writer of microtexts is considered the toughest task due to the shorter length of the suspect piece of text. We present a Capsule-based convolutional neural network (CNN) model over character $n$ -grams for performing the AA task. Capsule with kervolutional neural networks (KNNs) has also been utilized for this task. We also present different analyses of our developed system, which improves the interpretability of our developed system. Heat-maps for different models illustrate the relevant text fragments for the prediction task. A standard Twitter data set is used for evaluating the performance of the developed systems. The experimental evaluation shows that capsule-based CNNs and capsule-based KNNs perform competitively and are able to outperform previous methods. The source codes and the supplementary file are available here https://github.com/chanchalIITP/AuthorIdentification. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Suman2022Authorship
ER  -

TY  - JOUR
AU  - Lv, Z.
AU  - Huang, X.
AU  - Cao, W.
TI  - An improved GAN with transformers for pedestrian trajectory prediction models
PY  - 2022
T2  - International Journal of Intelligent Systems
VL  - 37
IS  - 8
SP  - 4417
EP  - 4436
DO  - 10.1002/int.22724
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118297394&doi=10.1002%2fint.22724&partnerID=40&md5=97e986fbf6de1bc80d6d352b47f80479
AB  - Predicting the future trajectories of multiple pedestrians in certain scenes is critical for autonomous moving platforms (like, self-driving cars and social robots). In this paper, we propose a novel Generative Adversarial Network model with Transformers, which simulates the pedestrian distribution to capture the uncertainty of the predicted paths and generate more reasonable future trajectories. The design of our method includes a generator and a discriminator. The generator mainly contains an encoder, a decoder, and a prediction module. Specifically, the encoder and the decoder comprise multihead convolutional self-attention to learn the sequence of historical movement, and the prediction module incorporates the Mish Feed-Forward Network to yield the predicted target. The discriminator takes both the predicted paths and ground truth as input, classifies them as socially acceptable or not. Experimental results show that the proposed method consistently boosts the performance of trajectory forecasting, and our framework surpasses several existing baselines by evaluating the results on various data sets. Code is available at https://github.com/lzz970818/Trajectory-Prediction. © 2021 Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; 
LB  - Lv2022improved
ER  -

TY  - JOUR
AU  - Duan, G.
AU  - Han, W.
TI  - Heavy Overload Prediction Method of Distribution Transformer Based on GBDT
PY  - 2022
T2  - International Journal of Pattern Recognition and Artificial Intelligence
VL  - 36
IS  - 9
C7  - 2259014
DO  - 10.1142/S0218001422590145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135841226&doi=10.1142%2fS0218001422590145&partnerID=40&md5=224edbc0b6fc61bc1b000d492e0ce7dc
AB  - The distribution transformer voltage may be overloaded, which may lead to the aging of distribution transformer components, shorten the service life of distribution transformer components and even a®ect the daily life of community residents and the operation of enterprises. A large amount of real data are collected, and the factors that a®ect the heavy overload of distribution transformer are comprehensively considered from multiple angles, so as to establish a model for future prediction and early maintenance to reduce losses. First, the collected data is analyzed by attributes and preprocessed to improve the quality of the data. Then, the time attributes are generalized according to seasons, months, holidays and weekends. The test results show that the data prediction value is more accurate when generalized according to seasons. For the prediction model, the gradient lifting decision tree algorithm is selected to establish the model, and then the parameters are further optimized, and ¯nally the model is evaluated. Lastly, the prediction accuracy of the model reaches a high level, and it can be determined that the prediction is close to the objective fact. The model can be used to predict the heavy overload of distribution transformer voltage, so as to reduce the loss caused by abnormal conditions of relevant equipment for the enterprises. © World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Duan2022Heavy
ER  -

TY  - JOUR
AU  - Ye, X.
AU  - Fang, S.
AU  - Sun, F.
AU  - Zhang, C.
AU  - Xiang, S.
TI  - Meta Graph Transformer: A Novel Framework for Spatial–Temporal Traffic Prediction
PY  - 2022
T2  - Neurocomputing
VL  - 491
SP  - 544
EP  - 563
DO  - 10.1016/j.neucom.2021.12.033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121918064&doi=10.1016%2fj.neucom.2021.12.033&partnerID=40&md5=1a4386efee5b25df351003de3e7008cc
AB  - Accurate traffic prediction is critical for enhancing the performance of intelligent transportation systems. The key challenge to this task is how to properly model the complex dynamics of traffic while respecting and exploiting both spatial and temporal heterogeneity in data. This paper proposes a novel framework called Meta Graph Transformer (MGT) to address this problem. The MGT framework is a generalization of the original transformer, which is used to model vector sequences in natural language processing. Specifically, MGT has an encoder-decoder architecture. The encoder is responsible for encoding historical traffic data into intermediate representations, while the decoder predicts future traffic states autoregressively. The main building blocks of MGT are three types of attention layers named Temporal Self-Attention (TSA), Spatial Self-Attention (SSA), and Temporal Encoder-Decoder Attention (TEDA), respectively. They all have a multi-head structure. TSAs and SSAs are employed by both the encoder and decoder to capture temporal and spatial correlations. TEDAs are employed by the decoder, allowing every position in the decoder to attend all positions in the input sequence temporally. By leveraging multiple graphs, SSA can conduct sparse spatial attention with various inductive biases. To facilitate the model's awareness of temporal and spatial conditions, Spatial–Temporal Embeddings (STEs) are learned from external attributes, which are composed of temporal attributes (e.g. sequential order, time of day) and spatial attributes (e.g. Laplacian eigenmaps). These embeddings are then utilized by all the attention layers via meta-learning, hence endowing these layers with Spatial–Temporal Heterogeneity-Aware (STHA) properties. Experiments on three real-world traffic datasets demonstrate the superiority of our model over several state-of-the-art methods. Our code and data are available at ( http://github.com/lonicera-yx/MGT). © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 62
C2  - CCF:C期刊; 
LB  - Ye2022Meta
ER  -

TY  - JOUR
AU  - Drury, B.
AU  - Gonçalo Oliveira, H.
AU  - De Andrade Lopes, A.
TI  - A survey of the extraction and applications of causal relations
PY  - 2022
T2  - Natural Language Engineering
VL  - 28
IS  - 3
SP  - 361
EP  - 400
DO  - 10.1017/S135132492100036X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124234667&doi=10.1017%2fS135132492100036X&partnerID=40&md5=526d974792dcbea1ab7d2396ad2624ed
AB  - Causationin written natural language can express a strong relationship between events and facts. Causation in the written form can be referred to as a causal relation where a cause event entails the occurrence of an effect event. A cause and effect relationship is stronger than a correlation between events, and therefore aggregated causal relations extracted from large corpora can be used in numerous applications such as question-answering and summarisation to produce superior results than traditional approaches. Techniques like logical consequence allow causal relations to be used in niche practical applications such as event prediction which is useful for diverse domains such as security and finance. Until recently, the use of causal relations was a relatively unpopular technique because the causal relation extraction techniques were problematic, and the relations returned were incomplete, error prone or simplistic. The recent adoption of language models and improved relation extractors for natural language such as Transformer-XL (Dai et al. (2019). Transformer-xl: Attentive language models beyond a fixed-length context. arXiv preprint arXiv:1901.02860) has seen a surge of research interest in the possibilities of using causal relations in practical applications. Until now, there has not been an extensive survey of the practical applications of causal relations; therefore, this survey is intended precisely to demonstrate the potential of causal relations. It is a comprehensive survey of the work on the extraction of causal relations and their applications, while also discussing the nature of causation and its representation in text.  ©
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Drury2022survey
ER  -

TY  - JOUR
AU  - Zhuang, X.
AU  - Liu, F.
AU  - Hou, J.
AU  - Hao, J.
AU  - Cai, X.
TI  - Transformer-Based Interactive Multi-Modal Attention Network for Video Sentiment Detection
PY  - 2022
T2  - Neural Processing Letters
VL  - 54
IS  - 3
SP  - 1943
EP  - 1960
DO  - 10.1007/s11063-021-10713-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122313823&doi=10.1007%2fs11063-021-10713-5&partnerID=40&md5=d0600f634f63e2b7937dbb0d036efe99
AB  - Social media allows users to express opinions in multiple modalities such as text, pictures, and short-videos. Multi-modal sentiment detection can more effectively predict the emotional tendencies expressed by users. Therefore, multi-modal sentiment detection has received extensive attention in recent years. Current works consider utterances from videos as independent modal, ignoring the effective interaction among diffence modalities of a video. To tackle these challenges, we propose transformer-based interactive multi-modal attention network to investigate multi-modal paired attention between multiple modalities and utterances for video sentiment detection. Specifically, we first take a series of utterances as input and use three separate transformer encoders to capture the utterances-level features of each modality. Subsequently, we introduced multimodal paired attention mechanisms to learn the cross-modality information between multiple modalities and utterances. Finally, we inject the cross-modality information into the multi-headed self-attention layer for making final emotion and sentiment classification. Our solutions outperform baseline models on three multi-modal datasets. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Zhuang2022Transformer-Based
ER  -

TY  - JOUR
AU  - Ru, Y.
AU  - Qiu, X.
AU  - Tan, X.
AU  - Chen, B.
AU  - Gao, Y.
AU  - Jin, Y.
TI  - Sparse-attentive meta temporal point process for clinical decision support
PY  - 2022
T2  - Neurocomputing
VL  - 485
SP  - 114
EP  - 123
DO  - 10.1016/j.neucom.2022.02.028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125275849&doi=10.1016%2fj.neucom.2022.02.028&partnerID=40&md5=98988cad4200f21f015897cec80f8006
AB  - In the study of clinical decision-making, prediction of future clinical events of patients has become an important task, especially for variant disease predictions. In previous studies, the disease prediction problems are considered as binary classification based on the patients’ electronic health records (EHRs), which lack the capacity to predict multiple types of diseases. In this paper, we propose a method which can predict both the patients’ disease types among various candidate diseases and patients’ next hospital visit time. The next hospital visit time is crucial for medical experts in making decisions, because it reflects the onset time information of disease and provides sufficient information on the severity of the disease. Our proposed method is implemented based on the point process framework, which utilizes meta-learning to gain the prior knowledge of the individual patient's clinical data with context information, adopts sparse-attention to determine the importance of past major clinical events, and simulates the intensity of clinical events through Hawkes process to predict the types of diseases diagnosed by the doctor and patient’ next hospital visit time. The experimental data are extracted from the public datasets: Multiparameter Intelligent Monitoring in Intensive Care (MIMIC-II) and Medical Information Mart for Intensive Care (MIMIC-III). Compared with the baseline time series models, our proposed method has achieved superior results, with a higher F1-score (66.67%) and a lower root-mean-square error (RMSE) (6.69) on the test set, which proves the effectiveness of the proposed method. We further study the self-attention mechanism based on Transformer and sparse-attention methods to demonstrate the validity of our model. Our proposed method provides empirical evidence of its ability in facilitating the decision-making process of clinicians, which can be potentially utilized as effective clinical decision support tools to better improve the quality of medical services and reduce medical errors. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Ru2022Sparse-attentive
ER  -

TY  - JOUR
AU  - Tiwari, S.
AU  - Jain, A.
AU  - Ahmed, N.M.O.S.
AU  - Alkwai, L.M.
AU  - Dafhalla, A.K.Y.
AU  - Hamad, S.A.S.
TI  - Machine learning-based model for prediction of power consumption in smart grid- smart way towards smart city
PY  - 2022
T2  - Expert Systems
VL  - 39
IS  - 5
C7  - e12832
DO  - 10.1111/exsy.12832
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115719123&doi=10.1111%2fexsy.12832&partnerID=40&md5=1db9bbc2520a5b999355feec0d6b6c02
AB  - A smart city is an idea that is realized by the computing of a large amount of data collected through sensors, cameras, and other electronic methods to provide services, manage resources and solve daily life problems. The transformation of the conventional grid to a smart grid is one step in the direction towards smart city realization. An electric grid is composed of control stations, generation centres, transformers, communication lines, and distributors, which helps in transferring power from the power station to domestic and commercial consumers. Present electric grids are not smart enough that they can estimate the varying power requirement of the consumer. Also, these conventional grids are not enough robust and scalable. This has become the motivation for shifting from a conventional grid to a smart grid. The smart grid is a kind of power grid, which is robust and adapts itself to the varying needs of the consumer and self-healing in nature. In this way, the transformation from a conventional grid to a smart grid will help the government to make a smart city. The emergence of machine learning has helped in the prediction of the stability of the grid under the dynamically changing requirement of the consumer. Also, the usage of a variety of sensors will help in the collection of real-time consumption data. Through machine learning algorithms, we can gain an insight view of the collected data. This has helped the smart grid to convert into a robust smart grid, as this will help in avoiding the situation of failure. In this work, the authors have applied logistic regression, decision tree, support vector machine, linear discriminant analysis, quadratic discriminant analysis, naïve Bayes, random forest, and k-nearest neighbour algorithms to predict the stability of the grid. The authors have used the smart grid stability dataset freely available on Kaggle to train and test the models. It has been found that a model designed using the support vector machine algorithm has given the most accurate result. © 2021 John Wiley & Sons, Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Tiwari2022Machine
ER  -

TY  - JOUR
AU  - Nwoye, C.I.
AU  - Yu, T.
AU  - Gonzalez, C.
AU  - Seeliger, B.
AU  - Mascagni, P.
AU  - Mutter, D.
AU  - Marescaux, J.
AU  - Padoy, N.
TI  - Rendezvous: Attention mechanisms for the recognition of surgical action triplets in endoscopic videos
PY  - 2022
T2  - Medical Image Analysis
VL  - 78
C7  - 102433
DO  - 10.1016/j.media.2022.102433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127688027&doi=10.1016%2fj.media.2022.102433&partnerID=40&md5=04fc31bc9b671aa485a4e782ca0ef4d7
AB  - Out of all existing frameworks for surgical workflow analysis in endoscopic videos, action triplet recognition stands out as the only one aiming to provide truly fine-grained and comprehensive information on surgical activities. This information, presented as 〈instrument, verb, target〉 combinations, is highly challenging to be accurately identified. Triplet components can be difficult to recognize individually; in this task, it requires not only performing recognition simultaneously for all three triplet components, but also correctly establishing the data association between them. To achieve this task, we introduce our new model, the Rendezvous (RDV), which recognizes triplets directly from surgical videos by leveraging attention at two different levels. We first introduce a new form of spatial attention to capture individual action triplet components in a scene; called Class Activation Guided Attention Mechanism (CAGAM). This technique focuses on the recognition of verbs and targets using activations resulting from instruments. To solve the association problem, our RDV model adds a new form of semantic attention inspired by Transformer networks; called Multi-Head of Mixed Attention (MHMA). This technique uses several cross and self attentions to effectively capture relationships between instruments, verbs, and targets. We also introduce CholecT50 - a dataset of 50 endoscopic videos in which every frame has been annotated with labels from 100 triplet classes. Our proposed RDV model significantly improves the triplet prediction mAP by over 9% compared to the state-of-the-art methods on this dataset. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 68
C2  - CCF:C期刊; 
LB  - Nwoye2022Rendezvous
ER  -

TY  - JOUR
AU  - Blanc, C.
AU  - Bailly, A.
AU  - Francis, É.
AU  - Guillotin, T.
AU  - Jamal, F.
AU  - Wakim, B.
AU  - Roy, P.
TI  - FlauBERT vs. CamemBERT: Understanding patient's answers by a French medical chatbot
PY  - 2022
T2  - Artificial Intelligence in Medicine
VL  - 127
C7  - 102264
DO  - 10.1016/j.artmed.2022.102264
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126120860&doi=10.1016%2fj.artmed.2022.102264&partnerID=40&md5=e051f37ff9a8d205d278a963571b4dd8
AB  - In a number of circumstances, obtaining health-related information from a patient is time-consuming, whereas a chatbot interacting efficiently with that patient might help saving health care professional time and better assisting the patient. Making a chatbot understand patients' answers uses Natural Language Understanding (NLU) technology that relies on ‘intent’ and ‘slot’ predictions. Over the last few years, language models (such as BERT) pre-trained on huge amounts of data achieved state-of-the-art intent and slot predictions by connecting a neural network architecture (e.g., linear, recurrent, long short-term memory, or bidirectional long short-term memory) and fine-tuning all language model and neural network parameters end-to-end. Currently, two language models are specialized in French language: FlauBERT and CamemBERT. This study was designed to find out which combination of language model and neural network architecture was the best for intent and slot prediction by a chatbot from a French corpus of clinical cases. The comparisons showed that FlauBERT performed better than CamemBERT whatever the network architecture used and that complex architectures did not significantly improve performance vs. simple ones whatever the language model. Thus, in the medical field, the results support recommending FlauBERT with a simple linear network architecture. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:C期刊; 
LB  - Blanc2022FlauBERT
ER  -

TY  - JOUR
AU  - Jia, X.
AU  - Wang, Y.
AU  - Peng, Y.
AU  - Chen, S.
TI  - Semantic association enhancement transformer with relative position for image captioning
PY  - 2022
T2  - Multimedia Tools and Applications
VL  - 81
IS  - 15
SP  - 21349
EP  - 21367
DO  - 10.1007/s11042-022-12776-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126303252&doi=10.1007%2fs11042-022-12776-5&partnerID=40&md5=a1d1daa8228dfaf3c2ea18abc1e456b7
AB  - Transformer-based architectures have shown encouraging results in image captioning. They usually utilize self-attention based methods to establish the semantic association between objects in an image for predicting caption. However, when appearance features between the candidate object and query object show weak dependence, the self-attention based methods are hard to capture the semantic association between them. In this paper, a Semantic Association Enhancement Transformer model is proposed to address the above challenge. First, an Appearance-Geometry Multi-Head Attention is introduced to model a visual relationship by integrating the geometry features and appearance features of the objects. The visual relationship characterizes the semantic association and relative position among the objects. Secondly, a Visual Relationship Improving module is presented to weigh the importance of appearance feature and geometry feature of query object to the modeled visual relationship. Then, the visual relationship among different objects is adaptively improved according to the constructed importance, especially the objects with weak dependence on appearance features, thereby enhancing their semantic association. Extensive experiments on MS COCO dataset demonstrate that the proposed method outperforms the state-of-the-art methods. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Jia2022Semantic
ER  -

TY  - JOUR
AU  - Murthy, C.B.
AU  - Hashmi, M.F.
AU  - Keskar, A.G.
TI  - EfficientLiteDet: a real-time pedestrian and vehicle detection algorithm
PY  - 2022
T2  - Machine Vision and Applications
VL  - 33
IS  - 3
C7  - 47
DO  - 10.1007/s00138-022-01293-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128207348&doi=10.1007%2fs00138-022-01293-y&partnerID=40&md5=0f640d2f2f215a278f3c8bb40ee0e073
AB  - Since safety plays a crucial role and the top priority, in both unmanned and driver-assistance driving systems, there is a need of efficient and accurate detection of captured objects by object detection algorithms in real-time. Directly applying existing models to tackle real-time pedestrian and vehicle detection tasks captured by high speed moving vehicle scenarios has two problems. First, the target scale varies drastically because the vehicle speed changes greatly. Second, captured images contain both tiny targets and high density targets, which brings in occlusion between targets. To solve the two issues, an efficient light weight real-time detection algorithm is proposed, which is referred to as EfficientLiteDet. Based on Tiny-YOLOv4, one more prediction head is introduced in the proposed model to detect multi-scale targets effectively. In order to detect tiny and occluded denser targets, we used Transformer Prediction Heads (TPH) instead of original anchor detection heads in our model. To explore the potential of self-attention mechanism in TPH, the proposed model integrates “convolutional block attention model” to locate crucial attention region on scenarios with denser targets. Further to improve the detection performance of our model, we applied various data augmentation strategies such as mosaic, mix-up, multi-scale, and random-horizontal-flip during the model training. Extensive experiments are conducted on five challenging pedestrian and vehicle datasets shows that the EfficientLiteDet model has better performance in real-time scenarios. On Pascal Voc-2007, Highway and Udacity datasets, the proposed model achieves mean average precision (mAP) 87.3%, 80.1% and 77.8%, respectively, which is quite better than Tiny-YOLOv4 state-of-the-art algorithm by + 2.4%, 1.8% and + 2.4%, respectively. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:C期刊; 
LB  - Murthy2022EfficientLiteDet
ER  -

TY  - JOUR
AU  - Manku, R.R.
AU  - Paul, A.J.
TI  - Local and global context-based pairwise models for sentence ordering
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 243
C7  - 108453
DO  - 10.1016/j.knosys.2022.108453
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126341639&doi=10.1016%2fj.knosys.2022.108453&partnerID=40&md5=9d9c6cbb30e55bc32fc41bfcac764e9b
AB  - Sentence Ordering refers to the task of rearranging a set of sentences into the appropriate coherent order. For this task, most previous approaches have explored global context-based end-to-end methods using Sequence Generation techniques. In this paper, we put forward a set of robust local and global context-based pairwise ordering strategies, leveraging which our prediction strategies outperform all previous works in this domain. Our proposed encoding method utilizes the paragraph's rich global contextual information to predict the pairwise order using novel transformer architectures. Analysis of the two proposed decoding strategies helps better explain error propagation in pairwise models. This approach is the most accurate pure pairwise model and our encoding strategy also significantly improves the performance of other recent approaches that use pairwise models, including the previous state-of-the-art, demonstrating the research novelty and generalizability of this work. Additionally, we show how the pre-training task for ALBERT helps it to significantly outperform BERT, despite having considerably lesser parameters. The extensive experimental results, architectural analysis and ablation studies demonstrate the effectiveness and superiority of the proposed models compared to the previous state-of-the-art, besides providing a much better understanding of the functioning of pairwise models. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; FMS:C; 
LB  - Manku2022Local
ER  -

TY  - JOUR
AU  - Sharma, H.
AU  - Singh Jalal, A.
TI  - A framework for visual question answering with the integration of scene-text using PHOCs and fisher vectors
PY  - 2022
T2  - Expert Systems with Applications
VL  - 190
C7  - 116159
DO  - 10.1016/j.eswa.2021.116159
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118877951&doi=10.1016%2fj.eswa.2021.116159&partnerID=40&md5=e5add948322bce6ef246b56d19666e81
AB  - Text contained in an image gives useful information about that image. Consider a warning signboard with text “high voltage”; it indicates the hazard or risk involved in the image. Thus, this semantic textual information can be very useful for better understanding of images, which is not utilized by the existing visual question answering (VQA) models. However, the presence of this textual information in images can strongly guide the VQA task. This work deal with the task of visual question answering by exploiting these textual cues together with the visual content to boost the accuracy of VQA models. In the work, a novel VQA model is proposed based on the PHOC and fisher vector based representation. Based on the PHOCs of the scene-text, we have constructed a powerful descriptor by using a Fisher Vectors. Also, the proposed model uses transformer model together with dynamic pointer networks for answer decoding process. Thus, the proposed model uses a sequence of decoding steps for answer generation instead of just assuming answer prediction as a classification problem as considered by previous works. We have shown the qualitative and quantitative results on three popular datasets: VQA 2.0, TextVQA and ST-VQA. The results show the effectiveness of the proposed model over the existing models. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Sharma2022framework
ER  -

TY  - JOUR
AU  - Yang, S.
AU  - Tong, S.
AU  - Zhu, G.
AU  - Cao, J.
AU  - Wang, Y.
AU  - Xue, Z.
AU  - Sun, H.
AU  - Wen, Y.
TI  - MVE-FLK: A multi-task legal judgment prediction via multi-view encoder fusing legal keywords
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 239
C7  - 107960
DO  - 10.1016/j.knosys.2021.107960
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123257286&doi=10.1016%2fj.knosys.2021.107960&partnerID=40&md5=76fbcd23f51d9d41bd8ab0a865d1c1e2
AB  - Legal Judgment Prediction (LJP) aims to predict the judgment result based on the fact description of a criminal case, and is gradually becoming a hot research topic in the legal realm. Generally, a classic LJP contains three subtasks, i.e., applicable law article prediction, charge prediction, and term of penalty prediction. In real-world scenarios, both charge prediction and applicable law article prediction are actually the tasks of multi-class classification with multi-label learning. However, most existing studies model them as the problems of multi-class classification with single-label learning. Besides, they only consider the context of the fact description, and ignore the exploitation of effective keywords that are widely existed in abundant law articles. To fill the above gaps, we propose a novel multi-task legal judgment prediction framework via multi-view encoder fusing legal keywords, named MVE-FLK, to jointly model multiple subtasks in LJP. Specifically, the multi-view encoder is the core module of MVE-FLK, in this module, we devise a word and sentence encoder (WSE) with an attention mechanism to fuse legal keywords. And then, we develop a multi-view attention network to combine WSE with classic Transformer and DAN (Deep Averaging Network) for encoding the case from multiple views. After that, we propose a multi-task prediction module by developing a novel keywords fusing approach to enhance the performance of multi-task prediction. In addition, we devise a unique prediction principle for each subtask at a fine-grained level, which effectively improves the performance of subtasks. The experimental results on two real-life legal datasets show that our model yields significant prediction performance advantages over six competitive methods. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; FMS:C; 
LB  - Yang2022MVE-FLK
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Zhu, T.
AU  - Gao, D.
AU  - Xu, J.
AU  - Liu, H.
AU  - Ning, H.
TI  - Few-shot activity learning by dual Markov logic networks
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 240
C7  - 108158
DO  - 10.1016/j.knosys.2022.108158
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123346074&doi=10.1016%2fj.knosys.2022.108158&partnerID=40&md5=255dad1a27ec39e0b25642ad2e4263e8
AB  - In Human activity recognition (HAR), a large amount of data may have no labels, so it is necessary to realize effective and credible data calibration under Few-shot learning (FSL). This paper proposes a new method for calibrating unlabeled data by using two models to improve the credibility of data labels further. Markov logic network (MLN) is used as the basic model. On the one hand, the construction of knowledge can reduce the dependence on the amount of data. On the other hand, the relationship between the actions can be effectively expressed. Specifically, we pre-train two MLN models using two unmatched training datasets. Then, these models are used to infer the possible labels of unlabeled data simultaneously. When labels are inconsistent, the most likely label will be selected and used to retrain the models. In order to ensure the credibility of the selected label, the selection process adopts a dual-model cross-validation method. This method uses the least square method to determine models’ weights according to the test results. Finally, it gives the possible probability of the labels under the common prediction of the models. Experimental results showed that the dual-model design method is better than the single model method in terms of time efficiency and better than the single model, TextCNN, TextLSTM, Transformer, and other models in terms of label credibility. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; FMS:C; 
LB  - Zhang2022Few-shot
ER  -

TY  - JOUR
AU  - Zhao, Q.
AU  - Ma, J.
AU  - Wang, Y.
AU  - Xie, F.
AU  - Lv, Z.
AU  - Xu, Y.
AU  - Shi, H.
AU  - Han, K.
TI  - Mul-SNO: A Novel Prediction Tool for S-Nitrosylation Sites Based on Deep Learning Methods
PY  - 2022
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 26
IS  - 5
SP  - 2379
EP  - 2387
DO  - 10.1109/JBHI.2021.3123503
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119441262&doi=10.1109%2fJBHI.2021.3123503&partnerID=40&md5=b73dfc054aeb56438649e30ceb2a3a53
AB  - Protein s-nitrosylation (SNO) is one of the most important post-translational modifications and is formed by the covalent modification of nitric oxide and cysteine residues. Extensive studies have shown that SNO plays a pivotal role in the plant immune response and treating various major human diseases. In recent years, SNO sites have become a hot research topic. Traditional biochemical methods for SNO site identification are time-consuming and costly. In this study, we developed an economical and efficient SNO site prediction tool named Mul-SNO. Mul-SNO ensembled current popular and powerful deep learning model bidirectional long short-term memory (BiLSTM) and bidirectional encoder representations from Transformers (BERT). Compared with existing state-of-the-art methods, Mul-SNO obtained better ACC of 0.911 and 0.796 based on 10-fold cross-validation and independent data sets, respectively.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhao2022Mul-SNO
ER  -

TY  - JOUR
AU  - Shen, L.
AU  - Wang, Y.
TI  - TCCT: Tightly-coupled convolutional transformer on time series forecasting
PY  - 2022
T2  - Neurocomputing
VL  - 480
SP  - 131
EP  - 145
DO  - 10.1016/j.neucom.2022.01.039
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123707840&doi=10.1016%2fj.neucom.2022.01.039&partnerID=40&md5=efcf2b5ba0665cf3c9c3e1b2f2dd9cbb
AB  - Time series forecasting is essential for a wide range of real-world applications. Recent studies have shown the superiority of Transformer in dealing with such problems, especially long sequence time series input (LSTI) and long sequence time series forecasting (LSTF) problems. To improve the efficiency and enhance the locality of Transformer, these studies combine Transformer with CNN in varying degrees. However, their combinations are loosely-coupled and do not make full use of CNN. To address this issue, we propose the concept of tightly-coupled convolutional Transformer (TCCT) and three TCCT architectures which apply transformed CNN architectures into Transformer: (1) CSPAttention: through fusing CSPNet with self-attention mechanism, the computation cost of self-attention mechanism is reduced by 30% and the memory usage is reduced by 50% while achieving equivalent or beyond prediction accuracy. (2) Dilated causal convolution: this method is to modify the distilling operation proposed by Informer through replacing canonical convolutional layers with dilated causal convolutional layers to gain exponentially receptive field growth. (3) Passthrough mechanism: the application of passthrough mechanism to stack of self-attention blocks helps Transformer-like models get more fine-grained information with negligible extra computation costs. Our experiments on real-world datasets show that our TCCT architectures could greatly improve the performance of existing state-of-the-art Transformer models on time series forecasting with much lower computation and memory costs, including canonical Transformer, LogTrans and Informer. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 79
C2  - CCF:C期刊; 
LB  - Shen2022TCCT
ER  -

TY  - JOUR
AU  - He, X.
AU  - Tan, E.-L.
AU  - Bi, H.
AU  - Zhang, X.
AU  - Zhao, S.
AU  - Lei, B.
TI  - Fully transformer network for skin lesion analysis
PY  - 2022
T2  - Medical Image Analysis
VL  - 77
C7  - 102357
DO  - 10.1016/j.media.2022.102357
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123843454&doi=10.1016%2fj.media.2022.102357&partnerID=40&md5=e0721984d9e006a145eec17d91bb5f12
AB  - Automatic skin lesion analysis in terms of skin lesion segmentation and disease classification is of great importance. However, these two tasks are challenging as skin lesion images of multi-ethnic population are collected using various scanners in multiple international medical institutes. To address them, most recent works adopt convolutional neural networks (CNNs) for skin lesion analysis. However, due to the intrinsic locality of the convolution operator, CNNs lack the ability to capture contextual information and long-range dependency. To improve the baseline performance established by CNNs, we propose a Fully Transformer Network (FTN) to learn long-range contextual information for skin lesion analysis. FTN is a hierarchical Transformer computing features using Spatial Pyramid Transformer (SPT). SPT has linear computational complexity as it introduces a spatial pyramid pooling (SPP) module into multi-head attention (MHA)to largely reduce the computation and memory usage. We conduct extensive skin lesion analysis experiments to verify the effectiveness and efficiency of FTN using ISIC 2018 dataset. Our experimental results show that FTN consistently outperforms other state-of-the-art CNNs in terms of computational efficiency and the number of tunable parameters due to our efficient SPT and hierarchical network structure. The code and models will be public available at: https://github.com/Novestars/Fully-Transformer-Network. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 77
C2  - CCF:C期刊; 
LB  - He2022Fully
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Yang, X.
AU  - Shi, L.
AU  - Wang, B.
AU  - Du, Z.
AU  - Zhang, F.
AU  - Liu, R.
TI  - A neural network framework for fine-grained tropical cyclone intensity prediction
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 241
C7  - 108195
DO  - 10.1016/j.knosys.2022.108195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123843353&doi=10.1016%2fj.knosys.2022.108195&partnerID=40&md5=60a30b2f0b531c52a7d870c9f7835952
AB  - Huge losses of life and economy are brought by Tropical Cyclones(TCs). Accurate TC intensity prediction is crucial for disaster prevention and emergency decision-making, but the chaotic nature of TC makes the intensity prediction a challenging task. Recently, TC intensity prediction has been regarded as a spatio-temporal prediction problem by a surging number of researchers, and deep learning methods have been used to model both spatial and temporal characteristics of which. However, existing studies on TC intensity prediction based on deep learning methods are still inadequate in spatio-temporal feature modeling and prediction granularity. In this study, a neural network framework specifically for TC intensity prediction named TC-Pred is proposed. To be Specific, a novel feature extraction and aggregation approach is designed considering the characteristics of multi-source environmental variables, and the sequence-to-sequence architecture is innovatively introduced to make fine-grained predictions. Moreover, a module inspired by the convolutional transformer is developed that aims to alleviate the long-term dependency decay problem and improve model performance. Extensive experiments are performed on the environmental variables dataset to verify the effectiveness and practicability of the proposed framework. The experimental results demonstrate that most of the models based on TC-Pred have achieved better performance, and the TC-Pred(ConvGRU) model obtains a significant improvement by 18.31%, 7.01%, 14.17%, and 11.95% improvements compared with baselines at 6h, 12h, 18h, and 24h intervals, respectively. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; FMS:C; 
LB  - Zhang2022neural
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Ma, J.
AU  - Xie, Y.
AU  - Yang, X.
AU  - Tao, X.
AU  - Peng, L.
AU  - Gao, W.
TI  - Contrastive predictive coding with transformer for video representation learning
PY  - 2022
T2  - Neurocomputing
VL  - 482
SP  - 154
EP  - 162
DO  - 10.1016/j.neucom.2021.11.031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120833511&doi=10.1016%2fj.neucom.2021.11.031&partnerID=40&md5=b876b85fdf6b3bfeb9d258a04ded1224
AB  - This paper presents a novel framework of self-supervised learning for video representation. Inspired by Contrastive Predictive Coding and Self-attention, we make the following contributions: First, we propose the Contrastive Predictive Coding with Transformer (CPCTR) framework for video representation learning in a self-supervised fashion. Second, we introduce the Transformer architecture to CPCTR to capture long-range spatio-temporal dependencies in order to facilitate the learning of “slow features” in video, and we conduct analysis of Transformer in our model to show its effectiveness. Finally, we evaluate our model by first training on the UCF101 dataset with self-supervised learning, and then fine-tuning on downstream video classification tasks. Using RGB only video data, we achieve state-of-the-art self-supervised performance on both UCF101 (Top1 accuracy of 99.3%) and HMDB51 (Top1 accuracy of 82.4%), we show that CPCTR even outperforms fully supervised methods on the two datasets. The code is available at https://github.com/yliu1229/CPCTR. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; 
LB  - Liu2022Contrastive
ER  -

TY  - JOUR
AU  - Su, J.
AU  - Jin, Z.
AU  - Ren, J.
AU  - Yang, J.
AU  - Liu, Y.
TI  - GDFormer: A Graph Diffusing Attention based approach for Traffic Flow Prediction
PY  - 2022
T2  - Pattern Recognition Letters
VL  - 156
SP  - 126
EP  - 132
DO  - 10.1016/j.patrec.2022.03.005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126512210&doi=10.1016%2fj.patrec.2022.03.005&partnerID=40&md5=475d1804c88dd625f4387ab4e79f4322
AB  - In this paper, we propose a novel traffic flow prediction approach, called as Graph Diffusing trans-Former (GDFormer). GDFormer is in architecture of transformer, which is composed by the encoder sequence and decoder sequence. both of the encoder sequence and decoder sequence in GDFormer are constituted by the novel designed Graph Diffusing Attention (GDA) module and the auxiliaries. The GDA module utilizes the query-key-value attention to learn the diffusion parameters for each diffusion step, and dynamically updates the adjacency transition, which reflects the dynamically changing traffic flow between the traffic monitors. To verify the efficiency of our approach, we conduct a lot of experiments on two real-world data sets. With a comparison between our approach and the benchmarks, we find that our approach has achieved state of the art performance. Ablation experiments are conducted to illustrate the effectiveness of the key components in the model. For ease of reproducibility, the code, the processed real-world data sets and the evaluation results are available at https://github.com/dublinsky/GDFormer. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Su2022GDFormer
ER  -

TY  - JOUR
AU  - Mei, X.
AU  - Cai, X.
AU  - Yang, L.
AU  - Wang, N.
TI  - Relation-aware Heterogeneous Graph Transformer based drug repurposing[Formula presented]
PY  - 2022
T2  - Expert Systems with Applications
VL  - 190
C7  - 116165
DO  - 10.1016/j.eswa.2021.116165
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119361240&doi=10.1016%2fj.eswa.2021.116165&partnerID=40&md5=c144344c87aac931041e16f8cfee6da2
AB  - Drug repurposing refers to discovery of new medical instructions for existing chemical drugs, which has great pharmaceutical significance. Recently, large-scale biological datasets are increasingly available, and many graph neural network (GNN) based methods for drug repurposing have been developed. These methods often deem drug repurposing as a link prediction problem, which mines features of biological data to identify drug–disease associations (i.e., drug–disease links). Due to heterogeneity of data, we need to deeply explore heterogeneous information of biological network for drug repurposing. In this paper, we propose a Relation-aware Heterogeneous Graph Transformer (RHGT) model to capture heterogeneous information for drug repurposing. We first construct a drug–gene–disease interactive network-based on biological data, and then propose a three-level network embedding model, which learns network embeddings at fine-grained subtype-level, node-level and coarse-grained edge-level, respectively. The output of subtype-level is the input of node-level and edge-level, and the output of node-level is the input of edge level. We get edge embeddings at edge-level, which integrates edge type embeddings and node embeddings. We deem that in this way, characteristics of drug–gene–disease interactive network can be captured more comprehensively. Finally, we identify drug–disease associations (i.e., drug–disease links) based on the relationship between drug–gene edge embeddings and gene–disease edge embeddings. Experimental results show that our model performs better than other state-of-the-art graph neural network methods, which validates effectiveness of the proposed model. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Mei2022Relation-aware
ER  -

TY  - JOUR
AU  - Sinclair, M.
AU  - Schuh, A.
AU  - Hahn, K.
AU  - Petersen, K.
AU  - Bai, Y.
AU  - Batten, J.
AU  - Schaap, M.
AU  - Glocker, B.
TI  - Atlas-ISTN: Joint segmentation, registration and atlas construction with image-and-spatial transformer networks
PY  - 2022
T2  - Medical Image Analysis
VL  - 78
C7  - 102383
DO  - 10.1016/j.media.2022.102383
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125246399&doi=10.1016%2fj.media.2022.102383&partnerID=40&md5=6b820f67019a339094c36e79863f9f10
AB  - Deep learning models for semantic segmentation are able to learn powerful representations for pixel-wise predictions, but are sensitive to noise at test time and may lead to implausible topologies. Image registration models on the other hand are able to warp known topologies to target images as a means of segmentation, but typically require large amounts of training data, and have not widely been benchmarked against pixel-wise segmentation models. We propose the Atlas Image-and-Spatial Transformer Network (Atlas-ISTN), a framework that jointly learns segmentation and registration on 2D and 3D image data, and constructs a population-derived atlas in the process. Atlas-ISTN learns to segment multiple structures of interest and to register the constructed atlas labelmap to an intermediate pixel-wise segmentation. Additionally, Atlas-ISTN allows for test time refinement of the model's parameters to optimize the alignment of the atlas labelmap to an intermediate pixel-wise segmentation. This process both mitigates for noise in the target image that can result in spurious pixel-wise predictions, as well as improves upon the one-pass prediction of the model. Benefits of the Atlas-ISTN framework are demonstrated qualitatively and quantitatively on 2D synthetic data and 3D cardiac computed tomography and brain magnetic resonance image data, out-performing both segmentation and registration baseline models. Atlas-ISTN also provides inter-subject correspondence of the structures of interest. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; 
LB  - Sinclair2022Atlas-ISTN
ER  -

TY  - JOUR
AU  - Lu, T.
AU  - Xiang, Y.
AU  - Zhang, L.
AU  - Zhang, J.
TI  - Sentence constituent-aware attention mechanism for end-to-end aspect-based sentiment analysis
PY  - 2022
T2  - Multimedia Tools and Applications
VL  - 81
IS  - 11
SP  - 15333
EP  - 15348
DO  - 10.1007/s11042-022-12487-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125399774&doi=10.1007%2fs11042-022-12487-x&partnerID=40&md5=7e62199e1dde1ae6e7dc65a5096f3572
AB  - End-to-end aspect-based sentiment analysis aims to complete aspect terms extraction and aspect sentiment classification simultaneously. Most existing methods ignore the sematic connection between the two subtasks. In this paper, we solve the problem by inducing constituents from input sentences, and propose a novel model based on sentence constituent-aware attention mechanism for end-to-end aspect-based sentiment analysis. Our framework mainly involves three layers. The first layer gets word representations by the pre-trained language model. Followed by the proposed sentence constituent-aware attention layer to induce constituents from the input sentence. With the operation of inducing constituents, the words in the same constituent are constrained to attend to each other, making the aspect term pay more attention to its corresponding opinion. Finally, a simple linear classification layer is adopted to predict the unified tags. Experimental results demonstrate that the proposed model outperforms other baselines on four benchmark datasets. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Lu2022Sentence
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Yang, Y.
TI  - Tweet Retweet Prediction Based on Deep Multitask Learning
PY  - 2022
T2  - Neural Processing Letters
VL  - 54
IS  - 1
SP  - 523
EP  - 536
DO  - 10.1007/s11063-021-10642-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115309320&doi=10.1007%2fs11063-021-10642-3&partnerID=40&md5=4b4cb3eb4f47d7841fd9fd7d7eb22ded
AB  - Today, as social networks play an increasingly important role, people are more likely to use them to discuss hot topics. Thus, reposting behavior plays a crucial role in such networks for information diffusion. However, the existing models do not consider the impact of some important numerical features on the spread of tweets. In addition, the potential correlation of the user information in different groups and their tweets will also affect the effect of retweet prediction. Considering the above problems, in this article, we propose a novel deep multitask learning-based method, CH-Transformer, for retweet prediction. First, we extract numerical features to represent tweet information features and social features. Then, the numerical features are concatenated with textual features. After feature extraction, we obtain the feature embeddings and feed them into our model to achieve propagation prediction. Finally, we evaluate the proposed method using well-known evaluation measures. The experimental results demonstrate the effectiveness of our method. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Wang2022Tweet
ER  -

TY  - JOUR
AU  - Liu, L.
AU  - Wang, M.
AU  - He, X.
AU  - Qing, L.
AU  - Chen, H.
TI  - Fact-based visual question answering via dual-process system
PY  - 2022
T2  - Knowledge-Based Systems
VL  - 237
C7  - 107650
DO  - 10.1016/j.knosys.2021.107650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121430804&doi=10.1016%2fj.knosys.2021.107650&partnerID=40&md5=12e749c160ef80fb6d2c3d81022875fd
AB  - Fact-based visual question answering (FVQA) requires the model to answer questions based on the observed images and external knowledge. The key is to enable the agent to understand questions and images and then reason on the knowledge base to find the correct answer. Founded on the dual-process theory in cognitive science, an effective framework for the FVQA is proposed in this study by coordinating a perception module (System 1) and an explicit reasoning module (System 2). When a question and an image are given, System 1 first learns the joint representation of them, and then System 2 predicts the answer via reasoning on a fact graph and a semantic graph. Specifically, System 1 is implemented by a two-parallel BERT-style model, while System 2 by a graph neural network (GNN) with a dual-level attention mechanism. Experiments on two public datasets, i.e., FVQA and OK-VQA datasets, show that our model outperforms other baselines. Moreover, the proposed model also provides the interpretation of the reasoning process in addition to a correct answer to the question. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; FMS:C; 
LB  - Liu2022Fact-based
ER  -

TY  - JOUR
AU  - Nie, L.
AU  - Chen, T.
AU  - Wang, Z.
AU  - Kang, W.
AU  - Lin, L.
TI  - Multi-label image recognition with attentive transformer-localizer module
PY  - 2022
T2  - Multimedia Tools and Applications
VL  - 81
IS  - 6
SP  - 7917
EP  - 7940
DO  - 10.1007/s11042-021-11818-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123894157&doi=10.1007%2fs11042-021-11818-8&partnerID=40&md5=eacf93571406c8712f241ba7649c39c3
AB  - Recently, remarkable progress on multi-label image classification has been achieved by locating semantic-agnostic image regions and extracting their features with deep convolutional neural networks. However, existing pipelines depend on the hypothesis region generation step, which typically brings about extra computational costs, e.g., generating hundreds of meaningless proposals and extracting their features. Moreover, the contextual dependencies among these localized regions are usually ignored or oversimplified during the learning and inference stages. To resolve these issues, we develop a novel attentive transformer-localizer (ATL) module that contains differential transformations (e.g., translation, scale), which can automatically discover the discriminative semantic-aware regions from input images in terms of multi-label recognition. This module can be flexibly incorporated with recurrent neural networks such as the long short-term memory (LSTM) network for memorizing and updating the contextual dependencies of the localized regions. We thus build a unified multi-label image recognition framework. Specifically, the ATL module is applied to progressively localize the attentive regions from the convolutional feature maps in a proposal-free manner, and the LSTM network sequentially predicts label scores for the localized regions and updates the parameters of the ATL module while capturing the global dependencies among these regions. To associate the localized regions with semantic labels over diverse locations and scales, we further design three constraints together with the ATL module. Extensive experiments and evaluations on two large-scale benchmarks (i.e., PASCAL VOC and Microsoft COCO) show that the proposed approach achieves superior performance over existing state-of-the-art methods in terms of both performance and efficiency. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Nie2022Multi-label
ER  -

TY  - JOUR
AU  - Geng, Z.
AU  - Chen, Z.
AU  - Meng, Q.
AU  - Han, Y.
TI  - Novel Transformer Based on Gated Convolutional Neural Network for Dynamic Soft Sensor Modeling of Industrial Processes
PY  - 2022
T2  - IEEE Transactions on Industrial Informatics
VL  - 18
IS  - 3
SP  - 1521
EP  - 1529
DO  - 10.1109/TII.2021.3086798
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111027501&doi=10.1109%2fTII.2021.3086798&partnerID=40&md5=264156944b7e260d163883127433b94d
AB  - Industrial process data are usually time-series data collected by sensors, which have the characteristics of high nonlinearity, dynamics, and noises. Many existing soft sensor modeling methods usually focus on dominant variables and auxiliary variables at a single time point while ignoring the timing characteristics of industrial process data. Meanwhile, the soft-sensing methods considering timing characteristics based on the deep learning are usually faced with gradient vanishing and the difficulty in parallel computing. Therefore, a novel Gated Convolutional neural network-based Transformer (GCT) is proposed for dynamic soft sensor modeling of industrial processes. The GCT encodes short-term patterns of the time series data and filters important features adaptively through an improved gated convolutional neural network (CNN). Then, the multihead attention mechanism is applied to modeling the correlation between any two moments. Finally, the prediction results are obtained through a linear neural network layer with the highway connection. In this article, the experiments in the dynamic soft sensor modeling of polypropylene and purified terephthalic acid industrial processes show that the proposed method achieves state-of-the-art comparing with the back propagation neural network, the extreme learning machine, the long short-term memory (LSTM) and the LSTM based on the CNN.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 112
C2  - CCF:C期刊; 
LB  - Geng2022Novel
ER  -

TY  - JOUR
AU  - Dong, Q.
AU  - Niu, S.
AU  - Yuan, T.
AU  - Li, Y.
TI  - Disentangled Graph Recurrent Network for Document Ranking
PY  - 2022
T2  - Data Science and Engineering
VL  - 7
IS  - 1
SP  - 30
EP  - 43
DO  - 10.1007/s41019-022-00179-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124742989&doi=10.1007%2fs41019-022-00179-3&partnerID=40&md5=e2c4b08de702f25f46bb461858f1da35
AB  - BERT-based ranking models are emerging for its superior natural language understanding ability. All word relations and representations in the concatenation of query and document are modeled in the self-attention matrix as latent knowledge. However, some latent knowledge has none or negative effect on the relevance prediction between query and document. We model the observable and unobservable confounding factors in a causal graph and perform do-query to predict the relevance label given an intervention over this graph. For the observed factors, we block the back door path by an adaptive masking method through the transformer layer and refine word representations over this disentangled word graph through the refinement layer. For the unobserved factors, we resolve the do-operation query from the front door path by decomposing word representations into query related and unrelated parts through the decomposition layer. Pairwise ranking loss is mainly used for the ad hoc document ranking task, triangle distance loss is introduced to both the transformer and refinement layers for more discriminative representations, and mutual information constraints are put on the decomposition layer. Experimental results on public benchmark datasets TREC Robust04 and WebTrack2009-12 show that DGRe outperforms state-of-the-art baselines more than 2% especially for short queries. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Dong2022Disentangled
ER  -

TY  - JOUR
AU  - Du, H.
AU  - Duan, Z.
TI  - Finder: A novel approach of change point detection for multivariate time series
PY  - 2022
T2  - Applied Intelligence
VL  - 52
IS  - 3
SP  - 2496
EP  - 2509
DO  - 10.1007/s10489-021-02532-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107780284&doi=10.1007%2fs10489-021-02532-x&partnerID=40&md5=7d2c573370d6bf492b8582988ac1c7f0
AB  - The multivariate time series often contain complex mixed inputs, with complex correlations between them. Detecting change points in multivariate time series is of great importance, which can find anomalies early and reduce losses, yet very challenging as it is affected by many complex factors, i.e., dynamic correlations and external factors. The performance of traditional methods typically scales poorly. In this paper, we propose Finder, a novel approach of change point detection via multivariate fusion attention networks. Our model consists of two key modules. First, in the time series prediction module, we employ multi-level attention networks based on the Transformer and integrate the external factor fusion component, achieving feature extraction and fusion of multivariate data. Secondly, in the change point detection module, a deep learning classifier is used to detect change points, improving efficiency and accuracy. Extensive experiments prove the superiority and effectiveness of Finder on two real-world datasets. Our approach outperforms the state-of-the-art methods by up to 10.50% on the F1 score. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Du2022Finder
ER  -

TY  - JOUR
AU  - Chang, Y.-C.
AU  - Ku, C.-H.
AU  - Nguyen, D.-D.L.
TI  - Predicting aspect-based sentiment using deep learning and information visualization: The impact of COVID-19 on the airline industry
PY  - 2022
T2  - Information and Management
VL  - 59
IS  - 2
C7  - 103587
DO  - 10.1016/j.im.2021.103587
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122150763&doi=10.1016%2fj.im.2021.103587&partnerID=40&md5=2e168c1b473d76696a8d3708c689f01b
AB  - This study investigates customer satisfaction through aspect-level sentiment analysis and visual analytics. We collected and examined the flight reviews on TripAdvisor from January 2016 to August 2020 to gauge the impact of COVID-19 on passenger travel sentiment in several aspects. Till now, information systems, management, and tourism research have paid little attention to the use of deep learning and word embedding techniques, such as bidirectional encoder representations from transformers, especially for aspect-level sentiment analysis. This paper aims to identify perceived aspect-based sentiments and predict unrated sentiments for various categories to address this research gap. Ultimately, this study complements existing sentiment analysis methods and extends the use of data-driven and visual analytics approaches to better understand customer satisfaction in the airline industry and within the context of the COVID-19. Our proposed method outperforms baseline comparisons and therefore contributes to the theoretical and managerial literature. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - CCF:C期刊; AJG:3; ZUFE:1A; zdy:3; 
LB  - Chang2022Predicting
ER  -

TY  - JOUR
AU  - Kejriwal, M.
AU  - Shen, K.
AU  - Ni, C.-C.
AU  - Torzec, N.
TI  - Transfer-based taxonomy induction over concept labels
PY  - 2022
T2  - Engineering Applications of Artificial Intelligence
VL  - 108
C7  - 104548
DO  - 10.1016/j.engappai.2021.104548
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120888917&doi=10.1016%2fj.engappai.2021.104548&partnerID=40&md5=0fc2ca97e756860236203b1752b1dfaa
AB  - Given a domain-specific set of concepts, taxonomy induction is the problem of inducing a taxonomy from the set of concepts. The problem, despite having practical importance, has not received as much research attention, in contrast with related problems such as link prediction, due to its difficulty and lack of domain-specific benchmarks. In this paper, we present a principled approach for taxonomy induction in the e-commerce domain over a set of concept-labels, given background resources such as a pre-trained language representation learning model and examples of other taxonomies, induced over other concept-sets, but no example links for the target concept-set. Our approach, developed as an academic-industrial collaboration, is significantly more competitive than seven different baselines, including the transformer-based RoBERTa model, on three real-world and widely used e-commerce concept-sets. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Kejriwal2022Transfer-based
ER  -

TY  - JOUR
AU  - Bhattacharya, A.
AU  - Baweja, T.
AU  - Karri, S.P.K.
TI  - Epileptic Seizure Prediction Using Deep Transformer Model
PY  - 2022
T2  - International Journal of Neural Systems
VL  - 32
IS  - 2
DO  - 10.1142/S0129065721500581
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118504450&doi=10.1142%2fS0129065721500581&partnerID=40&md5=106d8daa2be8aa00d2164ebfc66416e9
AB  - The electroencephalogram (EEG) is the most promising and efficient technique to study epilepsy and record all the electrical activity going in our brain. Automated screening of epilepsy through data-driven algorithms reduces the manual workload of doctors to diagnose epilepsy. New algorithms are biased either towards signal processing or deep learning, which holds subjective advantages and disadvantages. The proposed pipeline is an end-to-end automated seizure prediction framework with a Fourier transform feature extraction and deep learning-based transformer model, a blend of signal processing and deep learning - this imbibes the potential features to automatically identify the attentive regions in EEG signals for effective screening. The proposed pipeline has demonstrated superior performance on the benchmark dataset with average sensitivity and false-positive rate per hour (FPR/h) as 98.46%, 94.83% and 0.12439, 0, respectively. The proposed work shows great results on the benchmark datasets and a big potential for clinics as a support system with medical experts monitoring the patients.  © 2022 World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 57
C2  - CCF:C期刊; 
LB  - Bhattacharya2022Epileptic
ER  -

TY  - JOUR
AU  - Gao, C.
AU  - Yang, Y.
AU  - Li, W.
TI  - 3D interacting hand pose and shape estimation from a single RGB image
PY  - 2022
T2  - Neurocomputing
VL  - 474
SP  - 25
EP  - 36
DO  - 10.1016/j.neucom.2021.12.013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121444380&doi=10.1016%2fj.neucom.2021.12.013&partnerID=40&md5=af30ce8df52e299dd5c9efa7f5121d6f
AB  - Estimating 3D interacting hand poses and shapes from a single RGB image is challenging as it is difficult to distinguish the left and right-hands in interacting hand pose analysis. This paper proposes a network called GroupPoseNet using a grouping strategy to address this problem. GroupPoseNet extracts the left- and right-hand features respectively and thus avoids the mutual affection between the interacting hands. Empowered by a novel up-sampling block called MF-Block predicting 2D heat-maps in a progressive way by fusing image features, hand pose features, and multi-scale features, GroupPoseNet is effective and robust to severe occlusions. To achieve an effective 3D hand reconstruction, we design a transformer mechanism based inverse kinematics module(termed TikNet) to map 3D joint locations to hand shape and pose parameters of MANO hand model. Comprehensive experiments on the InterHand2.6M dataset show GroupPoseNet outperforms existing methods by a significant margin. Additional experiments also demonstrate it has a good generalization ability in the problems including left-hand, right-hand and interacting hand pose estimation from a single RGB image. We also show the efficiency of TikNet by the quantitative and qualitative results. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Gao20223D
ER  -

TY  - JOUR
AU  - Rouhou, A.C.
AU  - Dhiaf, M.
AU  - Kessentini, Y.
AU  - Salem, S.B.
TI  - Transformer-based approach for joint handwriting and named entity recognition in historical document
PY  - 2022
T2  - Pattern Recognition Letters
VL  - 155
SP  - 128
EP  - 134
DO  - 10.1016/j.patrec.2021.11.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119579469&doi=10.1016%2fj.patrec.2021.11.010&partnerID=40&md5=e2eb82ede2fa048283ba8bda2187e14d
AB  - The extraction of relevant information carried out by named entities in handwriting documents is still a challenging task. Unlike traditional information extraction approaches that usually face text transcription and named entity recognition as separate subsequent tasks, we propose in this paper an end-to-end transformer-based approach to jointly perform these two tasks. The proposed approach operates at the paragraph level, which brings two main benefits. First, it allows the model to avoid unrecoverable early errors due to line segmentation. Second, it allows the model to exploit larger bi-dimensional context information to identify the semantic categories, reaching a higher final prediction accuracy. We also explore different training scenarios to show their effect on the performance and we demonstrate that a two-stage learning strategy can make the model reach a higher final prediction accuracy. As far as we know, this work presents the first approach that adopts the transformer networks for named entity recognition in handwritten documents. We achieve the new state-of-the-art performance in the ICDAR 2017 Information Extraction competition using the Esposalles database, for the complete task, even though the proposed technique does not use any dictionaries, language modeling, or post-processing. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:C期刊; 
LB  - Rouhou2022Transformer-based
ER  -

TY  - JOUR
AU  - Sun, W.
AU  - Zhang, Y.
AU  - Liao, Y.
AU  - Yang, B.
AU  - Lin, M.
AU  - Zhai, R.
AU  - Gao, Z.
TI  - Rethinking Monocular Height Estimation From a Classification Task Perspective Leveraging the Vision Transformer
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
C7  - 6518705
DO  - 10.1109/LGRS.2022.3222457
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142774973&doi=10.1109%2fLGRS.2022.3222457&partnerID=40&md5=9092c1b85e46d7e2d4f4962c3aed2b30
AB  - Height estimation from a single remote sensing image has great potential in generating digital surface models (DSMs) efficiently for a quick Earth surface reconstruction. Recently, convolutional neural networks (CNNs) have emerged as a powerful method to deal with this ill-posed problem. Most existing methods formulate height estimation as a regression problem due to the continuity of object height. However, it is difficult for the model to regress the object heights exactly to the ground-truth values with a wide range. In this letter, we reformulate the height estimation task as a classification task to improve the model performance. Specifically, we discretize the continuous ground-truth height into bins and assign each pixel to a single label according to the bin subdivision. In addition, we propose to generate a unique bin subdivision for each input image adaptively by viewing bin generation as a set-to-set problem. Compared with the fixed bin subdivision method, a specific bin subdivision for each input image makes the model adaptively focus on the height range that is more probable to occur in the scene of the input image. In our experiments, we qualitatively and quantitatively demonstrate that the proposed method outperforms the state-of-the-art approaches on both the Vaihingen and Potsdam datasets.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Sun2022Rethinking
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Zhang, K.
AU  - Niu, Z.
AU  - Shi, H.
TI  - C2MT: A Credible and Class-Aware Multi-Task Transformer for SR-IQA
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 2662
EP  - 2666
DO  - 10.1109/LSP.2022.3232289
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146232659&doi=10.1109%2fLSP.2022.3232289&partnerID=40&md5=a5577d3952a0ead0358fda6bd1772254
AB  - In this letter a novel credible and class-aware multi-task transformer abbreviated as C2MT for SRIQA, is proposed. In the proposed C2MT, a quality-aware task for the quality prediction and the other class-aware task for the classification of SR algorithms are jointly framed to mine mutual information between the quality of SR images and the class of SR algorithms for more discriminative perceptual representation. In the class-aware task, we develop a supervised contrastive learning strategy to learn embedding perceived features related to a class-specific SR algorithm. While in the other quality-aware task, we employ a novel credible pseudo quality label generation strategy to actively adjust the quality labels by ranking the pair-wise consistency between the predicted quality scores and subjective perceptual scores but keep the image-level quality labels unchanged. The developed supervised contrastive learning and the variant of active learning strategies benefit learning a more consistent quality predictor for SR images. Experiment results indicate that our proposed C2MT achieves state-of-the-art results on five popular SRIQA benchmark databases.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Li2022C2MT
ER  -

TY  - JOUR
AU  - Fuller, A.
AU  - Millard, K.
AU  - Green, J.R.
TI  - SatViT: Pretraining Transformers for Earth Observation
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
C7  - 3513205
DO  - 10.1109/LGRS.2022.3201489
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137554397&doi=10.1109%2fLGRS.2022.3201489&partnerID=40&md5=a635d4bbc5042e2c17ac03bb6858a398
AB  - Despite the enormous success of the 'pretraining and fine-tuning' paradigm, widespread across machine learning, it has yet to pervade remote sensing (RS). To help rectify this, we pretrain a vision transformer (ViT) on 1.3 million satellite-derived RS images. We pretrain SatViT using a state-of-the-art (SOTA) self-supervised learning (SSL) algorithm called masked autoencoding (MAE), which learns general representations by reconstructing held-out image patches. Crucially, this approach does not require annotated data, allowing us to pretrain on unlabeled images acquired from Sentinel-1 and 2. After fine-tuning, SatViT outperforms SOTA ImageNet and RS-specific pretrained models on both of our downstream tasks. We further improve the overall accuracy (OA) (by 3.2% and 0.21%) by continuing to pretrain SatViT-still using MAE-on the unlabelled target datasets. Most importantly, we release our code, pretrained model weights, and tutorials aimed at helping researchers fine-tune our models (https://github.com/antofuller/SatViT). © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Fuller2022SatViT
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Shen, J.
AU  - Liu, N.
AU  - Xia, S.
AU  - Sun, H.
TI  - An Anchor-Free Vehicle Detection Algorithm in Aerial Image Based on Context Information and Transformer
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
C7  - 6515605
DO  - 10.1109/LGRS.2022.3202186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137563626&doi=10.1109%2fLGRS.2022.3202186&partnerID=40&md5=28ba0bfd443d3f7a48a057041a324154
AB  - Vehicle detection in the aerial image is an essential and challenging task widely used in industry and agriculture. Deep learning technology has recently achieved rapid development and good object detection results. However, the background of aerial images is complex; targets are densely distributed, and some of them are occluded. For densely distributed targets, we need to predict at each feature point. In the case of complex background and target occlusion, it is often difficult to determine whether a location contains a target if the model only focuses on the local information. Therefore, we need a global perspective and contextual information to help train the model. This letter proposes a new anchor-free small object detection algorithm, which improves feature extraction by fusing contextual semantic information. In addition, a dynamic activation function (DAF) is also used in our network, which helps us calculate the activation function value for each point from a global perspective. Moreover, we also use the channel attention module and the transformer as the spatial attention module to help the network efficiently obtain global information. We evaluate the effectiveness of our method on the public dataset DLR-3K and vehicle detection in aerial imagery dataset (VEDAI), and the average precision (AP) achieves 0.896 and 0.875. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Zhou2022Anchor-Free
ER  -

TY  - JOUR
AU  - Ji, B.
AU  - Wang, H.
AU  - Zhang, M.
AU  - Mao, B.
AU  - Li, X.
TI  - An Efficient Lightweight Network Based on Magnetic Resonance Images for Predicting Alzheimer’s Disease
PY  - 2022
T2  - International Journal on Semantic Web and Information Systems
VL  - 18
IS  - 1
DO  - 10.4018/IJSWIS.313715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149925288&doi=10.4018%2fIJSWIS.313715&partnerID=40&md5=dbc080e5d6d79fcbac5ae0899216fd98
AB  - Brain magnetic resonance images (MRI) are widely used for the classification of Alzheimer’s disease (AD). The size of 3D images is, however, too large. Some of the sliced image features are lost, which results in conflicting network size and classification performance. This article uses key components in the transformer model to propose a new lightweight method, ensuring the lightness of the network and achieving highly accurate classification. First, the transformer model is imitated by using image patch input to enhance feature perception. Second, the Gaussian error linear unit (GELU), commonly used in transformer models, is used to enhance the generalization ability of the network. Finally, the network uses MRI slices as learning data. The depthwise separable convolution makes the network more lightweight. Experiments are carried out on the ADNI public database. The accuracy rate of AD vs. normal control (NC) experiments reaches 98.54%. The amount of network parameters is 1.3% of existing similar networks. © 2022 IGI Global. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Ji2022Efficient
ER  -

TY  - JOUR
AU  - Xia, C.
AU  - Duan, S.
AU  - Ge, B.
AU  - Zhang, H.
AU  - Li, K.-C.
TI  - HDNet: Multi-Modality Hierarchy-Aware Decision Network for RGB-D Salient Object Detection
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 2577
EP  - 2581
DO  - 10.1109/LSP.2022.3229640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146218334&doi=10.1109%2fLSP.2022.3229640&partnerID=40&md5=3131af2b40f2d7a5aaf19d0172893569
AB  - RGB-D Salient object detection (SOD) is a pixel-level dense prediction task, which can highlight the prominent object in the scene. Recently, Convolution Neural Network (CNN) is widely applied in SOD to generate multi-level features, which are complementary to each other. However, most methods ignore the unique characteristics of multi-level features (high-level and low-level features). Given the effective employment of multi-level features, we propose a novel multi-modality hierarchy-aware decision network (HDNet) by embedding a Swin Transformer as an encoder. The proposed HDNet contains three primary designs: (1) a Swin Transformer encoder is employed instead of a CNN to learn long-range dependencies; (2) a hierarchy-aware feature decision mechanism (HFDM) is proposed to exploit effective local detail cues of low-level features and global semantic information of high-level features, which consists of two sub-modules, namely low-hierarchy edge module (LEM) and high-hierarchy region module (HRM); (3) a decision-based fusion module (DFM) is designed to fuse RGB and depth features under the attribute of multi-level features generated from HFDM. Experiments on five public benchmarks verify that our framework has better performance than the other 18 state-of-the-art algorithms.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Xia2022HDNet
ER  -

TY  - JOUR
AU  - Ding, J.
AU  - Li, X.
AU  - Zhao, L.
TI  - CDFormer: A Hyperspectral Image Change Detection Method Based on Transformer Encoders
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
C7  - 6015405
DO  - 10.1109/LGRS.2022.3216878
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141505264&doi=10.1109%2fLGRS.2022.3216878&partnerID=40&md5=8b6300f66c6e96b6635bbf37f7adfa50
AB  - Hyperspectral image (HSI) change detection (CD) has gained much attention in remote sensing. However, most deep-learning methods are restricted by a limited receptive field, without leveraging temporal information, and the need for many training samples. In this letter, we proposed a transformer encoder-based HSI CD framework called CDFormer. First, space and time encodings are added to the pixel sequence to guide transformers to exploit change information of space and time by the pixel embedding (PE) module. Second, the self-attention component of the transformer encoder module has a global space-time receptive field to mine the correlation and interaction between bi-temporal features, enhancing the utilization of temporal dependencies. Next, the multihead attention mechanism learns several attentions and extracts the joint weighted spatial-spectral-temporal features, which improves the feature discrimination ability of the changes. Finally, the detection result is predicted using a fully connected network. It is notable to mention that the proposed method only uses a few labeled samples to train the network. Experiments on two HSI datasets demonstrate that our proposed method can get effective performance in HSI CD.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Ding2022CDFormer
ER  -

TY  - JOUR
AU  - Xiao, F.
AU  - Guan, J.
AU  - Lan, H.
AU  - Zhu, Q.
AU  - Wang, W.
TI  - Local Information Assisted Attention-Free Decoder for Audio Captioning
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 1604
EP  - 1608
DO  - 10.1109/LSP.2022.3189536
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134256063&doi=10.1109%2fLSP.2022.3189536&partnerID=40&md5=0351be74a7002eabc3cb31b8207e3123
AB  - Automated audio captioning aims to describe audio data with captions using natural language. Existing methods often employ an encoder-decoder structure, where the attention-based decoder (e.g., Transformer decoder) is widely used and achieves state-of-the-art performance. Although this method effectively captures global information within audio data via the self-attention mechanism, it may ignore the event with short time duration, due to its limitation in capturing local information in an audio signal, leading to inaccurate prediction of captions. To address this issue, we propose a method using the pretrained audio neural networks (PANNs) as the encoder and local information assisted attention-free Transformer (LocalAFT) as the decoder. The novelty of our method is in the proposal of the LocalAFT decoder, which allows local information within an audio signal to be captured while retaining the global information. This enables the events of different duration, including short duration, to be captured for more precise caption generation. Experiments show that our method outperforms the state-of-the-art methods in Task 6 of the DCASE 2021 Challenge with the standard attention-based decoder for caption generation. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Xiao2022Local
ER  -

TY  - JOUR
AU  - Jiang, M.
AU  - Zhou, C.
AU  - Kong, J.
TI  - AOH: Online Multiple Object Tracking With Adaptive Occlusion Handling
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 1644
EP  - 1648
DO  - 10.1109/LSP.2022.3191549
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135238024&doi=10.1109%2fLSP.2022.3191549&partnerID=40&md5=d84b074a0194380a05c5f39cbaea145d
AB  - Multiple object tracking has improved drastically in recent years due to one-shot tracking methods. These methods design joint-detection-and-tracking structures to achieve real-time tracking performance and introduce more powerful detectors to deal with missed objects. However, most of them perform poorly in crowded scenes because of frequent occlusions. Several previous works have attempted to alleviate the occlusion issue, but they hardly involve the essence of the problem. In this letter, we suppose that occlusion is closely related to crowd density, so the degree of occlusion can be estimated. Therefore, we propose a Potential Object Mining strategy to adaptively obtain occluded objects for reducing broken trajectories, which re-weights detections based on the predicted density map. Additionally, for the strategy, Dense Estimator is designed to predict the density of each region in an image by employing a Transformer-based structure. Combining them together forms our Adaptive Occlusion Handling (AOH) tracking framework. Extensive experiments on MOTChallenge benchmarks (MOT17 and MOT20) demonstrate that our AOH achieves the state-of-the-art performance, especially on the heavily occluded MOT20.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Jiang2022AOH
ER  -

TY  - JOUR
AU  - Xing, M.
AU  - Ding, W.
AU  - Li, H.
AU  - Zhang, T.
TI  - A Power Transformer Fault Prediction Method through Temporal Convolutional Network on Dissolved Gas Chromatography Data
PY  - 2022
T2  - Security and Communication Networks
VL  - 2022
C7  - 5357412
DO  - 10.1155/2022/5357412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129282609&doi=10.1155%2f2022%2f5357412&partnerID=40&md5=e22be825121b4161722e96f0530fc8ec
AB  - The power transformer is an example of the key equipment of power grid, and its potential faults limit the system availability and the enterprise security. However, fault prediction for power transformers has its limitations in low data quality, binary classification effect, and small sample learning. We propose a method for fault prediction for power transformers based on dissolved gas chromatography data: after data preprocessing of defective raw data, fault classification is performed based on the predictive regression results. Here, Mish-SN Temporal Convolutional Network (MSTCN) is introduced to improve the accuracy during the regression step. Several experiments are conducted using data set from China State Grid. The discussion of the results of experiments is provided.  © 2022 Mengda Xing et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Xing2022Power
ER  -

TY  - JOUR
AU  - Sha, Z.
AU  - Li, J.
TI  - MITformer: A Multiinstance Vision Transformer for Remote Sensing Scene Classification
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
DO  - 10.1109/LGRS.2022.3176499
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130499012&doi=10.1109%2fLGRS.2022.3176499&partnerID=40&md5=2181f3ac1b27239a9759772fcf181238
AB  - The latest vision transformer (ViT) has stronger contextual feature representation capability than the existing convolutional neural networks and thus has the potential to depict the remote sensing scenes, which usually have more complicated object distribution and spatial arrangement than ground image scenes. However, recent researches reflect that while ViT learns global features, it also ignores the key local features, which poses a bottleneck for understanding remote sensing scenes. In this letter, we tackle this challenge by proposing a novel multiinstance vision transformer (MITformer). Its originality mainly lies in the classic multiple instance learning (MIL) formulation, where each image patch embedded in ViT is regarded as an instance and each image is regarded as a bag. The benefit of designing ViT under MIL formulation is straightforward, as it helps highlight the feature response of key local regions of remote sensing scenes. Moreover, to enhance the feature propagation of local features, attention-based multilayer perceptron (AMLP) head is embedded at the end of each encoder unit. Finally, to minimize the potential semantic prediction differences between the classic ViT and our MIL head, a semantic consistency loss is designed. Experiments on three remote sensing scene classification benchmarks show that our proposed MITformer outperforms the existing state-of-The-Art methods and validate the effectiveness of each component in our MITformer.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:C期刊; 
LB  - Sha2022MITformer
ER  -

TY  - JOUR
AU  - Yu, Y.
AU  - Li, Y.
AU  - Wang, J.
AU  - Guan, H.
AU  - Li, F.
AU  - Xiao, S.
AU  - Tang, E.
AU  - Ding, X.
TI  - C2-CapsViT: Cross-Context and Cross-Scale Capsule Vision Transformers for Remote Sensing Image Scene Classification
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
C7  - 6512005
DO  - 10.1109/LGRS.2022.3185454
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133797498&doi=10.1109%2fLGRS.2022.3185454&partnerID=40&md5=5b82e4ee43a80574d89a98cdbc78c064
AB  - Accurately interpreting image contents plays a vital role in many Earth observation tasks. This letter constructs a novel cross-context and cross-scale capsule vision transformer (C2-CapsViT) architecture to serve for remote sensing image scene classification. First, employed with a multicontext patch embedding strategy, the token representation quality is greatly boosted to encode different-context feature semantics. Second, designed with a multiscale transformer block, different-grained long-range global feature interactions and different-type feature self-attentions are concurrently exploited to promote the feature encoding quality. Moreover, by combining the convolution and transformer structures, local and global feature semantics are effectively fused to direct accurate predictions. The C2-CapsViT is elaborately verified on three scene classification datasets. Both quantitative evaluations and comparative analyses prove its competitive capability and advanced performance.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Yu2022C2-CapsViT
ER  -

TY  - JOUR
AU  - Kong, J.
AU  - Bian, Y.
AU  - Jiang, M.
TI  - MTT: Multi-Scale Temporal Transformer for Skeleton-Based Action Recognition
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 528
EP  - 532
DO  - 10.1109/LSP.2022.3142675
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123371407&doi=10.1109%2fLSP.2022.3142675&partnerID=40&md5=a5bf2e6e6d1860547cf5dc6361d67229
AB  - In the task of skeleton-based action recognition, long-term temporal dependencies are significant cues for sequential skeleton data. State-of-the-art methods rarely have access to long-term temporal information, due to the limitations of their receptive fields. Meanwhile, most of the recent multiple branches methods only consider different input modalities but ignore the information in various temporal scales. To address the above issues, we propose a multi-scale temporal transformer (MTT) in this letter, for skeleton-based action recognition. Firstly, the raw skeleton data are embedded by graph convolutional network (GCN) blocks and multi-scale temporal embedding modules (MT-EMs), which are designed as multiple branches to extract features in various temporal scales. Secondly, we introduce transformer encoders (TE) to integrate embeddings and model the long-term temporal pattern. Moreover, we propose a task-oriented lateral connection (LaC) aiming to align semantical hierarchies. LaC distributes input embeddings to the downstream transformer encoders (TE), according to semantical levels. The classification headers aggregate results from TE and predict the action categories at last. The proposed method is shown efficiency and universality during experiments and achieves the state-of-the-art on three large datasets, NTU-RGBD 60, NTU-RGBD 120 and Kinetics-Skeleton 400.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - CCF:C期刊; 
LB  - Kong2022MTT
ER  -

TY  - JOUR
AU  - Sarachai, W.
AU  - Bootkrajang, J.
AU  - Chaijaruwanich, J.
AU  - Somhom, S.
TI  - Orchid classification using homogeneous ensemble of small deep convolutional neural network
PY  - 2022
T2  - Machine Vision and Applications
VL  - 33
IS  - 1
C7  - 17
DO  - 10.1007/s00138-021-01267-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123370552&doi=10.1007%2fs00138-021-01267-6&partnerID=40&md5=5f9347a0e535acf610e8abac3e7bf1e1
AB  - Orchids are flowering plants in the large and diverse family Orchidaceae. Orchid flowers may share similar visual characteristics even they are from different species. Thus, classifying orchid species from images is a hugely challenging task. Motivated by the inadequacy of the current state-of-the-art general-purpose image classification methods in differentiating subtle differences between orchid flower images, we propose a hybrid model architecture to better classify the orchid species from images. The model architecture is composed of three parts: the global prediction network (GPN), the local prediction network (LPN), and the ensemble neural network (ENN). The GPN predicts the orchid species by global features of orchid flowers. The LPN looks into local features such as the organs of orchid plant via a spatial transformer network. Finally, the ENN fuses the intermediate predictions from the GPN and the LPN modules and produces the final prediction. All modules are implemented based on a robust convolutional neural network with transfer learning methodology from notable existing models. Due to the interplay between the modules, we also guidelined the training steps necessary for achieving higher predictive performance. The classification results based on an extensive in-house Orchids-52 dataset demonstrated the superiority of the proposed method compared to the state of the art. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Sarachai2022Orchid
ER  -

TY  - JOUR
AU  - Chen, P.
AU  - Li, L.
AU  - Wu, Q.
AU  - Wu, J.
TI  - SPIQ: A Self-Supervised Pre-Trained Model for Image Quality Assessment
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 513
EP  - 517
DO  - 10.1109/LSP.2022.3145326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124071789&doi=10.1109%2fLSP.2022.3145326&partnerID=40&md5=886e339de53d733db334fdc6a4a61e53
AB  - Blind image quality assessment (BIQA) has witnessed a flourishing progress due to the rapid advances in deep learning technique. The vast majority of prior BIQA methods try to leverage models pre-trained on ImageNet to mitigate the data shortage problem. These well-trained models, however, can be sub-optimal when applied to BIQA task that varies considerably from the image classification domain. To address this issue, we make the first attempt to leverage the plentiful unlabeled data to conduct self-supervised pre-training for BIQA task. Based on the distorted images generated from the high-quality samples using the designed distortion augmentation strategy, the proposed pre-training is implemented by a feature representation prediction task. Specifically, patch-wise feature representations corresponding to a certain grid are integrated to make prediction for the representation of the patch below it. The prediction quality is then evaluated using a contrastive loss to capture quality-aware information for BIQA task. Experimental results conducted on KADID-10 k and KonIQ-10 k databases demonstrate that the learned pre-trained model can significantly benefit the existing learning based IQA models. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:C期刊; 
LB  - Chen2022SPIQ
ER  -

TY  - JOUR
AU  - Zhao, P.
AU  - Xie, L.
AU  - Zhang, Y.
AU  - Tian, Q.
TI  - Actionness-Guided Transformer for Anchor-Free Temporal Action Localization
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 194
EP  - 198
DO  - 10.1109/LSP.2021.3132287
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120895319&doi=10.1109%2fLSP.2021.3132287&partnerID=40&md5=ed575e17fa6e93549b3705bc984ed81d
AB  - Temporal action localization, detecting actions in untrimmed videos, is widely studied by anchor-based approaches that first generate excessive action proposals, <italic>i.e.</italic>, temporal windows, then evaluate and classify these proposals. To reduce the number of action proposals, recent studies use an anchor-free approach that leverages each time point rather than a temporal window to represent an action instance. However, this point representation, usually modeled by temporal convolutions, may have the fixed and limited receptive field to detect an entire action. So we propose an Actionness-guided Transformer (Ag-Trans) model to learn representations for each point proposal. Ag-Trans first predicts the actionness, <italic>i.e.</italic>, time sequences of the action starting, continuing, and ending phases, then the corresponding action phase can be embedded to model the point representation. Experimental results show that the Ag-Trans model outperforms the CNN-based model under the same experiment settings, especially for long-duration actions. 1070-9908 © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhao2022Actionness-Guided
ER  -

TY  - JOUR
AU  - Vo, T.
TI  - An integrated fuzzy neural network with topic-aware auto-encoding for sentiment analysis
PY  - 2022
T2  - Soft Computing
VL  - 26
IS  - 2
SP  - 677
EP  - 693
DO  - 10.1007/s00500-021-06520-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122401242&doi=10.1007%2fs00500-021-06520-8&partnerID=40&md5=4080f1f75f18c1db9c533702ffa6669e
AB  - Recent advanced deep learning architectures, such as neural seq2seq and transformer, have demonstrated remarkable improvements in multi-typed sentiment classification tasks. Even though recent transformer-based and seq2seq-based models have successfully enabled to capture rich contextual information of texts, they still lacked attention on incorporating global semantic information which enables to sufficiently leverage the performance of downstream SA tasks. Moreover, emotional expressions of users are normally in the form of natural human-written textual data which contains a lot of noises and ambiguities that impose great challenges on the processes of textual representation learning as well as sentiment polarity prediction. To meet these challenges, we propose a novel integrated fuzzy neural architecture with a topic-driven textual representation learning approach for handling the SA task, called as: TopFuzz4SA. Specifically, in the proposed TopFuzz4SA model, we first apply a topic-driven neural encoder–decoder architecture with the incorporation of latent topic embedding and attention mechanism to sufficiently learn both rich contextual and global semantic information of the given textual data. Then, the achieved rich semantic representations of texts are fed into a fused deep fuzzy neural network to effectively reduce the feature ambiguity and noise, forming the final textual representations for sentiment classification task. Extensive experiments in benchmark datasets demonstrate the effectiveness of our proposed TopFuzz4SA model compared with contemporary state-of-the-art baselines. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; 
LB  - Vo2022integrated
ER  -

TY  - JOUR
AU  - Deng, P.
AU  - Xu, K.
AU  - Huang, H.
TI  - When CNNs Meet Vision Transformer: A Joint Framework for Remote Sensing Scene Classification
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
DO  - 10.1109/LGRS.2021.3109061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114741363&doi=10.1109%2fLGRS.2021.3109061&partnerID=40&md5=6ccbd45373588943f4c86bc1e1622554
AB  - Scene classification is an indispensable part of remote sensing image interpretation, and various convolutional neural network (CNN)-based methods have been explored to improve classification accuracy. Although they have shown good classification performance on high-resolution remote sensing (HRRS) images, discriminative ability of extracted features is still limited. In this letter, a high-performance joint framework combined CNNs and vision transformer (ViT) (CTNet) is proposed to further boost the discriminative ability of features for HRRS scene classification. The CTNet method contains two modules, including the stream of ViT (T-stream) and the stream of CNNs (C-stream). For the T-stream, flattened image patches are sent into pretrained ViT model to mine semantic features in HRRS images. To complement with T-stream, pretrained CNN is transferred to extract local structural features in the C-stream. Then, semantic features and structural features are concatenated to predict labels of unknown samples. Finally, a joint loss function is developed to optimize the joint model and increase the intraclass aggregation. The highest accuracies on the aerial image dataset (AID) and Northwestern Polytechnical University (NWPU)-RESISC45 datasets obtained by the CTNet method are 97.70% and 95.49%, respectively. The classification results reveal that the proposed method achieves high classification performance compared with other state-of-the-art (SOTA) methods.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 109
C2  - CCF:C期刊; 
LB  - Deng2022When
ER  -

TY  - JOUR
AU  - Bi, C.
AU  - Ren, P.
AU  - Yin, T.
AU  - Zhang, Y.
AU  - Li, B.
AU  - Xiang, Z.
TI  - An Informer Architecture-Based Ionospheric foF2 Model in the Middle Latitude Region
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
C7  - 1005305
DO  - 10.1109/LGRS.2022.3160422
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126668721&doi=10.1109%2fLGRS.2022.3160422&partnerID=40&md5=5d8188ffc329a863f81e5adab3f6c007
AB  - Monitoring of critical frequency variation in the ionospheric F2 layer (foF2) has lately received considerable attention for the frequency selection in skywave communication. Currently, both the deep learning and machine learning model have made a striking accomplishment in comprehending the ionosphere. In this letter, we utilize an Informer architecture to predict the foF2 parameter under the two scenarios in terms of the quiet space weather and storm events. The Informer method applied the past and present foF2 samples to capture time sequence processing characteristics, trained and tested for 2017-2018 years' measurement samples at Beijing, China (40.3°N, 116.2°E). It is evident from the results that the Informer performed better than International Reference Ionosphere 2016, Elman network, long short-term memory (LSTM), and bidirectional LSTM models. The Informer models extensively captured the correlation within the foF2 sequence features and better predicted it in storm events. © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Bi2022Informer
ER  -

TY  - JOUR
AU  - Zhao, S.
AU  - Li, H.
AU  - Ke, Q.
AU  - Liu, L.
AU  - Zhang, R.
TI  - Action-ViT: Pedestrian Intent Prediction in Traffic Scenes
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 324
EP  - 328
DO  - 10.1109/LSP.2021.3134194
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124793883&doi=10.1109%2fLSP.2021.3134194&partnerID=40&md5=7a5f7df3c824d1b1be95f69067059ee6
AB  - Pedestrian crossing intention prediction is crucial to traffic safety, which is a challenging task in real traffic scenarios. Traditional methods infer the intention of pedestrians to cross by predicting their future movements based on the observed trajectories in history. The performance of those methods is limited due to insufficient features and sources of information. To address those limitations, we propose a ViT-based model which incorporates multi-modal data to predict the pedestrian crossing intention. Specifically, the proposed model takes into consideration the visual information, poses, bounding box coordinates and action annotations, and gradually fuses those features for the final prediction. Besides, different data processing methods are designed based on the corresponding characteristics of different modalities to make full use of each type of data. Extensive ablation studies are conducted to show the performance of temporal modelling and feature fusion. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; 
LB  - Zhao2022Action-ViT
ER  -

TY  - JOUR
AU  - Tian, Z.
AU  - Yi, J.
AU  - Tao, J.
AU  - Zhang, S.
AU  - Wen, Z.
TI  - Hybrid Autoregressive and Non-Autoregressive Transformer Models for Speech Recognition
PY  - 2022
T2  - IEEE Signal Processing Letters
VL  - 29
SP  - 762
EP  - 766
DO  - 10.1109/LSP.2022.3152128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124822936&doi=10.1109%2fLSP.2022.3152128&partnerID=40&md5=6f675a0cdfab8489713dcff3bed1d7b1
AB  - The autoregressive (AR) models, such as attention-based encoder-decoder models and RNN-Transducer, have achieved great success in speech recognition. They predict the output sequence conditioned on the previous tokens and acoustic encoded states, which is inefficient on GPUs. The non-autoregressive (NAR) models can get rid of the temporal dependency between the output tokens and predict the entire output tokens in one inference step. However, the NAR model still faces two major problems. Firstly, there is still a great gap in performance between the NAR models and the advanced AR models. Secondly, it's difficult for most of the NAR models to train and converge. We propose a hybrid autoregressive and non-autoregressive transformer (HANAT) model, which integrates AR and NAR models deeply by sharing parameters. We assume that the AR model will assist the NAR model to learn some linguistic dependencies and accelerate the convergence. Furthermore, the two-stage hybrid inference is applied to improve the model performance. All the experiments are conducted on a mandarin dataset ASIEHLL-1 and a english dataset librispeech-960 h. The results show that the HANAT can achieve a competitive performance with the AR model and outperform many complicated NAR models. Besides, the RTF is only 1/5 of the AR model.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Tian2022Hybrid
ER  -

TY  - JOUR
AU  - Tao, R.
AU  - Liu, W.
AU  - Zheng, G.
TI  - Spine-transformers: Vertebra labeling and segmentation in arbitrary field-of-view spine CTs via 3D transformers
PY  - 2022
T2  - Medical Image Analysis
VL  - 75
C7  - 102258
DO  - 10.1016/j.media.2021.102258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117221522&doi=10.1016%2fj.media.2021.102258&partnerID=40&md5=e392cae786957a981914bf59a481fda8
AB  - In this paper, we address the problem of fully automatic labeling and segmentation of 3D vertebrae in arbitrary Field-Of-View (FOV) CT images. We propose a deep learning-based two-stage solution to tackle these two problems. More specifically, in the first stage, the challenging vertebra labeling problem is solved via a novel transformers-based 3D object detector that views automatic detection of vertebrae in arbitrary FOV CT scans as a one-to-one set prediction problem. The main components of the new method, called Spine-Transformers, are a one-to-one set based global loss that forces unique predictions and a light-weighted 3D transformer architecture equipped with a skip connection and learnable positional embeddings for encoder and decoder, respectively. We additionally propose an inscribed sphere-based object detector to replace the regular box-based object detector for a better handling of volume orientation variations. Our method reasons about the relationships of different levels of vertebrae and the global volume context to directly infer all vertebrae in parallel. In the second stage, the segmentation of the identified vertebrae and the refinement of the detected centers are then done by training one single multi-task encoder-decoder network for all vertebrae as the network does not need to identify which vertebra it is working on. The two tasks share a common encoder path but with different decoder paths. Comprehensive experiments are conducted on two public datasets and one in-house dataset. The experimental results demonstrate the efficacy of the present approach. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 45
C2  - CCF:C期刊; 
LB  - Tao2022Spine-transformers
ER  -

TY  - JOUR
AU  - Ye, F.
AU  - Hu, J.
AU  - Huang, T.-Q.
AU  - You, L.-J.
AU  - Weng, B.
AU  - Gao, J.-Y.
TI  - Transformer for EI Niño-Southern Oscillation Prediction
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
DO  - 10.1109/LGRS.2021.3100485
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112612053&doi=10.1109%2fLGRS.2021.3100485&partnerID=40&md5=ef7e46d45335009fead3195cb7ba1c12
AB  - Accurate prediction of EI Niño-southern oscillation (ENSO) is of great significance to seasonal climate forecast. Recently, a convolutional neural network (CNN) has shown an optimal skill for ENSO prediction. However, it is difficult for the convolutional kernel to capture long-range precursors of ENSO due to its build-in local property. The transformer model has long been used in natural language processing (NLP) for its ability to focus on global features. Here, we introduce it to the ENSO research community and propose the ENSO transformer (ENSOTR). We show that using the ENSOTR model, the monthly average Niño3.4 index can be skillfully predicted up to one and a half years ahead. The model can also predict strong EI Niño cases more than a year ahead, such as 1997-1998. Experimental results show that our model achieves better skill than CNN for ENSO prediction.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Ye2022Transformer
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Li, R.
AU  - Duan, C.
AU  - Zhang, C.
AU  - Meng, X.
AU  - Fang, S.
TI  - A Novel Transformer Based Semantic Segmentation Scheme for Fine-Resolution Remote Sensing Images
PY  - 2022
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 19
DO  - 10.1109/LGRS.2022.3143368
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123345592&doi=10.1109%2fLGRS.2022.3143368&partnerID=40&md5=d0031987fc958b0bee568411b096af14
AB  - The fully convolutional network (FCN) with an encoder-decoder architecture has been the standard paradigm for semantic segmentation. The encoder-decoder architecture utilizes an encoder to capture multilevel feature maps, which are incorporated into the final prediction by a decoder. As the context is crucial for precise segmentation, tremendous effort has been made to extract such information in an intelligent fashion, including employing dilated/atrous convolutions or inserting attention modules. However, these endeavors are all based on the FCN architecture with ResNet or other backbones, which cannot fully exploit the context from the theoretical concept. By contrast, we introduce the Swin Transformer as the backbone to extract the context information and design a novel decoder of densely connected feature aggregation module (DCFAM) to restore the resolution and produce the segmentation map. The experimental results on two remotely sensed semantic segmentation datasets demonstrate the effectiveness of the proposed scheme.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 219
C2  - CCF:C期刊; 
LB  - Wang2022Novel
ER  -

TY  - JOUR
AU  - Yao, Z.
AU  - Yu, J.
AU  - Ding, J.
TI  - Contrastive learning of graph encoder for accelerating pedestrian trajectory prediction training
PY  - 2021
T2  - IET Image Processing
VL  - 15
IS  - 14
SP  - 3645
EP  - 3660
DO  - 10.1049/ipr2.12185
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103981123&doi=10.1049%2fipr2.12185&partnerID=40&md5=eca1d789214dd7f8cb1a8f7ebf332d56
AB  - In the area of pedestrian trajectory prediction, the hybrid structures of temporal feature extractor or spatial feature extractor have paved the way for the precise prediction model, and they are in larger and larger scale. Learning of specific feature encoding model not only influenced by the structure of the network, but also by the learning manners such as supervised learning and unsupervised learning. Previous works concentrated on more comprehensive encoders and more delicate designs of feature extractors. However, the mutual influence factors from the neighbour pedestrians associate with the distance to the centre pedestrian seldomly noticed. Most of the existed feature extractors in prediction models trained in the way of supervised learning other than unsupervised manners caused the problem that the extracted features are always handcrafted without the natural distinction of obscure situations. The graph contrastive accelerating encoder is proposed, which accelerates the pedestrian trajectory prediction training process of the state of the art method of spatio-temporal graph transformer networks. Employing the unsupervised contrastive learning process and the graph of neighbours representing distance affection of nearest and farthest pedestrian to the centre pedestrian, the graph contrastive accelerating encoder significantly shrinked the training time. Holding the final performance on to state of the art level, the proposed method let the lowest pedestrian trajectory prediction error show up in the obviously earlier training steps. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Yao2021Contrastive
ER  -

TY  - JOUR
AU  - Elbayad, M.
AU  - Besacier, L.
AU  - Verbeek, J.
TI  - Joint source–target encoding with pervasive attention
PY  - 2021
T2  - Machine Translation
VL  - 35
IS  - 4
SP  - 637
EP  - 659
DO  - 10.1007/s10590-021-09289-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196664565&doi=10.1007%2fs10590-021-09289-7&partnerID=40&md5=cd04f8cbb55c06702b3303ddca929c9e
AB  - The pervasive attention model is a sequence-to-sequence model that addresses the issue of source–target interaction in encoder–decoder models by jointly encoding the two sequences with a two-dimensional convolutional neural network. We investigate different design choices for each building block of Pervasive Attention and study their impact to improve the predictive strength of the model. These include different types of layer connectivity, depth of the networks, the filter sizes, and source aggregation mechanisms. Machine translation experiments on the IWSLT’14 De→En, IWSLT’15 En→Vi, WMT’16 En→Ro and WMT’15 De→En datasets show results competitive with state-of-the-art encoder–decoder models, outperforming Transformer models on three of the four tested datasets. © The Author(s), under exclusive licence to Springer Nature B.V. 2021.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; 
LB  - Elbayad2021Joint
ER  -

TY  - JOUR
AU  - Duong, L.T.
AU  - Le, N.H.
AU  - Tran, T.B.
AU  - Ngo, V.M.
AU  - Nguyen, P.T.
TI  - Detection of tuberculosis from chest X-ray images: Boosting the performance with vision transformer and transfer learning
PY  - 2021
T2  - Expert Systems with Applications
VL  - 184
C7  - 115519
DO  - 10.1016/j.eswa.2021.115519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109871085&doi=10.1016%2fj.eswa.2021.115519&partnerID=40&md5=5d2431eacc35c47c80222ca399e16f9f
AB  - Tuberculosis (TB) caused by Mycobacterium tuberculosis is a contagious disease which is among the top deadly diseases in the world. Research in Medical Imaging has been done to provide doctors with techniques and tools to early detect, monitor and diagnose the disease using Artificial Intelligence. Recently, many attempts have been made to automatically recognize TB from chest X-ray (CXR) images. Still, while the obtained performance is encouraging, according to our investigation, many of the existing approaches have been evaluated on small and undiverse datasets. We suppose that such a good performance might not hold for heterogeneous data sources, which originate from real world scenarios. Our present work aims to fill the gap and improve the prediction performance on larger datasets. In particular, we present a practical solution for the detection of tuberculosis from CXR images, making use of cutting-edge Machine Learning and Computer Vision algorithms. We conceptualize a framework by adopting three recent deep neural networks as the main classification engines, namely modified EfficientNet, modified original Vision Transformer, and modified Hybrid EfficientNet with Vision Transformer. Moreover, we also empower the learning process with various augmentation techniques. We evaluated the proposed approach using a large dataset which has been curated by merging various public datasets. The resulting dataset has been split into training, validation, and testing sets which account for 80%, 10%, and 10% of the original dataset, respectively. To further study our proposed approach, we compared it with two state-of-the-art systems. The obtained results are encouraging: the maximum accuracy of 97.72% with AUC of 100% is achieved with ViT_Base_EfficientNet_B1_224. The experimental results demonstrate that our conceived tool outperforms the considered baselines with respect to different quality metrics. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 112
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Duong2021Detection
ER  -

TY  - JOUR
AU  - Smerdov, A.
AU  - Somov, A.
AU  - Burnaev, E.
AU  - Zhou, B.
AU  - Lukowicz, P.
TI  - Detecting Video Game Player Burnout with the Use of Sensor Data and Machine Learning
PY  - 2021
T2  - IEEE Internet of Things Journal
VL  - 8
IS  - 22
SP  - 16680
EP  - 16691
DO  - 10.1109/JIOT.2021.3074740
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104673627&doi=10.1109%2fJIOT.2021.3074740&partnerID=40&md5=542a5e560369e8f42457e772a0ba3fda
AB  - Current research in eSports lacks the tools for proper game practising and performance analytics. The majority of prior work relied only on in-game data for advising the players on how to perform better. However, in-game mechanics and trends are frequently changed by new patches limiting the lifespan of the models trained exclusively on the in-game logs. In this article, we propose the methods based on the sensor data analysis for predicting whether a player will win the future encounter. The sensor data were collected from ten participants in 22 matches in the League of Legends video game. We have trained machine learning models, including the transformer and gated recurrent unit, to predict whether the player wins the encounter taking place after some fixed time in the future. For 10-s forecasting horizon, the transformer neural network architecture achieves the ROC AUC score of 0.706. This model is further developed into the detector capable of predicting that a player will lose the encounter occurring in 10 s in 88.3% of cases with 73.5% accuracy. This might be used as a players' burnout or fatigue detector, advising players to retreat. We have also investigated which physiological features affect the chance to win or lose the next in-game encounter. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Smerdov2021Detecting
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Wang, B.
AU  - Jiang, J.
TI  - Siamese Pre-Trained Transformer Encoder for Knowledge Base Completion
PY  - 2021
T2  - Neural Processing Letters
VL  - 53
IS  - 6
SP  - 4143
EP  - 4158
DO  - 10.1007/s11063-021-10586-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114329324&doi=10.1007%2fs11063-021-10586-8&partnerID=40&md5=2f400d8922a27e60f5fe537102aa1c51
AB  - In this paper, we aim at leveraging a Siamese textual encoder to efficiently and effectively tackle knowledge base completion problem. Traditional graph embedding-based methods straightforwardly learn the embeddings by considering a knowledge base’s structure but are inherently vulnerable to the graph’s sparsity or incompleteness issue. In contrast, previous textual encoding-based methods capture such structured knowledge from a semantic perspective and employ deep neural textual encoder to model graph triples in semantic space, but they fail to trade off the contextual features with model’s efficiency. Therefore, in this paper we propose a Siamese textual encoder operating on each graph triple from the knowledge base, where the contextual features between a head/tail entity and a relation are well-captured to highlight relation-aware entity embedding while a Siamese structure is also adapted to avoid combinatorial explosion during inference. In the experiments, the proposed method reaches state-of-the-art or comparable performance on several link prediction datasets. Further analyses demonstrate that the proposed method is much more efficient than its baseline with similar evaluating results. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Li2021Siamese
ER  -

TY  - JOUR
AU  - Sharma, M.
AU  - Kandasamy, I.
AU  - Kandasamy, V.
TI  - Deep Learning for predicting neutralities in Offensive Language Identification Dataset[Formula presented]
PY  - 2021
T2  - Expert Systems with Applications
VL  - 185
C7  - 115458
DO  - 10.1016/j.eswa.2021.115458
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111953518&doi=10.1016%2fj.eswa.2021.115458&partnerID=40&md5=9839a13a11a45c78e99f033d78c8fed0
AB  - Deep learning is advancing rapidly; it has aided in solving problems that were thought impossible. Natural language understanding is one such task that has evolved with the advancement of deep learning systems. There have been several sentiment analysis attempts, but they aim to classify it as a single emotion. Human emotion in natural language is generally a complex combination of emotions, which may be indeterminate or neutral at times. Neutrosophy is a branch of philosophy that identifies neutralities and uses membership functions (positive, negative, neutral) to quantify a sample into Single Valued Neutrosophic Set (SVNS) values. Our work aims to combine the power of deep learning with SVNS to represent a sample's sentiment into membership functions of SVNS. We have worked on the Offensive Language Identification Dataset (OLID). Combining the power of state-of-the-art neural network techniques with neutrosophy allowed us to quantify the sentiments and identify the transition phase between positive and negative ones. We used the transition phase to capture neutral samples, which is beneficial if we want to obtain purely positive/negative samples. We performed experiments using Bi-directional Long Short Term Memory (BiLSTM) with attention, Bidirectional Encoder Representations from Transformers (BERT), A Lite BERT (ALBERT), A Robustly Optimised BERT Approach (RoBERTa), and MPNet. Our SVNS model performed equivalent to state-of-the-art neural network models on the OLID dataset. Here, we propose a novel framework that can integrate with any neural network model and quantify sentiments using SVNS. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Sharma2021Deep
ER  -

TY  - JOUR
AU  - Suman, C.
AU  - Naman, A.
AU  - Saha, S.
AU  - Bhattacharyya, P.
TI  - A Multimodal Author Profiling System for Tweets
PY  - 2021
T2  - IEEE Transactions on Computational Social Systems
VL  - 8
IS  - 6
SP  - 1407
EP  - 1416
DO  - 10.1109/TCSS.2021.3082942
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110854197&doi=10.1109%2fTCSS.2021.3082942&partnerID=40&md5=b28cd1d1fa14ff580065104c243ed84e
AB  - The rising usage of social media has motivated to invent different methodologies of anonymous writing, which leads to an increase in malicious and suspicious activities. This anonymity has created difficulty in finding the suspect. Author profiling deals with the characterization of an author through some key attributes such as gender, age, language, dialect region variety, personality, and so on. Identifying the gender of the author of a suspect document is a salient task of author-profiling. The linguistic profile of a user can help in determining his/her demographics. Different social media platforms, such as Twitter, Facebook, and Instagram, are used regularly by users for sharing their daily life activities. Moreover, users often post images along with text on different social media platforms; thus, the usage of multimodal information is very common nowadays. In this article, the task of automatic gender prediction from multimodal Twitter data is posed as a classification problem and an efficient multimodal neural framework is proposed for solving this. The popularly used BERT_base is utilized for learning the encoded representation for the text part of the tweet, and recently introduced EfficientNet is used for extracting the features from images. Finally, a direct product-based fusion strategy is applied for fusing the text and image representations, followed by a fully connected layer for predicting the gender of a Twitter user. Plagiarism detection authorship analysis near end duplicate detection (PAN)-2018 author profiling data are used for evaluating the performance of our proposed approach. Our proposed model achieved accuracies of 82.05%, 86.22%, and 89.53% for pure-image, pure-text, and multimodal setting, respectively; outperforming the previous state-of-the-art works in all the cases. Moreover, a deep analysis is carried out to interpret the produced results; different words that serve as clues for gender classification are identified characterizing different gender classes. The supplementary file and the source codes for the proposed approach are available at https://github.com/chanchalIITP/GenderTCSS. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; 
LB  - Suman2021Multimodal
ER  -

TY  - JOUR
AU  - Le, T.
AU  - Nguyen, H.T.
AU  - Nguyen, M.L.
TI  - Multi visual and textual embedding on visual question answering for blind people
PY  - 2021
T2  - Neurocomputing
VL  - 465
SP  - 451
EP  - 464
DO  - 10.1016/j.neucom.2021.08.117
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120703016&doi=10.1016%2fj.neucom.2021.08.117&partnerID=40&md5=71f67fa3accc4c3df50636c1694d4104
AB  - Visual impairment community, especially blind people have a thirst for assistance from advanced technologies for understanding and answering the image. Through the development and intersection between vision and language, Visual Question Answering (VQA) is to predict an answer from a textual question on an image. It is essential and ideal to help blind people with capturing the image and answering their questions automatically. Traditional approaches often utilize the strength of convolution and recurrent networks, which requires a great effort for learning and optimizing. A key challenge in VQA is finding an effective way to extract and combine textual and visual features. To take advantage of previous knowledge in different domains, we propose BERT-RG, the delicate integration of pre-trained models into feature extractors, which relies on the interaction between residual and global features in the image and linguistic features in the question. Moreover, our architecture integrates a stacked attention mechanism that exploits the relationship between textual and visual objects. Specifically, the partial regions of images interact with partial keywords in question to enhance the text-vision representation. Besides, we also propose a novel perspective by considering a specific question type in VQA. Our proposal is significantly meaningful enough to develop a specialized system instead of putting forth the effort to dig for unlimited and unrealistic approaches. Experiments on VizWiz-VQA, a practical benchmark dataset, show that our proposed model outperforms existing models on the VizWiz VQA dataset in the Yes/No question type. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Le2021Multi
ER  -

TY  - JOUR
AU  - Jin, K.
AU  - Wi, J.
AU  - Lee, E.
AU  - Kang, S.
AU  - Kim, S.
AU  - Kim, Y.
TI  - TrafficBERT: Pre-trained model with large-scale data for long-range traffic flow forecasting
PY  - 2021
T2  - Expert Systems with Applications
VL  - 186
C7  - 115738
DO  - 10.1016/j.eswa.2021.115738
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113591041&doi=10.1016%2fj.eswa.2021.115738&partnerID=40&md5=919b3b19b92a2ade44ce787c40961306
AB  - Traffic flow prediction has various applications such as in traffic systems and autonomous driving. Road conditions have become increasingly complex, and this, in turn, has increased the demand for effective traffic volume predictions. Statistical models and conventional machine-learning models have been employed for this purpose more recently, deep learning has been widely used. However, most deep learning-based models require data additional to traffic information, such as information on adjacent roads or road weather conditions. Therefore, the effectiveness of these models is typically restricted to certain roads. Even if such information were available, there is a possibility of bias toward a specific road. To overcome this limitation, based on the bidirectional encoder representations from transformers (BERT), we propose trafficBERT, a model that is suitable for use on various roads because it is pre-trained with large-scale traffic data. Our model captures time-series information by employing multi-head self-attention in place of the commonly used recurrent neural network. In addition, the autocorrelation between the states before and after each time step is determined more efficiently via factorized embedding parameterization. Our results indicate that trafficBERT outperforms models trained using data for specific roads, as well as commonly used statistical and deep learning models, such as Stacked Autoencoder, and models based on long short-term memory, in terms of accuracy. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Jin2021TrafficBERT
ER  -

TY  - JOUR
AU  - Fiok, K.
AU  - Karwowski, W.
AU  - Gutierrez, E.
AU  - Wilamowski, M.
TI  - Analysis of sentiment in tweets addressed to a single domain-specific Twitter account: Comparison of model performance and explainability of predictions
PY  - 2021
T2  - Expert Systems with Applications
VL  - 186
C7  - 115771
DO  - 10.1016/j.eswa.2021.115771
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114148510&doi=10.1016%2fj.eswa.2021.115771&partnerID=40&md5=c95e59aa1c1af7e6673a8bc62264a49c
AB  - Many institutions and companies find it valuable to know how people feel about their ventures; hence, scientific research in sentiment analysis has been intensely developed over time. Automated sentiment analysis can be considered as a machine learning (ML) prediction task, with classes representing human affective states. Due to the rapid development of ML and deep learning (DL), improvements in automatic sentiment analysis performance are achieved almost every year. Since 2013, Semantic Evaluation (SemEval) has hosted a worldwide community-acknowledged competition that allows for comparisons of recent innovations. The sentiment analysis tasks focus on assessing sentiment in Twitter posts authored by various publishers and addressing multiple subjects. Our study aimed to compare selected popular and recent natural language processing methods using a new data set of Twitter posts sent to a single Twitter account. For improved comparability of our experiments with SemEval, we adopted their metrics and also deployed our models on data published for SemEval-2017. In addition, we investigated if an unsupervised ML technique applied for the detection of topics in tweets can be leveraged to improve the predictive performance of a selected transformer model. We also demonstrated how a recent explainable artificial intelligence technique can be used in Twitter sentiment analysis to gain a deeper understanding of the models’ predictions. Our results show that the most recent DL language modeling approach provides the highest quality; however, this quality comes at reduced model transparency. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Fiok2021Analysis
ER  -

TY  - JOUR
AU  - Lin, Y.
AU  - Shen, J.
AU  - Wang, Y.
AU  - Pantic, M.
TI  - RoI Tanh-polar transformer network for face parsing in the wild
PY  - 2021
T2  - Image and Vision Computing
VL  - 112
C7  - 104190
DO  - 10.1016/j.imavis.2021.104190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106517296&doi=10.1016%2fj.imavis.2021.104190&partnerID=40&md5=568a32e77a8bc4d2d46f64f68e6aee9c
AB  - Face parsing aims to predict pixel-wise labels for facial components of a target face in an image. Existing approaches usually crop the target face from the input image with respect to a bounding box calculated during pre-processing, and thus can only parse inner facial Regions of Interest (RoIs). Peripheral regions like hair are ignored and nearby faces that are partially included in the bounding box can cause distractions. Moreover, these methods are only trained and evaluated on near-frontal portrait images and thus their performance for in-the-wild cases has been unexplored. To address these issues, this paper makes three contributions. First, we introduce iBugMask dataset for face parsing in the wild, which consists of 21,866 training images and 1000 testing images. The training images are obtained by augmenting an existing dataset with large face poses. The testing images are manually annotated with 11 facial regions and there are large variations in sizes, poses, expressions and background. Second, we propose RoI Tanh-polar transform that warps the whole image to a Tanh-polar representation with a fixed ratio between the face area and the context, guided by the target bounding box. The new representation contains all information in the original image, and allows for rotation equivariance in the convolutional neural networks (CNNs). Third, we propose a hybrid residual representation learning block, coined HybridBlock, that contains convolutional layers in both the Tanh-polar space and the Tanh-Cartesian space, allowing for receptive fields of different shapes in CNNs. Through extensive experiments, we show that the proposed method improves the state-of-the-art for face parsing in the wild and does not require facial landmarks for alignment. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 30
C2  - CCF:C期刊; 
LB  - Lin2021RoI
ER  -

TY  - JOUR
AU  - Meng, Y.
AU  - Speier, W.
AU  - Ong, M.K.
AU  - Arnold, C.W.
TI  - Bidirectional Representation Learning from Transformers Using Multimodal Electronic Health Record Data to Predict Depression
PY  - 2021
T2  - IEEE Journal of Biomedical and Health Informatics
VL  - 25
IS  - 8
C7  - 9369833
SP  - 3121
EP  - 3129
DO  - 10.1109/JBHI.2021.3063721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102286368&doi=10.1109%2fJBHI.2021.3063721&partnerID=40&md5=e3a83a9f6a2a37b5ed8a30d0f95444b6
AB  - Advancements in machine learning algorithms have had a beneficial impact on representation learning, classification, and prediction models built using electronic health record (EHR) data. Effort has been put both on increasing models' overall performance as well as improving their interpretability, particularly regarding the decision-making process. In this study, we present a temporal deep learning model to perform bidirectional representation learning on EHR sequences with a transformer architecture to predict future diagnosis of depression. This model is able to aggregate five heterogenous and high-dimensional data sources from the EHR and process them in a temporal manner for chronic disease prediction at various prediction windows. We applied the current trend of pretraining and fine-tuning on EHR data to outperform the current state-of-the-art in chronic disease prediction, and to demonstrate the underlying relation between EHR codes in the sequence. The model generated the highest increases of precision-recall area under the curve (PRAUC) from 0.70 to 0.76 in depression prediction compared to the best baseline model. Furthermore, the self-attention weights in each sequence quantitatively demonstrated the inner relationship between various codes, which improved the model's interpretability. These results demonstrate the model's ability to utilize heterogeneous EHR data to predict depression while achieving high accuracy and interpretability, which may facilitate constructing clinical decision support systems in the future for chronic disease screening and early detection.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 81
C2  - CCF:C期刊; 
LB  - Meng2021Bidirectional
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Jiang, Y.
AU  - Huang, B.
TI  - Long-term prediction for temporal propagation of seasonal influenza using Transformer-based model
PY  - 2021
T2  - Journal of Biomedical Informatics
VL  - 122
C7  - 103894
DO  - 10.1016/j.jbi.2021.103894
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114125158&doi=10.1016%2fj.jbi.2021.103894&partnerID=40&md5=92383173267f243be29381d628db7c38
AB  - Influenza is one of the most common infectious diseases worldwide, which causes a considerable economic burden on hospitals and other healthcare costs. Predicting new and urgent trends in epidemiological data is an effective way to prevent influenza outbreaks and protect public health. Traditional autoregressive(AR) methods and new deep learning models like Recurrent Neural Network(RNN) have been actively studied to solve the problem. Most existing studies focus on the short-term prediction of influenza. Recently, Transformer models show superior performance in capturing long-range dependency than RNN models. In this paper, we develop a Transformer-based model, which utilizes the potential of the Transformer to increase the prediction capacity. To fuse information from data of different sources and capture the spatial dependency, we design a sources selection module based on measuring curve similarity. Our model is compared with the widely used AR models and RNN-based models on USA and Japan datasets. Results show that our approach provides approximate performance in short-term forecasting and better performance in long-term forecasting. © 2021 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:C期刊; 
LB  - Li2021Long-term
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Liu, Z.
AU  - Xia, Y.
AU  - Zhu, C.
AU  - Zhao, D.
TI  - Spatiotemporal module for video saliency prediction based on self-attention
PY  - 2021
T2  - Image and Vision Computing
VL  - 112
C7  - 104216
DO  - 10.1016/j.imavis.2021.104216
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107090803&doi=10.1016%2fj.imavis.2021.104216&partnerID=40&md5=22f35e991e68fd06f36478003c6c4f1d
AB  - Considering that the existing video saliency prediction methods still have limitations in spatiotemporal correlation learning between features and saliency regions, this paper proposes a spatiotemporal module for video saliency prediction based on self-attention. The proposed model emphasizes three essential problems as follows. First, we raise a multi-scale feature-fusion network (MFN) for effective feature integration. The framework can extract and fuse features from four scales at low memory cost. Second, we view the task as a global evaluation of the correlation on pixel level to predict human visual attention in task-driven scenes more accurately. An adapted transformer encoder is designed for spatiotemporal correlation learning. Finally, we introduce DConvLSTM to learn the context in videos. Experimental results show that the proposed model achieves state-of-the-art performance on both driving scenes and natural scenes with multi-motion information. And our model also achieves very comparable performance especially in natural scenes with multi-category objects. It proves our method is practicable in both data-driven and task-driven conditions. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Wang2021Spatiotemporal
ER  -

TY  - JOUR
AU  - Abdel-Basset, M.
AU  - Hawash, H.
AU  - Chakrabortty, R.K.
AU  - Ryan, M.
TI  - Energy-Net: A Deep Learning Approach for Smart Energy Management in IoT-Based Smart Cities
PY  - 2021
T2  - IEEE Internet of Things Journal
VL  - 8
IS  - 15
C7  - 9371013
SP  - 12422
EP  - 12435
DO  - 10.1109/JIOT.2021.3063677
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102245550&doi=10.1109%2fJIOT.2021.3063677&partnerID=40&md5=9930ed2cb7bf5cb85d72a31e0a2392a8
AB  - Although intelligent load forecasting is essential for optimal energy management (EM) in smart cities, there is a lack of current research exploring EM in well-regulated Internet-of-Things (IoT) networks. This article develops a new deep learning (DL) model for efficient forecasting of short-term energy consumption while maintaining effective communication between energy providers and users. The proposed Energy-Net stack comprises multiple stacked spatiotemporal modules, where each module consists of a temporal transformer (TT) submodule and a spatial transformer (ST) submodule. The TT models the temporal relationships in load data; and the ST submodule extracts hidden spatial information by integrating convolutional layers and includes an improved self-attention mechanism. The experimental evaluation on IHPEC and independent system operator New England (ISO-NE) data set demonstrates the superiority of Energy-Net over recent cutting-edge DL models with root mean-square error (RMSE) of 0.354 and 0.535, respectively. The computational complexity of Energy-Net is appropriate for dependable resource-constrained IoT devices (i.e., fog nodes or edge nodes) linked to a joint IoT-cloud server that interacts with connected smart grids to handle EM tasks. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 50
C2  - CCF:C期刊; 
LB  - Abdel-Basset2021Energy-Net
ER  -

TY  - JOUR
AU  - Verma, P.K.
AU  - Agrawal, P.
AU  - Amorim, I.
AU  - Prodan, R.
TI  - WELFake: Word Embedding over Linguistic Features for Fake News Detection
PY  - 2021
T2  - IEEE Transactions on Computational Social Systems
VL  - 8
IS  - 4
C7  - 9395133
SP  - 881
EP  - 893
DO  - 10.1109/TCSS.2021.3068519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103915853&doi=10.1109%2fTCSS.2021.3068519&partnerID=40&md5=db70553e30cae549501be8f672423d5f
AB  - Social media is a popular medium for the dissemination of real-time news all over the world. Easy and quick information proliferation is one of the reasons for its popularity. An extensive number of users with different age groups, gender, and societal beliefs are engaged in social media websites. Despite these favorable aspects, a significant disadvantage comes in the form of fake news, as people usually read and share information without caring about its genuineness. Therefore, it is imperative to research methods for the authentication of news. To address this issue, this article proposes a two-phase benchmark model named WELFake based on word embedding (WE) over linguistic features for fake news detection using machine learning classification. The first phase preprocesses the data set and validates the veracity of news content by using linguistic features. The second phase merges the linguistic feature sets with WE and applies voting classification. To validate its approach, this article also carefully designs a novel WELFake data set with approximately 72 000 articles, which incorporates different data sets to generate an unbiased classification output. Experimental results show that the WELFake model categorizes the news in real and fake with a 96.73% which improves the overall accuracy by 1.31% compared to bidirectional encoder representations from transformer (BERT) and 4.25% compared to convolutional neural network (CNN) models. Our frequency-based and focused analyzing writing patterns model outperforms predictive-based related works implemented using the Word2vec WE method by up to 1.73%. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 152
C2  - CCF:C期刊; 
LB  - Verma2021WELFake
ER  -

TY  - JOUR
AU  - Yuan, Y.
AU  - Cai, X.
TI  - A Human-Machine Interaction Scheme Based on Background Knowledge in 6G-Enabled IoT Environment
PY  - 2021
T2  - IEEE Internet of Things Journal
VL  - 8
IS  - 20
SP  - 15292
EP  - 15302
DO  - 10.1109/JIOT.2021.3050880
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099575695&doi=10.1109%2fJIOT.2021.3050880&partnerID=40&md5=d5f395df9df015f161a294d178d264c6
AB  - 6G-Enabled Internet of Things (IoT) is about to open a new era of Internet of Everything (IoE). It creates favorable conditions for new application services. The human-machine dialogue system, one of the most important forms of human-machine interaction, is expected to replace mobile applications in the future. This article proposes a dialogue generation scheme named background knowledge-aware dialogue generation model with pretrained encoders (BKADGPE). Dialogue generation, which takes the context as input and response as output, is a sequence-to-sequence (Seq2Seq) task. Instead of only generating the response based on the previous sequence of utterances, background knowledge-aware dialogue generation is also relying on background knowledge documents. This is because people often communicate based on their background knowledge. This article divides it into two tasks: 1) a knowledge selection task and 2) a response generation task. One of the latest language pretraining models, a lite bidirectional encoder representations from transformers (ALBERT), is applied as the encoder. In the knowledge selection task, ALBERT adds the linear layer and softmax layer to predict the content-related knowledge span. In the response generation task, the ALBERT after fine-tuning through the knowledge selection task adds the left-context-only transformer with a copy mechanism to incorporate background knowledge span into the generated response. Empirical studies on the HOLL-E dataset show that the result of BKADGPE is better than the related works.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Yuan2021Human-Machine
ER  -

TY  - JOUR
AU  - Mayer, T.
AU  - Marro, S.
AU  - Cabrio, E.
AU  - Villata, S.
TI  - Enhancing evidence-based medicine with natural language argumentative analysis of clinical trials
PY  - 2021
T2  - Artificial Intelligence in Medicine
VL  - 118
C7  - 102098
DO  - 10.1016/j.artmed.2021.102098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110644673&doi=10.1016%2fj.artmed.2021.102098&partnerID=40&md5=fefa0398a2c0058c4b00ac1fc265a900
AB  - In the latest years, the healthcare domain has seen an increasing interest in the definition of intelligent systems to support clinicians in their everyday tasks and activities. Among others, also the field of Evidence-Based Medicine is impacted by this twist, with the aim to combine the reasoning frameworks proposed thus far in the field with mining algorithms to extract structured information from clinical trials, clinical guidelines, and Electronic Health Records. In this paper, we go beyond the state of the art by proposing a new end-to-end pipeline to address argumentative outcome analysis on clinical trials. More precisely, our pipeline is composed of (i) an Argument Mining module to extract and classify argumentative components (i.e., evidence and claims of the trial) and their relations (i.e., support, attack), and (ii) an outcome analysis module to identify and classify the effects (i.e., improved, increased, decreased, no difference, no occurrence) of an intervention on the outcome of the trial, based on PICO elements. We annotated a dataset composed of more than 500 abstracts of Randomized Controlled Trials (RCT) from the MEDLINE database, leading to a labeled dataset with 4198 argument components, 2601 argument relations, and 3351 outcomes on five different diseases (i.e., neoplasm, glaucoma, hepatitis, diabetes, hypertension). We experiment with deep bidirectional transformers in combination with different neural architectures (i.e., LSTM, GRU and CRF) and obtain a macro F1-score of.87 for component detection and.68 for relation prediction, outperforming current state-of-the-art end-to-end Argument Mining systems, and a macro F1-score of.80 for outcome classification. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:C期刊; 
LB  - Mayer2021Enhancing
ER  -

TY  - JOUR
AU  - Zaikis, D.
AU  - Vlahavas, I.
TI  - TP-DDI: Transformer-based pipeline for the extraction of Drug-Drug Interactions
PY  - 2021
T2  - Artificial Intelligence in Medicine
VL  - 119
C7  - 102153
DO  - 10.1016/j.artmed.2021.102153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113472053&doi=10.1016%2fj.artmed.2021.102153&partnerID=40&md5=10217d43d08e34ba2e3e0f9eecbe2a48
AB  - Drug-Drug Interaction (DDI) extraction is the task of identifying drug entities and the potential interactions between drug pairs from biomedical literature. Computer-aided extraction of DDIs is vital for drug discovery, as this process remains extremely expensive and time consuming. Therefore, Machine Learning-based approaches can reduce the laborious task during the drug development cycle. Numerous traditional and Neural Network-based approaches for Drug Named Entity Recognition (DNER) and the classification of DDIs have been proposed over the years. However, despite the development of many effective methods, achieving good prediction accuracy is an area where significant improvement can be made. In this article, we present a novel end-to-end approach that tackles the overall DDI extraction task as a pipelined method via the Transformer model architecture and biomedical domain pre-trained weights. In our approach, the tasks of DNER and DDI classification are executed successively to extract the drug entities and to classify their relationship respectively. The proposed approach, TP-DDI, integrates prior knowledge by using pre-trained weights from BioBERT and improves in both the Drug Named Entity Recognition and the overall DDI extraction task over the current state-of-the-art approaches on the DDI Extraction 2013 corpus. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; 
LB  - Zaikis2021TP-DDI
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Chen, Y.
AU  - Cao, C.
AU  - Wang, J.
AU  - Lu, H.
TI  - STN-enhanced message passing guided by adversarial learning for human pose estimation
PY  - 2021
T2  - Neurocomputing
VL  - 453
SP  - 60
EP  - 72
DO  - 10.1016/j.neucom.2021.04.110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106321203&doi=10.1016%2fj.neucom.2021.04.110&partnerID=40&md5=99e5b404e2417cdaf1a152e2648ff03e
AB  - In this paper, an STN (Spatial Transformer Network)-enhanced message passing module guided by adversarial learning is proposed for human pose estimation. Transformations performed on the predicted heatmaps mean to modify the raw predictions and conduct the message passing among human joints in an elegant way. Firstly, we employ STN submodule to transform the predicted heatmap of one human joint to heatmap of its neighboring joint to remove ambiguity of its neighboring predictions. STN submodule automatically learns the geometric information between adjacent joints and thus builds related neighboring associations among them. Nevertheless, it seems difficult for STN submodule to learn inherent geometric information from a single RGB image alone. Secondly, limb guidance is introduced to assist STN in predicting corresponding correlations. Since quality of limb predictions poses great significance for the guidance, we propose to exploit adversarial learning to improve the quality of limb heatmaps which are easier to learn than precise keypoint location. Hence, the precision of STN transformation improves owing to more precise prior instructions. However, STN submodule might be confused when performing the transformation due to massive noises of the heatmaps. To circumvent this dilemma, at last, we propose to utilize Weighted Mean Square Error (WMSE) loss and convolutional random walk (CRW) which improve the performance further. Our method achieves competitive results on both MPII and LSP benchmarks. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; 
LB  - Zhou2021STN-enhanced
ER  -

TY  - JOUR
AU  - Saeedi, R.
AU  - Sadanandan, S.K.
AU  - Srivastava, A.K.
AU  - Davies, K.L.
AU  - Gebremedhin, A.H.
TI  - An Adaptive Machine Learning Framework for Behind-the-Meter Load/PV Disaggregation
PY  - 2021
T2  - IEEE Transactions on Industrial Informatics
VL  - 17
IS  - 10
C7  - 9360481
SP  - 7060
EP  - 7069
DO  - 10.1109/TII.2021.3060898
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101764451&doi=10.1109%2fTII.2021.3060898&partnerID=40&md5=02c5f0f86c1a6a261ea61842f93bf3cb
AB  - A significant amount of distributed photovoltaic (PV) generation is 'invisible' to distribution system operators since it is behind the meter on customer premises and not directly monitored by the utility. The generation essentially adds an unknown varying negative demand to the system, which causes additional uncertainty in determining the total load. This uncertainty directly impacts system reliability, cold load pickup, load behavior modeling, and hence cost of operation. Thus, it is essential to create low-complexity localized models for estimating power generation from these invisible sites behind the meters. This article proposes an adaptive machine learning framework to: a) learn using weather data and a minimal number of BTM PV generation measurement sensors, b) forecast PV generation using weather, location of PV, and trained ML model at location for unmeasured BTM PV; c) use estimated PV and net load measured by smart meter or smart transformer to estimate total true load at each time step; and d) learn the specific load patterns eventually to adapt localized models. The proposed framework's core idea is to transform the data such that: a) the machine learning model can effectively utilize the time dependency of measurements; and b) the measurements are transformed into a lower dimensional space to reduce complexity while maintaining accuracy. The transformed measurements are then used to train the machine learning models for load/PV disaggregation. Machine learning models investigated include linear regression, decision tree, random forest (RF), and multilayer perceptron. The proposed framework's efficacy is demonstrated using two datasets, a real dataset from Hawaii and a simulated dataset using detailed models in GridLab-D. Several test/training split scenarios, including 90-10% split, one-month-out, one-season-out, and panel-independent split are presented to provide a thorough evaluation of the proposed framework. Results on both datasets show that the proposed framework can estimate PV generation with high accuracy using low-complexity methods. The accuracy results are comparable to higher complexity models (e.g., deep architectures), and RF is found to provide superior performance with these specific datasets compared to the other ML models investigated.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 39
C2  - CCF:C期刊; 
LB  - Saeedi2021Adaptive
ER  -

TY  - JOUR
AU  - Yu, K.
AU  - Yang, Z.
AU  - Wu, C.
AU  - Huang, Y.
AU  - Xie, X.
TI  - In-hospital resource utilization prediction from electronic medical records with deep learning
PY  - 2021
T2  - Knowledge-Based Systems
VL  - 223
C7  - 107052
DO  - 10.1016/j.knosys.2021.107052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104581569&doi=10.1016%2fj.knosys.2021.107052&partnerID=40&md5=64d019edc8f350044fec1bc460fd3857
AB  - Effective healthcare resource allocation is critical for intelligent medical systems, and accurate in-hospital resource utilization prediction from medical records is a prerequisite. Existing methods for this task usually rely on manual feature engineering which needs massive domain knowledge, and do not exploit the textual information in electronic medical records, e.g., diagnosis and operation texts. In this paper, we propose a deep in-hospital resource utilization prediction approach to jointly estimate the in-hospital costs and length of stays from patients’ admission records via multi-task learning. Our approach can exploit the heterogeneous information in records, such as patient features, diagnosis/operation texts, and the diagnosis/operation IDs, via a multi-view learning framework, where Transformers are used to learn the representations of words, diagnoses and operations. In addition, we design a diagnosis–operation attention network to capture the relations between diagnoses and operations. Besides, since different words, diagnoses and operations have different importance for cost estimation, we incorporate a hierarchical attention network to select important words, diagnoses and operations for learning informative record representations. Extensive experiments on a real-world medical dataset validate the effectiveness of our approach. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; FMS:C; 
LB  - Yu2021In-hospital
ER  -

TY  - JOUR
AU  - Sirrianni, J.W.
AU  - Liu, X.
AU  - Adams, D.
TI  - Predicting Stance Polarity and Intensity in Cyber Argumentation with Deep Bidirectional Transformers
PY  - 2021
T2  - IEEE Transactions on Computational Social Systems
VL  - 8
IS  - 3
C7  - 9353851
SP  - 655
EP  - 667
DO  - 10.1109/TCSS.2021.3056596
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101446694&doi=10.1109%2fTCSS.2021.3056596&partnerID=40&md5=67792be6bd914d3f35f5529077ae31a0
AB  - In online deliberation, participants argue in support or opposition to one another's arguments and ideas to advocate their position. Often their stance expressed in their posts is implicit and must be derived from the post's text. Existing stance detection models predict the polarity of the user's stance from the text, but do not consider the stance's intensity. We introduce a new research problem, stance polarity, and intensity prediction in response relationships between posts. This problem seeks to predict both the stance polarity and intensity of a replying post toward its parent post in online deliberation. Using our cyber argumentation platform, we have collected an empirical data set with explicitly labeled stance polarity and intensity relationships. In this work, we create six models: five are adapted from top-performing stance detection models and another novel model that fine-tunes the deep bidirectional transformer model BERT. We train and test these six models on our empirical data set to compare their performance for stance polarity and intensity prediction and stance detection. Our results demonstrate that our method of encoding the stance polarity and intensity labels allows the models to predict stance polarity and intensity without compromising their accuracy for stance detection, making these models more versatile. Our results reveal that a novel split architecture for fine-tuning the BERT model outperforms the other models for stance polarity and intensity prediction by 5% accuracy. This work is the first to train models for predicting both the stance polarity and intensity in one combined task while maintaining good accuracy.  © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; 
LB  - Sirrianni2021Predicting
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Fan, X.
AU  - Zhang, C.
AU  - Lai, C.S.
AU  - Zhang, Y.
AU  - Zheng, H.
AU  - Lai, L.L.
AU  - Zhang, E.
TI  - Moisture Diagnosis of Transformer Oil-Immersed Insulation with Intelligent Technique and Frequency-Domain Spectroscopy
PY  - 2021
T2  - IEEE Transactions on Industrial Informatics
VL  - 17
IS  - 7
C7  - 9157956
SP  - 4624
EP  - 4634
DO  - 10.1109/TII.2020.3014224
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092783850&doi=10.1109%2fTII.2020.3014224&partnerID=40&md5=104391f0cc83d928f0cd75d42d1d5204
AB  - Moisture is one of the critical factors to determine the service life of transformers. The moisture inside the transformer oil-immersed insulation could be quantified with feature parameters. This article proposes and develops a genetic algorithm support vector machine (GA-SVM) model to carry out the moisture diagnosis. Present findings reveal that these feature parameters can be obtained by using frequency-domain spectroscopy. Therefore, a novel model for predicting the frequency-domain spectroscopy curves is first reported based on a small number of samples, which could be utilized to obtain the feature parameters database to develop GA-SVM. Then, the moisture diagnosis in the lab and field conditions is presented to verify its feasibility and accuracy. The novelty of this article is in an exploration of the reported model as an intelligent based moisture diagnosis tool for power transformers.  © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 54
C2  - CCF:C期刊; 
LB  - Liu2021Moisture
ER  -

TY  - JOUR
AU  - Stylianou, N.
AU  - Vlahavas, I.
TI  - TransforMED: End-to-Εnd Transformers for Evidence-Based Medicine and Argument Mining in medical literature
PY  - 2021
T2  - Journal of Biomedical Informatics
VL  - 117
C7  - 103767
DO  - 10.1016/j.jbi.2021.103767
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103971975&doi=10.1016%2fj.jbi.2021.103767&partnerID=40&md5=122a95f7dec16a45592e985e0a2a459e
AB  - Argument Mining (AM) refers to the task of automatically identifying arguments in a text and finding their relations. In medical literature this is done by identifying Claims and Premises and classifying their relations as either Support or Attack. Evidence-Based Medicine (EBM) refers to the task of identifying all related evidence in medical literature to allow medical practitioners to make informed choices and form accurate treatment plans. This is achieved through the automatic identification of Population, Intervention, Comparator and Outcome entities (PICO) in the literature to limit the collection to only the most relevant documents. In this work, we combine EBM with AM in medical literature to increase the performance of the individual models and create high quality argument graphs, annotated with PICO entities. To that end, we introduce a state-of-the-art EBM model, used to predict the PICO entities and two novel Argument Identification and Argument Relation classification models that utilize the PICO entities to enhance their performance. Our final system works in a pipeline and is able to identify all PICO entities in a medical publication, the arguments presented in them and their relations. © 2021 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:C期刊; 
LB  - Stylianou2021TransforMED
ER  -

TY  - JOUR
AU  - Sharma, M.
AU  - Kandasamy, I.
AU  - Vasantha, W.B.
TI  - Comparison of neutrosophic approach to various deep learning models for sentiment analysis[Formula presented]
PY  - 2021
T2  - Knowledge-Based Systems
VL  - 223
C7  - 107058
DO  - 10.1016/j.knosys.2021.107058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105698330&doi=10.1016%2fj.knosys.2021.107058&partnerID=40&md5=9dd258e88f019b921a14b6eccfea4970
AB  - Deep learning has been widely used in numerous real-world engineering applications and for classification problems. Real-world data is present with neutrality and indeterminacy, which neutrosophic theory captures clearly. Though both are currently developing research areas, there has been little study on their interlinking. We have proposed a novel framework to implement neutrosophy in deep learning models. Instead of just predicting a single class as output, we have quantified the sentiments using three membership functions to understand them better. Our proposed model consists of two blocks, feature extraction, and feature classification. Having a separate feature extraction block enables us to use any model as a feature extractor. We experimented with BiLSTM using GloVe (Global Vectors for word representation), BERT (Bidirectional Encoder Representations from Transformers), ALBERT (A Lite BERT), RoBERTa (Robustly optimized BERT approach), MPNet, and stacked ensemble models. Feature classification performs prediction and dimensionality reduction of features. Experimental analysis was done on the SemEval 2017 Task 4 dataset (Subtask A). We used the intermediate layer features to define membership functions of Single Valued Neutrosophic Sets (SVNS). We used these membership functions for prediction as well. We have compared our models with the top five teams of the task and recent state-of-the-art systems. Our proposed stacked ensemble model achieved the best recall (0.733) score. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:C期刊; FMS:C; 
LB  - Sharma2021Comparison
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Peng, X.
AU  - Su, Y.
AU  - Qiao, Y.
AU  - Cheng, J.
TI  - TTPP: Temporal Transformer with Progressive Prediction for efficient action anticipation
PY  - 2021
T2  - Neurocomputing
VL  - 438
SP  - 270
EP  - 279
DO  - 10.1016/j.neucom.2021.01.087
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100697335&doi=10.1016%2fj.neucom.2021.01.087&partnerID=40&md5=4b6a35d3238f51b242c4f14b0bac8bcc
AB  - Video action anticipation aims to predict future action categories from observed frames. Current state-of-the-art approaches mainly resort to recurrent neural networks to encode history information into hidden states, and predict future actions from the hidden representations. It is well known that the recurrent pipeline is inefficient in capturing long-term information which may limit its performance in predication task. To address this problem, this paper proposes a simple yet efficient Temporal Transformer with Progressive Prediction (TTPP) framework, which repurposes a Transformer-style architecture to aggregate observed features, and then leverages a light-weight network to progressively predict future features and actions. Specifically, predicted features along with predicted probabilities are accumulated into the inputs of subsequent prediction. We evaluate our approach on three action datasets, namely TVSeries, THUMOS-14, and TV-Human-Interaction. Additionally we also conduct a comprehensive study for several popular aggregation and prediction strategies. Extensive results show that TTPP not only outperforms the state-of-the-art methods but also more efficient. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:C期刊; 
LB  - Wang2021TTPP
ER  -

TY  - JOUR
AU  - Zainab, K.
AU  - Srivastava, G.
AU  - Mago, V.
TI  - Identifying health related occupations of Twitter users through word embedding and deep neural networks
PY  - 2021
T2  - BMC Bioinformatics
VL  - 22
C7  - 630
DO  - 10.1186/s12859-022-04933-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138973298&doi=10.1186%2fs12859-022-04933-2&partnerID=40&md5=f7405edf2b09c3ab038afb95114e3c8a
AB  - Background: Twitter is a popular social networking site where short messages or “tweets” of users have been used extensively for research purposes. However, not much research has been done in mining the medical professions, such as detecting the occupations of users from their biographical contents. Mining such professions can be used to build efficient recommender systems for cost-effective targeted advertisements. Moreover, it is highly important to develop effective methods to identify the occupation of users since conventional classification methods rely on features developed by human intelligence. Although, the result may be favorable for the classification problem. However, it is still extremely challenging for traditional classifiers to predict the medical occupations accurately since it involves predicting multiple occupations. Hence this study emphasizes predicting the medical occupational class of users through their public biographical (“Bio”) content. We have conducted our analysis by annotating the bio content of Twitter users. In this paper, we propose a method of combining word embedding with state-of-art neural network models that include: Long Short Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit, Bidirectional Encoder Representations from Transformers, and A lite BERT. Moreover, we have also observed that by composing the word embedding with the neural network models there is no need to construct any particular attribute or feature. By using word embedding, the bio contents are formatted as dense vectors which are fed as input into the neural network models as a sequence of vectors. Result: Performance metrics that include accuracy, precision, recall, and F1-score have shown a significant difference between our method of combining word embedding with neural network models than with the traditional methods. The scores have proved that our proposed approach has outperformed the traditional machine learning techniques for detecting medical occupations among users. ALBERT has performed the best among the deep learning networks with an F1 score of 0.90. Conclusion: In this study, we have presented a novel method of detecting the occupations of Twitter users engaged in the medical domain by merging word embedding with state-of-art neural networks. The outcomes of our approach have demonstrated that our method can further advance the process of analyzing corpora of social media without going through the trouble of developing computationally expensive features. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zainab2021Identifying
ER  -

TY  - JOUR
AU  - Ferri, P.
AU  - Sáez, C.
AU  - Félix-De Castro, A.
AU  - Juan-Albarracín, J.
AU  - Blanes-Selva, V.
AU  - Sánchez-Cuesta, P.
AU  - García-Gómez, J.M.
TI  - Deep ensemble multitask classification of emergency medical call incidents combining multimodal data improves emergency medical dispatch
PY  - 2021
T2  - Artificial Intelligence in Medicine
VL  - 117
C7  - 102088
DO  - 10.1016/j.artmed.2021.102088
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107308915&doi=10.1016%2fj.artmed.2021.102088&partnerID=40&md5=ac052596336c3c66bc99473056b77de8
AB  - The objective of this work was to develop a predictive model to aid non-clinical dispatchers to classify emergency medical call incidents by their life-threatening level (yes/no), admissible response delay (undelayable, minutes, hours, days) and emergency system jurisdiction (emergency system/primary care) in real time. We used a total of 1 244 624 independent incidents from the Valencian emergency medical dispatch service in Spain, compiled in retrospective from 2009 to 2012, including clinical features, demographics, circumstantial factors and free text dispatcher observations. Based on them, we designed and developed DeepEMC2, a deep ensemble multitask model integrating four subnetworks: three specialized to context, clinical and text data, respectively, and another to ensemble the former. The four subnetworks are composed in turn by multi-layer perceptron modules, bidirectional long short-term memory units and a bidirectional encoding representations from transformers module. DeepEMC2 showed a macro F1-score of 0.759 in life-threatening classification, 0.576 in admissible response delay and 0.757 in emergency system jurisdiction. These results show a substantial performance increase of 12.5 %, 17.5 % and 5.1 %, respectively, with respect to the current in-house triage protocol of the Valencian emergency medical dispatch service. Besides, DeepEMC2 significantly outperformed a set of baseline machine learning models, including naive bayes, logistic regression, random forest and gradient boosting (α = 0.05). Hence, DeepEMC2 is able to: 1) capture information present in emergency medical calls not considered by the existing triage protocol, and 2) model complex data dependencies not feasible by the tested baseline models. Likewise, our results suggest that most of this unconsidered information is present in the free text dispatcher observations. To our knowledge, this study describes the first deep learning model undertaking emergency medical call incidents classification. Its adoption in medical dispatch centers would potentially improve emergency dispatch processes, resulting in a positive impact in patient wellbeing and health services sustainability. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:C期刊; 
LB  - Ferri2021Deep
ER  -

TY  - JOUR
AU  - Liao, W.
AU  - Zeng, B.
AU  - Yin, X.
AU  - Wei, P.
TI  - An improved aspect-category sentiment analysis model for text sentiment analysis based on RoBERTa
PY  - 2021
T2  - Applied Intelligence
VL  - 51
IS  - 6
SP  - 3522
EP  - 3533
DO  - 10.1007/s10489-020-01964-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096056784&doi=10.1007%2fs10489-020-01964-1&partnerID=40&md5=c369e00246edf6fd5933ad50bc6f7132
AB  - The aspect-category sentiment analysis can provide more and deeper information than the document-level sentiment analysis, because it aims to predict the sentiment polarities of different aspect categories in the same text. The main challenge of aspect-category sentiment analysis is that different aspect categories may present different polarities in the same text. Previous studies combine the Long Short-Term Memory (LSTM) and attention mechanism to predict the sentiment polarity of the given aspect category, but the LSTM-based methods are not really bidirectional text feature extraction methods. In this paper, we propose a multi-task aspect-category sentiment analysis model based on RoBERTa (Robustly Optimized BERT Pre-training Approach). Treating each aspect category as a subtask, we employ the RoBERTa based on deep bidirectional Transformer to extract features from both text and aspect tokens, and apply the cross-attention mechanism to guide the model to focus on the features most relevant to the given aspect category. According to the experimental results, the proposed model outperforms other models for comparison in aspect-category sentiment analysis. Furthermore, the influencing factors of our proposed model are also analyzed. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 89
C2  - CCF:C期刊; 
LB  - Liao2021improved
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Hu, B.
AU  - Chen, Q.
AU  - Wang, X.
AU  - Qi, Q.
AU  - Wang, L.
AU  - Liu, H.
TI  - Attentive capsule network for click-through rate and conversion rate prediction in online advertising
PY  - 2021
T2  - Knowledge-Based Systems
VL  - 211
C7  - 106522
DO  - 10.1016/j.knosys.2020.106522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092938594&doi=10.1016%2fj.knosys.2020.106522&partnerID=40&md5=cad6b92d8358eb88955058c962910cb1
AB  - Estimating Click-through Rate (CTR) and Conversion Rate (CVR) are two essential user response prediction tasks in computing advertising and recommendation systems. The mainstream methods map sparse, high-dimensional categorical features (e.g., user id, item id) into low-dimensional representations with neural networks. Although they have achieved significant advancement in recent years, how to capture user's diverse interests effectively from past behaviors is still challenging. Recently some works try using attention-based methods to learn the representation from user behavior history adaptively. However, it is insufficient to capture the diversity of user's interests. As a step forward to improve this goal, we propose a method named Attentive Capsule Network (ACN). It uses Transformers for feature interaction and leverages capsule networks to capture multiple interests from user behavior history. To precisely obtain sequence representation related to the current advertisement, we further design a modified dynamic routing algorithm integrating with an attention mechanism. Experimental results on real-world datasets demonstrate the effectiveness of our proposed ACN with significant improvement over state-of-the-art approaches. Moreover, it also offers good explainability when extracting diverse interest points of users from behavior history. © 2020 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - CCF:C期刊; FMS:C; 
LB  - Li2021Attentive
ER  -

TY  - JOUR
AU  - Zhu, H.
AU  - Wang, R.
AU  - Zhang, X.
TI  - Image Captioning with Dense Fusion Connection and Improved Stacked Attention Module
PY  - 2021
T2  - Neural Processing Letters
VL  - 53
IS  - 2
SP  - 1101
EP  - 1118
DO  - 10.1007/s11063-021-10431-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100613311&doi=10.1007%2fs11063-021-10431-y&partnerID=40&md5=b9637b864c5d98b51a5784f449103b1e
AB  - In the existing image captioning methods, masked convolution is usually used to generate language description, and traditional residual network (ResNets) methods used for masked convolution bring about the vanishing gradient problem. To address this issue, we propose a new image captioning framework that combines dense fusion connection (DFC) and improved stacked attention module. DFC uses dense convolutional networks (DenseNets) architecture to connect each layer to any other layer in a feed-forward fashion, then adopts ResNets method to combine features through summation. The improved stacked attention module can capture more fine-grained visual information highly relevant to the word prediction. Finally, we employ the Transformer to the image encoder to sufficiently obtain the attended image representation. The experimental results on MS-COCO dataset demonstrate the proposed model can increase CIDEr score from 91.2 % to 106.1 % , which has higher performance than the comparable models and verifies the effectiveness of the proposed model. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Zhu2021Image
ER  -

TY  - JOUR
AU  - Singh, T.D.
AU  - Khilji, A.F.U.R.
AU  - Singh, A.V.
AU  - Thokchom, S.
AU  - Bandyopadhyay, S.
TI  - Predictive approaches for the UNIX command line: curating and exploiting domain knowledge in semantics deficit data
PY  - 2021
T2  - Multimedia Tools and Applications
VL  - 80
IS  - 6
SP  - 9209
EP  - 9229
DO  - 10.1007/s11042-020-10109-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096123538&doi=10.1007%2fs11042-020-10109-y&partnerID=40&md5=73766e315407e9b2325046027604b44e
AB  - The command line has always been the most efficient method to interact with UNIX flavor based systems while offering a great deal of flexibility and efficiency as preferred by professionals. Such a system is based on manually inputting commands to instruct the computing machine to carry out tasks as desired. This human-computer interface is quite tedious especially for a beginner. And hence, the command line has not been able to garner an overwhelming reception from new users. Therefore, to improve user-friendliness and to mark a step towards a more intuitive command line system, we propose two predictive approaches that can benefit all kinds of users specially the novice ones by integrating into the command line interface. These methods are based on deep learning based predictions. The first approach is based on the sequence to sequence (Seq2seq) model with joint learning by leveraging continuous representations of a self-curated exhaustive knowledge base (KB) comprising an all-inclusive command description to enhance the embedding employed in the model. The other is based on the attention-based transformer architecture where a pretrained model is employed. This allows the model to dynamically evolve over time making it adaptable to different circumstances by learning as the system is being used. To reinforce our idea, we have experimented with our models on three major publicly available Unix command line datasets and have achieved benchmark results using GLoVe and Word2Vec embeddings. Our finding is that the transformer based framework performs better on two different datasets of the three in our experiment in a semantic deficit scenario like UNIX command line prediction. However, Seq2seq based model outperforms bidirectional encoder representations from transformers (BERT) based model on a larger dataset. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; 
LB  - Singh2021Predictive
ER  -

TY  - JOUR
AU  - Leng, X.-L.
AU  - Miao, X.-A.
AU  - Liu, T.
TI  - Using recurrent neural network structure with Enhanced Multi-Head Self-Attention for sentiment analysis
PY  - 2021
T2  - Multimedia Tools and Applications
VL  - 80
IS  - 8
SP  - 12581
EP  - 12600
DO  - 10.1007/s11042-020-10336-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104527853&doi=10.1007%2fs11042-020-10336-3&partnerID=40&md5=1f75a796dfe64a044577fa8446eb7a65
AB  - Sentiment analysis is a process of analysis, processing, induction, and reasoning of subjective text with emotional color. It is a research direction of Natural Language Processing (NLP). It is often used to extract the attitudes towards someone or something of people. That can help users find potential problems to improve or predict. As one of the main resources of online media data, film review information is often used as a dataset in the field of sentiment analysis. Researchers put forward many models in sentiment analysis to analyze the film review dataset. Accuracy, precision, recall rate, F1-scores are important standards to measure the quality of a model. To improve these criteria, a new model is proposed in this paper. The new model combines a bidirectional Long Short-Term Memory network (biLSTM) or a bidirectional Gated Recurrent Unit (biGRU) and an Enhanced Multi-Head Self-Attention mechanism. The Enhanced Multi-Head Self-Attention is a two-layer modified Transformer encoder. This modified Transformer encoder is that its masking operation and the last feedforward layer are removed. Besides, the loss function of this new model is the sum of the weighted root mean square error (RMSE) and the cross entropy loss. The operation of this sum can improve the ability of auto-encoder to reproduce. That can improve classification accuracy. The proposed model is an autoencoder classification model. In this model, biLSTM or biGRU are used as encoders and decoders at both ends of the network. Enhanced Multi-Head Self-Attention is used to encode the inter-sentence information as the middle hidden layer. A four-layer autoencoder network model is constructed to perform sentiment analysis on movie review in this paper. The movie review data sets (IMDB movie comment data set and SST-2 sentiment data set) are used in experiments. Experiment results show that the proposed model performs better in terms of accuracy, precision, recall rate, and F1-scores comparing with the baseline models. BiLSTM is better than biGRU by comparing the effect of them in the model. Finally, Bidirectional Encoder Representations from Transformers (BERT) is used in our method instead of word2vec as a pre-training structure. Compared with the baseline model based on BERT, the proposed model is better. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; 
LB  - Leng2021Using
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Zhang, D.
AU  - Nanehkaran, Y.
TI  - Research of power load prediction based on boost clustering
PY  - 2021
T2  - Soft Computing
VL  - 25
IS  - 8
SP  - 6401
EP  - 6413
DO  - 10.1007/s00500-021-05632-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101199449&doi=10.1007%2fs00500-021-05632-5&partnerID=40&md5=90a9d42fafba3593a68aef872cc9b348
AB  - Power load prediction which helps make the optimal decision for energy management is of great significance to the safe, reliable, and economical operation of the power system. It is also a challenging task; however, if every large customer of a special transformer is modeled and forecasted for power load, a huge amount of calculation work is needed and it is not practical. Therefore, in this study, we propose a boost clustering-based approach for the prediction of power load. The traditional k-means algorithm is enhanced, and the initial cluster centers are determined in advance instead of random selection. Then, the enhanced k-means paired with the HAC algorithm are used for the clustering of power consumption users. Next, the power load of each group is predicted after the users are clustered into the different groups, and the predicted results of each group are finally summed to obtain the prediction value of the power load. Experimental findings demonstrate the validity of the proposed procedure, and the boost clustering-based approach significantly outperforms the direct prediction approach in the empirical analysis. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; 
LB  - Chen2021Research
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Poon, J.
AU  - Wang, S.
AU  - Sun, S.
AU  - Poon, S.
TI  - A novel method for clinical risk prediction with low-quality data
PY  - 2021
T2  - Artificial Intelligence in Medicine
VL  - 114
C7  - 102052
DO  - 10.1016/j.artmed.2021.102052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103130578&doi=10.1016%2fj.artmed.2021.102052&partnerID=40&md5=973125c4e0b0cc19ee654dac59849316
AB  - In real-world data, predictive models for clinical risks (such as adverse drug reactions, hospital readmission, and chronic disease onset) are constantly struggling with low-quality issues, namely redundant and highly correlated features, extreme category imbalances, and most importantly, a large number of missing values. In most existing work, each patient is represented as a value vector with the fixed-length from some feature space, and missing values are forced to be imputed, which introduces much noise for prediction if the data set is highly incomplete. Besides, other challenges are either remaining unresolved or only partially solved when modeling, but without a systematic approach. In this paper, we propose a novel framework to address these low-quality problems, that we first treat patients as bags with the various number of feature-value pairs, called instances, and map them to an embedding space through our proposed feature embedding method to learn from it directly. In this way, predictive models can avoid the negative impact of missing data naturally. A novel multi-instance neural network is then connected, using two computational modules to deal with the problems of correlated and redundant features: multi-head attention and attention-based multi-instance pooling. They are capable of capturing the instance correlations and locating valuable information in each instance or bag. The feature embedding and multi-instance neural network are parameterized and optimized jointly in an end-to-end manner. Moreover, the training process is under both main and auxiliary supervision with focal loss functions to avoid the caveat of a highly imbalanced label set. This proposed framework is named AMI-Net3. We evaluate it on three suitable data sets from real-world settings with different clinical risk prediction tasks: adverse drug reaction of risperidone, schizophrenia relapse, and invasive fungi infection, respectively. The comprehensive experimental results demonstrate the effectiveness and superiority of our proposed method over competitive baselines. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; 
LB  - Wang2021novel
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Shi, X.
AU  - Mi, S.
AU  - Yang, X.
TI  - Image captioning with transformer and knowledge graph
PY  - 2021
T2  - Pattern Recognition Letters
VL  - 143
SP  - 43
EP  - 49
DO  - 10.1016/j.patrec.2020.12.020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099439006&doi=10.1016%2fj.patrec.2020.12.020&partnerID=40&md5=418a80b3c122f847657b8aab9da9e6fa
AB  - The Transformer model has achieved very good results in machine translation tasks. In this paper, we adopt the Transformer model for the image captioning task. To promote the performance of image captioning, we improve the Transformer model from two aspects. First, we augment the maximum likelihood estimation (MLE) with an extra Kullback-Leibler (KL) divergence term to distinguish the difference between incorrect predictions. Second, we introduce a method to help the Transformer model generate captions by leveraging the knowledge graph. Experiments on benchmark datasets demonstrate the effectiveness of our method. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 63
C2  - CCF:C期刊; 
LB  - Zhang2021Image
ER  -

TY  - JOUR
AU  - González, J.Á.
AU  - Hurtado, L.-F.
AU  - Pla, F.
TI  - TWilBert: Pre-trained deep bidirectional transformers for Spanish Twitter
PY  - 2021
T2  - Neurocomputing
VL  - 426
SP  - 58
EP  - 69
DO  - 10.1016/j.neucom.2020.09.078
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095806184&doi=10.1016%2fj.neucom.2020.09.078&partnerID=40&md5=dfde86a8cdb725511577408f126fc30d
AB  - In recent years, the Natural Language Processing community have been moving from uncontextualized word embeddings towards contextualized word embeddings. Among these contextualized architectures, BERT stands out due to its capacity to compute bidirectional contextualized word representations. However, its competitive performance in English downstream tasks is not obtained by its multilingual version when it is applied to other languages and domains. This is especially true in the case of the Spanish language used in Twitter. In this work, we propose TWiLBERT, a specialization of BERT architecture both for the Spanish language and the Twitter domain. Furthermore, we propose a Reply Order Prediction signal to learn inter-sentence coherence in Twitter conversations, which improves the performance of TWilBERT in text classification tasks that require reasoning on sequences of tweets. We perform an extensive evaluation of TWilBERT models on 14 different text classification tasks, such as irony detection, sentiment analysis, or emotion detection. The results obtained by TWilBERT outperform the state-of-the-art systems and Multilingual BERT. In addition, we carry out a thorough analysis of the TWilBERT models to study the reasons of their competitive behavior. We release the pre-trained TWilBERT models used in this paper, along with a framework for training, evaluating, and fine-tuning TWilBERT models. © 2020 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - CCF:C期刊; 
LB  - González2021TWilBert
ER  -

TY  - JOUR
AU  - Brody, S.
AU  - Alon, U.
AU  - Yahav, E.
TI  - A structural model for contextual code changes
PY  - 2020
T2  - Proceedings of the ACM on Programming Languages
VL  - 4
IS  - OOPSLA
C7  - 215
DO  - 10.1145/3428283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097576594&doi=10.1145%2f3428283&partnerID=40&md5=c8f1cf8fcc9f5fdcbcc50c340ad1c81a
AB  - We address the problem of predicting edit completions based on a learned model that was trained on past edits. Given a code snippet that is partially edited, our goal is to predict a completion of the edit for the rest of the snippet. We refer to this task as the EditCompletion task and present a novel approach for tackling it. The main idea is to directly represent structural edits. This allows us to model the likelihood of the edit itself, rather than learning the likelihood of the edited code. We represent an edit operation as a path in the program's Abstract Syntax Tree (AST), originating from the source of the edit to the target of the edit. Using this representation, we present a powerful and lightweight neural model for the EditCompletion task. We conduct a thorough evaluation, comparing our approach to a variety of representation and modeling approaches that are driven by multiple strong models such as LSTMs, Transformers, and neural CRFs. Our experiments show that our model achieves a 28% relative gain over state-of-the-art sequential models and 2× higher accuracy than syntactic models that learn to generate the edited code, as opposed to modeling the edits directly. Our code, dataset, and trained models are publicly available at <a>https://github.com/tech-srl/c3po/</a> . © 2020 Owner/Author.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; 
LB  - Brody2020structural
ER  -

TY  - JOUR
AU  - Yu, Z.
AU  - Li, X.
AU  - Wang, P.
AU  - Zhao, G.
TI  - TransRPPG: Remote Photoplethysmography Transformer for 3D Mask Face Presentation Attack Detection
PY  - 2021
T2  - IEEE Signal Processing Letters
VL  - 28
C7  - 9460762
SP  - 1290
EP  - 1294
DO  - 10.1109/LSP.2021.3089908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109362012&doi=10.1109%2fLSP.2021.3089908&partnerID=40&md5=eaf5920cf7fef82730470d148c40411c
AB  - 3D mask face presentation attack detection (PAD) plays a vital role in securing face recognition systems from emergent 3D mask attacks. Recently, remote photoplethysmography (rPPG) has been developed as an intrinsic liveness clue for 3D mask PAD without relying on the mask appearance. However, the rPPG features for 3D mask PAD are still needed expert knowledge to design manually, which limits its further progress in the deep learning and big data era. In this letter, we propose a pure rPPG transformer (TransRPPG) framework for learning intrinsic liveness representation efficiently. At first, rPPG-based multi-scale spatial-temporal maps (MSTmap) are constructed from facial skin and background regions. Then the transformer fully mines the global relationship within MSTmaps for liveness representation, and gives a binary prediction for 3D mask detection. Comprehensive experiments are conducted on two benchmark datasets to demonstrate the efficacy of the TransRPPG on both intra- and cross-dataset testings. Our TransRPPG is lightweight and efficient (with only 547 K parameters and 763 M FLOPs), which is promising for mobile-level applications.  © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 82
C2  - CCF:C期刊; 
LB  - Yu2021TransRPPG
ER  -

TY  - JOUR
AU  - Chen, N.
AU  - Watanabe, S.
AU  - Villalba, J.
AU  - Zelasko, P.
AU  - Dehak, N.
TI  - Non-Autoregressive Transformer for Speech Recognition
PY  - 2021
T2  - IEEE Signal Processing Letters
VL  - 28
C7  - 9292943
SP  - 121
EP  - 125
DO  - 10.1109/LSP.2020.3044547
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098783807&doi=10.1109%2fLSP.2020.3044547&partnerID=40&md5=80e343fd33c45e8222c545997e915f51
AB  - Very deep transformers outperform conventional bi-directional long short-term memory networks for automatic speech recognition (ASR) by a significant margin. However, being autoregressive models, their computational complexity is still a prohibitive factor in their deployment into production systems. To amend this problem, we study two different non-autoregressive transformer structures for ASR: Audio-Conditional Masked Language Model (A-CMLM) and Audio-Factorized Masked Language Model (A-FMLM). When training these frameworks, the decoder input tokens are randomly replaced by special mask tokens. Then, the network is optimized to predict the masked tokens by taking both the unmasked context tokens and the input speech into consideration. During inference, we start from all masked tokens and the network iteratively predicts missing tokens based on partial results. A new decoding strategy is proposed as an example, which starts from the most confident predictions to the rest. Results on Mandarin (AISHELL), Japanese (CSJ), English (LibriSpeech) benchmarks show promising results to train such a non-autoregressive network for ASR. Especially in AISHELL, the proposed method outperformed the Kaldi ASR system and matched the performance of the state-of-the-art autoregressive transformer with 7\times speedup. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 66
C2  - CCF:C期刊; 
LB  - Chen2021Non-Autoregressive
ER  -

TY  - JOUR
AU  - Yin, J.
AU  - Tang, M.
AU  - Cao, J.
AU  - Wang, H.
TI  - Apply transfer learning to cybersecurity: Predicting exploitability of vulnerabilities by description
PY  - 2020
T2  - Knowledge-Based Systems
VL  - 210
C7  - 106529
DO  - 10.1016/j.knosys.2020.106529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092712488&doi=10.1016%2fj.knosys.2020.106529&partnerID=40&md5=51b4182cc5f1d9da82fe17a523fd519e
AB  - Thousands of software vulnerabilities are archived and disclosed to the public each year, posing severe cybersecurity threats to the whole society. Predicting the exploitability of vulnerabilities is crucial for decision-makers to prioritize their efforts and patch the most critical vulnerabilities. Software vulnerability descriptions are accessible features in early stage and contain rich semantic information. Therefore, descriptions are wildly used for exploitability prediction in both industry and academia. However, comparing with other corpora, the size of vulnerability description corpus is too small to train a comprehensive Natural Language Processing (NLP) model. To gain a better performance, this paper proposes a framework named ExBERT to accurately predict if a vulnerability will be exploited or not. ExBERT essentially is an improved Bidirectional Encoder Representations from Transformers (BERT) model for exploitability prediction. First, we fine-tune a pre-trained BERT using collected domain-specific corpus. Then, we design a Pooling Layer and a Classification Layer on top of the fine-tuned BERT model to extract sentence-level semantic features and predict the exploitability of vulnerabilities. Results on 46,176 real-word vulnerabilities have demonstrated that the proposed ExBERT framework achieves 91.12% on accuracy and 91.82% on precision, outperforming the state-of-the-art approach with 89.0% on accuracy and 81.8% on precision. © 2020 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 56
C2  - CCF:C期刊; FMS:C; 
LB  - Yin2020Apply
ER  -

TY  - JOUR
AU  - David, Y.
AU  - Alon, U.
AU  - Yahav, E.
TI  - Neural reverse engineering of stripped binaries using augmented control flow graphs
PY  - 2020
T2  - Proceedings of the ACM on Programming Languages
VL  - 4
IS  - OOPSLA
C7  - 225
DO  - 10.1145/3428293
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097580663&doi=10.1145%2f3428293&partnerID=40&md5=92d28ed585238c2e45e24f884d7ddccb
AB  - We address the problem of reverse engineering of stripped executables, which contain no debug information. This is a challenging problem because of the low amount of syntactic information available in stripped executables, and the diverse assembly code patterns arising from compiler optimizations. We present a novel approach for predicting procedure names in stripped executables. Our approach combines static analysis with neural models. The main idea is to use static analysis to obtain augmented representations of call sites; encode the structure of these call sites using the control-flow graph (CFG) and finally, generate a target name while attending to these call sites. We use our representation to drive graph-based, LSTM-based and Transformer-based architectures. Our evaluation shows that our models produce predictions that are difficult and time consuming for humans, while improving on existing methods by 28% and by 100% over state-of-the-art neural textual models that do not use any static analysis. Code and data for this evaluation are available at https://github.com/tech-srl/Nero. © 2020 Owner/Author.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - CCF:C期刊; 
LB  - David2020Neural
ER  -

TY  - JOUR
AU  - Wang, G.
AU  - Chen, X.
AU  - Gao, J.
AU  - Zhou, X.
AU  - Ge, S.
TI  - Self-Guided Body Part Alignment with Relation Transformers for Occluded Person Re-Identification
PY  - 2021
T2  - IEEE Signal Processing Letters
VL  - 28
C7  - 9448489
SP  - 1155
EP  - 1159
DO  - 10.1109/LSP.2021.3087079
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111005915&doi=10.1109%2fLSP.2021.3087079&partnerID=40&md5=cadfb4c39774e085e8c25366fa4ed8a3
AB  - Person re-identification in the wild is often challenged by occlusion. Existing methods mainly rely on learned external cues like pose or parsing to ease occlusion distraction. This knowledge highly related to body semantics may introduce alignment effects, leading to additional requirements for dedicated training data and inference computation. We propose the Self-guided Body Part Alignment method that learns cue-free semantic-aligned local prediction for feature representations to avoid high-cost dependence on external cues. First, scale-wise global spatial attention is utilized to determine essential body parts automatically. A relation transformer network is then employed to predict semantic-aligned local parts, guided with anchored global information by constraint loss. Similarity metrics for all parts are merged with threshold conditions to filter invisible body parts comprehensively. Experimental results on occluded and holistic person reID benchmarks show the proposed method outperforms other cue-relied and cue-free methods. As far as we know, this is the first method that applies transformer networks on local predictions for occluded reID tasks. © 1994-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Wang2021Self-Guided
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Zhang, J.
AU  - Wang, M.
AU  - Tian, J.
AU  - Zhuo, L.
TI  - Multilevel fusion of multimodal deep features for porn streamer recognition in live video
PY  - 2020
T2  - Pattern Recognition Letters
VL  - 140
SP  - 150
EP  - 157
DO  - 10.1016/j.patrec.2020.09.027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092373892&doi=10.1016%2fj.patrec.2020.09.027&partnerID=40&md5=526e11a405e947494472b546ef4868fc
AB  - Live video hosted by streamers is being sought after by an increasing number of Internet users. Some streamers mix pornographic content with live video for profit and popularity, but this greatly harms the network environment. To effectively identify porn streamers, a multilevel fusion method of multimodal deep features for porn streamer recognition in live video is proposed in this paper. (1) Visual and audio features including spatial, audio, motion, and temporal context in live video are extracted by a multimodal deep network. (2) Audio-visual attention features are obtained by fusing visual and audio features at the feature level based on a multimodal attention mechanism. (3) Text features are extracted by using the bullet screen text network based on the BERT (bidirectional encoder representations from transformers) model after collecting text information from the viewers’ bullet screen comments. (4) The prediction results of the audio-visual deep network and the bullet screen text network are fused at the decision level to improve the porn streamer recognition accuracy. We build a real-world dataset of porn streamers and conduct experiments and demonstrate that our method can improve the porn streamer recognition accuracy. © 2020 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Wang2020Multilevel
ER  -

TY  - JOUR
AU  - Huang, W.
AU  - Mao, Y.
AU  - Yang, Z.
AU  - Zhu, L.
AU  - Long, J.
TI  - Relation classification via knowledge graph enhanced transformer encoder
PY  - 2020
T2  - Knowledge-Based Systems
VL  - 206
C7  - 106321
DO  - 10.1016/j.knosys.2020.106321
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089218225&doi=10.1016%2fj.knosys.2020.106321&partnerID=40&md5=86586076140461c8cbd7c95cd7997255
AB  - Relation classification is an important task in natural language processing fields. The goal is to predict predefined relations for the marked nominal pairs in given sentences. State-of-the-art works usually focus on using deep neural networks as classifier to conduct the relation prediction. The rich semantic information of relationships in the triples of existing knowledge graph (KG) can be used as additional supervision for relation classification. However, these relationships were simply used as labels to specify the class of sentences in previous works, and their semantic information was completely ignored. In this paper, a novel approach is proposed for relation classification, which jointly uses information from textual sentences and knowledge graphs. To this end, we introduce a Transformer encoder to measure the semantic similarity between sentences and relation types. Besides, we connect the semantic information of marked nominals in sentences with that of the corresponding entities in knowledge graph to generate the semantic matching information between textual relations and KG relations. The matching information can provide additional supervision for relation classification. Since the words and entities are used interactively with each other in our work, we propose an embedding translating strategy to handle the semantic gap problem between word embeddings and entity embeddings. Experimental results on two widely used datasets, SemEval-2010 Task 8 and TACRED, show that our approach is able to efficiently use the semantic information from the knowledge graph to enhance the performance of the Transformer encoder for relation classification. © 2020 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; FMS:C; 
LB  - Huang2020Relation
ER  -

TY  - JOUR
AU  - Romaguera, L.V.
AU  - Plantefève, R.
AU  - Romero, F.P.
AU  - Hébert, F.
AU  - Carrier, J.-F.
AU  - Kadoury, S.
TI  - Prediction of in-plane organ deformation during free-breathing radiotherapy via discriminative spatial transformer networks
PY  - 2020
T2  - Medical Image Analysis
VL  - 64
C7  - 101754
DO  - 10.1016/j.media.2020.101754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086635778&doi=10.1016%2fj.media.2020.101754&partnerID=40&md5=baa97c50330c38611f094b4e02f10bb7
AB  - External beam radiotherapy is a commonly used treatment option for patients with cancer in the thoracic and abdominal regions. However, respiratory motion constitutes a major limitation during the intervention. It may stray the pre-defined target and trajectories determined during planning from the actual anatomy. We propose a novel framework to predict the in-plane organ motion. We introduce a recurrent encoder-decoder architecture which leverages feature representations at multiple scales. It simultaneously learns to map dense deformations between consecutive images from a given input sequence and to extrapolate them through time. Subsequently, several cascade-arranged spatial transformers use the predicted deformation fields to generate a future image sequence. We propose the use of a composite loss function which minimizes the difference between ground-truth and predicted images while maintaining smooth deformations. Our model is trained end-to-end in an unsupervised manner, thus it does not require additional information beyond image data. Moreover, no pre-processing steps such as segmentation or registration are needed. We report results on 85 different cases (healthy subjects and patients) belonging to multiples datasets across different imaging modalities. Experiments were aimed at investigating the importance of the proposed multi-scale architecture design and the effect of increasing the number of predicted frames on the overall accuracy of the model. The proposed model was able to predict vessel positions in the next temporal image with a median accuracy of 0.45 (0.55) mm, 0.45 (0.74) mm and 0.28 (0.58) mm in MRI, US and CT datasets, respectively. The obtained results show the strong potential of the model by achieving accurate matching between the predicted and target images on several imaging modalities. © 2020
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:C期刊; 
LB  - Romaguera2020Prediction
ER  -

TY  - JOUR
AU  - Sutphin, C.
AU  - Lee, K.
AU  - Yepes, A.J.
AU  - Uzuner, Ö.
AU  - McInnes, B.T.
TI  - Adverse drug event detection using reason assignments in FDA drug labels
PY  - 2020
T2  - Journal of Biomedical Informatics
VL  - 110
C7  - 103552
DO  - 10.1016/j.jbi.2020.103552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090150669&doi=10.1016%2fj.jbi.2020.103552&partnerID=40&md5=449e99a5a9cdcb228e744ad2ea0111b2
AB  - Adverse drug events (ADEs) are unintended incidents that involve the taking of a medication. ADEs pose significant health and financial problems worldwide. Information about ADEs can inform health care and improve patient safety. However, much of this information is buried in narrative texts and needs to be extracted with Natural Language Processing techniques, in order to be useful to computerized methods. ADEs can be found on drug labels, contained in the different sections such as descriptions of the drug's active components or more prominently in descriptions of studied side-effects. Extracting these automatically could be useful in triaging and processing drug reports. In this paper, we present three base methods consisting of a Conditional Random Field (CRF), a bi-directional Long Short Term Memory unit with a CRF layer (biLSTM+CRF), and a pre-trained Bi-directional Encoder Representations from Transformers (BERT) model. We also present several ensembles of the CRF and biLSTM+CRF methods for extracting ADEs and their Reason from FDA drug labels. We show that all three methods perform well on our task, and that combining the models through different ensemble methods can improve results, providing increases in recall for the majority class and improving precision for all other classes. We also show the potential of framing ADE extraction from drug labels as a multi-class classification task on the Reason, or type, of ADE. © 2020 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; 
LB  - Sutphin2020Adverse
ER  -

TY  - JOUR
AU  - Xu, Q.
AU  - Zhu, L.
AU  - Dai, T.
AU  - Yan, C.
TI  - Aspect-based sentiment classification with multi-attention network
PY  - 2020
T2  - Neurocomputing
VL  - 388
SP  - 135
EP  - 143
DO  - 10.1016/j.neucom.2020.01.024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078124407&doi=10.1016%2fj.neucom.2020.01.024&partnerID=40&md5=ba852265bfdbe542aa06237507d529fe
AB  - Aspect-based sentiment classification aims to predict the sentiment polarity of an aspect term in a sentence instead of the sentiment polarity of the entire sentence. Neural networks have been used for this task, and most existing methods have adopted sequence models, which require more training time than other models. When an aspect term comprises several words, most methods involve a coarse-level attention mechanism to model the aspect, and this may result in information loss. In this paper, we propose a multi-attention network (MAN) to address the above problems. The proposed model uses intra- and inter-level attention mechanisms. In the former, the MAN employs a transformer encoder instead of a sequence model to reduce training time. The transformer encoder encodes the input sentence in parallel and preserves long-distance sentiment relations. In the latter, the MAN uses a global and a local attention module to capture differently grained interactive information between aspect and context. The global attention module focuses on the entire relation, whereas the local attention module considers interactions at word level; this was often neglected in previous studies. Experiments demonstrate that the proposed model achieves superior results when compared to the baseline models. © 2020 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 109
C2  - CCF:C期刊; 
LB  - Xu2020Aspect-based
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Liu, P.
AU  - Yang, S.
AU  - Zhang, W.
TI  - Dynamic interaction networks for image-text multimodal learning
PY  - 2020
T2  - Neurocomputing
VL  - 379
SP  - 262
EP  - 272
DO  - 10.1016/j.neucom.2019.10.103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075466337&doi=10.1016%2fj.neucom.2019.10.103&partnerID=40&md5=e690163cde9061e5a186e013caa848d8
AB  - Recently, there is a surge of interest in image-text multimodal representation learning, and many neural network based models have been proposed aiming to capture the interaction between two modalities with different forms of functions. Despite their success, a potential limitation of these methods is insufficient to model all kinds of interactions with a set of static parameters. To alleviate this problem, we present a dynamic interaction network, in which the parameters of the interaction function are dynamically generated by a meta network. Additionally, to provide necessary multimodal features that the meta network needs, we propose a new neural module called Multimodal Transformer. Experimentally, we not only make a comprehensively quantitative evaluation on four image-text tasks, but also show some interpretable analyses of our models, revealing the internal working mechanism of the dynamic parameter learning. © 2019 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Wang2020Dynamic
ER  -

TY  - JOUR
AU  - Sun, C.
AU  - Yang, Z.
AU  - Wang, L.
AU  - Zhang, Y.
AU  - Lin, H.
AU  - Wang, J.
TI  - Attention guided capsule networks for chemical-protein interaction extraction
PY  - 2020
T2  - Journal of Biomedical Informatics
VL  - 103
C7  - 103392
DO  - 10.1016/j.jbi.2020.103392
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080097889&doi=10.1016%2fj.jbi.2020.103392&partnerID=40&md5=89f2d9533d07428fd46d4a3bc01445ae
AB  - The biomedical literature contains a sufficient number of chemical-protein interactions (CPIs). Automatic extraction of CPI is a crucial task in the biomedical domain, which has excellent benefits for precision medicine, drug discovery and basic biomedical research. In this study, we propose a novel model, BERT-based attention-guided capsule networks (BERT-Att-Capsule), for CPI extraction. Specifically, the approach first employs BERT (Bidirectional Encoder Representations from Transformers) to capture the long-range dependencies and bidirectional contextual information of input tokens. Then, the aggregation is regarded as a routing problem for how to pass messages from source capsule nodes to target capsule nodes. This process enables capsule networks to determine what and how much information need to be transferred, as well as to identify sophisticated and interleaved features. Afterwards, the multi-head attention is applied to guide the model to learn different contribution weights of capsule networks obtained by the dynamic routing. We evaluate our model on the CHEMPROT corpus. Our approach is superior in performance as compared with other state-of-the-art methods. Experimental results show that our approach can adequately capture the long-range dependencies and bidirectional contextual information of input tokens, obtain more fine-grained aggregation information through attention-guided capsule networks, and therefore improve the performance. © 2020
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Sun2020Attention
ER  -

TY  - JOUR
AU  - Zhu, Y.
AU  - Zhao, X.
AU  - Zhao, C.
AU  - Wang, J.
AU  - Lu, H.
TI  - Food det: Detecting foods in refrigerator with supervised transformer network
PY  - 2020
T2  - Neurocomputing
VL  - 379
SP  - 162
EP  - 171
DO  - 10.1016/j.neucom.2019.10.106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075477688&doi=10.1016%2fj.neucom.2019.10.106&partnerID=40&md5=59a30e1c42ebe32cb3f05d09ce0f835b
AB  - Most of existing methods mainly focus on the food image recognition which assumes that one food image contains only one food item. However, in this paper, we present a system to detect a diversity of foods in refrigerator where multiple food items may exist. In view of the refrigerator environment, we propose a food detection framework based on the supervised transformer network. More specifically, the supervised transformer network, dotted as RectNet, is first proposed to automatically select the irregular food regions and transform them to the frontal views. Then, based on the rectified food images, we further propose an end-to-end detection network that predicts the categories and locations of food items. The proposed detection network, called Lite Fully Convolutional Network (LiteFCN), is evolved from the advanced object detection algorithm Faster R-CNN while several significant improvements are tailored to achieve a higher accuracy and keep inference time efficiency. To validate the effectiveness of each component of our method, we build a real-world refrigerator dataset with 80 classes. Extensive experiments demonstrate that our methods achieve the state-of-the-art results, which improves the baseline by a large margin, e.g., 3–5% in terms of F-measure. We also show that the proposed detection network achieve a competitive result on the public PASCAL VOC2007 dataset, which outperforms the Faster R-CNN by 2.3% with a higher speed. © 2019 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Zhu2020Food
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Liu, Y.
AU  - Ge, B.
AU  - Abu-Rub, H.
TI  - Interactive Grid Interfacing System by Matrix-Converter-Based Solid State Transformer with Model Predictive Control
PY  - 2020
T2  - IEEE Transactions on Industrial Informatics
VL  - 16
IS  - 4
C7  - 7873242
SP  - 2533
EP  - 2541
DO  - 10.1109/TII.2017.2679137
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078413226&doi=10.1109%2fTII.2017.2679137&partnerID=40&md5=2332cde8aa0b8c64496ad4798992de99
AB  - The back-to-back connection of two three-to-single-phase matrix converters (MCs) through a high-frequency transformer to create the so called MC-based solid state transformer (SST) for interactive grid interfacing is proposed in this paper. The solution provides single-stage bidirectional ac-ac power conversion. There are advantages of no lifetime-limited storage capacitors, light weight, and compact volume. The conventional modulation methods of this MC-SST system require additional control design for power management. Besides, space vector modulation contains sophisticated voltage and current vectors computation and duty cycle composition, considering the two back-to-back connected three-to-single-phase MCs. In this paper, a model predictive control (MPC) is proposed for this MC-SST linking different ac grids. The proposed MPC predicts the state variables based on the discrete model of MC-SST system and the present circuit variables, and then selects an optimal switching state that ensures the smallest value of a cost function, for the next sampling time. Simulation and experimental studies are carried out to demonstrate effectiveness and simplicity of the proposed MPC for such MC-SST grid-interfacing system. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:C期刊; 
LB  - Liu2020Interactive
ER  -

TY  - JOUR
AU  - Maldonado, R.
AU  - Harabagiu, S.M.
TI  - Active deep learning for the identification of concepts and relations in electroencephalography reports
PY  - 2019
T2  - Journal of Biomedical Informatics
VL  - 98
C7  - 103265
DO  - 10.1016/j.jbi.2019.103265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072278284&doi=10.1016%2fj.jbi.2019.103265&partnerID=40&md5=7474d90ffa2f94ca912b328aadcc08fb
AB  - The identification of medical concepts, their attributes and the relations between concepts in a large corpus of Electroencephalography (EEG) reports is a crucial step in the development of an EEG-specific patient cohort retrieval system. However, the recognition of multiple types of medical concepts, along with the many attributes characterizing them is challenging, and so is the recognition of the possible relations between them, especially when desiring to make use of active learning. To address these challenges, in this paper we present the Self-Attention Concept, Attribute and Relation (SACAR) identifier, which relies on a powerful encoding mechanism based on the recently introduced Transformer neural architecture (Dehghani et al., 2018). The SACAR identifier enabled us to consider a recently introduced framework for active learning which uses deep imitation learning for its selection policy. Our experimental results show that SACAR was able to identify medical concepts more precisely and exhibited enhanced recall, compared with previous methods. Moreover, SACAR achieves superior performance in attribute classification for attribute categories of interest, while identifying the relations between concepts with performance competitive with our previous techniques. As a multi-task network, SACAR achieves this performance on the three prediction tasks simultaneously, with a single, complex neural network. The learning curves obtained in the active learning process when using the novel Active Learning Policy Neural Network (ALPNN) show a significant increase in performance as the active learning progresses. These promising results enable the extraction of clinical knowledge available in a large collection of EEG reports. © 2019 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Maldonado2019Active
ER  -

TY  - JOUR
AU  - Bianco, S.
AU  - Mazzini, D.
AU  - Napoletano, P.
AU  - Schettini, R.
TI  - Multitask painting categorization by deep multibranch neural network
PY  - 2019
T2  - Expert Systems with Applications
VL  - 135
SP  - 90
EP  - 101
DO  - 10.1016/j.eswa.2019.05.036
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067171418&doi=10.1016%2fj.eswa.2019.05.036&partnerID=40&md5=e07108a7476ad8384799a46aee0bdc93
AB  - We propose a novel deep multibranch and multitask neural network for artist, style, and genre painting categorization. The multibranch approach allows us to exploit at the same time the coarse layout of the painting and the fine-grained structures by using painting crops at different resolutions that are wisely extracted using a Spatial Transformer Network trained to identify the most discriminative subregions of paintings. The effectiveness of the proposed network is proved in experiments that are performed on a new dataset originally sourced from wikiart.org and hosted by Kaggle, and made suitable for artist, style and genre multitask learning. The dataset here proposed and made available for research is named MultitaskPainting100k, and is composed by 100K paintings, 1508 artists, 125 styles and 41 genres annotated by human experts. Among the different variants of the proposed network, the best method achieves accuracy levels of 56.5%, 57.2%, and 63.6% on the MultitaskPainting100k dataset for the tasks of artist, style and genre prediction respectively. © 2019 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Bianco2019Multitask
ER  -

TY  - JOUR
AU  - Duan, Z.
AU  - Tan, S.
AU  - Zhao, S.
AU  - Wang, Q.
AU  - Chen, J.
AU  - Zhang, Y.
TI  - Reviewer assignment based on sentence pair modeling
PY  - 2019
T2  - Neurocomputing
VL  - 366
SP  - 97
EP  - 108
DO  - 10.1016/j.neucom.2019.06.074
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072716992&doi=10.1016%2fj.neucom.2019.06.074&partnerID=40&md5=3f71a9cc94d4aecc9a70837a7909875e
AB  - Assigning appropriate reviewers to a manuscript from a pool of candidate reviewers is an important task in the academic community. Recent researches have focused mainly on text processing methods based on natural language processing, such as topic model, word embedding and so on. However, it is difficult for the computer to understand the research fields of reviewers and manuscripts. In this paper, a novel supervisory information that is expressed as sentence pairs constructed by titles and abstracts is adopted to solve reviewer assignment problem. We propose a sentence pair modeling-based reviewer assignment (SPM-RA) method, which models the relationship of sentence pairs by supervising information. The supervisory information makes the model accurately learn the field features of reviewers and manuscripts. Firstly, we construct the training set by the field relationship between title and abstract. We use TF-IDF sampling to solve the problem of unbalanced data set. Then, we use neural network models, such as the BERT (bidirectional encoder representations from transformers), CNN (convolution neural network), biLSTM (bidirectional long short term memory), or various combinations of them to do modeling sentence pair and learn the field features of the paper through the training set. Finally, we predict the similarity between reviewers and manuscripts by training model. We evaluate SPM-RA on two real datasets and compare its performance to that of seven existing methods. The experimental results show that SPM-RA improves the recommendation precision by at least 18% on the public dataset. © 2019 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:C期刊; 
LB  - Duan2019Reviewer
ER  -

TY  - JOUR
AU  - Lu, J.
AU  - Hu, W.
AU  - Sun, Y.
TI  - A deep learning method for image super-resolution based on geometric similarity
PY  - 2019
T2  - Signal Processing: Image Communication
VL  - 70
SP  - 210
EP  - 219
DO  - 10.1016/j.image.2018.10.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055704553&doi=10.1016%2fj.image.2018.10.003&partnerID=40&md5=c0b694f9a6da172f82c84345d68c772d
AB  - A single image super-resolution (SR) algorithm that combines deep convolutional neural networks (CNNs) with multi-scale similarity is presented in this work. The aim of this method is to address the incapability of the existing CNN methods in digging the potential information in the image itself. In order to dig these information, the image patches that look similar within the same scale and across the different scales are firstly searched inside the input image. Subsequently, a spatial transform networks (STNs) are embedded into the CNNs to make the similar patches well aligned. The STNs allow the CNNs to have the ability of spatial manipulation of data. Finally, when SR is performing through the proposed pyramid-shaped CNNs, the high-resolution (HR) image will be predicted gradually according to the complementary information provided by these aligned patches. The experimental results confirm the effectiveness of the proposed method and demonstrate it can be compared with state-of-the-art approaches for single image SR. © 2018 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:C期刊; 
LB  - Lu2019deep
ER  -

TY  - JOUR
AU  - Lu, X.
AU  - Ni, B.
AU  - Ma, C.
AU  - Yang, X.
TI  - Learning transform-aware attentive network for object tracking
PY  - 2019
T2  - Neurocomputing
VL  - 349
SP  - 133
EP  - 144
DO  - 10.1016/j.neucom.2019.02.021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064265628&doi=10.1016%2fj.neucom.2019.02.021&partnerID=40&md5=d9df833632f88e1e1791e6c9ce513275
AB  - Existing trackers often decompose the task of visual tracking into multiple independent components, such as target appearance sampling, classifier learning, and target state inferring. In this paper, we present a transform-aware attentive tracking framework, which uses a deep attentive network to directly predict the target states via spatial transform parameters. During off-line training, the proposed network learns generic motion patterns of target objects from auxiliary large-scale videos. These leaned motion patterns are then applied to track target objects on test sequences. Built on the Spatial Transform Network (STN), the proposed attentive network is fully differentiable and can be trained in an end-to-end manner. Notably, we only fine-tune the pre-trained network in the initial frame. The proposed tracker requires neither online model update nor appearance sampling during the tracking process. Extensive experiments on OTB-2013, OTB-2015, VOT-2014 and UAV-123 datasets demonstrate the competitive performance of our method against state-of-the-art attentive tracking methods. © 2019
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 30
C2  - CCF:C期刊; 
LB  - Lu2019Learning
ER  -

TY  - JOUR
AU  - Vigneault, D.M.
AU  - Xie, W.
AU  - Ho, C.Y.
AU  - Bluemke, D.A.
AU  - Noble, J.A.
TI  - Ω-Net (Omega-Net): Fully automatic, multi-view cardiac MR detection, orientation, and segmentation with deep neural networks
PY  - 2018
T2  - Medical Image Analysis
VL  - 48
SP  - 95
EP  - 106
DO  - 10.1016/j.media.2018.05.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047610606&doi=10.1016%2fj.media.2018.05.008&partnerID=40&md5=1e5d602932ac3fc7473940e57a55164f
AB  - Pixelwise segmentation of the left ventricular (LV) myocardium and the four cardiac chambers in 2-D steady state free precession (SSFP) cine sequences is an essential preprocessing step for a wide range of analyses. Variability in contrast, appearance, orientation, and placement of the heart between patients, clinical views, scanners, and protocols makes fully automatic semantic segmentation a notoriously difficult problem. Here, we present Ω-Net (Omega-Net): A novel convolutional neural network (CNN) architecture for simultaneous localization, transformation into a canonical orientation, and semantic segmentation. First, an initial segmentation is performed on the input image; second, the features learned during this initial segmentation are used to predict the parameters needed to transform the input image into a canonical orientation; and third, a final segmentation is performed on the transformed image. In this work, Ω-Nets of varying depths were trained to detect five foreground classes in any of three clinical views (short axis, SA; four-chamber, 4C; two-chamber, 2C), without prior knowledge of the view being segmented. This constitutes a substantially more challenging problem compared with prior work. The architecture was trained using three-fold cross-validation on a cohort of patients with hypertrophic cardiomyopathy (HCM, N=42) and healthy control subjects (N=21). Network performance, as measured by weighted foreground intersection-over-union (IoU), was substantially improved for the best-performing Ω-Net compared with U-Net segmentation without localization or orientation (0.858 vs 0.834). In addition, to be comparable with other works, Ω-Net was retrained from scratch using five-fold cross-validation on the publicly available 2017 MICCAI Automated Cardiac Diagnosis Challenge (ACDC) dataset. The Ω-Net outperformed the state-of-the-art method in segmentation of the LV and RV bloodpools, and performed slightly worse in segmentation of the LV myocardium. We conclude that this architecture represents a substantive advancement over prior approaches, with implications for biomedical image segmentation more generally. © 2018
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 119
C2  - CCF:C期刊; 
LB  - Vigneault2018Ω-Net
ER  -

TY  - JOUR
AU  - Rafiei, M.
AU  - Niknam, T.
AU  - Khooban, M.-H.
TI  - Probabilistic Forecasting of Hourly Electricity Price by Generalization of ELM for Usage in Improved Wavelet Neural Network
PY  - 2017
T2  - IEEE Transactions on Industrial Informatics
VL  - 13
IS  - 1
C7  - 7500086
SP  - 71
EP  - 79
DO  - 10.1109/TII.2016.2585378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013350175&doi=10.1109%2fTII.2016.2585378&partnerID=40&md5=0c1c0ac1c9551cf0a7f98e551905bcc8
AB  - In restructured markets where transactions process is competitive, forecasting of electricity price is inevitably an important available tool for market participants. Due to the sensitivity of forecasting issues in market's performance, and high prediction error resulted from the behavior of price series, nowadays probabilistic forecasting highly attracted participants' attention. In this paper, a probabilistic approach for the hourly electricity price forecasting is presented. In the proposed method, the uncertainty of predictor model is considered as the uncertainty factor. The bootstrapping technique is used to implement the uncertainty and since the method is needed to be fast and of low computational cost in the daily forecasting, a generalized learning method is applied, which has high accuracy and speed. This newly presented learning method is based on generalized extreme learning machine approach to be used for improved wavelet neural networks. Also in order to reach more accommodation, the predictor model with the changes of price time series, the wavelet preprocessing is used. Effective performance of the proposed model is validated by testing on data of Ontario and Australian electricity markets. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 115
C2  - CCF:C期刊; 
LB  - Rafiei2017Probabilistic
ER  -

TY  - JOUR
AU  - Chaudhari, S.S.
AU  - Biradar, R.C.
TI  - Traffic and mobility aware resource prediction using cognitive agent in mobile ad hoc networks
PY  - 2016
T2  - Journal of Network and Computer Applications
VL  - 72
SP  - 87
EP  - 103
DO  - 10.1016/j.jnca.2016.06.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989815364&doi=10.1016%2fj.jnca.2016.06.010&partnerID=40&md5=16328fefe3b4c25dc160d78bc2a12831
AB  - Mobile Ad hoc NETwork (MANET) characteristics such as limited resources, shared channel, unpredictable mobility, improper load balancing, and variation in signal strength affect the routing of real-time multimedia data that requires Quality of Service (QoS) provisioning. Accurate prediction of the resource availability assists efficient resource allocation before the routing of such data. Most of the published work on resource prediction in MANET focuses on either bandwidth or energy without considering mobility effects. Adoption of intelligent software agent such as Cognitive Agent (CA) for the accurate resource prediction has a significant potential to solve the challenges of resource prediction in MANET. The intelligence provided in CA is similar to the logical thinking like a human for decision-making. The predominant CA architecture is the Belief-Desire-Intention (BDI) model, which performs the various tasks on behalf of the human user as an assistant. In this paper, we propose a CA-based Resource Prediction mechanism considering Mobility (CA-RPM) that predicts the resources using agents through the resource prediction agency consisting of one static agent, one cognitive agent and two mobile agents. Agents predict the traffic, mobility, buffer space, energy, and bandwidth effectively that is necessary for efficient resource allocation to support real-time and multimedia communications. The mobile agents collect and distribute network traffic statistics over MANET whereas a static agent collects the local statistics. CA creates static/mobile agent during the process of resource prediction. Initially, the designed time-series Wavelet Neural Networks (WNNs) predict traffic and mobility. Buffer space, energy, and bandwidth prediction use the predicted mobility and traffic. Simulation results show that the predicted resources closely match with the real values at the cost of little overheads due to the usage of agents. Simulation analysis of predicted traffic and mobility also shows the improvement compared to recurrent WNN in terms of mean square error, covariance, memory overhead, agent overhead and computation overhead. We plan to use these predicted resources for its efficient utilization in QoS routing is our future work. © 2016 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:C期刊; 
LB  - Chaudhari2016Traffic
ER  -

TY  - JOUR
AU  - Sahri, Z.
AU  - Yusof, R.
AU  - Watada, J.
TI  - FINNIM: Iterative imputation of missing values in dissolved gas analysis dataset
PY  - 2014
T2  - IEEE Transactions on Industrial Informatics
VL  - 10
IS  - 4
C7  - 6882199
SP  - 2093
EP  - 2102
DO  - 10.1109/TII.2014.2350837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909951993&doi=10.1109%2fTII.2014.2350837&partnerID=40&md5=9e8923166a288f19f714d211c235d530
AB  - Missing values are a common occurrence in a number of real world databases, and statistical methods have been developed to deal with this problem, referred to as missing data imputation. In the detection and prediction of incipient faults in power transformers using dissolved gas analysis (DGA), the problem of missing values is significant and has resulted in inconclusive decision-making. This study proposes an efficient nonparametric iterative imputation method named FINNIM, which comprises of three components: 1) the imputation ordering; 2) the imputation estimator; and 3) the iterative imputation. The relationship between gases and faults, and the percentage of missing values in an instance are used as a basis for the imputation ordering; whereas the plausible values for the missing values are estimated from bm{k}-nearest neighbor instances in the imputation estimator, and the iterative imputation allows complete and incomplete instances in a DGA dataset to be utilized iteratively for imputing all the missing values. Experimental results on both artificially inserted and actual missing values found in a few DGA datasets demonstrate that the proposed method outperforms the existing methods in imputation accuracy, classification performance, and convergence criteria at different missing percentages. © 2014 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 49
C2  - CCF:C期刊; 
LB  - Sahri2014FINNIM
ER  -

TY  - JOUR
AU  - Bessa, R.J.
AU  - Trindade, A.
AU  - Miranda, V.
TI  - Spatial-temporal solar power forecasting for smart grids
PY  - 2015
T2  - IEEE Transactions on Industrial Informatics
VL  - 11
IS  - 1
C7  - 6939731
SP  - 232
EP  - 241
DO  - 10.1109/TII.2014.2365703
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922994684&doi=10.1109%2fTII.2014.2365703&partnerID=40&md5=7107eba74905d350e406fb49498642d7
AB  - The solar power penetration in distribution grids is growing fast during the last years, particularly at the low-voltage (LV) level, which introduces new challenges when operating distribution grids. Across the world, distribution system operators (DSO) are developing the smart grid concept, and one key tool for this new paradigm is solar power forecasting. This paper presents a new spatial-temporal forecasting method based on the vector autoregression framework, which combines observations of solar generation collected by smart meters and distribution transformer controllers. The scope is 6-h-ahead forecasts at the residential solar photovoltaic and medium-voltage (MV)/LV substation levels. This framework has been tested in the smart grid pilot of Évora, Portugal, and using data from 44 microgeneration units and 10 MV/LV substations. A benchmark comparison was made with the autoregressive forecasting model (AR - univariate model) leading to an improvement on average between 8% and 10%. © 2005-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 148
C2  - CCF:C期刊; 
LB  - Bessa2015Spatial-temporal
ER  -

TY  - JOUR
AU  - Kodogiannis, V.S.
AU  - Amina, M.
AU  - Petrounias, I.
TI  - A clustering-based fuzzy wavelet neural network model for short-term load forecasting
PY  - 2013
T2  - International Journal of Neural Systems
VL  - 23
IS  - 5
C7  - 1350024
DO  - 10.1142/S012906571350024X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882243892&doi=10.1142%2fS012906571350024X&partnerID=40&md5=a7d6a187850ff31553105ec307721a4c
AB  - Load forecasting is a critical element of power system operation, involving prediction of the future level of demand to serve as the basis for supply and demand planning. This paper presents the development of a novel clustering-based fuzzy wavelet neural network (CB-FWNN) model and validates its prediction on the short-term electric load forecasting of the Power System of the Greek Island of Crete. The proposed model is obtained from the traditional Takagi-Sugeno-Kang fuzzy system by replacing the THEN part of fuzzy rules with a «multiplication» wavelet neural network (MWNN). Multidimensional Gaussian type of activation functions have been used in the IF part of the fuzzyrules. A Fuzzy Subtractive Clustering scheme is employed as a pre-processing technique to find out the initial set and adequate number of clusters and ultimately the number of multiplication nodes in MWNN, while Gaussian Mixture Models with the Expectation Maximization algorithm are utilized for the definition of the multidimensional Gaussians. The results corresponding to the minimum and maximum power load indicate that the proposed load forecasting model provides significantly accurate forecasts, compared to conventional neural networks models. © 2013 World Scientific Publishing Company.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 78
C2  - CCF:C期刊; 
LB  - Kodogiannis2013clustering-based
ER  -

TY  - JOUR
AU  - Du Toit, D.
AU  - Mouton, H.D.T.
AU  - Kennel, R.
AU  - Stolze, P.
TI  - Predictive control of series stacked flying-capacitor active rectifiers
PY  - 2013
T2  - IEEE Transactions on Industrial Informatics
VL  - 9
IS  - 2
SP  - 697
EP  - 707
DO  - 10.1109/TII.2012.2224875
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889241237&doi=10.1109%2fTII.2012.2224875&partnerID=40&md5=cebe6e31efa9afee71226d5d6180d37a
AB  - This paper considers the use of back-to-back, full-bridge, three-level flying-capacitor converters in a series- input-parallel-output connected fashion for the implementation of a solid-state transformer. A finite-control-set model-based predictive control algorithm is developed for the control of the active rectifier front-ends. Pulse width modulation is used for the isolation back-ends. A solid-state transformer is constructed with two of the proposed back-to-back converters and experimental results are presented. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:C期刊; 
LB  - Du Toit2013Predictive
ER  -

TY  - JOUR
AU  - Amina, M.
AU  - Kodogiannis, V.S.
AU  - Petrounias, I.P.
AU  - Lygouras, J.N.
AU  - Nychas, G.-J.E.
TI  - Identification of the Listeria monocytogenes survival curves in UHT whole milk utilising local linear wavelet neural networks
PY  - 2012
T2  - Expert Systems with Applications
VL  - 39
IS  - 1
SP  - 1435
EP  - 1450
DO  - 10.1016/j.eswa.2011.08.028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855201898&doi=10.1016%2fj.eswa.2011.08.028&partnerID=40&md5=6a83014a6727b89cdaedb5b1aa0d49e0
AB  - The aim of the present work is to investigate the capabilities of a wavelet neural network for describing the inactivation pattern of Listeria monocytogenes by high hydrostatic pressure in milk, and to compare its performance against classic neural network architectures and models utilised in food microbiology. A new wavelet network is being proposed that includes a "product operation" layer between wavelet functions and output layer, while the connection output-layer weights have been replaced by a local linear model. Milk was artificially inoculated with an initial population of the pathogen and exposed to a range of high pressures (350, 450, 550, 600 MPa) for up to 40 min at ambient temperature (25 °C). Models were validated at 400 and 500 MPa with independent experimental data. First or second order polynomial models were employed to relate the inactivation parameters to pressure, whereas all learning-based networks were utilised in a standard identification approach. The prediction performance of the proposed local linear wavelet network was better at both validation pressures. The development of accurate models to describe the survival curves of microorganisms in high pressure treatment would be very important to the food industry for process optimisation, food safety and would eventually expand the applicability of this non-thermal process. © 2011 Elsevier Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Amina2012Identification
ER  -

TY  - JOUR
AU  - Souza, L.M.
AU  - Lemos, A.P.
AU  - Caminhas, W.M.
AU  - Boaventura, W.C.
TI  - Thermal modeling of power transformers using evolving fuzzy systems
PY  - 2012
T2  - Engineering Applications of Artificial Intelligence
VL  - 25
IS  - 5
SP  - 980
EP  - 988
DO  - 10.1016/j.engappai.2011.12.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862136659&doi=10.1016%2fj.engappai.2011.12.007&partnerID=40&md5=802ea8bcc85bc9a6aea1c43885874c3a
AB  - Thermal models for distribution transformers with core immersed in oil are of utmost importance for transformers lifetime study. The hot spot temperature determines the degradation speed of the insulating paper. High temperatures cause loss of mechanical stiffness, generating failures. Since the paper is the most fragile component of the transformer, its degradation determines the lifetime limits. Thus, good thermal models are needed to generate reliable data for lifetime forecasting methodologies. It is also desired that thermal models are able to adapt to cope with changes in the transformer behavior due to structural changes, maintenance and so on. In this work we apply an evolving fuzzy model to build adaptive thermal models of distribution transformers. The model used is able to adapt its parameters and also its structure based on a stream of data. The proposed model is evaluated using actual data from an experimental transformer. The results suggest that evolving fuzzy models are a promising approach for adaptive thermal modeling of distribution transformers. © 2012 Elsevier Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:C期刊; 
LB  - Souza2012Thermal
ER  -

TY  - JOUR
AU  - Lin, C.-H.
AU  - Chen, J.-L.
AU  - Huang, P.-Z.
TI  - Dissolved gases forecast to enhance oil-immersed transformer fault diagnosis with grey prediction-clustering analysis
PY  - 2011
T2  - Expert Systems
VL  - 28
IS  - 2
SP  - 123
EP  - 137
DO  - 10.1111/j.1468-0394.2010.00542.x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955055263&doi=10.1111%2fj.1468-0394.2010.00542.x&partnerID=40&md5=39986fc7eeb47ff22656f79d6eb23a3e
AB  - A method is proposed for dissolved gases forecast and fault diagnosis in oil-immersed transformers using grey prediction-clustering analysis. Incipient faults can produce hydrocarbon molecules and carbon oxides due to the thermal decomposition of mineral oil, cellulose and other solid insulation. Dissolved gas analysis is employed to detect and monitor abnormal conditions in oil-immersed power transformers. However, the procedure takes a long time to decompose overall key gases and monitor conditions. The grey prediction GM(1, 2) model uses the variant information of hydrogen to forecast the further trends of both combustible and non-combustible gases. Grey clustering analysis is applied to diagnose internal faults including thermal faults, electrical faults and faults involving cellulose degradation. Numerical tests with field gas records were conducted to show the effectiveness of the proposed model, and are easy to implement with the help of portable devices. © 2010 Blackwell Publishing Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:C期刊; FMS:C; AJG:2; zdy:2; 
LB  - Lin2011Dissolved
ER  -

TY  - JOUR
AU  - Umurkan, N.
AU  - Koroglu, S.
AU  - Kilic, O.
AU  - Adam, A.A.
TI  - A neural network based estimation method for magnetic shielding at extremely low frequencies
PY  - 2010
T2  - Expert Systems with Applications
VL  - 37
IS  - 4
SP  - 3195
EP  - 3201
DO  - 10.1016/j.eswa.2009.09.062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-71349085712&doi=10.1016%2fj.eswa.2009.09.062&partnerID=40&md5=f0dd0cac8ddafe9e2644c9cea1ccc4b1
AB  - The attenuation of extremely low-frequency magnetic fields is important in reducing electromagnetic interference on electric and electronic equipment. In this paper, an innovative method is presented for shielded magnetic field level estimation at power frequencies by a neural network (NN) technique which uses experimental data. The utilized NN is applied to cylindrical shields (transformer-grade iron, copper, and aluminum) in various shield arrangements. Using the developed NN model, the mitigated magnetic field of multilayered shields is measured and evaluated to predict the magnetic field at any distance apart from the magnetic source. The NN, which is based on a feed-forward neural network (FNN), is trained with scaled conjugate gradient, gradient descent with momentum and adaptive learning back propagation, and Levenberg-Marquardt algorithms to compute the shielded magnetic field. Results have shown that the developed FNN trained with the Levenberg-Marquardt algorithm is better than the other training algorithms in predicting the shielded magnetic field value accurately even in the presence of various shield arrangements. © 2009 Elsevier Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Umurkan2010neural
ER  -

TY  - JOUR
AU  - Cao, J.
AU  - Lin, Z.
AU  - Huang, G.-B.
TI  - Composite function wavelet neural networks with extreme learning machine
PY  - 2010
T2  - Neurocomputing
VL  - 73
IS  - 7-9
SP  - 1405
EP  - 1416
DO  - 10.1016/j.neucom.2009.12.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649238806&doi=10.1016%2fj.neucom.2009.12.007&partnerID=40&md5=3040091f4043f95ef7656c5d2225905d
AB  - A new structure of wavelet neural networks (WNN) with extreme learning machine (ELM) is introduced in this paper. In the proposed wavelet neural networks, composite functions are applied at the hidden nodes and the learning is done using ELM. The input information is first processed by wavelet functions and then passed through a type of bounded nonconstant piecewise continuous activation functions g : R → R. A selection method that takes into account the domain of input space where the wavelets are not zero is used to initialize the translation and dilation parameters. The formed wavelet neural network is then trained with the computationally efficient ELM algorithm. Experimental results on the regression of some nonlinear functions and real-world data, the prediction of a chaotic signal and classifications on serval benchmark real-world data sets show that the proposed neural networks can achieve better performances in most cases than some relevant neural networks and learn much faster than neural networks training with the traditional back-propagation (BP) algorithm. © 2009 Elsevier B.V. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 94
C2  - CCF:C期刊; 
LB  - Cao2010Composite
ER  -

TY  - JOUR
AU  - Jana, A.K.
TI  - A hybrid FLC-EKF scheme for temperature control of a refinery debutanizer column
PY  - 2010
T2  - IEEE Transactions on Industrial Informatics
VL  - 6
IS  - 1
C7  - 5337967
SP  - 25
EP  - 35
DO  - 10.1109/TII.2009.2034514
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-76849096286&doi=10.1109%2fTII.2009.2034514&partnerID=40&md5=1ddd89b572d26888e954ae32c931ae1a
AB  - A nonlinear feedback linearizing control (FLC) strategy is proposed within the differential geometric framework for temperature control of a refinery debutanizer column. The distillation model is verified by real data. The FLC control algorithm usually consists of a transformer, a state estimator and an external linear controller. Here, two state estimators, namely extended Kalman filter (EKF) and short-cut model-based open-loop estimator (SMBOLE), have been developed to device the hybrid FLC-EKF and FLC-SMBOLE control systems, respectively. In order to avoid estimator design complexity as well as computational burden, an ideal binary distillation model [light key (LK)/heavy key (HK)] has been used as an EKF predictor and open-loop estimator (OLE). In this article, a comparative study has been conducted between the FLC-EKF, FLC-SMBOLE and a classical dual-loop proportional integral derivative (PID) control structure. Simulation results show that despite the significant process/model mismatch, the proposed FLC controllers perform better than the PID control scheme. © 2009 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:C期刊; 
LB  - Jana2010hybrid
ER  -

TY  - JOUR
AU  - Chauhan, N.
AU  - Ravi, V.
AU  - Karthik Chandra, D.
TI  - Differential evolution trained wavelet neural networks: Application to bankruptcy prediction in banks
PY  - 2009
T2  - Expert Systems with Applications
VL  - 36
IS  - 4
SP  - 7659
EP  - 7665
DO  - 10.1016/j.eswa.2008.09.019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-60249090307&doi=10.1016%2fj.eswa.2008.09.019&partnerID=40&md5=ec10bc7843fc7b00ac231da233c0c8d4
AB  - In this study, differential evolution algorithm (DE) is proposed to train a wavelet neural network (WNN). The resulting network is named as differential evolution trained wavelet neural network (DEWNN). The efficacy of DEWNN is tested on bankruptcy prediction datasets viz. US banks, Turkish banks and Spanish banks. Further, its efficacy is also tested on benchmark datasets such as Iris, Wine and Wisconsin Breast Cancer. Moreover, Garson's algorithm for feature selection in multi layer perceptron is adapted in the case of DEWNN. The performance of DEWNN is compared with that of threshold accepting trained wavelet neural network (TAWNN) [Vinay Kumar, K., Ravi, V., Mahil Carr, & Raj Kiran, N. (2008). Software cost estimation using wavelet neural networks. Journal of Systems and Software] and the original wavelet neural network (WNN) in the case of all data sets without feature selection and also in the case of four data sets where feature selection was performed. The whole experimentation is conducted using 10-fold cross validation method. Results show that soft computing hybrids viz., DEWNN and TAWNN outperformed the original WNN in terms of accuracy and sensitivity across all problems. Furthermore, DEWNN outscored TAWNN in terms of accuracy and sensitivity across all problems except Turkish banks dataset. © 2008 Elsevier Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 179
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Chauhan2009Differential
ER  -

TY  - JOUR
AU  - Fei, S.-w.
AU  - Liu, C.-l.
AU  - Miao, Y.-b.
TI  - Support vector machine with genetic algorithm for forecasting of key-gas ratios in oil-immersed transformer
PY  - 2009
T2  - Expert Systems with Applications
VL  - 36
IS  - 3 PART 2
SP  - 6326
EP  - 6331
DO  - 10.1016/j.eswa.2008.08.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-58349107243&doi=10.1016%2fj.eswa.2008.08.012&partnerID=40&md5=db21c19ebf6ee21f34b3d44e63b98c73
AB  - Failures of power transformer are related with key-gas ratios C2H2/C2H4, CH4/H2 and C2H4/C2H6 strongly. Forecasting of these ratios of key-gas in power transformer oil is very significant to detect and identify incipient failures of transformer early. Forecasting of the ratios of key-gas in power transformer oil is a complicated problem due to its non-linearity and the small quantity of training data. In this study, support vector machine with genetic algorithm (SVMG) is proposed to forecast the ratios of key-gas in power transformer oil, among which genetic algorithm (GA) is used to determine free parameters of support vector machine. The experimental results indicate that the SVMG method can achieve greater accuracy than grey model, artificial neural network under the circumstance of small training data. Consequently, the SVMG model is a proper alternative for forecasting of the ratios of key-gas in power transformer oil. © 2008 Elsevier Ltd. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 55
C2  - CCF:C期刊; FMS:C; AJG:1; zdy:1; 
LB  - Fei2009Support
ER  -

TY  - JOUR
AU  - Georgilakis, P.S.
AU  - Hatziargyriou, N.D.
AU  - Doulamis, N.D.
AU  - Doulamis, A.D.
AU  - Kollias, S.D.
TI  - Prediction of iron losses of wound core distribution transformers based on artificial neural networks
PY  - 1998
T2  - Neurocomputing
VL  - 23
IS  - 1-3
SP  - 15
EP  - 29
DO  - 10.1016/S0925-2312(98)00071-X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032495057&doi=10.1016%2fS0925-2312%2898%2900071-X&partnerID=40&md5=7d12117081de0b3514fd237709f9c73b
AB  - This paper presents an artificial neural network (ANN) approach to predicting and classifying distribution transformer specific iron losses, i.e., losses per weight unit. The ANN is trained to learn the relationship of several parameters affecting iron losses. For this reason, the ANN learning and testing sets are formed using actual industrial measurements, obtained from previous completed transformer constructions. Data comprise grain oriented steel electrical characteristics, cores constructional parameters, quality control measurements of cores production line and transformers assembly line measurements. It is shown that an average absolute error of 2.32% has been achieved in the prediction of individual core specific iron losses and an error of 2.2% in case of transformer specific losses. This is compared with average errors of 5.7% and 4.0% in prediction of specific iron losses of individual core and transformer, respectively, obtained by the current practice applying the typical loss curve to the same data.; This paper presents an artificial neural network (ANN) approach to predicting and classifying distribution transformer specific iron losses, i.e., losses per weight unit. The ANN is trained to learn the relationship of several parameters affecting iron losses. For this reason, the ANN learning and testing sets are formed using actual industrial measurements, obtained from previous completed transformer constructions. Data comprise grain oriented steel electrical characteristics, cores constructional parameters, quality control measurements of cores production line and transformers assembly line measurements. It is shown that an average absolute error of 2.32% has been achieved in the prediction of individual core specific iron losses and an error of 2.2% in case of transformer specific losses. This is compared with average errors of 5.7% and 40% in prediction of specific iron losses of individual core and transformer, respectively, obtained by the current practice applying the typical loss curve to the same data.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; 
LB  - Georgilakis1998Prediction
ER  -

TY  - JOUR
AU  - Kumar, B.
AU  - Dutta Roy, S.C.
AU  - Sabharwal, S.
TI  - Interrelations between the coefficients of FIR digital differentiators and other FIR filters and a versatile multifunction configuration
PY  - 1994
T2  - Signal Processing
VL  - 39
IS  - 3
SP  - 247
EP  - 262
DO  - 10.1016/0165-1684(94)90088-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028514268&doi=10.1016%2f0165-1684%2894%2990088-4&partnerID=40&md5=eaaccd1c2d7c1380c0a759ab70c149a9
AB  - Interrelationships between seven types of digital FIR filters, viz. the differentiators (DD), Hilbert transformers, half-band lowpass/highpass filters, bandpass/bandstop filters and frequency discriminators, have been established. It has been shown that all the aforementioned filters can be derived from the design of a DD. If we use the optimality criteria of maximal linearity of the frequency response of a differentiator, the proposed relations yield maximally flat/linear frequency responses for the remaining six filters. Similarly, an equiripple relative error design of a DD gives equiripple filters through the use of the suggested interrelations. A versatile, multipurpose, FIR configuration has also been proposed which yeilds optimal frequency response for all the seven types of digital filters. The suggested design is shown to be particularly useful for operation over the frequency ranges 0 {slanted equal to or less-than} ω {slanted equal to or less-than} 0.50π (0.5π {slanted equal to or less-than} ω {slanted equal to or less-than} π) for lowpass (highpass) filters and 0.25π {slanted equal to or less-than} ω {slanted equal to or less-than} 0.75π for the remaining ones. Mathematical formulas for computing the weights of aforementioned filters have also been derived. Possible uses of the suggested design have been given. © 1994.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; 
LB  - Kumar1994Interrelations
ER  -

TY  - JOUR
AU  - Misra, R.
AU  - Pandey, S.
AU  - Sundaresan, V.
TI  - Reliability prediction of solid dielectrics using electrial noise as a screening parameter
PY  - 1991
T2  - IEEE Transactions on Reliability
VL  - 40
IS  - 1
SP  - 113
EP  - 116
DO  - 10.1109/24.75346
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026135789&doi=10.1109%2f24.75346&partnerID=40&md5=a39f6ec106220cc9c54ab5a6c462d885
AB  - Conclusions - This paper reports the use of electrical noise for the screening of dielectric sheet material for reliability. Results indicate that high-noise units have a greater failure rate compared to low noise units when subjected to identical voltage and temperature stresses. Solid dielectric sheet materials and small transformers were tested. Measurement of electrical noise in a dielectric will be useful in reliability screening and preventive maintenance.The problem to be solved in a given machine or component, is how to probe for the noise that may be generated at a given spot and then locate that spot precisely. © 1991 IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; 
LB  - Misra1991Reliability
ER  -

TY  - JOUR
AU  - Pei, S.-C.
AU  - Shyu, J.-J.
TI  - Design of real FIR filters with arbitrary complex frequency responses by two real Chebyshev approximations
PY  - 1992
T2  - Signal Processing
VL  - 26
IS  - 1
SP  - 119
EP  - 129
DO  - 10.1016/0165-1684(92)90058-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026747978&doi=10.1016%2f0165-1684%2892%2990058-5&partnerID=40&md5=97b008e654e9c881106d9e19269bfd07
AB  - Since the real coefficients of a FIR filter with arbitrary complex-valued desired frequency responses are neither symmetric nor antisymmetric, the Remez exchange algorithm cannot be applied directly. The problem can be solved by dividing the original complex approximation into two real ones such that the Remez exchange algorithm can be applied by slightly modifying the Parks-McClellan program. This method is much easier than the currently existing methods using linear programming or complex Chebyshev approximation, and the performance is satisfactory. More importantly, the magnitudes of the resultant complex errors are also equiripple as the direct complex Chebyshev approximation designs. Several numerical examples including a low-pass filter, a full-band differentiator, a wide-band Hilbert transformer, and a chirp-delay and sine-delay FIR all-pass phase equalizer are given to show the effectiveness of this approach. © 1992.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:C期刊; 
LB  - Pei1992Design
ER  -
