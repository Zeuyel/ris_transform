TY  - JOUR
AU  - Sharma, N.
AU  - Dhiman, C.
AU  - Indu, S.
TI  - Predicting pedestrian intentions with multimodal IntentFormer: A Co-learning approach
PY  - 2025
T2  - Pattern Recognition
VL  - 161
C7  - 111205
DO  - 10.1016/j.patcog.2024.111205
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211072830&doi=10.1016%2fj.patcog.2024.111205&partnerID=40&md5=7513f2378741d24759a01dc00471e42b
AB  - The prediction of pedestrian crossing intention is a crucial task in the context of autonomous driving to ensure traffic safety and reduce the risk of accidents without human intervention. Nevertheless, the complexity of pedestrian behaviour, which is influenced by numerous contextual factors in conjunction with visual appearance cues and past trajectory, poses a significant challenge. Several state-of-the-art approaches have recently emerged that incorporate multiple modalities. Nonetheless, the suboptimal modality integration techniques in these approaches fail to capture the intricate intermodal relationships and robustly represent pedestrian-environment interactions in challenging scenarios. To address these issues, a novel Multimodal IntentFormer architecture is presented. It works with three transformer encoders {TEI,TEII,TEIII} which learn RGB, segmentation maps, and trajectory paths in a co-learning environment controlled by a Co-learning module. A novel Co-learning Adaptive Composite (CAC) loss function is also proposed, which penalizes different stages of the architecture, regularizes the model, and mitigates the risk of overfitting. Each encoder {TEη} applies the concept of the Multi-Head Shared Weight Attention (MHSWA) mechanism while learning three modalities in the proposed co-learning approach. The proposed architecture outperforms existing state-of-the-art approaches on benchmark datasets, PIE and JAAD, with 93 % and 92 % accuracy, respectively. Furthermore, extensive ablation studies demonstrate the efficiency and robustness of the architecture, even under varying Time-to-event (TTE) and observation lengths. The code is available at https://github.com/neha013/IntentFormer © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Feng, M.
AU  - Yang, Y.
AU  - Zhou, W.
AU  - Li, H.
TI  - TIMAR: Transition-informed representation for sample-efficient multi-agent reinforcement learning
PY  - 2025
T2  - Neural Networks
VL  - 184
C7  - 107081
DO  - 10.1016/j.neunet.2024.107081
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214107617&doi=10.1016%2fj.neunet.2024.107081&partnerID=40&md5=00b61856b8d7fc5aa5cb0775a5783c5b
AB  - In MARL (Multi-Agent Reinforcement Learning), the trial-and-error learning paradigm based on multiple agents requires massive interactions to produce training samples, significantly increasing both the training cost and difficulty. Therefore, enhancing data efficiency is a core issue in MARL. However, in the context of MARL, agent partially observed information leads to a lack of consideration for agent interactions and coordination from an ego perspective under the world model, which becomes the main obstacle to improving the data efficiency of current proposed MARL methods. To address this, motivated by the success of learning a world model in RL and cognitive science, we devise a world-model-driven learning paradigm enabling agents to gain a more holistic representation of individual observation of the environment. Specifically, we present the Transition-Informed Multi-Agent Representations (TIMAR) framework, which leverages the joint transition model, i.e., a surrogate world model that captures the dynamics of the multi-agent system, to learn effective representations among agents through a self-supervised learning objective. This objective encourages consistency between predicted and actual future observations, allowing the model to learn without explicit labels. TIMAR incorporates an auxiliary module to predict future transitions based on sequential observations and actions, allowing agents to infer the latent state of the system and consider the influences of others. Unlike traditional MARL approaches that primarily focus on efficient policy improvement, TIMAR is designed to learn a useful semantic representation from high-dimensional observations. This enables the used MARL algorithm built on these representations to achieve improvements in data efficiency. Experimental evaluation of TIMAR in various MARL environments demonstrates its significantly improved performance and data efficiency compared to strong baselines such as MAPPO, HAPPO, finetuned QMIX, MAT, and MA2CL. In addition, we found TIMAR can also improve the generalization of the Transformer-based MARL algorithm such as MAT. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ke, J.
AU  - Zhang, Q.
AU  - Wang, J.
AU  - Ding, H.
AU  - Zhang, P.
AU  - Wen, J.
TI  - Graph-based referring expression comprehension with expression-guided selective filtering and noun-oriented reasoning
PY  - 2025
T2  - Pattern Recognition
VL  - 161
C7  - 111222
DO  - 10.1016/j.patcog.2024.111222
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212141912&doi=10.1016%2fj.patcog.2024.111222&partnerID=40&md5=73a15735d20e1905e52335e19c34b321
AB  - The objective of referring expression comprehension (REC) is to find the common feature domain between language expressions and visual objects. Due to the complex nature of modeling relationships between objects in images, graph-based methods are widely used for the REC task. However, during the process of graph construction, existing graph-based REC methods insufficiently harness the visual information associated with objects in images. Moreover, in modeling the relationships between objects, these methods consider only the relational words of the expression and the positions of the objects, while ignoring the objects themselves. Thus, they are sub-optimal in capturing underlying relationships between the objects and the expression, leading to incorrect predictions when given a complex expression. To address these issues, we propose a plug-and-adapt module called expression-guided selective and filtering module (EGSFM) for graph-based REC methods that constructs an expression-guided filter to adaptively select relevant and important visual features from feature maps of objects. Then, the selected visual object features and the textual features of the expression are jointly used for graph construction. Finally, a noun-oriented reasoning strategy is proposed for graph reasoning and target object matching, with the number of reasoning steps based on the number of nouns or noun phrases in the expression. Extensive experimental results on three challenging public datasets, including RefCOCO, RefCOCO+, and RefCOCOg, show that our method outperforms the compared graph-based methods and is robust to complex language expressions. In addition, our method performs favorably against other state-of-the-art transformer-based methods while consuming much fewer computational resources for training than those methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, D.
AU  - Wei, X.
AU  - Chen, C.
TI  - CAST: An innovative framework for Cross-dimensional Attention Structure in Transformers
PY  - 2025
T2  - Pattern Recognition
VL  - 159
C7  - 111153
DO  - 10.1016/j.patcog.2024.111153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209153715&doi=10.1016%2fj.patcog.2024.111153&partnerID=40&md5=81f6cd9bf0c8a169e448e5ca9098deec
AB  - Dominant Transformer-based approaches rely solely on attention mechanisms and their variations, primarily emphasizing capturing crucial information within the temporal dimension. For enhanced performance, we introduce a novel architecture for Cross-dimensional Attention Structure in Transformers (CAST), which presents an innovative approach in Transformer-based models, emphasizing attention mechanisms across both temporal and spatial dimensions. The core component of CAST, the cross-dimensional attention structure (CAS), captures dependencies among multivariable time series in both temporal and spatial dimensions. The Static Attention Mechanism (SAM) is incorporated to simplify and enhance multivariate time series forecasting performance. This integration effectively reduces complexity, leading to a more efficient model. CAST demonstrates robust and efficient capabilities in predicting multivariate time series, with the simplicity of SAM broadening its applicability to various tasks. Beyond time series forecasting, CAST also shows promise in CV classification tasks. By integrating CAS into pre-trained image models, CAST facilitates spatiotemporal reasoning. Experimental results highlight the superior performance of CAST in time series forecasting and its competitive edge in CV classification tasks. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Karimian, M.
AU  - Beigy, H.
TI  - CPT4: Continual Prompted Transformer for Test Time Training
PY  - 2025
T2  - Information Sciences
VL  - 700
C7  - 121841
DO  - 10.1016/j.ins.2024.121841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214289896&doi=10.1016%2fj.ins.2024.121841&partnerID=40&md5=fc033d9fbc6ce0fa044a290b67383cd5
AB  - Adapting machine learning models to non-stationary environments is challenging due to evolving domain shifts. Test-time adaptation (TTA) methods address this challenge by employing pre-trained models on source data to predict on unlabeled target data with different domains and adapt the model. However, real-world scenarios frequently encounter continual shifts in target data domains during testing, leading to complexities in ongoing adaptation and error propagation. While earlier TTA methods for image classification tasks mainly focused on convolutional-based models, this paper introduces a transformer-based approach to address TTA challenges, particularly in non-stationary environments. We propose a method, Continual Prompted Transformer for Test-Time Training (CPT4), that enhances the Vision Transformer (ViT) model by incorporating shared prompts (small learnable parameters) and a batch normalization module, aiming to mitigate catastrophic forgetting and handle domain shifts effectively. The prompt pool retains information from prior tasks, while the batch normalization module transfers source data statistics to test time. This work contributes to utilizing small learnable parameters for continual learning in TTA scenarios without access to source data or target labels. Comprehensive experiments using continual image classification benchmarks with non-stationary environments demonstrate CPT4's substantial performance improvement over the original ViT model in a continual test-time training scenario across different adaptation strategies. © 2025 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Karimian2025CPT4
ER  -

TY  - JOUR
AU  - Hassan Anik, B.M.T.
AU  - Abdel-Aty, M.
AU  - Islam, Z.
TI  - Can we realize seamless traffic safety at smart intersections by predicting and preventing impending crashes?
PY  - 2025
T2  - Accident Analysis and Prevention
VL  - 211
C7  - 107908
DO  - 10.1016/j.aap.2024.107908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213567305&doi=10.1016%2fj.aap.2024.107908&partnerID=40&md5=8f9fe32797ab8c8bf5baa2fcf8de0054
AB  - Intersections are frequently identified as crash hotspots for roadways in major cities, leading to significant human casualties. We propose crash likelihood prediction as an effective strategy to proactively prevent intersection crashes. So far, no reliable models have been developed for intersections that effectively account for the variation in crash types and the cyclical nature of Signal Phasing and Timing (SPaT) and traffic flow. Moreover, the limited research available has primarily relied on sampling techniques to address data imbalance, without exploring alternative solutions. We develop an anomaly detection framework by integrating Generative Adversarial Networks (GANs) and Transformers to predict the likelihood of cycle-level crashes at intersections. The model is built using high-resolution event data extracted from Automated Traffic Signal Performance Measures (ATSPM), including SPaT and traffic flow insights from 11 intersections in Seminole County, Florida. Our framework demonstrates a sensitivity of 76% in predicting crash events using highly imbalanced crash data along with real-world SPaT and traffic data, highlighting its potential for deployment at smart intersections. Overall, the results provide a roadmap for city-wide implementation at smart intersections, with the potential for multiple real-time solutions for impending crashes. These include adjustments in signal timing, driver warnings using various means, and more efficient emergency response, all with major implications for creating more livable and safe cities. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Hassan Anik2025Can
ER  -

TY  - JOUR
AU  - Kim, B.
AU  - Kim, J.
AU  - Chang, H.J.
AU  - Oh, T.-H.
TI  - A unified framework for unsupervised action learning via global-to-local motion transformer
PY  - 2025
T2  - Pattern Recognition
VL  - 159
C7  - 111118
DO  - 10.1016/j.patcog.2024.111118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208117666&doi=10.1016%2fj.patcog.2024.111118&partnerID=40&md5=82519d244c34eabdb5375c38374a6ba3
AB  - Human action recognition remains challenging due to the inherent complexity arising from the combination of diverse granularity of semantics, ranging from the local motion of body joints to high-level relationships across multiple people. To learn this multi-level characteristic of human action in an unsupervised manner, we propose a novel pretraining strategy along with a transformer-based model architecture named GL-Transformer++. Prior methods in unsupervised action recognition or unsupervised group activity recognition (GAR) have shown limitations, often focusing solely on capturing a partial scope of the action, such as the local movements of each individual or the broader context of the overall motion. To tackle this problem, we introduce a novel pretraining strategy named multi-interval pose displacement prediction (MPDP) that enables the model to learn the diverse extents of the action. In the architectural aspect, we incorporate the global and local attention (GLA) mechanism within the transformer blocks to learn local dynamics between joints, global context of each individual, as well as high-level interpersonal relationships in both spatial and temporal manner. In fact, the proposed method is a unified approach that demonstrates efficacy in both action recognition and GAR. Particularly, our method presents a new and strong baseline, surpassing the current SOTA GAR method by significant margins: 29.6% in Volleyball and 60.3% and 59.9% on the xsub and xset settings of the Mutual NTU dataset, respectively. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ding, P.
AU  - Wang, J.
AU  - He, S.
AU  - Gao, X.
AU  - Yu, X.
AU  - Yu, B.
TI  - DeepUTF: Locating transcription factor binding sites via interpretable dual-channel encoder-decoder structure
PY  - 2025
T2  - Pattern Recognition
VL  - 161
C7  - 111279
DO  - 10.1016/j.patcog.2024.111279
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212349450&doi=10.1016%2fj.patcog.2024.111279&partnerID=40&md5=683bbd893a31e050c4c743f2b1627457
AB  - The accurate location of transcription factor binding sites (TFBSs) is important for the design of synthetic biology components and the realization of precision medicine. Despite the growing use of deep learning for TFBSs prediction, model interpretability remains challenging. We introduce DeepUTF, a novel architecture integrating improved encoder-decoder, swin transformer, and parallel Bi-LSTM, which realizes precise localization of TFBSs and prediction of motifs. We elucidate the effectiveness of the swin transformer in capturing a wide range of dependencies and emphasizing the learning of critical features. Meanwhile, interpretability analysis of the model's output and predictions of TF-DNA binding motifs are conducted, providing a thorough exploration of the model's intrinsic mechanisms and feature learning process. Experiments conducted on 53 ChIP-seq datasets illustrate that DeepUTF surpasses several leading algorithms. The trained model accurately predicts direct and indirect TF-DNA binding motifs. Furthermore, comparisons with the PDB database validate the continuity and accuracy of predictions. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, K.
AU  - Chen, M.
AU  - Feng, Y.
AU  - Dong, Z.
TI  - Advancing rule learning in knowledge graphs with structure-aware graph transformer
PY  - 2025
T2  - Information Processing and Management
VL  - 62
IS  - 2
C7  - 103976
DO  - 10.1016/j.ipm.2024.103976
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210129659&doi=10.1016%2fj.ipm.2024.103976&partnerID=40&md5=f7f32f1d06bb26ce2179057a8f072472
AB  - In knowledge graphs (KGs), logic rules offer interpretable explanations for predictions and are essential for reasoning on downstream tasks, such as question answering. However, a key challenge remains unresolved: how to effectively encode and utilize the structural features around the head entity to generate the most applicable rules. This paper proposes a structure-aware graph transformer for rule learning, namely Structure-Aware Rule Learning (SARL), which leverages both local and global structural information of the subgraph around the head entity to generate the most suitable rule path. SARL employs a generalized attention mechanism combined with replaceable feature extractors to aggregate local structural information of entities. It then incorporates global structural and relational information to further model the subgraph structure. Finally, a rule decoder utilizes the comprehensive subgraph representation to generate the most appropriate rules. Comprehensive experiments on four real-world knowledge graph datasets reveal that SARL significantly enhances performance and surpasses existing methods in the link prediction task on large-scale KGs, with Hits@1 improvements of 6.5% on UMLS and 4.5% on FB15K-237. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Maslov, K.A.
AU  - Persello, C.
AU  - Schellenberger, T.
AU  - Stein, A.
TI  - Globally scalable glacier mapping by deep learning matches expert delineation accuracy
PY  - 2025
T2  - Nature Communications
VL  - 16
IS  - 1
C7  - 43
DO  - 10.1038/s41467-024-54956-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213955865&doi=10.1038%2fs41467-024-54956-x&partnerID=40&md5=8e7ca179ab2fe0134e6b2d09d1281cb6
AB  - Accurate global glacier mapping is critical for understanding climate change impacts. Despite its importance, automated glacier mapping at a global scale remains largely unexplored. Here we address this gap and propose Glacier-VisionTransformer-U-Net (GlaViTU), a convolutional-transformer deep learning model, and five strategies for multitemporal global-scale glacier mapping using open satellite imagery. Assessing the spatial, temporal and cross-sensor generalisation shows that our best strategy achieves intersection over union >0.85 on previously unobserved images in most cases, which drops to >0.75 for debris-rich areas such as High-Mountain Asia and increases to >0.90 for regions dominated by clean ice. A comparative validation against human expert uncertainties in terms of area and distance deviations underscores GlaViTU performance, approaching or matching expert-level delineation. Adding synthetic aperture radar data, namely, backscatter and interferometric coherence, increases the accuracy in all regions where available. The calibrated confidence for glacier extents is reported making the predictions more reliable and interpretable. We also release a benchmark dataset that covers 9% of glaciers worldwide. Our results support efforts towards automated multitemporal and global glacier mapping. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Nashaat, M.
AU  - Miller, J.
TI  - Refining software defect prediction through attentive neural models for code understanding
PY  - 2025
T2  - Journal of Systems and Software
VL  - 220
C7  - 112266
DO  - 10.1016/j.jss.2024.112266
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207697011&doi=10.1016%2fj.jss.2024.112266&partnerID=40&md5=9f08f9a157a958a6841fc89e55cd6375
AB  - Identifying defects through manual software testing is a resource-intensive task in software development. To alleviate this, software defect prediction identifies code segments likely to contain faults using data-driven methods. Traditional techniques rely on static code metrics, which often fail to reflect the deeper syntactic and semantic features of the code. This paper introduces a novel framework that utilizes transformer-based networks with attention mechanisms to predict software defects. The framework encodes input vectors to develop meaningful representations of software modules. A bidirectional transformer encoder is employed to model programming languages, followed by fine-tuning with labeled data to detect defects. The performance of the framework is assessed through experiments across various software projects and compared against baseline techniques. Additionally, statistical hypothesis testing and an ablation study are performed to assess the impact of different parameter choices. The empirical findings indicate that the proposed approach can increase classification accuracy by an average of 15.93% and improve the F1 score by up to 44.26% compared to traditional methods. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Sun, K.
AU  - Liu, H.
TI  - Attention-aware semantic relevance predicting Chinese sentence reading
PY  - 2025
T2  - Cognition
VL  - 255
C7  - 105991
DO  - 10.1016/j.cognition.2024.105991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210133018&doi=10.1016%2fj.cognition.2024.105991&partnerID=40&md5=aba498dbb3e9ebf2669cbc0d0447ddd5
AB  - In recent years, several influential computational models and metrics have been proposed to predict how humans comprehend and process sentence. One particularly promising approach is contextual semantic similarity. Inspired by the attention algorithm in Transformer and human memory mechanisms, this study proposes an “attention-aware” approach for computing contextual semantic relevance. This new approach takes into account the different contributions of contextual parts and the expectation effect, allowing it to incorporate contextual information fully. The attention-aware approach also facilitates the simulation of existing reading models and their evaluation. The resulting “attention-aware” metrics of semantic relevance can more accurately predict fixation durations in Chinese reading tasks recorded in an eye-tracking corpus than those calculated by existing approaches. The study's findings further provide strong support for the presence of semantic preview benefits in Chinese naturalistic reading. Furthermore, the attention-aware metrics of semantic relevance, being memory-based, possess high interpretability from both linguistic and cognitive standpoints, making them a valuable computational tool for modeling eye-movements in reading and further gaining insight into the process of language comprehension. Our approach emphasizes the potential of these metrics to advance our understanding of how humans comprehend and process language. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - AJG:4; zdy:4; 
LB  - Sun2025Attention-aware
ER  -

TY  - JOUR
AU  - Ibrahem, H.
AU  - Salem, A.
AU  - Kang, H.-S.
TI  - Pixel shuffling is all you need: spatially aware convmixer for dense prediction tasks
PY  - 2025
T2  - Pattern Recognition
VL  - 158
C7  - 111068
DO  - 10.1016/j.patcog.2024.111068
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206494000&doi=10.1016%2fj.patcog.2024.111068&partnerID=40&md5=c82819869783b57f9ff62a79e35400d1
AB  - ConvMixer is an extremely simple model that could perform better than the state-of-the-art convolutional-based and vision transformer-based methods thanks to mixing the input image patches using a standard convolution. The global mixing process of the patches is only valid for the classification tasks, but it cannot be used for dense prediction tasks as the spatial information of the image is lost in the mixing process. We propose a more efficient technique for image patching, known as pixel shuffling, as it can preserve spatial information. We downsample the input image using the pixel shuffle downsampling in the same form of image patches so that the ConvMixer can be extended for the dense prediction tasks. This paper proves that pixel shuffle downsampling is more efficient than the standard image patching as it outperforms the original ConvMixer architecture in the CIFAR10 and ImageNet-1k classification tasks. We also suggest spatially-aware ConvMixer architectures based on efficient pixel shuffle downsampling and upsampling operations for semantic segmentation and monocular depth estimation. We performed extensive experiments to test the proposed architectures on several datasets; Pascal VOC2012, Cityscapes, and ADE20k for semantic segmentation, NYU-depthV2, and Cityscapes for depth estimation. We show that SA-ConvMixer is efficient enough to get relatively high accuracy at many tasks in a few training epochs (150∼400). The proposed SA-ConvMixer could achieve an ImageNet-1K Top-1 classification accuracy of 87.02%, mean intersection over union (mIOU) of 87.1% in the PASCAL VOC2012 semantic segmentation task, and absolute relative error of 0.096 in the NYU depthv2 depth estimation task. The implementation code of the proposed method is available at: https://github.com/HatemHosam/SA-ConvMixer/. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shih, B.
AU  - Peyvan, A.
AU  - Zhang, Z.
AU  - Karniadakis, G.E.
TI  - Transformers as neural operators for solutions of differential equations with finite regularity
PY  - 2025
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 434
C7  - 117560
DO  - 10.1016/j.cma.2024.117560
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210269573&doi=10.1016%2fj.cma.2024.117560&partnerID=40&md5=1f823aba3a6e5e13057321f41ebd1c34
AB  - Neural operator learning models have emerged as very effective surrogates in data-driven methods for partial differential equations (PDEs) across different applications from computational science and engineering. Such operator learning models not only predict particular instances of a physical or biological system in real-time but also forecast classes of solutions corresponding to a distribution of initial and boundary conditions or forcing terms. DeepONet is the first neural operator model and has been tested extensively for a broad class of solutions, including Riemann problems. Transformers have not been used in that capacity, and specifically, they have not been tested for solutions of PDEs with low regularity. In this work, we first establish the theoretical groundwork that transformers possess the universal approximation property as operator learning models. We then apply transformers to forecast solutions of diverse dynamical systems with solutions of finite regularity for a plurality of initial conditions and forcing terms. In particular, we consider three examples: the Izhikevich neuron model, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and the one-dimensional Euler equation Riemann problem. For the latter problem, we also compare with variants of DeepONet, and we find that transformers outperform DeepONet in accuracy but they are computationally more expensive. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Zheng, X.
AU  - Luo, Y.
AU  - Zhou, P.
AU  - Wang, L.
TI  - Distilling efficient Vision Transformers from CNNs for semantic segmentation
PY  - 2025
T2  - Pattern Recognition
VL  - 158
C7  - 111029
DO  - 10.1016/j.patcog.2024.111029
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204689984&doi=10.1016%2fj.patcog.2024.111029&partnerID=40&md5=08129f949b4b08d0157dc024ba523f64
AB  - In this paper, we tackle the problem of how to transfer knowledge from a pre-trained, yet well-performing CNN-based model to train a compact Vision Transformer (ViT)-based model while maintaining the CNN learning capacity? Due to the completely different characteristics of ViT and CNN and the long-existing capacity gap between teacher and student models in Knowledge Distillation (KD), directly transferring the cross-model knowledge is non-trivial. To this end, we subtly leverage the visual and linguistic-compatible feature character of ViT (i.e., student), and its capacity gap with the CNN (i.e., teacher) and propose a novel CNN-to-ViT KD framework, dubbed C2VKD. Importantly, as the teacher's features are heterogeneous to those of the student, we first propose a novel visual-linguistic feature distillation (VLFD) module that explores efficient KD among the aligned visual and linguistic-compatible representations. Moreover, due to the large capacity gap between the teacher and student and the inevitable prediction errors of the teacher, we then propose a pixel-wise decoupled distillation (PDD) module to supervise the student under the combination of labels and teacher's predictions from the decoupled target and non-target classes. Experiments on three semantic segmentation benchmark datasets consistently show that the increment of mIoU of our method is over 200% of the SoTA KD methods. 1 © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Iqbal, S.
AU  - Khan, T.M.
AU  - Naqvi, S.S.
AU  - Naveed, A.
AU  - Meijering, E.
TI  - TBConvL-Net: A hybrid deep learning architecture for robust medical image segmentation
PY  - 2025
T2  - Pattern Recognition
VL  - 158
C7  - 111028
DO  - 10.1016/j.patcog.2024.111028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204675842&doi=10.1016%2fj.patcog.2024.111028&partnerID=40&md5=1900dc2229d02395a9a8732804fab77d
AB  - Deep learning has shown great potential for automated medical image segmentation to improve the precision and speed of disease diagnostics. However, the task presents significant difficulties due to variations in the scale, shape, texture, and contrast of the pathologies. Traditional convolutional neural network (CNN) models have certain limitations when it comes to effectively modelling multiscale context information and facilitating information interaction between skip connections across levels. To overcome these limitations, a novel deep learning architecture is introduced for medical image segmentation, which takes advantage of CNNs and vision transformers. Our proposed model, named TBConvL-Net, involves a hybrid network that combines the local features of a CNN encoder–decoder architecture with long-range and temporal dependencies using biconvolutional long-short-term memory (LSTM) networks and vision transformers (ViT). This enables the model to capture contextual channel relationships in the data and account for the uncertainty of the segmentation over time. Additionally, we introduce a novel composite loss function that considers both segmentation robustness and boundary agreement of the predicted output with the gold standard. Our proposed model shows consistent improvement over the state of the art on ten publicly available datasets of seven different medical imaging modalities. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, T.
AU  - Fang, L.
AU  - Ma, X.
AU  - Li, X.
AU  - Zhang, C.
TI  - TFformer: A time–frequency domain bidirectional sequence-level attention based transformer for interpretable long-term sequence forecasting
PY  - 2025
T2  - Pattern Recognition
VL  - 158
C7  - 110994
DO  - 10.1016/j.patcog.2024.110994
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203623546&doi=10.1016%2fj.patcog.2024.110994&partnerID=40&md5=ed48597c62f0ef3152eee9f491be1764
AB  - Transformer methods have shown strong predictive performance in long-term time series prediction. However, its attention mechanism destroys temporal dependence and has quadratic complexity. This makes prediction processes difficult to interpret, limiting their application in tasks requiring interpretability. To address this issue, this paper proposes a highly interpretable long-term sequence forecasting model, TFformer. TFformer decomposes time series into low frequency trend component and high frequency period component by frequency decomposition, and forecasts them respectively. The periodic information in high-frequency component is enhanced with the sequential frequency attention, and then the temporal patterns of the two components are obtained by feature extraction. According to the period property in time domain, TFformer through periodic extension to predict the future period patterns using sequential periodic matching attention. Finally, the predicted future period pattern and the extracted trend pattern are reconstructed to future series. TFformer provides an interpretable forecasting process with low time complexity, as it retains temporal dependence using sequence-level attentions. TFformer achieves significant prediction performance in both univariate and multivariate forecasting across six datasets. Detailed experimental results and analyses verify the effectiveness and generalization of TFformer. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Ma, B.
AU  - Jin, L.
AU  - Yang, Y.
AU  - Tong, C.
TI  - CosineTR: A dual-branch transformer-based network for semantic line detection
PY  - 2025
T2  - Pattern Recognition
VL  - 158
C7  - 110952
DO  - 10.1016/j.patcog.2024.110952
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202933008&doi=10.1016%2fj.patcog.2024.110952&partnerID=40&md5=f87e15bd56f02efaebabd7a9aea6d3ba
AB  - Semantic line is a straight line based representation designed to well capture the spatial layout or structural shape of the scene in an image that is valuable as a high-level visual property. In this paper, we propose an efficient end-to-end trainable semantic line detection model named Complementary semantic line TRansformer (CosineTR), which is designed according to an old proverb “two heads are better than one”. CosineTR adopts a dual-branch framework to detect semantic lines with a coarse to fine strategy. These two branches are built based on well-designed attention modules to capture multi-scale line semantic features locally and globally, and are equipped with heatmap prediction head and parameter regression head respectively to perform semantic line detection from two different perspectives. In addition, we introduce bilateral region attention and Gaussian prior cross-attention modules to reinforce semantic contexts extracted by the two branches, and couple them to form complementary feature representations by leveraging a feature interaction method. Extensive experiments demonstrate that our approach is effective and achieves competitive semantic line detection performance on multiple datasets. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Zhou, K.
AU  - Lu, F.
AU  - Li, Z.
AU  - Shao, X.
AU  - Zhou, X.-D.
AU  - Shi, Y.
TI  - ESMformer: Error-aware self-supervised transformer for multi-view 3D human pose estimation
PY  - 2025
T2  - Pattern Recognition
VL  - 158
C7  - 110955
DO  - 10.1016/j.patcog.2024.110955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203882324&doi=10.1016%2fj.patcog.2024.110955&partnerID=40&md5=e8c6e0793d9ad71b54127d18b69a3c26
AB  - Multi-view 3D human pose estimation (HPE) currently faces several key challenges. Information from different viewpoints exhibits high variability due to complex environmental factors, posing difficulties in cross-view feature extraction and fusion. Additionally, multi-view 3D labeled pose data is rather scarce, and the impact of input 2D poses on 3D HPE accuracy has received little attention. To address these issues, we propose an Error-aware Self-supervised transformer framework for Multi-view 3D HPE (ESMformer). Firstly, we introduce a single-view multi-level feature extraction module to enhance pose features in individual viewpoints, which incorporates a novel relative attention mechanism for representative feature extraction at different levels. Subsequently, we develop multi-view intra-level and cross-level fusion modules to exploit spatio-temporal feature dependencies among human joints, and progressively fuse pose information from all views and levels. Furthermore, we explore an error-aware self-supervised learning strategy to reduce the model's reliance on 3D pose annotations and mitigate the impact of incorrect 2D poses. This strategy adaptively selects reliable input 2D poses based on 3D pose prediction errors. Experiments on three popular benchmarks show that ESMformer achieves state-of-the-art results and maintains cost-effective computational complexity. Notably, ESMformer does not rely on any 3D pose annotations or prior human body knowledge, making it highly versatile and adaptable in practical applications.1 © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, D.
AU  - Zhang, Z.
AU  - Chen, N.
AU  - Wang, Y.
TI  - RFNet: Multivariate long sequence time-series forecasting based on recurrent representation and feature enhancement
PY  - 2025
T2  - Neural Networks
VL  - 181
C7  - 106800
DO  - 10.1016/j.neunet.2024.106800
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207873963&doi=10.1016%2fj.neunet.2024.106800&partnerID=40&md5=620294b918b44c5a4864610d89c0e1a1
AB  - Multivariate time series exhibit complex patterns and structures involving interactions among multiple variables and long-term temporal dependencies, making multivariate long sequence time series forecasting (MLSTF) exceptionally challenging. Despite significant progress in Transformer-based methods in the MLSTF domain, many models still rely on stacked encoder–decoder architectures to capture complex time series patterns. This leads to increased computational complexity and overlooks spatial pattern information in multivariate time series, thereby limiting the model's performance. To address these challenges, we propose RFNet, a lightweight model based on recurrent representation and feature enhancement. We partition the time series into fixed-size subsequences to retain local contextual temporal pattern information and cross-variable spatial pattern information. The recurrent representation module employs gate attention mechanisms and memory units to capture local information of the subsequences and obtain long-term correlation information of the input sequence by integrating information from different memory units. Meanwhile, we utilize a shared multi-layer perceptron (MLP) to capture global pattern information of the input sequence. The feature enhancement module explicitly extracts complex spatial patterns in the time series by transforming the input sequence. We validate the performance of RFNet on ten real-world datasets. The results demonstrate an improvement of approximately 55.3% over state-of-the-art MLSTF models, highlighting its significant advantage in addressing multivariate long sequence time series forecasting problems. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Di Rocco, J.
AU  - Nguyen, P.T.
AU  - Di Sipio, C.
AU  - Rubei, R.
AU  - Di Ruscio, D.
AU  - Di Penta, M.
TI  - DeepMig: A transformer-based approach to support coupled library and code migrations
PY  - 2025
T2  - Information and Software Technology
VL  - 177
C7  - 107588
DO  - 10.1016/j.infsof.2024.107588
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205990085&doi=10.1016%2fj.infsof.2024.107588&partnerID=40&md5=3b7f11f7bd4909535b956a5643722acd
AB  - Context: While working on software projects, developers often replace third-party libraries (TPLs) with different ones offering similar functionalities. However, choosing a suitable TPL to migrate to is a complex task. As TPLs provide developers with Application Programming Interfaces (APIs) to allow for the invocation of their functionalities after adopting a new TPL, projects need to be migrated by the methods containing the affected API calls. Altogether, the coupled migration of TPLs and code is a strenuous process, requiring massive development effort. Most of the existing approaches either deal with library or API call migration but usually fail to solve both problems coherently simultaneously. Objective: This paper presents DeepMig, a novel approach to the coupled migration of TPLs and API calls. We aim to support developers in managing their projects, at the library and API level, allowing them to increase their productivity. Methods: DeepMig is based on a transformer architecture, accepts a set of libraries to predict a new set of libraries. Then, it looks for the changed API calls and recommends a migration plan for the affected methods. We evaluate DeepMig using datasets of Java projects collected from the Maven Central Repository, ensuring an assessment based on real-world dependency configurations. Results: Our evaluation reveals promising outcomes: DeepMig recommends both libraries and code; by several projects, it retrieves a perfect match for the recommended items, obtaining an accuracy of 1.0. Moreover, being fed with proper training data, DeepMig provides comparable code migration steps of a static API migrator, a baseline for the code migration task. Conclusion: We conclude that DeepMig is capable of recommending both TPL and API migration, providing developers with a practical tool to migrate the entire project. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Di Rocco2025DeepMig
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Wang, H.
AU  - Shen, H.
AU  - Duan, S.
AU  - Wen, S.
TI  - Analog Spiking U-Net integrating CBAM&ViT for medical image segmentation
PY  - 2025
T2  - Neural Networks
VL  - 181
C7  - 106765
DO  - 10.1016/j.neunet.2024.106765
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205295282&doi=10.1016%2fj.neunet.2024.106765&partnerID=40&md5=66d1494ae6e115eef0841bcfa9b2a9d1
AB  - SNNs are gaining popularity in AI research as a low-power alternative in deep learning due to their sparse properties and biological interpretability. Using SNNs for dense prediction tasks is becoming an important research area. In this paper, we firstly proposed a novel modification on the conventional Spiking U-Net architecture by adjusting the firing positions of neurons. The modified network model, named Analog Spiking U-Net (AS U-Net), is capable of incorporating the Convolutional Block Attention Module (CBAM) into the domain of SNNs. This is the first successful implementation of CBAM in SNNs, which has the potential to improve SNN model's segmentation performance while decreasing information loss. Then, the proposed AS U-Net (with CBAM&ViT) is trained by direct encoding on a comprehensive dataset obtained by merging several diabetic retinal vessel segmentation datasets. Based on the experimental results, the provided SNN model achieves the highest segmentation accuracy in retinal vessel segmentation for diabetes mellitus, surpassing other SNN-based models and most ANN-based related models. In addition, under the same structure, our model demonstrates comparable performance to the ANN model. And then, the novel model achieves state-of-the-art(SOTA) results in comparative experiments when both accuracy and energy consumption are considered (Fig. 1). At the same time, the ablative analysis of CBAM further confirms its feasibility and effectiveness in SNNs, which means that a novel approach could be provided for subsequent deployment and hardware chip application. In the end, we conduct extensive generalization experiments on the same type of segmentation task (ISBI and ISIC), the more complex multi-segmentation task (Synapse), and a series of image generation tasks (MNIST, Day2night, Maps, Facades) in order to visually demonstrate the generality of the proposed method. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Xie, J.
AU  - Zhang, C.
AU  - Zhang, Y.
AU  - Zhao, Y.
TI  - A transformer-based convolutional method to model inverse cascade in forced two-dimensional turbulence
PY  - 2025
T2  - Journal of Computational Physics
VL  - 520
C7  - 113475
DO  - 10.1016/j.jcp.2024.113475
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205587318&doi=10.1016%2fj.jcp.2024.113475&partnerID=40&md5=24ea09f7b204ecbd4b182307f5c33dee
AB  - The present work proposes a novel transformer-based convolutional neural network (TransCNN) method to effectively model the inverse energy cascade in two dimensional (2D) turbulence. The TransCNN structure combines large-scale features extracted by transformer with small-scale features from convolutional layers, thus is considered suitable for multi-scale modeling. The novel TransCNN method has been applied to model sub-grid scale (SGS) stress for large-eddy simulation (LES) of 2D turbulence, under the extremely challenging situation that the LES grid is too coarse to resolve the external forcing scale. The data-driven model trained by the novel TransCNN structure is compared to two deep CNN models with varying complexities. All models exhibit proficiency during a priori tests. Notably, TransCNN surpasses its counterparts in predictive accuracy and generalizability in a posteriori tests. An investigation into the receptive fields reveals that the TransCNN model can efficiently leverage global information with the transformer structure, which is key to its superior performance in representing the inverse energy cascade in the 2D turbulent simulations. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Xu, K.
AU  - Wang, M.
AU  - Zou, X.
AU  - Liu, J.
AU  - Wei, A.
AU  - Chen, J.
AU  - Tang, C.
TI  - HSTrans: Homogeneous substructures transformer for predicting frequencies of drug-side effects
PY  - 2025
T2  - Neural Networks
VL  - 181
C7  - 106779
DO  - 10.1016/j.neunet.2024.106779
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207945687&doi=10.1016%2fj.neunet.2024.106779&partnerID=40&md5=5223430ffa5e4d0def898f13c828eae2
AB  - Identifying the frequencies of drug-side effects is crucial for assessing drug risk-benefit. However, accurately determining these frequencies remains challenging due to the limitations of time and scale in clinical randomized controlled trials. As a result, several computational methods have been proposed to address these issues. Nonetheless, two primary problems still persist. Firstly, most of these methods face challenges in generating accurate predictions for novel drugs, as they heavily depend on the interaction graph between drugs and side effects (SEs) within their modeling framework. Secondly, some previous methods often simply concatenate the features of drugs and SEs, which fails to effectively capture their underlying association. In this work, we present HSTrans, a novel approach that treats drugs and SEs as sets of substructures, leveraging a transformer encoder for unified substructure embedding and incorporating an interaction module for association capture. Specifically, HSTrans extracts drug substructures through a specialized algorithm and identifies effective substructures for each SE by employing an indicator that measures the importance of each substructure and SE. Additionally, HSTrans applies convolutional neural network (CNN) in the interaction module to capture complex relationships between drugs and SEs. Experimental results on datasets from Galeano et al.’s study demonstrate that the proposed method outperforms other state-of-the-art approaches. The demo codes for HSTrans are available at https://github.com/Dtdtxuky/HSTrans/tree/master. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Han, S.
AU  - Xun, Y.
AU  - Cai, J.
AU  - Yang, H.
AU  - Li, Y.
TI  - DyGraphformer: Transformer combining dynamic spatio-temporal graph network for multivariate time series forecasting
PY  - 2025
T2  - Neural Networks
VL  - 181
C7  - 106776
DO  - 10.1016/j.neunet.2024.106776
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206919594&doi=10.1016%2fj.neunet.2024.106776&partnerID=40&md5=c0cd977e638850072cc30d48f63e4d94
AB  - Transformer-based models demonstrate tremendous potential for Multivariate Time Series (MTS) forecasting due to their ability to capture long-term temporal dependencies by using the self-attention mechanism. However, effectively modeling the spatial correlation cross series for MTS is a challenge for Transformer. Although Graph Neural Networks (GNN) are competent for modeling spatial dependencies across series, existing methods are based on the assumption of static relationships between variables, which do not align with the time-varying spatial dependencies in real-world series. Therefore, we propose DyGraphformer, which integrates graph convolution into Transformer to assist Transformer in effectively modeling spatial dependencies, while also dynamically inferring time-varying spatial dependencies by combining historical spatial information. In DyGraphformer, decoder module involving complex recursion is abandoned to accelerate model execution. First, the input is embedded using DSW (Dimension Segment Wise) through integrating its position and node level embedding to preserve temporal and spatial information. Then, the time self-attention layer and dynamic graph convolutional layer are constructed to capture temporal dependencies and spatial dependencies of multivariate time series, respectively. The dynamic graph convolutional layer utilizes Gated Recurrent Unit (GRU) to obtain historical spatial dependencies, and integrates the series features of the current time to perform graph structure inference in multiple subspaces. Specifically, to fully utilize the spatio-temporal information at different scales, DyGraphformer performs hierarchical encoder learning for the final forecasting. Extensive experimental results on seven real-world datasets demonstrate DyGraphformer outperforms state-of-the-art baseline methods, with comparisons including Transformer-based and GNN-based methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, L.
AU  - Liang, Y.
AU  - Lu, Y.
AU  - Cheung, Y.-M.
TI  - GradToken: Decoupling tokens with class-aware gradient for visual explanation of Transformer network
PY  - 2025
T2  - Neural Networks
VL  - 181
C7  - 106837
DO  - 10.1016/j.neunet.2024.106837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208581513&doi=10.1016%2fj.neunet.2024.106837&partnerID=40&md5=8c6c3b6f64095255e8b3dfe3b2cd46f0
AB  - Transformer networks have been widely used in the fields of computer vision, natural language processing, graph-structured data analysis, etc. Subsequently, explanations of Transformer play a key role in helping humans understand and analyze its decision-making and working mechanism, thereby improving the trustworthiness in its real-world applications. However, it is difficult to apply the existing explanation methods for convolutional neural networks to Transformer networks, due to the significant differences between their structures. How to design a specific and effective explanation method for Transformer poses a challenge in the explanation area. To address this challenge, we first analyze the semantic coupling problem of attention weight matrices in Transformer, which puts obstacles in providing distinctive explanations for different categories of targets. Then, we propose a gradient-decoupling-based token relevance method (i.e., GradToken) for the visual explanation of Transformer's predictions. GradToken exploits the class-aware gradient to decouple the tangled semantics in the class token to the semantics corresponding to each category. GradToken further leverages the relations between the class token and spatial tokens to generate relevance maps. As a result, the visual explanation results generated by GradToken can effectively focus on the regions of selected targets. Extensive quantitative and qualitative experiments are conducted to verify the validity and reliability of the proposed method. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Thrift, W.J.
AU  - Lounsbury, N.W.
AU  - Broadwell, Q.
AU  - Heidersbach, A.
AU  - Freund, E.
AU  - Abdolazimi, Y.
AU  - Phung, Q.T.
AU  - Chen, J.
AU  - Capietto, A.-H.
AU  - Tong, A.-J.
AU  - Rose, C.M.
AU  - Blanchette, C.
AU  - Lill, J.R.
AU  - Haley, B.
AU  - Delamarre, L.
AU  - Bourgon, R.
AU  - Liu, K.
AU  - Jhunjhunwala, S.
TI  - Towards designing improved cancer immunotherapy targets with a peptide-MHC-I presentation model, HLApollo
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 10752
DO  - 10.1038/s41467-024-54887-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213799538&doi=10.1038%2fs41467-024-54887-7&partnerID=40&md5=78ae0c98e9596321e255441d9e25f779
AB  - Based on the success of cancer immunotherapy, personalized cancer vaccines have emerged as a leading oncology treatment. Antigen presentation on MHC class I (MHC-I) is crucial for the adaptive immune response to cancer cells, necessitating highly predictive computational methods to model this phenomenon. Here, we introduce HLApollo, a transformer-based model for peptide-MHC-I (pMHC-I) presentation prediction, leveraging the language of peptides, MHC, and source proteins. HLApollo provides end-to-end treatment of MHC-I sequences and deconvolution of multi-allelic data, using a negative-set switching strategy to mitigate misassigned negatives in unlabelled ligandome data. HLApollo shows a 12.65% increase in average precision (AP) on ligandome data and a 4.1% AP increase on immunogenicity test data compared to next-best models. Incorporating protein features from protein language models yields further gains and reduces the need for gene expression measurements. Guided by clinical use, we demonstrate pan-allelic generalization which effectively captures rare alleles in underrepresented ancestries. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Zhang, Y.
TI  - Filling GRACE data gap using an innovative transformer-based deep learning approach
PY  - 2024
T2  - Remote Sensing of Environment
VL  - 315
C7  - 114465
DO  - 10.1016/j.rse.2024.114465
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206157836&doi=10.1016%2fj.rse.2024.114465&partnerID=40&md5=e95bd4133b54726f9541919f31961c5d
AB  - The terrestrial water storage anomaly (TWSA), derived from the Gravity Recovery and Climate Experiment (GRACE) and its successor, the GRACE Follow-on (GRACE-FO) satellite, presents a remarkable opportunity for extreme weather detection and the enhancement of environmental protection. However, the practical utility of GRACE data is challenged by an 11-month data gap and several months of missing data. To address this limitation, we have developed an innovative transformer-based deep learning model for data gap-filling. This model incorporates a self-attention mechanism using causal convolution, allowing the neural network to capture the local context of GRACE time series data. It takes into account various factors such as temperature (T), precipitation (P), and evapotranspiration (ET). We trained the model using a global dataset of 10,000 time series pixels and applied it to fill all the time gaps. The validation results demonstrate its robustness, with an average root mean square error (RMSE) of 6.18 cm and Nash-Sutcliffe efficiency (NSE) of 0.906. Notably, the Transformer-based method outperforms other state-of-the-art approaches in arid regions. The incorporation of T, P, and ET has further enhanced the accuracy of gap filling, with an average RMSE decrease of 7.5 %. This study has produced a reliable gap-filling product that addresses 11-month data gaps and 24 isolated gaps, ensuring the continuity of GRACE data for various scholarly applications. Moreover, our Transformer approach holds important potential for surpassing traditional methods in predicting and filling gaps in remote sensing data and gridded observations. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Jeong, N.
AU  - Park, S.
AU  - Mahajan, S.
AU  - Zhou, J.
AU  - Blotevogel, J.
AU  - Li, Y.
AU  - Tong, T.
AU  - Chen, Y.
TI  - Elucidating governing factors of PFAS removal by polyamide membranes using machine learning and molecular simulations
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 10918
DO  - 10.1038/s41467-024-55320-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212428040&doi=10.1038%2fs41467-024-55320-9&partnerID=40&md5=bdc07fa8a0c965bf4b3a0b99cde22305
AB  - Per- and polyfluoroalkyl substances (PFASs) have recently garnered considerable concerns regarding their impacts on human and ecological health. Despite the important roles of polyamide membranes in remediating PFASs-contaminated water, the governing factors influencing PFAS transport across these membranes remain elusive. In this study, we investigate PFAS rejection by polyamide membranes using two machine learning (ML) models, namely XGBoost and multimodal transformer models. Utilizing the Shapley additive explanation method for XGBoost model interpretation unveils the impacts of both PFAS characteristics and membrane properties on model predictions. The examination of the impacts of chemical structure involves interpreting the multimodal transformer model incorporated with simplified molecular input line entry system strings through heat maps, providing a visual representation of the attention score assigned to each atom of PFAS molecules. Both ML interpretation methods highlight the dominance of electrostatic interaction in governing PFAS transport across polyamide membranes. The roles of functional groups in altering PFAS transport across membranes are further revealed by molecular simulations. The combination of ML with computer simulations not only advances our knowledge of PFAS removal by polyamide membranes, but also provides an innovative approach to facilitate data-driven feature selection for the development of high-performance membranes with improved PFAS removal efficiency. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Méndez-Lucio, O.
AU  - Nicolaou, C.A.
AU  - Earnshaw, B.
TI  - MolE: a foundation model for molecular graphs using disentangled attention
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 9431
DO  - 10.1038/s41467-024-53751-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209475948&doi=10.1038%2fs41467-024-53751-y&partnerID=40&md5=379a4764e9f5466d49bb6dd2448421d1
AB  - Models that accurately predict properties based on chemical structure are valuable tools in the chemical sciences. However, for many properties, public and private training sets are typically small, making it difficult for models to generalize well outside of the training data. Recently, this lack of generalization has been mitigated by using self-supervised pretraining on large unlabeled datasets, followed by finetuning on smaller, labeled datasets. Inspired by these advances, we report MolE, a Transformer architecture adapted for molecular graphs together with a two-step pretraining strategy. The first step of pretraining is a self-supervised approach focused on learning chemical structures trained on ~842 million molecular graphs, and the second step is a massive multi-task approach to learn biological information. We show that finetuning models that were pretrained in this way perform better than the best published results on 10 of the 22 ADMET (absorption, distribution, metabolism, excretion and toxicity) tasks included in the Therapeutic Data Commons leaderboard (c. September 2023). © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lai, H.
AU  - Wang, L.
AU  - Qian, R.
AU  - Huang, J.
AU  - Zhou, P.
AU  - Ye, G.
AU  - Wu, F.
AU  - Wu, F.
AU  - Zeng, X.
AU  - Liu, W.
TI  - Interformer: an interaction-aware model for protein-ligand docking and affinity prediction
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 10223
DO  - 10.1038/s41467-024-54440-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210162175&doi=10.1038%2fs41467-024-54440-6&partnerID=40&md5=9d0929c034690325e6cde8d29dd7066b
AB  - In recent years, the application of deep learning models to protein-ligand docking and affinity prediction, both vital for structure-based drug design, has garnered increasing interest. However, many of these models overlook the intricate modeling of interactions between ligand and protein atoms in the complex, consequently limiting their capacity for generalization and interpretability. In this work, we propose Interformer, a unified model built upon the Graph-Transformer architecture. The proposed model is designed to capture non-covalent interactions utilizing an interaction-aware mixture density network. Additionally, we introduce a negative sampling strategy, facilitating an effective correction of interaction distribution for affinity prediction. Experimental results on widely used and our in-house datasets demonstrate the effectiveness and universality of the proposed approach. Extensive analyses confirm our claim that our approach improves performance by accurately modeling specific protein-ligand interactions. Encouragingly, our approach advances docking tasks state-of-the-art (SOTA) performance. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Wang, Y.
AU  - Chen, S.
AU  - Tan, Y.S.
AU  - Deng, L.
AU  - Wu, M.
TI  - DeepRSMA: A cross-fusion-based deep learning method for RNA-small molecule binding affinity prediction
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 12
C7  - btae678
DO  - 10.1093/bioinformatics/btae678
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212439664&doi=10.1093%2fbioinformatics%2fbtae678&partnerID=40&md5=3bb5c7b943b302cf7b77dcad4f1fe79d
AB  - Motivation: RNA is implicated in numerous aberrant cellular functions and disease progressions, highlighting the crucial importance of RNA-Targeted drugs. To accelerate the discovery of such drugs, it is essential to develop an effective computational method for predicting RNA-small molecule affinity (RSMA). Recently, deep learning-based computational methods have been promising due to their powerful nonlinear modeling ability. However, the leveraging of advanced deep learning methods to mine the diverse information of RNAs, small molecules, and their interaction still remains a great challenge. Results: In this study, we present DeepRSMA, an innovative cross-Attention-based deep learning method for RSMA prediction. To effectively capture fine-grained features from RNA and small molecules, we developed nucleotide-level and atomic-level feature extraction modules for RNA and small molecules, respectively. Additionally, we incorporated both sequence and graph views into these modules to capture features from multiple perspectives. Moreover, a transformer-based cross-fusion module is introduced to learn the general patterns of interactions between RNAs and small molecules. To achieve effective RSMA prediction, we integrated the RNA and small molecule representations from the feature extraction and cross-fusion modules. Our results show that DeepRSMA outperforms baseline methods in multiple test settings. The interpretability analysis and the case study on spinal muscular atrophy demonstrate that DeepRSMA has the potential to guide RNA-Targeted drug design.  © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Fan, Y.
AU  - Waldmann, P.
TI  - Tabular deep learning: a comparative study applied to multi-task genome-wide prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 322
DO  - 10.1186/s12859-024-05940-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205826603&doi=10.1186%2fs12859-024-05940-1&partnerID=40&md5=be12933541479a9c6937567fcfb084b6
AB  - Purpose: More accurate prediction of phenotype traits can increase the success of genomic selection in both plant and animal breeding studies and provide more reliable disease risk prediction in humans. Traditional approaches typically use regression models based on linear assumptions between the genetic markers and the traits of interest. Non-linear models have been considered as an alternative tool for modeling genomic interactions (i.e. non-additive effects) and other subtle non-linear patterns between markers and phenotype. Deep learning has become a state-of-the-art non-linear prediction method for sound, image and language data. However, genomic data is better represented in a tabular format. The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports successful results on various datasets. Tabular deep learning applications in genome-wide prediction (GWP) are still rare. In this work, we perform an overview of the main families of recent deep learning architectures for tabular data and apply them to multi-trait regression and multi-class classification for GWP on real gene datasets. Methods: The study involves an extensive overview of recent deep learning architectures for tabular data learning: NODE, TabNet, TabR, TabTransformer, FT-Transformer, AutoInt, GANDALF, SAINT and LassoNet. These architectures are applied to multi-trait GWP. Comprehensive benchmarks of various tabular deep learning methods are conducted to identify best practices and determine their effectiveness compared to traditional methods. Results: Extensive experimental results on several genomic datasets (three for multi-trait regression and two for multi-class classification) highlight LassoNet as a standout performer, surpassing both other tabular deep learning models and the highly efficient tree based LightGBM method in terms of both best prediction accuracy and computing efficiency. Conclusion: Through series of evaluations on real-world genomic datasets, the study identifies LassoNet as a standout performer, surpassing decision tree methods like LightGBM and other tabular deep learning architectures in terms of both predictive accuracy and computing efficiency. Moreover, the inherent variable selection property of LassoNet provides a systematic way to find important genetic markers that contribute to phenotype expression. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Fan2024Tabular
ER  -

TY  - JOUR
AU  - Baek, B.
AU  - Lee, H.
TI  - Crossfeat: a transformer-based cross-feature learning model for predicting drug side effect frequency
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 324
DO  - 10.1186/s12859-024-05915-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205976245&doi=10.1186%2fs12859-024-05915-2&partnerID=40&md5=ffd008f0a10ad3731fdfe2ffee34971e
AB  - Background: Safe drug treatment requires an understanding of the potential side effects. Identifying the frequency of drug side effects can reduce the risks associated with drug use. However, existing computational methods for predicting drug side effect frequencies heavily depend on known drug side effect frequency information. Consequently, these methods face challenges when predicting the side effect frequencies of new drugs. Although a few methods can predict the side effect frequencies of new drugs, they exhibit unreliable performance owing to the exclusion of drug-side effect relationships. Results: This study proposed CrossFeat, a model based on convolutional neural network-transformer architecture with cross-feature learning that can predict the occurrence and frequency of drug side effects for new drugs, even in the absence of information regarding drug-side effect relationships. CrossFeat facilitates the concurrent learning of drugs and side effect information within its transformer architecture. This simultaneous exchange of information enables drugs to learn about their associated side effects, while side effects concurrently acquire information about the respective drugs. Such bidirectional learning allows for the comprehensive integration of drug and side effect knowledge. Our five-fold cross-validation experiments demonstrated that CrossFeat outperforms existing studies in predicting side effect frequencies for new drugs without prior knowledge. Conclusions: Our model offers a promising approach for predicting the drug side effect frequencies, particularly for new drugs where prior information is limited. CrossFeat’s superior performance in cross-validation experiments, along with evidence from case studies and ablation experiments, highlights its effectiveness. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Baek2024Crossfeat
ER  -

TY  - JOUR
AU  - Hu, H.
AU  - Liang, M.
AU  - Wang, C.
AU  - Zhao, M.
AU  - Shi, F.
AU  - Zhang, C.
AU  - Han, Y.
TI  - Monocular depth estimation with boundary attention mechanism and Shifted Window Adaptive Bins
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 249
C7  - 104220
DO  - 10.1016/j.cviu.2024.104220
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208283968&doi=10.1016%2fj.cviu.2024.104220&partnerID=40&md5=8fdd3ed83f4d7522494efe603868b9c5
AB  - Monocular depth estimation is a classic research topic in computer vision. In recent years, development of Convolutional Neural Networks (CNNs) has facilitated significant breakthroughs in this field. However, there still exist two challenges: (1) The network struggles to effectively fuse edge features in the feature fusion stage, which ultimately results in the loss of structure or boundary distortion of objects in the scene. (2) Classification based studies typically depend on Transformers for global modeling, a process that often introduces substantial computational complexity overhead as described in Equation 2. In this paper, we propose two modules to address the aforementioned issues. The first module is the Boundary Attention Module (BAM), which leverages the attention mechanism to enhance the ability of the network to perceive object boundaries during the feature fusion stage. In addition, to mitigate the computational complexity overhead resulting from predicting adaptive bins, we propose a Shift Window Adaptive Bins (SWAB) module to reduce the amount of computation in global modeling. The proposed method is evaluated on three public datasets, NYU Depth V2, KITTI and SUNRGB-D, and demonstrates state-of-the-art (SOTA) performance. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shao, B.
AU  - Yan, J.
TI  - A long-context language model for deciphering and generating bacteriophage genomes
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 9392
DO  - 10.1038/s41467-024-53759-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208162723&doi=10.1038%2fs41467-024-53759-4&partnerID=40&md5=56e8d043017dbc3c5da983a4bb317173
AB  - Inspired by the success of large language models (LLMs), we develop a long-context generative model for genomes. Our multiscale transformer model, megaDNA, is pre-trained on unannotated bacteriophage genomes with nucleotide-level tokenization. We demonstrate the foundational capabilities of our model including the prediction of essential genes, genetic variant effects, regulatory element activity and taxonomy of unannotated sequences. Furthermore, it generates de novo sequences up to 96 K base pairs, which contain potential regulatory elements and annotated proteins with phage-related functions. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Conwell, C.
AU  - Prince, J.S.
AU  - Kay, K.N.
AU  - Alvarez, G.A.
AU  - Konkle, T.
TI  - A large-scale examination of inductive biases shaping high-level visual representation in brains and machines
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 9383
DO  - 10.1038/s41467-024-53147-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208167299&doi=10.1038%2fs41467-024-53147-y&partnerID=40&md5=083b01d05bb13ef2a358acbe11c9bf2b
AB  - The rapid release of high-performing computer vision models offers new potential to study the impact of different inductive biases on the emergent brain alignment of learned representations. Here, we perform controlled comparisons among a curated set of 224 diverse models to test the impact of specific model properties on visual brain predictivity – a process requiring over 1.8 billion regressions and 50.3 thousand representational similarity analyses. We find that models with qualitatively different architectures (e.g. CNNs versus Transformers) and task objectives (e.g. purely visual contrastive learning versus vision- language alignment) achieve near equivalent brain predictivity, when other factors are held constant. Instead, variation across visual training diets yields the largest, most consistent effect on brain predictivity. Many models achieve similarly high brain predictivity, despite clear variation in their underlying representations – suggesting that standard methods used to link models to brains may be too flexible. Broadly, these findings challenge common assumptions about the factors underlying emergent brain alignment, and outline how we can leverage controlled model comparison to probe the common computational principles underlying biological and artificial visual systems. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Durst, D.
AU  - Xie, F.
AU  - Sarukkai, V.
AU  - Shacklett, B.
AU  - Frosio, I.
AU  - Tessler, C.
AU  - Kim, J.
AU  - Taylor, C.
AU  - Bernstein, G.
AU  - Choudhury, S.
AU  - Hanrahan, P.
AU  - Fatahalian, K.
TI  - Learning to Move Like Professional Counter-Strike Players
PY  - 2024
T2  - Computer Graphics Forum
VL  - 43
IS  - 8
C7  - e15173
DO  - 10.1111/cgf.15173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205818316&doi=10.1111%2fcgf.15173&partnerID=40&md5=fa5c673d28594325c02e4f75dadfd3d8
AB  - In multiplayer, first-person shooter games like Counter-Strike: Global Offensive (CS:GO), coordinated movement is a critical component of high-level strategic play. However, the complexity of team coordination and the variety of conditions present in popular game maps make it impractical to author hand-crafted movement policies for every scenario. We show that it is possible to take a data-driven approach to creating human-like movement controllers for CS:GO. We curate a team movement dataset comprising 123 hours of professional game play traces, and use this dataset to train a transformer-based movement model that generates human-like team movement for all players in a “Retakes” round of the game. Importantly, the movement prediction model is efficient. Performing inference for all players takes less than 0.5 ms per game step (amortized cost) on a single CPU core, making it plausible for use in commercial games today. Human evaluators assess that our model behaves more like humans than both commercially-available bots and procedural movement controllers scripted by experts (16% to 59% higher by TrueSkill rating of “human-like”). Using experiments involving in-game bot vs. bot self-play, we demonstrate that our model performs simple forms of teamwork, makes fewer common movement mistakes, and yields movement distributions, player lifetimes, and kill locations similar to those observed in professional CS:GO match play. © 2024 Eurographics - The European Association for Computer Graphics and John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pizurica, M.
AU  - Zheng, Y.
AU  - Carrillo-Perez, F.
AU  - Noor, H.
AU  - Yao, W.
AU  - Wohlfart, C.
AU  - Vladimirova, A.
AU  - Marchal, K.
AU  - Gevaert, O.
TI  - Digital profiling of gene expression from histology images with linearized attention
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 9886
DO  - 10.1038/s41467-024-54182-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209117057&doi=10.1038%2fs41467-024-54182-5&partnerID=40&md5=457525666a59d178ed5b6e0b2e6a97ac
AB  - Cancer is a heterogeneous disease requiring costly genetic profiling for better understanding and management. Recent advances in deep learning have enabled cost-effective predictions of genetic alterations from whole slide images (WSIs). While transformers have driven significant progress in non-medical domains, their application to WSIs lags behind due to high model complexity and limited dataset sizes. Here, we introduce SEQUOIA, a linearized transformer model that predicts cancer transcriptomic profiles from WSIs. SEQUOIA is developed using 7584 tumor samples across 16 cancer types, with its generalization capacity validated on two independent cohorts comprising 1368 tumors. Accurately predicted genes are associated with key cancer processes, including inflammatory response, cell cycles and metabolism. Further, we demonstrate the value of SEQUOIA in stratifying the risk of breast cancer recurrence and in resolving spatial gene expression at loco-regional levels. SEQUOIA hence deciphers clinically relevant information from WSIs, opening avenues for personalized cancer management. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Blaabjerg, L.M.
AU  - Jonsson, N.
AU  - Boomsma, W.
AU  - Stein, A.
AU  - Lindorff-Larsen, K.
TI  - SSEmb: A joint embedding of protein sequence and structure enables robust variant effect predictions
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 9646
DO  - 10.1038/s41467-024-53982-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208809308&doi=10.1038%2fs41467-024-53982-z&partnerID=40&md5=63c56ccda47e79caf2b0707b895e113c
AB  - The ability to predict how amino acid changes affect proteins has a wide range of applications including in disease variant classification and protein engineering. Many existing methods focus on learning from patterns found in either protein sequences or protein structures. Here, we present a method for integrating information from sequence and structure in a single model that we term SSEmb (Sequence Structure Embedding). SSEmb combines a graph representation for the protein structure with a transformer model for processing multiple sequence alignments. We show that by integrating both types of information we obtain a variant effect prediction model that is robust when sequence information is scarce. We also show that SSEmb learns embeddings of the sequence and structure that are useful for other downstream tasks such as to predict protein-protein binding sites. We envisage that SSEmb may be useful both for variant effect predictions and as a representation for learning to predict protein properties that depend on sequence and structure. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Weissbart, H.
AU  - Martin, A.E.
TI  - The structure and statistics of language jointly shape cross-frequency neural dynamics during spoken language comprehension
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 8850
DO  - 10.1038/s41467-024-53128-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206274450&doi=10.1038%2fs41467-024-53128-1&partnerID=40&md5=665a1c1deb96c114a3e28df95447e56b
AB  - Humans excel at extracting structurally-determined meaning from speech despite inherent physical variability. This study explores the brain’s ability to predict and understand spoken language robustly. It investigates the relationship between structural and statistical language knowledge in brain dynamics, focusing on phase and amplitude modulation. Using syntactic features from constituent hierarchies and surface statistics from a transformer model as predictors of forward encoding models, we reconstructed cross-frequency neural dynamics from MEG data during audiobook listening. Our findings challenge a strict separation of linguistic structure and statistics in the brain, with both aiding neural signal reconstruction. Syntactic features have a more temporally spread impact, and both word entropy and the number of closing syntactic constituents are linked to the phase-amplitude coupling of neural dynamics, implying a role in temporal prediction and cortical oscillation alignment during speech processing. Our results indicate that structured and statistical information jointly shape neural dynamics during spoken language comprehension and suggest an integration process via a cross-frequency coupling mechanism. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Feng, B.
AU  - Zhou, X.-P.
TI  - The novel graph transformer-based surrogate model for learning physical systems
PY  - 2024
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 432
C7  - 117410
DO  - 10.1016/j.cma.2024.117410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205377716&doi=10.1016%2fj.cma.2024.117410&partnerID=40&md5=a417333388c3eb612bba302860635a8d
AB  - Predicting physical systems over long-term horizons has a significant challenge. Although prevalent machine learning techniques, such as Physics-Informed Neural Networks (PINNs), can achieve high accuracy, they primarily focus on single-step solutions and entail high computational costs. To address this gap, we propose a novel surrogate model leveraging graph representation for mesh-based physical systems. The proposed model incorporates Graph Transformer with attention mechanisms to aggregate information from neighboring nodes efficiently. Furthermore, we employ a multi-step prediction strategy in the loss function formulation to ensure robust long-term prediction capabilities. Additionally, in order to predict stress in solid mechanics, innovative symlog and symexp functions are proposed to enhance the robustness and reliability of the proposed model. Numerical results indicate that the proposed model can achieve high-accuracy and efficient long-term evolution prediction of physical systems. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Li, A.
AU  - Li, Y.
AU  - Xu, Y.
AU  - Li, X.
AU  - Zhang, C.
TI  - Multi-scale convolution enhanced transformer for multivariate long-term time series forecasting
PY  - 2024
T2  - Neural Networks
VL  - 180
C7  - 106745
DO  - 10.1016/j.neunet.2024.106745
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204960642&doi=10.1016%2fj.neunet.2024.106745&partnerID=40&md5=490451a8335163dbdd8e66d662d3d151
AB  - In data analysis and forecasting, particularly for multivariate long-term time series, challenges persist. The Transformer model in deep learning methods has shown significant potential in time series forecasting. The Transformer model's dot-product attention mechanism, however, due to its quadratic computational complexity, impairs training and forecasting efficiency. In addition, the Transformer architecture has limitations in modeling local features and dealing with multivariate cross-dimensional dependency relationship. In this article, a Multi-Scale Convolution Enhanced Transformer model (MSCformer) is proposed for multivariate long-term time series forecasting. As an alternative to modeling the time series in its entirety, a segmentation strategy is designed to convert the input original series into segmented forms with different lengths, then process time series segments using a new constructed multi-Dependency Aggregation module. This multi-Scale segmentation approach reduces the computational complexity of the attention mechanism part in subsequent models, and for each segment of length corresponds to a specific time scale, it also ensures that each segment retains the semantic information of the data sequence level, thereby comprehensively utilizing the multi-scale information of the data while more accurately capturing the real dependency of the time series. The Multi-Dependence Aggregate module captures both cross-temporal and cross-dimensional dependencies of multivariate long-term time series and compensates for local dependencies within the segments thereby captures local series features comprehensively and addressing the issue of insufficient information utilization. MSCformer synthesizes dependency information extracted from various temporal segments at different scales and reconstructs future series using linear layers. MSCformer exhibits higher forecasting accuracy, outperforming existing methods in multiple domains including energy, transportation, weather, electricity, disease and finance. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mohammadi, S.
AU  - Belgiu, M.
AU  - Stein, A.
TI  - A source-free unsupervised domain adaptation method for cross-regional and cross-time crop mapping from satellite image time series
PY  - 2024
T2  - Remote Sensing of Environment
VL  - 314
C7  - 114385
DO  - 10.1016/j.rse.2024.114385
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202981630&doi=10.1016%2fj.rse.2024.114385&partnerID=40&md5=23bc0e2703b43497e342f9db87a418a0
AB  - Precise and timely information about crop types plays a crucial role in various agriculture-related applications. However, crop type mapping methods often face significant challenges in cross-regional and cross-time scenarios with high discrepancies between temporal-spectral characteristics of crops from different regions and years. Unsupervised domain adaptation (UDA) methods have been employed to mitigate the problem of domain shift between the source and target domains. Since these methods require source domain data during the adaptation phase, they demand significant computational resources and data storage, especially when large labeled crop mapping source datasets are available. This leads to increased energy consumption and financial costs. To address this limitation, we developed a source-free UDA method for cross-regional and cross-time crop mapping, capable of adapting the source-pretrained models to the target datasets without requiring the source datasets. The method mitigates the domain shift problem by leveraging mutual information loss. The diversity and discriminability terms in the loss function are balanced through a novel unsupervised weighting strategy based on mean confidence scores of the predicted categories. Our experiments on mapping corn, soybean, and the class Other from Landsat image time series in the U.S. demonstrated that the adapted models using different backbone networks outperformed their non-adapted counterparts. With CNN, Transformer, and LSTM backbone networks, our adaptation method increased the macro F1 scores by 12.9%, 7.1%, and 5.8% on average in cross-time tests and by 20.1%, 12.5%, and 8.8% on average in cross-regional tests, respectively. Additionally, in an experiment covering a large study area of 450 km × 300 km, the adapted model with the CNN backbone network obtained a macro F1 score of 92.6%, outperforming its non-adapted counterpart with a macro F1 score of 89.2%. Our experiments on mapping the same classes using Sentinel-2 image times series in France demonstrated the effectiveness of our method across different countries and sensors. We also tested our method in more diverse agricultural areas in Denmark and France containing six classes. The results showed that the adapted models outperformed the non-adapted models. Moreover, in within-season experiments, the adapted models performed better than the non-adapted models in the vast majority of weeks. These results and their comparison to those obtained by the other investigated UDA methods demonstrated the efficiency of our proposed method for both end-of-season and within-season crop mapping tasks. Additionally, our study showed that the method is modular and flexible in employing various backbone networks. The code and data are available at https://github.com/Sina-Mohammadi/SFUDA-CropMapping. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lu, S.
AU  - Gao, Z.
AU  - He, D.
AU  - Zhang, L.
AU  - Ke, G.
TI  - Data-driven quantum chemical property prediction leveraging 3D conformations with Uni-Mol+
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 7104
DO  - 10.1038/s41467-024-51321-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201367008&doi=10.1038%2fs41467-024-51321-w&partnerID=40&md5=12f9e88a9ebdc7cc64780a1096318e37
AB  - Quantum chemical (QC) property prediction is crucial for computational materials and drug design, but relies on expensive electronic structure calculations like density functional theory (DFT). Recent deep learning methods accelerate this process using 1D SMILES or 2D graphs as inputs but struggle to achieve high accuracy as most QC properties depend on refined 3D molecular equilibrium conformations. We introduce Uni-Mol+, a deep learning approach that leverages 3D conformations for accurate QC property prediction. Uni-Mol+ first generates a raw 3D conformation using RDKit then iteratively refines it towards DFT equilibrium conformation using neural networks, which is finally used to predict the QC properties. To effectively learn this conformation update process, we introduce a two-track Transformer model backbone and a novel training approach. Our benchmarking results demonstrate that the proposed Uni-Mol+ significantly improves the accuracy of QC property prediction in various datasets. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Liu, F.
TI  - Scalable video transformer for full-frame video prediction
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 249
C7  - 104166
DO  - 10.1016/j.cviu.2024.104166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205012138&doi=10.1016%2fj.cviu.2024.104166&partnerID=40&md5=89e4755bd61e79c8eb797c0baf524859
AB  - Vision Transformers (ViTs) have shown success in many low-level computer vision tasks. However, existing ViT models are limited by their high computation and memory cost when generating high-resolution videos for tasks like video prediction. This paper presents a scalable video transformer for full-frame video predication. Specifically, we design a backbone transformer block for our video transformer. This transformer block decouples the temporal and channel features to reduce the computation cost when processing large-scale spatial–temporal video features. We use transposed attention to focus on the channel dimension instead of the spatial window to further reduce the computation cost. We also design a Global Shifted Multi-Dconv Head Transposed Attention module (GSMDTA) for our transformer block. This module is built upon two key ideas. First, we design a depth shift module to better incorporate the cross-channel or temporal information from video features. Second, we introduce a global query mechanism to capture global information to handle large motion for video prediction. This new transformer block enables our video transformer to predict a full frame from multiple past frames at the resolution of 1024 × 512 with 12 GB VRAM. Experiments on various video prediction benchmarks demonstrate that our method with only RGB input outperforms state-of-the-art methods that require additional data, like segmentation maps and optical flows. Our method exceeds the state-of-the-art RGB-only methods by a large margin (1.2 dB) in PSNR. Our method is also faster than state-of-the-art video prediction transformers. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zanella, L.
AU  - Liberatori, B.
AU  - Menapace, W.
AU  - Poiesi, F.
AU  - Wang, Y.
AU  - Ricci, E.
TI  - Delving into CLIP latent space for Video Anomaly Recognition
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 249
C7  - 104163
DO  - 10.1016/j.cviu.2024.104163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204962363&doi=10.1016%2fj.cviu.2024.104163&partnerID=40&md5=eaee9c2a0a35ce06a28e2731124fb01a
AB  - We tackle the complex problem of detecting and recognising anomalies in surveillance videos at the frame level, utilising only video-level supervision. We introduce the novel method AnomalyCLIP, the first to combine Vision and Language Models (VLMs), such as CLIP, with multiple instance learning for joint video anomaly detection and classification. Our approach specifically involves manipulating the latent CLIP feature space to identify the normal event subspace, which in turn allows us to effectively learn text-driven directions for abnormal events. When anomalous frames are projected onto these directions, they exhibit a large feature magnitude if they belong to a particular class. We also leverage a computationally efficient Transformer architecture to model short- and long-term temporal dependencies between frames, ultimately producing the final anomaly score and class prediction probabilities. We compare AnomalyCLIP against state-of-the-art methods considering three major anomaly detection benchmarks, i.e. ShanghaiTech, UCF-Crime, and XD-Violence, and empirically show that it outperforms baselines in recognising video anomalies. Project website and code are available at https://lucazanella.github.io/AnomalyCLIP/. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Osman, N.
AU  - Camporese, G.
AU  - Ballan, L.
TI  - Multi-modal transformer with language modality distillation for early pedestrian action anticipation
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 249
C7  - 104144
DO  - 10.1016/j.cviu.2024.104144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204073558&doi=10.1016%2fj.cviu.2024.104144&partnerID=40&md5=5cf28809dd0d0251ce0a98f2af6da6ae
AB  - Language-vision integration has become an increasingly popular research direction within the computer vision field. In recent years, there has been a growing recognition of the importance of incorporating linguistic information into visual tasks, particularly in domains such as action anticipation. This integration allows anticipation models to leverage textual descriptions to gain deeper contextual understanding, leading to more accurate predictions. In this work, we focus on pedestrian action anticipation, where the objective is the early prediction of pedestrians’ future actions in urban environments. Our method relies on a multi-modal transformer model that encodes past observations and produces predictions at different anticipation times, employing a learned mask technique to filter out redundancy in the observed frames. Instead of relying solely on visual cues extracted from images or videos, we explore the impact of integrating textual information in enriching the input modalities of our pedestrian action anticipation model. We investigate various techniques for generating descriptive captions corresponding to input images, aiming to enhance the anticipation performance. Evaluation results on available public benchmarks demonstrate the effectiveness of our method in improving the prediction performance at different anticipation times compared to previous works. Additionally, incorporating the language modality in our anticipation model proved significant improvement, reaching a 29.5% increase in the F1 score at 1-second anticipation and a 16.66% increase at 4-second anticipation. These results underscore the potential of language-vision integration in advancing pedestrian action anticipation in complex urban environments. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kadan, A.
AU  - Deepak, P.
AU  - Gangan, M.P.
AU  - Abraham, S.S.
AU  - Lajish, V.L.
TI  - REDAffectiveLM: leveraging affect enriched embedding and transformer-based neural language model for readers’ emotion detection
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 12
SP  - 7495
EP  - 7525
DO  - 10.1007/s10115-024-02194-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201547232&doi=10.1007%2fs10115-024-02194-4&partnerID=40&md5=0cd9303c4e42b6f8a043c6f362a0760c
AB  - Technological advancements in web platforms allow people to express and share emotions toward textual write-ups written and shared by others. This brings about different interesting domains for analysis, emotion expressed by the writer and emotion elicited from the readers. In this paper, we propose a novel approach for readers’ emotion detection from short-text documents using a deep learning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is well understood that utilizing context-specific representations from transformer-based pre-trained language models helps achieve improved performance. Within this affective computing task, we explore how incorporating affective information can further enhance performance. Toward this, we leverage context-specific and affect enriched representations by using a transformer-based pre-trained language model in tandem with affect enriched Bi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k, besides using RENh-4k and SemEval-2007. We evaluate the performance of our REDAffectiveLM rigorously across these datasets, against a vast set of state-of-the-art baselines, where our model consistently outperforms baselines and obtains statistically significant results. Our results establish that utilizing affect enriched representation along with context-specific representation within a neural architecture can considerably enhance readers’ emotion detection. Since the impact of affect enrichment specifically in readers’ emotion detection isn’t well explored, we conduct a detailed analysis over affect enriched Bi-LSTM+Attention using qualitative and quantitative model behavior evaluation techniques. We observe that compared to conventional semantic embedding, affect enriched embedding increases the ability of the network to effectively identify and assign weightage to the key terms responsible for readers’ emotion detection to improve prediction. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Zhang, Z.
AU  - Schaeffer, H.
TI  - PROSE: Predicting Multiple Operators and Symbolic Expressions using multimodal transformers
PY  - 2024
T2  - Neural Networks
VL  - 180
C7  - 106707
DO  - 10.1016/j.neunet.2024.106707
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204977745&doi=10.1016%2fj.neunet.2024.106707&partnerID=40&md5=9aee860d519d4daa425cc5c3e488f7c1
AB  - Approximating nonlinear differential equations using a neural network provides a robust and efficient tool for various scientific computing tasks, including real-time predictions, inverse problems, optimal controls, and surrogate modeling. Previous works have focused on embedding dynamical systems into networks through two approaches: learning a single operator (i.e., the mapping from input parameterised functions to solutions) or learning the governing system of equations (i.e., the constitutive model relative to the state variables). Both of these approaches yield different representations for the same underlying data or function. Observing that families of differential equations often share key characteristics, we seek one network representation across a wide range of equations. Our multimodality approach, called Predicting Multiple Operators and Symbolic Expressions (PROSE), is capable of constructing multi-operators and governing equations simultaneously through a novel fusion structure. In particular, PROSE solves differential equations, predicts future states, and generates the underlying equations of motion by incorporating symbolic “words” through a language model. Experiments with 25600 distinct equations show that PROSE benefits from its multimodal nature, resulting in robust generalization (e.g. noisy observations, equation misspecification, and data imbalance) supported by comparison and ablation studies. PROSE provides a new operator learning framework that incorporates multimodal input/output and language models for solving forward and inverse problems related to differential equations. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sanabria, M.
AU  - Hirsch, J.
AU  - Poetsch, A.R.
TI  - Distinguishing word identity and sequence context in DNA language models
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 301
DO  - 10.1186/s12859-024-05869-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203874823&doi=10.1186%2fs12859-024-05869-5&partnerID=40&md5=cfa985529d638985a6de5d96a7bbfe03
AB  - Transformer-based large language models (LLMs) are very suited for biological sequence data, because of analogies to natural language. Complex relationships can be learned, because a concept of "words" can be generated through tokenization. Training the models with masked token prediction, they learn both token sequence identity and larger sequence context. We developed methodology to interrogate model learning, which is both relevant for the interpretability of the model and to evaluate its potential for specific tasks. We used DNABERT, a DNA language model trained on the human genome with overlapping k-mers as tokens. To gain insight into the model′s learning, we interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps. This task evaluates foundation models without interrogating specific genome biology, it does not depend on tokenization strategies, vocabulary size, the dictionary, or the number of training parameters. Lastly, there is no leakage of information from token identity into the prediction task, which makes it particularly useful to evaluate the learning of sequence context. We discovered that the model with overlapping k-mers struggles to learn larger sequence context. Instead, the learned embeddings largely represent token sequence. Still, good performance is achieved for genome-biology-inspired fine-tuning tasks. Models with overlapping tokens may be used for tasks where a larger sequence context is of less relevance, but the token sequence directly represents the desired learning features. This emphasizes the need to interrogate knowledge representation in biological LLMs. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Sanabria2024Distinguishing
ER  -

TY  - JOUR
AU  - Krapp, L.F.
AU  - Meireles, F.A.
AU  - Abriata, L.A.
AU  - Devillard, J.
AU  - Vacle, S.
AU  - Marcaida, M.J.
AU  - Dal Peraro, M.
TI  - Context-aware geometric deep learning for protein sequence design
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 6273
DO  - 10.1038/s41467-024-50571-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199550670&doi=10.1038%2fs41467-024-50571-y&partnerID=40&md5=30c1f83b847b8b56be4068e19898f677
AB  - Protein design and engineering are evolving at an unprecedented pace leveraging the advances in deep learning. Current models nonetheless cannot natively consider non-protein entities within the design process. Here, we introduce a deep learning approach based solely on a geometric transformer of atomic coordinates and element names that predicts protein sequences from backbone scaffolds aware of the restraints imposed by diverse molecular environments. To validate the method, we show that it can produce highly thermostable, catalytically active enzymes with high success rates. This concept is anticipated to improve the versatility of protein design pipelines for crafting desired functions. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Oliver, M.
AU  - Allou, N.
AU  - Devineau, M.
AU  - Allyn, J.
AU  - Ferdynus, C.
TI  - A transformer model for cause-specific hazard prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 175
DO  - 10.1186/s12859-024-05799-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192108759&doi=10.1186%2fs12859-024-05799-2&partnerID=40&md5=4a3ed79c22d5ee633504b325e549c5ef
AB  - Backgroud: Modelling discrete-time cause-specific hazards in the presence of competing events and non-proportional hazards is a challenging task in many domains. Survival analysis in longitudinal cohorts often requires such models; notably when the data is gathered at discrete points in time and the predicted events display complex dynamics. Current models often rely on strong assumptions of proportional hazards, that is rarely verified in practice; or do not handle sequential data in a meaningful way. This study proposes a Transformer architecture for the prediction of cause-specific hazards in discrete-time competing risks. Contrary to Multilayer perceptrons that were already used for this task (DeepHit), the Transformer architecture is especially suited for handling complex relationships in sequential data, having displayed state-of-the-art performance in numerous tasks with few underlying assumptions on the task at hand. Results: Using synthetic datasets of 2000–50,000 patients, we showed that our Transformer model surpassed the CoxPH, PyDTS, and DeepHit models for the prediction of cause-specific hazard, especially when the proportional assumption did not hold. The error along simulated time outlined the ability of our model to anticipate the evolution of cause-specific hazards at later time steps where few events are observed. It was also superior to current models for prediction of dementia and other psychiatric conditions in the English longitudinal study of ageing cohort using the integrated brier score and the time-dependent concordance index. We also displayed the explainability of our model’s prediction using the integrated gradients method. Conclusions: Our model provided state-of-the-art prediction of cause-specific hazards, without adopting prior parametric assumptions on the hazard rates. It outperformed other models in non-proportional hazards settings for both the synthetic dataset and the longitudinal cohort study. We also observed that basic models such as CoxPH were more suited to extremely simple settings than deep learning models. Our model is therefore especially suited for survival analysis on longitudinal cohorts with complex dynamics of the covariate-to-outcome relationship, which are common in clinical practice. The integrated gradients provided the importance scores of input variables, which indicated variables guiding the model in its prediction. This model is ready to be utilized for time-to-event prediction in longitudinal cohorts. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Oliver2024transformer
ER  -

TY  - JOUR
AU  - Wan, J.
AU  - Liu, H.
AU  - Wu, Y.
AU  - Lai, Z.
AU  - Min, W.
AU  - Liu, J.
TI  - Precise facial landmark detection by Dynamic Semantic Aggregation Transformer
PY  - 2024
T2  - Pattern Recognition
VL  - 156
C7  - 110827
DO  - 10.1016/j.patcog.2024.110827
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199989820&doi=10.1016%2fj.patcog.2024.110827&partnerID=40&md5=aa4516d7ed1b591fdf930b53d6464259
AB  - At present, deep neural network methods have played a dominant role in face alignment field. However, they generally use predefined network structures to predict landmarks, which tends to learn general features and leads to mediocre performance, e.g., they perform well on neutral samples but struggle with faces exhibiting large poses or occlusions. Moreover, they cannot effectively deal with semantic gaps and ambiguities among features at different scales, which may hinder them from learning efficient features. To address the above issues, in this paper, we propose a Dynamic Semantic-Aggregation Transformer (DSAT) for more discriminative and representative feature (i.e., specialized feature) learning. Specifically, a Dynamic Semantic-Aware (DSA) model is first proposed to partition samples into subsets and activate the specific pathways for them by estimating the semantic correlations of feature channels, making it possible to learn specialized features from each subset. Then, a novel Dynamic Semantic Specialization (DSS) model is designed to mine the homogeneous information from features at different scales for eliminating the semantic gap and ambiguities and enhancing the representation ability. Finally, by integrating the DSA model and DSS model into our proposed DSAT in both dynamic architecture and dynamic parameter manners, more specialized features can be learned for achieving more precise face alignment. It is interesting to show that harder samples can be handled by activating more feature channels. Extensive experiments on popular face alignment datasets demonstrate that our proposed DSAT outperforms state-of-the-art models in the literature. Our code is available at https://github.com/GERMINO-LiuHe/DSAT. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Alfasly, S.
AU  - Lu, J.
AU  - Xu, C.
AU  - Li, Y.
AU  - Zou, Y.
TI  - Auxiliary audio–textual modalities for better action recognition on vision-specific annotated videos
PY  - 2024
T2  - Pattern Recognition
VL  - 156
C7  - 110808
DO  - 10.1016/j.patcog.2024.110808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199944110&doi=10.1016%2fj.patcog.2024.110808&partnerID=40&md5=0abace8d055456d5b69620731bc014d0
AB  - Most current audio–visual datasets are class-relevant, where audio and visual modalities are annotated. Thus, current audio–visual recognition methods apply cross-modality attention or modality fusion. However, leveraging the audio modality effectively in vision-specific videos for human activity recognition is of particular challenge. We address this challenge by proposing a novel audio–visual recognition framework that effectively leverages audio modality in any vision-specific annotated dataset. The proposed framework employs language models (e.g., GPT-3, CPT-text, BERT) for building a semantic audio–video label dictionary (SAVLD) that serves as a bridge between audio and video datasets by mapping each video label to its most K-relevant audio labels. Then, SAVLD along with a pre-trained audio multi-label model are used to estimate the audio–visual modality relevance. Accordingly, we propose a novel learnable irrelevant modality dropout (IMD) to completely drop the irrelevant audio modality and fuse only the relevant modalities. Finally, for the efficiency of the proposed multimodal framework, we present an efficient two-stream video Transformer to process the visual modalities (i.e., RGB frames and optical flow). The final predictions are re-ranked with GPT-3 recommendations of the human activity classes. GPT-3 provides high-level recommendations using the labels of the detected visual objects and the audio predictions of the input video. Our framework demonstrated a remarkable performance on the vision-specific annotated datasets Kinetics400 and UCF-101 by outperforming most relevant human activity recognition methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Aksamit, N.
AU  - Tchagang, A.
AU  - Li, Y.
AU  - Ombuki-Berman, B.
TI  - Hybrid fragment-SMILES tokenization for ADMET prediction in drug discovery
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 255
DO  - 10.1186/s12859-024-05861-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200259886&doi=10.1186%2fs12859-024-05861-z&partnerID=40&md5=ad9adcb793a7491349c1c631efbe5484
AB  - Background: Drug discovery and development is the extremely costly and time-consuming process of identifying new molecules that can interact with a biomarker target to interrupt the disease pathway of interest. In addition to binding the target, a drug candidate needs to satisfy multiple properties affecting absorption, distribution, metabolism, excretion, and toxicity (ADMET). Artificial intelligence approaches provide an opportunity to improve each step of the drug discovery and development process, in which the first question faced by us is how a molecule can be informatively represented such that the in-silico solutions are optimized. Results: This study introduces a novel hybrid SMILES-fragment tokenization method, coupled with two pre-training strategies, utilizing a Transformer-based model. We investigate the efficacy of hybrid tokenization in improving the performance of ADMET prediction tasks. Our approach leverages MTL-BERT, an encoder-only Transformer model that achieves state-of-the-art ADMET predictions, and contrasts the standard SMILES tokenization with our hybrid method across a spectrum of fragment library cutoffs. Conclusion: The findings reveal that while an excess of fragments can impede performance, using hybrid tokenization with high frequency fragments enhances results beyond the base SMILES tokenization. This advancement underscores the potential of integrating fragment- and character-level molecular features within the training of Transformer models for ADMET property prediction. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Aksamit2024Hybrid
ER  -

TY  - JOUR
AU  - Giri, N.
AU  - Cheng, J.
TI  - De novo atomic protein structure modeling for cryoEM density maps using 3D transformer and HMM
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 5511
DO  - 10.1038/s41467-024-49647-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197648578&doi=10.1038%2fs41467-024-49647-6&partnerID=40&md5=b56d76bf5c855689a018cea6b7d2ae74
AB  - Accurately building 3D atomic structures from cryo-EM density maps is a crucial step in cryo-EM-based protein structure determination. Converting density maps into 3D atomic structures for proteins lacking accurate homologous or predicted structures as templates remains a significant challenge. Here, we introduce Cryo2Struct, a fully automated de novo cryo-EM structure modeling method. Cryo2Struct utilizes a 3D transformer to identify atoms and amino acid types in cryo-EM density maps, followed by an innovative Hidden Markov Model (HMM) to connect predicted atoms and build protein backbone structures. Cryo2Struct produces substantially more accurate and complete protein structural models than the widely used ab initio method Phenix. Additionally, its performance in building atomic structural models is robust against changes in the resolution of density maps and the size of protein structures. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Cisternino, F.
AU  - Ometto, S.
AU  - Chatterjee, S.
AU  - Giacopuzzi, E.
AU  - Levine, A.P.
AU  - Glastonbury, C.A.
TI  - Self-supervised learning for characterising histomorphological diversity and spatial RNA expression prediction across 23 human tissue types
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 5906
DO  - 10.1038/s41467-024-50317-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198397243&doi=10.1038%2fs41467-024-50317-w&partnerID=40&md5=fb7815faa20779289c2f8a29d8d361b4
AB  - As vast histological archives are digitised, there is a pressing need to be able to associate specific tissue substructures and incident pathology to disease outcomes without arduous annotation. Here, we learn self-supervised representations using a Vision Transformer, trained on 1.7 M histology images across 23 healthy tissues in 838 donors from the Genotype Tissue Expression consortium (GTEx). Using these representations, we can automatically segment tissues into their constituent tissue substructures and pathology proportions across thousands of whole slide images, outperforming other self-supervised methods (43% increase in silhouette score). Additionally, we can detect and quantify histological pathologies present, such as arterial calcification (AUROC = 0.93) and identify missing calcification diagnoses. Finally, to link gene expression to tissue morphology, we introduce RNAPath, a set of models trained on 23 tissue types that can predict and spatially localise individual RNA expression levels directly from H&E histology (mean genes significantly regressed = 5156, FDR 1%). We validate RNAPath spatial predictions with matched ground truth immunohistochemistry for several well characterised control genes, recapitulating their known spatial specificity. Together, these results demonstrate how self-supervised machine learning when applied to vast histological archives allows researchers to answer questions about tissue pathology, its spatial organisation and the interplay between morphological tissue variability and gene expression. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Hu, L.
AU  - Zu, C.
AU  - Zhang, J.
AU  - Hou, Y.
AU  - Chen, Y.
AU  - Zhou, J.
AU  - Zhou, L.
AU  - Wang, Y.
TI  - CL-TransFER: Collaborative learning based transformer for facial expression recognition with masked reconstruction
PY  - 2024
T2  - Pattern Recognition
VL  - 156
C7  - 110741
DO  - 10.1016/j.patcog.2024.110741
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198249831&doi=10.1016%2fj.patcog.2024.110741&partnerID=40&md5=1d2df56a54e69fd288fb1245262efd3f
AB  - Facial expression recognition (FER) has attracted intensive attention due to its critical role in various computer vision tasks. However, existing FER approaches suffer from either noisy annotations or expression ambiguity (high inter-class and low intra-class similarity), limiting the FER performance. To this end, we propose a robust end-to-end collaborative learning based transformer for FER (CL-TransFER) in this paper. Specifically, CL-TransFER co-trains a CNN feature extractor and a transformer feature extractor jointly to extract both rich local semantic features as well as global structural information from facial images. By enforcing the consensus between the predictions of two extractors, the CL-TransFER could suppress the influence of noisy annotations. To further tackle the expression ambiguity problem, we design a simple yet efficient self-supervised masked reconstruction (SSMR) task to pre-train the transformer feature extractor of CL-TransFER. This enhances the model's capability of learning fine-grained discriminative representations. Extensive experiments on three popular benchmarks have demonstrated the effectiveness and superiority of our method. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Aksamit, N.
AU  - Hou, J.
AU  - Li, Y.
AU  - Ombuki-Berman, B.
TI  - Integrating transformers and many-objective optimization for drug design
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 208
DO  - 10.1186/s12859-024-05822-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195533391&doi=10.1186%2fs12859-024-05822-6&partnerID=40&md5=9005e1932ef780845a40d82b750e2949
AB  - Background: Drug design is a challenging and important task that requires the generation of novel and effective molecules that can bind to specific protein targets. Artificial intelligence algorithms have recently showed promising potential to expedite the drug design process. However, existing methods adopt multi-objective approaches which limits the number of objectives. Results: In this paper, we expand this thread of research from the many-objective perspective, by proposing a novel framework that integrates a latent Transformer-based model for molecular generation, with a drug design system that incorporates absorption, distribution, metabolism, excretion, and toxicity prediction, molecular docking, and many-objective metaheuristics. We compared the performance of two latent Transformer models (ReLSO and FragNet) on a molecular generation task and show that ReLSO outperforms FragNet in terms of reconstruction and latent space organization. We then explored six different many-objective metaheuristics based on evolutionary algorithms and particle swarm optimization on a drug design task involving potential drug candidates to human lysophosphatidic acid receptor 1, a cancer-related protein target. Conclusion: We show that multi-objective evolutionary algorithm based on dominance and decomposition performs the best in terms of finding molecules that satisfy many objectives, such as high binding affinity and low toxicity, and high drug-likeness. Our framework demonstrates the potential of combining Transformers and many-objective computational intelligence for drug design. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Aksamit2024Integrating
ER  -

TY  - JOUR
AU  - Stanojević, D.
AU  - Li, Z.
AU  - Bakić, S.
AU  - Foo, R.
AU  - Šikić, M.
TI  - Rockfish: A transformer-based model for accurate 5-methylcytosine prediction from nanopore sequencing
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 5580
DO  - 10.1038/s41467-024-49847-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197381856&doi=10.1038%2fs41467-024-49847-0&partnerID=40&md5=3ab354458f42a724eb4e69d8c0621a3a
AB  - DNA methylation plays an important role in various biological processes, including cell differentiation, ageing, and cancer development. The most important methylation in mammals is 5-methylcytosine mostly occurring in the context of CpG dinucleotides. Sequencing methods such as whole-genome bisulfite sequencing successfully detect 5-methylcytosine DNA modifications. However, they suffer from the serious drawbacks of short read lengths and might introduce an amplification bias. Here we present Rockfish, a deep learning algorithm that significantly improves read-level 5-methylcytosine detection by using Nanopore sequencing. Rockfish is compared with other methods based on Nanopore sequencing on R9.4.1 and R10.4.1 datasets. There is an increase in the single-base accuracy and the F1 measure of up to 5 percentage points on R.9.4.1 datasets, and up to 0.82 percentage points on R10.4.1 datasets. Moreover, Rockfish shows a high correlation with whole-genome bisulfite sequencing, requires lower read depth, and achieves higher confidence in biologically important regions such as CpG-rich promoters while being computationally efficient. Its superior performance in human and mouse samples highlights its versatility for studying 5-methylcytosine methylation across varied organisms and diseases. Finally, its adaptable architecture ensures compatibility with new versions of pores and chemistry as well as modification types. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kumar, S.
AU  - Sumers, T.R.
AU  - Yamakoshi, T.
AU  - Goldstein, A.
AU  - Hasson, U.
AU  - Norman, K.A.
AU  - Griffiths, T.L.
AU  - Hawkins, R.D.
AU  - Nastase, S.A.
TI  - Shared functional specialization in transformer-based language models and the human brain
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 5523
DO  - 10.1038/s41467-024-49173-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197356145&doi=10.1038%2fs41467-024-49173-5&partnerID=40&md5=aec51f5f2c09cd70e69b66591ec04170
AB  - When processing language, the brain is thought to deploy specialized computations to construct meaning from complex linguistic structures. Recently, artificial neural networks based on the Transformer architecture have revolutionized the field of natural language processing. Transformers integrate contextual information across words via structured circuit computations. Prior work has focused on the internal representations (“embeddings”) generated by these circuits. In this paper, we instead analyze the circuit computations directly: we deconstruct these computations into the functionally-specialized “transformations” that integrate contextual information across words. Using functional MRI data acquired while participants listened to naturalistic stories, we first verify that the transformations account for considerable variance in brain activity across the cortical language network. We then demonstrate that the emergent computations performed by individual, functionally-specialized “attention heads” differentially predict brain activity in specific cortical regions. These heads fall along gradients corresponding to different layers and context lengths in a low-dimensional cortical space. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wei, Z.
AU  - Zhao, C.
AU  - Zhang, M.
AU  - Xu, J.
AU  - Xu, N.
AU  - Wu, S.
AU  - Xin, X.
AU  - Yu, L.
AU  - Feng, W.
TI  - PrCRS: a prediction model of severe CRS in CAR-T therapy based on transfer learning
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 197
DO  - 10.1186/s12859-024-05804-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193804776&doi=10.1186%2fs12859-024-05804-8&partnerID=40&md5=629afbd214c9cf23d7e7abec7eb5780f
AB  - Background: CAR-T cell therapy represents a novel approach for the treatment of hematologic malignancies and solid tumors. However, its implementation is accompanied by the emergence of potentially life-threatening adverse events known as cytokine release syndrome (CRS). Given the escalating number of patients undergoing CAR-T therapy, there is an urgent need to develop predictive models for severe CRS occurrence to prevent it in advance. Currently, all existing models are based on decision trees whose accuracy is far from meeting our expectations, and there is a lack of deep learning models to predict the occurrence of severe CRS more accurately. Results: We propose PrCRS, a deep learning prediction model based on U-net and Transformer. Given the limited data available for CAR-T patients, we employ transfer learning using data from COVID-19 patients. The comprehensive evaluation demonstrates the superiority of the PrCRS model over other state-of-the-art methods for predicting CRS occurrence. We propose six models to forecast the probability of severe CRS for patients with one, two, and three days in advance. Additionally, we present a strategy to convert the model's output into actual probabilities of severe CRS and provide corresponding predictions. Conclusions: Based on our findings, PrCRS effectively predicts both the likelihood and timing of severe CRS in patients, thereby facilitating expedited and precise patient assessment, thus making a significant contribution to medical research. There is little research on applying deep learning algorithms to predict CRS, and our study fills this gap. This makes our research more novel and significant. Our code is publicly available at https://github.com/wzy38828201/PrCRS. The website of our prediction platform is: http://prediction.unicar-therapy.com/index-en.html. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Wei2024PrCRS
ER  -

TY  - JOUR
AU  - Sadeghi, S.
AU  - Bui, A.
AU  - Forooghi, A.
AU  - Lu, J.
AU  - Ngom, A.
TI  - Can large language models understand molecules?
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 225
DO  - 10.1186/s12859-024-05847-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197180887&doi=10.1186%2fs12859-024-05847-x&partnerID=40&md5=d6306148d578fe6bcc56789b6d82f49c
AB  - Purpose: Large Language Models (LLMs) like Generative Pre-trained Transformer (GPT) from OpenAI and LLaMA (Large Language Model Meta AI) from Meta AI are increasingly recognized for their potential in the field of cheminformatics, particularly in understanding Simplified Molecular Input Line Entry System (SMILES), a standard method for representing chemical structures. These LLMs also have the ability to decode SMILES strings into vector representations. Method: We investigate the performance of GPT and LLaMA compared to pre-trained models on SMILES in embedding SMILES strings on downstream tasks, focusing on two key applications: molecular property prediction and drug-drug interaction prediction. Results: We find that SMILES embeddings generated using LLaMA outperform those from GPT in both molecular property and DDI prediction tasks. Notably, LLaMA-based SMILES embeddings show results comparable to pre-trained models on SMILES in molecular prediction tasks and outperform the pre-trained models for the DDI prediction tasks. Conclusion: The performance of LLMs in generating SMILES embeddings shows great potential for further investigation of these models for molecular embedding. We hope our study bridges the gap between LLMs and molecular embedding, motivating additional research into the potential of LLMs in the molecular representation field. GitHub: https://github.com/sshaghayeghs/LLaMA-VS-GPT. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Sadeghi2024Can
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Liu, G.
AU  - Xu, F.
AU  - Deng, L.
TI  - CarvingNet: Point cloud completion by stepwise refining multi-resolution features
PY  - 2024
T2  - Pattern Recognition
VL  - 156
C7  - 110780
DO  - 10.1016/j.patcog.2024.110780
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199472007&doi=10.1016%2fj.patcog.2024.110780&partnerID=40&md5=53bbdd640a80e8766cd79650dbc0c348
AB  - In the field of 3D vision, 3D point cloud completion is a crucial task in many practical applications. Current methods use Transformer's Encoder-Decoder framework to predict the missing part of the point cloud features at low resolution, which does not fully utilize the feature information at multiple resolutions and can result in the loss of the object's geometric details. In this paper, we present a novel point cloud completion method, CarvingNet, which, to the best of our knowledge, is the first to apply the U-Net architecture to the point cloud completion task by operating directly on unordered point cloud features at multiple resolutions. Firstly, we gradually expand the receptive field and use cross-attention to purify the features of the missing part of the point cloud at each resolution and to generate the contour features of the complete point cloud at the last obtained resolution. Then, we gradually reduce the receptive field and use cross-attention to refine the features of the complete point cloud at each resolution and to generate the features of the complete point cloud with rich details at the last obtained resolution. To obtain point cloud features at different resolutions, we specifically design the up-sampling module and down-sampling module for disordered point cloud features. Furthermore, we improve the FoldingNet network to make it more suitable for generating high-quality dense point clouds. The experimental results demonstrate that our proposed CarvingNet achieves the performance of existing state-of-the-art methods on the ShapeNet-55, ShapeNet-34, and KITTI benchmarks. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ahmed, F.S.
AU  - Aly, S.
AU  - Liu, X.
TI  - EPI-Trans: an effective transformer-based deep learning model for enhancer promoter interaction prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 216
DO  - 10.1186/s12859-024-05784-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196151842&doi=10.1186%2fs12859-024-05784-9&partnerID=40&md5=ccaed3fd449a58cc80705d8015b3d775
AB  - Background: Recognition of enhancer–promoter Interactions (EPIs) is crucial for human development. EPIs in the genome play a key role in regulating transcription. However, experimental approaches for classifying EPIs are too expensive in terms of effort, time, and resources. Therefore, more and more studies are being done on developing computational techniques, particularly using deep learning and other machine learning techniques, to address such problems. Unfortunately, the majority of current computational methods are based on convolutional neural networks, recurrent neural networks, or a combination of them, which don’t take into consideration contextual details and the long-range interactions between the enhancer and promoter sequences. A new transformer-based model called EPI-Trans is presented in this study to overcome the aforementioned limitations. The multi-head attention mechanism in the transformer model automatically learns features that represent the long interrelationships between enhancer and promoter sequences. Furthermore, a generic model is created with transferability that can be utilized as a pre-trained model for various cell lines. Moreover, the parameters of the generic model are fine-tuned using a particular cell line dataset to improve performance. Results: Based on the results obtained from six benchmark cell lines, the average AUROC for the specific, generic, and best models is 94.2%, 95%, and 95.7%, while the average AUPR is 80.5%, 66.1%, and 79.6% respectively. Conclusions: This study proposed a transformer-based deep learning model for EPI prediction. The comparative results on certain cell lines show that EPI-Trans outperforms other cutting-edge techniques and can provide superior performance on the challenge of recognizing EPI. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Ahmed2024EPI-Trans
ER  -

TY  - JOUR
AU  - Hao, A.
AU  - Yuan, H.
AU  - Hui, S.C.
AU  - Su, J.
TI  - Effective type label-based synergistic representation learning for biomedical event trigger detection
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 251
DO  - 10.1186/s12859-024-05851-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200257970&doi=10.1186%2fs12859-024-05851-1&partnerID=40&md5=20766319435bede235f3460eb86748ff
AB  - Background: Detecting event triggers in biomedical texts, which contain domain knowledge and context-dependent terms, is more challenging than in general-domain texts. Most state-of-the-art models rely mainly on external resources such as linguistic tools and knowledge bases to improve system performance. However, they lack effective mechanisms to obtain semantic clues from label specification and sentence context. Given its success in image classification, label representation learning is a promising approach to enhancing biomedical event trigger detection models by leveraging the rich semantics of pre-defined event type labels. Results: In this paper, we propose the Biomedical Label-based Synergistic representation Learning (BioLSL) model, which effectively utilizes event type labels by learning their correlation with trigger words and enriches the representation contextually. The BioLSL model consists of three modules. Firstly, the Domain-specific Joint Encoding module employs a transformer-based, domain-specific pre-trained architecture to jointly encode input sentences and pre-defined event type labels. Secondly, the Label-based Synergistic Representation Learning module learns the semantic relationships between input texts and event type labels, and generates a Label-Trigger Aware Representation (LTAR) and a Label-Context Aware Representation (LCAR) for enhanced semantic representations. Finally, the Trigger Classification module makes structured predictions, where each label is predicted with respect to its neighbours. We conduct experiments on three benchmark BioNLP datasets, namely MLEE, GE09, and GE11, to evaluate our proposed BioLSL model. Results show that BioLSL has achieved state-of-the-art performance, outperforming the baseline models. Conclusions: The proposed BioLSL model demonstrates good performance for biomedical event trigger detection without using any external resources. This suggests that label representation learning and context-aware enhancement are promising directions for improving the task. The key enhancement is that BioLSL effectively learns to construct semantic linkages between the event mentions and type labels, which provide the latent information of label-trigger and label-context relationships in biomedical texts. Moreover, additional experiments on BioLSL show that it performs exceptionally well with limited training data under the data-scarce scenarios. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Hao2024Effective
ER  -

TY  - JOUR
AU  - He, X.
AU  - Zhao, L.
AU  - Tian, Y.
AU  - Li, R.
AU  - Chu, Q.
AU  - Gu, Z.
AU  - Zheng, M.
AU  - Wang, Y.
AU  - Li, S.
AU  - Jiang, H.
AU  - Jiang, Y.
AU  - Wen, L.
AU  - Wang, D.
AU  - Cheng, X.
TI  - Highly accurate carbohydrate-binding site prediction with DeepGlycanSite
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 5163
DO  - 10.1038/s41467-024-49516-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196089142&doi=10.1038%2fs41467-024-49516-2&partnerID=40&md5=0ae3a0b39cd5d255e7ace880b6f22e24
AB  - As the most abundant organic substances in nature, carbohydrates are essential for life. Understanding how carbohydrates regulate proteins in the physiological and pathological processes presents opportunities to address crucial biological problems and develop new therapeutics. However, the diversity and complexity of carbohydrates pose a challenge in experimentally identifying the sites where carbohydrates bind to and act on proteins. Here, we introduce a deep learning model, DeepGlycanSite, capable of accurately predicting carbohydrate-binding sites on a given protein structure. Incorporating geometric and evolutionary features of proteins into a deep equivariant graph neural network with the transformer architecture, DeepGlycanSite remarkably outperforms previous state-of-the-art methods and effectively predicts binding sites for diverse carbohydrates. Integrating with a mutagenesis study, DeepGlycanSite reveals the guanosine-5’-diphosphate-sugar-recognition site of an important G-protein coupled receptor. These findings demonstrate DeepGlycanSite is invaluable for carbohydrate-binding site prediction and could provide insights into molecular mechanisms underlying carbohydrate-regulation of therapeutically important proteins. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Xie, B.
AU  - Cao, J.
AU  - Anwer, R.M.
AU  - Xie, J.
AU  - Nie, J.
AU  - Yang, A.
AU  - Pang, Y.
TI  - Multi-query and multi-level enhanced network for semantic segmentation
PY  - 2024
T2  - Pattern Recognition
VL  - 156
C7  - 110777
DO  - 10.1016/j.patcog.2024.110777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198990471&doi=10.1016%2fj.patcog.2024.110777&partnerID=40&md5=504d23ebbb2d8d9d25a3a24ab61a5a8a
AB  - Plain transformer-based methods have achieved promising performance on semantic segmentation recently. These methods adopt a single set of class queries to predict masks of different semantic categories based on multi-level feature maps. We argue that this single-query design cannot fully exploit diverse information of different levels for improved semantic segmentation. To address this issue, we propose a multi-query and multi-level enhanced network for semantic segmentation (named QLSeg). Our QLSeg first performs multi-level feature enhancement on plain transformer to improve feature discriminability. Afterwards, we introduce multi-query decoder to respectively extract feature embeddings and predict mask logits at different levels, where feature embeddings are adaptively merged for classification and mask logits are summed for output masks. In addition, we introduce masked attention-to-mask to focus on local regions with the same class. We perform the experiments on three widely-used semantic segmentation datasets: ADE20K, COCO-Stuff-10K, and PASCAL-Context. Our proposed QLSeg achieves competitive results on all these three datasets. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Xue, W.
AU  - Zhou, Y.
AU  - Zhang, K.
AU  - Chen, S.
TI  - Hunt-inspired Transformer for visual object tracking
PY  - 2024
T2  - Pattern Recognition
VL  - 156
C7  - 110703
DO  - 10.1016/j.patcog.2024.110703
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197517944&doi=10.1016%2fj.patcog.2024.110703&partnerID=40&md5=fc8f119658774bfc69e0af8e6e28ed1f
AB  - This paper presents a hunt-inspired Transformer for visual object tracking, dubbed as HuntFormer. The HuntFormer focuses on robust target detection and identification, simulating natural hunting processes. Specifically, the HuntFormer comprises two essential module designs including a predictor for detection and a verifier for identification. The predictor emulates the detection stage by designing a motion trajectory guided particle filter, which identifies potential target locations by predicting the motion state within a particle filtering framework. The predictor utilizes spatio-temporal correlation scores between dynamic target templates and the search region to guide the learning process to generate a set of reliable particles. This enables the base tracker to narrow its search range to focus on the target, and swiftly re-detect the target in case of model drift. Once the target is re-detected, the verifier assesses the detection result as a reliable tracked item. The verifier initially maintains a dynamic memory that stores reliable target templates and their corresponding locations in the motion trajectory. It then models the uncertainty of appearance information within this memory probabilistically. The output uncertainty score determines whether the memory gets updated or not. Ultimately, the predictor and the verifier collaborate, ensuring a robust tracking outcome. Extensive evaluations on six challenging benchmark datasets demonstrate HuntFormer's favorable performance against various state-of-the-art trackers. Notably, in the VOT-LT2022 tracking challenge, the HuntFormer won the third place with an F-score of 0.598, closely competing for the second place with an F-score of 0.600. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - He, S.
AU  - Yun, L.
AU  - Yi, H.
TI  - Fusing graph transformer with multi-aggregate GCN for enhanced drug–disease associations prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 79
DO  - 10.1186/s12859-024-05705-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185447456&doi=10.1186%2fs12859-024-05705-w&partnerID=40&md5=b33e2a40b658508475ee4b368363ecfd
AB  - Background: Identification of potential drug–disease associations is important for both the discovery of new indications for drugs and for the reduction of unknown adverse drug reactions. Exploring the potential links between drugs and diseases is crucial for advancing biomedical research and improving healthcare. While advanced computational techniques play a vital role in revealing the connections between drugs and diseases, current research still faces challenges in the process of mining potential relationships between drugs and diseases using heterogeneous network data. Results: In this study, we propose a learning framework for fusing Graph Transformer Networks and multi-aggregate graph convolutional network to learn efficient heterogenous information graph representations for drug–disease association prediction, termed WMAGT. This method extensively harnesses the capabilities of a robust graph transformer, effectively modeling the local and global interactions of nodes by integrating a graph convolutional network and a graph transformer with self-attention mechanisms in its encoder. We first integrate drug–drug, drug–disease, and disease–disease networks to construct heterogeneous information graph. Multi-aggregate graph convolutional network and graph transformer are then used in conjunction with neural collaborative filtering module to integrate information from different domains into highly effective feature representation. Conclusions: Rigorous cross-validation, ablation studies examined the robustness and effectiveness of the proposed method. Experimental results demonstrate that WMAGT outperforms other state-of-the-art methods in accurate drug–disease association prediction, which is beneficial for drug repositioning and drug safety research. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - He2024Fusing
ER  -

TY  - JOUR
AU  - Sargsyan, K.
AU  - Lim, C.
TI  - Using protein language models for protein interaction hot spot prediction with limited data
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 115
DO  - 10.1186/s12859-024-05737-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187917332&doi=10.1186%2fs12859-024-05737-2&partnerID=40&md5=47f855b48d4a2ff4411636e6c8b8c5b9
AB  - Background: Protein language models, inspired by the success of large language models in deciphering human language, have emerged as powerful tools for unraveling the intricate code of life inscribed within protein sequences. They have gained significant attention for their promising applications across various areas, including the sequence-based prediction of secondary and tertiary protein structure, the discovery of new functional protein sequences/folds, and the assessment of mutational impact on protein fitness. However, their utility in learning to predict protein residue properties based on scant datasets, such as protein–protein interaction (PPI)-hotspots whose mutations significantly impair PPIs, remained unclear. Here, we explore the feasibility of using protein language-learned representations as features for machine learning to predict PPI-hotspots using a dataset containing 414 experimentally confirmed PPI-hotspots and 504 PPI-nonhot spots. Results: Our findings showcase the capacity of unsupervised learning with protein language models in capturing critical functional attributes of protein residues derived from the evolutionary information encoded within amino acid sequences. We show that methods relying on protein language models can compete with methods employing sequence and structure-based features to predict PPI-hotspots from the free protein structure. We observed an optimal number of features for model precision, suggesting a balance between information and overfitting. Conclusions: This study underscores the potential of transformer-based protein language models to extract critical knowledge from sparse datasets, exemplified here by the challenging realm of predicting PPI-hotspots. These models offer a cost-effective and time-efficient alternative to traditional experimental methods for predicting certain residue properties. However, the challenge of explaining why specific features are important for determining certain residue properties remains. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Sargsyan2024Using
ER  -

TY  - JOUR
AU  - Zeng, X.
AU  - Chen, W.
AU  - Lei, B.
TI  - CAT-DTI: cross-attention and Transformer network with domain adaptation for drug-target interaction prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 141
DO  - 10.1186/s12859-024-05753-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189203029&doi=10.1186%2fs12859-024-05753-2&partnerID=40&md5=6fa839cabc9870933ca5805b7ef66862
AB  - Accurate and efficient prediction of drug-target interaction (DTI) is critical to advance drug development and reduce the cost of drug discovery. Recently, the employment of deep learning methods has enhanced DTI prediction precision and efficacy, but it still encounters several challenges. The first challenge lies in the efficient learning of drug and protein feature representations alongside their interaction features to enhance DTI prediction. Another important challenge is to improve the generalization capability of the DTI model within real-world scenarios. To address these challenges, we propose CAT-DTI, a model based on cross-attention and Transformer, possessing domain adaptation capability. CAT-DTI effectively captures the drug-target interactions while adapting to out-of-distribution data. Specifically, we use a convolution neural network combined with a Transformer to encode the distance relationship between amino acids within protein sequences and employ a cross-attention module to capture the drug-target interaction features. Generalization to new DTI prediction scenarios is achieved by leveraging a conditional domain adversarial network, aligning DTI representations under diverse distributions. Experimental results within in-domain and cross-domain scenarios demonstrate that CAT-DTI model overall improves DTI prediction performance compared with previous methods. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zeng2024CAT-DTI
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Huang, T.
AU  - Wang, D.
AU  - Zeng, W.
AU  - Sun, Y.
AU  - Zhang, L.
TI  - MSCAN: multi-scale self- and cross-attention network for RNA methylation site prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 32
DO  - 10.1186/s12859-024-05649-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182390871&doi=10.1186%2fs12859-024-05649-1&partnerID=40&md5=5749da43ff4c226ff91617a9f16a7e87
AB  - Background: Epi-transcriptome regulation through post-transcriptional RNA modifications is essential for all RNA types. Precise recognition of RNA modifications is critical for understanding their functions and regulatory mechanisms. However, wet experimental methods are often costly and time-consuming, limiting their wide range of applications. Therefore, recent research has focused on developing computational methods, particularly deep learning (DL). Bidirectional long short-term memory (BiLSTM), convolutional neural network (CNN), and the transformer have demonstrated achievements in modification site prediction. However, BiLSTM cannot achieve parallel computation, leading to a long training time, CNN cannot learn the dependencies of the long distance of the sequence, and the Transformer lacks information interaction with sequences at different scales. This insight underscores the necessity for continued research and development in natural language processing (NLP) and DL to devise an enhanced prediction framework that can effectively address the challenges presented. Results: This study presents a multi-scale self- and cross-attention network (MSCAN) to identify the RNA methylation site using an NLP and DL way. Experiment results on twelve RNA modification sites (m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um) reveal that the area under the receiver operating characteristic of MSCAN obtains respectively 98.34%, 85.41%, 97.29%, 96.74%, 99.04%, 79.94%, 76.22%, 65.69%, 92.92%, 92.03%, 95.77%, 89.66%, which is better than the state-of-the-art prediction model. This indicates that the model has strong generalization capabilities. Furthermore, MSCAN reveals a strong association among different types of RNA modifications from an experimental perspective. A user-friendly web server for predicting twelve widely occurring human RNA modification sites (m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um) is available at http://47.242.23.141/MSCAN/index.php . Conclusions: A predictor framework has been developed through binary classification to predict RNA methylation sites. © 2024, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Wang2024MSCAN
ER  -

TY  - JOUR
AU  - Stöckl, C.
AU  - Yang, Y.
AU  - Maass, W.
TI  - Local prediction-learning in high-dimensional spaces enables neural networks to plan
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 2344
DO  - 10.1038/s41467-024-46586-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187802348&doi=10.1038%2fs41467-024-46586-0&partnerID=40&md5=098aafd89d6c1b8d9de1fd095814b4cb
AB  - Planning and problem solving are cornerstones of higher brain function. But we do not know how the brain does that. We show that learning of a suitable cognitive map of the problem space suffices. Furthermore, this can be reduced to learning to predict the next observation through local synaptic plasticity. Importantly, the resulting cognitive map encodes relations between actions and observations, and its emergent high-dimensional geometry provides a sense of direction for reaching distant goals. This quasi-Euclidean sense of direction provides a simple heuristic for online planning that works almost as well as the best offline planning algorithms from AI. If the problem space is a physical space, this method automatically extracts structural regularities from the sequence of observations that it receives so that it can generalize to unseen parts. This speeds up learning of navigation in 2D mazes and the locomotion with complex actuator systems, such as legged bodies. The cognitive map learner that we propose does not require a teacher, similar to self-attention networks (Transformers). But in contrast to Transformers, it does not require backpropagation of errors or very large datasets for learning. Hence it provides a blue-print for future energy-efficient neuromorphic hardware that acquires advanced cognitive capabilities through autonomous on-chip learning. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shao, B.
AU  - Yan, J.
AU  - Zhang, J.
AU  - Liu, L.
AU  - Chen, Y.
AU  - Buskirk, A.R.
TI  - Riboformer: a deep learning framework for predicting context-dependent translation dynamics
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 2011
DO  - 10.1038/s41467-024-46241-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186888335&doi=10.1038%2fs41467-024-46241-8&partnerID=40&md5=4fcc941386d6badb9371c7e0c04969ab
AB  - Translation elongation is essential for maintaining cellular proteostasis, and alterations in the translational landscape are associated with a range of diseases. Ribosome profiling allows detailed measurements of translation at the genome scale. However, it remains unclear how to disentangle biological variations from technical artifacts in these data and identify sequence determinants of translation dysregulation. Here we present Riboformer, a deep learning-based framework for modeling context-dependent changes in translation dynamics. Riboformer leverages the transformer architecture to accurately predict ribosome densities at codon resolution. When trained on an unbiased dataset, Riboformer corrects experimental artifacts in previously unseen datasets, which reveals subtle differences in synonymous codon translation and uncovers a bottleneck in translation elongation. Further, we show that Riboformer can be combined with in silico mutagenesis to identify sequence motifs that contribute to ribosome stalling across various biological contexts, including aging and viral infection. Our tool offers a context-aware and interpretable approach for standardizing ribosome profiling datasets and elucidating the regulatory basis of translation kinetics. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Tan, Y.
AU  - Xie, L.
AU  - Yang, H.
AU  - Zhang, Q.
AU  - Luo, J.
AU  - Zhang, Y.
TI  - BioDSNN: a dual-stream neural network with hybrid biological knowledge integration for multi-gene perturbation response prediction
PY  - 2024
T2  - Briefings in bioinformatics
VL  - 26
IS  - 1
DO  - 10.1093/bib/bbae617
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210549478&doi=10.1093%2fbib%2fbbae617&partnerID=40&md5=68768702345f462469b0e3b28cab5828
AB  - Studying the outcomes of genetic perturbation based on single-cell RNA-seq data is crucial for understanding genetic regulation of cells. However, the high cost of cellular experiments and single-cell sequencing restrict us from measuring the full combination space of genetic perturbations and cell types. Consequently, a bunch of computational models have been proposed to predict unseen combinations based on existing data. Among them, generative models, e.g. variational autoencoder and diffusion models, have the superiority in capturing the perturbed data distribution, but lack a biologically understandable foundation for generalization. On the other side of the spectrum, Gene Regulation Networks or gene pathway knowledge have been exploited for more reasonable generalization enhancement. Unfortunately, they do not reach a balanced processing of the two data modalities, leading to a degraded fitting ability. Hence, we propose a dual-stream architecture. Before the information from two modalities are merged, the sequencing data are learned with a generative model while three types of knowledge data are comprehensively processed with graph networks and a masked transformer, enforcing a deep understanding of single-modality data, respectively. The benchmark results show an approximate 20% reduction in terms of mean squared error, proving the effectiveness of the model. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, K.E.
AU  - Yang, K.K.
AU  - van den Berg, R.
AU  - Alamdari, S.
AU  - Zou, J.Y.
AU  - Lu, A.X.
AU  - Amini, A.P.
TI  - Protein structure generation via folding diffusion
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 1059
DO  - 10.1038/s41467-024-45051-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184446803&doi=10.1038%2fs41467-024-45051-2&partnerID=40&md5=57a9f8c2e8786b2c25f50afe31533715
AB  - The ability to computationally generate novel yet physically foldable protein structures could lead to new biological discoveries and new treatments targeting yet incurable diseases. Despite recent advances in protein structure prediction, directly generating diverse, novel protein structures from neural networks remains difficult. In this work, we present a diffusion-based generative model that generates protein backbone structures via a procedure inspired by the natural folding process. We describe a protein backbone structure as a sequence of angles capturing the relative orientation of the constituent backbone atoms, and generate structures by denoising from a random, unfolded state towards a stable folded structure. Not only does this mirror how proteins natively twist into energetically favorable conformations, the inherent shift and rotational invariance of this representation crucially alleviates the need for more complex equivariant networks. We train a denoising diffusion probabilistic model with a simple transformer backbone and demonstrate that our resulting model unconditionally generates highly realistic protein structures with complexity and structural patterns akin to those of naturally-occurring proteins. As a useful resource, we release an open-source codebase and trained models for protein structure diffusion. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yoshikai, Y.
AU  - Mizuno, T.
AU  - Nemoto, S.
AU  - Kusuhara, H.
TI  - Difficulty in chirality recognition for Transformer architectures learning chemical structures from string representations
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 1197
DO  - 10.1038/s41467-024-45102-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185336463&doi=10.1038%2fs41467-024-45102-8&partnerID=40&md5=0bacd3129fb6d5d18370fe6c9e475f62
AB  - Recent years have seen rapid development of descriptor generation based on representation learning of extremely diverse molecules, especially those that apply natural language processing (NLP) models to SMILES, a literal representation of molecular structure. However, little research has been done on how these models understand chemical structure. To address this black box, we investigated the relationship between the learning progress of SMILES and chemical structure using a representative NLP model, the Transformer. We show that while the Transformer learns partial structures of molecules quickly, it requires extended training to understand overall structures. Consistently, the accuracy of molecular property predictions using descriptors generated from models at different learning steps was similar from the beginning to the end of training. Furthermore, we found that the Transformer requires particularly long training to learn chirality and sometimes stagnates with low performance due to misunderstanding of enantiomers. These findings are expected to deepen the understanding of NLP models in chemistry. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Ahmed, F.S.
AU  - Aly, S.
AU  - Liu, X.
TI  - NABP-BERT: NANOBODY®-antigen binding prediction based on bidirectional encoder representations from transformers (BERT) architecture
PY  - 2024
T2  - Briefings in bioinformatics
VL  - 26
IS  - 1
DO  - 10.1093/bib/bbae518
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212905783&doi=10.1093%2fbib%2fbbae518&partnerID=40&md5=773ccae7ed2247f2a051f4e4fb016a79
AB  - Antibody-mediated immunity is crucial in the vertebrate immune system. Nanobodies, also known as VHH or single-domain antibodies (sdAbs), are emerging as promising alternatives to full-length antibodies due to their compact size, precise target selectivity, and stability. However, the limited availability of nanobodies (Nbs) for numerous antigens (Ags) presents a significant obstacle to their widespread application. Understanding the interactions between Nbs and Ags is essential for enhancing their binding affinities and specificities. Experimental identification of these interactions is often costly and time-intensive. To address this issue, we introduce NABP-BERT, a deep-learning model based on the BERT architecture, designed to predict NANOBODY®-Ag binding solely from sequence information. Furthermore, we have developed a general pretrained model with transfer capabilities suitable for protein-related tasks, including protein-protein interaction tasks. NABP-BERT focuses on the surrounding amino acid contexts and outperforms existing methods, achieving an AUROC of 0.986 and an AUPR of 0.985. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Liu, J.
AU  - Wang, H.
AU  - Zhou, M.
AU  - Ke, G.
AU  - Zhang, L.
AU  - Wu, J.
AU  - Gao, Z.
AU  - Lu, D.
TI  - A comprehensive transformer-based approach for high-accuracy gas adsorption predictions in metal-organic frameworks
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 1904
DO  - 10.1038/s41467-024-46276-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186531320&doi=10.1038%2fs41467-024-46276-x&partnerID=40&md5=dcdaf6177212bce2a017e405d65fe08f
AB  - Gas separation is crucial for industrial production and environmental protection, with metal-organic frameworks (MOFs) offering a promising solution due to their tunable structural properties and chemical compositions. Traditional simulation approaches, such as molecular dynamics, are complex and computationally demanding. Although feature engineering-based machine learning methods perform better, they are susceptible to overfitting because of limited labeled data. Furthermore, these methods are typically designed for single tasks, such as predicting gas adsorption capacity under specific conditions, which restricts the utilization of comprehensive datasets including all adsorption capacities. To address these challenges, we propose Uni-MOF, an innovative framework for large-scale, three-dimensional MOF representation learning, designed for multi-purpose gas prediction. Specifically, Uni-MOF serves as a versatile gas adsorption estimator for MOF materials, employing pure three-dimensional representations learned from over 631,000 collected MOF and COF structures. Our experimental results show that Uni-MOF can automatically extract structural representations and predict adsorption capacities under various operating conditions using a single model. For simulated data, Uni-MOF exhibits remarkably high predictive accuracy across all datasets. Additionally, the values predicted by Uni-MOF correspond with the outcomes of adsorption experiments. Furthermore, Uni-MOF demonstrates considerable potential for broad applicability in predicting a wide array of other properties. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Iliadis, D.
AU  - De Baets, B.
AU  - Pahikkala, T.
AU  - Waegeman, W.
TI  - A comparison of embedding aggregation strategies in drug–target interaction prediction
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 59
DO  - 10.1186/s12859-024-05684-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184544856&doi=10.1186%2fs12859-024-05684-y&partnerID=40&md5=3f0080924dbc10fa403111f5e9c411c5
AB  - The prediction of interactions between novel drugs and biological targets is a vital step in the early stage of the drug discovery pipeline. Many deep learning approaches have been proposed over the last decade, with a substantial fraction of them sharing the same underlying two-branch architecture. Their distinction is limited to the use of different types of feature representations and branches (multi-layer perceptrons, convolutional neural networks, graph neural networks and transformers). In contrast, the strategy used to combine the outputs (embeddings) of the branches has remained mostly the same. The same general architecture has also been used extensively in the area of recommender systems, where the choice of an aggregation strategy is still an open question. In this work, we investigate the effectiveness of three different embedding aggregation strategies in the area of drug–target interaction (DTI) prediction. We formally define these strategies and prove their universal approximator capabilities. We then present experiments that compare the different strategies on benchmark datasets from the area of DTI prediction, showcasing conditions under which specific strategies could be the obvious choice. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Iliadis2024comparison
ER  -

TY  - JOUR
AU  - Min, X.
AU  - Yang, C.
AU  - Xie, J.
AU  - Huang, Y.
AU  - Liu, N.
AU  - Jin, X.
AU  - Wang, T.
AU  - Kong, Z.
AU  - Lu, X.
AU  - Ge, S.
AU  - Zhang, J.
AU  - Xia, N.
TI  - Tpgen: a language model for stable protein design with a specific topology structure
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 35
DO  - 10.1186/s12859-024-05637-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182823512&doi=10.1186%2fs12859-024-05637-5&partnerID=40&md5=ea54f28fac4b12048e87c96109ac0ac8
AB  - Background: Natural proteins occupy a small portion of the protein sequence space, whereas artificial proteins can explore a wider range of possibilities within the sequence space. However, specific requirements may not be met when generating sequences blindly. Research indicates that small proteins have notable advantages, including high stability, accurate resolution prediction, and facile specificity modification. Results: This study involves the construction of a neural network model named TopoProGenerator(TPGen) using a transformer decoder. The model is trained with sequences consisting of a maximum of 65 amino acids. The training process of TopoProGenerator incorporates reinforcement learning and adversarial learning, for fine-tuning. Additionally, it encompasses a stability predictive model trained with a dataset comprising over 200,000 sequences. The results demonstrate that TopoProGenerator is capable of designing stable small protein sequences with specified topology structures. Conclusion: TPGen has the ability to generate protein sequences that fold into the specified topology, and the pretraining and fine-tuning methods proposed in this study can serve as a framework for designing various types of proteins. © 2024, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Min2024Tpgen
ER  -

TY  - JOUR
AU  - Lao, C.
AU  - Zheng, P.
AU  - Chen, H.
AU  - Liu, Q.
AU  - An, F.
AU  - Li, Z.
TI  - DeepAEG: a model for predicting cancer drug response based on data enhancement and edge-collaborative update strategies
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 105
DO  - 10.1186/s12859-024-05723-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187130252&doi=10.1186%2fs12859-024-05723-8&partnerID=40&md5=d752736d2439433a62f9499e3fd7d976
AB  - Motivation: The prediction of cancer drug response is a challenging subject in modern personalized cancer therapy due to the uncertainty of drug efficacy and the heterogeneity of patients. It has been shown that the characteristics of the drug itself and the genomic characteristics of the patient can greatly influence the results of cancer drug response. Therefore, accurate, efficient, and comprehensive methods for drug feature extraction and genomics integration are crucial to improve the prediction accuracy. Results: Accurate prediction of cancer drug response is vital for guiding the design of anticancer drugs. In this study, we propose an end-to-end deep learning model named DeepAEG which is based on a complete-graph update mode to predict IC50. Specifically, we integrate an edge update mechanism on the basis of a hybrid graph convolutional network to comprehensively learn the potential high-dimensional representation of topological structures in drugs, including atomic characteristics and chemical bond information. Additionally, we present a novel approach for enhancing simplified molecular input line entry specification data by employing sequence recombination to eliminate the defect of single sequence representation of drug molecules. Our extensive experiments show that DeepAEG outperforms other existing methods across multiple evaluation parameters in multiple test sets. Furthermore, we identify several potential anticancer agents, including bortezomib, which has proven to be an effective clinical treatment option. Our results highlight the potential value of DeepAEG in guiding the design of specific cancer treatment regimens. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Lao2024DeepAEG
ER  -

TY  - JOUR
AU  - Kwak, I.-Y.
AU  - Kim, B.-C.
AU  - Lee, J.
AU  - Kang, T.
AU  - Garry, D.J.
AU  - Zhang, J.
AU  - Gong, W.
TI  - Proformer: a hybrid macaron transformer model predicts expression values from promoter sequences
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 81
DO  - 10.1186/s12859-024-05645-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185523971&doi=10.1186%2fs12859-024-05645-5&partnerID=40&md5=0ec96a548507eb93bb7c41ea1657c09b
AB  - The breakthrough high-throughput measurement of the cis-regulatory activity of millions of randomly generated promoters provides an unprecedented opportunity to systematically decode the cis-regulatory logic that determines the expression values. We developed an end-to-end transformer encoder architecture named Proformer to predict the expression values from DNA sequences. Proformer used a Macaron-like Transformer encoder architecture, where two half-step feed forward (FFN) layers were placed at the beginning and the end of each encoder block, and a separable 1D convolution layer was inserted after the first FFN layer and in front of the multi-head attention layer. The sliding k-mers from one-hot encoded sequences were mapped onto a continuous embedding, combined with the learned positional embedding and strand embedding (forward strand vs. reverse complemented strand) as the sequence input. Moreover, Proformer introduced multiple expression heads with mask filling to prevent the transformer models from collapsing when training on relatively small amount of data. We empirically determined that this design had significantly better performance than the conventional design such as using the global pooling layer as the output layer for the regression task. These analyses support the notion that Proformer provides a novel method of learning and enhances our understanding of how cis-regulatory sequences determine the expression values. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Kwak2024Proformer
ER  -

TY  - JOUR
AU  - Yuge, C.C.
AU  - Hang, E.S.
AU  - Mamtha, M.R.N.
AU  - Vishwakarma, S.
AU  - Wang, S.
AU  - Wang, C.
AU  - Le, N.Q.K.
TI  - RNA-ModX: a multilabel prediction and interpretation framework for RNA modifications
PY  - 2024
T2  - Briefings in bioinformatics
VL  - 26
IS  - 1
DO  - 10.1093/bib/bbae688
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214190050&doi=10.1093%2fbib%2fbbae688&partnerID=40&md5=52e5e32e49dc0d63688a2c4ff2665187
AB  - Accurate prediction of RNA modifications holds profound implications for elucidating RNA function and mechanism, with potential applications in drug development. Here, the RNA-ModX presents a highly precise predictive model designed to forecast post-transcriptional RNA modifications, complemented by a user-friendly web application tailored for seamless utilization by future researchers. To achieve exceptional accuracy, the RNA-ModX systematically explored a range of machine learning models, including Long Short-Term Memory (LSTM), Gated Recurrent Unit, and Transformer-based architectures. The model underwent rigorous testing using a dataset comprising RNA sequences containing the four fundamental nucleotides (A, C, G, U) and spanning 12 prevalent modification classes (m6A, m1A, m5C, m5U, m6Am, m7G, Ψ, I, Am, Cm, Gm, and Um), with sequences of length 1001 nucleotides. Notably, the LSTM model, augmented with 3-mer encoding, demonstrated the highest level of model accuracy. Furthermore, Local Interpretable Model-Agnostic Explanations were employed to facilitate result interpretation, enhancing the transparency and interpretability of the model's predictions. In conjunction with the model development, a user-friendly web application was meticulously crafted, featuring an intuitive interface for researchers to effortlessly upload RNA sequences. Upon submission, the model executes in the backend, generating predictions which are seamlessly presented to the user in a coherent manner. This integration of cutting-edge predictive modeling with a user-centric interface signifies a significant step forward in facilitating the exploration and utilization of RNA modification prediction technologies by the broader research community. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Duan, M.
AU  - Li, J.
AU  - Ma, A.
AU  - Xin, G.
AU  - Xu, D.
AU  - Li, Z.
AU  - Liu, B.
AU  - Ma, Q.
TI  - MarsGT: Multi-omics analysis for rare population inference using single-cell graph transformer
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 338
DO  - 10.1038/s41467-023-44570-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181454825&doi=10.1038%2fs41467-023-44570-8&partnerID=40&md5=da205ae7a57eed38cfd6d2b4e142d79a
AB  - Rare cell populations are key in neoplastic progression and therapeutic response, offering potential intervention targets. However, their computational identification and analysis often lag behind major cell types. To fill this gap, we introduce MarsGT: Multi-omics Analysis for Rare population inference using a Single-cell Graph Transformer. It identifies rare cell populations using a probability-based heterogeneous graph transformer on single-cell multi-omics data. MarsGT outperforms existing tools in identifying rare cells across 550 simulated and four real human datasets. In mouse retina data, it reveals unique subpopulations of rare bipolar cells and a Müller glia cell subpopulation. In human lymph node data, MarsGT detects an intermediate B cell population potentially acting as lymphoma precursors. In human melanoma data, it identifies a rare MAIT-like population impacted by a high IFN-I response and reveals the mechanism of immunotherapy. Hence, MarsGT offers biological insights and suggests potential strategies for early detection and therapeutic intervention of disease. © 2024, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yang, T.
AU  - Wang, Y.
AU  - He, Y.
TI  - TEC-miTarget: enhancing microRNA target prediction based on deep learning of ribonucleic acid sequences
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 159
DO  - 10.1186/s12859-024-05780-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190783400&doi=10.1186%2fs12859-024-05780-z&partnerID=40&md5=45169046289c997dbd1d23b2a064fb66
AB  - Background: MicroRNAs play a critical role in regulating gene expression by binding to specific target sites within gene transcripts, making the identification of microRNA targets a prominent focus of research. Conventional experimental methods for identifying microRNA targets are both time-consuming and expensive, prompting the development of computational tools for target prediction. However, the existing computational tools exhibit limited performance in meeting the demands of practical applications, highlighting the need to improve the performance of microRNA target prediction models. Results: In this paper, we utilize the most popular natural language processing and computer vision technologies to propose a novel approach, called TEC-miTarget, for microRNA target prediction based on transformer encoder and convolutional neural networks. TEC-miTarget treats RNA sequences as a natural language and encodes them using a transformer encoder, a widely used encoder in natural language processing. It then combines the representations of a pair of microRNA and its candidate target site sequences into a contact map, which is a three-dimensional array similar to a multi-channel image. Therefore, the contact map's features are extracted using a four-layer convolutional neural network, enabling the prediction of interactions between microRNA and its candidate target sites. We applied a series of comparative experiments to demonstrate that TEC-miTarget significantly improves microRNA target prediction, compared with existing state-of-the-art models. Our approach is the first approach to perform comparisons with other approaches at both sequence and transcript levels. Furthermore, it is the first approach compared with both deep learning-based and seed-match-based methods. We first compared TEC-miTarget’s performance with approaches at the sequence level, and our approach delivers substantial improvements in performance using the same datasets and evaluation metrics. Moreover, we utilized TEC-miTarget to predict microRNA targets in long mRNA sequences, which involves two steps: selecting candidate target site sequences and applying sequence-level predictions. We finally showed that TEC-miTarget outperforms other approaches at the transcript level, including the popular seed match methods widely used in previous years. Conclusions: We propose a novel approach for predicting microRNA targets at both sequence and transcript levels, and demonstrate that our approach outperforms other methods based on deep learning or seed match. We also provide our approach as an easy-to-use software, TEC-miTarget, at https://github.com/tingpeng17/TEC-miTarget. Our results provide new perspectives for microRNA target prediction. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Yang2024TEC-miTarget
ER  -

TY  - JOUR
AU  - Yao, D.
AU  - Li, B.
AU  - Zhan, X.
AU  - Zhan, X.
AU  - Yu, L.
TI  - GCNFORMER: graph convolutional network and transformer for predicting lncRNA-disease associations
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 5
DO  - 10.1186/s12859-023-05625-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181246956&doi=10.1186%2fs12859-023-05625-1&partnerID=40&md5=0baa1864bd9e2b4d5afbccee2a6e6802
AB  - Background: A growing body of researches indicate that the disrupted expression of long non-coding RNA (lncRNA) is linked to a range of human disorders. Therefore, the effective prediction of lncRNA-disease association (LDA) can not only suggest solutions to diagnose a condition but also save significant time and labor costs. Method: In this work, we proposed a novel LDA predicting algorithm based on graph convolutional network and transformer, named GCNFORMER. Firstly, we integrated the intraclass similarity and interclass connections between miRNAs, lncRNAs and diseases, and built a graph adjacency matrix. Secondly, to completely obtain the features between various nodes, we employed a graph convolutional network for feature extraction. Finally, to obtain the global dependencies between inputs and outputs, we used a transformer encoder with a multiheaded attention mechanism to forecast lncRNA-disease associations. Results: The results of fivefold cross-validation experiment on the public dataset revealed that the AUC and AUPR of GCNFORMER achieved 0.9739 and 0.9812, respectively. We compared GCNFORMER with six advanced LDA prediction models, and the results indicated its superiority over the other six models. Furthermore, GCNFORMER's effectiveness in predicting potential LDAs is underscored by case studies on breast cancer, colon cancer and lung cancer. Conclusions: The combination of graph convolutional network and transformer can effectively improve the performance of LDA prediction model and promote the in-depth development of this research filed. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Yao2024GCNFORMER
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Meng, X.
AU  - Li, R.
AU  - Huang, B.
AU  - Wang, X.
TI  - NanoBERTa-ASP: predicting nanobody paratope based on a pretrained RoBERTa model
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 122
DO  - 10.1186/s12859-024-05750-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188353610&doi=10.1186%2fs12859-024-05750-5&partnerID=40&md5=edf44754062fb0be0f0bfffa936322ed
AB  - Background: Nanobodies, also known as VHH or single-domain antibodies, are unique antibody fragments derived solely from heavy chains. They offer advantages of small molecules and conventional antibodies, making them promising therapeutics. The paratope is the specific region on an antibody that binds to an antigen. Paratope prediction involves the identification and characterization of the antigen-binding site on an antibody. This process is crucial for understanding the specificity and affinity of antibody-antigen interactions. Various computational methods and experimental approaches have been developed to predict and analyze paratopes, contributing to advancements in antibody engineering, drug development, and immunotherapy. However, existing predictive models trained on traditional antibodies may not be suitable for nanobodies. Additionally, the limited availability of nanobody datasets poses challenges in constructing accurate models. Methods: To address these challenges, we have developed a novel nanobody prediction model, named NanoBERTa-ASP (Antibody Specificity Prediction), which is specifically designed for predicting nanobody-antigen binding sites. The model adopts a training strategy more suitable for nanobodies, based on an advanced natural language processing (NLP) model called BERT (Bidirectional Encoder Representations from Transformers). To be more specific, the model utilizes a masked language modeling approach named RoBERTa (Robustly Optimized BERT Pretraining Approach) to learn the contextual information of the nanobody sequence and predict its binding site. Results: NanoBERTa-ASP achieved exceptional performance in predicting nanobody binding sites, outperforming existing methods, indicating its proficiency in capturing sequence information specific to nanobodies and accurately identifying their binding sites. Furthermore, NanoBERTa-ASP provides insights into the interaction mechanisms between nanobodies and antigens, contributing to a better understanding of nanobodies and facilitating the design and development of nanobodies with therapeutic potential. Conclusion: NanoBERTa-ASP represents a significant advancement in nanobody paratope prediction. Its superior performance highlights the potential of deep learning approaches in nanobody research. By leveraging the increasing volume of nanobody data, NanoBERTa-ASP can further refine its predictions, enhance its performance, and contribute to the development of novel nanobody-based therapeutics. Github repository: https://github.com/WangLabforComputationalBiology/NanoBERTa-ASP © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Li2024NanoBERTa-ASP
ER  -

TY  - JOUR
AU  - Xue, S.
AU  - Zhu, F.
AU  - Chen, J.
AU  - Min, W.
TI  - Inferring single-cell resolution spatial gene expression via fusing spot-based spatial transcriptomics, location, and histology using GCN
PY  - 2024
T2  - Briefings in bioinformatics
VL  - 26
IS  - 1
DO  - 10.1093/bib/bbae630
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212904120&doi=10.1093%2fbib%2fbbae630&partnerID=40&md5=0a8094cdb5ac3fe0f67a97e140df8e8e
AB  - Spatial transcriptomics (ST technology allows for the detection of cellular transcriptome information while preserving the spatial location of cells. This capability enables researchers to better understand the cellular heterogeneity, spatial organization, and functional interactions in complex biological systems. However, current technological methods are limited by low resolution, which reduces the accuracy of gene expression levels. Here, we propose scstGCN, a multimodal information fusion method based on Vision Transformer and Graph Convolutional Network that integrates histological images, spot-based ST data and spatial location information to infer super-resolution gene expression profiles at single-cell level. We evaluated the accuracy of the super-resolution gene expression profiles generated on diverse tissue ST datasets with disease and healthy by scstGCN along with their performance in identifying spatial patterns, conducting functional enrichment analysis, and tissue annotation. The results show that scstGCN can predict super-resolution gene expression accurately and aid researchers in discovering biologically meaningful differentially expressed genes and pathways. Additionally, scstGCN can segment and annotate tissues at a finer granularity, with results demonstrating strong consistency with coarse manual annotations. Our source code and all used datasets are available at https://github.com/wenwenmin/scstGCN and https://zenodo.org/records/12800375. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Solera-Rico, A.
AU  - Sanmiguel Vila, C.
AU  - Gómez-López, M.
AU  - Wang, Y.
AU  - Almashjary, A.
AU  - Dawson, S.T.M.
AU  - Vinuesa, R.
TI  - β-Variational autoencoders and transformers for reduced-order modelling of fluid flows
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 1361
DO  - 10.1038/s41467-024-45578-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185236290&doi=10.1038%2fs41467-024-45578-4&partnerID=40&md5=5ca12e9947831e9da3482dafa8a0abdc
AB  - Variational autoencoder architectures have the potential to develop reduced-order models for chaotic fluid flows. We propose a method for learning compact and near-orthogonal reduced-order models using a combination of a β-variational autoencoder and a transformer, tested on numerical data from a two-dimensional viscous flow in both periodic and chaotic regimes. The β-variational autoencoder is trained to learn a compact latent representation of the flow velocity, and the transformer is trained to predict the temporal dynamics in latent-space. Using the β-variational autoencoder to learn disentangled representations in latent-space, we obtain a more interpretable flow model with features that resemble those observed in the proper orthogonal decomposition, but with a more efficient representation. Using Poincaré maps, the results show that our method can capture the underlying dynamics of the flow outperforming other prediction models. The proposed method has potential applications in other fields such as weather forecasting, structural dynamics or biomedical engineering. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Casert, C.
AU  - Tamblyn, I.
AU  - Whitelam, S.
TI  - Learning stochastic dynamics and predicting emergent behavior using transformers
PY  - 2024
T2  - Nature Communications
VL  - 15
IS  - 1
C7  - 1875
DO  - 10.1038/s41467-024-45629-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186369937&doi=10.1038%2fs41467-024-45629-w&partnerID=40&md5=281ccb0af370fa6b27e5db590b78a0ac
AB  - We show that a neural network originally designed for language processing can learn the dynamical rules of a stochastic system by observation of a single dynamical trajectory of the system, and can accurately predict its emergent behavior under conditions not observed during training. We consider a lattice model of active matter undergoing continuous-time Monte Carlo dynamics, simulated at a density at which its steady state comprises small, dispersed clusters. We train a neural network called a transformer on a single trajectory of the model. The transformer, which we show has the capacity to represent dynamical rules that are numerous and nonlocal, learns that the dynamics of this model consists of a small number of processes. Forward-propagated trajectories of the trained transformer, at densities not encountered during training, exhibit motility-induced phase separation and so predict the existence of a nonequilibrium phase transition. Transformers have the flexibility to learn dynamical rules from observation without explicit enumeration of rates or coarse-graining of configuration space, and so the procedure used here can be applied to a wide range of physical systems, including those with large and complex dynamical generators. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Gong, Y.
AU  - Cosma, G.
AU  - Finke, A.
TI  - VITR: Augmenting Vision Transformers with Relation-Focused Learning for Cross-modal Information Retrieval
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 9
C7  - 220
DO  - 10.1145/3686805
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210317345&doi=10.1145%2f3686805&partnerID=40&md5=587d2687bb03a1fc4f8f4a361168a059
AB  - The relations expressed in user queries are vital for cross-modal information retrieval. Relation-focused cross-modal retrieval aims to retrieve information that corresponds to these relations, enabling effective retrieval across different modalities. Pre-Trained networks, such as Contrastive Language-Image Pre-Training networks, have gained significant attention and acclaim for their exceptional performance in various cross-modal learning tasks. However, the Vision Transformer (ViT) used in these networks is limited in its ability to focus on image region relations. Specifically, ViT is trained to match images with relevant descriptions at the global level, without considering the alignment between image regions and descriptions. This article introduces VITR, a novel network that enhances ViT by extracting and reasoning about image region relations based on a local encoder. VITR is comprised of two key components. Firstly, it extends the capabilities of ViT-based cross-modal networks by enabling them to extract and reason with region relations present in images. Secondly, VITR incorporates a fusion module that combines the reasoned results with global knowledge to predict similarity scores between images and descriptions. The proposed VITR network was evaluated through experiments on the tasks of relation-focused cross-modal information retrieval. The results derived from the analysis of the Flickr30K, MS-COCO, RefCOCOg, and CLEVR datasets demonstrated that the proposed VITR network consistently outperforms state-of-The-Art networks in image-To-Text and text-To-image retrieval. © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Gong2024VITR
ER  -

TY  - JOUR
AU  - He, X.
AU  - Yan, M.
TI  - GraphKM: machine and deep learning for KM prediction of wildtype and mutant enzymes
PY  - 2024
T2  - BMC Bioinformatics
VL  - 25
IS  - 1
C7  - 135
DO  - 10.1186/s12859-024-05746-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188814486&doi=10.1186%2fs12859-024-05746-1&partnerID=40&md5=7527270d649e22817b33906afb7401c2
AB  - Michaelis constant (KM) is one of essential parameters for enzymes kinetics in the fields of protein engineering, enzyme engineering, and synthetic biology. As overwhelming experimental measurements of KM are difficult and time-consuming, prediction of the KM values from machine and deep learning models would increase the pace of the enzymes kinetics studies. Existing machine and deep learning models are limited to the specific enzymes, i.e., a minority of enzymes or wildtype enzymes. Here, we used a deep learning framework PaddlePaddle to implement a machine and deep learning approach (GraphKM) for KM prediction of wildtype and mutant enzymes. GraphKM is composed by graph neural networks (GNN), fully connected layers and gradient boosting framework. We represented the substrates through molecular graph and the enzymes through a pretrained transformer-based language model to construct the model inputs. We compared the difference of the model results made by the different GNN (GIN, GAT, GCN, and GAT-GCN). The GAT-GCN-based model generally outperformed. To evaluate the prediction performance of the GraphKM and other reported KM prediction models, we collected an independent KM dataset (HXKm) from literatures. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - He2024GraphKM
ER  -

TY  - JOUR
AU  - Park, S.
AU  - Lee, H.
TI  - Robust self-supervised learning strategy to tackle the inherent sparsity in single-cell RNA-seq data
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae586
DO  - 10.1093/bib/bbae586
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209747453&doi=10.1093%2fbib%2fbbae586&partnerID=40&md5=2a6c89eed1e9eae7e4ecec4c7dc89869
AB  - Single-cell RNA sequencing (scRNA-seq) is a powerful tool for elucidating cellular heterogeneity and tissue function in various biological contexts. However, the sparsity in scRNA-seq data limits the accuracy of cell type annotation and transcriptomic analysis due to information loss. To address this limitation, we present scRobust, a robust self-supervised learning strategy to tackle the inherent sparsity of scRNA-seq data. Built upon the Transformer architecture, scRobust employs a novel self-supervised learning strategy comprising contrastive learning and gene expression prediction tasks. We demonstrated the effectiveness of scRobust using nine benchmarks, additional dropout scenarios, and combined datasets. scRobust outperformed recent methods in cell-type annotation tasks and generated cell embeddings that capture multi-faceted clustering information (e.g. cell types and HbA1c levels). In addition, cell embeddings of scRobust were useful for detecting specific marker genes related to drug tolerance stages. Furthermore, when we applied scRobust to scATAC-seq data, high-quality cell embedding vectors were generated. These results demonstrate the representational power of scRobust. © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hayashi, H.
AU  - Ko, T.
AU  - Dai, Z.
AU  - Fujita, K.
AU  - Nomura, S.
AU  - Kiyoshima, H.
AU  - Ishihara, S.
AU  - Hamano, M.
AU  - Komuro, I.
AU  - Yamanishi, Y.
TI  - TRAITER: transformer-guided diagnosis and prognosis of heart failure using cell nuclear morphology and DNA damage marker
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 11
C7  - 610
DO  - 10.1093/bioinformatics/btae610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208996030&doi=10.1093%2fbioinformatics%2fbtae610&partnerID=40&md5=949d3698bccc3c5ef30f0966043ae361
AB  - Motivation: Heart failure (HF), a major cause of morbidity and mortality, necessitates precise diagnostic and prognostic methods. Results: This study presents a novel deep learning approach, Transformer-based Analysis of Images of Tissue for Effective Remedy (TRAITER), for HF diagnosis and prognosis. Using image segmentation techniques and a Vision Transformer, TRAITER predicts HF likelihood from cardiac tissue cell nuclear morphology images and the potential for left ventricular reverse remodeling (LVRR) from dual-stained images with cell nuclei and DNA damage markers. In HF prediction using 31 158 images from 9 patients, TRAITER achieved 83.1% accuracy. For LVRR prediction with 231 840 images from 46 patients, TRAITER attained 84.2% accuracy for individual images and 92.9% for individual patients. TRAITER outperformed other neural network models in terms of receiver operating characteristics, and precision–recall curves. Our method promises to advance personalized HF medicine decision-making. Availability and implementation: The source code and data are available at the following link: https://github.com/HamanoLaboratory/predict-of-HF-and-LVRR. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kushwaha, A.
AU  - Duroux, P.
AU  - Giudicelli, V.
AU  - Todorov, K.
AU  - Kossida, S.
TI  - IMGT/RobustpMHC: robust training for class-I MHC peptide binding prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae552
DO  - 10.1093/bib/bbae552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208689255&doi=10.1093%2fbib%2fbbae552&partnerID=40&md5=eab6615c274ef5084f341022fe035c3d
AB  - The accurate prediction of peptide-major histocompatibility complex (MHC) class I binding probabilities is a critical endeavor in immunoinformatics, with broad implications for vaccine development and immunotherapies. While recent deep neural network based approaches have showcased promise in peptide-MHC (pMHC) prediction, they have two shortcomings: (i) they rely on hand-crafted pseudo-sequence extraction, (ii) they do not generalize well to different datasets, which limits the practicality of these approaches. While existing methods rely on a 34 amino acid pseudo-sequence, our findings uncover the involvement of 147 positions in direct interactions between MHC and peptide. We further show that neural architectures can learn the intricacies of pMHC binding using even full sequences. To this end, we present PerceiverpMHC that is able to learn accurate representations on full-sequences by leveraging efficient transformer based architectures. Additionally, we propose IMGT/RobustpMHC that harnesses the potential of unlabeled data in improving the robustness of pMHC binding predictions through a self-supervised learning strategy. We extensively evaluate RobustpMHC on eight different datasets and showcase an overall improvement of over 6% in binding prediction accuracy compared to state-of-the-art approaches. We compile CrystalIMGT, a crystallography-verified dataset presenting a challenge to existing approaches due to significantly different pMHC distributions. Finally, to mitigate this distribution gap, we further develop a transfer learning pipeline. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fallon, B.O.
AU  - Bolia, A.
AU  - Durtschi, J.
AU  - Yang, L.
AU  - Fredrickson, E.
AU  - Best, H.
TI  - Generative haplotype prediction outperforms statistical methods for small variant detection in next-generation sequencing data
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 11
C7  - btae565
DO  - 10.1093/bioinformatics/btae565
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208815228&doi=10.1093%2fbioinformatics%2fbtae565&partnerID=40&md5=f76a68c9b1d5ccf0c546c49066588a0f
AB  - Motivation: Detection of germline variants in next-generation sequencing data is an essential component of modern genomics analysis. Variant detection tools typically rely on statistical algorithms such as de Bruijn graphs or Hidden Markov models, and are often coupled with heuristic techniques and thresholds to maximize accuracy. Despite significant progress in recent years, current methods still generate thousands of false-positive detections in a typical human whole genome, creating a significant manual review burden. Results: We introduce a new approach that replaces the handcrafted statistical techniques of previous methods with a single deep generative model. Using a standard transformer-based encoder and double-decoder architecture, our model learns to construct diploid germline haplotypes in a generative fashion identical to modern large language models. We train our model on 37 whole genome sequences from Genome-in-a-Bottle samples, and demonstrate that our method learns to produce accurate haplotypes with correct phase and genotype for all classes of small variants. We compare our method, called Jenever, to FreeBayes, GATK HaplotypeCaller, Clair3, and DeepVariant, and demonstrate that our method has superior overall accuracy compared to other methods. At F1-maximizing quality thresholds, our model delivers the highest sensitivity, precision, and the fewest genotyping errors for insertion and deletion variants. For single nucleotide variants, our model demonstrates the highest sensitivity but at somewhat lower precision, and achieves the highest overall F1 score among all callers we tested. Availability and implementation: Jenever is implemented as a python-based command line tool. Source code is available at https://github.com/ARUP-NGS/jenever/ © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Zhu, F.
AU  - Min, W.
TI  - SpaDiT: diffusion transformer for spatial gene expression prediction using scRNA-seq
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae571
DO  - 10.1093/bib/bbae571
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208809573&doi=10.1093%2fbib%2fbbae571&partnerID=40&md5=abcb7f37537b4a67d2727f59f1f6c86d
AB  - The rapid development of spatially resolved transcriptomics (SRT) technologies has provided unprecedented opportunities for exploring the structure of specific organs or tissues. However, these techniques (such as image-based SRT) can achieve single-cell resolution, but can only capture the expression levels of tens to hundreds of genes. Such spatial transcriptomics (ST) data, carrying a large number of undetected genes, have limited its application value. To address the challenge, we develop SpaDiT, a deep learning framework for spatial reconstruction and gene expression prediction using scRNA-seq data. SpaDiT employs scRNA-seq data as an a priori condition and utilizes shared genes between ST and scRNA-seq data as latent representations to construct inputs, thereby facilitating the accurate prediction of gene expression in ST data. SpaDiT enhances the accuracy of spatial gene expression predictions over a variety of spatial transcriptomics datasets. We have demonstrated the effectiveness of SpaDiT by conducting extensive experiments on both seq-based and image-based ST data. We compared SpaDiT with eight highly effective baseline methods and found that our proposed method achieved an 8%–12% improvement in performance across multiple metrics. Source code and all datasets used in this paper are available at https://github.com/wenwenmin/SpaDiT and https://zenodo.org/records/12792074. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Y.-F.
AU  - Lu, X.-L.
TI  - Learning and consolidating the contextualized contour representations of tones from F0 sequences and durational variations via transformers
PY  - 2024
T2  - Journal of the Acoustical Society of America
VL  - 156
IS  - 5
SP  - 3353
EP  - 3372
DO  - 10.1121/10.0034359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209658372&doi=10.1121%2f10.0034359&partnerID=40&md5=8a19cc47c2d59aa9933a937c8051676e
AB  - Many speech characteristics, including conventional acoustic features such as mel frequency cepstrum coefficients and mel-spectrograms, as well as pre-trained contextualized acoustic representations such as wav2vec2.0, are used in a deep neural network or successfully fine-tuned with a connectionist temporal classification for Mandarin tone classification. In this study, the authors propose a transformer-based tone classification architecture, TNet-Full, which uses estimated fundamental frequency (F0) values and aligned boundary information on syllables and words. Key components of the model framework are the contour encoder and rhythm encoder, as well as the cross-attention between contours and rhythms established in the interaction encoder. Using contextual tonal contours as a reference, as well as rhythmic information derived from duration variations to consolidate more on contour representations for tone recognition, TNet-Full achieves absolute performance improvements of 24.4% for read speech (from 71.4% to 95.8%) and 6.3% for conversational speech (from 52.1% to 58.4%) when compared to a naive, simple baseline transformer, TNet-base. The relative improvements are 34.2% and 12.1%. As humans perceive tones, contour abstractions of tones can only be derived from F0 sequences, and tone recognition would be improved if syllable temporal organization was stable and predictable instead of fluctuating as seen in conversations. © 2024 Acoustical Society of America.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Liu, S.
AU  - Li, L.
AU  - Zhou, W.
AU  - Li, H.
TI  - SwinShadow: Shifted Window for Ambiguous Adjacent Shadow Detection
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 11
C7  - 360
DO  - 10.1145/3688803
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209675028&doi=10.1145%2f3688803&partnerID=40&md5=f1a6c7b7d1944475764f4e82eae98e03
AB  - Shadow detection is a fundamental and challenging task in many computer vision applications. Intuitively, most shadows come from the occlusion of light by the object itself, resulting in the object and its shadow being contiguous (referred to as the adjacent shadow in this article). In this case, when the color of the object is similar to that of the shadow, existing methods struggle to achieve accurate detection. To address this problem, we present SwinShadow, a transformer-based architecture that fully utilizes the powerful shifted window mechanism for detecting adjacent shadows. The mechanism operates in two steps. Initially, it applies local self-attention within a single window, enabling the network to focus on local details. Subsequently, it shifts the attention windows to facilitate inter-window attention, enabling the capture of a broader range of adjacent information. These combined steps significantly improve the network’s capacity to distinguish shadows from nearby objects. And the whole process can be divided into three parts: encoder, decoder, and feature integration. During encoding, we adopt Swin Transformer to acquire hierarchical features. Then during decoding, for shallow layers, we propose a deep supervision (DS) module to suppress the false positives and boost the representation capability of shadow features for subsequent processing, while for deep layers, we leverage a double attention (DA) module to integrate local and shifted window in one stage to achieve a larger receptive field and enhance the continuity of information. Ultimately, a new multi-level aggregation (MLA) mechanism is applied to fuse the decoded features for mask prediction. Extensive experiments on three shadow detection benchmark datasets, SBU, UCF, and ISTD, demonstrate that our network achieves good performance in terms of balance error rate (BER). The source code and results are now publicly available at https://github.com/harrytea/SwinShadow. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Olsen, T.H.
AU  - Moal, I.H.
AU  - Deane, C.M.
TI  - Addressing the antibody germline bias and its effect on language models for improved antibody design
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 11
C7  - btae618
DO  - 10.1093/bioinformatics/btae618
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208689168&doi=10.1093%2fbioinformatics%2fbtae618&partnerID=40&md5=af0f9352551eb51a490e595ceb63408f
AB  - Motivation: The versatile binding properties of antibodies have made them an extremely important class of biotherapeutics. However, therapeutic antibody development is a complex, expensive, and time-consuming task, with the final antibody needing to not only have strong and specific binding but also be minimally impacted by developability issues. The success of transformer-based language models in protein sequence space and the availability of vast amounts of antibody sequences, has led to the development of many antibody-specific language models to help guide antibody design. Antibody diversity primarily arises from V(D)J recombination, mutations within the CDRs, and/or from a few nongermline mutations outside the CDRs. Consequently, a significant portion of the variable domain of all natural antibody sequences remains germline. This affects the pre-training of antibody-specific language models, where this facet of the sequence data introduces a prevailing bias toward germline residues. This poses a challenge, as mutations away from the germline are often vital for generating specific and potent binding to a target, meaning that language models need be able to suggest key mutations away from germline. Results: In this study, we explore the implications of the germline bias, examining its impact on both general-protein and antibody-specific language models. We develop and train a series of new antibody-specific language models optimized for predicting nongermline residues. We then compare our final model, AbLang-2, with current models and show how it suggests a diverse set of valid mutations with high cumulative probability. Availability and implementation: AbLang-2 is trained on both unpaired and paired data, and is freely available at https://github.com/oxpig/AbLang2.git. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kumar, R.
AU  - Mendes-Moreira, J.
AU  - Chandra, J.
TI  - Spatio-Temporal Parallel Transformer Based Model for Traffic Prediction
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 9
C7  - 213
DO  - 10.1145/3679017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210313256&doi=10.1145%2f3679017&partnerID=40&md5=5128289e3a2caebb12224eb7ad4e3fa5
AB  - Traffic forecasting problems involve jointly modeling the non-linear spatio-Temporal dependencies at different scales. While graph neural network models have been effectively used to capture the non-linear spatial dependencies, capturing the dynamic spatial dependencies between the locations remains a major challenge. The errors in capturing such dependencies propagate in modeling the temporal dependencies between the locations, thereby severely affecting the performance of long-Term predictions. While transformer-based mechanisms have been recently proposed for capturing the dynamic spatial dependencies, these methods are susceptible to fluctuations in data brought on by unforeseen events like traffic congestion and accidents. To mitigate these issues we propose an improvised spatio-Temporal parallel transformer (STPT) based model for traffic prediction that uses multiple adjacency graphs passed through a pair of coupled graph transformer-convolution network units, operating in parallel, to generate more noise-resilient embeddings. We conduct extensive experiments on 4 real-world traffic datasets and compare the performance of STPT with several state-of-The-Art baselines, in terms of measures like RMSE, MAE, and MAPE. We find that using STPT improves the performance by around as compared to the baselines. We also investigate the applicability of the model on other spatio-Temporal data in other domains. We use a Covid-19 dataset to predict the number of future occurrences in different regions from a given set of historical occurrences. The results demonstrate the superiority of our model for such datasets.  © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Kumar2024Spatio-Temporal
ER  -

TY  - JOUR
AU  - Mo, G.
AU  - Xia, Y.
AU  - Ou, J.
AU  - Cai, S.
AU  - Xiong, X.
TI  - Layout Congestion Prediction Based on Regression-ViT
PY  - 2024
T2  - ACM Transactions on Design Automation of Electronic Systems
VL  - 30
IS  - 1
C7  - 4
DO  - 10.1145/3698196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213264199&doi=10.1145%2f3698196&partnerID=40&md5=a23cf0fddd9e28705e3989861c4c6196
AB  - To accelerate the back-end design flow of integrated circuit (IC), numerous studies have made exploratory advancements in machine learning (ML) for electronic design automation (EDA). However, most research works are limited to deep learning (DL) models predominantly based on convolutional neural networks, and the models often suffer from poor generalization due to the scarcity of data. In this study, we propose the Double generative adversarial networks (D-GAN) model to enrich the dataset and propose the Regression Vision Transformer (R-ViT) model to predict layout congestion information. Compared with the baseline model, experimental results show improvements of 3.03% and 2.64% in Receiver Operating Characteristic-Area under Curve (ROC-AUC) and Precision-Recall Curve-Area under Curve (PRC-AUC) respectively. To further enhance the prediction accuracy of the model, an adaptive Huber loss function is designed to optimize the training process, resulting in an improvement of up to 11.03% in ROC-AUC compared with the baseline model. Lastly, extended experiments are conducted to study the effects of parameters and convolutional kernel size on performance, which find a better configuration.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bai, P.
AU  - Li, G.
AU  - Luo, J.
AU  - Liang, C.
TI  - Deep learning model for protein multi-label subcellular localization and function prediction based on multi-Task collaborative training
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae568
DO  - 10.1093/bib/bbae568
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208497965&doi=10.1093%2fbib%2fbbae568&partnerID=40&md5=c50df053cf09479f2f2e2b7163366def
AB  - The functional study of proteins is a critical task in modern biology, playing a pivotal role in understanding the mechanisms of pathogenesis, developing new drugs, and discovering novel drug targets. However, existing computational models for subcellular localization face significant challenges, such as reliance on known Gene Ontology (GO) annotation databases or overlooking the relationship between GO annotations and subcellular localization. To address these issues, we propose DeepMTC, an end-To-end deep learning-based multi-Task collaborative training model. DeepMTC integrates the interrelationship between subcellular localization and the functional annotation of proteins, leveraging multi-Task collaborative training to eliminate dependence on known GO databases. This strategy gives DeepMTC a distinct advantage in predicting newly discovered proteins without prior functional annotations. First, DeepMTC leverages pre-Trained language model with high accuracy to obtain the 3D structure and sequence features of proteins. Additionally, it employs a graph transformer module to encode protein sequence features, addressing the problem of long-range dependencies in graph neural networks. Finally, DeepMTC uses a functional cross-Attention mechanism to efficiently combine upstream learned functional features to perform the subcellular localization task. The experimental results demonstrate that DeepMTC outperforms state-of-The-Art models in both protein function prediction and subcellular localization. Moreover, interpretability experiments revealed that DeepMTC can accurately identify the key residues and functional domains of proteins, confirming its superior performance. The code and dataset of DeepMTC are freely available at https://github.com/ghli16/DeepMTC.  © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Shou, Y.
AU  - Meng, T.
AU  - Ai, W.
AU  - Li, K.
TI  - A multi-view mask contrastive learning graph convolutional neural network for age estimation
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 11
SP  - 7137
EP  - 7162
DO  - 10.1007/s10115-024-02193-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200867347&doi=10.1007%2fs10115-024-02193-5&partnerID=40&md5=1f44e29641594e55da90a97999310823
AB  - The age estimation task aims to use facial features to predict the age of people and is widely used in public security, marketing, identification, and other fields. However, the features are mainly concentrated in facial keypoints, and existing CNN and Transformer-based methods have inflexibility and redundancy for modeling complex irregular structures. Therefore, this paper proposes a multi-view mask contrastive learning graph convolutional neural network (MMCL-GCN) for age estimation. Specifically, the overall structure of the MMCL-GCN network contains a feature extraction stage and an age estimation stage. In the feature extraction stage, we introduce a graph structure to construct face images as input and then design a multi-view mask contrastive learning (MMCL) mechanism to learn complex structural and semantic information about face images. The learning mechanism employs an asymmetric Siamese network architecture, which utilizes an online encoder–decoder structure to reconstruct the missing information from the original graph and utilizes the target encoder to learn latent representations for contrastive learning. Furthermore, to promote the two learning mechanisms better compatible and complementary, we adopt two augmentation strategies and optimize the joint losses. In the age estimation stage, we design a multi-layer extreme learning machine (ML-IELM) with identity mapping to fully use the features extracted by the online encoder. Then, a classifier and a regressor were constructed based on ML-IELM, which were used to identify the age grouping interval and accurately estimate the final age. Extensive experiments show that MMCL-GCN can effectively reduce the error of age estimation on benchmark datasets such as Adience, MORPH-II, and LAP-2016. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jia, K.
AU  - Yu, X.
AU  - Zhang, C.
AU  - Xie, W.
AU  - Zhao, D.
AU  - Xiang, J.
TI  - PMTT: Parallel multi-scale temporal convolution network and transformer for predicting the time to aging failure of software systems
PY  - 2024
T2  - Journal of Systems and Software
VL  - 217
C7  - 112167
DO  - 10.1016/j.jss.2024.112167
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200957620&doi=10.1016%2fj.jss.2024.112167&partnerID=40&md5=11cc8a9a442c16050ecde6759d3df923
AB  - Software aging is one of the significant factors affecting the reliability and availability of long-running software systems, such as Android, Cloud systems, etc. The time to aging failure (TTAF) prediction for software systems plays a crucial role in proactive rejuvenation scheduling through machine learning or statistical analysis techniques, due to its ability to determine when to perform rejuvenation to mitigate the aging effects. However, software aging characterization is relatively complicated, and only fitting the variations for a single aging indicator cannot grasp the comprehensive degradation process across different case systems; moreover, since software systems often exhibit long and short-term inherent degradation characteristics, existing prediction models possess a poor ability for modeling both global and local information simultaneously. To tackle the above problems, a novel TTAF prediction framework based on the parallel multi-scale temporal convolution network and transformer (named PMTT) is proposed, by mapping various system running indicators reflecting the software aging to TTAF. PMTT possesses the following distinctive characteristics. First, a local feature extraction module that contains multiple channel TCNs with different scales is developed to extract inherent local information from the raw input. Second, in a parallel manner, a global feature extraction module integrating transformer blocks is built to extract global information representation synchronously using the self-attention mechanism. Afterward, high-level global–local features extracted from different channels are fused, and TTAF is estimated through two fully connected regression layers using the fused features. The proposed PMTT has been compared to seven competitors using run-to-failure data collected from Android and OpenStack systems. The experiments have demonstrated the superiority of PMTT, showing an average improvement of 11.2%, 9.0%, and 9.3% in performance across three evaluation metrics compared with the optimal baseline model. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Xie, J.
AU  - Song, Y.
AU  - Zheng, H.
AU  - Luo, S.
AU  - Chen, Y.
AU  - Zhang, C.
AU  - Yu, R.
AU  - Tong, M.
TI  - PathMethy: an interpretable AI framework for cancer origin tracing based on DNA methylation
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae497
DO  - 10.1093/bib/bbae497
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206031942&doi=10.1093%2fbib%2fbbae497&partnerID=40&md5=781553bff241871a0ef9411901a35746
AB  - Despite advanced diagnostics, 3%-5% of cases remain classified as cancer of unknown primary (CUP). DNA methylation, an important epigenetic feature, is essential for determining the origin of metastatic tumors. We presented PathMethy, a novel Transformer model integrated with functional categories and crosstalk of pathways, to accurately trace the origin of tumors in CUP samples based on DNA methylation. PathMethy outperformed seven competing methods in F1-score across nine cancer datasets and predicted accurately the molecular subtypes within nine primary tumor types. It not only excelled at tracing the origins of both primary and metastatic tumors but also demonstrated a high degree of agreement with previously diagnosed sites in cases of CUP. PathMethy provided biological insights by highlighting key pathways, functional categories, and their interactions. Using functional categories of pathways, we gained a global understanding of biological processes. For broader access, a user-friendly web server for researchers and clinicians is available at https://cup.pathmethy.com.  © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wen, W.
AU  - Zhong, J.
AU  - Zhang, Z.
AU  - Jia, L.
AU  - Chu, T.
AU  - Wang, N.
AU  - Danko, C.G.
AU  - Wang, Z.
TI  - dHICA: a deep transformer-based model enables accurate histone imputation from chromatin accessibility
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae459
DO  - 10.1093/bib/bbae459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204941029&doi=10.1093%2fbib%2fbbae459&partnerID=40&md5=bba32dc77b49d8ca10639db9a0fdfdd9
AB  - Histone modifications (HMs) are pivotal in various biological processes, including transcription, replication, and DNA repair, significantly impacting chromatin structure. These modifications underpin the molecular mechanisms of cell-type-specific gene expression and complex diseases. However, annotating HMs across different cell types solely using experimental approaches is impractical due to cost and time constraints. Herein, we present dHICA (deep histone imputation using chromatin accessibility), a novel deep learning framework that integrates DNA sequences and chromatin accessibility data to predict multiple HM tracks. Employing the transformer architecture alongside dilated convolutions, dHICA boasts an extensive receptive field and captures more cell-type-specific information. dHICA outperforms state-of-the-art baselines and achieves superior performance in cell-type-specific loci and gene elements, aligning with biological expectations. Furthermore, dHICA's imputations hold significant potential for downstream applications, including chromatin state segmentation and elucidating the functional implications of SNPs (Single Nucleotide Polymorphisms). In conclusion, dHICA serves as a valuable tool for advancing the understanding of chromatin dynamics, offering enhanced predictive capabilities and interpretability.  © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qin, X.
AU  - Zhu, W.
AU  - Hu, Q.
AU  - Zhou, Z.
AU  - Ding, Y.
AU  - Gao, X.
AU  - Gu, R.
TI  - DenseNet-Transformer: A deep learning method for spatial–temporal traffic prediction in optical fronthaul network
PY  - 2024
T2  - Computer Networks
VL  - 253
C7  - 110674
DO  - 10.1016/j.comnet.2024.110674
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201414702&doi=10.1016%2fj.comnet.2024.110674&partnerID=40&md5=52bc6e04ae46e67f34f6b75f6c743a69
AB  - The rapid evolution of 6G Radio Access Networks (RAN) towards virtualization and intelligence is driven by the widespread adoption of high-bandwidth services and the proliferation of mobile communications. Active Antenna Units (AAU) interface with Distributed Units (DU) over Passive Optical Networks (PON), serving as crucial bearers that transmit extensive data through the optical fronthaul network to the core network. However, the escalating demand for high-bandwidth services, coupled with the uneven spatial–temporal traffic patterns influenced by factors such as geographical location and urban functionalities across various base stations, poses significant challenges to the optical fronthaul network in terms of operational costs and resource allocation efficiency. To tackle these challenges, we introduce the DenseNet-Transformer spatial–temporal traffic prediction algorithm tailored specifically for the traffic characteristics of optical fronthaul networks. In DenseNet-Transformer, DenseNet captures spatial feature correlations among nearby traffic in adjacent regions, facilitating enhanced learning of traffic characteristics across distant areas through dense connections. The Transformer component learns both long and short-term temporal dependencies, enhancing the algorithm's temporal prediction capabilities using multi-head attention mechanisms and positional encoding. We validate the effectiveness of DenseNet-Transformer through a series of ablation experiments and comparative tests against other algorithms under identical conditions. Experimental results on real datasets demonstrate that, in most scenarios, DenseNet-Transformer outperforms existing algorithms for time traffic prediction in both wireless and optical communication domains, as well as spatial–temporal prediction algorithms. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Chen, Y.
AU  - Jin, X.
AU  - Mao, W.
AU  - Xiao, Z.
AU  - Zhang, S.
AU  - Zhang, T.
AU  - Liu, T.
AU  - Kendrick, K.
AU  - Jiang, X.
TI  - Fusing multi-scale functional connectivity patterns via Multi-Branch Vision Transformer (MB-ViT) for macaque brain age prediction
PY  - 2024
T2  - Neural Networks
VL  - 179
C7  - 106592
DO  - 10.1016/j.neunet.2024.106592
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201442310&doi=10.1016%2fj.neunet.2024.106592&partnerID=40&md5=cd1993690347c826691b55548800a69e
AB  - Brain age (BA) is defined as a measure of brain maturity and could help characterize both the typical brain development and neuropsychiatric disorders in mammals. Various biological phenotypes have been successfully applied to predict BA of human using chronological age (CA) as label. However, whether the BA of macaque, one of the most important animal models, can also be reliably predicted is largely unknown. To address this question, we propose a novel deep learning model called Multi-Branch Vision Transformer (MB-ViT) to fuse multi-scale (i.e., from coarse-grained to fine-grained) brain functional connectivity (FC) patterns derived from resting state functional magnetic resonance imaging (rs-fMRI) data to predict BA of macaques. The discriminative functional connections and the related brain regions contributing to the prediction are further identified based on Gradient-weighted Class Activation Mapping (Grad-CAM) method. Our proposed model successfully predicts BA of 450 normal rhesus macaques from the publicly available PRIMatE Data Exchange (PRIME-DE) dataset with lower mean absolute error (MAE) and mean square error (MSE) as well as higher Pearson's correlation coefficient (PCC) and coefficient of determination (R2) compared to other baseline models. The correlation between the predicted BA and CA reaches as high as 0.82 of our proposed method. Furthermore, our analysis reveals that the functional connections predominantly contributing to the prediction results are situated in the primary motor cortex (M1), visual cortex, area v23 in the posterior cingulate cortex, and dysgranular temporal pole. In summary, our proposed deep learning model provides an effective tool to accurately predict BA of primates (macaque in this study), and lays a solid foundation for future studies of age-related brain diseases in those animal models. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Min, W.
AU  - Shi, Z.
AU  - Zhang, J.
AU  - Wan, J.
AU  - Wang, C.
TI  - Multimodal contrastive learning for spatial gene expression prediction using histology images
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 6
C7  - bbae551
DO  - 10.1093/bib/bbae551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208161324&doi=10.1093%2fbib%2fbbae551&partnerID=40&md5=c713e3ee80cc68d995fa8224e0fb4df4
AB  - In recent years, the advent of spatial transcriptomics (ST) technology has unlocked unprecedented opportunities for delving into the complexities of gene expression patterns within intricate biological systems. Despite its transformative potential, the prohibitive cost of ST technology remains a significant barrier to its widespread adoption in large-scale studies. An alternative, more cost-effective strategy involves employing artificial intelligence to predict gene expression levels using readily accessible whole-slide images stained with Hematoxylin and Eosin (H&E). However, existing methods have yet to fully capitalize on multimodal information provided by H&E images and ST data with spatial location. In this paper, we propose mclSTExp, a multimodal contrastive learning with Transformer and Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We conceptualize each spot as a "word", integrating its intrinsic features with spatial context through the self-attention mechanism of a Transformer encoder. This integration is further enriched by incorporating image features via contrastive learning, thereby enhancing the predictive capability of our model. We conducted an extensive evaluation of highly variable genes in two breast cancer datasets and a skin squamous cell carcinoma dataset, and the results demonstrate that mclSTExp exhibits superior performance in predicting spatial gene expression. Moreover, mclSTExp has shown promise in interpreting cancer-specific overexpressed genes, elucidating immune-related genes, and identifying specialized spatial domains annotated by pathologists. Our source code is available at https://github.com/shizhiceng/mclSTExp. © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pourbehzadi, M.
AU  - Javidi, G.
AU  - Howell, C.J.
AU  - Kamar, E.
AU  - Sheybani, E.
TI  - Enhanced (cyber) situational awareness: Using interpretable principal component analysis (iPCA) to automate vulnerability severity scoring
PY  - 2024
T2  - Decision Support Systems
VL  - 186
C7  - 114308
DO  - 10.1016/j.dss.2024.114308
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203133481&doi=10.1016%2fj.dss.2024.114308&partnerID=40&md5=931bc984689f65da24ec09990f4428cf
AB  - The Common Vulnerability Scoring System (CVSS) is widely used in the cybersecurity industry to assess the severity of vulnerabilities. However, manual assessments and human error can lead to delays and inconsistencies. This study employs situational awareness theory to develop an automated decision support system, integrating perception, comprehension, and projection components to enhance effectiveness. Specifically, an interpretable principal component analysis (iPCA) combined with machine learning is utilized to forecast CVSS scores using text descriptions from the Common Vulnerabilities and Exposures (CVE) database. Different forecasting approaches, including traditional machine learning models, Long-Short Term Memory Neural Networks, and Transformer architectures (ChatGPT) are compared to determine the best performance. The results show that iPCA combined with support vector regression achieves a high performance (R2 = 98%) in predicting CVSS scores using CVE text descriptions. The results indicate that the variability, length, and details in the vulnerability description contribute to the performance of the transformer model. These findings are consistent across vulnerability descriptions from six companies between 2017 and 2019. The study's outcomes have the potential to enhance organizations' security posture, improving situational awareness and enabling better managerial decision-making in cybersecurity. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:C期刊; FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Pourbehzadi2024Enhanced
ER  -

TY  - JOUR
AU  - Kumar, K.N.
AU  - Roy, D.
AU  - Suman, T.A.
AU  - Vishnu, C.
AU  - Mohan, C.K.
TI  - TSANet: Forecasting traffic congestion patterns from aerial videos using graphs and transformers
PY  - 2024
T2  - Pattern Recognition
VL  - 155
C7  - 110721
DO  - 10.1016/j.patcog.2024.110721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197418071&doi=10.1016%2fj.patcog.2024.110721&partnerID=40&md5=1fc5e616ea9d029104cb8a51b081bb14
AB  - Forecasting traffic congestion patterns in lane-less traffic scenarios is a complex task because of the combination of high & irregular vehicle densities, fluctuating speeds, and the presence of environmental obstacles. Existing techniques like vehicle counting and density prediction, which successfully estimate congestion in lane-based traffic, are unsuitable for lane-less traffic scenarios due to the irregular and unpredictable nature of traffic density patterns. To overcome these challenges, we propose traffic states to measure congestion patterns in lane-less traffic scenarios. Each traffic state is characterized by the spatio-temporal distribution of neighbouring road users, including vehicles and motorcyclists. We employ traffic graphs to capture the spatial distribution of neighbouring road users. Also, we propose a novel method for the automated construction of traffic graphs by leveraging the detection and tracking of individual road users in aerial videos. Further, in order to incorporate the temporal distribution, we utilize a transformer model to capture the evolution of spatial traffic graphs over time. This enables us to forecast future spatio-temporal distributions and their associated traffic states. Our proposed model, named Traffic State Anticipation Network (TSANet), can effectively forecast future traffic states by analysing sequences of current traffic graphs, thereby enhancing our understanding of evolving traffic patterns in lane-less scenarios. Also, to address the lack of publicly available lane-less traffic datasets, we introduce EyeonTraffic (EoT), a large-scale lane-less traffic dataset containing three hours of aerial videos captured at three busy intersections in Ahmedabad city, India. Experimental results on the EoT dataset demonstrate the efficacy of our proposed TSANet in effectively anticipating traffic states across diverse spatial regions within an intersection. In addition, we also show that TSANet generalizes well for previously unseen intersections, making it suitable for analysing various traffic scenarios without the need for explicit training, thereby enhancing its practical applicability. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Chen, C.
AU  - Lv, X.
AU  - Zuo, E.
AU  - Li, M.
AU  - Wu, L.
AU  - Chen, X.
AU  - Wu, X.
AU  - Chen, C.
TI  - CMACF: Transformer-based cross-modal attention cross-fusion model for systemic lupus erythematosus diagnosis combining Raman spectroscopy, FTIR spectroscopy, and metabolomics
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 6
C7  - 103804
DO  - 10.1016/j.ipm.2024.103804
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198328645&doi=10.1016%2fj.ipm.2024.103804&partnerID=40&md5=0ecdfae675da6fc14e93ae449b04d09e
AB  - As complex multi-omics data in the medical field tend to be multi-modal. Integrating these multimodal information into novel disease diagnosis models has become challenging. However, previous methods mainly focus on single omics, which cannot effectively capture the contributions between different combinations of multi-omics information. To solve this problem, based on Raman spectroscopy, FTIR spectroscopy, and metabolomics data, this paper proposes a new Cross-modal Cross-fusion network based on the Transformer self-attention mechanism (CMACF). The research focuses on effectively combining the feature patterns of different omics for disease prediction. Specifically, by constructing the Raman-IR, Raman-metabolomic, and IR spectral-metabolomic feature pairs and reasonably focusing on the information of different combination pairs through multiple stages of feature sub-network, attention cross-fusion, bimodal interaction, and sequence interaction feature level fusion, it is interesting to find that the information contribution between different pairs is different. We conducted extensive experiments on the systemic lupus erythematosus multi-omics dataset, and the accuracy and AUC values are as high as 99.44 % and 99.98 %, respectively, with the best classification effect. The results show that CMACF can efficiently fuse multi-omics medical data, provide an efficient baseline for processing medical multimodal data, and analyze the contribution of multi-omics data fusion. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Xiao, C.
AU  - Cao, Q.
AU  - Zhong, Y.
AU  - Lan, L.
AU  - Zhang, X.
AU  - Luo, Z.
AU  - Tao, D.
TI  - MotionTrack: Learning motion predictor for multiple object tracking
PY  - 2024
T2  - Neural Networks
VL  - 179
C7  - 106539
DO  - 10.1016/j.neunet.2024.106539
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199951775&doi=10.1016%2fj.neunet.2024.106539&partnerID=40&md5=e88210f3f552810dc86d7d998bc606b5
AB  - Significant progress has been achieved in multi-object tracking (MOT) through the evolution of detection and re-identification (ReID) techniques. Despite these advancements, accurately tracking objects in scenarios with homogeneous appearance and heterogeneous motion remains a challenge. This challenge arises from two main factors: the insufficient discriminability of ReID features and the predominant utilization of linear motion models in MOT. In this context, we introduce a novel motion-based tracker, MotionTrack, centered around a learnable motion predictor that relies solely on object trajectory information. This predictor comprehensively integrates two levels of granularity in motion features to enhance the modeling of temporal dynamics and facilitate precise future motion prediction for individual objects. Specifically, the proposed approach adopts a self-attention mechanism to capture token-level information and a Dynamic MLP layer to model channel-level features. MotionTrack is a simple, online tracking approach. Our experimental results demonstrate that MotionTrack yields state-of-the-art performance on datasets such as Dancetrack and SportsMOT, characterized by highly complex object motion. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liu, X.
AU  - Yuan, D.
AU  - Wang, J.
AU  - Wu, P.
AU  - Liu, J.
TI  - A Transformer-based visual object tracker via learning immediate appearance change
PY  - 2024
T2  - Pattern Recognition
VL  - 155
C7  - 110705
DO  - 10.1016/j.patcog.2024.110705
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197904645&doi=10.1016%2fj.patcog.2024.110705&partnerID=40&md5=16eae1c02fbeb71dcdedc6d905855bf9
AB  - Transformer has shown its great strength in visual object tracking due to its effective attention mechanism, but most prevailing transformer-based trackers only explore temporal information frame by frame, thus overlooking the rich context information inherent in videos. To alleviate this problem, we propose a transformer-based tracker via learning immediate appearance change information in videos, called IAC-tracker. The proposed tracker enhances the perception of the immediate motion state to improve the performance of single target tracking. IAC-tracker contains three key components: a spatial information extractor (SIE) with a superior attention mechanism to progressively extract spatial information, a temporal information extractor (TIE) with a designed temporal attention mechanism to progressively learn target immediate appearance change, and a novel spatial–temporal context enhanced fusion module integrating the information from SIE and TIE to prepare for the final prediction head. Comparison experiments with state-of-the-art trackers on six challenging datasets demonstrate the superior performance of IAC-tracker with real-time running speed. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ni, R.
AU  - Cai, W.
AU  - Jiang, Y.
TI  - Contrastive cross-domain sequential recommendation via emphasized intention features
PY  - 2024
T2  - Neural Networks
VL  - 179
C7  - 106488
DO  - 10.1016/j.neunet.2024.106488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197770697&doi=10.1016%2fj.neunet.2024.106488&partnerID=40&md5=621aa7f43f899d790320a5d16f8db471
AB  - The objective of cross-domain sequential recommendation is to forecast upcoming interactions by leveraging past interactions across diverse domains. Most methods aim to utilize single-domain and cross-domain information as much as possible for personalized preference extraction and effective integration. However, on one hand, most models ignore that cross-domain information is composed of multiple single-domains when generating representations. They still treat cross-domain information the same way as single-domain information, resulting in noisy representation generation. Only by imposing certain constraints on cross-domain information during representation generation can subsequent models minimize interference when considering user preferences. On the other hand, some methods neglect the joint consideration of users’ long-term and short-term preferences and reduce the weight of cross-domain user preferences to minimize noise interference. To better consider the mutual promotion of cross-domain and single-domains factors, we propose a novel model (C2DREIF) that utilizes Gaussian graph encoders to handle information, effectively constraining the correlation of information and capturing useful contextual information more accurately. It also employs a Top-down transformer to accurately extract user intents within each domain, taking into account the user's long-term and short-term preferences. Additionally, entropy regularized is applied to enhance contrastive learning and mitigate the impact of randomness caused by negative sample composition. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, C.
AU  - Xiang, J.
AU  - Hao, R.
AU  - Hu, W.
AU  - Cotroneo, D.
AU  - Natella, R.
AU  - Pietrantuono, R.
TI  - SGT: Aging-related bug prediction via semantic feature learning based on graph-transformer
PY  - 2024
T2  - Journal of Systems and Software
VL  - 217
C7  - 112156
DO  - 10.1016/j.jss.2024.112156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199497850&doi=10.1016%2fj.jss.2024.112156&partnerID=40&md5=e9406ee748f8c9980e98581759827ccd
AB  - Software aging, characterized by an increasing failure rate or performance decline in long-running software systems, poses significant risks including financial losses and potential harm to human life. This is primarily attributed to the accumulation of runtime errors, commonly referred to as aging-related bugs (ARBs). ARBP aims to detect and address ARBs before software release, optimizing testing resource allocation. However, ARBP's effectiveness relies heavily on dataset quality. Prior research often relied on manually designed metrics that lack semantic features, resulting in low prediction accuracy. Some studies construct models to learn semantic features from source code, but typically focus on token-level features from abstract Syntax Trees, neglecting critical topological and functional connections. In this paper, we introduce the SGT model, an ARBP method based on Graph-Transformer. This model efficiently extracts semantic information and logical structures from source code, capturing data dependencies and program dependencies. We also propose sub-graph sampling based on node degree to reduce structural complexity and apply random oversampling to address class imbalance. Experiments on three projects demonstrate notable improvements. For instance, SGT achieved F1 scores of 0.726 and 0.706 on Linux and MySQL, respectively. Compared to ALW, SGT shows a 12.3% and 6.8% improvement on Linux and MySQL. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Puthiya Parambath, S.A.
AU  - Anagnostopoulos, C.
AU  - Murray-Smith, R.
TI  - Sequential query prediction based on multi-armed bandits with ensemble of transformer experts and immediate feedback
PY  - 2024
T2  - Data Mining and Knowledge Discovery
VL  - 38
IS  - 6
SP  - 3758
EP  - 3782
DO  - 10.1007/s10618-024-01057-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200326713&doi=10.1007%2fs10618-024-01057-4&partnerID=40&md5=298c9f17074142cc5d58ab33b28e87bd
AB  - We study the problem of predicting the next query to be recommended in interactive data exploratory analysis to guide users to correct content. Current query prediction approaches are based on sequence-to-sequence learning, exploiting past interaction data. However, due to the resource-hungry training process, such approaches fail to adapt to immediate user feedback. Immediate feedback is essential and considered as a signal of the user’s intent. We contribute with a novel query prediction ensemble mechanism, which adapts to immediate feedback relying on multi-armed bandits framework. Our mechanism, an extension to the popular Exp3 algorithm, augments Transformer-based language models for query predictions by combining predictions from experts, thus dynamically building a candidate set during exploration. Immediate feedback is leveraged to choose the appropriate prediction in a probabilistic fashion. We provide comprehensive large-scale experimental and comparative assessment using a popular online literature discovery service, which showcases that our mechanism (i) improves the per-round regret substantially against state-of-the-art Transformer-based models and (ii) shows the superiority of causal language modelling over masked language modelling for query recommendations. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kim, S.
AU  - Warner, B.C.
AU  - Lew, D.
AU  - Lou, S.S.
AU  - Kannampallil, T.
TI  - Measuring cognitive effort using tabular transformer-based language models of electronic health record-based audit log action sequences
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 10
SP  - 2228
EP  - 2235
DO  - 10.1093/jamia/ocae171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204660483&doi=10.1093%2fjamia%2focae171&partnerID=40&md5=f9316f8facb46c19f56bd2d840e076ab
AB  - Objectives: To develop and validate a novel measure, action entropy, for assessing the cognitive effort associated with electronic health record (EHR)-based work activities. Materials and Methods: EHR-based audit logs of attending physicians and advanced practice providers (APPs) from four surgical intensive care units in 2019 were included. Neural language models (LMs) were trained and validated separately for attendings' and APPs' action sequences. Action entropy was calculated as the cross-entropy associated with the predicted probability of the next action, based on prior actions. To validate the measure, a matched pairs study was conducted to assess the difference in action entropy during known high cognitive effort scenarios, namely, attention switching between patients and to or from the EHR inbox. Results: Sixty-five clinicians performing 5 904 429 EHR-based audit log actions on 8956 unique patients were included. All attention switching scenarios were associated with a higher action entropy compared to non-switching scenarios (P <. 001), except for the from-inbox switching scenario among APPs. The highest difference among attendings was for the from-inbox attention switching: Action entropy was 1.288 (95% CI, 1.256-1.320) standard deviations (SDs) higher for switching compared to non-switching scenarios. For APPs, the highest difference was for the to-inbox switching, where action entropy was 2.354 (95% CI, 2.311-2.397) SDs higher for switching compared to non-switching scenarios. Discussion: We developed a LM-based metric, action entropy, for assessing cognitive burden associated with EHR-based actions. The metric showed discriminant validity and statistical significance when evaluated against known situations of high cognitive effort (ie, attention switching). With additional validation, this metric can potentially be used as a screening tool for assessing behavioral action phenotypes that are associated with higher cognitive burden. Conclusion: An LM-based action entropy metric - relying on sequences of EHR actions - offers opportunities for assessing cognitive effort in EHR-based workflows.  © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Duan, Y.
AU  - Cao, X.
AU  - Zhao, J.
AU  - Li, M.
AU  - Yang, X.
AU  - Zhao, F.
AU  - Zhang, X.
TI  - Health indicator adaptive construction method of rotating machinery under variable working conditions based on spatiotemporal fusion autoencoder
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102945
DO  - 10.1016/j.aei.2024.102945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209364336&doi=10.1016%2fj.aei.2024.102945&partnerID=40&md5=fdf4300ccf8be5344d7324fb32251ee3
AB  - Health indicators (HI) can effectively reveal potential faults and express the degradation process of rotating machinery in engineering, which are significant for health state assessment, prognostic and decision-making. Nevertheless, most classical HI construction methods have some problems of inadequate spatiotemporal feature extraction, neglect of working conditions and individual discrepancy, and difficulty in adapting to complex degradation, leading to poor model feature expression and adaptability. To overcome these challenges, this paper proposes a new HI adaptive construction method of rotating machinery (HCPTSCAE). A spatiotemporal fusion autoencoder neural network integrating pyramid convolution and Transformer is proposed to extract the signal's deep spatiotemporal degradation features. Then, condition domain alignment and individual degradation alignment are introduced as homogeneity constraints to reduce the discrepancy of conditions and individuals. On this basis, an autoencoder structure with adaptive weight is used to adjust the model and automatically construct HI based on the quadratic function degradation rule. The effectiveness and applicability of the HCPTSCAE network are validated by the Xi'an Jiaotong University (XJTU) bearing degradation dataset and our lab's reducer dataset. The mean comprehensive score for different bearings is 0.7283, showing an average increase of 0.2026 compared with other methods. The mean comprehensive score for different reducers is 0.6680, with an average increase of 0.1664 compared with other methods. Moreover, the results indicate that HCPTSCAE has advantages in finding the early state degradation point and predicting remaining useful life, which promotes the trend consistency of the samples’ same features. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Lu, Y.
AU  - Rao, Y.
TI  - A self-training interpretable cell type annotation framework using specific marker gene
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 10
C7  - btae569
DO  - 10.1093/bioinformatics/btae569
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206958388&doi=10.1093%2fbioinformatics%2fbtae569&partnerID=40&md5=d1803efc8438a1c0bf67a7fbdd02f927
AB  - Motivation: Recent advances in sequencing technology provide opportunities to study biological processes at a higher resolution. Cell type annotation is an important step in scRNA-seq analysis, which often relies on established marker genes. However, most of the previous methods divide the identification of cell types into two stages, clustering and assignment, whose performances are susceptible to the clustering algorithm, and the marker information cannot effectively guide the clustering process. Furthermore, their linear heuristic-based cell assignment process is often insufficient to capture potential dependencies between cells and types. Results: Here, we present Interpretable Cell Type Annotation based on self-training (sICTA), a marker-based cell type annotation method that combines the self-training strategy with pseudo-labeling and the nonlinear association capturing capability of Transformer. In addition, we incorporate biological priori knowledge of genes and pathways into the classifier through an attention mechanism to enhance the transparency of the model. A benchmark analysis on 11 publicly available single-cell datasets demonstrates the superiority of sICTA compared to state-of-the-art methods. The robustness of our method is further validated by evaluating the prediction accuracy of the model on different cell types for each single-cell data. Moreover, ablation studies show that self-training and the ability to capture potential dependencies between cells and cell types, both of which are mutually reinforcing, work together to improve model performance. Finally, we apply sICTA to the pancreatic dataset, exemplifying the interpretable attention matrix captured by sICTA. Availability and implementation: The source code of sICTA is available in public at https://github.com/nbnbhwyy/sICTA. The processed datasets can be found at https://drive.google.com/drive/folders/1jbqSxacL_IDIZ4uPjq220C9Kv024m9eL. The final version of the model will be permanently available at https://doi.org/10.5281/zenodo.13474010 © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Zheng, X.
AU  - Meng, D.
AU  - Chen, D.
AU  - Wong, W.-K.
AU  - To, K.-H.
AU  - Zhu, L.
AU  - Wu, J.
AU  - Liang, Y.
AU  - Leung, K.-S.
AU  - Wong, M.-H.
AU  - Cheng, L.
TI  - scCaT: An explainable capsulating architecture for sepsis diagnosis transferring from single-cell RNA sequencing
PY  - 2024
T2  - PLoS Computational Biology
VL  - 20
IS  - 10
C7  - e1012083
DO  - 10.1371/journal.pcbi.1012083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208449195&doi=10.1371%2fjournal.pcbi.1012083&partnerID=40&md5=d7d13d1fb4afc85bc905670976ada55d
AB  - Sepsis is a life-threatening condition characterized by an exaggerated immune response to pathogens, leading to organ damage and high mortality rates in the intensive care unit. Although deep learning has achieved impressive performance on prediction and classification tasks in medicine, it requires large amounts of data and lacks explainability, which hinder its application to sepsis diagnosis. We introduce a deep learning framework, called scCaT, which blends the capsulating architecture with Transformer to develop a sepsis diagnostic model using single-cell RNA sequencing data and transfers it to bulk RNA data. The capsulating architecture effectively groups genes into capsules based on biological functions, which provides explainability in encoding gene expressions. The Transformer serves as a decoder to classify sepsis patients and controls. Our model achieves high accuracy with an AUROC of 0.93 on the single-cell test set and an average AUROC of 0.98 on seven bulk RNA cohorts. Additionally, the capsules can recognize different cell types and distinguish sepsis from control samples based on their biological pathways. This study presents a novel approach for learning gene modules and transferring the model to other data types, offering potential benefits in diagnosing rare diseases with limited subjects. © 2024 Zheng et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Van Buchem, M.M.
AU  - De Hond, A.A.H.
AU  - Fanconi, C.
AU  - Shah, V.
AU  - Schuessler, M.
AU  - Kant, I.M.J.
AU  - Steyerberg, E.W.
AU  - Hernandez-Boussard, T.
TI  - Applying natural language processing to patient messages to identify depression concerns in cancer patients
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 10
SP  - 2255
EP  - 2262
DO  - 10.1093/jamia/ocae188
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204659671&doi=10.1093%2fjamia%2focae188&partnerID=40&md5=c36849879a9ac114403477dcd8e462ac
AB  - Objective: This study aims to explore and develop tools for early identification of depression concerns among cancer patients by leveraging the novel data source of messages sent through a secure patient portal. Materials and Methods: We developed classifiers based on logistic regression (LR), support vector machines (SVMs), and 2 Bidirectional Encoder Representations from Transformers (BERT) models (original and Reddit-pretrained) on 6600 patient messages from a cancer center (2009-2022), annotated by a panel of healthcare professionals. Performance was compared using AUROC scores, and model fairness and explainability were examined. We also examined correlations between model predictions and depression diagnosis and treatment. Results: BERT and RedditBERT attained AUROC scores of 0.88 and 0.86, respectively, compared to 0.79 for LR and 0.83 for SVM. BERT showed bigger differences in performance across sex, race, and ethnicity than RedditBERT. Patients who sent messages classified as concerning had a higher chance of receiving a depression diagnosis, a prescription for antidepressants, or a referral to the psycho-oncologist. Explanations from BERT and RedditBERT differed, with no clear preference from annotators. Discussion: We show the potential of BERT and RedditBERT in identifying depression concerns in messages from cancer patients. Performance disparities across demographic groups highlight the need for careful consideration of potential biases. Further research is needed to address biases, evaluate real-world impacts, and ensure responsible integration into clinical settings. Conclusion: This work represents a significant methodological advancement in the early identification of depression concerns among cancer patients. Our work contributes to a route to reduce clinical burden while enhancing overall patient care, leveraging BERT-based models.  © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Shu, K.
AU  - Ma, H.
AU  - Yang, J.
AU  - Zhang, D.
TI  - GraphSmin: Imbalanced dissolved gas analysis with contrastive dual-channel graph filters
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102839
DO  - 10.1016/j.aei.2024.102839
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204676790&doi=10.1016%2fj.aei.2024.102839&partnerID=40&md5=0c3b37dfc5a953890157c3f0185cd60c
AB  - Dissolved Gas Analysis (DGA) is a widely adopted technique for detecting faults in oil-immersed power transformers. However, in the context of DGA fault diagnosis, the fault class has considerably fewer samples compared to the normal class. Directly constructing fault diagnosis model in such an imbalanced scenario may result in insufficient representation of fault classes, which can ultimately lead to a decrease in diagnostic performance. To tackle this issue, we propose a novel imbalanced DGA model called GraphSmin. This approach is equipped with contrastive dual-channel graph filters and deliberately generate minority samples to effectively address the imbalance problem in fault diagnosis. Specifically, similar KNN graph (S-KNN) and dissimilar KNN graph (DS-KNN) are established to better reveal the complex relationship between samples. Subsequently, the dual-channel graph filters with contrastive learning is presented to obtain high-quality embeddings of DGA samples. In particular, we expand minority class samples in the embedding space to ensure effective learning of minority class features. Besides, an edge predictor is trained to model the relationship information between nodes. Extensive experiments on two datasets demonstrate the outstanding capability and reliability of the proposed method in imbalanced DGA fault diagnosis. Our code is available at https://github.com/SK-1230/GraphSmin. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, T.
AU  - Shang, K.
AU  - Jin, X.
AU  - Zhang, Z.
AU  - Li, C.
AU  - Wang, S.
AU  - Liu, J.
TI  - Spatially embedded transformer: A point cloud deep learning model for aero-engine coaxiality prediction based on virtual measurement
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102900
DO  - 10.1016/j.aei.2024.102900
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207796760&doi=10.1016%2fj.aei.2024.102900&partnerID=40&md5=bb3cb7dca249171c2a138af311f489c1
AB  - Coaxiality is a critical indicator of assembly accuracy in aero-engines, directly impacting the device's operational performance and lifespan. Due to the enclosed nature of the aero-engine casing system, measuring the coaxiality of assembled components presents significant challenges. This paper introduces a novel deep learning architecture, the spatially embedded transformer (SETrans), designed to predict coaxiality from unassembled part data by correlating it with the contact surface points of assembled components. Additionally, a virtual measurement model is developed to collect micron-scale point cloud data, facilitating the fine-tuning of the deep learning model. The SETrans utilizes the transformer's capability for global information aggregation to process point cloud inputs, capturing the comprehensive relationships across assembled surfaces. A newly designed module, the spatial bias, integrates distance and angular information between neighboring point clouds into the transformer block, enhancing the model's ability to capture fine-grained local details. Experimental validation is conducted using two distinct datasets representing different assembly scenarios: the aero-engine casing, sampled using contact-based coordinate measuring machines, and the rotor, sampled using non-contact optical gaging products. These specific sampling methods test the generalizability of the SETrans across diverse measurement techniques. Comparative analysis with other point cloud deep learning benchmarks shows that the proposed approach achieves top prediction accuracies of 93.65% and 94.31% with a coaxiality precision of 0.01 mm across different data domains. These results confirm the effectiveness of the SETrans and demonstrate its adaptability to real-world assembly conditions involving various components. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Alam, R.
AU  - Mahbub, S.
AU  - Bayzid, M.
TI  - Pair-EGRET: enhancing the prediction of protein–protein interaction sites through graph attention networks and protein language models
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 10
C7  - btae588
DO  - 10.1093/bioinformatics/btae588
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207384745&doi=10.1093%2fbioinformatics%2fbtae588&partnerID=40&md5=e9811df5245c4462735fc5598254726f
AB  - Motivation: Proteins are responsible for most biological functions, many of which require the interaction of more than one protein molecule. However, accurately predicting protein–protein interaction (PPI) sites (the interfacial residues of a protein that interact with other protein molecules) remains a challenge. The growing demand and cost associated with the reliable identification of PPI sites using conventional experimental methods call for computational tools for automated prediction and understanding of PPIs. Results: We present Pair-EGRET, an edge-aggregated graph attention network that leverages the features extracted from pretrained transformer-like models to accurately predict PPI sites. Pair-EGRET works on a k-nearest neighbor graph, representing the 3D structure of a protein, and utilizes the cross-attention mechanism for accurate identification of interfacial residues of a pair of proteins. Through an extensive evaluation study using a diverse array of experimental data, evaluation metrics, and case studies on representative protein sequences, we demonstrate that Pair-EGRET can achieve remarkable performance in predicting PPI sites. Moreover, Pair-EGRET can provide interpretable insights from the learned cross-attention matrix. Availability and implementation: Pair-EGRET is freely available in open source form at the GitHub Repository https://github.com/1705004/ Pair-EGRET. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Bai, Y.
AU  - Zhong, H.
AU  - Wang, T.
AU  - Lu, Z.J.
TI  - OligoFormer: an accurate and robust prediction method for siRNA design
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 10
C7  - btae577
DO  - 10.1093/bioinformatics/btae577
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207392122&doi=10.1093%2fbioinformatics%2fbtae577&partnerID=40&md5=33cd92a350475246aa72e4e508e50db7
AB  - Motivation: RNA interference (RNAi) has become a widely used experimental approach for post-transcriptional regulation and is increasingly showing its potential as future targeted drugs. However, the prediction of highly efficient siRNAs (small interfering RNAs) is still hindered by dataset biases, the inadequacy of prediction methods, and the presence of off-target effects. To overcome these limitations, we propose an accurate and robust prediction method, OligoFormer, for siRNA design. Results: OligoFormer comprises three different modules including thermodynamic calculation, RNA-FM module, and Oligo encoder. Oligo encoder is the core module based on the transformer encoder. Taking siRNA and mRNA sequences as input, OligoFormer can obtain thermodynamic parameters, RNA-FM embedding, and Oligo embedding through these three modules, respectively. We carefully benchmarked OligoFormer against six comparable methods on siRNA efficacy datasets. OligoFormer outperforms all the other methods, with an average improvement of 9% in AUC, 6.6% in PRC, 9.8% in F1 score, and 5.1% in PCC compared to the best method among them in our inter-dataset validation. We also provide a comprehensive pipeline with prediction of siRNA efficacy and off-target effects using PITA score and TargetScan score. The ablation study shows RNA-FM module and thermodynamic parameters improved the performance and accelerated convergence of OligoFormer. The saliency maps by gradient backpropagation and base preference maps show certain base preferences in initial and terminal region of siRNAs. Availability and implementation: The source code of OligoFormer is freely available on GitHub at: https://github.com/lulab/OligoFormer. Docker image of OligoFormer is freely available on the docker hub at https://hub.docker.com/r/yilanbai/oligoformer. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Yu, W.
AU  - Lin, Q.
AU  - Wang, W.
AU  - Ge, E.
AU  - Su, A.
AU  - Zhao, Y.
TI  - TF-F-GAN: A GAN-based model to predict the assembly physical fields under multi-modal variables fusion on vision transformer
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102871
DO  - 10.1016/j.aei.2024.102871
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206948618&doi=10.1016%2fj.aei.2024.102871&partnerID=40&md5=aa4120b6801d3bb902ca3074e3eb7ead
AB  - Assembly is the final step in ensuring the precision and performance of mechanical products. Geometric variables, process variables, and other material or physical variables during the assembly process can all impact the assembly outcome. Therefore, the key for analyzing and predicting assembly results lies in establishing the mapping relationship between various assembly variables and the results. Traditional analysis methods typically consider the evolution of a single variable in relation to the assembly results and often focus on the value at a few nodes. Essentially, this approach constructs a value-to-value nonlinear mapping model, ignoring the coupling relationships between different variables. However, with the increase in assembly precision requirements and advancements in measurement equipment, assembly analysis has evolved from value-to-value prediction to field-to-field prediction. This shift necessitates the study of the assembly physical field results for specific regions rather than focusing on a few nodes. Therefore, this paper proposes an analysis framework, TF-F-GAN (Transformer-based- Field-Generative adversarial network), which is suitable for multi-source assembly variable inputs and physical field outputs. The framework draws inspiration from multimodal fusion and text-image generation models, leveraging the Vision Transformer (VIT) network to integrate multi-source heterogeneous data from the assembly process. The physical field data is color-mapped into a cloud image format, transforming the physical field prediction into a cloud image generation problem. The CFRP bolted joint structure assembly is used as a case study in this paper. Since assembly accuracy primarily focuses on geometric deformation, the deformation field of key regions in the CFRP bolted joint is taken as the output variable. In the case study, the geometric deviations of parts and mechanical behavior during the assembly process were considered. Data augmentation methods were used to construct the dataset. After training TF-F-GAN on this dataset, transfer learning was further conducted using experimental data. The final prediction error of TF-F-GAN relative to the experimental data was less than 15 %, with a computation time of less than 7 s. This prediction framework can serve as an effective tool for predicting the physical fields of general mechanical product assembly. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Luo, J.
AU  - Cai, B.
AU  - Yu, Y.
AU  - Ke, A.
AU  - Zhou, K.
AU  - Zhang, J.
TI  - Learning multimodal adaptive relation graph and action boost memory for visual navigation
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102678
DO  - 10.1016/j.aei.2024.102678
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198502534&doi=10.1016%2fj.aei.2024.102678&partnerID=40&md5=daaf663a1f087069768b3ac318a42058
AB  - The task of visual navigation (VN) is steering the agent find target object only using visual perceptions. Previous works largely exploit multimodal information (e.g. visual and training memory) to improve the environmental perception ability, while making less effort to leverage interchange information. Besides, multimodal fusion tends to ignore the data dependencies (prefer a part of the modal data) as well as the supervision of the action. In this work, we present a novel multimodal graph learning (MGL) structure for VN, which consists of three parts. (1) the multimodal fusion exploits the rich information across spatial, RGB, and depth information about objects’ place, as well as semantic information about their categories, (2) adaptive relation graph (ARG) is dynamically built using object detectors, which encodes multimodal fusion and adapt to a novel environment. It embeds its navigation history and other useful task-oriented structural information, thus make the agent own the association ability and make advisable informed decisions and (3) action boost module (ABM) aims to assist the agent make intelligent decisions, which predicts more accurate action using beneficial training experience. Our agent can foresight what the goal state may look like and how to get closer towards that state. These combinations of the “what” and the “how” allow the agent to navigate to the target object effectively. We validate our approach on the AI2-THOR dataset. It reports 24.2% and 23.7% increase in SPL(Success weighted by Per Length) and SR(Success Rate) compared with baselines, respectively. Code and datasets can be found in https://github.com/luosword/ABM_VN. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, M.
AU  - Chen, M.
AU  - Yang, Y.
TI  - UAHOI: Uncertainty-aware robust interaction learning for HOI detection
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 247
C7  - 104091
DO  - 10.1016/j.cviu.2024.104091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200218659&doi=10.1016%2fj.cviu.2024.104091&partnerID=40&md5=a1c26de08261ca434476a412860ed225
AB  - This paper focuses on Human–Object Interaction (HOI) detection, addressing the challenge of identifying and understanding the interactions between humans and objects within a given image or video frame. Spearheaded by Detection Transformer (DETR), recent developments lead to significant improvements by replacing traditional region proposals by a set of learnable queries. However, despite the powerful representation capabilities provided by Transformers, existing Human–Object Interaction (HOI) detection methods still yield low confidence levels when dealing with complex interactions and are prone to overlooking interactive actions. To address these issues, we propose a novel approach UAHOI, Uncertainty-aware Robust Human–Object Interaction Learning that explicitly estimates prediction uncertainty during the training process to refine both detection and interaction predictions. Our model not only predicts the HOI triplets but also quantifies the uncertainty of these predictions. Specifically, we model this uncertainty through the variance of predictions and incorporate it into the optimization objective, allowing the model to adaptively adjust its confidence threshold based on prediction variance. This integration helps in mitigating the adverse effects of incorrect or ambiguous predictions that are common in traditional methods without any hand-designed components, serving as an automatic confidence threshold. Our method is flexible to existing HOI detection methods and demonstrates improved accuracy. We evaluate UAHOI on two standard benchmarks in the field: V-COCO and HICO-DET, which represent challenging scenarios for HOI detection. Through extensive experiments, we demonstrate that UAHOI achieves significant improvements over existing state-of-the-art methods, enhancing both the accuracy and robustness of HOI detection. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhong, Y.
AU  - Tang, Z.
AU  - Zhang, H.
AU  - Dai, Z.
AU  - Nie, Z.
AU  - Xie, Y.
TI  - Pulp grade monitoring using binocular image through multi-scale feature cross-attention fusion network and saliency map constraint
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102780
DO  - 10.1016/j.aei.2024.102780
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201604843&doi=10.1016%2fj.aei.2024.102780&partnerID=40&md5=442fc0092c7ae8bcbff509398ff8ba9a
AB  - Pulp grade is an important indicator for performance monitoring in froth flotation process. Previous studies have shown that the pulp grade can be predicted more accurately by using the stereo vision information of froth images. However, due to the low intra-class variation among froth images under the identical working conditions and the similarity in shape and texture among bubbles, it is challenging for current binocular image-based methods for grade prediction. Therefore, to accurately predict the key performance indicators in flotation process, a prediction model based on binocular image fusion is proposed in this paper. First, a calculation method of froth image saliency map is proposed, and the saliency map is used as a priori knowledge to guide the prediction model to learn the characteristics of the region of interest in the image. This measure aims to solve the problem of difficulty in grade prediction caused by low intra-class differences in froth images. Then, a multi-scale feature cross-attention fusion network is introduced, wherein the multi-scale features of the left and right views serve as attention mechanism gating signals to extract common feature from binocular image. After that, a pulp grade prediction model is developed based on Video Transformer Network. The results on actual industrial flotation datasets show that, compared with other pulp grade prediction methods, our proposed approach reduces the mean absolute error and root mean square error by 22.84% and 23.55%, respectively. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yuan, W.
AU  - Zhao, H.
AU  - Yang, X.
AU  - Han, T.
AU  - Chang, D.
TI  - Toward dynamic rehabilitation management: A novel smart product-service system development approach based on fine-tuned large vision model and Fuzzy-Dematel
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102616
DO  - 10.1016/j.aei.2024.102616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195196944&doi=10.1016%2fj.aei.2024.102616&partnerID=40&md5=687ee9be3e7ecf93121750626cd73229
AB  - Nowadays, transformative technologies such as artificial intelligence, big data, and cloud computing are significantly influencing and reshaping the daily lives of individuals. Guided by the overarching concept of digital transformation, data-driven Smart Product-Service Systems (SPSS) have emerged, prompting scholars to investigate development approaches tailored to diverse data sources. However, the current approaches employed in the construction of SPSS exhibit limited capability in processing vast amounts of user-generated unstructured data. The relationship between big data intelligence and personalized services remains undisclosed. Moreover, the current focus of SPSS orientation predominantly addresses end consumers or manufacturers, with inadequate attention given to dynamic collaborative models that involve multiple stakeholders. These gaps are particularly conspicuous in complex industries such as rehabilitation management. To tackle these challenges, this study introduces a novel SPSS development approach that integrates a large vision model and the fuzzy-DEMATEL method. Specifically, a data-driven predictive assessment module was proposed, which constructs a medical image dataset and trains a rehabilitation predictive assessment model based on the transformer architecture. Secondly, personalized intervention services were generated, involving the representation of system elements, configuration, and optimization of service parameters. The fuzzy-DEMATEL method is mainly used for the initialization of service parameters. Then, interactive feedback is integrated into rehabilitation exercises for achieving continuous rehabilitation evaluation and service improvement. To validate the proposed approach, a FPRM-SPSS case was implemented, and it shows that the predictive assessment model achieved a high level of accuracy when applied to the clinical dataset constructed in this study, and the system was evaluated with high scores in user satisfaction. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Song, C.
AU  - Wu, J.
AU  - Xian, K.
AU  - Huang, J.
AU  - Lu, L.
TI  - Spatio-temporal graph learning: Traffic flow prediction of mobile edge computing in 5G/6G vehicular networks
PY  - 2024
T2  - Computer Networks
VL  - 252
C7  - 110676
DO  - 10.1016/j.comnet.2024.110676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200811542&doi=10.1016%2fj.comnet.2024.110676&partnerID=40&md5=6e77f1fb542e4d68e932bd460507e6c3
AB  - Mobile Edge Computing (MEC) is a key technology that emerged to address the increasing computational demands and communication requirements of vehicular networks. It is a form of edge computing that brings cloud computing capabilities closer to end-users, specifically within the context of vehicular networks, which are part of the broader Internet of Vehicles (IoV) ecosystem. However, the dynamic nature of traffic flows in MEC in 5G/6G vehicular networks poses challenges for accurate prediction and resource allocation when aiming to provide edge service for mobile vehicles. In this paper, we present a novel approach to predict the traffic flow of MEC in 5G/6G vehicular networks using graph-based learning. In our framework, MEC servers in vehicular networks are construed as nodes to construct a dynamic similarity graph and a dynamic transition graph over a duration of multiple days. We utilize Graph Attention Networks (GAT) to learn and fuse the node embeddings of these dynamic graphs. A transformer model is subsequently employed to predict the vehicle frequency accessing the edge computing services for the next day. Our experimental results have shown that the model achieves high accuracy in predicting edge service access volumes with low error metrics. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Wang, J.
AU  - Wang, J.
AU  - Guan, Q.
TI  - Predicting air quality using a multi-scale spatiotemporal graph attention network
PY  - 2024
T2  - Information Sciences
VL  - 680
C7  - 121072
DO  - 10.1016/j.ins.2024.121072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198004548&doi=10.1016%2fj.ins.2024.121072&partnerID=40&md5=5ce16a899a8ecb53d36568e9808e84ef
AB  - As urbanization accelerates, air quality has become a pressing concern. Accurate air quality prediction is essential for informed governmental decision-making and for protecting public health. Variations in air quality are influenced by complex multi-scale spatiotemporal processes. Existing research primarily relies on capturing single spatiotemporal features of air quality to predict changes. Meanwhile, when constructing spatiotemporal dynamic graphs, the inherent characteristics of the input data and the comprehensive effects of both global and local influences are not fully considered. To address these problems, we propose a graph-attention-based approach, named Multi-scale Spatiotemporal Graph Attention Network (MSTGAN). MSTGAN addresses the intricate spatiotemporal patterns of air quality across various scales through three key components: (1) a multistation transformer to model the temporal patterns of air quality at individual monitoring stations; (2) a bilinear spatiotemporal attention mechanism to capture the spatiotemporal dynamic global dependencies among all stations in a region; and (3) a set of spatiotemporal dependence graph-coupled Chebyshev graph convolution gate recurrent units to extract and aggregate the local spatiotemporal features of interrelated stations. Experiments conducted on three real-world datasets demonstrated that MSTGAN achieved significant improvements of 4.2%, 3.9%, and 7.8% in the mean absolute error, root mean square error, and R2 evaluation metrics, respectively, compared to seven state-of-the-art time-series forecasting methods. This code is publicly available at https://github.com/HPSCIL/MSTGAN-airquality-prediction. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024Predicting
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Tang, Z.
AU  - Shao, J.
AU  - Robertson, S.
AU  - Gómez, M.-Á.
AU  - Zhang, S.
TI  - HoopTransformer: Advancing NBA Offensive Play Recognition with Self-Supervised Learning from Player Trajectories
PY  - 2024
T2  - Sports Medicine
VL  - 54
IS  - 10
SP  - 2663
EP  - 2673
DO  - 10.1007/s40279-024-02030-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194731021&doi=10.1007%2fs40279-024-02030-3&partnerID=40&md5=3559e3c3c4d2f33e9deae3fa166127b5
AB  - Background and Objective: Understanding and recognizing basketball offensive set plays, which involve intricate interactions between players, have always been regarded as challenging tasks for untrained humans, not to mention machines. In this study, our objective is to propose an artificial intelligence model that can automatically recognize offensive plays using a novel self-supervised learning approach. Methods: The dataset was collected by SportVU from 632 games during the 2015–2016 season of the National Basketball Association (NBA), with a total of 90,524 possessions. A multi-agent motion prediction pretraining model was built on the basis of axial-attention transformer and trained with different masking strategies: motion prediction (MP), motion reconstruction (MR), and MP + MR joint strategy. A downstream play-level classification task and similarity search were used to evaluate the models’ performance. Results: The results showed that the MP + MR joint masking strategy maximized the ability of the model compared with individual masking strategies. For the classification task, the joint strategy achieved a top-1 accuracy of 81.5% and top-3 accuracy of 97.5%. In the similarity search evaluation, the joint strategy attained a top-5 accuracy of 76% and top-10 accuracy of 59%. Additionally, with the same MP + MR joint masking strategy, our HoopTransformer model outperformed the two baseline models in the classification task and similarity search. Conclusion: This study presents a self-supervised learning model and demonstrates the effectiveness and potential of the model in accurately comprehending and capturing player movements and complex interactions during offensive plays. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Wang, R.
AU  - He, X.
AU  - Lin, C.
AU  - Wang, T.
AU  - Jia, Q.
AU  - Fan, X.
TI  - WBNet: Weakly-supervised salient object detection via scribble and pseudo-background priors
PY  - 2024
T2  - Pattern Recognition
VL  - 154
C7  - 110579
DO  - 10.1016/j.patcog.2024.110579
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193683006&doi=10.1016%2fj.patcog.2024.110579&partnerID=40&md5=896b19694dcdcc178afd63e6bae074f3
AB  - Weakly supervised salient object detection (WSOD) methods endeavor to boost sparse labels to get more salient cues in various ways. Among them, an effective approach is using pseudo labels from multiple unsupervised self-learning methods, but inaccurate and inconsistent pseudo labels could ultimately lead to detection performance degradation. To tackle this problem, we develop a new multi-source WSOD framework, WBNet, that can effectively utilize pseudo-background (non-salient region) labels combined with scribble labels to obtain more accurate salient features. We first design a comprehensive salient pseudo-mask generator from multiple self-learning features. Then, we pioneer the exploration of generating salient pseudo-labels via point-prompted and box-prompted Segment Anything Models (SAM). Then, WBNet leverages a pixel-level Feature Aggregation Module (FAM), a mask-level Transformer-decoder (TFD), and an auxiliary Boundary Prediction Module (EPM) with a hybrid loss function to handle complex saliency detection tasks. Comprehensively evaluated with state-of-the-art methods on five widely used datasets, the proposed method significantly improves saliency detection performance. The code and results are publicly available at https://github.com/yiwangtz/WBNet. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ribeiro, R.
AU  - Moraes, A.
AU  - Moreno, M.
AU  - Ferreira, P.G.
TI  - Integration of multi-modal datasets to estimate human aging
PY  - 2024
T2  - Machine Learning
VL  - 113
IS  - 10
SP  - 7293
EP  - 7317
DO  - 10.1007/s10994-024-06588-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200044997&doi=10.1007%2fs10994-024-06588-x&partnerID=40&md5=0f62a823e59aef9852440b28c140f745
AB  - Aging involves complex biological processes leading to the decline of living organisms. As population lifespan increases worldwide, the importance of identifying factors underlying healthy aging has become critical. Integration of multi-modal datasets is a powerful approach for the analysis of complex biological systems, with the potential to uncover novel aging biomarkers. In this study, we leveraged publicly available epigenomic, transcriptomic and telomere length data along with histological images from the Genotype-Tissue Expression project to build tissue-specific regression models for age prediction. Using data from two tissues, lung and ovary, we aimed to compare model performance across data modalities, as well as to assess the improvement resulting from integrating multiple data types. Our results demostrate that methylation outperformed the other data modalities, with a mean absolute error of 3.36 and 4.36 in the test sets for lung and ovary, respectively. These models achieved lower error rates when compared with established state-of-the-art tissue-agnostic methylation models, emphasizing the importance of a tissue-specific approach. Additionally, this work has shown how the application of Hierarchical Image Pyramid Transformers for feature extraction significantly enhances age modeling using histological images. Finally, we evaluated the benefits of integrating multiple data modalities into a single model. Combining methylation data with other data modalities only marginally improved performance likely due to the limited number of available samples. Combining gene expression with histological features yielded more accurate age predictions compared with the individual performance of these data types. Given these results, this study shows how machine learning applications can be extended to/in multi-modal aging research. Code used is available at https://github.com/zroger49/multi_modal_age_prediction. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Li, M.
AU  - Zheng, L.
AU  - Shi, M.
AU  - Zheng, Z.
AU  - Pei, X.
TI  - Phyformer: A degradation physics-informed self-data driven approach to machinery prognostics
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102772
DO  - 10.1016/j.aei.2024.102772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201629364&doi=10.1016%2fj.aei.2024.102772&partnerID=40&md5=cb4292618d3f2b2ed4ce06b57b824d40
AB  - Machinery degradation prognostics methods have been suffering the “dilemma” that both physics and data-driven methods have their own limitations. On one hand, constructing accurate close-form mathematical physics models are prohibitively difficult for a complex system. On the other hand, for pure data driven models such as deep learning models, due to the lack of physics guidance, their extrapolation capability decays over time and even yield unexplainable predictions that violate common cognition. Therefore, relaxing the pursuit for the perfect and accurate degradation model, and instead coupling general degradation model with deep learning model, fully leveraging the advantages from both physics-based prognostics and data-driven prognostics, is a promising way to solve the “dilemma”. Driven by this motivation, this paper proposes Phyformer, a general degradation physics-informed self-data-driven method for machinery prognostics. A backbone deep learning model based on auto-correlation and Transformer architecture is developed for time series data prediction. Multiple local physical models that are constructed with data in sliding time windows are embedded into the backbone model in the form of loss function. Only the historical data of the machine itself are used to extrapolate the future, which is significant especially for high-end equipment since their run-to-fail data are scarce. Then the predicted data are mapped to degradation stage by an unsupervised clustering model Gath-Geva adaptively without the requirement of knowing the number of degradation stages in advance. Due to the above nature, Phyformer is high flexibility, easy to be deployed in different applications, working condition-independent and simple. Two typical prognostics tasks are studied, which use direct and indirect condition monitoring data as input, respectively. Comparisons with other state-of-the-art machinery prognostics models show the advances of Phyformer. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, Y.
AU  - Zhang, Y.
AU  - Li, X.
AU  - Wang, L.
TI  - 3MTox: A motif-level graph-based multi-view chemical language model for toxicity identification with deep interpretation
PY  - 2024
T2  - Journal of Hazardous Materials
VL  - 476
C7  - 135114
DO  - 10.1016/j.jhazmat.2024.135114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198008584&doi=10.1016%2fj.jhazmat.2024.135114&partnerID=40&md5=ef9c1dfba9bb0d15397a8a4ca3eb3c27
AB  - Toxicity identification plays a key role in maintaining human health, as it can alert humans to the potential hazards caused by long-term exposure to a wide variety of chemical compounds. Experimental methods for determining toxicity are time-consuming, and costly, while computational methods offer an alternative for the early identification of toxicity. For example, some classical ML and DL methods, which demonstrate excellent performance in toxicity prediction. However, these methods also have some defects, such as over-reliance on artificial features and easy overfitting, etc. Proposing novel models with superior prediction performance is still an urgent task. In this study, we propose a motifs-level graph-based multi-view pretraining language model, called 3MTox, for toxicity identification. The 3MTox model uses Bidirectional Encoder Representations from Transformers (BERT) as the backbone framework, and a motif graph as input. The results of extensive experiments showed that our 3MTox model achieved state-of-the-art performance on toxicity benchmark datasets and outperformed the baseline models considered. In addition, the interpretability of the model ensures that the it can quickly and accurately identify toxicity sites in a given molecule, thereby contributing to the determination of the status of toxicity and associated analyses. We think that the 3MTox model is among the most promising tools that are currently available for toxicity identification. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, W.-D.
AU  - Li, Z.
AU  - Zhang, L.
TI  - Combining Innovative CVTNet and Regularization Loss for Robust Adversarial Defense
PY  - 2024
T2  - Journal of Computer Science and Technology
VL  - 39
IS  - 5
SP  - 1078
EP  - 1093
DO  - 10.1007/s11390-024-3515-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211358778&doi=10.1007%2fs11390-024-3515-8&partnerID=40&md5=a82e8cc6ca70c0704d0637f475f0f25d
AB  - Deep neural networks (DNNs) are vulnerable to elaborately crafted and imperceptible adversarial perturbations. With the continuous development of adversarial attack methods, existing defense algorithms can no longer defend against them proficiently. Meanwhile, numerous studies have shown that vision transformer (ViT) has stronger robustness and generalization performance than the convolutional neural network (CNN) in various domains. Moreover, because the standard denoiser is subject to the error amplification effect, the prediction network cannot correctly classify all reconstruction examples. Firstly, this paper proposes a defense network (CVTNet) that combines CNNs and ViTs that is appended in front of the prediction network. CVTNet can effectively eliminate adversarial perturbations and maintain high robustness. Furthermore, this paper proposes a regularization loss (LCPL), which optimizes the CVTNet by computing different losses for the correct prediction set (CPS) and the wrong prediction set (WPS) of the reconstruction examples, respectively. The evaluation results on several standard benchmark datasets show that CVTNet performs better robustness than other advanced methods. Compared with state-of-the-art algorithms, the proposed CVTNet defense improves the average accuracy of pixel-constrained attack examples generated on the CIFAR-10 dataset by 24.25% and spatially-constrained attack examples by 14.06%. Moreover, CVTNet shows excellent generalizability in cross-model protection. © Institute of Computing Technology, Chinese Academy of Sciences 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Ai, C.
AU  - Yang, H.
AU  - Dong, R.
AU  - Tang, J.
AU  - Zheng, S.
AU  - Guo, F.
TI  - RetroCaptioner: beyond attention in end-to-end retrosynthesis transformer via contrastively captioned learnable graph representation
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 9
C7  - btae561
DO  - 10.1093/bioinformatics/btae561
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205336829&doi=10.1093%2fbioinformatics%2fbtae561&partnerID=40&md5=6884d91364a26f95bea7618d7cde7331
AB  - Motivation: Retrosynthesis identifies available precursor molecules for various and novel compounds. With the advancements and practicality of language models, Transformer-based models have increasingly been used to automate this process. However, many existing methods struggle to efficiently capture reaction transformation information, limiting the accuracy and applicability of their predictions. Results: We introduce RetroCaptioner, an advanced end-to-end, Transformer-based framework featuring a Contrastive Reaction Center Captioner. This captioner guides the training of dual-view attention models using a contrastive learning approach. It leverages learned molecular graph representations to capture chemically plausible constraints within a single-step learning process. We integrate the single-encoder, dual-encoder, and encoder–decoder paradigms to effectively fuse information from the sequence and graph representations of molecules. This involves modifying the Transformer encoder into a uni-view sequence encoder and a dual-view module. Furthermore, we enhance the captioning of atomic correspondence between SMILES and graphs. Our proposed method, RetroCaptioner, achieved outstanding performance with 67:2% in top-1 and 93:4% in top-10 exact matched accuracy on the USPTO-50k dataset, alongside an exceptional SMILES validity score of 99:4%. In addition, RetroCaptioner has demonstrated its reliability in generating synthetic routes for the drug protokylol. Availability and implementation: The code and data are available at https://github.com/guofei-tju/RetroCaptioner. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Rubin, O.
AU  - Berant, J.
TI  - Retrieval-Pretrained Transformer: Long-range Language Modeling with Self-retrieval
PY  - 2024
T2  - Transactions of the Association for Computational Linguistics
VL  - 12
SP  - 1197
EP  - 1213
DO  - 10.1162/tacl_a_00693
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206360071&doi=10.1162%2ftacl_a_00693&partnerID=40&md5=a6a58662273ea837d46ae07a00ee3436
AB  - Retrieval-augmented language models (LMs) have received much attention recently. However, typically the retriever is not trained jointly as a native component of the LM, but added post-hoc to an already-pretrained LM, which limits the ability of the LM and the retriever to adapt to one another. In this work, we propose the Retrieval-Pretrained Transformer (RPT), an architecture and training procedure for jointly training a retrieval-augmented LM from scratch and applying it to the task of modeling long texts. Given a recently generated text chunk in a long document, the LM computes query representations, which are then used to retrieve earlier chunks in the document, located potentially tens of thousands of tokens before. Information from retrieved chunks is fused into the LM representations to predict the next target chunk. We train the retriever component with a semantic objective, where the goal is to retrieve chunks that increase the probability of the next chunk, according to a reference LM. We evaluate RPT on four long-range language modeling tasks, spanning books, code, and mathematical writing, and demonstrate that RPT improves retrieval quality and subsequently perplexity across the board compared to strong baselines. © 2024 Association for Computational Linguistics.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Boshar, S.
AU  - Trop, E.
AU  - de Almeida, B.P.
AU  - Copoiu, L.
AU  - Pierrot, T.
TI  - Are genomic language models all you need? Exploring genomic language models on protein downstream tasks
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 9
C7  - btae529
DO  - 10.1093/bioinformatics/btae529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204040050&doi=10.1093%2fbioinformatics%2fbtae529&partnerID=40&md5=8471883aa6d20d2edebc6911090b92f9
AB  - Motivation: Large language models, trained on enormous corpora of biological sequences, are state-of-the-art for downstream genomic and proteomic tasks. Since the genome contains the information to encode all proteins, genomic language models (gLMs) hold the potential to make downstream predictions not only about DNA sequences, but also about proteins. However, the performance of gLMs on protein tasks remains unknown, due to few tasks pairing proteins with the coding DNA sequences (CDS) that can be processed by gLMs. Results: In this work, we curated five such datasets and used them to evaluate the performance of gLMs and proteomic language models (pLMs). We show that gLMs are competitive and even outperform their pLMs counterparts on some tasks. The best performance was achieved using the retrieved CDS compared to sampling strategies. We found that training a joint genomic-proteomic model outperforms each individual approach, showing that they capture different but complementary sequence representations, as we demonstrate through model interpretation of their embeddings. Lastly, we explored different genomic tokenization schemes to improve downstream protein performance. We trained a new Nucleotide Transformer (50M) foundation model with 3mer tokenization that outperforms its 6mer counterpart on protein tasks while maintaining performance on genomics tasks. The application of gLMs to proteomics offers the potential to leverage rich CDS data, and in the spirit of the central dogma, the possibility of a unified and synergistic approach to genomics and proteomics.  © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Yu, Y.
AU  - Zhang, T.
AU  - Song, K.
AU  - Wang, Y.
AU  - Gao, S.
TI  - Improved dendritic learning: Activation function analysis
PY  - 2024
T2  - Information Sciences
VL  - 679
C7  - 121034
DO  - 10.1016/j.ins.2024.121034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196773201&doi=10.1016%2fj.ins.2024.121034&partnerID=40&md5=568396940fcbd6c34c6a376ed7be38e1
AB  - This study conducted a thorough evaluation of an improved dendritic learning (DL) framework, focusing specifically on its application in power load forecasting. The objective was to optimise the activation functions within the synapses and somas of DL to enhance their adaptability across diverse real-world scenarios. Through a rigorous analysis involving 25 experiments across five activation functions (sigmoid, hyperbolic tangent (tanh), rectified linear unit (ReLU), leaky ReLU, and exponential linear unit (ELU)), we elucidated their impacts on both regression and classification performance. Notably, the leaky ReLU–tanh combination demonstrated exceptional mean performance and effectiveness across 14 benchmark datasets from the University of California Irvine Machine Learning Repository, surpassing alternative combinations. When applied to power load forecasting, this combination outperformed other models, particularly transformer and LSTM. These findings underscore the significant advantages of the leaky ReLU–tanh-based DL framework in accurately predicting electricity load in smart grids, as evidenced by the lowest mean absolute error (39.27), root mean squared error (29.13), and mean absolute percentage error (2.84). © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2024Improved
ER  -

TY  - JOUR
AU  - Wang, T.
AU  - Xiang, G.
AU  - He, S.
AU  - Su, L.
AU  - Wang, Y.
AU  - Yan, X.
AU  - Lu, H.
TI  - DeepEnzyme: a robust deep learning model for improved enzyme turnover number prediction by utilizing features of protein 3D-structures
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 5
C7  - bbae409
DO  - 10.1093/bib/bbae409
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201743138&doi=10.1093%2fbib%2fbbae409&partnerID=40&md5=c6f33054a2fe7d3677973882b61ee238
AB  - Turnover numbers (kcat), which indicate an enzyme’s catalytic efficiency, have a wide range of applications in fields including protein engineering and synthetic biology. Experimentally measuring the enzymes’ kcat is always time-consuming. Recently, the prediction of kcat using deep learning models has mitigated this problem. However, the accuracy and robustness in kcat prediction still needs to be improved significantly, particularly when dealing with enzymes with low sequence similarity compared to those within the training dataset. Herein, we present DeepEnzyme, a cutting-edge deep learning model that combines the most recent Transformer and Graph Convolutional Network (GCN) to capture the information of both the sequence and 3D-structure of a protein. To improve the prediction accuracy, DeepEnzyme was trained by leveraging the integrated features from both sequences and 3D-structures. Consequently, DeepEnzyme exhibits remarkable robustness when processing enzymes with low sequence similarity compared to those in the training dataset by utilizing additional features from high-quality protein 3D-structures. DeepEnzyme also makes it possible to evaluate how point mutations affect the catalytic activity of the enzyme, which helps identify residue sites that are crucial for the catalytic function. In summary, DeepEnzyme represents a pioneering effort in predicting enzymes’ kcat values with improved accuracy and robustness compared to previous algorithms. This advancement will significantly contribute to our comprehension of enzyme function and its evolutionary patterns across species. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ko, Y.S.
AU  - Parkinson, J.
AU  - Liu, C.
AU  - Wang, W.
TI  - TUnA: an uncertainty-aware transformer model for sequence-based protein–protein interaction prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 5
C7  - bbae359
DO  - 10.1093/bib/bbae359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199660345&doi=10.1093%2fbib%2fbbae359&partnerID=40&md5=6f9288732b9c3faf0d3da41b8ce3bf58
AB  - Protein–protein interactions (PPIs) are important for many biological processes, but predicting them from sequence data remains challenging. Existing deep learning models often cannot generalize to proteins not present in the training set and do not provide uncertainty estimates for their predictions. To address these limitations, we present TUnA, a Transformer-based uncertainty-aware model for PPI prediction. TUnA uses ESM-2 embeddings with Transformer encoders and incorporates a Spectral-normalized Neural Gaussian Process. TUnA achieves state-of-the-art performance and, importantly, evaluates uncertainty for unseen sequences. We demonstrate that TUnA’s uncertainty estimates can effectively identify the most reliable predictions, significantly reducing false positives. This capability is crucial in bridging the gap between computational predictions and experimental validation. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Fan, Z.
AU  - Shen, S.
AU  - Wu, M.
AU  - Deng, L.
TI  - MolMVC: Enhancing molecular representations for drug-related tasks through multi-view contrastive learning
PY  - 2024
T2  - Bioinformatics
VL  - 40
SP  - ii190
EP  - ii197
DO  - 10.1093/bioinformatics/btae386
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203223901&doi=10.1093%2fbioinformatics%2fbtae386&partnerID=40&md5=99a760d1cb124c1b33c528eab2dc9203
AB  - Motivation: Effective molecular representation is critical in drug development. The complex nature of molecules demands comprehensive multi-view representations, considering 1D, 2D, and 3D aspects, to capture diverse perspectives. Obtaining representations that encompass these varied structures is crucial for a holistic understanding of molecules in drug-related contexts. Results: In this study, we introduce an innovative multi-view contrastive learning framework for molecular representation, denoted as MolMVC. Initially, we use a Transformer encoder to capture 1D sequence information and a Graph Transformer to encode the intricate 2D and 3D structural details of molecules. Our approach incorporates a novel attention-guided augmentation scheme, leveraging prior knowledge to create positive samples tailored to different molecular data views. To align multi-view molecular positive samples effectively in latent space, we introduce an adaptive multi-view contrastive loss (AMCLoss). In particular, we calculate AMCLoss at various levels within the model to effectively capture the hierarchical nature of the molecular information. Eventually, we pre-train the encoders via minimizing AMCLoss to obtain the molecular representation, which can be used for various down-stream tasks. In our experiments, we evaluate the performance of our MolMVC on multiple tasks, including molecular property prediction (MPP), drug-target binding affinity (DTA) prediction and cancer drug response (CDR) prediction. The results demonstrate that the molecular representation learned by our MolMVC can enhance the predictive accuracy on these tasks and also reduce the computational costs. Furthermore, we showcase MolMVC’s efficacy in drug repositioning across a spectrum of drug-related applications. Availability and implementation: The code and pre-trained model are publicly available at https://github.com/Hhhzj-7/MolMVC. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yang, W.
AU  - Yang, C.
AU  - Li, J.
AU  - Tan, Y.
AU  - Lu, X.
AU  - Shi, C.
TI  - Non-autoregressive personalized bundle generation
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 5
C7  - 103814
DO  - 10.1016/j.ipm.2024.103814
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196629268&doi=10.1016%2fj.ipm.2024.103814&partnerID=40&md5=489cbf31328820ffe4420d56696d83c9
AB  - The personalized bundle generation problem, which aims to create a preferred bundle for user from numerous candidate items, receives increasing attention in recommendation. However, existing works ignore the order-invariant nature of the bundle and adopt sequential modeling methods as the solution, which might introduce inductive bias and cause a large latency in prediction. To address this problem, we propose to perform the bundle generation via non-autoregressive mechanism and design a novel encoder–decoder framework named BundleNAT, which can effectively output the targeted bundle in one-shot without relying on any inherent order. In detail, instead of learning sequential dependency, we propose to adopt pre-training techniques and graph neural network to fully embed user-based preference and item-based compatibility information, and use a self-attention based encoder to further extract global dependency pattern. We then design a permutation-equivariant decoding architecture that is able to directly output the desired bundle in a one-shot manner. Experiments on three real-world datasets from Youshu and Netease show the proposed BundleNAT significantly outperforms the current state-of-the-art methods in average by up to 35.92%, 10.97% and 23.67% absolute improvements in Precision, Precision+, and Recall, respectively. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Ren, M.
AU  - Wang, Z.
AU  - Li, G.
TI  - MEMF: Multi-entity multimodal fusion framework for sales prediction in live streaming commerce
PY  - 2024
T2  - Decision Support Systems
VL  - 184
C7  - 114277
DO  - 10.1016/j.dss.2024.114277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197270719&doi=10.1016%2fj.dss.2024.114277&partnerID=40&md5=94f1408b74744fce523e837f1033ac36
AB  - Live streaming commerce thrives with a rich tapestry of multimodal information that intertwines with various entities, including the anchor, the commodities, and the live streaming environment. Despite the wealth of data at hand, the synthesis and analysis of this information to predict sales remains a significant challenge. This study introduces a framework for multi-entity multimodal fusion, which is characterized by the effective synthesis of multimodal data and its prioritization of entity-level fusion, thereby providing a comprehensive feature representation for improving predictive performance. In addressing the multimodal data associated with a diverse range of products, our framework improves the Transformer architecture to initially capture the intra-product modal features and subsequently integrate the inter-product features. Data experiments are conducted on a real-world dataset from Taobao Live. The framework outperforms both traditional machine learning methods and state-of-the-art multimodal fusion methods, which affirms its value as a robust decision-support tool for sales prediction, enabling more accurate pre-event predictions and strategic planning. We also examine the impact of different types of information in accurate sales prediction. It is found that harnessing a comprehensive suite of data leads to optimal performance across all evaluation metrics. Commodity-related data is primary factor in determining the prediction accuracy, followed by video data and streaming room-related data, providing insights regarding the resource allocation for collecting and analyzing multimodal data from live streaming platforms. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Xu2024MEMF
ER  -

TY  - JOUR
AU  - Hu, S.
AU  - Chen, J.
AU  - Zhang, W.
AU  - Liu, G.
AU  - Chang, X.
TI  - Graph transformer embedded deep learning for short-term passenger flow prediction in urban rail transit systems: A multi-gate mixture-of-experts model
PY  - 2024
T2  - Information Sciences
VL  - 679
C7  - 121095
DO  - 10.1016/j.ins.2024.121095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196797751&doi=10.1016%2fj.ins.2024.121095&partnerID=40&md5=cb934481b7bdeccbf0cc7b51b23d1cfd
AB  - Urban rail transit (URT) plays a crucial role in mitigating urban traffic congestion by offering faster and higher-quality travel services. Short-term passenger flow predictions have practical significance for metro management and operation. However, the complex spatiotemporal characteristics and the relationship between entry and exit passenger flows make it challenging to detect the dynamic evolution patterns. This study proposes a Spatio-Temporal Graph Transformer (STGT) under the multi-task learning framework, utilizing Graph Transformer network and gated residual units to select and aggregate features. To account for the correlation between entry and exit passenger flow prediction tasks, the STGT model integrates a Multi-gate Mixture-of-Experts (MMoE) approach, which combines different expert networks for diverse input and explicitly learns to model passenger flow relationships in various scenarios. Metro-related characteristics such as weather conditions, train operation characteristics, and accessibility of nearby bus stops are incorporated to enhance prediction accuracy. Experimental evaluations are conducted using real-world historical passenger travel records from the Beijing subway. The results demonstrate the superior robustness and advantages of the STGT-MMoE model over basic and advanced benchmarks for passenger flow prediction tasks. These findings provide compelling evidence to address the challenges of short-term inflow and outflow prediction in urban rail transit systems. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Hu2024Graph
ER  -

TY  - JOUR
AU  - Fan, K.
AU  - Gökbag, B.
AU  - Tang, S.
AU  - Li, S.
AU  - Huang, Y.
AU  - Wang, L.
AU  - Cheng, L.
AU  - Li, L.
TI  - Synthetic lethal connectivity and graph transformer improve synthetic lethality prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 5
C7  - bbae425
DO  - 10.1093/bib/bbae425
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202809852&doi=10.1093%2fbib%2fbbae425&partnerID=40&md5=7c7e773ce1eb0930257702d06acae351
AB  - Synthetic lethality (SL) has shown great promise for the discovery of novel targets in cancer. CRISPR double-knockout (CDKO) technologies can only screen several hundred genes and their combinations, but not genome-wide. Therefore, good SL prediction models are highly needed for genes and gene pairs selection in CDKO experiments. However, lack of scalable SL properties prevents generalizability of SL interactions to out-of-sample data, thereby hindering modeling efforts. In this paper, we recognize that SL connectivity is a scalable and generalizable SL property. We develop a novel two-step multilayer encoder for individual sample-specific SL prediction model (MLEC-iSL), which predicts SL connectivity first and SL interactions subsequently. MLEC-iSL has three encoders, namely, gene, graph, and transformer encoders. MLEC-iSL achieves high SL prediction performance in K562 (AUPR, 0.73; AUC, 0.72) and Jurkat (AUPR, 0.73; AUC, 0.71) cells, while no existing methods exceed 0.62 AUPR and AUC. The prediction performance of MLEC-iSL is validated in a CDKO experiment in 22Rv1 cells, yielding a 46.8% SL rate among 987 selected gene pairs. The screen also reveals SL dependency between apoptosis and mitosis cell death pathways. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Glicksberg, B.S.
AU  - Timsina, P.
AU  - Patel, D.
AU  - Sawant, A.
AU  - Vaid, A.
AU  - Raut, G.
AU  - Charney, A.W.
AU  - Apakama, D.
AU  - Carr, B.G.
AU  - Freeman, R.
AU  - Nadkarni, G.N.
AU  - Klang, E.
TI  - Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 9
SP  - 1921
EP  - 1928
DO  - 10.1093/jamia/ocae103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201786452&doi=10.1093%2fjamia%2focae103&partnerID=40&md5=fb8a868510125d6c891fb44d8bee8d74
AB  - Background: Artificial intelligence (AI) and large language models (LLMs) can play a critical role in emergency room operations by augmenting decision-making about patient admission. However, there are no studies for LLMs using real-world data and scenarios, in comparison to and being informed by traditional supervised machine learning (ML) models. We evaluated the performance of GPT-4 for predicting patient admissions from emergency department (ED) visits. We compared performance to traditional ML models both naively and when informed by few-shot examples and/or numerical probabilities. Methods: We conducted a retrospective study using electronic health records across 7 NYC hospitals. We trained Bio-Clinical-BERT and XGBoost (XGB) models on unstructured and structured data, respectively, and created an ensemble model reflecting ML performance. We then assessed GPT-4 capabilities in many scenarios: through Zero-shot, Few-shot with and without retrieval-augmented generation (RAG), and with and without ML numerical probabilities. Results: The Ensemble ML model achieved an area under the receiver operating characteristic curve (AUC) of 0.88, an area under the precision-recall curve (AUPRC) of 0.72 and an accuracy of 82.9%. The naïve GPT-4's performance (0.79 AUC, 0.48 AUPRC, and 77.5% accuracy) showed substantial improvement when given limited, relevant data to learn from (ie, RAG) and underlying ML probabilities (0.87 AUC, 0.71 AUPRC, and 83.1% accuracy). Interestingly, RAG alone boosted performance to near peak levels (0.82 AUC, 0.56 AUPRC, and 81.3% accuracy). Conclusions: The naïve LLM had limited performance but showed significant improvement in predicting ED admissions when supplemented with real-world examples to learn from, particularly through RAG, and/or numerical probabilities from traditional ML models. Its peak performance, although slightly lower than the pure ML model, is noteworthy given its potential for providing reasoning behind predictions. Further refinement of LLMs with real-world data is necessary for successful integration as decision-support tools in care settings. © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Ren, R.
AU  - Yu, H.
AU  - Teng, J.
AU  - Mao, S.
AU  - Bian, Z.
AU  - Tao, Y.
AU  - Yau, S.S.-T.
TI  - CAPE: a deep learning framework with Chaos-Attention net for Promoter Evolution
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 5
C7  - bbae398
DO  - 10.1093/bib/bbae398
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201034389&doi=10.1093%2fbib%2fbbae398&partnerID=40&md5=08981a5e43c9f45b72fea9c1fb4ecb85
AB  - Predicting the strength of promoters and guiding their directed evolution is a crucial task in synthetic biology. This approach significantly reduces the experimental costs in conventional promoter engineering. Previous studies employing machine learning or deep learning methods have shown some success in this task, but their outcomes were not satisfactory enough, primarily due to the neglect of evolutionary information. In this paper, we introduce the Chaos-Attention net for Promoter Evolution (CAPE) to address the limitations of existing methods. We comprehensively extract evolutionary information within promoters using merged chaos game representation and process the overall information with modified DenseNet and Transformer structures. Our model achieves state-of-the-art results on two kinds of distinct tasks related to prokaryotic promoter strength prediction. The incorporation of evolutionary information enhances the model's accuracy, with transfer learning further extending its adaptability. Furthermore, experimental results confirm CAPE's efficacy in simulating in silico directed evolution of promoters, marking a significant advancement in predictive modeling for prokaryotic promoter strength.Our paper also presents a user-friendly website for the practical implementation of in silico directed evolution on promoters. The source code implemented in this study and the instructions on accessing the website can be found in our GitHub repository https://github.com/BobYHY/CAPE.  © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hadadi, F.
AU  - Dawes, J.H.
AU  - Shin, D.
AU  - Bianculli, D.
AU  - Briand, L.
TI  - Systematic Evaluation of Deep Learning Models for Log-based Failure Prediction
PY  - 2024
T2  - Empirical Software Engineering
VL  - 29
IS  - 5
C7  - 105
DO  - 10.1007/s10664-024-10501-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196548862&doi=10.1007%2fs10664-024-10501-4&partnerID=40&md5=f3ea90d7cc8bc3d2efb9ef56625a0f2f
AB  - With the increasing complexity and scope of software systems, their dependability is crucial. The analysis of log data recorded during system execution can enable engineers to automatically predict failures at run time. Several Machine Learning (ML) techniques, including traditional ML and Deep Learning (DL), have been proposed to automate such tasks. However, current empirical studies are limited in terms of covering all main DL types—Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and transformer—as well as examining them on a wide range of diverse datasets. In this paper, we aim to address these issues by systematically investigating the combination of log data embedding strategies and DL types for failure prediction. To that end, we propose a modular architecture to accommodate various configurations of embedding strategies and DL-based encoders. To further investigate how dataset characteristics such as dataset size and failure percentage affect model accuracy, we synthesised 360 datasets, with varying characteristics, for three distinct system behavioural models, based on a systematic and automated generation approach. Using the F1 score metric, our results show that the best overall performing configuration is a CNN-based encoder with Logkey2vec. Additionally, we provide specific dataset conditions, namely a dataset size >350 or a failure percentage >7.5%, under which this configuration demonstrates high accuracy for failure prediction. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, B.-B.
AU  - Huang, Z.
TI  - CSTrans: Correlation-guided Self-Activation Transformer for Counting Everything
PY  - 2024
T2  - Pattern Recognition
VL  - 153
C7  - 110556
DO  - 10.1016/j.patcog.2024.110556
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192883126&doi=10.1016%2fj.patcog.2024.110556&partnerID=40&md5=f2138abc7212770c357520f0e3a6f3ce
AB  - Counting everything, also named few-shot counting, requires a model to be able to count objects with any novel (unseen) category giving few exemplar boxes. However, the existing few-shot counting methods are sub-optimal due to weak feature representation, such as the correlation between the exemplar patch and query feature, and contextual dependencies in density map prediction. In this paper, we propose a very simple but effective method, CSTrans, consisting of a Correlation-guided Self-Activation (CSA) module and a Local Dependency Transformer (LDT) module, to mitigate the above two issues, respectively. The CSA utilizes the correlation map to activate the semantic features and suppress the noisy influence of the query features, aiming at mining the potential relation while enriching correlation representation. Furthermore, the LDT incorporates a Transformer to explore local contextual dependencies and predict the density map. Our method achieves competitive performance on FSC-147 and CARPK datasets. We hope its simple implementation and superior performance can serve as a new and strong baseline for few-shot counting tasks and attract more interest in designing simple but effective models in future studies. Our code for CSTrans is available at https://github.com/gaobb/CSTrans. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Xi, Y.
AU  - Dong, L.
AU  - Zhao, M.
AU  - Li, C.
AU  - Liu, X.
AU  - Cui, X.
TI  - Identifying influential nodes in complex networks via Transformer
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 5
C7  - 103775
DO  - 10.1016/j.ipm.2024.103775
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193453763&doi=10.1016%2fj.ipm.2024.103775&partnerID=40&md5=17a9ea279e77af35df88e320a5b1ef87
AB  - In the domain of complex networks, the identification of influential nodes plays a crucial role in ensuring network stability and facilitating efficient information dissemination. Although the study of influential nodes has been applied in many fields such as suppression of rumor spreading, regulation of group behavior, and prediction of mass events evolution, current deep learning-based algorithms have limited input features and are incapable of aggregating neighbor information of nodes, thus failing to adapt to complex networks. We propose an influential node identification method in complex networks based on the Transformer. In this method, the input sequence of a node includes information about the node itself and its neighbors, enabling the model to effectively aggregate node information to identify its influence. Experiments were conducted on 9 synthetic networks and 12 real networks. Using the SIR model and a benchmark method to verify the effectiveness of our approach. The experimental results show that this method can more effectively identify influential nodes in complex networks. In particular, the method improves 27 percent compared to the second place method in network Netscience and 21 percent in network Faa. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Huang, K.
AU  - Yang, J.
AU  - Wang, J.
AU  - He, S.
AU  - Wang, Z.
AU  - He, H.
AU  - Zhang, Q.
AU  - Lu, G.
TI  - Granular3D: Delving into multi-granularity 3D scene graph prediction
PY  - 2024
T2  - Pattern Recognition
VL  - 153
C7  - 110562
DO  - 10.1016/j.patcog.2024.110562
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192714926&doi=10.1016%2fj.patcog.2024.110562&partnerID=40&md5=885c9aff644b6d160e6c9a2b819737b2
AB  - This paper addresses the significant challenges in 3D Semantic Scene Graph (3DSSG) prediction, essential for understanding complex 3D environments. Traditional approaches, primarily using PointNet and Graph Convolutional Networks, struggle with effectively extracting multi-grained features from intricate 3D scenes, largely due to a focus on global scene processing and single-scale feature extraction. To overcome these limitations, we introduce Granular3D, a novel approach that shifts the focus towards multi-granularity analysis by predicting relation triplets from specific sub-scenes. One key is the Adaptive Instance Enveloping Method (AIEM), which establishes an approximate envelope structure around irregular instances, providing shape-adaptive local point cloud sampling, thereby comprehensively covering the contextual environments of instances. Moreover, Granular3D incorporates a Hierarchical Dual-Stage Network (HDSN), which differentiates and processes features of instances and their pairs at varying scales, leading to a targeted prediction of instance categories and their relationships. To advance the perception of sub-scene in HDSN, we design a Gather Point Transformer structure (GaPT) that enables the combinatorial interaction of local information from multiple point cloud sets, achieving a more comprehensive local contextual feature extraction. Extensive evaluations on the challenging 3DSSG benchmark demonstrate that our methods provide substantial improvements, establishing a new state-of-the-art in 3DSSG prediction, boosting the top-50 triplet accuracy by ＋2.8%. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chandran, P.
AU  - Zoss, G.
AU  - Gotardo, P.
AU  - Bradley, D.
TI  - Infinite 3D Landmarks: Improving Continuous 2D Facial Landmark Detection
PY  - 2024
T2  - Computer Graphics Forum
VL  - 43
IS  - 6
C7  - e15126
DO  - 10.1111/cgf.15126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195562011&doi=10.1111%2fcgf.15126&partnerID=40&md5=3cc247273cbd6d8f6b7ea4325bf99716
AB  - In this paper, we examine three important issues in the practical use of state-of-the-art facial landmark detectors and show how a combination of specific architectural modifications can directly improve their accuracy and temporal stability. First, many facial landmark detectors require a face normalization step as a pre-process, often accomplished by a separately trained neural network that crops and resizes the face in the input image. There is no guarantee that this pre-trained network performs optimal face normalization for the task of landmark detection. Thus, we instead analyse the use of a spatial transformer network that is trained alongside the landmark detector in an unsupervised manner, jointly learning an optimal face normalization and landmark detection by a single neural network. Second, we show that modifying the output head of the landmark predictor to infer landmarks in a canonical 3D space rather than directly in 2D can further improve accuracy. To convert the predicted 3D landmarks into screen-space, we additionally predict the camera intrinsics and head pose from the input image. As a side benefit, this allows to predict the 3D face shape from a given image only using 2D landmarks as supervision, which is useful in determining landmark visibility among other things. Third, when training a landmark detector on multiple datasets at the same time, annotation inconsistencies across datasets forces the network to produce a sub-optimal average. We propose to add a semantic correction network to address this issue. This additional lightweight neural network is trained alongside the landmark detector, without requiring any additional supervision. While the insights of this paper can be applied to most common landmark detectors, we specifically target a recently proposed continuous 2D landmark detector to demonstrate how each of our additions leads to meaningful improvements over the state-of-the-art on standard benchmarks. © 2024 Eurographics - The European Association for Computer Graphics and John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Janssens, B.
AU  - Schetgen, L.
AU  - Bogaert, M.
AU  - Meire, M.
AU  - Van den Poel, D.
TI  - 360 Degrees rumor detection: When explanations got some explaining to do
PY  - 2024
T2  - European Journal of Operational Research
VL  - 317
IS  - 2
SP  - 366
EP  - 381
DO  - 10.1016/j.ejor.2023.06.024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163863220&doi=10.1016%2fj.ejor.2023.06.024&partnerID=40&md5=a0fa02043541c9833815686aa590ee2a
AB  - Unverified rumor detection recently received considerable academic attention due to the societal impact resulting from this potential misinformation. Previous work in this area mainly focused on textual features using a limited number of data sets and candidate algorithms, and completely disregarded model explainability. This study aims to come up with a more comprehensive social media rumor detection methodology. First, we investigate which machine or deep learning algorithm is best suited to classify tweets into rumors and non-rumors using both textual and structured features. Next, we interpret these rumor detection models with the LIME method and assess the quality of the explanations via fidelity and stability. To ensure the robustness of our methodology, it is benchmarked across the well-known PHEME data sets and two novel data sets, which are made publicly available. The results indicate that machine learners perform best on small data sets, while transformer architectures show the highest predictive accuracy for larger data sets. Unfortunately, these high accuracy transformer models are incompatible with LIME, which results in low fidelity. Moreover, our study shows that all LIME explanations are unstable across folds. Based on these results, we argue to evaluate explanation quality using fidelity and stability before explanation deployment. Our results further demonstrate that apparent model-agnostic explanations such as LIME do not seem to be completely model-agnostic and should be used with caution. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Janssens2024360
ER  -

TY  - JOUR
AU  - Yu, Y.
AU  - Ma, R.
AU  - Ma, Z.
TI  - Robformer: A robust decomposition transformer for long-term time series forecasting
PY  - 2024
T2  - Pattern Recognition
VL  - 153
C7  - 110552
DO  - 10.1016/j.patcog.2024.110552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192675742&doi=10.1016%2fj.patcog.2024.110552&partnerID=40&md5=6976c0b332e7f87350bc03c5821d7c51
AB  - Transformer-based forecasting methods have been widely applied to forecast long-term multivariate time series, which achieves significant improvements on extending the forecasting time. However, their performance can degenerate terribly when abrupt trend shift and seasonal fluctuation arise in long-term time series. Hence, we identify two bottlenecks of previous Transformers architecture: (1) the robustless decomposition module and (2) trend shifting problem. These result in a different distribution between the trend prediction and ground truth in the long-term multivariate series forecasting. Towards these bottlenecks, we design Robformer as a novel decomposition-based Transformer, which consists of three new inner module to enhance the predictability of Transformers. Concretely, we renew the decomposition module and add a seasonal component adjustment module to tackle the unstationarized series. Further, we propose a novel inner trend forecasting architecture inspired by polynomial fitting method, which outperforms previous design in accuracy and robustness. Our empirical studies show that Robformer can achieve 17% and 10% relative improvements than state-of-the-art Autoformer and FEDformer baselines under the fair long-term multivariate setting on six benchmarks, covering five mainstream time series forecasting applications: energy, economics, traffic, weather, and disease. The code will be released upon publication. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Akkaya, I.B.
AU  - Kathiresan, S.S.
AU  - Arani, E.
AU  - Zonooz, B.
TI  - Enhancing performance of vision transformers on small datasets through local inductive bias incorporation
PY  - 2024
T2  - Pattern Recognition
VL  - 153
C7  - 110510
DO  - 10.1016/j.patcog.2024.110510
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191897205&doi=10.1016%2fj.patcog.2024.110510&partnerID=40&md5=ff2ce97c369baef679680a4f8861978e
AB  - Vision transformers (ViTs) achieve remarkable performance on large datasets, but tend to perform worse than convolutional neural networks (CNNs) when trained from scratch on smaller datasets, possibly due to a lack of local inductive bias in the architecture. Recent studies have therefore added locality to the architecture and demonstrated that it can help ViTs achieve performance comparable to CNNs in the small-size dataset regime. Existing methods, however, are architecture-specific or have higher computational and memory costs. Thus, we propose a module called Local InFormation Enhancer (LIFE) that extracts patch-level local information and incorporates it into the embeddings used in the self-attention block of ViTs. Our proposed module is memory and computation efficient, as well as flexible enough to process auxiliary tokens such as the classification and distillation tokens. Empirical results show that the addition of the LIFE module improves the performance of ViTs on small image classification datasets. We further demonstrate how the effect can be extended to downstream tasks, such as object detection and semantic segmentation. In addition, we introduce a new visualization method, Dense Attention Roll-Out, specifically designed for dense prediction tasks, allowing the generation of class-specific attention maps utilizing the attention maps of all tokens. The code for this project is available on Github (https://github.com/NeurAI-Lab/LIFEhttps://github.com/NeurAI-Lab/LIFE). © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Peng, Z.
AU  - Rong, Y.
AU  - Zhu, T.
TI  - Transformer-based choice model: A tool for assortment optimization evaluation
PY  - 2024
T2  - Naval Research Logistics
VL  - 71
IS  - 6
SP  - 854
EP  - 877
DO  - 10.1002/nav.22183
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189067701&doi=10.1002%2fnav.22183&partnerID=40&md5=ef556e64837f96e490c9923c87cd86a5
AB  - Assessing the efficacy of algorithms plays a pivotal role in advancing various fields, both in theory and practice. Unlike the predictive models, due to the intricate relationship between decisions and the underlying data-generating processes, the evaluation of decision algorithms cannot directly rely on real data. Hence, a simulator becomes indispensable for appraising decision algorithm effectiveness. In this paper, we aim to leverage assortment decisions, a widely used application in revenue management, to illustrate the utilization of a machine learning-based simulation. The process can be summarised as: we utilize the modified Transformer-based choice model, acting as a simulator, to generate a synthetic dataset that mimics consumer purchasing behavior. After training the MNL, DeepFM, and DeepFM-a models, all of which can swiftly provide assortment decisions in real-time, we utilize the simulator to evaluate the revenue generated by each assortment prescribed by different choice models. This approach mitigates the challenge of validating decision models that alter real-world observed data. To show the benefit of such a simulation approach, we have conducted various numerical studies. These studies aim to examine the impact of outside option attractiveness, data size, the number of features, and cardinality. Admittedly, due to the close alignment between the simulator and complex consumer purchase choice datasets, some numerical observations may be challenging to explain. Nevertheless, by employing the simulator, we are able to contrast the differences between the MNL and DeepFM/DeepFM-a models, shedding light on their respective model misspecifications. © 2024 Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Peng2024Transformer-based
ER  -

TY  - JOUR
AU  - Wang, T.
AU  - Zhuo, L.
AU  - Chen, Y.
AU  - Fu, X.
AU  - Zeng, X.
AU  - Zou, Q.
TI  - ECD-CDGI: An efficient energy-constrained diffusion model for cancer driver gene identification
PY  - 2024
T2  - PLoS Computational Biology
VL  - 20
IS  - 8 August
C7  - e1012400
DO  - 10.1371/journal.pcbi.1012400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202783475&doi=10.1371%2fjournal.pcbi.1012400&partnerID=40&md5=92ce3cd98bd785b2d1681a4167e5a44f
AB  - The identification of cancer driver genes (CDGs) poses challenges due to the intricate interdependencies among genes and the influence of measurement errors and noise. We propose a novel energy-constrained diffusion (ECD)-based model for identifying CDGs, termed ECD-CDGI. This model is the first to design an ECD-Attention encoder by combining the ECD technique with an attention mechanism. ECD-Attention encoder excels at generating robust gene representations that reveal the complex interdependencies among genes while reducing the impact of data noise. We concatenate topological embedding extracted from gene-gene networks through graph transformers to these gene representations. We conduct extensive experiments across three testing scenarios. Extensive experiments show that the ECD-CDGI model possesses the ability to not only be proficient in identifying known CDGs but also efficiently uncover unknown potential CDGs. Furthermore, compared to the GNN-based approach, the ECD-CDGI model exhibits fewer constraints by existing gene-gene networks, thereby enhancing its capability to identify CDGs. Additionally, ECD-CDGI is open-source and freely available. We have also launched the model as a complimentary online tool specifically crafted to expedite research efforts focused on CDGs identification. © 2024 Wang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chowdhury, S.
AU  - Chen, Y.
AU  - Li, P.
AU  - Rajaganapathy, S.
AU  - Wen, A.
AU  - Ma, X.
AU  - Dai, Q.
AU  - Yu, Y.
AU  - Fu, S.
AU  - Jiang, X.
AU  - He, Z.
AU  - Sohn, S.
AU  - Liu, X.
AU  - Bielinski, S.J.
AU  - Chamberlain, A.M.
AU  - Cerhan, J.R.
AU  - Zong, N.
TI  - Stratifying heart failure patients with graph neural network and transformer using Electronic Health Records to optimize drug response prediction
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 8
SP  - 1671
EP  - 1681
DO  - 10.1093/jamia/ocae137
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199141244&doi=10.1093%2fjamia%2focae137&partnerID=40&md5=9621bbf48ea3ef7460e2207272f97b4f
AB  - Objectives: Heart failure (HF) impacts millions of patients worldwide, yet the variability in treatment responses remains a major challenge for healthcare professionals. The current treatment strategies, largely derived from population based evidence, often fail to consider the unique characteristics of individual patients, resulting in suboptimal outcomes. This study aims to develop computational models that are patient-specific in predicting treatment outcomes, by utilizing a large Electronic Health Records (EHR) database. The goal is to improve drug response predictions by identifying specific HF patient subgroups that are likely to benefit from existing HF medications. Materials and Methods: A novel, graph-based model capable of predicting treatment responses, combining Graph Neural Network and Transformer was developed. This method differs from conventional approaches by transforming a patient's EHR data into a graph structure. By defining patient subgroups based on this representation via K-Means Clustering, we were able to enhance the performance of drug response predictions. Results: Leveraging EHR data from 11 627 Mayo Clinic HF patients, our model significantly outperformed traditional models in predicting drug response using NT-proBNP as a HF biomarker across five medication categories (best RMSE of 0.0043). Four distinct patient subgroups were identified with differential characteristics and outcomes, demonstrating superior predictive capabilities over existing HF subtypes (best mean RMSE of 0.0032). Discussion: These results highlight the power of graph-based modeling of EHR in improving HF treatment strategies. The stratification of patients sheds light on particular patient segments that could benefit more significantly from tailored response predictions. Conclusions: Longitudinal EHR data have the potential to enhance personalized prognostic predictions through the application of graph-based AI techniques.  © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Qin, Y.
AU  - DeWitt, S.
AU  - Radhakrishnan, B.
AU  - Biros, G.
TI  - GrainGNN: A dynamic graph neural network for predicting 3D grain microstructure
PY  - 2024
T2  - Journal of Computational Physics
VL  - 510
C7  - 113061
DO  - 10.1016/j.jcp.2024.113061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192685066&doi=10.1016%2fj.jcp.2024.113061&partnerID=40&md5=c80adeefe4430245def59926ee168f3d
AB  - We propose GrainGNN, a surrogate model for the evolution of polycrystalline grain structure under rapid solidification conditions in metal additive manufacturing. High fidelity simulations of solidification microstructures are typically performed using multicomponent partial differential equations (PDEs) with moving interfaces. The inherent randomness of the PDE initial conditions (grain seeds) necessitates ensemble simulations to predict microstructure statistics, e.g., grain size, aspect ratio, and crystallographic orientation. Currently such ensemble simulations are prohibitively expensive and surrogates are necessary. In GrainGNN, we use a dynamic graph to represent interface motion and topological changes due to grain coarsening. We use a reduced representation of the microstructure using hand-crafted features; we combine pattern finding and altering graph algorithms with two neural networks, a classifier (for topological changes) and a regressor (for interface motion). Both networks have an encoder-decoder architecture; the encoder has a multi-layer transformer long-short-term-memory architecture; the decoder is a single layer perceptron. We evaluate GrainGNN by comparing it to high-fidelity phase field simulations for in-distribution and out-of-distribution grain configurations for solidification under laser power bed fusion conditions. GrainGNN results in 80%–90% pointwise accuracy; and nearly identical distributions of scalar quantities of interest (QoI) between phase field and GrainGNN simulations compared using Kolmogorov-Smirnov test. GrainGNN's inference speedup (PyTorch on single x86 CPU) over a high-fidelity phase field simulation (CUDA on a single NVIDIA A100 GPU) is 150×–2000× for 100-initial grain problem. Further, using GrainGNN, we model the formation of 11,600 grains in 220 seconds on a single CPU core. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shaabanzadeh, S.S.
AU  - Sánchez-González, J.
TI  - A spatio-temporal prediction methodology based on deep learning and real Wi-Fi measurements
PY  - 2024
T2  - Computer Networks
VL  - 250
C7  - 110569
DO  - 10.1016/j.comnet.2024.110569
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196515584&doi=10.1016%2fj.comnet.2024.110569&partnerID=40&md5=46075e9dc7d35f7351f290edb9b57dca
AB  - The rapid development of Wi-Fi technologies in recent years has caused a significant increase in the traffic usage. Hence, knowledge obtained from Wi-Fi network measurements can be helpful for a more efficient network management. In this paper, we propose a methodology to predict future values of some specific network metrics (e.g. traffic load, transmission failures, etc.). These predictions may be useful for improving the network performance. After data collection and preprocessing, the correlation between each target access point (AP) and its neighbouring APs is estimated. According to these correlations, either an only-temporal or a spatio-temporal based prediction is done. To evaluate the proposed methodology, real measurements are collected from 100 APs deployed in different university buildings for 3 months. Deep Learning (DL) methods (i.e. Convolutional Neural Network (CNN), Simple Recurrent Neural Network (SRNN), Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM), Transformer) are evaluated and compared for both temporal and spatio-temporal based predictions. Moreover, a hybrid prediction methodology is proposed using a spatial processing based on CNN and a temporal prediction based on RNN. The proposed hybrid methodology provides an improvement in the prediction accuracy at expenses of a slight increase in the Training Computational Time (TCT) and negligible in Prediction Computational Time (PCT). © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Papadopoulos, L.
AU  - Atzarakis, K.
AU  - Sotiropoulos, G.
AU  - Kalogeris, I.
AU  - Papadopoulos, V.
TI  - Fusing nonlinear solvers with transformers for accelerating the solution of parametric transient problems
PY  - 2024
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 428
C7  - 117074
DO  - 10.1016/j.cma.2024.117074
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194375085&doi=10.1016%2fj.cma.2024.117074&partnerID=40&md5=86d228fe68dec8f8b2939414ca7802b4
AB  - In the field of computational science and engineering, solving nonlinear transient problems still poses a challenging task that often requires significant computational resources. This research introduces a novel methodology that harnesses the power of cutting-edge Temporal Fusion Transformers (TFTs) to accelerate the solution of such problems in multi-query scenarios (i.e. parameterized problems). At each time step, TFT models, renowned for their time series forecasting capabilities, are combined with dimensionality reduction techniques to efficiently generate initial solutions for nonlinear solvers. Specifically, during the training phase, a reduced set of high-fidelity system solutions is obtained by solving the system of differential equations governing the problem for different parameter instances. Then, dimensionality reduction is applied to create a reduced latent space to simplify the representation of the complex system solutions. Subsequently, TFT models are trained for one-step-ahead forecasting in the latent space, utilizing information from previous states to make accurate predictions about future states. The TFTs’ predictions are fed back to the system as initial guesses at each time step of the solution algorithm and are then guided towards the exact solutions that satisfy equilibrium using Newton–Raphson (NR) iterations. The basic premise of the proposed idea is that having accurate initial predictions will significantly decrease the number of the costly NR-iterations needed in nonlinear dynamic problems, effectively reducing the solution time. In addition, the proposed scheme is able to handle problems with parametric and time-variant forcing forces. A customized TFT architecture is developed that takes as input not only the response history of the system, but also the current loading, and makes informed guesses about the future state of the system. The methodology's effectiveness is demonstrated in numerical applications that involve high nonlinearity, where the TFT-generated initial solutions resulted in a notable reduction in the number of NR-iterations required for solver convergence. This significant enhancement in computational efficiency holds substantial promise, especially in scenarios involving a multitude of analyses and high iteration demands, with wide-ranging applications across computational mechanics and related fields. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - D'Agostino, D.
AU  - Ilievski, I.
AU  - Shoemaker, C.A.
TI  - Learning active subspaces and discovering important features with Gaussian radial basis functions neural networks
PY  - 2024
T2  - Neural Networks
VL  - 176
C7  - 106335
DO  - 10.1016/j.neunet.2024.106335
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192465924&doi=10.1016%2fj.neunet.2024.106335&partnerID=40&md5=27d9751e8f08780ba71ed63d743f908d
AB  - Providing a model that achieves a strong predictive performance and is simultaneously interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the radial basis function neural network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the prediction task enhancing the model interpretability. We conducted numerical experiments for regression, classification, and feature selection tasks, comparing our model against popular machine learning models, the state-of-the-art deep learning-based embedding feature selection techniques, and a transformer model for tabular data. Our results demonstrate that the proposed model does not only yield an attractive prediction performance compared to the competitors but also provides meaningful and interpretable results that potentially could assist the decision-making process in real-world applications. A PyTorch implementation of the model is available on GitHub at the following link.1 © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, K.
AU  - Li, Q.
AU  - Tian, C.
AU  - Zhang, H.
AU  - Shi, A.
AU  - Li, J.
TI  - DeforT: Deformable transformer for visual tracking
PY  - 2024
T2  - Neural Networks
VL  - 176
C7  - 106380
DO  - 10.1016/j.neunet.2024.106380
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193056612&doi=10.1016%2fj.neunet.2024.106380&partnerID=40&md5=2897f8de1418afabb3fcf319e7a46bc7
AB  - Most trackers formulate visual tracking as common classification and regression (i.e., bounding box regression) tasks. Correlation features that are computed through depth-wise convolution or channel-wise multiplication operations are input into both the classification and regression branches for inference. However, this matching computation with the linear correlation method tends to lose semantic features and obtain only a local optimum. Moreover, these trackers use an unreliable ranking based on the classification score and the intersection over union (IoU) loss for the regression training, thus degrading the tracking performance. In this paper, we introduce a deformable transformer model, which effectively computes the correlation features of the training and search sets. A new loss called the quality-aware focal loss (QAFL) is used to train the classification network; it efficiently alleviates the inconsistency between the classification and localization quality predictions. We use a new regression loss called α-GIoU to train the regression network, and it effectively improves localization accuracy. To further improve the tracker's robustness, the candidate object location is predicted by using a combination of online learning scores with a transformer-assisted framework and classification scores. An extensive experiment on six testing datasets demonstrates the effectiveness of our method. In particular, the proposed method attains a success score of 71.7% on the OTB-2015 dataset and an AUC score of 67.3% on the NFS30 dataset, respectively. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Chen, L.
AU  - Yang, J.
AU  - Shi, T.
AU  - Cheng, L.
AU  - Feng, Z.
AU  - Song, M.
TI  - Life regression based patch slimming for vision transformers
PY  - 2024
T2  - Neural Networks
VL  - 176
C7  - 106340
DO  - 10.1016/j.neunet.2024.106340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192110099&doi=10.1016%2fj.neunet.2024.106340&partnerID=40&md5=60f9653d879fa451cd956b3577c6504b
AB  - Vision transformers have achieved remarkable success in computer vision tasks by using multi-head self-attention modules to capture long-range dependencies within images. However, the high inference computation cost poses a new challenge. Several methods have been proposed to address this problem, mainly by slimming patches. In the inference stage, these methods classify patches into two classes, one to keep and the other to discard in multiple layers. This approach results in additional computation at every layer where patches are discarded, which hinders inference acceleration. In this study, we tackle the patch slimming problem from a different perspective by proposing a life regression module that determines the lifespan of each image patch in one go. During inference, the patch is discarded once the current layer index exceeds its life. Our proposed method avoids additional computation and parameters in multiple layers to enhance inference speed while maintaining competitive performance. Additionally, our approach1 requires fewer training epochs than other patch slimming methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Liu, S.
AU  - Yang, J.
AU  - Jing, H.
AU  - Zhao, W.
AU  - Yang, G.
TI  - A Joint Time-Frequency Domain Transformer for multivariate time series forecasting
PY  - 2024
T2  - Neural Networks
VL  - 176
C7  - 106334
DO  - 10.1016/j.neunet.2024.106334
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191421026&doi=10.1016%2fj.neunet.2024.106334&partnerID=40&md5=7ce5474d56c0a5f7cd1e449d84c490ac
AB  - In order to enhance the performance of Transformer models for long-term multivariate forecasting while minimizing computational demands, this paper introduces the Joint Time-Frequency Domain Transformer (JTFT). JTFT combines time and frequency domain representations to make predictions. The frequency domain representation efficiently extracts multi-scale dependencies while maintaining sparsity by utilizing a small number of learnable frequencies. Simultaneously, the time domain (TD) representation is derived from a fixed number of the most recent data points, strengthening the modeling of local relationships and mitigating the effects of non-stationarity. Importantly, the length of the representation remains independent of the input sequence length, enabling JTFT to achieve linear computational complexity. Furthermore, a low-rank attention layer is proposed to efficiently capture cross-dimensional dependencies, thus preventing performance degradation resulting from the entanglement of temporal and channel-wise modeling. Experimental results on eight real-world datasets demonstrate that JTFT outperforms state-of-the-art baselines in predictive performance. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, J.
AU  - Zhai, J.
TI  - MCNet: Multivariate long-term time series forecasting with local and global context modeling
PY  - 2024
T2  - Information Sciences
VL  - 676
C7  - 120864
DO  - 10.1016/j.ins.2024.120864
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195031425&doi=10.1016%2fj.ins.2024.120864&partnerID=40&md5=4f52ef4ed4ca6022e00f624793070fc9
AB  - Time series data typically exhibit various intra-sequence and inter-sequence correlations, resulting in intricate, intertwined dependencies, which pose challenges for accurately predicting future long-term trends. Previous studies have not fully considered the two correlations, and they also still face challenges of excessive time and memory complexity when dealing with long-term predictions. To address these challenges and establish high-precision prediction models, we propose MCNet that consists of a local branch and a global branch. The local branch aims at capturing short-term variations of intra-sequences, as well as capturing inter-sequence correlations. The global branch models long-term dependencies within sequences. Specifically, the local branch consists only of MLP module, which effectively captures short-term variations of intra-sequences by independently modeling the temporal information within and between patches of the most recent time series. Subsequently, inter-sequence dependencies are captured through the channel interaction module, which further explores more key information to improve the performance of MCNet. Meanwhile, global branch models long-term dependencies within the time series through structured global convolution. Experimental results on multiple popular long-term time series forecasting benchmarks demonstrate that MCNet outperforms state-of-the-art methods, yielding a relative improvement of 12% for multivariate time series while also being more efficient. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Sun2024MCNet
ER  -

TY  - JOUR
AU  - Mena, G.
AU  - Coussement, K.
AU  - De Bock, K.W.
AU  - De Caigny, A.
AU  - Lessmann, S.
TI  - Exploiting time-varying RFM measures for customer churn prediction with deep neural networks
PY  - 2024
T2  - Annals of Operations Research
VL  - 339
IS  - 1-2
SP  - 765
EP  - 787
DO  - 10.1007/s10479-023-05259-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150436491&doi=10.1007%2fs10479-023-05259-9&partnerID=40&md5=9d2ff25f3729b6123263555a3e266049
AB  - Deep neural network (DNN) architectures such as recurrent neural networks and transformers display outstanding performance in modeling sequential unstructured data. However, little is known about their merit to model customer churn with time-varying data. The paper provides a comprehensive evaluation of the ability of recurrent neural networks and transformers for customer churn prediction (CCP) using time-varying behavioral features in the form of recency, frequency, and monetary value (RFM). RFM variables are the backbone of CCP and, more generally, customer behavior forecasting. We examine alternative strategies for integrating time-varying and non-variant customer features in one network architecture. In this scope, we also assess hybrid approaches that incorporate the outputs of DNNs in conventional CCP models. Using a comprehensive panel data set from a large financial services company, we find recurrent neural networks to outperform transformer architectures when focusing on time-varying RFM features. This finding is confirmed when time-invariant customer features are included, independent of the specific form of feature integration. Finally, we find no statistical evidence that hybrid approaches (based on regularized logistic regression and extreme gradient boosting) improve predictive performance—highlighting that DNNs and especially recurrent neural networks are suitable standalone classifiers for CCP using time-varying RFM measures. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Mena2024Exploiting
ER  -

TY  - JOUR
AU  - Gao, J.-J.
AU  - Dong, Q.-J.
AU  - Wang, R.-A.
AU  - Chen, S.-M.
AU  - Xin, S.-Q.
AU  - Tu, C.-H.
AU  - Wang, W.
TI  - OAAFormer: Robust and Efficient Point Cloud Registration Through Overlapping-Aware Attention in Transformer
PY  - 2024
T2  - Journal of Computer Science and Technology
VL  - 39
IS  - 4
SP  - 755
EP  - 770
DO  - 10.1007/s11390-024-4165-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204801180&doi=10.1007%2fs11390-024-4165-6&partnerID=40&md5=2fb8ecd730dd4390882aaa6a5c8b6b86
AB  - In the domain of point cloud registration, the coarse-to-fine feature matching paradigm has received significant attention due to its impressive performance. This paradigm involves a two-step process: first, the extraction of multilevel features, and subsequently, the propagation of correspondences from coarse to fine levels. However, this approach faces two notable limitations. Firstly, the use of the Dual Softmax operation may promote one-to-one correspondences between superpoints, inadvertently excluding valuable correspondences. Secondly, it is crucial to closely examine the overlapping areas between point clouds, as only correspondences within these regions decisively determine the actual transformation. Considering these issues, we propose OAAFormer to enhance correspondence quality. On the one hand, we introduce a soft matching mechanism to facilitate the propagation of potentially valuable correspondences from coarse to fine levels. On the other hand, we integrate an overlapping region detection module to minimize mismatches to the greatest extent possible. Furthermore, we introduce a region-wise attention module with linear complexity during the fine-level matching phase, designed to enhance the discriminative capabilities of the extracted features. Tests on the challenging 3DLoMatch benchmark demonstrate that our approach leads to a substantial increase of about 7% in the inlier ratio, as well as an enhancement of 2%–4% in registration recall. Finally, to accelerate the prediction process, we replace the Conventional Random Sample Consensus (RANSAC) algorithm with the selection of a limited yet representative set of high-confidence correspondences, resulting in a 100 times speedup while still maintaining comparable registration performance. © Institute of Computing Technology, Chinese Academy of Sciences 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, T.
AU  - Song, L.
AU  - Cui, L.
AU  - Wang, H.
TI  - Advancing RUL prediction in mechanical systems: A hybrid deep learning approach utilizing non-full lifecycle data
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 61
C7  - 102524
DO  - 10.1016/j.aei.2024.102524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189747978&doi=10.1016%2fj.aei.2024.102524&partnerID=40&md5=b9c2b0ff63d03d4842b30f76dd071696
AB  - This paper addresses the significant challenge of predicting the Remaining Useful Life (RUL) of mechanical equipment, a critical aspect of predictive maintenance and reliability engineering. Traditional deep learning methods in RUL prediction have been hindered by key challenges, including the scarcity of comprehensive lifecycle data, the prevalence of high-frequency noise in sensor readings, and a heavy reliance on supervised learning. To overcome these challenges, we propose a novel methodology that synergizes self-supervised and supervised learning. Our approach uniquely leverages non-full lifecycle data abundant in industrial settings, thereby bypassing the limitations posed by data scarcity. The model undergoes a two-stage training process, initially learning from vast quantities of non-full lifecycle data in a self-supervised manner, followed by fine-tuning in a supervised phase with available full lifecycle data. We employ Contrastive Predictive Coding (CPC) for the encoder and a Transformer-based decoder, a combination adept at extracting low-frequency, significant features from the sensor data and effectively predicting RUL. The paper demonstrates the efficacy of our approach through comprehensive experiments testing on both bearing datasets from experimental setup and wheelset datasets from urban rail train, showing superior or comparable performance against state-of-the-art methods. Our results, supported by ablation studies, suggest the potential robustness and innovative aspects of our model, indicating it could contribute meaningfully to the field of predictive maintenance. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, X.
AU  - Lin, X.
AU  - Yang, X.
AU  - Yu, L.
AU  - Cheng, K.-T.
AU  - Yan, Z.
TI  - UCTNet: Uncertainty-guided CNN-Transformer hybrid networks for medical image segmentation
PY  - 2024
T2  - Pattern Recognition
VL  - 152
C7  - 110491
DO  - 10.1016/j.patcog.2024.110491
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190300695&doi=10.1016%2fj.patcog.2024.110491&partnerID=40&md5=bbceffe383b14800b0a1e9aede3b0ed5
AB  - Transformer, born for long-range dependency establishment, has been widely studied as a complementary of convolutional neural networks (CNNs) in medical image segmentation. However, existing CNN-Transformer hybrid approaches simply pursue implicit feature fusion without considering their underlying functional overlap. Medical images typically follow stable anatomical structures, making convolution capable of handling most segmentation targets. Without differentiation, enforcing transformers to operate self-attention for all image patches would result in severe redundancy, hindering global feature extraction. In this paper, we propose a simple yet effective hybrid network named UCTNet where transformers only focus on establishing global dependency for CNN's unreliable regions predicted through uncertainty estimation. In this way, CNN and transformer are explicitly fused to minimize functional overlap. More importantly, with fewer regions to handle, UCTNet is of better convergence to learn more robust feature representations for hard examples. Extensive experiments on publicly-available datasets demonstrate the superiority of UCTNet against the state-of-the-art approaches, achieving 89.44%, 92.91%, and 91.15% in Dice similarity coefficient on Synapse, ACDC, and ISIC2018 respectively. Furthermore, such a CNN-Transformer hybrid strategy is highly extendable to other frameworks without introducing additional computational burdens. Code is available at https://github.com/innocence0206/UCTNet. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Dai, J.
AU  - Bai, J.
AU  - Pan, J.
TI  - DGFormer: Dynamic graph transformer for 3D human pose estimation
PY  - 2024
T2  - Pattern Recognition
VL  - 152
C7  - 110446
DO  - 10.1016/j.patcog.2024.110446
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188841912&doi=10.1016%2fj.patcog.2024.110446&partnerID=40&md5=1fea47928fa0369dc64fbd13bd02914b
AB  - Despite the significant progress for monocular 3D human pose estimation, it still faces challenges due to self-occlusions and depth ambiguities. To tackle those issues, we propose a novel Dynamic Graph Transformer (DGFormer) to exploit local and global relationships between skeleton joints for pose estimation. Specifically, the proposed DGFormer mainly consists of three core modules: Transformer Encoder (TE), immobile Graph Convolutional Network (GCN), and dynamic GCN. TE module leverages the self-attention mechanism to learn the complex global relationships among skeleton joints. The immobile GCN is responsible for capturing the local physical connections between human joints, while the dynamic GCN concentrates on learning the sparse dynamic K-nearest neighbor interactions according to different action poses. By building the adequately global long-range, local physical, and sparse dynamic dependencies of human joints, experiments on Human3.6M and MPI-INF-3DHP datasets demonstrate that our method can predict 3D pose with lower errors outperforming the recent state-of-the-art image-based performance. Furthermore, experiments on in-the-wild videos demonstrate the impressive generalization abilities of our method. Code will be available at: https://github.com/czmmmm/DGFormer. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, G.P.
AU  - Xia, Y.
AU  - Xie, M.
TI  - Intermittent demand forecasting with transformer neural networks
PY  - 2024
T2  - Annals of Operations Research
VL  - 339
IS  - 1-2
SP  - 1051
EP  - 1072
DO  - 10.1007/s10479-023-05447-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162732740&doi=10.1007%2fs10479-023-05447-7&partnerID=40&md5=901011c95349939dc6fbb5ce1fb51a0c
AB  - Intermittent demand forecasting is an important yet challenging task in many organizations. While prior research has been focused on traditional methods such as Croston’s method and its variants, limited research has been conducted using advanced machine learning or deep learning methods. In this study, we introduce Transformer, a recently developed deep learning approach, to forecast intermittent demand. Its effectiveness is empirically tested with a dataset of 925 intermittent demand items from an airline spare parts provider and compared with that of two traditional methods such as Croston’s and the Syntetos–Boylan approximation as well as several popular neural network architectures including feedforward neural networks, recurrent neural networks, and long short-term memory. Our results based on six different forecasting performance measures show that Transformer performs very well against other methods in a variety of settings. We also examine how data sparsity impacts model performance and find that different models perform similarly when sparsity is low. Although the performance of all models generally gets worse as the sparsity level increases, the advantage of Transformer over other models increases with sparsity. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Zhang2024Intermittent
ER  -

TY  - JOUR
AU  - Dong, H.
AU  - Qi, H.
AU  - Zhou, H.
AU  - Dong, J.
AU  - Dong, X.
TI  - WRD-Net: Water Reflection Detection using a parallel attention transformer
PY  - 2024
T2  - Pattern Recognition
VL  - 152
C7  - 110467
DO  - 10.1016/j.patcog.2024.110467
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189748052&doi=10.1016%2fj.patcog.2024.110467&partnerID=40&md5=5821f2efff8b717f59e00680a8eb33b3
AB  - In contrast to symmetry detection, Water Reflection Detection (WRD) is less studied. We treat this topic as a Symmetry Axis Point Prediction task which outputs a set of points by implicitly learning Gaussian heat maps and explicitly learning numerical coordinates. We first collect a new data set, namely, the Water Reflection Scene Data Set (WRSD). Then, we introduce a novel Water Reflection Detection Network, i.e., WRD-Net. This network is built on top of a series of Parallel Attention Vision Transformer blocks with the Atrous Spatial Pyramid (ASP-PAViT) that we deliberately design. Each block captures both the local and global features at multiple scales. To our knowledge, neither the WRSD nor the WRD-Net has been used for water reflection detection before. To derive the axis of symmetry, we perform Principal Component Analysis (PCA) on the points predicted. Experimental results show that the WRD-Net outperforms its counterparts and achieves the true positive rate of 0.823 compared with the human annotation. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Jiang, T.
AU  - Liu, H.
AU  - Sun, Y.
AU  - Lv, C.
AU  - Li, Q.
AU  - Yin, G.
AU  - Liu, Y.
TI  - Lane changing maneuver prediction by using driver's spatio-temporal gaze attention inputs for naturalistic driving
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 61
C7  - 102529
DO  - 10.1016/j.aei.2024.102529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190343128&doi=10.1016%2fj.aei.2024.102529&partnerID=40&md5=47c576bc7d17f94fc0946e0481f590a5
AB  - Driver's lane changing maneuver prediction holds significant importance in enhancing the functionality of the Advanced Driver Assistance System (ADAS) and ensuring driving safety. This study introduces an innovative approach to model the driver's spatio-temporal gaze attention to the traffic environment, and realizes high-precision lane changing prediction by integrating multi-source inputs. Firstly, a naturalistic driving dataset containing information of the ego vehicle, the traffic environment, and the driver's eye movements is created based on the real-vehicle apparatus. Secondly, the driver's gaze attention to the traffic environment is creatively modeled by introducing a gaze cone and quantified by using spatio-temporal indexes. Concurrently, vehicle dynamic inputs and traffic environmental inputs including the information of surrounding vehicles and the lane are also constructed. Thirdly, a Transformer Encoder model, containing the multi-head attention mechanism, is established to extract the information from input sequences for maneuver prediction. Performance comparison is carried out using various historical horizons, input combinations, and prediction horizons. The model shows an enhanced prediction performance after adding gaze attention inputs, with the accuracy, precision, recall, F1-score, and Area Under Curve (AUC) being 0.945, 0.937, 0.931, 0.934, and 0.986, respectively. In addition, as the prediction horizon extends from 1 s to 3 s, the model utilizing multi-source inputs consistently demonstrates the highest accuracy and minimal performance decline, exhibiting stable predictive capabilities. In future application, the proposed driver's gaze attention model can serve to alert drivers about unobserved objects, and the maneuver prediction method shows promise for the integration into lane change assistance systems. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bao, H.-W.-S.
TI  - The Fill-Mask Association Test (FMAT): Measuring Propositions in Natural Language
PY  - 2024
T2  - Journal of Personality and Social Psychology
VL  - 127
IS  - 3
SP  - 537
EP  - 561
DO  - 10.1037/pspa0000396
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191325590&doi=10.1037%2fpspa0000396&partnerID=40&md5=eaeb7f726d2c3f0675090162ce267b23
AB  - Recent advances in large language models are enabling the computational intelligent analysis of psychology in natural language. Here, the Fill-Mask Association Test (FMAT) is introduced as a novel and integrative method leveraging Masked Language Models to study and measure psychology from a propositional perspective at the societal level. The FMAT uses Bidirectional Encoder Representations from Transformers (BERT) models to compute semantic probabilities of option words filling in the masked blank of a designed query (i.e., a clozelike contextualized sentence). The current research presents 15 studies that establish the reliability and validity of the FMAT in predicting factual associations (Studies 1A–1C), measuring attitudes/ biases (Studies 2A–2D), capturing social stereotypes (Studies 3A–3D), and retrospectively delineating lay perceptions of sociocultural changes over time (Studies 4A–4D). Empirically, the FMAT replicated seminal findings previously obtained with human participants (e.g., the Implicit Association Test) and other big-data text-analytic methods (e.g., word frequency analysis, the Word Embedding Association Test), demonstrating robustness across 12 BERT model variants and diverse training text corpora. Theoretically, the current findings substantiate the propositional (vs. associative) perspective on how semantic associations are represented in natural language. Methodologically, the FMAT allows for more fine-grained language-based psychological measurement, with an R package developed to streamline its workflow for use on broader research questions. © 2024 American Psychological Association
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:4; ZUFE:1A; zdy:4; 
LB  - Bao2024Fill-Mask
ER  -

TY  - JOUR
AU  - Paeedeh, N.
AU  - Pratama, M.
AU  - Wibirama, S.
AU  - Mayer, W.
AU  - Cao, Z.
AU  - Kowalczyk, R.
TI  - Few-shot class incremental learning via robust transformer approach
PY  - 2024
T2  - Information Sciences
VL  - 675
C7  - 120751
DO  - 10.1016/j.ins.2024.120751
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193934831&doi=10.1016%2fj.ins.2024.120751&partnerID=40&md5=80eb993f004590655574aa86322be9b7
AB  - Few-Shot Class-Incremental Learning (FSCIL)presents an extension of the Class Incremental Learning (CIL)problem where a model is faced with the problem of data scarcity while addressing the Catastrophic Forgetting (CF)problem. This problem remains an open problem because all recent works are built upon the Convolutional Neural Networks (CNNs)performing sub-optimally compared to the transformer approaches. Our paper presents Robust Transformer Approach (ROBUSTA)built upon the Compact Convolutional Transformer (CCT). The issue of overfitting due to few samples is overcome with the notion of the stochastic classifier, where the classifier's weights are sampled from a distribution with mean and variance vectors, thus increasing the likelihood of correct classifications, and the batch-norm layer to stabilize the training process. The issue of CFis dealt with the idea of delta parameters, small task-specific trainable parameters while keeping the backbone networks frozen. A non-parametric approach is developed to infer the delta parameters for the model's predictions. The prototype rectification approach is applied to avoid biased prototype calculations due to the issue of data scarcity. The advantage of ROBUSTAis demonstrated through a series of experiments in the benchmark problems where it is capable of outperforming prior arts with big margins without any data augmentation protocols. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Paeedeh2024Few-shot
ER  -

TY  - JOUR
AU  - Xiang, W.
AU  - Zhong, F.
AU  - Ni, L.
AU  - Zheng, M.
AU  - Li, X.
AU  - Shi, Q.
AU  - Wang, D.
TI  - Gram matrix: an efficient representation of molecular conformation and learning objective for molecular pretraining
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 4
C7  - bbae340
DO  - 10.1093/bib/bbae340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198466653&doi=10.1093%2fbib%2fbbae340&partnerID=40&md5=796cc5028466a2939243c279f8c47ea4
AB  - Accurate prediction of molecular properties is fundamental in drug discovery and development, providing crucial guidance for effective drug design. A critical factor in achieving accurate molecular property prediction lies in the appropriate representation of molecular structures. Presently, prevalent deep learning–based molecular representations rely on 2D structure information as the primary molecular representation, often overlooking essential three-dimensional (3D) conformational information due to the inherent limitations of 2D structures in conveying atomic spatial relationships. In this study, we propose employing the Gram matrix as a condensed representation of 3D molecular structures and for efficient pretraining objectives. Subsequently, we leverage this matrix to construct a novel molecular representation model, Pre-GTM, which inherently encapsulates 3D information. The model accurately predicts the 3D structure of a molecule by estimating the Gram matrix. Our findings demonstrate that Pre-GTM model outperforms the baseline Graphormer model and other pretrained models in the QM9 and MoleculeNet quantitative property prediction task. The integration of the Gram matrix as a condensed representation of 3D molecular structure, incorporated into the Pre-GTM model, opens up promising avenues for its potential application across various domains of molecular research, including drug design, materials science, and chemical engineering. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yuan, J.
AU  - Zhang, F.
AU  - Qiu, Y.
AU  - Lin, H.
AU  - Zhang, Y.
TI  - Document-level biomedical relation extraction via hierarchical tree graph and relation segmentation module
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 7
C7  - btae418
DO  - 10.1093/bioinformatics/btae418
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197973826&doi=10.1093%2fbioinformatics%2fbtae418&partnerID=40&md5=40ee3658786dbac4862b571dee678a5a
AB  - Motivation: Biomedical relation extraction at the document level (Bio-DocRE) involves extracting relation instances from biomedical texts that span multiple sentences, often containing various entity concepts such as genes, diseases, chemicals, variants, etc. Currently, this task is usually implemented based on graphs or transformers. However, most work directly models entity features to relation prediction, ignoring the effectiveness of entity pair information as an intermediate state for relation prediction. In this article, we decouple this task into a three-stage process to capture sufficient information for improving relation prediction. Results: We propose an innovative framework HTGRS for Bio-DocRE, which constructs a hierarchical tree graph (HTG) to integrate key information sources in the document, achieving relation reasoning based on entity. In addition, inspired by the idea of semantic segmentation, we conceptualize the task as a table-filling problem and develop a relation segmentation (RS) module to enhance relation reasoning based on the entity pair. Extensive experiments on three datasets show that the proposed framework outperforms the state-of-the-art methods and achieves superior performance. Availability and implementation: Our source code is available at https://github.com/passengeryjy/HTGRS. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Fang, Y.
AU  - Luo, M.
AU  - Ren, Z.
AU  - Wei, L.
AU  - Wei, D.-Q.
TI  - CELA-MFP: a contrast-enhanced and label-adaptive framework for multi-functional therapeutic peptides prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 4
C7  - bbae348
DO  - 10.1093/bib/bbae348
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199393249&doi=10.1093%2fbib%2fbbae348&partnerID=40&md5=6a28998032c30d4e7448d4dccd1adeea
AB  - Functional peptides play crucial roles in various biological processes and hold significant potential in many fields such as drug discovery and biotechnology. Accurately predicting the functions of peptides is essential for understanding their diverse effects and designing peptide-based therapeutics. Here, we propose CELA-MFP, a deep learning framework that incorporates feature Contrastive Enhancement and Label Adaptation for predicting Multi-Functional therapeutic Peptides. CELA-MFP utilizes a protein language model (pLM) to extract features from peptide sequences, which are then fed into a Transformer decoder for function prediction, effectively modeling correlations between different functions. To enhance the representation of each peptide sequence, contrastive learning is employed during training. Experimental results demonstrate that CELA-MFP outperforms state-of-the-art methods on most evaluation metrics for two widely used datasets, MFBP and MFTP. The interpretability of CELA-MFP is demonstrated by visualizing attention patterns in pLM and Transformer decoder. Finally, a user-friendly online server for predicting multi-functional peptides is established as the implementation of the proposed CELA-MFP and can be freely accessed at http: //dreamai.cmii.online/CELA-MFP.  © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mall, R.
AU  - Singh, A.
AU  - Patel, C.N.
AU  - Guirimand, G.
AU  - Castiglione, F.
TI  - VISH-Pred: an ensemble of fine-tuned ESM models for protein toxicity prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 4
C7  - bbae270
DO  - 10.1093/bib/bbae270
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195340624&doi=10.1093%2fbib%2fbbae270&partnerID=40&md5=4012e3c704e186d7b78b42927783b8ee
AB  - Peptide- and protein-based therapeutics are becoming a promising treatment regimen for myriad diseases. Toxicity of proteins is the primary hurdle for protein-based therapies. Thus, there is an urgent need for accurate in silico methods for determining toxic proteins to filter the pool of potential candidates. At the same time, it is imperative to precisely identify non-toxic proteins to expand the possibilities for protein-based biologics. To address this challenge, we proposed an ensemble framework, called VISH-Pred, comprising models built by fine-tuning ESM2 transformer models on a large, experimentally validated, curated dataset of protein and peptide toxicities. The primary steps in the VISH-Pred framework are to efficiently estimate protein toxicities taking just the protein sequence as input, employing an under sampling technique to handle the humongous class-imbalance in the data and learning representations from fine-tuned ESM2 protein language models which are then fed to machine learning techniques such as Lightgbm and XGBoost. The VISH-Pred framework is able to correctly identify both peptides/proteins with potential toxicity and non-toxic proteins, achieving a Matthews correlation coefficient of 0.737, 0.716 and 0.322 and F1-score of 0.759, 0.696 and 0.713 on three non-redundant blind tests, respectively, outperforming other methods by over on these quality metrics. Moreover, VISH-Pred achieved the best accuracy and area under receiver operating curve scores on these independent test sets, highlighting the robustness and generalization capability of the framework. By making VISH-Pred available as an easy-to-use web server, we expect it to serve as a valuable asset for future endeavors aimed at discerning the toxicity of peptides and enabling efficient protein-based therapeutics.  © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Xu, Y.
AU  - Law, R.
AU  - Wang, S.
TI  - Enhancing tourism demand forecasting with a transformer-based framework
PY  - 2024
T2  - Annals of Tourism Research
VL  - 107
C7  - 103791
DO  - 10.1016/j.annals.2024.103791
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194049607&doi=10.1016%2fj.annals.2024.103791&partnerID=40&md5=47e181c735e846b4769df9ada547c475
AB  - This study introduces an innovative framework that harnesses the most recent transformer architecture to enhance tourism demand forecasting. The proposed transformer-based model integrates the tree-structured parzen estimator for hyperparameter optimization, a robust time series decomposition approach, and a temporal fusion transformer for multivariate time series prediction. Our novel approach initially employs the decomposition method to decompose the data series to effectively mitigate the influence of outliers. The temporal fusion transformer is subsequently utilized for forecasting, and its hyperparameters are meticulously fine-tuned by a Bayesian-based algorithm, culminating in a more efficient and precise model for tourism demand forecasting. Our model surpasses existing state-of-the-art methodologies in terms of forecasting accuracy and robustness. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Li2024Enhancing
ER  -

TY  - JOUR
AU  - Kim, M.
AU  - Kang, D.
AU  - Kim, M.S.
AU  - Choe, J.C.
AU  - Lee, S.-H.
AU  - Ahn, J.H.
AU  - Oh, J.-H.
AU  - Choi, J.H.
AU  - Lee, H.C.
AU  - Cha, K.S.
AU  - Jang, K.
AU  - Bong, W.
AU  - Song, G.
AU  - Lee, H.
TI  - Acute myocardial infarction prognosis prediction with reliable and interpretable artificial intelligence system
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 7
SP  - 1540
EP  - 1550
DO  - 10.1093/jamia/ocae114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196626278&doi=10.1093%2fjamia%2focae114&partnerID=40&md5=fefa8cb4af26e67946c94e744e16b46b
AB  - Objective: Predicting mortality after acute myocardial infarction (AMI) is crucial for timely prescription and treatment of AMI patients, but there are no appropriate AI systems for clinicians. Our primary goal is to develop a reliable and interpretable AI system and provide some valuable insights regarding short, and long-term mortality. Materials and methods: We propose the RIAS framework, an end-to-end framework that is designed with reliability and interpretability at its core and automatically optimizes the given model. Using RIAS, clinicians get accurate and reliable predictions which can be used as likelihood, with global and local explanations, and “what if” scenarios to achieve desired outcomes as well. Results: We apply RIAS to AMI prognosis prediction data which comes from the Korean Acute Myocardial Infarction Registry. We compared FT-Transformer with XGBoost and MLP and found that FT-Transformer has superiority in sensitivity and comparable performance in AUROC and F1 score to XGBoost. Furthermore, RIAS reveals the significance of statin-based medications, beta-blockers, and age on mortality regardless of time period. Lastly, we showcase reliable and interpretable results of RIAS with local explanations and counterfactual examples for several realistic scenarios. Discussion: RIAS addresses the “black-box” issue in AI by providing both global and local explanations based on SHAP values and reliable predictions, interpretable as actual likelihoods. The system’s “what if” counterfactual explanations enable clinicians to simulate patient-specific scenarios under various conditions, enhancing its practical utility. Conclusion: The proposed framework provides reliable and interpretable predictions along with counterfactual examples. © The Author(s) 2024. Published by Oxford University Press on behalf of the American Medical Informatics Association.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Tang, X.
AU  - Tran, A.
AU  - Tan, J.
AU  - Gerstein, M.B.
TI  - MolLM: a unified language model for integrating biomedical text with 2D and 3D molecular representations
PY  - 2024
T2  - Bioinformatics
VL  - 40
SP  - i357
EP  - i368
DO  - 10.1093/bioinformatics/btae260
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197155314&doi=10.1093%2fbioinformatics%2fbtae260&partnerID=40&md5=a51c04a545c0a39083bcdf1ec89c4011
AB  - Motivation: The current paradigm of deep learning models for the joint representation of molecules and text primarily relies on 1D or 2D molecular formats, neglecting significant 3D structural information that offers valuable physical insight. This narrow focus inhibits the models’ versatility and adaptability across a wide range of modalities. Conversely, the limited research focusing on explicit 3D representation tends to overlook textual data within the biomedical domain. Results: We present a unified pre-trained language model, MolLM, that concurrently captures 2D and 3D molecular information alongside biomedical text. MolLM consists of a text Transformer encoder and a molecular Transformer encoder, designed to encode both 2D and 3D molecular structures. To support MolLM’s self-supervised pre-training, we constructed 160K molecule-text pairings. Employing contrastive learning as a supervisory signal for learning, MolLM demonstrates robust molecular representation capabilities across four downstream tasks, including cross-modal molecule and text matching, property prediction, captioning, and text-prompted molecular editing. Through ablation, we demonstrate that the inclusion of explicit 3D representations improves performance in these downstream tasks. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wu, X.
AU  - Laufer, E.
AU  - Li, H.
AU  - Khomh, F.
AU  - Srinivasan, S.
AU  - Luo, J.
TI  - Characterizing and classifying developer forum posts with their intentions
PY  - 2024
T2  - Empirical Software Engineering
VL  - 29
IS  - 4
C7  - 84
DO  - 10.1007/s10664-024-10487-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195514449&doi=10.1007%2fs10664-024-10487-z&partnerID=40&md5=100742bc5a47959454da23bb1c86f895
AB  - With the rapid growth of the developer community, the amount of posts on online technical forums has been growing rapidly, which poses difficulties for users to filter useful posts and find important information. Tags provide a concise feature dimension for users to locate their interested posts and for search engines to index the most relevant posts according to the queries. Most tags are only focused on the technical perspective (e.g., program language, platform, tool). In most cases, forum posts in online developer communities reveal the author’s intentions to solve a problem, ask for advice, share information, etc. The modeling of the intentions of posts can provide an extra dimension to the current tag taxonomy. By referencing previous studies and learning from industrial perspectives, we create a refined taxonomy for the intentions of technical forum posts. Through manual labeling and analysis on a sampled post dataset extracted from online forums, we understand the relevance between the constitution of posts (code, error messages) and their intentions. Furthermore, inspired by our manual study, we design a pre-trained transformer-based model to automatically predict post intentions. The best variant of our intention prediction framework, which achieves a Micro F1-score of 0.589, Top 1-3 accuracy of 62.6% to 87.8%, and an average AUC of 0.787, outperforms the state-of-the-art baseline approach. Our characterization and automated classification of forum posts regarding their intentions may help forum maintainers or third-party tool developers improve the organization and retrieval of posts on technical forums. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cuturello, F.
AU  - Celoria, M.
AU  - Ansuini, A.
AU  - Cazzaniga, A.
TI  - Enhancing predictions of protein stability changes induced by single mutations using MSA-based language models
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 7
C7  - btae447
DO  - 10.1093/bioinformatics/btae447
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199525306&doi=10.1093%2fbioinformatics%2fbtae447&partnerID=40&md5=18892aa51b7d35abb3cc2aabde389431
AB  - Motivation: Protein language models offer a new perspective for addressing challenges in structural biology, while relying solely on sequence information. Recent studies have investigated their effectiveness in forecasting shifts in thermodynamic stability caused by single amino acid mutations, a task known for its complexity due to the sparse availability of data, constrained by experimental limitations. To tackle this problem, we introduce two key novelties: leveraging a protein language model that incorporates Multiple Sequence Alignments to capture evolutionary information, and using a recently released mega-scale dataset with rigorous data preprocessing to mitigate overfitting. Results: We ensure comprehensive comparisons by fine-tuning various pretrained models, taking advantage of analyses such as ablation studies and baselines evaluation. Our methodology introduces a stringent policy to reduce the widespread issue of data leakage, rigorously removing sequences from the training set when they exhibit significant similarity with the test set. The MSA Transformer emerges as the most accurate among the models under investigation, given its capability to leverage co-evolution signals encoded in aligned homologous sequences. Moreover, the optimized MSA Transformer outperforms existing methods and exhibits enhanced generalization power, leading to a notable improvement in predicting changes in protein stability resulting from point mutations. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - da Silva, A.J.A.
AU  - Vieira, R.G.
AU  - Mesquita, D.P.P.
AU  - Gomes, J.P.P.
AU  - Rocha, L.S.
TI  - Towards automatic labeling of exception handling bugs: A case study of 10 years bug-fixing in Apache Hadoop
PY  - 2024
T2  - Empirical Software Engineering
VL  - 29
IS  - 4
C7  - 85
DO  - 10.1007/s10664-024-10494-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195456940&doi=10.1007%2fs10664-024-10494-0&partnerID=40&md5=c3f87d487651926d7c76aeb30e6d4a80
AB  - Context: Exception handling (EH) bugs stem from incorrect usage of exception handling mechanisms (EHMs) and often incur severe consequences (e.g., system downtime, data loss, and security risk). Tracking EH bugs is particularly relevant for contemporary systems (e.g., cloud- and AI-based systems), in which the software’s sophisticated logic is an additional threat to the correct use of the EHM. On top of that, bug reporters seldom can tag EH bugs — since it may require an encompassing knowledge of the software’s EH strategy. Surprisingly, to the best of our knowledge, there is no automated procedure to identify EH bugs from report descriptions. Objective: First, we aim to evaluate the extent to which Natural Language Processing (NLP) and Machine Learning (ML) can be used to reliably label EH bugs using the text fields from bug reports (e.g., summary, description, and comments). Second, we aim to provide a reliably labeled dataset that the community can use in future endeavors. Overall, we expect our work to raise the community’s awareness regarding the importance of EH bugs. Method: We manually analyzed 4,516 bug reports from the four main components of Apache’s Hadoop project, out of which we labeled ≈20% (943) as EH bugs. We also labeled 2,584 non-EH bugs analyzing their bug-fixing code and creating a dataset composed of 7,100 bug reports. Then, we used word embedding techniques (Bag-of-Words and TF-IDF) to summarize the textual fields of bug reports. Subsequently, we used these embeddings to fit five classes of ML methods and evaluate them on unseen data. We also evaluated a pre-trained transformer-based model using the complete textual fields. We have also evaluated whether considering only EH keywords is enough to achieve high predictive performance. Results: Our results show that using a pre-trained DistilBERT with a linear layer trained with our proposed dataset can reasonably label EH bugs, achieving ROC-AUC scores of up to 0.88. The combination of NLP and ML traditional techniques achieved ROC-AUC scores of up to 0.74 and recall up to 0.56. As a sanity check, we also evaluate methods using embeddings extracted solely from keywords. Considering ROC-AUC as the primary concern, for the majority of ML methods tested, the analysis suggests that keywords alone are not sufficient to characterize reports of EH bugs, although this can change based on other metrics (such as recall and precision) or ML methods (e.g., Random Forest). Conclusions: To the best of our knowledge, this is the first study addressing the problem of automatic labeling of EH bugs. Based on our results, we can conclude that the use of ML techniques, specially transformer-base models, sounds promising to automate the task of labeling EH bugs. Overall, we hope (i) that our work will contribute towards raising awareness around EH bugs; and (ii) that our (publicly available) dataset will serve as a benchmarking dataset, paving the way for follow-up works. Additionally, our findings can be used to build tools that help maintainers flesh out EH bugs during the triage process. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cassee, N.
AU  - Agaronian, A.
AU  - Constantinou, E.
AU  - Novielli, N.
AU  - Serebrenik, A.
TI  - Transformers and meta-tokenization in sentiment analysis for software engineering
PY  - 2024
T2  - Empirical Software Engineering
VL  - 29
IS  - 4
C7  - 77
DO  - 10.1007/s10664-024-10468-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195391187&doi=10.1007%2fs10664-024-10468-2&partnerID=40&md5=4662df39d13912d1836a892a58f906eb
AB  - Sentiment analysis has been used to study aspects of software engineering, such as issue resolution, toxicity, and self-admitted technical debt. To address the peculiarities of software engineering texts, sentiment analysis tools often consider the specific technical lingo practitioners use. To further improve the application of sentiment analysis, there have been two recommendations: Using pre-trained transformer models to classify sentiment and replacing non-natural language elements with meta-tokens. In this work, we benchmark five different sentiment analysis tools (two pre-trained transformer models and three machine learning tools) on 2 gold-standard sentiment analysis datasets. We find that pre-trained transformers outperform the best machine learning tool on only one of the two datasets, and that even on that dataset the performance difference is a few percentage points. Therefore, we recommend that software engineering researchers should not just consider predictive performance when selecting a sentiment analysis tool because the best-performing sentiment analysis tools perform very similarly to each other (within 4 percentage points). Meanwhile, we find that meta-tokenization does not improve the predictive performance of sentiment analysis tools. Both of our findings can be used by software engineering researchers who seek to apply sentiment analysis tools to software engineering data. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Song, T.
AU  - Garza, P.
AU  - Meo, M.
AU  - Munafò, M.M.
TI  - DeX: Deep learning-based throughput prediction for real-time communications with emphasis on traffic eXtremes
PY  - 2024
T2  - Computer Networks
VL  - 249
C7  - 110507
DO  - 10.1016/j.comnet.2024.110507
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193901444&doi=10.1016%2fj.comnet.2024.110507&partnerID=40&md5=3f28fcb6cf8ba18b4cbca00e0ba0dadb
AB  - Recent years have witnessed a remarkable upsurge in the global proliferation of Real-Time Communications (RTC) applications, a trend propelled by the flourishing advancement of network technologies and further amplified by the COVID-19 pandemic. Within this context, there is a burgeoning interest in the innovation of sophisticated and intelligent network infrastructures and technologies. Positioned as a promising candidate for this purpose, real-time throughput prediction emerges as a key enabler to foster network observability and offer proactive functions, upholding advanced system management, including but not limited to, bandwidth allocation and adaptive streaming. Nonetheless, existing methodologies struggle with predicting extreme conditions of throughput, notably peaks, valleys, and abrupt changes, that are critical in RTC traffic. To surmount these obstacles, we introduce DeX, a Deep Learning (DL)-based framework, designed to predict short-term throughput, with a dexterous proficiency and dedicated focus on navigating the complexities of traffic eXtremes. In particular, DeX leverages solely packet-level information as features and is composed of three integral components: a packet selection module that opts for an optimal subset of input features, a feature extraction block that partially incorporates the Transformer architecture, and a multi-task learning pipeline that improves the proficiency in handling traffic extremes. Moreover, our work is anchored in extensive traffic traces garnered during actual video-teleconferencing calls, and we formulate a time-series regression problem, rigorously evaluating a spectrum of technologies ranging from an adaptive filter to diverse Machine Learning (ML) and DL approaches. Initially, we aim at predicting throughput within 500-ms time windows using historical 1024 packets out of 2048, and consequently, our methodology exhibits exceptional efficacy, especially in forecasting traffic extremities. Conclusively, we conduct a series of ablation experiments and thorough analyses to showcase the enhanced performance of various scenarios, further validating the effectiveness and robustness of DeX. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Beaney, T.
AU  - Jha, S.
AU  - Alaa, A.
AU  - Smith, A.
AU  - Clarke, J.
AU  - Woodcock, T.
AU  - Majeed, A.
AU  - Aylin, P.
AU  - Barahona, M.
TI  - Comparing natural language processing representations of coded disease sequences for prediction in electronic health records
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 7
SP  - 1451
EP  - 1462
DO  - 10.1093/jamia/ocae091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196673148&doi=10.1093%2fjamia%2focae091&partnerID=40&md5=143efa6a629036a8ca48282ff6f3fb4e
AB  - Objective: Natural language processing (NLP) algorithms are increasingly being applied to obtain unsupervised representations of electronic health record (EHR) data, but their comparative performance at predicting clinical endpoints remains unclear. Our objective was to compare the performance of unsupervised representations of sequences of disease codes generated by bag-of-words versus sequence-based NLP algorithms at predicting clinically relevant outcomes. Materials and Methods: This cohort study used primary care EHRs from 6 286 233 people with Multiple Long-Term Conditions in England. For each patient, an unsupervised vector representation of their time-ordered sequences of diseases was generated using 2 input strategies (212 disease categories versus 9462 diagnostic codes) and different NLP algorithms (Latent Dirichlet Allocation, doc2vec, and 2 transformer models designed for EHRs). We also developed a transformer architecture, named EHR-BERT, incorporating sociodemographic information. We compared the performance of each of these representations (without fine-tuning) as inputs into a logistic classifier to predict 1-year mortality, healthcare use, and new disease diagnosis. Results: Patient representations generated by sequence-based algorithms performed consistently better than bag-of-words methods in predicting clinical endpoints, with the highest performance for EHR-BERT across all tasks, although the absolute improvement was small. Representations generated using disease categories perform similarly to those using diagnostic codes as inputs, suggesting models can equally manage smaller or larger vocabularies for prediction of these outcomes. Discussion and Conclusion: Patient representations produced by sequence-based NLP algorithms from sequences of disease codes demonstrate improved predictive content for patient outcomes compared with representations generated by co-occurrence-based algorithms. This suggests transformer models may be useful for generating multi-purpose representations, even without fine-tuning. © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Gharizadeh, A.
AU  - Abbasi, K.
AU  - Ghareyazi, A.
AU  - Mofrad, M.R.K.
AU  - Rabiee, H.R.
TI  - HGTDR: Advancing drug repurposing with heterogeneous graph transformers
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 7
C7  - btae349
DO  - 10.1093/bioinformatics/btae349
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198002124&doi=10.1093%2fbioinformatics%2fbtae349&partnerID=40&md5=c61a0669b8e40d5d2051f4445ffc7ae4
AB  - Motivation: Drug repurposing is a viable solution for reducing the time and cost associated with drug development. However, thus far, the proposed drug repurposing approaches still need to meet expectations. Therefore, it is crucial to offer a systematic approach for drug repurposing to achieve cost savings and enhance human lives. In recent years, using biological network-based methods for drug repurposing has generated promising results. Nevertheless, these methods have limitations. Primarily, the scope of these methods is generally limited concerning the size and variety of data they can effectively handle. Another issue arises from the treatment of heterogeneous data, which needs to be addressed or converted into homogeneous data, leading to a loss of information. A significant drawback is that most of these approaches lack end-to-end functionality, necessitating manual implementation and expert knowledge in certain stages. Results: We propose a new solution, Heterogeneous Graph Transformer for Drug Repurposing (HGTDR), to address the challenges associated with drug repurposing. HGTDR is a three-step approach for knowledge graph-based drug repurposing: (1) constructing a heterogeneous knowledge graph, (2) utilizing a heterogeneous graph transformer network, and (3) computing relationship scores using a fully connected network. By leveraging HGTDR, users gain the ability to manipulate input graphs, extract information from diverse entities, and obtain their desired output. In the evaluation step, we demonstrate that HGTDR performs comparably to previous methods. Furthermore, we review medical studies to validate our method’s top 10 drug repurposing suggestions, which have exhibited promising results. We also demonstrated HGTDR’s capability to predict other types of relations through numerical and experimental validation, such as drug–protein and disease–protein inter-relations. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shen, A.
AU  - Yuan, M.
AU  - Ma, Y.
AU  - Du, J.
AU  - Wang, M.
TI  - Complementary multi-modality molecular self-supervised learning via non-overlapping masking for property prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 4
C7  - bbae256
DO  - 10.1093/bib/bbae256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194521032&doi=10.1093%2fbib%2fbbae256&partnerID=40&md5=ddd136e950de58e17a8fb601a413e5be
AB  - Self-supervised learning plays an important role in molecular representation learning because labeled molecular data are usually limited in many tasks, such as chemical property prediction and virtual screening. However, most existing molecular pre-training methods focus on one modality of molecular data, and the complementary information of two important modalities, SMILES and graph, is not fully explored. In this study, we propose an effective multi-modality self-supervised learning framework for molecular SMILES and graph. Specifically, SMILES data and graph data are first tokenized so that they can be processed by a unified Transformer-based backbone network, which is trained by a masked reconstruction strategy. In addition, we introduce a specialized non-overlapping masking strategy to encourage fine-grained interaction between these two modalities. Experimental results show that our framework achieves state-of-the-art performance in a series of molecular property prediction tasks, and a detailed ablation study demonstrates efficacy of the multi-modality framework and the masking strategy. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Win Myint, P.Y.
AU  - Lo, S.L.
AU  - Zhang, Y.
TI  - Unveiling the dynamics of crisis events: Sentiment and emotion analysis via multi-task learning with attention mechanism and subject-based intent prediction
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 4
C7  - 103695
DO  - 10.1016/j.ipm.2024.103695
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187218468&doi=10.1016%2fj.ipm.2024.103695&partnerID=40&md5=39e4fa3540f622222496169b7916ff74
AB  - In the age of rapid internet expansion, social media platforms like Twitter have become crucial for sharing information, expressing emotions, and revealing intentions during crisis situations. They offer crisis responders a means to assess public sentiment, attitudes, intentions, and emotional shifts by monitoring crisis-related tweets. To enhance sentiment and emotion classification, we adopt a transformer-based multi-task learning (MTL) approach with attention mechanism, enabling simultaneous handling of both tasks, and capitalizing on task interdependencies. Incorporating attention mechanism allows the model to concentrate on important words that strongly convey sentiment and emotion. We compare three baseline models, and our findings show that BERTweet outperforms the standard BERT model and exhibits similar performance to RoBERTa in crisis tweets. Furthermore, we employ natural language processing techniques to extract key subject entities (e.g., police, victims) and leverage the publicly available commonsense knowledge model, COMET-ATOMIC 2020, to identify their intentions in given crisis scenarios. Evaluation of COMET-ATOMIC 2020 on subject-based intent prediction in crisis tweets reveals that BART was superior to GPT2-XL model, providing crisis responders with vital information for better decision making. Notably, the integration of sentiment and emotion classification, identification of attention words and subject-based intent prediction represents a novel methodology, not previously applied in the context of crisis scenarios. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Ang, G.
AU  - Lim, E.-P.
TI  - Learning Dynamic Multimodal Network Slot Concepts from the Web for Forecasting Environmental, Social and Governance Ratings
PY  - 2024
T2  - ACM Transactions on the Web
VL  - 18
IS  - 3
C7  - 38
DO  - 10.1145/3663674
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201920922&doi=10.1145%2f3663674&partnerID=40&md5=366966953ef9c05661b5d3d008764b28
AB  - Dynamic multimodal networks are networks with node attributes from different modalities where the attributes and network relationships evolve across time, i.e., both networks and multimodal attributes are dynamic; for example, dynamic relationship networks between companies that evolve across time due to changes in business strategies and alliances, which are associated with dynamic company attributes from multiple modalities such as textual online news, categorical events, and numerical financial-related data. Such information can be useful in predictive tasks involving companies. Environmental, social, and governance (ESG) ratings of companies are important for assessing the sustainability risks of companies. The process of generating ESG ratings by expert analysts is, however, laborious and time-intensive. We thus explore the use of dynamic multimodal networks extracted from the web for forecasting ESG ratings. Learning such dynamic multimodal networks from the web for forecasting ESG ratings is, however, challenging due to its heterogeneity and the low signal-to-noise ratios and non-stationary distributions of web information. Human analysts cope with such issues by learning concepts from past experience through relational thinking and scanning for such concepts when analyzing new information about a company. In this article, we propose the Dynamic Multimodal Slot Concept Attention-based Network (DynScan) model. DynScan utilizes slot attention mechanisms together with slot concept alignment and disentanglement loss functions to learn latent slot concepts from dynamic multimodal networks to improve performance on ESG rating forecasting tasks. DynScan is evaluated on forecasting tasks on six datasets, comprising three ESG ratings across two sets of companies. Our experiments show that DynScan outperforms other state-of-the-art models on these forecasting tasks. We also visualize the slot concepts learned by DynScan on five synthetic datasets and three real-world datasets and observe distinct and meaningful slot concepts being learned by DynScan across both synthetic and real-world datasets. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xie, Y.
AU  - Wu, J.
AU  - Zhou, Y.
TI  - GTHP: a novel graph transformer Hawkes process for spatiotemporal event prediction
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 7
SP  - 4043
EP  - 4062
DO  - 10.1007/s10115-024-02080-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188076596&doi=10.1007%2fs10115-024-02080-z&partnerID=40&md5=6eadd2dbdc820819368f0029c8d1dd9f
AB  - The event sequences with spatiotemporal characteristics have been rapidly produced in various domains, such as earthquakes in seismology, electronic medical records in healthcare, and transactions in the financial market. These data often continue for weeks, months, or years, and the past events may trigger subsequent events. In this context, modeling the spatiotemporal event sequences and forecasting the next event has become a hot topic. However, existing models either failed to capture the long-term temporal dependencies or ignored the essential spatial information between sequences. In this paper, we proposed a novel graph transformer Hawkes process (GTHP) model to capture the long-term temporal dependencies and spatial information from historical events. The core concept of GTHP is to learn the spatial information by graph convolutional neural networks and capture long-term temporal dependencies from events embedding by self-attention mechanism. Moreover, we integrated the learned spatial information into the event embedding as auxiliary information. Numerous experiments on synthetic and real-world datasets proved the effectiveness of the proposed model. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Moura, R.
AU  - Carvalho, J.
AU  - Plastino, A.
AU  - Paes, A.
TI  - Less is more: Pruning BERTweet architecture in Twitter sentiment analysis
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 4
C7  - 103688
DO  - 10.1016/j.ipm.2024.103688
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186955265&doi=10.1016%2fj.ipm.2024.103688&partnerID=40&md5=263ebd9fa8209708a0fa69c6ca5c0729
AB  - Transformer-based models have been scaled up to account for absorbing more information and improve their performances. However, several studies have called attention to their overparametrization and the costs of experimenting with such huge models. This paper investigates the overparametrization of BERTweet, a transformer-based model trained with Twitter data, focusing on the prevalent task of tweets sentiment analysis. The paper contributes with a pruning method that reduces BERTweet size before tuning it to a downstream task. Using twenty-two datasets of tweets, the experiments evaluated several obtained pruned models, which achieved even superior performance after the finetuning procedure than when tuning the complete model. After applying the method on BERTweet, the pruned model with the best overall predictive performance was the result of pruning 47.22% of all heads (68 from 144 heads). In the generalization check, the time spent to finetune this pruned model was reduced by at least 10% while achieving the same or better predictive performance than the original model with a significance level of 0.05. The proposed pruning method can also be applied to other transformer-based models or tasks to find pruned models that perform similarly to the complete one. The execution of a straightforward version of our method yielded a highly pruned model, with a 74.31% reduction (107 out of 144 heads) while reaching high predictive performance. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Xin, Z.
AU  - Sirejiding, S.
AU  - Lu, Y.
AU  - Ding, Y.
AU  - Wang, C.
AU  - Alsarhan, T.
AU  - Lu, H.
TI  - TFUT: Task fusion upward transformer model for multi-task learning on dense prediction
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 244
C7  - 104014
DO  - 10.1016/j.cviu.2024.104014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190519831&doi=10.1016%2fj.cviu.2024.104014&partnerID=40&md5=86af71554d4d1248517dae69f11aebf6
AB  - Transformer-based advancements have shown great promise in solving multi-task learning on dense prediction tasks. Well-designed task interaction modules of these methods further improve the performances by effectively transferring contextual information between tasks. However, many of these methods do not leverage the target task to guide contextual information from the source task. We propose the Task Fusion Upward Transformer (TFUT) model for multi-task learning on dense prediction. To facilitate task interaction, we introduce the Asymmetric Cross Task Interaction module, which utilizes asymmetric transmission in attention. During similarity calculations, the model leverages the target task to guide the expression of contextual information from the source task, ensuring effective transmission of the context information. In order to avoid the loss of detail and the discontinuity of gradient in upsampling, the Upward Transformer Decoder is designed to extract and align multi-scale features using multi-level convolution. The effectiveness of the proposed model has been demonstrated through experiments on the NYUD-v2 dataset and the PASCAL Context dataset. The experimental results show that this model has achieved optimal performance in various single task and multi-task scenarios. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pan, J.
AU  - Liu, X.
AU  - Bai, Y.
AU  - Zhai, D.
AU  - Jiang, J.
AU  - Zhao, D.
TI  - Illumination-Aware Low-Light Image Enhancement with Transformer and Auto-Knee Curve
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 8
C7  - 254
DO  - 10.1145/3664653
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202720632&doi=10.1145%2f3664653&partnerID=40&md5=670d0ac75c2212d6b71707bdafdbd13a
AB  - Images captured under low-light conditions suffer from several combined degradation factors, including low brightness, low contrast, noise, and color bias. Many learning-based techniques attempt to learn the low-to-clear mapping between low-light and normal-light images. However, they often fall short when applied to low-light images taken in wide-contrast scenes because uneven illumination brings illumination-varying noise and the enhanced images are easily over-saturated in highlight areas. In this article, we present a novel two-stage method to tackle the problem of uneven illumination distribution in low-light images. Under the assumption that noise varies with illumination, we design an illumination-aware transformer network for the first stage of image restoration. In this stage, we introduce the Illumination-aware Attention Block featured with Illumination-aware Multi-head Self-attention, which incorporates different scales of illumination features to guide the attention module, thereby enhancing the denoising and reconstruction capabilities of the restoration network. In the second stage, we innovatively introduce a cubic auto-knee curve transfer with a global parameter predictor to alleviate the over-exposure caused by uneven illumination. We also adopt a white balance correction module to address color bias issues at this stage. Extensive experiments on various benchmarks demonstrate the advantages of our method over state-of-the-art methods qualitatively and quantitatively. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, W.
AU  - Chen, W.
AU  - Li, G.
AU  - Lei, D.
AU  - Yang, J.
AU  - Chen, Y.
AU  - Jiang, Y.
AU  - Wu, J.
AU  - Ni, B.
AU  - Sun, Y.
AU  - Wang, S.
AU  - Sun, Y.
AU  - Li, M.
AU  - Liu, J.
TI  - GMILT: A Novel Transformer Network That Can Noninvasively Predict EGFR Mutation Status
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 6
SP  - 7324
EP  - 7338
DO  - 10.1109/TNNLS.2022.3190671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195228007&doi=10.1109%2fTNNLS.2022.3190671&partnerID=40&md5=e2b29ac76310b56476221be8f97fea8a
AB  - Noninvasively and accurately predicting the epidermal growth factor receptor (EGFR) mutation status is a clinically vital problem. Moreover, further identifying the most suspicious area related to the EGFR mutation status can guide the biopsy to avoid false negatives. Deep learning methods based on computed tomography (CT) images may improve the noninvasive prediction of EGFR mutation status and potentially help clinicians guide biopsies by visual methods. Inspired by the potential inherent links between EGFR mutation status and invasiveness information, we hypothesized that the predictive performance of a deep learning network can be improved through extra utilization of the invasiveness information. Here, we created a novel explainable transformer network for EGFR classification named gated multiple instance learning transformer (GMILT) by integrating multi-instance learning and discriminative weakly supervised feature learning. Pathological invasiveness information was first introduced into the multitask model as embeddings. GMILT was trained and validated on a total of 512 patients with adenocarcinoma and tested on three datasets (the internal test dataset, the external test dataset, and The Cancer Imaging Archive (TCIA) public dataset). The performance (area under the curve (AUC) =0.772 on the internal test dataset) of GMILT exceeded that of previously published methods and radiomics-based methods (i.e., random forest and support vector machine) and attained a preferable generalization ability (AUC =0.856 in the TCIA test dataset and AUC =0.756 in the external dataset). A diameter-based subgroup analysis further verified the efficiency of our model (most of the AUCs exceeded 0.772) to noninvasively predict EGFR mutation status from computed tomography (CT) images. In addition, because our method also identified the 'core area' of the most suspicious area related to the EGFR mutation status, it has the potential ability to guide biopsies.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hemmasian, A.
AU  - Barati Farimani, A.
TI  - Multi-scale time-stepping of Partial Differential Equations with transformers
PY  - 2024
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 426
C7  - 116983
DO  - 10.1016/j.cma.2024.116983
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190258311&doi=10.1016%2fj.cma.2024.116983&partnerID=40&md5=2a7963277e9400e60bfcd27bcd8c2e35
AB  - Developing fast surrogates for Partial Differential Equations (PDEs) will accelerate design and optimization in almost all scientific and engineering applications. Neural networks have been receiving ever-increasing attention and demonstrated remarkable success in computational modeling of PDEs, however; their prediction accuracy is not at the level of full deployment. In this work, we utilize the transformer architecture, the backbone of numerous state-of-the-art AI models, to learn the dynamics of physical systems as the mixing of spatial patterns learned by a convolutional autoencoder. Moreover, we incorporate the idea of multi-scale hierarchical time-stepping to increase the prediction speed and decrease accumulated error over time. Our model achieves similar or better results in predicting the time-evolution of Navier–Stokes equations compared to the powerful Fourier Neural Operator (FNO) and two transformer-based neural operators OFormer and Galerkin Transformer. The code and data are available on https://github.com/BaratiLab/MST_PDE. © 2024 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Zhan, Y.
AU  - Ma, X.
AU  - Ding, L.
AU  - Tao, D.
AU  - Wu, J.
AU  - Hu, W.
AU  - Du, B.
TI  - Exploring sparsity in graph transformers
PY  - 2024
T2  - Neural Networks
VL  - 174
C7  - 106265
DO  - 10.1016/j.neunet.2024.106265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189014418&doi=10.1016%2fj.neunet.2024.106265&partnerID=40&md5=6e5ace13143358245cd985ab033d3b25
AB  - Graph Transformers (GTs) have achieved impressive results on various graph-related tasks. However, the huge computational cost of GTs hinders their deployment and application, especially in resource-constrained environments. Therefore, in this paper, we explore the feasibility of sparsifying GTs, a significant yet under-explored topic. We first discuss the redundancy of GTs based on the characteristics of existing GT models, and then propose a comprehensive Graph Transformer SParsification (GTSP) framework that helps to reduce the computational complexity of GTs from four dimensions: the input graph data, attention heads, model layers, and model weights. Specifically, GTSP designs differentiable masks for each individual compressible component, enabling effective end-to-end pruning. We examine our GTSP through extensive experiments on prominent GTs, including GraphTrans, Graphormer, and GraphGPS. The experimental results demonstrate that GTSP effectively reduces computational costs, with only marginal decreases in accuracy or, in some instances, even improvements. For example, GTSP results in a 30% reduction in Floating Point Operations while contributing to a 1.8% increase in Area Under the Curve accuracy on the OGBG-HIV dataset. Furthermore, we provide several insights on the characteristics of attention heads and the behavior of attention mechanisms, all of which have immense potential to inspire future research endeavors in this domain. Our code is available at https://github.com/LiuChuang0059/GTSP. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Chen, Y.
AU  - Wang, J.
TI  - SlowFastFormer for 3D human pose estimation
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 243
C7  - 103992
DO  - 10.1016/j.cviu.2024.103992
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189032821&doi=10.1016%2fj.cviu.2024.103992&partnerID=40&md5=9351997a33f3a9e90a091f3d8bb14b5f
AB  - 3D human pose estimation in videos aims at locating the human joints in the 3D space given a temporal sequence. Motion information and skeleton context are two significant elements for pose estimation in videos. In this paper, we propose a SlowFastFormer (slow-fast transformer) network where two branches with different input rates are composed to encode these two different kinds of context. For the slow branch, skeleton context is well learned at a higher frame rate. For the fast branch, motion information is captured at a lower frame rate. Through these two branches, different kinds of context are encoded separately. We fuse these two branches at a later stage to fully utilize the skeleton context and motion information. Afterwards, a blending module is developed to promote the message exchange among multiple branches. In the blending stage, different kinds of context information are exchanged and feature representation is enhanced consequently. Lastly, a hierarchical supervision scheme is tailored where predictions of different levels are inferred in a progressive manner. Our approach achieves competitive performance with lower computation complexity on several benchmarks, i.e., Human3.6M, MPI-INF-3DHP and HumanEva-I. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Urhan, A.
AU  - Cosma, B.-M.
AU  - Earl, A.M.
AU  - Manson, A.L.
AU  - Abeel, T.
TI  - SAFPred: synteny-aware gene function prediction for bacteria using protein embeddings
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 6
C7  - btae328
DO  - 10.1093/bioinformatics/btae328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195223616&doi=10.1093%2fbioinformatics%2fbtae328&partnerID=40&md5=9798e714439862d775da0b226c0f9bba
AB  - Motivation: Today, we know the function of only a small fraction of the protein sequences predicted from genomic data. This problem is even more salient for bacteria, which represent some of the most phylogenetically and metabolically diverse taxa on Earth. This low rate of bacterial gene annotation is compounded by the fact that most function prediction algorithms have focused on eukaryotes, and conventional annotation approaches rely on the presence of similar sequences in existing databases. However, often there are no such sequences for novel bacterial proteins. Thus, we need improved gene function prediction methods tailored for bacteria. Recently, transformer-based language models - adopted from the natural language processing field - have been used to obtain new representations of proteins, to replace amino acid sequences. These representations, referred to as protein embeddings, have shown promise for improving annotation of eukaryotes, but there have been only limited applications on bacterial genomes. Results: To predict gene functions in bacteria, we developed SAFPred, a novel synteny-aware gene function prediction tool based on protein embeddings from state-of-the-art protein language models. SAFpred also leverages the unique operon structure of bacteria through conserved synteny. SAFPred outperformed both conventional sequence-based annotation methods and state-of-the-art methods on multiple bacterial species, including for distant homolog detection, where the sequence similarity to the proteins in the training set was as low as 40%. Using SAFPred to identify gene functions across diverse enterococci, of which some species are major clinical threats, we identified 11 previously unrecognized putative novel toxins, with potential significance to human and animal health. © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Xu, B.
AU  - Cao, S.
AU  - Zhang, L.
TI  - Mitigating spectral bias for the multiscale operator learning
PY  - 2024
T2  - Journal of Computational Physics
VL  - 506
C7  - 112944
DO  - 10.1016/j.jcp.2024.112944
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188663279&doi=10.1016%2fj.jcp.2024.112944&partnerID=40&md5=68b32a321eec87e56cb0bc3c3ff2a803
AB  - Neural operators have emerged as a powerful tool for learning the mapping between infinite-dimensional parameter and solution spaces of partial differential equations (PDEs). In this work, we focus on multiscale PDEs that have important applications such as reservoir modeling and turbulence prediction. We demonstrate that for such PDEs, the spectral bias towards low-frequency components presents a significant challenge for existing neural operators. To address this challenge, we propose a hierarchical attention neural operator (HANO) inspired by the hierarchical matrix approach. HANO features a scale-adaptive interaction range and self-attentions over a hierarchy of levels, enabling nested feature computation with controllable linear cost and encoding/decoding of multiscale solution space. We also incorporate an empirical H1 loss function to enhance the learning of high-frequency components. Our numerical experiments demonstrate that HANO outperforms state-of-the-art (SOTA) methods for representative multiscale problems. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Zhang, D.
AU  - Liu, G.
AU  - Huang, L.
AU  - Qin, K.
TI  - Enhancing relation extraction using multi-task learning with SDP evidence
PY  - 2024
T2  - Information Sciences
VL  - 670
C7  - 120610
DO  - 10.1016/j.ins.2024.120610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190323295&doi=10.1016%2fj.ins.2024.120610&partnerID=40&md5=be97f12aec05468038c2b64b0d98dfa2
AB  - Relation extraction (RE) is a crucial subtask of information extraction, which involves recognizing the relation between entity pairs in a sentence. Previous studies have extensively employed syntactic information, notably the shortest dependency path (SDP), to collect word evidence, termed SDP evidence, which gives clues about the given entity pair, thus improving RE. Nevertheless, prevalent transformer-based techniques lack syntactic information and cannot effectively model essential syntactic clues to support relations. This study exerts multi-task learning to address these issues by imbibing an SDP token position prediction task into the RE task. To this end, we introduce SGA, an SDP evidence guiding approach that transfers the SDP evidence into two novel supervisory signal labels: SDP tokens label and SDP matrix label. The former guides the attention modules to assign high attention weights to SDP token positions, emphasizing relational clues. In the meantime, the latter supervises SGA to predict a parameterized asymmetric product matrix among the SDP tokens for RE. Experimental outcomes demonstrate the model's enhanced ability to leverage SDP information, thereby directing attention modules and predicted matrix labels to focus on SDP evidence. Consequently, our proposed approach surpasses existing publicly available optimal baselines across four RE datasets: SemEval2010-Task8, KBP37, NYT, and WebNLG.1 © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2024Enhancing
ER  -

TY  - JOUR
AU  - Xiao, J.
AU  - Long, B.
TI  - A multi-channel spatial-temporal transformer model for traffic flow forecasting
PY  - 2024
T2  - Information Sciences
VL  - 671
C7  - 120648
DO  - 10.1016/j.ins.2024.120648
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191339568&doi=10.1016%2fj.ins.2024.120648&partnerID=40&md5=83208979d22afe239f676c8c3019f41b
AB  - Traffic flow forecasting is a crucial task in transportation management and planning. The main challenges for traffic flow forecasting are that (1) as the length of prediction time increases, the accuracy of prediction will decrease; (2) the predicted results greatly rely on the extraction of temporal and spatial dependencies from the road networks. To overcome the challenges mentioned above, we propose a multi-channel spatial-temporal transformer model for traffic flow forecasting, which improves the accuracy of the prediction by fusing results from different channels of traffic data. Our approach leverages graph convolutional network to extract spatial features from each channel while using a transformer-based architecture to capture temporal dependencies across channels. We introduce an adaptive adjacency matrix to overcome limitations in feature extraction from fixed topological structures. Experimental results on six real-world datasets demonstrate that introducing a multi-channel mechanism into the temporal model enhances performance and our proposed model outperforms state-of-the-art models in terms of accuracy. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Xiao2024multi-channel
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Du, B.
AU  - Wang, W.
AU  - Xu, C.
TI  - Multi-tailed vision transformer for efficient inference
PY  - 2024
T2  - Neural Networks
VL  - 174
C7  - 106235
DO  - 10.1016/j.neunet.2024.106235
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189509050&doi=10.1016%2fj.neunet.2024.106235&partnerID=40&md5=38d2a31564a2bb9ca2e89710669fa314
AB  - Recently, Vision Transformer (ViT) has achieved promising performance in image recognition and gradually serves as a powerful backbone in various vision tasks. To satisfy the sequential input of Transformer, the tail of ViT first splits each image into a sequence of visual tokens with a fixed length. Then, the following self-attention layers construct the global relationship between tokens to produce useful representation for the downstream tasks. Empirically, representing the image with more tokens leads to better performance, yet the quadratic computational complexity of self-attention layer to the number of tokens could seriously influence the efficiency of ViT's inference. For computational reduction, a few pruning methods progressively prune uninformative tokens in the Transformer encoder, while leaving the number of tokens before the Transformer untouched. In fact, fewer tokens as the input for the Transformer encoder can directly reduce the following computational cost. In this spirit, we propose a Multi-Tailed Vision Transformer (MT-ViT) in the paper. MT-ViT adopts multiple tails to produce visual sequences of different lengths for the following Transformer encoder. A tail predictor is introduced to decide which tail is the most efficient for the image to produce accurate prediction. Both modules are optimized in an end-to-end fashion, with the Gumbel-Softmax trick. Experiments on ImageNet-1K demonstrate that MT-ViT can achieve a significant reduction on FLOPs with no degradation of the accuracy and outperform compared methods in both accuracy and FLOPs. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Benrachou, D.E.
AU  - Glaser, S.
AU  - Elhenawy, M.
AU  - Rakotonirainy, A.
TI  - Improving Efficiency and Generalisability of Motion Predictions with Deep Multi-Agent Learning and Multi-Head Attention
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 5356
EP  - 5373
DO  - 10.1109/TITS.2023.3339640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181804783&doi=10.1109%2fTITS.2023.3339640&partnerID=40&md5=ad3f40a3bf0efa8c2abf6074da9c0e64
AB  - Automated Vehicles (AVs) have been receiving increasing attention as a potential highly mechanised, intelligent, self-regulating futuristic mode of transport. AVs are predicted to address limitations and human factors associated with traditional modes of transportation. Beyond the typical operations of AVs which can perform rudimentary tasks, the intelligent embedded program fit in to process challenging scenarios and deep multi-dimensional/ agent intents and interaction of the roadway is the grey area yet to be explored to design an exclusive encoding of social functionality and operation in order to address human factors causing road crashes. The aim of this study is to design a data-driven prediction framework for AVs that utilises multiple inputs to prove a multimodal, probabilistic estimate of the future intentions and trajectories of surrounding vehicles in freeway operation. Our proposed framework is a deep multi-agent learning-based system designed to effectively capture social interactions between vehicles without relying on map information. Our approach excels in capturing the high-level behaviours of multiple vehicles and generating a multi-modal trajectory forecast. It employs a multi-headed neural architecture to learn from social interactions between vehicle pairs and generates diverse trajectories proportional to predicted target intents, thus enabling feature fusion. Additionally, a multi-head self-attention mechanism is incorporated for prediction refinement. We achieved a good prediction performance with a lower prediction error in real traffic data at highways. Evaluation of the proposed framework using the NGSIM (US-101 and I-80) and HighD datasets shows satisfactory prediction performance for long-term trajectory prediction of multiple surrounding vehicles. Additionally, the proposed framework has higher prediction accuracy and generalisability than state-of-the-art approaches. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Benrachou2024Improving
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Ni, D.
AU  - Wang, Y.
TI  - Recursive Deformable Pyramid Network for Unsupervised Medical Image Registration
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 6
SP  - 2229
EP  - 2240
DO  - 10.1109/TMI.2024.3362968
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184824437&doi=10.1109%2fTMI.2024.3362968&partnerID=40&md5=939e2db7f3be3f9eaf535faf650bd19f
AB  - Complicated deformation problems are frequently encountered in medical image registration tasks. Although various advanced registration models have been proposed, accurate and efficient deformable registration remains challenging, especially for handling the large volumetric deformations. To this end, we propose a novel recursive deformable pyramid (RDP) network for unsupervised non-rigid registration. Our network is a pure convolutional pyramid, which fully utilizes the advantages of the pyramid structure itself, but does not rely on any high-weight attentions or transformers. In particular, our network leverages a step-by-step recursion strategy with the integration of high-level semantics to predict the deformation field from coarse to fine, while ensuring the rationality of the deformation field. Meanwhile, due to the recursive pyramid strategy, our network can effectively attain deformable registration without separate affine pre-alignment. We compare the RDP network with several existing registration methods on three public brain magnetic resonance imaging (MRI) datasets, including LPBA, Mindboggle and IXI. Experimental results demonstrate our network consistently outcompetes state of the art with respect to the metrics of Dice score, average symmetric surface distance, Hausdorff distance, and Jacobian. Even for the data without the affine pre-alignment, our network maintains satisfactory performance on compensating for the large deformation. The code is publicly available at https://github.com/ZAX130/RDP.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - He, S.
AU  - Liu, H.
AU  - Chen, J.
AU  - Dong, H.
TI  - WindTrans: Transformer-Based Wind Speed Forecasting Method for High-Speed Railway
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 4947
EP  - 4963
DO  - 10.1109/TITS.2023.3337150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182947459&doi=10.1109%2fTITS.2023.3337150&partnerID=40&md5=6804eb6652caa4cbc75449a2b213244c
AB  - Wind speed forecasting provides the upcoming wind information and is important to the safe operation of High-Speed Railway (HSR). However, it remains a challenge due to the stochastic and highly varying characteristics of wind. In this paper, we propose a novel Transformer-based method for short-term wind speed forecasting, named WindTrans. Two major cruxes are addressed. First, the task is performed on fine-grained wind speed gathered from multiple sensors. These data present dynamic intra-series and inter-series correlations, which are hard for previous methods to recover. We advance a Transformer-based deep learning model, which has two distinctive characteristics: (1) a graph encoder, which captures the dynamic spatial correlation among wind speeds at different locations, and (2) a temporal decoder to model long sequence wind speed time series, which is resistant to noise in time series. Second, wind speed patterns gradually evolve in long-term periods, thus deactivating prediction models trained on historical data. To tackle this bottleneck, we put forward an experience replay-based scheme to renew the model regularly. To ensure that the renewed model still dominates historical wind patterns, we store and replay only a small portion of historical data named episodic memory. A simple but efficient strategy is designed to constitute episodic memory and thus relieve the computation burden. Experiments conducted on two real-world datasets demonstrate the superiority of our method over existing approaches. Particularly, WindTrans surpasses state-of-the-art methods by up to 36.7%, 29.3% and 13.3% improvement in MAPE measure for 1 hour ahead prediction on 10-minute, 5-minute, and 1-minute-based tasks, respectively. Furthermore, via our continual learning scheme, the model retains competitive performance with only 6.9% datum stored and retrained on. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Liu2024WindTrans
ER  -

TY  - JOUR
AU  - Li, T.
AU  - Dong, X.
AU  - Lin, J.
AU  - Peng, Y.
TI  - A transformer-CNN parallel network for image guided depth completion
PY  - 2024
T2  - Pattern Recognition
VL  - 150
C7  - 110305
DO  - 10.1016/j.patcog.2024.110305
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184149691&doi=10.1016%2fj.patcog.2024.110305&partnerID=40&md5=bfccf00ee6d4de87e48c8e6789ebaf63
AB  - Image guided depth completion aims to predict a dense depth map from sparse depth measurements and the corresponding single color image. However, most state-of-the-art methods only rely on convolutional neural network (CNN) or transformer. In this paper, we propose a transformer-CNN parallel network (TCPNet) to integrate the advantages of CNN in local detail recovery and transformer in long-range semantic modeling. Specifically, our CNN branch adopts dense connection to strengthen feature propagation. Since the common transformer computes self-attention based on all the tokens in the window, no matter if they are relevant or not, this will inevitably introduce interferences and noises. To improve the self-attention accuracy, we propose a correlation-based transformer to only allow nearest neighbor tokens to participate in the self-attention computation. We also design a multi-scale conditional random field (CRF) module to implement multi-scale high-dimensional filtering for depth refinement. The comprehensive experimental results on KITTI and NYUv2 demonstrate that our method outperforms the state-of-the-art methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, M.
AU  - Bai, Y.
AU  - Cao, Z.
AU  - Nie, L.
AU  - Zhang, M.
TI  - Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 6
SP  - 5132
EP  - 5145
DO  - 10.1109/TCSVT.2023.3339489
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179809403&doi=10.1109%2fTCSVT.2023.3339489&partnerID=40&md5=a5793cb2cb45d20a1a3f3f627c51bfb8
AB  - Image-text retrieval is a fundamental task to model a connection between images and natural language. Under its flourishing development in performance, most current methods suffer from N-related time complexity, which hinders their application in practice to a certain extent. Targeting efficiency improvement, we propose a simple and effective keyword-guided pre-screening framework for image-text retrieval. Specifically, we convert the image and text data into keywords and perform keyword matching across the modalities to exclude a large number of irrelevant gallery samples prior to the retrieval network. For the keyword prediction, we transfer it into a multi-label classification problem and propose a multi-task learning scheme by appending the multi-label classifiers to the image-text retrieval network to achieve a lightweight and high-performance keyword prediction. For keyword matching, we introduce the inverted index from the search engine and thus create a win-win situation on both time and space complexities for the pre-screening. Extensive experiments on the two widely-used datasets, i.e., Flickr30K and MS-COCO, verify the effectiveness of the proposed framework. The proposed framework equipped with only two embedding layers achieves O(1) querying time complexity, while improving the retrieval efficiency and maintaining performance, when applied prior to the common image-text retrieval methods.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hajikhani, M.
AU  - Hegde, A.
AU  - Snyder, J.
AU  - Cheng, J.
AU  - Lin, M.
TI  - Integrating transformer-based machine learning with SERS technology for the analysis of hazardous pesticides in spinach
PY  - 2024
T2  - Journal of Hazardous Materials
VL  - 470
C7  - 134208
DO  - 10.1016/j.jhazmat.2024.134208
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189749036&doi=10.1016%2fj.jhazmat.2024.134208&partnerID=40&md5=fa2a7ed9e383ef9d0acdb0633038d0b1
AB  - This study introduces an innovative strategy for the rapid and accurate identification of pesticide residues in agricultural products by combining surface-enhanced Raman spectroscopy (SERS) with a state-of-the-art transformer model, termed SERSFormer. Gold-silver core-shell nanoparticles were synthesized and served as high-performance SERS substrates, which possess well-defined structures, uniform dispersion, and a core-shell composition with an average diameter of 21.44 ± 4.02 nm, as characterized by TEM-EDS. SERSFormer employs sophisticated, task-specific data processing techniques and CNN embedders, powered by an architecture features weight-shared multi-head self-attention transformer encoder layers. The SERSFormer model demonstrated exceptional proficiency in qualitative analysis, successfully classifying six categories, including five pesticides (coumaphos, oxamyl, carbophenothion, thiabendazole, and phosmet) and a control group of spinach data, with 98.4% accuracy. For quantitative analysis, the model accurately predicted pesticide concentrations with a mean absolute error of 0.966, a mean squared error of 1.826, and an R2 score of 0.849. This novel approach, which combines SERS with machine learning and is supported by robust transformer models, showcases the potential for real-time pesticide detection to improve food safety in the agricultural and food industries. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Dong, Y.
AU  - Lu, Z.-M.
AU  - Yu, Y.
AU  - Han, J.
TI  - Self-Prompting Perceptual Edge Learning for Dense Prediction
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 6
C7  - 10348598
SP  - 4528
EP  - 4541
DO  - 10.1109/TCSVT.2023.3340740
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179835880&doi=10.1109%2fTCSVT.2023.3340740&partnerID=40&md5=928bfe8b81f22809725956cb1ad73f57
AB  - Numerous studies have employed prompt learning structures to enhance dense prediction tasks by integrating additional semantic or geometric information. While the inclusion of extra information has shown improvements in performance, it also poses challenges for applications that cannot provide extra input. To address this issue, this study evaluates the performance of different prompts and introduces an additional-input-free method, called self-prompting perceptual edge learning (SPPEL), which extracts edge-embedded semantic prompts directly from the image feature itself using trainable handcrafted edge operators within a plug-and-play module. To obtain the edge features, our approach incorporates an adversarial structure that compares the similarity between two edge features generated by the Hog and Kirsch operators, where the edge features are measured using multiplication, finetuned through a trainable all-one embedding, and enhanced with channel-to-channel attention. We conduct extensive evaluations of SPPEL on 7 tasks, utilizing 7 different backbones and applying 5 distinct methods. Our experimental results demonstrate that SPPEL achieves strong competitiveness in various settings with an average improvement of 1.7% across all 7 tasks, including ADE20K, COCO (Instance Segmentation), COCO (Object Detection), Pascal VOC2012, STARE, CHASE DB1, and HRF, while incurring a parameter increase of less than 3% (the detailed computation analysis of parameters and Gflops are shown in different experimental tables).  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, W.
AU  - Xi, Z.
AU  - Hu, C.
AU  - Zhao, B.
AU  - Niu, Y.
TI  - Passenger Comfort Quantification for Automated Vehicle Based on Stacking of Psychophysics Mechanism and Encoder-Transformer Model
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 5211
EP  - 5224
DO  - 10.1109/TITS.2023.3337775
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180348108&doi=10.1109%2fTITS.2023.3337775&partnerID=40&md5=f05f4293f228366611ac11d9cde5813e
AB  - Passenger comfort is a crucial aspect that influences humans' acceptance of automated vehicles. The passenger comfort score (PCS) is closely related to the passengers' psychological states, however, comfort quantification methods based on the passengers' psychophysics mechanism are rare. This research pioneers a passenger comfort quantification model (PCQM) specifically designed for automated vehicles, demonstrating the model's ability to accurately quantify subjective PCS under urban LCS. Three significant contributions form the basis of this study: 1) A dataset dedicated to comfort quantification is collected. A novel PCQM based on ensemble learning of psychophysics mechanism based sub-model and encoder-transformer based sub-model is proposed. The psychophysics mechanism model is derived from Stevens' power law. 2) As a subjective indicator, the self-reported score (SRS), which is the indicator of PCS contains considerable noise. The PCQM addresses the issue of substantial noise prevalent in the subjective SRS by incorporating a semi-supervised learning strategy, which enhances data consistency and suppresses noise. 3) The efficacy of the proposed PCQM is corroborated via deployment on an automated vehicle, where the model's real-time predictions strongly align with SRS from onboard passengers. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhu2024Passenger
ER  -

TY  - JOUR
AU  - Nie, X.
AU  - Ni, B.
AU  - Chang, J.
AU  - Meng, G.
AU  - Huo, C.
AU  - Xiang, S.
AU  - Tian, Q.
TI  - Pro-Tuning: Unified Prompt Tuning for Vision Tasks
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 6
SP  - 4653
EP  - 4667
DO  - 10.1109/TCSVT.2023.3327605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176379437&doi=10.1109%2fTCSVT.2023.3327605&partnerID=40&md5=6ca14e5846b04ace421b2553b24573b6
AB  - In computer vision, fine-tuning is the de-facto approach to leverage pre-trained vision models to perform downstream tasks. However, deploying it in practice is quite challenging, due to adopting parameter inefficient global update and heavily relying on high-quality downstream data. Recently, prompt-based learning, which adds the task-relevant prompt to adapt the pre-trained models to downstream tasks, has drastically boosted the performance of many natural language downstream tasks. In this work, we extend this notable transfer ability benefited from prompt into vision models as an alternative to fine-tuning. To this end, we propose parameter-efficient Prompt tuning (Pro-tuning) to adapt diverse frozen pre-trained models to a wide variety of downstream vision tasks. The key to Pro-tuning is prompt-based tuning, i.e., learning task-specific vision prompts for downstream input images with the pre-trained model frozen. By only training a small number of additional parameters, Pro-tuning can generate compact and robust downstream models both for CNN-based and transformer-based network architectures. Comprehensive experiments evidence that the proposed Pro-tuning outperforms fine-tuning on a broad range of vision tasks and scenarios, including image classification (under generic objects, class imbalance, image corruption, natural adversarial examples, and out-of-distribution generalization), and dense prediction tasks such as object detection and semantic segmentation.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, R.
AU  - Song, Z.
AU  - Liu, L.
AU  - He, J.
AU  - Zhang, T.
AU  - Zhang, Y.
TI  - HA-Bins: Hierarchical Adaptive Bins for Robust Monocular Depth Estimation Across Multiple Datasets
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 6
SP  - 4354
EP  - 4366
DO  - 10.1109/TCSVT.2023.3335316
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177998059&doi=10.1109%2fTCSVT.2023.3335316&partnerID=40&md5=e4995c5fbf92f001e5421d4ccb772e7a
AB  - Existing monocular depth estimation methods have achieved satisfactory performance on wild datasets. However, these methods are usually trained and tested on a single dataset, which makes them difficult to generalize to other scenarios. To learn diverse scene priors from multiple datasets, we propose a hierarchical framework with adaptive bins for robust monocular depth estimation, which consists of two critical components: a group-wise query generator to assign hierarchical bins and a correlation-aware transformer decoder to generate adaptive bin features. The proposed HA-Bins enjoys several merits. First, the group-wise query generator progressively increases the number of bin queries for multi-scale image features, resulting in a hierarchical bin distribution robust to diverse scenarios. Second, the correlation-aware transformer decoder refines the correlation of bin queries and image features, effectively improving adaptive image feature aggregation. We visualize the query activation maps on NYUDepthv2 dataset, showing that the proposed network effectively suppresses the depth-irrelevant regions. Experiments on KITTI, Sintel, and RabbitAI benchmarks show that without any fine-tuning, our model jointly trained on multiple datasets achieves competitive performance with the state-of-the-art and solid robustness toward diverse scenarios. In addition, our method wins second place in Robust Vision Challenge 2022 towards challenging scenarios with different characteristics.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bai, S.
AU  - Yang, L.
AU  - Liu, Y.
AU  - Yu, H.
TI  - DMF-Net: A Dual-Encoding Multi-Scale Fusion Network for Pavement Crack Detection
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 6
SP  - 5981
EP  - 5996
DO  - 10.1109/TITS.2023.3331769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184801141&doi=10.1109%2fTITS.2023.3331769&partnerID=40&md5=a435187e7d113592a7a554868f908009
AB  - Currently, cracks are the most common defect in pavement diseases. Long-term non-maintenance can lead to crack lengthening and expansion, causing serious traffic accidents, as well as shortening the service life of pavement cracks. Therefore, it is of utmost importance to maintain cracks at an early stage. Due to the effect of some challenging factors, such as various shape information of the cracks, complex textured backgrounds, light shadows, similar texture objects, micro cracks and other factors, accurate crack detection still faces a certain challenges. To solve the above problems, a dual-encoding multi-scale fusion network based on the combination of convolutional neural network (CNN) and transformer network is proposed, named DMF-Net. To obtain stronger feature representations, a dual-encoding path is built to acquire global context features and local detail information simultaneously, where global context features are extracted based on the transformer branch, and the local detail features are extracted based on the CNN branch to detect tiny details of the cracks. Meanwhile, an interactive attention learning (IAL) module is introduced to effectively fuse the global features from the transformer branch and the local detail information from the CNN branch, achieving mutual communication and learning of different feature information. In addition, to enrich the feature representation ability, an attention-based feature enhancement (AFE) module is introduced to acquire more global contexts. Furthermore, faced with the crack detection task with class imbalance issue, a triple attention module (TAM) is built to emphasize the micro cracks. Finally, in the segmentation prediction stage, the deep supervision mechanism is also introduced to accelerate the convergence speed of the model, and serve effective multi-scale feature fusion. Compared with the current mainstream segmentation models, excellent performance has been obtained, which could provide a feasible scheme for the early maintenance of pavement cracks. The source code about proposed DMF-Net is available at https://github.com/Bsl1/DMFNet.git. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; FMS:B; 
LB  - Bai2024DMF-Net
ER  -

TY  - JOUR
AU  - Hu, S.
AU  - Wu, W.
AU  - Su, R.
AU  - Hou, W.
AU  - Zheng, L.
AU  - Xu, B.
TI  - Raster-to-Graph: Floorplan Recognition via Autoregressive Graph Prediction with an Attention Transformer
PY  - 2024
T2  - Computer Graphics Forum
VL  - 43
IS  - 2
C7  - e15007
DO  - 10.1111/cgf.15007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190558338&doi=10.1111%2fcgf.15007&partnerID=40&md5=2397531d7cf0ab1f7bcee074ada8eb0e
AB  - Recognizing the detailed information embedded in rasterized floorplans is at the research forefront in the community of computer graphics and vision. With the advent of deep neural networks, automatic floorplan recognition has made tremendous breakthroughs. However, co-recognizing both the structures and semantics of floorplans through one neural network remains a significant challenge. In this paper, we introduce a novel framework Raster-to-Graph, which automatically achieves structural and semantic recognition of floorplans. We represent vectorized floorplans as structural graphs embedded with floorplan semantics, thus transforming the floorplan recognition task into a structural graph prediction problem. We design an autoregressive prediction framework using the neural network architecture of the visual attention Transformer, iteratively predicting the wall junctions and wall segments of floorplans in the order of graph traversal. Additionally, we propose a large-scale floorplan dataset containing over 10,000 real-world residential floorplans. Our autoregressive framework can automatically recognize the structures and semantics of floorplans. Extensive experiments demonstrate the effectiveness of our framework, showing significant improvements on all metrics. Qualitative and quantitative evaluations indicate that our framework outperforms existing state-of-the-art methods. Code and dataset for this paper are available at: https://github.com/HSZVIS/Raster-to-Graph. © 2024 Eurographics - The European Association for Computer Graphics and John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Meng, L.
AU  - Chen, X.
AU  - Cheng, K.
AU  - Chen, N.
AU  - Zheng, Z.
AU  - Wang, F.
AU  - Sun, H.
AU  - Wong, K.-C.
TI  - TransPTM: A transformer-based model for non-histone acetylation site prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 3
C7  - bbae219
DO  - 10.1093/bib/bbae219
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192792843&doi=10.1093%2fbib%2fbbae219&partnerID=40&md5=87e412b1dee9e7e74865ef3ab115659a
AB  - Protein acetylation is one of the extensively studied post-translational modifications (PTMs) due to its significant roles across a myriad of biological processes. Although many computational tools for acetylation site identification have been developed, there is a lack of benchmark dataset and bespoke predictors for non-histone acetylation site prediction.To address these problems,we have contributed to both dataset creation and predictor benchmark in this study. First, we construct a non-histone acetylation site benchmark dataset, namely NHAC, which includes 11 subsets according to the sequence length ranging from 11 to 61 amino acids. There are totally 886 positive samples and 4707 negative samples for each sequence length. Secondly, we propose TransPTM, a transformer-based neural network model for non-histone acetylation site predication. During the data representation phase, per-residue contextualized embeddings are extracted using ProtT5 (an existing pre-trained protein language model). This is followed by the implementation of a graph neural network framework, which consists of three TransformerConv layers for feature extraction and a multilayer perceptron module for classification. The benchmark results reflect that TransPTM has the competitive performance for non-histone acetylation site prediction over three state-of-the-art tools.It improves our comprehension on the PTM mechanism and provides a theoretical basis for developing drug targets for diseases. Moreover, the created PTM datasets fills the gap in non-histone acetylation site datasets and is beneficial to the related communities. The related source code and data utilized by TransPTM are accessible at https://www.github. com/TransPTM/TransPTM. © 2024 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Janson, G.
AU  - Feig, M.
TI  - Transferable deep generative modeling of intrinsically disordered protein conformations
PY  - 2024
T2  - PLoS Computational Biology
VL  - 20
IS  - 5 May
C7  - e1012144
DO  - 10.1371/journal.pcbi.1012144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194072643&doi=10.1371%2fjournal.pcbi.1012144&partnerID=40&md5=9b726369e297d65b50e17c1a5c6591be
AB  - Intrinsically disordered proteins have dynamic structures through which they play key biological roles. The elucidation of their conformational ensembles is a challenging problem requiring an integrated use of computational and experimental methods. Molecular simulations are a valuable computational strategy for constructing structural ensembles of disordered proteins but are highly resource-intensive. Recently, machine learning approaches based on deep generative models that learn from simulation data have emerged as an efficient alternative for generating structural ensembles. However, such methods currently suffer from limited transferability when modeling sequences and conformations absent in the training data. Here, we develop a novel generative model that achieves high levels of transferability for intrinsically disordered protein ensembles. The approach, named idpSAM, is a latent diffusion model based on transformer neural networks. It combines an autoencoder to learn a representation of protein geometry and a diffusion model to sample novel conformations in the encoded space. IdpSAM was trained on a large dataset of simulations of disordered protein regions performed with the ABSINTH implicit solvent model. Thanks to the expressiveness of its neural networks and its training stability, idpSAM faithfully captures 3D structural ensembles of test sequences with no similarity in the training set. Our study also demonstrates the potential for generating full conformational ensembles from datasets with limited sampling and underscores the importance of training set size for generalization. We believe that idpSAM represents a significant progress in transferable protein ensemble modeling through machine learning. © 2024 Janson, Feig. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gurvich, R.
AU  - Markel, G.
AU  - Tanoli, Z.
AU  - Meirson, T.
TI  - Peptriever: a Bi-Encoder approach for large-scale protein–peptide binding search
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 5
C7  - btae303
DO  - 10.1093/bioinformatics/btae303
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194073484&doi=10.1093%2fbioinformatics%2fbtae303&partnerID=40&md5=e014a078410cb891526e82e646523ec4
AB  - Motivation: Peptide therapeutics hinge on the precise interaction between a tailored peptide and its designated receptor while mitigating interactions with alternate receptors is equally indispensable. Existing methods primarily estimate the binding score between protein and peptide pairs. However, for a specific peptide without a corresponding protein, it is challenging to identify the proteins it could bind due to the sheer number of potential candidates. Results: We propose a transformers-based protein embedding scheme in this study that can quickly identify and rank millions of interacting proteins. Furthermore, the proposed approach outperforms existing sequence- and structure-based methods, with a mean AUC-ROC and AUC-PR of 0.73. Availability and implementation: Training data, scripts, and fine-tuned parameters are available at https://github.com/RoniGurvich/Peptriever. The proposed method is linked with a web application available for customized prediction at https://peptriever.app/. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Alazba, A.
AU  - Aljamaan, H.
AU  - Alshayeb, M.
TI  - CoRT: Transformer-based code representations with self-supervision by predicting reserved words for code smell detection
PY  - 2024
T2  - Empirical Software Engineering
VL  - 29
IS  - 3
C7  - 59
DO  - 10.1007/s10664-024-10445-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188448314&doi=10.1007%2fs10664-024-10445-9&partnerID=40&md5=180b68245490c5e236e4b75831b8513a
AB  - Context: Code smell detection is the process of identifying poorly designed and implemented code pieces. Machine learning-based approaches require enormous amounts of manually labeled data, which are costly and difficult to scale. Unsupervised semantic feature learning, or learning without manual annotation, is vital for effectively harvesting an enormous amount of available data. Objective: The objective of this study is to propose a new code smell detection approach that utilizes self-supervised learning to learn intermediate representations without the need for labels and then fine-tune these representations on multiple tasks. Method: We propose a Code Representation with Transformers (CoRT) to learn the semantic and structural features of the source code by training transformers to recognize masked reserved words that are applied to the code given as input. We empirically demonstrated that the defined proxy task provides a powerful method for learning semantic and structural features. We exhaustively evaluated our approach on four downstream tasks: detection of the Data Class, God Class, Feature Envy, and Long Method code smells. Moreover, we compare our results with those of two paradigms: supervised learning and a feature-based approach. Finally, we conducted a cross-project experiment to evaluate the generalizability of our method to unseen labeled data. Results: The results indicate that the proposed method has a high detection performance for code smells. For instance, the detection performance of CoRT on Data Class achieved a score of F1 between 88.08–99.4, Area Under Curve (AUC) between 89.62–99.88, and Matthews Correlation Coefficient (MCC) between 75.28–98.8, while God Class achieved a value of F1 ranges from 86.32–99.03, AUC of 92.1–99.85, and MCC of 76.15–98.09. Compared with the baseline model and feature-based approach, CoRT achieved better detection performance and had a high capability to detect code smells in unseen datasets. Conclusions: The proposed method has been shown to be effective in detecting class-level, and method-level code smells. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Tao, Y.
AU  - Cai, Z.
AU  - Bao, P.
AU  - Ma, H.
AU  - Li, K.
AU  - Li, M.
AU  - Zhu, Y.
AU  - Lu, Z.J.
TI  - Pathformer: a biological pathway informed transformer for disease diagnosis and prognosis using multi-omics data
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 5
C7  - btae316
DO  - 10.1093/bioinformatics/btae316
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194958555&doi=10.1093%2fbioinformatics%2fbtae316&partnerID=40&md5=30af0f7ec54375a22bdb7a9df60539c4
AB  - Motivation: Multi-omics data provide a comprehensive view of gene regulation at multiple levels, which is helpful in achieving accurate diagnosis of complex diseases like cancer. However, conventional integration methods rarely utilize prior biological knowledge and lack interpretability. Results: To integrate various multi-omics data of tissue and liquid biopsies for disease diagnosis and prognosis, we developed a biological pathway informed Transformer, Pathformer. It embeds multi-omics input with a compacted multi-modal vector and a pathway-based sparse neural network. Pathformer also leverages criss-cross attention mechanism to capture the crosstalk between different pathways and modalities. We first benchmarked Pathformer with 18 comparable methods on multiple cancer datasets, where Pathformer outperformed all the other methods, with an average improvement of 6.3%–14.7% in F1 score for cancer survival prediction, 5.1%–12% for cancer stage prediction, and 8.1%–13.6% for cancer drug response prediction. Subsequently, for cancer prognosis prediction based on tissue multi-omics data, we used a case study to demonstrate the biological interpretability of Pathformer by identifying key pathways and their biological crosstalk. Then, for cancer early diagnosis based on liquid biopsy data, we used plasma and platelet datasets to demonstrate Pathformer’s potential of clinical applications in cancer screening. Moreover, we revealed deregulation of interesting pathways (e.g. scavenger receptor pathway) and their crosstalk in cancer patients’ blood, providing potential candidate targets for cancer microenvironment study. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, R.
AU  - Zhang, Y.
AU  - Wang, Q.
AU  - Zhang, X.
TI  - TransAC4C - a novel interpretable architecture for multi-species identification of N4-acetylcytidine sites in RNA with single-base resolution
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 3
C7  - bbae200
DO  - 10.1093/bib/bbae200
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192115247&doi=10.1093%2fbib%2fbbae200&partnerID=40&md5=b0f59c48d1b351ac0a649698fee57086
AB  - N4-acetylcytidine (ac4C) is a modification found in ribonucleic acid (RNA) related to diseases. Expensive and labor-intensive methods hindered the exploration of ac4C mechanisms and the development of specific anti-ac4C drugs. Therefore, an advanced prediction model for ac4C in RNA is urgently needed. Despite the construction of various prediction models, several limitations exist: (1) insufficient resolution at base level for ac4C sites; (2) lack of information on species other than Homo sapiens; (3) lack of information on RNA other than mRNA; and (4) lack of interpretation for each prediction. In light of these limitations, we have reconstructed the previous benchmark dataset and introduced a new dataset including balanced RNA sequences from multiple species and RNA types, while also providing base-level resolution for ac4C sites. Additionally, we have proposed a novel transformer-based architecture and pipeline for predicting ac4C sites, allowing for highly accurate predictions, visually interpretable results and no restrictions on the length of input RNA sequences. Statistically, our work has improved the accuracy of predicting specific ac4C sites in multiple species from less than 40% to around 85%, achieving a high AUC > 0.9. These results significantly surpass the performance of all existing models.  © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pratyush, P.
AU  - Bahmani, S.
AU  - Pokharel, S.
AU  - Ismail, H.D.
AU  - Dukka, B.K.C.
TI  - LMCrot: an enhanced protein crotonylation site predictor by leveraging an interpretable window-level embedding from a transformer-based protein language model
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 5
C7  - btae290
DO  - 10.1093/bioinformatics/btae290
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192899043&doi=10.1093%2fbioinformatics%2fbtae290&partnerID=40&md5=10043626840aceaa4a2dff066201237b
AB  - Motivation: Recent advancements in natural language processing have highlighted the effectiveness of global contextualized representations from protein language models (pLMs) in numerous downstream tasks. Nonetheless, strategies to encode the site-of-interest leveraging pLMs for per-residue prediction tasks, such as crotonylation (Kcr) prediction, remain largely uncharted. Results: Herein, we adopt a range of approaches for utilizing pLMs by experimenting with different input sequence types (full-length protein sequence versus window sequence), assessing the implications of utilizing per-residue embedding of the site-of-interest as well as embeddings of window residues centered around it. Building upon these insights, we developed a novel residual ConvBiLSTM network designed to process window-level embeddings of the site-of-interest generated by the ProtT5-XL-UniRef50 pLM using full-length sequences as input. This model, termed T5ResConvBiLSTM, surpasses existing state-of-the-art Kcr predictors in performance across three diverse datasets. To validate our approach of utilizing full sequence-based window-level embeddings, we also delved into the interpretability of ProtT5-derived embedding tensors in two ways: firstly, by scrutinizing the attention weights obtained from the transformer’s encoder block; and secondly, by computing SHAP values for these tensors, providing a model-agnostic interpretation of the prediction results. Additionally, we enhance the latent representation of ProtT5 by incorporating two additional local representations, one derived from amino acid properties and the other from supervised embedding layer, through an intermediate fusion stacked generalization approach, using an n-mer window sequence (or, peptide/fragment). The resultant stacked model, dubbed LMCrot, exhibits a more pronounced improvement in predictive performance across the tested datasets. Availability and implementation: LMCrot is publicly available at https://github.com/KCLabMTU/LMCrot. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Huang, S.
AU  - Liu, Y.
AU  - Cui, H.
AU  - Zhang, F.
AU  - Li, J.
AU  - Zhang, X.
AU  - Zhang, M.
AU  - Zhang, C.
TI  - MEAformer: An all-MLP transformer with temporal external attention for long-term time series forecasting
PY  - 2024
T2  - Information Sciences
VL  - 669
C7  - 120605
DO  - 10.1016/j.ins.2024.120605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190243936&doi=10.1016%2fj.ins.2024.120605&partnerID=40&md5=bb25f17f4de6888dd0e4c1d735f69544
AB  - Transformer-based models have significantly improved performance in Long-term Time Series Forecasting (LTSF). These models employ various self-attention mechanisms to discover long-term dependencies. However, the computational efficiency is hampered by the inherent permutation invariance of self-attention, and they primarily focus on relationships within the sequence while neglecting potential relationships between different sample sequences. This limits the ability and flexibility of self-attention in LTSF. In addition, the Transformer's decoder outputs sequences in an autoregressive manner, leading to slow inference speed and error accumulation effects, especially for LTSF. Regarding the issues with Transformer-based models for LTSF, we propose a model better suited for LTSF, named MEAformer. MEAformer adopts a fully connected Multi-Layer Perceptron (MLP) architecture consisting of two types of layers: encoder layers and MLP layers. Unlike most encoder layers in Transformer-based models, the MEAformer replaces self-attention with temporal external attention. Temporal external attention explores potential relationships between different sample sequences in the training dataset. Compared to the quadratic complexity of self-attention mechanisms, temporal external attention has efficient linear complexity. Encoder layers can be stacked multiple times to capture time-dependent relationships at different scales. Furthermore, the MEAformer replaces the intricate decoder layers of the original model with more straightforward MLP layers. This modification aims to enhance inference speed and facilitate single-pass sequence generation, effectively mitigating the problem of error accumulation effects. Regarding long-term forecasting, MEAformer achieves state-of-the-art performance on six benchmark datasets, covering five real-world domains: energy, transportation, economy, weather, and disease. Code is available at: https://github.com/huangsiyuan924/MEAformer. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2024MEAformer
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Liao, Q.
AU  - Wei, J.
AU  - Zhuo, L.
AU  - Wu, X.
AU  - Fu, X.
AU  - Zou, Q.
TI  - Revisiting drug–protein interaction prediction: a novel global–local perspective
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 5
C7  - btae271
DO  - 10.1093/bioinformatics/btae271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192918851&doi=10.1093%2fbioinformatics%2fbtae271&partnerID=40&md5=aba5f70596002a9c22f00ba460927264
AB  - Motivation: Accurate inference of potential drug–protein interactions (DPIs) aids in understanding drug mechanisms and developing novel treatments. Existing deep learning models, however, struggle with accurate node representation in DPI prediction, limiting their performance. Results: We propose a new computational framework that integrates global and local features of nodes in the drug–protein bipartite graph for efficient DPI inference. Initially, we employ pre-trained models to acquire fundamental knowledge of drugs and proteins and to determine their initial features. Subsequently, the MinHash and HyperLogLog algorithms are utilized to estimate the similarity and set cardinality between drug and protein subgraphs, serving as their local features. Then, an energy-constrained diffusion mechanism is integrated into the transformer architecture, capturing interdependencies between nodes in the drug–protein bipartite graph and extracting their global features. Finally, we fuse the local and global features of nodes and employ multilayer perceptrons to predict the likelihood of potential DPIs. A comprehensive and precise node representation guarantees efficient prediction of unknown DPIs by the model. Various experiments validate the accuracy and reliability of our model, with molecular docking results revealing its capability to identify potential DPIs not present in existing databases. This approach is expected to offer valuable insights for furthering drug repurposing and personalized medicine research. Availability and implementation: Our code and data are accessible at: https://github.com/ZZCrazy00/DPI. © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wu, K.
AU  - Yang, X.
AU  - Wang, Z.
AU  - Li, N.
AU  - Zhang, J.
AU  - Liu, L.
TI  - Data-balanced transformer for accelerated ionizable lipid nanoparticles screening in mRNA delivery
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 3
C7  - bbae186
DO  - 10.1093/bib/bbae186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191637095&doi=10.1093%2fbib%2fbbae186&partnerID=40&md5=b8087a1d714830fb2786b765402c4e56
AB  - Despite the widespread use of ionizable lipid nanoparticles (LNPs) in clinical applications for messenger RNA (mRNA) delivery, the mRNA drug delivery system faces an efficient challenge in the screening of LNPs. Traditional screening methods often require a substantial amount of experimental time and incur high research and development costs. To accelerate the early development stage of LNPs, we propose TransLNP, a transformer-based transfection prediction model designed to aid in the selection of LNPs for mRNA drug delivery systems. TransLNP uses two types of molecular information to perceive the relationship between structure and transfection efficiency: coarse-grained atomic sequence information and fine-grained atomic spatial relationship information. Due to the scarcity of existing LNPs experimental data, we find that pretraining the molecular model is crucial for better understanding the task of predicting LNPs properties, which is achieved through reconstructing atomic 3D coordinates and masking atom predictions. In addition, the issue of data imbalance is particularly prominent in the real-world exploration of LNPs. We introduce the BalMol block to solve this problem by smoothing the distribution of labels and molecular features. Our approach outperforms state-of-the-art works in transfection property prediction under both random and scaffold data splitting. Additionally, we establish a relationship between molecular structural similarity and transfection differences, selecting 4267 pairs of molecular transfection cliffs, which are pairs of molecules that exhibit high structural similarity but significant differences in transfection efficiency, thereby revealing the primary source of prediction errors. The code, model and data are made publicly available at https://github.com/wklix/TransLNP. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kroll, A.
AU  - Ranjan, S.
AU  - Lercher, M.J.
TI  - A multimodal Transformer Network for protein-small molecule interactions enhances predictions of kinase inhibition and enzymesubstrate relationships
PY  - 2024
T2  - PLoS Computational Biology
VL  - 20
IS  - 5 May
C7  - e1012100
DO  - 10.1371/journal.pcbi.1012100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193578428&doi=10.1371%2fjournal.pcbi.1012100&partnerID=40&md5=68b0c2ce7b84f1e3e81020464fad5596
AB  - The activities of most enzymes and drugs depend on interactions between proteins and small molecules. Accurate prediction of these interactions could greatly accelerate pharmaceutical and biotechnological research. Current machine learning models designed for this task have a limited ability to generalize beyond the proteins used for training. This limitation is likely due to a lack of information exchange between the protein and the small molecule during the generation of the required numerical representations. Here, we introduce Pro- Smith, a machine learning framework that employs a multimodal Transformer Network to simultaneously process protein amino acid sequences and small molecule strings in the same input. This approach facilitates the exchange of all relevant information between the two molecule types during the computation of their numerical representations, allowing the model to account for their structural and functional interactions. Our final model combines gradient boosting predictions based on the resulting multimodal Transformer Network with independent predictions based on separate deep learning representations of the proteins and small molecules. The resulting predictions outperform recently published state-of-theart models for predicting protein-small molecule interactions across three diverse tasks: predicting kinase inhibitions; inferring potential substrates for enzymes; and predicting Michaelis constants KM. The Python code provided can be used to easily implement and improve machine learning predictions involving arbitrary protein-small molecule interactions.  © 2024 Kroll et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wagner, A.
TI  - Genotype sampling for deep-learning assisted experimental mapping of a combinatorially complete fitness landscape
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 5
C7  - btae317
DO  - 10.1093/bioinformatics/btae317
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194960200&doi=10.1093%2fbioinformatics%2fbtae317&partnerID=40&md5=b2851aeeae1f585ee639df90704b3422
AB  - Motivation: Experimental characterization of fitness landscapes, which map genotypes onto fitness, is important for both evolutionary biology and protein engineering. It faces a fundamental obstacle in the astronomical number of genotypes whose fitness needs to be measured for any one protein. Deep learning may help to predict the fitness of many genotypes from a smaller neural network training sample of genotypes with experimentally measured fitness. Here I use a recently published experimentally mapped fitness landscape of more than 260 000 protein genotypes to ask how such sampling is best performed. Results: I show that multilayer perceptrons, recurrent neural networks, convolutional networks, and transformers, can explain more than 90% of fitness variance in the data. In addition, 90% of this performance is reached with a training sample comprising merely ≈103 sequences. Generalization to unseen test data is best when training data is sampled randomly and uniformly, or sampled to minimize the number of synonymous sequences. In contrast, sampling to maximize sequence diversity or codon usage bias reduces performance substantially. These observations hold for more than one network architecture. Simple sampling strategies may perform best when training deep learning neural networks to map fitness landscapes from experimental data. © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Zeng, X.
AU  - Zhou, J.
AU  - Liu, F.
AU  - Luan, X.
AU  - Wang, X.
TI  - BERT-TFBS: a novel BERT-based model for predicting transcription factor binding sites by transfer learning
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 3
C7  - bbae195
DO  - 10.1093/bib/bbae195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192125220&doi=10.1093%2fbib%2fbbae195&partnerID=40&md5=88b9e00a0ab39ca5e8fd693641868db8
AB  - Transcription factors (TFs) are proteins essential for regulating genetic transcriptions by binding to transcription factor binding sites (TFBSs) in DNA sequences. Accurate predictions of TFBSs can contribute to the design and construction of metabolic regulatory systems based on TFs. Although various deep-learning algorithms have been developed for predicting TFBSs, the prediction performance needs to be improved. This paper proposes a bidirectional encoder representations from transformers (BERT)-based model, called BERT-TFBS, to predict TFBSs solely based on DNA sequences. The model consists of a pre-trained BERT module (DNABERT-2), a convolutional neural network (CNN) module, a convolutional block attention module (CBAM) and an output module. The BERT-TFBS model utilizes the pre-trained DNABERT-2 module to acquire the complex long-term dependencies in DNA sequences through a transfer learning approach, and applies the CNN module and the CBAM to extract high-order local features. The proposed model is trained and tested based on 165 ENCODE ChIP-seq datasets. We conducted experiments with model variants, cross-cell-line validations and comparisons with other models. The experimental results demonstrate the effectiveness and generalization capability of BERT-TFBS in predicting TFBSs, and they show that the proposed model outperforms other deep-learning models.  © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bian, M.
AU  - Ren, Y.
AU  - He, G.
AU  - Feng, G.
AU  - Zhang, X.
TI  - VMMP: Verifiable privacy-preserving multi-modal multi-task prediction
PY  - 2024
T2  - Information Sciences
VL  - 669
C7  - 120547
DO  - 10.1016/j.ins.2024.120547
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189608457&doi=10.1016%2fj.ins.2024.120547&partnerID=40&md5=db12f5869e8c14caefc5773fcf81d24c
AB  - Transformer is emerging as a promising model with intrinsic traits in various multi-modal applications. Edge computing has provided an efficient platform for computationally-weak clients, but this entails risks to confidential data and proprietary models. Prior works on the privacy-preserving transformer-based inference only process a single modal data and protect confidential data or model parameters, or approximate non-linear functions with utility degradation. To mitigate the aforementioned issues, we propose the first verifiable outsourcing framework for multi-modal multi-task prediction (VMMP) via the additive secret sharing technique in an edge computing paradigm, which not only ensures the confidentiality of local data and model parameters but also guarantees the verifiability of prediction results. The security analysis and computational consumption reveal that VMMP can save the time costs of clients by 87%, 30%, and 40% compared to the original model on three types of cross-modal tasks and achieves significant time cost savings on the client side compared to the previous works in a secure manner. To evaluate the effective utility, VMMP is examined on three public datasets across visual and language modalities. Extensive evaluations indicate that VMMP outperforms the related works without utility degradation. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Bian2024VMMP
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Luo, Y.
AU  - Lu, X.
AU  - Gao, H.
AU  - He, R.
AU  - Zhang, X.
AU  - Zhang, X.
AU  - Li, Y.
TI  - Genotypic-phenotypic landscape computation based on first principle and deep learning
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 3
C7  - bbae191
DO  - 10.1093/bib/bbae191
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192131041&doi=10.1093%2fbib%2fbbae191&partnerID=40&md5=9bae3a78f193e59127daa78bffc6a8bf
AB  - The relationship between genotype and fitness is fundamental to evolution, but quantitatively mapping genotypes to fitness has remained challenging. We propose the Phenotypic-Embedding theorem (P-E theorem) that bridges genotype-phenotype through an encoder-decoder deep learning framework. Inspired by this, we proposed a more general first principle for correlating genotype-phenotype, and the P-E theorem provides a computable basis for the application of first principle. As an application example of the P-E theorem, we developed the Co-attention based Transformer model to bridge Genotype and Fitness model, a Transformer-based pre-train foundation model with downstream supervised fine-tuning that can accurately simulate the neutral evolution of viruses and predict immune escape mutations. Accordingly, following the calculation path of the P-E theorem, we accurately obtained the basic reproduction number of SARS-CoV-2 from first principles, quantitatively linked immune escape to viral fitness and plotted the genotype-fitness landscape. The theoretical system we established provides a general and interpretable method to construct genotype-phenotype landscapes, providing a new paradigm for studying theoretical and computational biology.  © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ji, H.
AU  - Wang, X.-X.
AU  - Zhang, Q.
AU  - Zhang, C.
AU  - Zhang, H.-M.
TI  - Predicting TCR sequences for unseen antigen epitopes using structural and sequence features
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 3
C7  - bbae210
DO  - 10.1093/bib/bbae210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192588344&doi=10.1093%2fbib%2fbbae210&partnerID=40&md5=2e36e42a097a9357237dfe3aa4e2d9ab
AB  - T-cell receptor (TCR) recognition of antigens is fundamental to the adaptive immune response. With the expansion of experimental techniques, a substantial database of matched TCR-antigen pairs has emerged, presenting opportunities for computational prediction models. However, accurately forecasting the binding affinities of unseen antigen-TCR pairs remains a major challenge. Here, we present convolutional-self-attention TCR (CATCR), a novel framework tailored to enhance the prediction of epitope and TCR interactions. Our approach utilizes convolutional neural networks to extract peptide features from residue contact matrices, as generated by OpenFold, and a transformer to encode segment-based coded sequences. We introduce CATCR-D, a discriminator that can assess binding by analyzing the structural and sequence features of epitopes and CDR3-β regions. Additionally, the framework comprises CATCR-G, a generative module designed for CDR3-β sequences, which applies the pretrained encoder to deduce epitope characteristics and a transformer decoder for predicting matching CDR3-β sequences. CATCR-D achieved an AUROC of 0.89 on previously unseen epitope-TCR pairs and outperformed four benchmark models by a margin of 17.4%. CATCR-G has demonstrated high precision, recall and F1 scores, surpassing 95% in bidirectional encoder representations from transformers score assessments. Our results indicate that CATCR is an effective tool for predicting unseen epitope-TCR interactions. Incorporating structural insights enhances our understanding of the general rules governing TCR-epitope recognition significantly. The ability to predict TCRs for novel epitopes using structural and sequence information is promising, and broadening the repository of experimental TCR-epitope data could further improve the precision of epitope-TCR binding predictions.  © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Rollins, Z.A.
AU  - Widatalla, T.
AU  - Waight, A.
AU  - Cheng, A.C.
AU  - Metwally, E.
TI  - AbLEF: antibody language ensemble fusion for thermodynamically empowered property predictions
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 5
C7  - btae268
DO  - 10.1093/bioinformatics/btae268
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192409657&doi=10.1093%2fbioinformatics%2fbtae268&partnerID=40&md5=b59cb2e1f4c6a1ca479e389b8e090256
AB  - Motivation: Pre-trained protein language and/or structural models are often fine-tuned on drug development properties (i.e. developability properties) to accelerate drug discovery initiatives. However, these models generally rely on a single structural conformation and/or a single sequence as a molecular representation. We present a physics-based model, whereby 3D conformational ensemble representations are fused by a transformer-based architecture and concatenated to a language representation to predict antibody protein properties. Antibody language ensemble fusion enables the direct infusion of thermodynamic information into latent space and this enhances property prediction by explicitly infusing dynamic molecular behavior that occurs during experimental measurement. Results: We showcase the antibody language ensemble fusion model on two developability properties: hydrophobic interaction chromatography retention time and temperature of aggregation (Tagg). We find that (i) 3D conformational ensembles that are generated from molecular simulation can further improve antibody property prediction for small datasets, (ii) the performance benefit from 3D conformational ensembles matches shallow machine learning methods in the small data regime, and (iii) fine-tuned large protein language models can match smaller antibody-specific language models at predicting antibody properties. © 2024 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Ni, Y.
AU  - Chen, G.
AU  - Feng, Z.
AU  - Cui, H.
AU  - Metaxas, D.
AU  - Zhang, S.
AU  - Zhu, W.
TI  - DA-Tran: Multiphase liver tumor segmentation with a domain-adaptive transformer network
PY  - 2024
T2  - Pattern Recognition
VL  - 149
C7  - 110233
DO  - 10.1016/j.patcog.2023.110233
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182400093&doi=10.1016%2fj.patcog.2023.110233&partnerID=40&md5=b8c94e03135493d131697bc82ec0d086
AB  - Accurate liver tumor segmentation from multiphase CT images is a prerequisite for data-driven tumor analysis. This study presents a domain-adaptive transformer (DA-Tran) network to segment liver tumors from each CT phase. First, a DA module is designed to produce domain-adapted feature maps from noncontrast-enhanced (NC)-phase, arterial (ART)-phase, portal venous (PV)-phase, and delay-phase (DP) images. Then, these domain-adapted feature maps are integrated using 3D transformer blocks to catch patch-structured similarity information and global context attention. Finally, the attention fusion decoder (AFD) integrates features from different branches to generate a more refined prediction. Extensive experimental results demonstrate that DA-Tran achieves state-of-the-art tumor segmentation results, i.e., a Dice similarity coefficient (DSC) of 87.00% and a 95% Hausdorff distance (HD95) of 5.10 mm on a clinical dataset (DB1). Additionally, DA-Tran consistently outperforms other cutting-edge methods on another multiphase liver tumor dataset (DB2). The DA module and transformer blocks can boost the co-segmentation performance and make DA-Tran an ideal solution for multiphase liver tumor segmentation. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, B.
AU  - He, C.
AU  - Wang, P.
AU  - Chan, C.-Y.
AU  - Liu, X.
AU  - Chen, Y.
TI  - TPPO: A Novel Trajectory Predictor With Pseudo Oracle
PY  - 2024
T2  - IEEE Transactions on Systems, Man, and Cybernetics: Systems
VL  - 54
IS  - 5
SP  - 2846
EP  - 2859
DO  - 10.1109/TSMC.2024.3351859
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184316571&doi=10.1109%2fTSMC.2024.3351859&partnerID=40&md5=517be93530b92807965234108343b907
AB  - Forecasting pedestrian trajectories in dynamic scenes remains a critical problem in various applications, such as autonomous driving and socially aware robots. Such forecasting is challenging due to human-human and human-object interactions and future uncertainties caused by human randomness. Generative model-based methods handle future uncertainties by sampling a latent variable. However, few studies explored the generation of the latent variable. In this work, we propose the trajectory predictor with pseudo Oracle (TPPO), which is a generative model-based trajectory predictor. The first pseudo oracle is pedestrians' moving directions, and the second one is the latent variable estimated from ground truth trajectories. A social attention module is used to aggregate neighbors' interactions based on the correlation between pedestrians' moving directions and future trajectories. This correlation is inspired by the fact that pedestrians' future trajectories are often influenced by pedestrians in front. A latent variable predictor is proposed to estimate latent variable distributions from observed and ground-truth trajectories. Moreover, the gap between these two distributions is minimized during training. Therefore, the latent variable predictor can estimate the latent variable from observed trajectories to approximate that estimated from ground-truth trajectories. We compare the performance of TPPO with related methods on several public datasets. Results demonstrate that TPPO outperforms state-of-the-art methods with low average and final displacement errors. The ablation study shows that the prediction performance will not dramatically decrease as sampling times decline during tests.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; AJG:3; zdy:3; 
LB  - Yang2024TPPO
ER  -

TY  - JOUR
AU  - Kennedy, C.
AU  - Crowdis, T.
AU  - Hu, H.
AU  - Vaidyanathan, S.
AU  - Zhang, H.-K.
TI  - Data-driven learning of chaotic dynamical systems using Discrete-Temporal Sobolev Networks
PY  - 2024
T2  - Neural Networks
VL  - 173
C7  - 106152
DO  - 10.1016/j.neunet.2024.106152
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185252744&doi=10.1016%2fj.neunet.2024.106152&partnerID=40&md5=c4df50988083a7677d33a010aa2acd43
AB  - We introduce the Discrete-Temporal Sobolev Network (DTSN), a neural network loss function that assists dynamical system forecasting by minimizing variational differences between the network output and the training data via a temporal Sobolev norm. This approach is entirely data-driven, architecture agnostic, and does not require derivative information from the estimated system. The DTSN is particularly well suited to chaotic dynamical systems as it minimizes noise in the network output which is crucial for such sensitive systems. For our test cases we consider discrete approximations of the Lorenz-63 system and the Chua circuit. For the network architectures we use the Long Short-Term Memory (LSTM) and the Transformer. The performance of the DTSN is compared with the standard MSE loss for both architectures, as well as with the Physics Informed Neural Network (PINN) loss for the LSTM. The DTSN loss is shown to substantially improve accuracy for both architectures, while requiring less information than the PINN and without noticeably increasing computational time, thereby demonstrating its potential to improve neural network forecasting of dynamical systems. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Peng, P.
AU  - Zhang, J.
AU  - Wang, H.
AU  - Shen, W.
TI  - SCCAM: Supervised Contrastive Convolutional Attention Mechanism for Ante-Hoc Interpretable Fault Diagnosis With Limited Fault Samples
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 5
SP  - 6194
EP  - 6205
DO  - 10.1109/TNNLS.2023.3313728
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173054202&doi=10.1109%2fTNNLS.2023.3313728&partnerID=40&md5=63acaf5898978c925bfb929b8db9a68d
AB  - In real industrial processes, fault diagnosis methods are required to learn from limited fault samples since the procedures are mainly under normal conditions and the faults rarely occur. Although attention mechanisms have become increasingly popular for the task of fault diagnosis, the existing attention-based methods are still unsatisfying for the above practical applications. First, pure attention-based architectures like transformers need a substantial quantity of fault samples to offset the lack of inductive biases thus performing poorly under limited fault samples. Moreover, the poor fault classification dilemma further leads to the failure of the existing attention-based methods to identify the root causes. To develop a solution to the aforementioned problems, we innovatively propose a supervised contrastive convolutional attention mechanism (SCCAM) with ante-hoc interpretability, which solves the root cause analysis problem under limited fault samples for the first time. First, accurate classification results are obtained under limited fault samples. More specifically, we integrate the convolutional neural network (CNN) with attention mechanisms to provide strong intrinsic inductive biases of locality and spatial invariance, thereby strengthening the representational power under limited fault samples. In addition, we ulteriorly enhance the classification capability of the SCCAM method under limited fault samples by employing the supervised contrastive learning (SCL) loss. Second, a novel ante-hoc interpretable attention-based architecture is designed to directly obtain the root causes without expert knowledge. The convolutional block attention module (CBAM) is utilized to directly provide feature contributions behind each prediction thus achieving feature-level explanations. The proposed SCCAM method is testified on a continuous stirred tank heater (CSTH) and the Tennessee Eastman (TE) industrial process benchmark. Three common fault diagnosis scenarios are covered, including a balanced scenario for additional verification and two scenarios with limited fault samples (i.e., imbalanced scenario and long-tail scenario). The effectiveness of the presented SCCAM method is evidenced by the comprehensive results that show our method outperforms the state-of-the-art methods in terms of fault classification and root cause analysis.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, H.
AU  - Deng, F.
AU  - Liang, J.
AU  - Yang, J.
TI  - Stochastic Non-Autoregressive Transformer-Based Multi-Modal Pedestrian Trajectory Prediction for Intelligent Vehicles
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3561
EP  - 3574
DO  - 10.1109/TITS.2023.3342040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181818146&doi=10.1109%2fTITS.2023.3342040&partnerID=40&md5=adf2a2e89976d4ceca7e95593c36ede9
AB  - Pedestrian trajectory prediction, which aims at predicting the future positions of all pedestrians in a crowd scene given their past trajectories, is the cornerstone of autonomous driving and intelligent transportation systems. Accurate prediction and fast inference are both indispensable for real-world applications. In this paper, we propose a stochastic non-autoregressive Transformer-based multi-modal trajectory prediction model to address the two challenges. Specifically, a novel graph attention module dedicated to joint learning of social and temporal interaction is proposed to explore the complex interaction among pedestrians while integrating sparse attention mechanism, pedestrian identity, and temporal order contained in the trajectory data. By doing so, the interaction across temporal and social dimensions can be simultaneously processed to extract abundant context features for prediction. Besides, to accelerate inference speed, we put forward a stochastic non-autoregressive Transformer model with multi-modal prediction capability where each future trajectory can be inferred in a parallel fashion, therefore, resulting in diverse trajectory predictions and less computational cost. Extensive experiments and ablation studies are performed to evaluate our approach. The empirical results demonstrate that the proposed model not only produces high prediction accuracy but also infers with fast speed. The code of the proposed method will be publicly available at https://github.com/xbchen82/SNARTF. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2024Stochastic
ER  -

TY  - JOUR
AU  - Wan, J.
AU  - Xia, N.
AU  - Yin, Y.
AU  - Pan, X.
AU  - Hu, J.
AU  - Yi, J.
TI  - TCDformer: A transformer framework for non-stationary time series forecasting based on trend and change-point detection
PY  - 2024
T2  - Neural Networks
VL  - 173
C7  - 106196
DO  - 10.1016/j.neunet.2024.106196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186476386&doi=10.1016%2fj.neunet.2024.106196&partnerID=40&md5=b802c15f3912c54da745075a2342f72c
AB  - Although time series prediction models based on Transformer architecture have achieved significant advances, concerns have arisen regarding their performance with non-stationary real-world data. Traditional methods often use stabilization techniques to boost predictability, but this often results in the loss of non-stationarity, notably underperforming when tackling major events in practical applications. To address this challenge, this research introduces an innovative method named TCDformer (Trend and Change-point Detection Transformer). TCDformer employs a unique strategy, initially encoding abrupt changes in non-stationary time series using the local linear scaling approximation (LLSA) module. The reconstructed contextual time series is then decomposed into trend and seasonal components. The final prediction results are derived from the additive combination of a multilayer perceptron (MLP) for predicting trend components and wavelet attention mechanisms for seasonal components. Comprehensive experimental results show that on standard time series prediction datasets, TCDformer significantly surpasses existing benchmark models in terms of performance, reducing MSE by 47.36% and MAE by 31.12%. This approach offers an effective framework for managing non-stationary time series, achieving a balance between performance and interpretability, making it especially suitable for addressing non-stationarity challenges in real-world scenarios. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, T.
AU  - Zeng, Z.
AU  - Li, Q.
AU  - Sun, S.
TI  - Integrating GIN-based multimodal feature transformation and multi-feature combination voting for irony-aware cyberbullying detection
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 3
C7  - 103651
DO  - 10.1016/j.ipm.2024.103651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182016789&doi=10.1016%2fj.ipm.2024.103651&partnerID=40&md5=c4a557be75eef99d149a56aa42f3da4c
AB  - With the increasing diversity of expressions, irony-aware cyberbullying has emerged as a significant issue in online social networks. However, detecting irony-aware cyberbullying is challenging, as it requires a comprehensive understanding of context and external factors beyond literal meanings. To take full advantage of multiple features of multimodal data to detect challenging irony-aware cyberbullying, we propose an integration framework (GINBV_MFCV). The multimodal feature construction method with Graph Isomorphism Network (GIN) feature transformation (GINBV) leverages the message passing and aggregation operations of GIN to extract the potential representations of text-image features, which enriches the structural information of multimodal data. In addition, the multi-feature combination voting strategy (MFCV) soft-votes the prediction results of constructed multimodal features and multiple combinations of GIN, Bidirectional Encoder Representations from Transformers (BERT), and Vision Transformers (ViT) embedded features to reduce the data structure information bias, which has a positive effect on irony-aware cyberbullying detection. Experimental results on a real-world dataset from Weibo demonstrate that GINBV_MFCV achieves an F1-score of 83.29% and an AUC of 91.21% in irony-aware cyberbullying detection, improving 8.65% and 15.73% over the baseline algorithm, respectively. These promising results confirm the potential of GINBV_MFCV for detecting irony-aware cyberbullying. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Govers, W.
AU  - Yurtman, A.
AU  - Aslandere, T.
AU  - Eikelenberg, N.
AU  - Meert, W.
AU  - Davis, J.
TI  - Time-Shifted Transformers for Driver Identification Using Vehicle Data
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3767
EP  - 3776
DO  - 10.1109/TITS.2023.3326652
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181563911&doi=10.1109%2fTITS.2023.3326652&partnerID=40&md5=e8d6a36fe55a89ded82f5194f2ab9f67
AB  - A modern vehicle contains a large number of electronic control units and sensors that are connected to cloud environments. These electronic units generate a huge amount of data that can be leveraged to identify the current driver and adapt to their behavior. For example, driver identification can improve the accuracy of range estimation in battery electric vehicles. This study focuses on identifying drivers based on their behaviour by using multivariate time series data acquired by the sensors available in the vehicle. We propose two different classifiers: one based on Bi-directional stacked Long Short-Term Memory with Attention mechanism (BiLSTM-A) and another based on a Modified Time Series Transformer (MTST). We perform driver identification in two different ways: 1) by applying a classifier on a single time segment; and 2) by using our proposed time-shift ensembles to combine predictions made from multiple time segments. We experimentally evaluate the proposed techniques on a publicly available dataset that comprises 10 drivers. By using all appropriate features, the proposed BiLSTM-A and MTST classifiers identify the driver with an accuracy of 55% and 73%, respectively, from a single time segment of 60 seconds duration. Time-shift ensembles increase the accuracy substantially, to 92% for BiLSTM-A and 97% for MTST when a 460-second time period is used for each prediction. We conclude that the proposed MTST classifier outperforms BiLSTM-A and existing classifiers in the driver identification task, and time-shift ensembles substantially improve the accuracy.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Govers2024Time-Shifted
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Zhang, J.
AU  - Yang, L.
AU  - Wang, C.
AU  - Gao, Z.
TI  - COV-STFormer for Short-Term Passenger Flow Prediction during COVID-19 in Urban Rail Transit Systems
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3793
EP  - 3811
DO  - 10.1109/TITS.2023.3323379
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174831981&doi=10.1109%2fTITS.2023.3323379&partnerID=40&md5=c6cbb160c59d7278ad2cb36ab2255dc6
AB  - Accurate passenger flow prediction of urban rail transit systems (URT) is essential for improving the performance of intelligent transportation systems, especially during the epidemic. How to dynamically model the complex spatiotemporal dependencies of passenger flow is the main issue in achieving accurate passenger flow prediction during the epidemic. To solve this issue, this paper proposes a brand-new transformer-based architecture called COVID-19 Spatial-Temporal Transformer Network (COV-STFormer) under the encoder-decoder framework specifically for COVID-19. Concretely, a modified self-Attention mechanism named Causal-Convolution ProbSparse Self-Attention (CPSA) is developed to model the complex temporal dependencies of passenger flow. A novel Adaptive Multi-Graph Convolution Network (AMGCN) is introduced to capture the complex and dynamic spatial dependencies by leveraging multiple graphs in a self-Adaptive manner. Additionally, the Multi-source Data Fusion block fuses the passenger flow data, COVID-19 confirmed case data, and the relevant social media data to study the impact of COVID-19 to passenger flow. Experiments on real-world passenger flow datasets demonstrate the superiority of COV-STFormer over the other thirteen state-of-The-Art methods. Several ablation studies are carried out to verify the effectiveness and reliability of our model structure. Results can provide critical insights for the operation of URT systems.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2024COV-STFormer
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Li, J.
AU  - Wu, J.
AU  - Chang, J.
AU  - Liu, D.
AU  - Zhu, K.
TI  - Flexibly utilizing syntactic knowledge in aspect-based sentiment analysis
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 3
C7  - 103630
DO  - 10.1016/j.ipm.2023.103630
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182021580&doi=10.1016%2fj.ipm.2023.103630&partnerID=40&md5=aa45ebc9e47673f4c421b6d3e5ba7ff8
AB  - Aspect-based sentiment analysis (ABSA) refers to ascertaining the propensity of sentiment expressed in a text towards a particular aspect. While previous models have utilized dependency graphs and GNNs to facilitate information exchange, they face challenges such as smoothing of aspect representation and a gap between word-based dependency graphs and subword-based BERT. Taking into account the above deficiencies, we argue for a new approach called SRE-BERT that flexibly utilizes syntax knowledge to enhance aspect representations by relying on syntax representations. First, we propose a syntax representation encoder to acquire the syntactic vector for each token. Then, we devise a syntax-guided transformer that employs syntax representation to compute multi-head attention, thereby enabling direct syntactic interaction between any two tokens. Finally, the token-level vectors derived from the syntax-guided transformer are employed to enhance the semantic representations obtained by BERT. In addition, during the aforementioned process, we introduced a Masked POS Label Prediction (MPLP) method to pre-train the syntax encoder. A wide range of studies have been undertaken on data collections covering three distinct fields, and the results indicate that our SRE-BERT outperforms the second-ranked model by 1.97%, 1.55%, and 1.20% on the Rest14, Lap14, and Twitter 3 datasets, respectively. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Liao, Z.
AU  - Zhou, W.
AU  - Li, H.
TI  - DaFIR: Distortion-Aware Representation Learning for Fisheye Image Rectification
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 5
SP  - 3606
EP  - 3618
DO  - 10.1109/TCSVT.2023.3315967
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171568537&doi=10.1109%2fTCSVT.2023.3315967&partnerID=40&md5=217c9c570ca048e3f3d257b9b69ef4e7
AB  - This paper focuses on fisheye image rectification. Existing learning-based solutions learn image representations that mix distortion features and content features. Since the distortion feature dominates the rectification process, we propose a novel distortion-aware representation learning framework, which decouples the distortion feature from the content feature, for fisheye image rectification. Specifically, we first pre-train a Vision Transformer with a supervised pre-text task, which regresses the distortion distribution map of a distorted image. The pre-training equips the Vision Transformer with the ability to capture distortion-related patterns. After that, the pre-trained model is fine-tuned to predict the pixel-wise flow map to rectify the fisheye images. Extensive experiments are conducted to evaluate our approach and verify our idea of feature decoupling. The experiment results demonstrate the state-of-the-art performance of our approach compared to existing algorithms, as well as its generality on real-world images. Our source code is publicly available at https://github.com/lzk9508/DaFIR.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Deng, C.
AU  - Wang, X.
AU  - Li, Z.
AU  - Zheng, C.
AU  - Wang, J.
AU  - Li, B.
TI  - Joint inter-word and inter-sentence multi-relation modeling for summary-based recommender system
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 3
C7  - 103631
DO  - 10.1016/j.ipm.2023.103631
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182028882&doi=10.1016%2fj.ipm.2023.103631&partnerID=40&md5=2a03a08223463e9f6fb17fb00f918934
AB  - Review is an essential piece of information that influences users’ decisions, but excessively long reviews not only degrade the user experience but also affect the accuracy of the recommender system. Therefore, Joint Inter-Word and Inter-Sentence Multi-Relation Modeling for the Summary-based Recommender System (MRSR) is proposed in this paper. In MRSR, the concise summary information serves as representation data, and a multi-relation modeling module is designed to construct user and item characteristics from two levels. Specifically, the inter-word relation modeling module, which consists of the Transformer and the pooling layer, is used to learn the long dependencies of summaries and extract word-level features by calculating the relative weights between words within sentences. The inter-sentence relation modeling module is used to enrich the sentence-level features of users and items, where an attention mechanism is employed to perceive the relative weights between different summary sentences. Finally, the fusion layer based on multi-head attention and the prediction layer based on attentional factorization machine are implemented to conduct the shallow and deep interactions between user and item features, based on which MRSR completes the final rating prediction. Extensive experimental results on five publicly available datasets demonstrate that MRSR achieves a 5.94% improvement in RMSE metrics compared to state-of-the-art methods. Furthermore, the accuracy of most existing models is improved by 1%∼2% while the inference time is reduced by 10% by utilizing summaries as representation data. It proves the efficiency and effectiveness of our proposed approach, which has promising application prospects. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Yang, J.
AU  - Chu, D.
AU  - Yin, J.
AU  - Pi, D.
AU  - Wang, J.
AU  - Lu, L.
TI  - Distributed Model Predictive Control for Heterogeneous Platoon with Leading Human-Driven Vehicle Acceleration Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3944
EP  - 3959
DO  - 10.1109/TITS.2023.3330941
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177997556&doi=10.1109%2fTITS.2023.3330941&partnerID=40&md5=1ff75152736f61504d5122f9418bcf93
AB  - Heterogeneous vehicle platoons, consisting of a human-driven vehicle (HDV) as the leader and connected automated vehicles (CAVs) as followers, present a promising solution to address various challenges arising from fully autonomous driving. In this paper, we propose a novel LSTM-based distributed model predictive control (DMPC) platooning method. Initially, we develop and train a vehicle acceleration prediction model based on a long short-Term memory (LSTM) network using real-world driving data. Subsequently, the predicted acceleration sequence of the leading HDV is integrated into the DMPC-based platoon control model for the following CAVs. To validate the effectiveness of our method, we conduct simulation experiments using real-world driving data. The results demonstrate that, with a time headway of 1 s, the maximum speed error and maximum spacing error of the heterogeneous vehicle platoon using the proposed LSTM-based DMPC are reduced by at least 5.8% and 5.9%, respectively, compared to the traditional DMPC method. Furthermore, the LSTM-based DMPC outperforms the Transformer-based DMPC method, resulting in a 1.0% reduction in maximum speed error and a 0.7% reduction in maximum spacing error. The proposed method effectively dampens oscillation caused by the leading HDV and enhances tracking accuracy.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2024Distributed
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Zhou, W.
AU  - Mao, Y.
AU  - Li, H.
TI  - Detect Any Shadow: Segment Anything for Video Shadow Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 5
SP  - 3782
EP  - 3794
DO  - 10.1109/TCSVT.2023.3320688
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173400392&doi=10.1109%2fTCSVT.2023.3320688&partnerID=40&md5=ebb0ac5b26e70c8aeb88c3b722d149da
AB  - Segment anything model (SAM) has achieved great success in the field of natural image segmentation. Nevertheless, SAM tends to consider shadows as background and therefore does not perform segmentation on them. In this paper, we propose ShadowSAM, a simple yet effective framework for fine-tuning SAM to detect shadows. Besides, by combining it with long short-term attention mechanism, we extend its capability for efficient video shadow detection. Specifically, we first fine-tune SAM on ViSha training dataset by utilizing the bounding boxes obtained from the ground truth shadow mask. Then during the inference stage, we simulate user interaction by providing bounding boxes to detect a specific frame (e.g., the first frame). Subsequently, using the detected shadow mask as a prior, we employ a long short-term network to learn spatial correlations between distant frames and temporal consistency between adjacent frames, thereby achieving precise shadow information propagation across video frames. Extensive experimental results demonstrate the effectiveness of our method, with notable margin over the state-of-the-art approaches in terms of MAE and IoU metrics. Moreover, our method exhibits accelerated inference speed compared to previous video shadow detection approaches, validating the effectiveness and efficiency of our method. The source code is now publicly available at https://github.com/harrytea/Detect-AnyShadow. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Liu, H.
AU  - Jing, L.
TI  - Transparent Embedding Space for Interpretable Image Recognition
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 5
SP  - 3204
EP  - 3219
DO  - 10.1109/TCSVT.2023.3314769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171595092&doi=10.1109%2fTCSVT.2023.3314769&partnerID=40&md5=4fd2719f87bc47498ffdf9cb4d1d6af7
AB  - When humans explain their reasoning, such as their classification decisions, they often break down an image into parts and highlight the evidence from those parts to support the concepts they have in mind. Drawing inspiration from this cognitive process, several self-explaining models have been proposed to explain predictions by part-level concepts. However, these models can be limited by their structure and difficulty in determining the effect of individual parts on the output category. To address these challenges, we introduce a self-explaining architecture that uses a plug-in transparent embedding space (TesNet) to connect high-level input patches (e.g. feature maps or tokens) with output categories. The transparent embedding space is spanned by basis concepts and constructed on the Grassmann manifold. The basis concepts are enforced to be category-aware, and within-category concepts are orthogonal to each other, ensuring the embedding space is disentangled. To reduce concept redundancy and restore the concept space structure, we introduce two concept pruning methods and a new re-training strategy to build a slimming transparent embedding space. We verify the scalability of TesNet through experiments on deep networks such as VGG, ResNet, DenseNet, and Vision Transformer. Additionally, we design several metrics for self-explaining models to quantify interpretability and compare them with state-of-the-art self-explaining methods. Our experiments demonstrate that TesNet is much more effective for classification tasks, providing better interpretability on predictions and improving final accuracy.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Unger, M.
AU  - Wedel, M.
AU  - Tuzhilin, A.
TI  - Predicting consumer choice from raw eye-movement data using the RETINA deep learning architecture
PY  - 2024
T2  - Data Mining and Knowledge Discovery
VL  - 38
IS  - 3
SP  - 1069
EP  - 1100
DO  - 10.1007/s10618-023-00989-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180908106&doi=10.1007%2fs10618-023-00989-7&partnerID=40&md5=b9bac962bc3365c5ffa03f203152519b
AB  - We propose the use of a deep learning architecture, called RETINA, to predict multi-alternative, multi-attribute consumer choice from eye movement data. RETINA directly uses the complete time series of raw eye-tracking data from both eyes as input to state-of-the art Transformer and Metric Learning Deep Learning methods. Using the raw data input eliminates the information loss that may result from first calculating fixations, deriving metrics from the fixations data and analysing those metrics, as has been often done in eye movement research, and allows us to apply Deep Learning to eye tracking data sets of the size commonly encountered in academic and applied research. Using a data set with 112 respondents who made choices among four laptops, we show that the proposed architecture outperforms other state-of-the-art machine learning methods (standard BERT, LSTM, AutoML, logistic regression) calibrated on raw data or fixation data. The analysis of partial time and partial data segments reveals the ability of RETINA to predict choice outcomes well before participants reach a decision. Specifically, we find that using a mere 5 s of data, the RETINA architecture achieves a predictive validation accuracy of over 0.7. We provide an assessment of which features of the eye movement data contribute to RETINA’s prediction accuracy. We make recommendations on how the proposed deep learning architecture can be used as a basis for future academic research, in particular its application to eye movements collected from front-facing video cameras. © The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ke, X.
AU  - Miao, X.
AU  - Guo, W.
TI  - U-Transformer-based multi-levels refinement for weakly supervised action segmentation
PY  - 2024
T2  - Pattern Recognition
VL  - 149
C7  - 110199
DO  - 10.1016/j.patcog.2023.110199
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182390263&doi=10.1016%2fj.patcog.2023.110199&partnerID=40&md5=fedff5dcbd84a9fb2311c4a0dcf6a576
AB  - Action segmentation is a research hotspot in human action analysis, which aims to split videos into segments of different actions. Recent algorithms have achieved great success in modeling based on temporal convolution, but these methods weight local or global timing information through additional modules, ignoring the existing long-term and short-term information connections between actions. This paper proposes a U-Transformer structure based on multi-level refinement, introduces neighborhood attention to learn the neighborhood information of adjacent frames, and aggregates video frame features to effectively process long-term sequence information. Then a loss optimization strategy is proposed to smooth the original classification effect and generate a more accurate calibration sequence by introducing a pairing similarity optimization method based on deep feature learning. In addition, we propose a timestamp supervised training method to generate complete information for actions based on pseudo-label predictions for action boundary predictions. Experiments on three challenging action segmentation datasets, 50Salads, GTEA, and Breakfast, show that our model performs state-of-the-art models, and our weakly supervised model also performs comparably to fully supervised performance. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ouyang, J.
AU  - Yu, M.
AU  - Yu, W.
AU  - Qin, Z.
AU  - Regan, A.C.
AU  - Wu, D.
TI  - TPGraph: A Spatial-Temporal Graph Learning Framework for Accurate Traffic Prediction on Arterial Roads
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 5
SP  - 3911
EP  - 3926
DO  - 10.1109/TITS.2023.3334558
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181577965&doi=10.1109%2fTITS.2023.3334558&partnerID=40&md5=4c280e5135012b3bb6cc723af6bb8cdb
AB  - The accurate prediction of traffic conditions, including speed, flow, and travel time, poses a critical challenge in urbanization that significantly impacts car owners and road administrators. However, in certain scenarios with restricted road data availability (e.g. lack of traffic light status and signal control strategies, cooperation between road administrators and third parties, etc.), it is imperative to make effective use of basic road information (e.g. historical traffic data and road connectivity) to improve both prediction accuracy and scalability on various arterial road networks against state-of-art deep learning models. In this paper, we propose a spatial-temporal learning framework TPGraph for an accurate prediction of arterial roads' traffic data by effectively utilizing upstream and downstream road information. TPGraph is composed of three major parts: 1) A multi-scale temporal feature fusion module that utilizes a multi-head attention mechanism to integrate recently-periodic features, daily-periodic features, and weekly-periodic features; 2) A multi-graph convolution module that employs graph fusion and graph convolution networks to capture richer spatial semantics, and 3) A dynamic spatial-temporal prediction module that leverages a spatial-temporal transformer for single or multiple traffic-state predictions. Our proposed framework, TPGraph, leverages just multi-scale historical traffic conditions and readily accessible spatial factors as input to generate accurate predictions of future traffic conditions. We mainly evaluate the performance of our approach through multi-step prediction experiments conducted at hourly intervals, forecasting travel time or travel speed for each road at 15 mins, 30 mins, and 1 hour. Furthermore, we conduct extensive experiments on real-world arterial road datasets to demonstrate the superior predictive performance of TPGraph compared to existing methods. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Ouyang2024TPGraph
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Wang, L.
TI  - MSRMNet: Multi-scale skip residual and multi-mixed features network for salient object detection
PY  - 2024
T2  - Neural Networks
VL  - 173
C7  - 106144
DO  - 10.1016/j.neunet.2024.106144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184777975&doi=10.1016%2fj.neunet.2024.106144&partnerID=40&md5=547b18cbbb54810b96c71981ef78c7c1
AB  - The current models for the salient object detection (SOD) have made remarkable progress through multi-scale feature fusion strategies. However, the existing models have large deviations in the detection of different scales, and the target boundaries of the prediction images are still blurred. In this paper, we propose a new model addressing these issues using a transformer backbone to capture multiple feature layers. The model uses multi-scale skip residual connections during encoding to improve the accuracy of the model's predicted object position and edge pixel information. Furthermore, to extract richer multi-scale semantic information, we perform multiple mixed feature operations in the decoding stage. In addition, we add the structure similarity index measure (SSIM) function with coefficients in the loss function to enhance the accurate prediction performance of the boundaries. Experiments demonstrate that our algorithm achieves state-of-the-art results on five public datasets, and improves the performance metrics of the existing SOD tasks. Codes and results are available at: https://github.com/xxwudi508/MSRMNet. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Chen, Y.
AU  - Wang, J.
TI  - Dual-Path Transformer for 3D Human Pose Estimation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 5
SP  - 3260
EP  - 3270
DO  - 10.1109/TCSVT.2023.3318557
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173300825&doi=10.1109%2fTCSVT.2023.3318557&partnerID=40&md5=62605b367f065561d7961f6b37fd4734
AB  - Video-based 3D human pose estimation has achieved great progress, however, it is still difficult to learn precise 2D-3D projection under some hard cases. Multi-level human knowledge and motion information serve as two key elements in the field to conquer the challenges caused by various factors, where the former encodes various human structure information spatially and the latter captures the motion change temporally. Inspired by this, we propose a DualFormer (dual-path transformer) network which encodes multiple human contexts and motion detail to perform the spatial-temporal modeling. Firstly, motion information which depicts the movement change of human body is embedded to provide explicit motion prior for the transformer module. Secondly, a dual-path transformer framework is proposed to model long-range dependencies of both joint sequence and limb sequence. Parallel context embedding is performed initially and a cross transformer block is then appended to promote the interaction of the dual paths which improves the feature robustness greatly. Specifically, predictions of multiple levels can be acquired simultaneously. Lastly, we employ the weighted distillation technique to accelerate the convergence of the dual-path framework. We conduct extensive experiments on three different benchmarks, i.e., Human 3.6M, MPI-INF-3DHP and HumanEva-I. We mainly compute the MPJPE, P-MPJPE, PCK and AUC to evaluate the effectiveness of proposed approach and our work achieves competitive results compared with state-of-the-art approaches. Specifically, the MPJPE is reduced to 42.8mm which is 1.5mm lower than PoseFormer on Human3.6M, which proves the efficacy of the proposed approach. © 2024 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, P.
AU  - Yang, X.
AU  - Zhang, R.
AU  - Huang, K.
TI  - Continuous Image Outpainting with Neural ODE
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 7
C7  - 203
DO  - 10.1145/3648367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193687841&doi=10.1145%2f3648367&partnerID=40&md5=59afa4c6f960812afc7540606d0ba591
AB  - Generalised image outpainting is an important and active research topic in computer vision, which aims to extend appealing content all-side around a given image. Existing state-of-the-art outpainting methods often rely on discrete extrapolation to extend the feature map in the bottleneck. They thus suffer from content unsmoothness, especially in circumstances where the outlines of objects in the extrapolated regions are incoherent with the input sub-images. To mitigate this issue, we design a novel bottleneck with Neural ODEs to make continuous extrapolation in latent space, which could be a plug-in for many deep learning frameworks. Our ODE-based network continuously transforms the state and makes accurate predictions by learning the incremental relationship among latent points, leading to both smooth and structured feature representation. Experimental results on three real-world datasets both applied on transformer-based and CNN-based frameworks show that our methods could generate more realistic and coherent images against the state-of-the-art image outpainting approaches. Our code is available at https://github.com/PengleiGao/Continuous-Image-Outpainting-with-Neural-ODE. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shi, F.
AU  - Huang, W.
AU  - Wang, L.
TI  - End-to-end dense video grounding via parallel regression
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 242
C7  - 103980
DO  - 10.1016/j.cviu.2024.103980
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187226595&doi=10.1016%2fj.cviu.2024.103980&partnerID=40&md5=29fd76d250f7fbdf9ea58c9fcea17782
AB  - Video grounding aims to localize the corresponding moment in an untrimmed video given a sentence description. Existing methods often address this task in an indirect “one-to-many” way, i.e., predicting more than one proposal for one sentence description, by casting it as a propose-and-match or fusion-and-detection problem. Solving these surrogate problems often requires sophisticated label assignment during training and hand-crafted removal of near-duplicate results. Meanwhile, existing works typically focus on sparse video grounding with a single sentence as input, which could result in ambiguous localization due to its unclear description. In this paper, we tackle a new problem of dense video grounding, by simultaneously localizing multiple moments with a paragraph as input. From a perspective on video grounding as language-conditioned regression, we present an end-to-end parallel decoding paradigm by re-purposing a Transformer-alike architecture (PRVG). The key design in our PRVG is to use languages as queries, and regress only one temporal boundary for each sentence based on language-modulated visual representations. Thanks to its simplicity in design, our PRVG framework predicts in a “one-to-one” manner, getting rid of complicated label assignment during training and allowing for efficient inference without any post-processing technique. In addition, we devise a robust proposal-level attention loss to guide the training of PRVG, which is invariant to moment duration and contributes to model convergence. We perform experiments on two benchmarks, namely ActivityNet Captions and TACoS, demonstrating the superiority of PRVG. We also perform in-depth studies to investigate the effectiveness of the parallel regression paradigm on video grounding. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Pan, J.
AU  - Dai, J.
AU  - Sun, Z.
AU  - Xiao, Y.
TI  - Self-Supervised Lightweight Depth Estimation in Endoscopy Combining CNN and Transformer
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 5
SP  - 1934
EP  - 1944
DO  - 10.1109/TMI.2024.3352390
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182377136&doi=10.1109%2fTMI.2024.3352390&partnerID=40&md5=722c9464510d991d4006be6cef46c763
AB  - In recent years, an increasing number of medical engineering tasks, such as surgical navigation, pre-operative registration, and surgical robotics, rely on 3D reconstruction techniques. Self-supervised depth estimation has attracted interest in endoscopic scenarios because it does not require ground truth. Most existing methods depend on expanding the size of parameters to improve their performance. There, designing a lightweight self-supervised model that can obtain competitive results is a hot topic. We propose a lightweight network with a tight coupling of convolutional neural network (CNN) and Transformer for depth estimation. Unlike other methods that use CNN and Transformer to extract features separately and then fuse them on the deepest layer, we utilize the modules of CNN and Transformer to extract features at different scales in the encoder. This hierarchical structure leverages the advantages of CNN in texture perception and Transformer in shape extraction. In the same scale of feature extraction, the CNN is used to acquire local features while the Transformer encodes global information. Finally, we add multi-head attention modules to the pose network to improve the accuracy of predicted poses. Experiments demonstrate that our approach obtains comparable results while effectively compressing the model parameters on two datasets.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yuan, J.
AU  - Zhu, A.
AU  - Xu, Q.
AU  - Wattanachote, K.
AU  - Gong, Y.
TI  - CTIF-Net: A CNN-Transformer Iterative Fusion Network for Salient Object Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 5
SP  - 3795
EP  - 3805
DO  - 10.1109/TCSVT.2023.3321190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174814831&doi=10.1109%2fTCSVT.2023.3321190&partnerID=40&md5=9b7b46df4a705aa6de7370b343f80280
AB  - Capturing sufficient global context and rich spatial structure information is critical for dense prediction tasks. Convolutional Neural Network (CNN) is particularly adept at modeling fine-grained local features, while Transformer excels at modeling global context information. It is evident that CNN and Transformer exhibit complementary characteristics. Exploring the design of a network, that efficiently fuses these two models to leverage their strengths fully and achieve more accurate detection, represents a promising and worthwhile research topic. In this paper, we introduce a novel CNN-Transformer Iterative Fusion Network (CTIF-Net) for salient object detection. It efficiently combines CNN and Transformer to achieve superior performance by using a parallel dual encoder structure and a feature iterative fusion module. Firstly, CTIF-Net extracts features from the image using the CNN and the Transformer, respectively. Secondly, two feature convertors and a feature iterative fusion module are employed to combine and iteratively refine the two sets of features. The experimental results on multiple SOD datasets show that CTIF-Net outperforms 17 state-of-the-art methods, achieving higher performance in various mainstream evaluation metrics such as F-measure, S-measure, and MAE value. Code can be found at https://github.com/danielfaster/CTIF-Net/. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xia, Y.
AU  - Luo, J.
AU  - Zhou, G.
AU  - Lan, M.
AU  - Chen, X.
AU  - Chen, J.
TI  - DT4KGR: Decision transformer for fast and effective multi-hop reasoning over knowledge graphs
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 3
C7  - 103648
DO  - 10.1016/j.ipm.2024.103648
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183708414&doi=10.1016%2fj.ipm.2024.103648&partnerID=40&md5=b6e5575033d03888fae586bd80cee019
AB  - Multi-hop reasoning over knowledge graphs has received plenty of attention from researchers and is being widely applied to facilitate the development of recommender systems, question answering systems, and other information retrieval systems. Existing multi-hop reasoning methods tend to suffer from poor training efficiency as a result of the large search space and have difficulty tackling missing paths during the reasoning process. Accordingly, we propose a sequence-to-sequence model called DT4KGR, in which an encoder–decoder Transformer framework was designed for knowledge graph reasoning. We trained our Transformer model using teacher forcing, so the model processes the entire sequence of reasoning paths in a highly parallel fashion. In this way, faster training speeds are achieved. The model conditions an autoregressive architecture to implement sequence path generation, rather than preceding path exploration, thus performed more robustly to missing paths. We also designed a rule-guided path exploration strategy by combining the local path semantic similarity with the attention mechanism and the global graph information with rule guidance, to sample high-quality training paths for our model. We evaluated DT4KGR through various tasks on seven different real-world datasets. The experimental results reveal DT4KGR achieves better link prediction results compared with the state-of-the-art baseline models while converging 5–8 times faster, especially achieving an approximately 7.8% relative improvement for MRR on NELL-995 dataset. In addition, efficiency studies indicate our model performs better scalability in large-scale knowledge graph environments compared with other methods. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Sataer, Y.
AU  - Fan, Y.
AU  - Li, B.
AU  - Gao, M.
AU  - Shi, C.
AU  - Gao, Z.
TI  - Hierarchical information matters! Improving AMR parsing with multi-granularity representation interactions
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 3
C7  - 103698
DO  - 10.1016/j.ipm.2024.103698
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186590421&doi=10.1016%2fj.ipm.2024.103698&partnerID=40&md5=77c51b89a02c66612a6f7537f42f9299
AB  - Meaning Representation (AMR) parsing aims to automatically translate text into a directed and acyclic semantic graph, which recently has been improved significantly by Transformer-based pre-trained models (e.g., BART and T5). However, the existing parsers still encounter errors, particularly in graph structure prediction and concept abstraction, that substantially distort text meaning. In this paper, we attempt to alleviate these issues in AMR parsing by incorporating the hierarchical structure of the input text into pre-trained models. We first present a hierarchical multi-granularity (HMG) schema to describe the hierarchical structures of the given text, containing a sentence-clause-phrase-word hierarchy. Furthermore, we propose a hierarchical multi-granularity AMR parsing framework (HMG-AMR) based on a Transformer, which explicitly integrates the HMG schema of the input text. Specifically, we introduce new inductive biases and enhance the interactions among multi-granularity representations (i.e., words, phrases, clauses and sentences) by modifying the attention mechanisms in the encoder and the decoder. We conduct extensive experiments on two public in-distribution benchmarks (i.e., AMR2.0 and AMR3.0), on three out-of-distribution benchmarks (i.e., Bio, New3, and TLP), and in several few-shot settings. The results show that HMG-AMR outperforms the solid baseline by up to 1.4% and 1.1% in terms of the Smatch scores attained on AMR2.0 and AMR3.0, respectively. In addition, HMG-AMR exhibits notable advantages in out-of-distribution and few-shot settings, showing its ability to compensate for insufficient data and adapt to diverse domains. Most notably, further analyses involving 10 linguistic probing tasks verify that incorporating the HMG schema allows the model to capture distinct linguistic properties, demonstrating the universality of the proposed framework and its potential for application in other tasks. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Dotan, E.
AU  - Jaschek, G.
AU  - Pupko, T.
AU  - Belinkov, Y.
TI  - Effect of tokenization on transformers for biological sequences
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 4
DO  - 10.1093/bioinformatics/btae196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191660346&doi=10.1093%2fbioinformatics%2fbtae196&partnerID=40&md5=6c69bd1bfa85210837939a3ec5bfc187
AB  - Motivation: Deep-learning models are transforming biological research, including many bioinformatics and comparative genomics algorithms, such as sequence alignments, phylogenetic tree inference, and automatic classification of protein functions. Among these deep-learning algorithms, models for processing natural languages, developed in the natural language processing (NLP) community, were recently applied to biological sequences. However, biological sequences are different from natural languages, such as English, and French, in which segmentation of the text to separate words is relatively straightforward. Moreover, biological sequences are characterized by extremely long sentences, which hamper their processing by current machine-learning models, notably the transformer architecture. In NLP, one of the first processing steps is to transform the raw text to a list of tokens. Deep-learning applications to biological sequence data mostly segment proteins and DNA to single characters. In this work, we study the effect of alternative tokenization algorithms on eight different tasks in biology, from predicting the function of proteins and their stability, through nucleotide sequence alignment, to classifying proteins to specific families. Results: We demonstrate that applying alternative tokenization algorithms can increase accuracy and at the same time, substantially reduce the input length compared to the trivial tokenizer in which each character is a token. Furthermore, applying these tokenization algorithms allows interpreting trained models, taking into account dependencies among positions. Finally, we trained these tokenizers on a large dataset of protein sequences containing more than 400 billion amino acids, which resulted in over a 3-fold decrease in the number of tokens. We then tested these tokenizers trained on large-scale data on the above specific tasks and showed that for some tasks it is highly beneficial to train database-specific tokenizers. Our study suggests that tokenizers are likely to be a critical component in future deep-network analysis of biological sequence data. Availability and implementation: Code, data, and trained tokenizers are available on https://github.com/technion-cs-nlp/BiologicalTokenizers. # The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Ding, F.
AU  - Kang, X.
AU  - Ren, F.
TI  - Neuro or Symbolic? Fine-Tuned Transformer With Unsupervised LDA Topic Clustering for Text Sentiment Analysis
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 2
SP  - 493
EP  - 507
DO  - 10.1109/TAFFC.2023.3279318
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195238357&doi=10.1109%2fTAFFC.2023.3279318&partnerID=40&md5=ed967a1bd107cea66567280bd1851a07
AB  - For text sentiment analysis, state-of-the-art neural language models have demonstrated promising performance. However, they lack interpretability, require vast volumes of annotated data, and are typically specialized for tasks. In this article, we explore a connection between fine-tuned Transformer models and unsupervised LDA approach to cope with text sentiment analysis tasks, inspired by the concept of Neuro-symbolic AI. The Transformer and LDA models are combined as a feature extractor to extract the hidden representations of the input text sequences. Subsequently, we employ a feedforward network to forecast various sentiment analysis tasks, such as multi-label emotion prediction, dialogue quality prediction, and nugget detection. Our proposed method obtains the best results in the NTCIR-16 dialogue evaluation (DialEval-2) task, as well as cutting-edge results in emotional intensity prediction using the Ren_CECps corpus. Extensive experiments show that our proposed method is highly explainable, cost-effective in training, and superior in terms of accuracy and robustness.  © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Rai, P.
AU  - Jain, A.
AU  - Kumar, S.
AU  - Sharma, D.
AU  - Jha, N.
AU  - Chawla, S.
AU  - Raj, A.
AU  - Gupta, A.
AU  - Poonia, S.
AU  - Majumdar, A.
AU  - Chakraborty, T.
AU  - Ahuja, G.
AU  - Sengupta, D.
TI  - Literature mining discerns latent disease–gene relationships
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 4
DO  - 10.1093/bioinformatics/btae185
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192028844&doi=10.1093%2fbioinformatics%2fbtae185&partnerID=40&md5=137ae04a07a25ee19b8be5249b441e38
AB  - Motivation: Dysregulation of a gene’s function, either due to mutations or impairments in regulatory networks, often triggers pathological states in the affected tissue. Comprehensive mapping of these apparent gene–pathology relationships is an ever-daunting task, primarily due to genetic pleiotropy and lack of suitable computational approaches. With the advent of high throughput genomics platforms and community scale initiatives such as the Human Cell Landscape project, researchers have been able to create gene expression portraits of healthy tissues resolved at the level of single cells. However, a similar wealth of knowledge is currently not at our finger-tip when it comes to diseases. This is because the genetic manifestation of a disease is often quite diverse and is confounded by several clinical and demographic covariates. Results: To circumvent this, we mined 18 million PubMed abstracts published till May 2019 and automatically selected 4.5 million of them that describe roles of particular genes in disease pathogenesis. Further, we fine-tuned the pretrained bidirectional encoder representations from transformers (BERT) for language modeling from the domain of natural language processing to learn vector representation of entities such as genes, diseases, tissues, cell-types, etc., in a way such that their relationship is preserved in a vector space. The repurposed BERT predicted disease–gene associations that are not cited in the training data, thereby highlighting the feasibility of in silico synthesis of hypotheses linking different biological entities such as genes and conditions. Availability and implementation: PathoBERT pretrained model: https://github.com/Priyadarshini-Rai/Pathomap-Model. BioSentVec-based abstract classification model: https://github.com/Priyadarshini-Rai/Pathomap-Model. Pathomap R package: https://github.com/Priyadarshini-Rai/Pathomap. # The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Zisser, M.
AU  - Aran, D.
TI  - Transformer-based time-to-event prediction for chronic kidney disease deterioration
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 4
SP  - 980
EP  - 990
DO  - 10.1093/jamia/ocae025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189782327&doi=10.1093%2fjamia%2focae025&partnerID=40&md5=7450fc64e41f2b35ea5821b5f3460da2
AB  - Objective: Deep-learning techniques, particularly the Transformer model, have shown great potential in enhancing the prediction performance of longitudinal health records. Previous methods focused on fixed-time risk prediction, however, time-to-event prediction is often more appropriate for clinical scenarios. Here, we present STRAFE, a generalizable survival analysis Transformer-based architecture for electronic health records. Materials and Methods: The input for STRAFE is a sequence of visits with SNOMED-CT codes in OMOP-CDM format. A Transformer-based architecture was developed to calculate probabilities of the occurrence of the event in each of 48 months. Performance was evaluated using a real-world claims dataset of over 130 000 individuals with stage 3 chronic kidney disease (CKD). Results: STRAFE showed improved mean absolute error (MAE) compared to other time-to-event algorithms in predicting the time to deterioration to stage 5 CKD. Additionally, STRAFE showed an improved area under the receiver operating curve compared to binary outcome algorithms. We show that STRAFE predictions can improve the positive predictive value of high-risk patients by 3-fold. Finally, we suggest a novel visualization approach to predictions on a per-patient basis. Discussion: Time-to-event predictions are the most appropriate approach for clinical predictions. Our deep-learning algorithm outperformed not only other time-to-event prediction algorithms but also fixed-time algorithms, possibly due to its ability to train on censored data. We demonstrated possible clinical usage by identifying the highest-risk patients. Conclusions: The ability to accurately identify patients at high risk and prioritize their needs can result in improved health outcomes, reduced costs, and more efficient use of resources.  © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Nguyen, H.
AU  - Kim, C.
AU  - Li, F.
TI  - Space–time recurrent memory network
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 241
C7  - 103943
DO  - 10.1016/j.cviu.2024.103943
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184843569&doi=10.1016%2fj.cviu.2024.103943&partnerID=40&md5=5d8b1bf39a794f942865ba57a0baad92
AB  - Transformers have recently been popular for learning and inference in the spatial–temporal domain. However, their performance relies on storing and applying attention to the feature tensor of each frame in video. Hence, their space and time complexity increase linearly as the length of video grows, which could be very costly for long videos. We propose a novel visual memory network architecture for the learning and inference problem in the spatial–temporal domain. We maintain a fixed set of memory slots in our memory network and propose an algorithm based on Gumbel-Softmax to learn an adaptive strategy to update this memory. Finally, this architecture is benchmarked on the video object segmentation (VOS) and video prediction problems. We demonstrate that our memory architecture achieves state-of-the-art results, outperforming transformer-based methods on VOS and other recent methods on video prediction while maintaining constant memory capacity independent of the sequence length. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, M.
AU  - Janson, B.
AU  - Peng, Y.
TI  - A spatiotemporal deep learning approach for pedestrian crash risk prediction based on POI trip characteristics and pedestrian exposure intensity
PY  - 2024
T2  - Accident Analysis and Prevention
VL  - 198
C7  - 107493
DO  - 10.1016/j.aap.2024.107493
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185306410&doi=10.1016%2fj.aap.2024.107493&partnerID=40&md5=373ef853b8d813b65307ebba6832c765
AB  - Pedestrians represent a population of vulnerable road users who are directly exposed to complex traffic conditions, thereby increasing their risk of injury or fatality. This study first constructed a multidimensional indicator to quantify pedestrian exposure, considering factors such as Point of Interest (POI) attributes, POI intensity, traffic volume, and pedestrian walkability. Following risk interpolation and feature engineering, a comprehensive data source for risk prediction was formed. Finally, based on risk factors, the VT-NET deep learning network model was proposed, integrating the algorithmic characteristics of the VGG16 deep convolutional neural network and the Transformer deep learning network. The model involved training non-temporal features and temporal features separately. The training dataset incorporated features such as weather conditions, exposure intensity, socioeconomic factors, and the built environment. By employing different training methods for different types of causative feature variables, the VT-NET model analyzed changes in risk features and separately trained temporal and non-temporal risk variables. It was used to generate spatiotemporal grid-level predictions of crash risk across four spatiotemporal scales. The performance of the VT-NET model was assessed, revealing its efficacy in predicting pedestrian crash risks across the study area. The results indicated that areas with concentrated crash risks are primarily located in the city center and persist for several hours. These high-risk areas dissipate during the late night and early morning hours. High-risk areas were also found to cluster in the city center; this clustering behavior was more prominent during weekends compared to weekdays and coincided with commercial zones, public spaces, and educational and medical facilities. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Guo2024spatiotemporal
ER  -

TY  - JOUR
AU  - Li, Z.-J.
AU  - Cheng, D.-J.
AU  - Zhang, H.-B.
AU  - Zhou, K.-L.
AU  - Wang, Y.-F.
TI  - Multi-feature spaces cross adaption transfer learning-based bearings piece-wise remaining useful life prediction under unseen degradation data
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 60
C7  - 102413
DO  - 10.1016/j.aei.2024.102413
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185411294&doi=10.1016%2fj.aei.2024.102413&partnerID=40&md5=61b193a8715bf2cd58f9f0acfc46099e
AB  - In actual industry, rolling bearings always exhibit complex and uncertain degradation processes, and it is difficult to collect sufficient full lifecycle data, resulting in the remaining useful life (RUL) prognosis performance deterioration. In this study, we propose a novel multi-feature spaces cross adaption transfer learning-based piece-wise adaptive RUL prediction method to address these issues. A novel multistage transition point identification method is developed with a combination of adaptive gradient iterative partitioning (AGIP) algorithm and degradation indicator gradient to accurately detect the transition points of each degradation stage. Then, a novel physics degradation rate-informed (PDRI) RUL labeling method is deduced to reflect the realistic of degradation process through calculating the multistage degradation rate. Based on these, the multi-feature spaces cross adaption transformer network (MSCATN)-based piece-wise adaptive RUL prediction model is established to transfer degradation knowledge learned from source domain to unlabeled incomplete target domain. Meanwhile, a joint loss function based on gradient norm balancing is designed to ensure the predicted RUL is consistent with the realistic physics degradation process. Extensive cross-domain transfer prognostics cases were designed on the XJTU-SY dataset to validate the proposed method. Comparison results manifest that the proposed method outperforms other traditional methods and can significantly improve RUL prediction accuracy under unseen degradation data. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Haruna, A.
AU  - Yang, M.
AU  - Jiang, P.
AU  - Ren, H.
TI  - Collaborative task of entity and relation recognition for developing a knowledge graph to support knowledge reasoning for design for additive manufacturing
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 60
C7  - 102364
DO  - 10.1016/j.aei.2024.102364
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184995161&doi=10.1016%2fj.aei.2024.102364&partnerID=40&md5=a4c2a042ed8303822b18a21f046e7ae1
AB  - Additive Manufacturing (AM) is gaining acceptance as a strategic manufacturing technique and technology for allowing new product development. Due to the lack of knowledge, design for additive manufacturing (DFAM) is now a major challenge in utilizing AM's product innovation and manufacturing capabilities. The AM sector will benefit from developing an intuitive knowledge reasoning method by constructing a Knowledge Graph (KG). We presented Bidirectional Encoder Representations from the Transformers (BERT) model for collaborative entity/relation recognition to address the issue, allowing us to study and utilize the advantages of AM through knowledge reasoning for Fused Deposition Modeling (FDM) based DFAM. First, the model analyzes preprocessed text to find and extract entities. Then, the relation recognition procedure based on dependency parsing extracts the semantic relationships between the entities. To convert word segments into vectors and improve dependency parsing, we used Continuous-Bag-of-Words (CBOW) to process texts. Therefore, this allowed us to anticipate the probability output of the center word based on the n − 1 words around the input. The extracted knowledge is then visualized as a graph and stored in the Neo4j database. Following the methods above creates a KG for the FDM-based DFAM knowledge. It can be shown that BERT is a good option for handling knowledge-driven issues needing specialists by extracting the process knowledge from text data using our suggested model. We provide evidence demonstrating the model's ability to set reasonable limitations on its predictions through a KG. Additionally, we use experiments and an application case study to demonstrate the effectiveness and competitiveness of our approach. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Peng, Y.
AU  - Zhang, G.
AU  - Shi, J.
AU  - Li, X.
AU  - Zheng, L.
TI  - MRGTraj: A Novel Non-Autoregressive Approach for Human Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 4
SP  - 2318
EP  - 2331
DO  - 10.1109/TCSVT.2023.3307442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168657020&doi=10.1109%2fTCSVT.2023.3307442&partnerID=40&md5=9874b21604732c88619e7f677bd8059f
AB  - Forecasting human trajectory is an essential technology in intelligent surveillance systems, robot navigation systems, autonomous driving systems, etc. Most of the trajectory prediction models based on RNN and Transformers use autoregressive methods to generate future trajectories, which may accumulate displacement errors and are inefficient for training and testing. To address these problems, we propose a novel decoder named MRG decoder, which introduces a Mapping-Refinement-Generation structure to generate trajectory in a non-autoregressive manner. Furthermore, we design the MRGTraj trajectory prediction model based on the proposed MRG decoder. Firstly, we employ a Transformer as an encoder to extract encoded features from the past trajectory. Secondly, we introduce an interaction-aware latent code generator to learn a Gaussian distribution from the social context among pedestrians for latent code sampling. Finally, we feed the encoded features to the MRG decoder and sample the latent code multiple times from the learned Gaussian distribution, providing additional inputs to the MRG decoder to generate multiple socially acceptable future trajectories. Experimental results on two public datasets, ETH and UCY, validate the effectiveness of the MRGTraj model. Besides, the MRGTraj model achieves superior prediction performance, with improvements of 13.21% on FDE metrics and a 71.29% speed-up compared to state-of-the-art models. The code is available at https://github.com/wisionpeng/MRGTraj. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, J.-Y.
AU  - Zhang, Y.-M.
AU  - Yin, F.
AU  - Liu, C.-L.
TI  - Transformer-based stroke relation encoding for online handwriting and sketches
PY  - 2024
T2  - Pattern Recognition
VL  - 148
C7  - 110131
DO  - 10.1016/j.patcog.2023.110131
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178668440&doi=10.1016%2fj.patcog.2023.110131&partnerID=40&md5=ba27e07621b4244f203302bf94a4f507
AB  - Stroke classification for online handwriting and sketches, aimed at grouping strokes into different semantic categories, has drawn considerable attention due to its wide applications. This task is challenging since individual strokes look similar and are easily confused with each other. The key is to consider both the individual strokes and the contextual information jointly for making prediction. Previous methods are insufficient in modeling and exploiting complex contextual information of strokes. To overcome this limitation, we propose a Transformer-based model for Online Handwriting and Sketches (T-OHS), with novel relation encoding schemes to take advantage of temporal and spatial information in stroke sequence. Particularly, we introduce a coarse-to-fine hierarchical encoding approach based on the polar coordinate system for precisely modeling spatial relations between strokes. Experiments on three types of handwriting data, including online handwritten documents, diagrams, and sketches, demonstrate that our method is universal and provides state-of-the-art performance. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, D.
AU  - Wang, Y.
AU  - Liu, C.
AU  - Wang, K.
AU  - Yuan, X.
AU  - Yang, C.
TI  - Blackout Missing Data Recovery in Industrial Time Series Based on Masked-Former Hierarchical Imputation Framework
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 21
IS  - 2
SP  - 1138
EP  - 1150
DO  - 10.1109/TASE.2023.3287895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163484682&doi=10.1109%2fTASE.2023.3287895&partnerID=40&md5=2aaa3563f4ea10d7790f8a48aa06a5ba
AB  - In industrial processes, frequent communication failures and information corruption may result in the loss of entire blocks of industrial process data, which is also known as blackout missing data. The imperfect data of industrial time series impede the performance of subsequent modeling and control tasks. However, traditional matrix factorization or supervised learning data imputation methods are hardly applicable to the challenging task of recovering blackout missing data. The difficulty in imputing the blackout data stems from two major factors: the imputation process lacks the reference of co- evolutionary variables, and the blackout data have strong autocorrelation and drift in distribution. To address these issues, this paper develops a novel hierarchical imputation framework for recovering blackout data based on the masked transformer network (Masked-Former). First, a reconstruction block strategy with random masked points is innovatively proposed to improve the ability of the model to recover missing values under different working conditions for incomplete datasets. Then, based on the masked incomplete data set, the proposed method utilizes the local feature capture capability of convolutional networks and the sample-level long-range dependency capture capability of the self-attention mechanism to complete coarse-grained and fine-grained missing data imputation, respectively. Finally, extensive experiments are conducted to verify the superior performance of the proposed method on two real-world industrial data sets. Note to Practitioners - Inspired by the phenomenon that industrial process data often have missing data, this paper proposes a novel hierarchical imputation Masked-Former method for blackout missing data recovery. The method combines local data features with long-term time series dependency performance to improve completion performance. Then, the obtained completed data can help practitioners monitor the status of industrial field conditions. In addition, it is helpful to perform subsequent quality prediction and process monitoring tasks, allowing practitioners to quickly take preventative measures to avoid disasters and take corrective operations to return the plant to its normal operating range.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Rao, S.
AU  - Mamouei, M.
AU  - Salimi-Khorshidi, G.
AU  - Li, Y.
AU  - Ramakrishnan, R.
AU  - Hassaine, A.
AU  - Canoy, D.
AU  - Rahimi, K.
TI  - Targeted-BEHRT: Deep Learning for Observational Causal Inference on Longitudinal Electronic Health Records
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 4
SP  - 5027
EP  - 5038
DO  - 10.1109/TNNLS.2022.3183864
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133757812&doi=10.1109%2fTNNLS.2022.3183864&partnerID=40&md5=15dfc2783616899114317801336bae4c
AB  - Observational causal inference is useful for decision-making in medicine when randomized clinical trials (RCTs) are infeasible or nongeneralizable. However, traditional approaches do not always deliver unconfounded causal conclusions in practice. The rise of 'doubly robust' nonparametric tools coupled with the growth of deep learning for capturing rich representations of multimodal data offers a unique opportunity to develop and test such models for causal inference on comprehensive electronic health records (EHRs). In this article, we investigate causal modeling of an RCT-established causal association: the effect of classes of antihypertensive on incident cancer risk. We develop a transformer-based model, targeted bidirectional EHR transformer (T-BEHRT) coupled with doubly robust estimation to estimate average risk ratio (RR). We compare our model to benchmark statistical and deep learning models for causal inference in multiple experiments on semi-synthetic derivations of our dataset with various types and intensities of confounding. In order to further test the reliability of our approach, we test our model on situations of limited data. We find that our model provides more accurate estimates of relative risk [least sum absolute error (SAE) from ground truth] compared with benchmark estimations. Finally, our model provides an estimate of class-wise antihypertensive effect on cancer risk that is consistent with results derived from RCTs.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hasnul Hadi, M.H.
AU  - Ker, P.J.
AU  - Lee, H.J.
AU  - Leong, Y.S.
AU  - Thiviyanathan, V.A.
AU  - Hannan, M.A.
AU  - Jamaludin, M.Z.
AU  - Mahdi, M.A.
TI  - Measuring Color Index of Transformer Oil-Enabling Single-Wavelength Spectroscopy with Artificial Neural Network-Fuzzy Logic Model
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 21
IS  - 2
SP  - 1358
EP  - 1368
DO  - 10.1109/TASE.2023.3238645
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147301297&doi=10.1109%2fTASE.2023.3238645&partnerID=40&md5=7146fc473b04761fd08dc10f65230962
AB  - Conventionally, the color index of transformer oil is determined by a color comparator based on the American Society for Testing and Materials (ASTM) D 1500 standard. The equipment requires humans to operate, which leads to human error and limited number of samples tested per day. This work proposes the utilization of single-wavelength spectroscopy with 405 nm laser diode using artificial neural network (ANN) to determine the color index of transformer oil. Two ANN models were developed using data collected from 50 oil samples with different optical pathlengths of 1 to 10 mm, and laser output powers of 1 to 15 mW. The first model classified the input into different color indices and another model correlated the input parameters through regression analysis to determine the color index. A hybrid ANN-fuzzy logic model was also developed to improve the color index prediction. The root-mean-squared error (RMSE) obtained from the prediction by ANN regressor and ANN classifier are 0.5602 and 0.6416, respectively. The hybrid ANN-fuzzy logic model improves the RMSE especially for optical pathlengths < 5 mm, which is required for measuring samples with high color index. This proposed method reduces the dependency on complex optoelectronic hardware to obtain highly accurate results.Note to Practitioners - Unlike the conventional testing method for color index of transformer oil that requires human observation, the findings of this study enables the possibility of compact and smart portable device through the utilization of single wavelength spectroscopy with machine learning models. With no human involvement, more computational power with lesser hardware dependency, the maintenance cost and error can be reduced. This proposed method can potentially be applied to measure the color of other amber-colored liquid products such as olive oil, honey and others.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Do, T.D.
AU  - Nguyen, T.D.
AU  - Ta, V.C.
AU  - Anh, D.T.
AU  - Tran Thi, T.-H.
AU  - Phan, D.
AU  - Mai, S.T.
TI  - Dynamic weighted ensemble for diarrhoea incidence predictions
PY  - 2024
T2  - Machine Learning
VL  - 113
IS  - 4
SP  - 2129
EP  - 2152
DO  - 10.1007/s10994-023-06465-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177034813&doi=10.1007%2fs10994-023-06465-z&partnerID=40&md5=01cc2643ffce65ad66cb23fe90a7ec8b
AB  - Diarrhoea (DH) disease pose significant threats to national morbidity and mortality in Vietnam, especially on children. Being a climate sensitive disease, it has strong links to various meteorological factors like rainfalls or temperatures. Hence, together with global climate changes, the risk of diarrhoea has been increasing gradually while Vietnam is already a hotspot of diarrhoea worldwide. Thus, having an effective early warning system is becoming an urgent need. However, it has not been paid enough attention with very few research works, mainly focusing on quantilizing the relationships among various climate factors and diarrhoea incidences. Exploring more sophisticated machine learning techniques is therefore an interesting work towards more efficient and effective warning systems. This paper consists of two main contributions. First, many different state-of-the-art prediction models from traditional to most recent advantaged methods, e.g., SARIMA, SARIMAX, LSTM, CNN, Xgboost, SVM, LightGBM, Catboost, LightGBM, N-HiST, BlockRNN, TCN, TFT, or Transformer, are studied for predicting DH rates for a large number of locations (55 provinces) with different climates, geographics and socio-economy factors. It provides a useful view on the overall performances of different ML models on the prediction task, which is extremely useful for other researchers when developing early-warning systems for DH in other places. Second, we introduce a novel ensemble prediction model, called dynamic weighted ensemble (DWE), for further improving the DH prediction performance. DWE is a two layer ensemble approach. The first generates different meta models based on four base component models. The second layer employs a novel approach to predict the performances of all selected meta models and uses these predicted results to dynamically combine these models in a weighted scheme to produce final results. This is totally different to traditional ensemble approaches which only rely on fixed combinations of their components. To the best of our knowledge, DWE is also the first ensemble approach for diarrhoea prediction. Extensive experiments are conducted over all 55 provinces of Vietnam to demonstrate the performance of DWE and to reveal its important characteristics. © The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, F.
AU  - Sun, B.
AU  - Li, S.
TI  - Transformer-Augmented Network With Online Label Correction for Facial Expression Recognition
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 2
SP  - 593
EP  - 605
DO  - 10.1109/TAFFC.2023.3285231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163182655&doi=10.1109%2fTAFFC.2023.3285231&partnerID=40&md5=4fb20a83fb98e6167df15a9d14804d05
AB  - Facial expression recognition (FER) in the wild is extremely challenging due to occlusions, variant head poses under unconstrained conditions and incorrect annotations (e.g., label noise). In this article, we aim to improve the performance of in-the-wild FER with Transformers and online label correction. Different from pure CNNs based methods, we propose a Transformer-augmented network (TAN) to dynamically capture the relationships within each facial patch and across the facial patches. Specifically, the TAN translates a number of facial patch images into a set of visual feature sequences by a backbone convolutional neural network. The intra-patch Transformer is subsequently utilized to capture the most discriminative features within each visual feature sequence. The position-disentangled attention mechanism of the intra-patch Transformer is proposed to better incorporate the positional information for feature sequences. Furthermore, we propose the inter-patch Transformer to model the dependencies across these feature sequences. More importantly, we present the online label correction (OLC) framework to correct suspicious hard labels and accumulate soft labels based on the predictions of the model, which strengthens the robustness of our model against label noise. We validate our method on several widely-used datasets (RAF-DB, FERPlus, AffectNet), realistic occlusion and pose variation datasets, and synthetic noisy datasets. Extensive experiments on these benchmarks demonstrate that the proposed method performs favorably against state-of-the-art methods. The source code will be made publicly available.  © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, X.
AU  - Pang, Y.
AU  - Liu, Y.
AU  - Han, M.
AU  - Yu, J.
AU  - Wang, W.
AU  - Chen, Y.
TI  - Multimodal Visual-Semantic Representations Learning for Scene Text Recognition
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 7
DO  - 10.1145/3646551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193707049&doi=10.1145%2f3646551&partnerID=40&md5=aeb52f8c529ddb2a32699201e761899f
AB  - Scene Text Recognition (STR), the critical step in OCR systems, has attracted much attention in computer vision. Recent research on modeling textual semantics with Language Model (LM) has witnessed remarkable progress. However, LM only optimizes the joint probability of the estimated characters generated from the Vision Model (VM) in a single language modality, ignoring the visual-semantic relations in different modalities. Thus, LM-based methods can hardly generalize well to some challenging conditions, in which the text has weak or multiple semantics, arbitrary shape, and so on. To migrate the above issue, in this paper, we propose Multimodal Visual-Semantic Representations Learning for Text Recognition Network (MVSTRN) to reason and combine the multimodal visual-semantic information for accurate Scene Text Recognition. Specifically, our MVSTRN builds a bridge between vision and language through its unified architecture and has the ability to reason visual semantics by guiding the network to reconstruct the original image from the latent text representation, breaking the structural gap between vision and language. Finally, the tailored multimodal Fusion (MMF) module is motivated to combine the multimodal visual and textual semantics from VM and LM to make the final predictions. Extensive experiments demonstrate our MVSTRN achieves state-of-the-art performance on several benchmarks.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Singh, G.
AU  - Brahma, D.
AU  - Rai, P.
AU  - Modi, A.
TI  - Text-Based Fine-Grained Emotion Prediction
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 2
SP  - 405
EP  - 416
DO  - 10.1109/TAFFC.2023.3298405
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165893437&doi=10.1109%2fTAFFC.2023.3298405&partnerID=40&md5=2e59ded6309f4ab4b5467e2f0f195819
AB  - Text-based emotion prediction is an important task in the field of affective computing. Most prior work has been restricted to predicting emotions corresponding to a few high-level emotion classes. This paper explores and experiments with various techniques for fine-grained (27 classes) emotion predictiondagger†. In particular, 1) we present a method to incorporate multiple annotations from different raters, 2) we analyze the model's performance on fused emotion classes and with sub-sampled training data, 3) we present a method to leverage the correlations among the emotion categories, and 4) we propose a new framework for text-based fine-grained emotion prediction through emotion definition modeling. The emotion definition-based model outperforms the existing state-of-the-art for fine-grained emotion dataset GoEmotions. The approach involves a multi-task learning framework that models definitions of emotions as an auxiliary task while being trained on the primary task of emotion prediction. We model definitions using masked language modeling and class definition prediction tasks. We show that this trained model can be used for transfer learning on other benchmark datasets in emotion prediction with varying emotion label sets, domains, and sizes. The proposed models outperform the baselines on transfer learning experiments demonstrating the model's generalization capability. © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chawla, K.
AU  - Clever, R.
AU  - Ramirez, J.
AU  - Lucas, G.M.
AU  - Gratch, J.
TI  - Towards Emotion-Aware Agents for Improved User Satisfaction and Partner Perception in Negotiation Dialogues
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 2
SP  - 433
EP  - 444
DO  - 10.1109/TAFFC.2023.3238007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147301403&doi=10.1109%2fTAFFC.2023.3238007&partnerID=40&md5=e7c001789792af6ea19ba999141ec443
AB  - Negotiation is a complex social interaction that encapsulates emotional encounters in human decision-making. Virtual agents that can negotiate with humans by the means of language are useful in pedagogy and conversational AI. To advance the development of such agents, we explore the role of emotion in the prediction of two important subjective goals in a negotiation - outcome satisfaction and partner perception. We devise ways to measure and compare different degrees of emotion expression in negotiation dialogues, consisting of emoticon, lexical, and contextual variables. Through an extensive analysis of a large-scale dataset in chat-based negotiations, we find that incorporating emotion expression explains significantly more variance, above and beyond the demographics and personality traits of the participants. Further, our temporal analysis reveals that emotive information from both early and later stages of the negotiation contributes to this prediction, indicating the need for a continual learning model of capturing emotion for automated agents. Finally, we extend our analysis to another dataset, showing promise that our findings generalize to more complex scenarios. We conclude by discussing our insights, which will be helpful for designing adaptive negotiation agents that interact through realistic communication interfaces.  © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qin, L.
AU  - Wang, M.
AU  - Deng, C.
AU  - Wang, K.
AU  - Chen, X.
AU  - Hu, J.
AU  - Deng, W.
TI  - SwinFace: A Multi-Task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 4
SP  - 2223
EP  - 2234
DO  - 10.1109/TCSVT.2023.3304724
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168270997&doi=10.1109%2fTCSVT.2023.3304724&partnerID=40&md5=9ab950cec8df1d74d3740f5d78366cd4
AB  - In recent years, vision transformers have been introduced into face recognition and analysis and have achieved performance breakthroughs. However, most previous methods generally train a single model or an ensemble of models to perform the desired task, which ignores the synergy among different tasks and fails to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper presents a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, the SwinFace, consists of a single shared backbone together with a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97% accuracy on RAF-DB and 0.22 ϵ-error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shen, M.
AU  - Huang, R.
TI  - Backdoor Attacks with Wavelet Embedding: Revealing and enhancing the insights of vulnerabilities in visual object detection models on transformers within digital twin systems
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 60
C7  - 102355
DO  - 10.1016/j.aei.2024.102355
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182023471&doi=10.1016%2fj.aei.2024.102355&partnerID=40&md5=dbc86e060b26d7a2613e363b668ba7a0
AB  - Given the pervasive use of deep learning models across various domains, ensuring model security has emerged as a critical concern. This paper examines backdoor attacks, a form of security threat that compromises model output by poisoning the training data. Our investigation specifically addresses backdoor attacks on object detection models, vital for security-sensitive applications like autonomous driving and smart city systems. Consequently, such attacks on object detection models could pose significant risks to human life and property. Consequently, backdoor attacks on object detection could pose serious threats to human life and property. To elucidate this security risk, we propose and experimentally evaluate five backdoor attack methods for object detection models. The key findings are: (1) Unnecessary Object Generation: a globally embedded trigger creating false objects in the target class; (2) Partial Misclassification: a trigger causing specific class misclassification; (3) Global Misclassification: a trigger reclassifying all objects into the target class; (4) Specific Object Vanishing: a trigger causing non-detection of certain objects; (5) Object Position Shifting: a trigger causing bounding box shifts for a specific class. To assess attack effectiveness, we introduced the Attack Success Rate (ASR), which can surpass 1 in object detection tasks, thus providing a more accurate reflection of the attack impact. Experimental outcomes indicate that the ASR values of these varied backdoor attacks frequently approach or surpass 1, demonstrating our method's capacity to impact multiple objects simultaneously. Additionally, to augment trigger stealth, we introduce Backdoor Attack with Wavelet Embedding (BAWE), which discreetly embeds triggers as image watermarks in training data. This embedding method yields more natural triggers with enhanced stealth. Highly stealthy triggers are less detectable, significantly increasing the likelihood of attack success and efficacy. We have developed a Transformer-based network architecture, diverging from traditional neural network frameworks. Our experiments across various object detection datasets highlight the susceptibility of these models and the high success rate of our approaches. This vulnerability poses significant risks to digital twin systems utilizing object detection technology. Our methodology not only enhances trigger stealth but also suits dense predictive tasks and circumvents current neural network backdoor attack detection methods. The experimental findings expose key challenges in the security of object detection models, particularly when integrated with digital twins, offering new avenues for backdoor attack research and foundational insights for devising defense strategies against these attacks. © 2024 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, W.
AU  - Gao, Z.
AU  - Liu, H.
AU  - Zhang, H.
TI  - A Deformable Constraint Transport Network for Optimal Aortic Segmentation From CT Images
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 4
SP  - 1462
EP  - 1475
DO  - 10.1109/TMI.2023.3339142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179829295&doi=10.1109%2fTMI.2023.3339142&partnerID=40&md5=42fcf8430a7de7084d94ae2c9078c5c1
AB  - Aortic segmentation from computed tomography (CT) is crucial for facilitating aortic intervention, as it enables clinicians to visualize aortic anatomy for diagnosis and measurement. However, aortic segmentation faces the challenge of variable geometry in space, as the geometric diversity of different diseases and the geometric transformations that occur between raw and measured images. Existing constraint-based methods can potentially solve the challenge, but they are hindered by two key issues: inaccurate definition of properties and inappropriate topology of transformation in space. In this paper, we propose a deformable constraint transport network (DCTN). The DCTN adaptively extracts aortic features to define intra-image constrained properties and guides topological implementation in space to constrain inter-image geometric transformation between raw and curved planar reformation (CPR) images. The DCTN contains a deformable attention extractor, a geometry-aware decoder and an optimal transport guider. The extractor generates variable patches that preserve semantic integrity and long-range dependency in long-sequence images. The decoder enhances the perception of geometric texture and semantic features, particularly for low-intensity aortic coarctation and false lumen, which removes background interference. The guider explores the geometric discrepancies between raw and CPR images, constructs probability distributions of discrepancies, and matches them with inter-image transformation to guide geometric topology in space. Experimental studies on 267 aortic subjects and four public datasets show the superiority of our DCTN over 23 methods. The results demonstrate DCTN’s advantages in aortic segmentation for different types of aortic disease, for different aortic segments, and in the measurement of clinical indexes. © 2023 The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Q.
AU  - Zhang, S.
AU  - Meng, Q.
AU  - Zhong, B.
AU  - Liu, P.
AU  - Yao, H.
TI  - End-to-End Human Instance Matting
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 4
SP  - 2633
EP  - 2647
DO  - 10.1109/TCSVT.2023.3306400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168736676&doi=10.1109%2fTCSVT.2023.3306400&partnerID=40&md5=4e8f181a71583d4ae1404d37994325b7
AB  - Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspondences of all instances. Finally, an instance matting network decodes the image features and united semantics guidance to predict all instance-level alpha mattes. In addition, we construct a large-scale human instance matting dataset (HIM-100K) comprising over 100,000 human images with instance alpha matte labels. Experiments on HIM-100K demonstrate the proposed E2E-HIM outperforms the existing methods on human instance matting with 50% lower errors and 5× faster speed (6 instances in a 640 × 640 image). Experiments on the PPM-100, RWP-636, and P3M datasets demonstrate that E2E-HIM also achieves competitive performance on traditional human matting. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, Q.
AU  - Zhang, Y.
AU  - Yang, Z.
AU  - Shikh-Bahaei, M.R.
TI  - Deep Channel Prediction-Based Energy-Efficient Intelligent Reflecting Surface-Aided Terahertz Communications
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 4
SP  - 2946
EP  - 2960
DO  - 10.1109/TWC.2023.3304597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168749589&doi=10.1109%2fTWC.2023.3304597&partnerID=40&md5=b41985f2d79262cbb592e8ddb34ac232
AB  - We propose a novel deep learning-based algorithm for channel prediction and energy efficiency (EE) optimisation in an intelligent reflecting surface (IRS) aided Terahertz communication system. Specifically, a multi-antenna base station with an IRS with massive reflecting elements is designed to serve multiple moving users. A deep learning-based prediction-optimisation scheme is presented where we first propose a transformer encoder with channel index embedding (TE-CIE) deep learning model for time-varying channel prediction. With the help of channel prediction, an EE optimisation algorithm is then designed to maximise the EE in advance based on the predicted channel state information (CSI). Finally, we combine both methods to construct a deep learning-based prediction-optimisation scheme. Specifically, the future CSI is predicted by TE-CIE and the IRS phase-shift and precoding matrices are optimised in advance. Simulation results demonstrate that our proposed channel prediction method achieves close-to-optimal performance in terms of low mean absolute error and a much faster speed than the two baseline models. We demonstrate that the proposed EE optimisation algorithm outperforms the baseline algorithms in terms of much better EE under diverse parameter settings. Finally, the proposed prediction-optimisation scheme achieves at least twice the EE improvement compared to the baseline methods in the literature.  © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, L.
AU  - Liu, B.
AU  - Fu, P.
AU  - Xu, M.
TI  - TSVT: Token Sparsification Vision Transformer for robust RGB-D salient object detection
PY  - 2024
T2  - Pattern Recognition
VL  - 148
C7  - 110190
DO  - 10.1016/j.patcog.2023.110190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179491007&doi=10.1016%2fj.patcog.2023.110190&partnerID=40&md5=60eaefe15bdb6f7350e97389348e8b24
AB  - Visual transformer-based salient object detection (SOD) models have attracted increasing research attention. However, the existing transformer-based RGB-D SOD models usually operate on the full token sequences of RGB-D images and use an equal tokenization process to treat appearance and depth modalities, which leads to limited feature richness and inefficiency. To address these limitations, we present a novel token sparsification vision transformer architecture for RGB-D SOD, named TSVT, that explicitly extracts global-local multi-modality features with sparse tokens. The TSVT is an asymmetric encoder–decoder architecture with a dynamic sparse token encoder that adaptively selects and operates on sparse tokens, along with an multiple cascade aggregation decoder (MCAD) that predicts saliency results. Furthermore, we deeply investigate the differences and similarities between the appearance and depth modalities and develop an interactive diversity fusion module (IDFM) to integrate each pair of multi-modality tokens in different stages. Finally, to comprehensively evaluate the performance of the proposed model, we conduct extensive experiments on seven standard RGB-D SOD benchmarks in terms of five evaluation metrics. The experimental results reveal that the proposed model is more robust and effective than fifteen existing RGB-D SOD models. Moreover, the complexity of our model with the sparsification module is more than two times lower than that of the variant model without the dynamic sparse token module (DSTM). © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Acciaio, B.
AU  - Kratsios, A.
AU  - Pammer, G.
TI  - Designing universal causal deep learning models: The geometric (Hyper)transformer
PY  - 2024
T2  - Mathematical Finance
VL  - 34
IS  - 2
SP  - 671
EP  - 735
DO  - 10.1111/mafi.12389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148992813&doi=10.1111%2fmafi.12389&partnerID=40&md5=674180fb95770929f0face01c7a095b1
AB  - Several problems in stochastic analysis are defined through their geometry, and preserving that geometric structure is essential to generating meaningful predictions. Nevertheless, how to design principled deep learning (DL) models capable of encoding these geometric structures remains largely unknown. We address this open problem by introducing a universal causal geometric DL framework in which the user specifies a suitable pair of metric spaces (Formula presented.) and (Formula presented.) and our framework returns a DL model capable of causally approximating any “regular” map sending time series in (Formula presented.) to time series in (Formula presented.) while respecting their forward flow of information throughout time. Suitable geometries on (Formula presented.) include various (adapted) Wasserstein spaces arising in optimal stopping problems, a variety of statistical manifolds describing the conditional distribution of continuous-time finite state Markov chains, and all Fréchet spaces admitting a Schauder basis, for example, as in classical finance. Suitable spaces (Formula presented.) are compact subsets of any Euclidean space. Our results all quantitatively express the number of parameters needed for our DL model to achieve a given approximation error as a function of the target map's regularity and the geometric structure both of (Formula presented.) and of (Formula presented.). Even when omitting any temporal structure, our universal approximation theorems are the first guarantees that Hölder functions, defined between such (Formula presented.) and (Formula presented.) can be approximated by DL models. © 2023 The Authors. Mathematical Finance published by Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Acciaio2024Designing
ER  -

TY  - JOUR
AU  - Han, Y.
TI  - Generation-based Multi-view Contrast for Self-supervised Graph Representation Learning
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 5
C7  - 130
DO  - 10.1145/3645095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189451786&doi=10.1145%2f3645095&partnerID=40&md5=18a8906d4406dc60d92390016df6d348
AB  - Graph contrastive learning has made remarkable achievements in the self-supervised representation learning of graph-structured data. By employing perturbation function (i.e., perturbation on the nodes or edges of graph), most graph contrastive learning methods construct contrastive samples on the original graph. However, the perturbation-based data augmentation methods randomly change the inherent information (e.g., attributes or structures) of the graph. Therefore, after nodes embedding on the perturbed graph, we cannot guarantee the validity of the contrastive samples as well as the learned performance of graph contrastive learning. To this end, in this article, we propose a novel generation-based multi-view contrastive learning framework (GMVC) for self-supervised graph representation learning, which generates the contrastive samples based on our generator rather than perturbation function. Specifically, after nodes embedding on the original graph we first employ random walk in the neighborhood to develop multiple relevant node sequences for each anchor node. We then utilize the transformer to generate the representations of relevant contrastive samples of anchor node based on the features and structures of the sampled node sequences. Finally, by maximizing the consistency between the anchor view and the generated views, we force the model to effectively encode graph information into nodes embeddings. We perform extensive experiments of node classification and link prediction tasks on eight benchmark datasets, which verify the effectiveness of our generation-based multi-view graph contrastive learning method.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Han2024Generation-based
ER  -

TY  - JOUR
AU  - Song, X.
AU  - Guo, F.
AU  - Zhang, L.
AU  - Lu, X.
AU  - Hei, X.
TI  - Salient Object Detection With Dual-Branch Stepwise Feature Fusion and Edge Refinement
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 4
SP  - 2832
EP  - 2844
DO  - 10.1109/TCSVT.2023.3312859
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171589821&doi=10.1109%2fTCSVT.2023.3312859&partnerID=40&md5=1170350fb9c7435c9b5e6c4510a5e308
AB  - In recent years, Transformers have been gradually applied in salient object detection tasks with good results. However, the Transformer’s global modeling capabilities can lead to the loss of local details that are important in salient object detection tasks. A feature extraction backbone based on a convolutional neural network (CNN) is good at extracting local detail features due to the gradual expansion of the receptive field but is limited by the size of the receptive field, resulting in an insufficient ability to extract global semantic features. Therefore, this paper combines the Transformer with a CNN and presents a dual-branch encoder to ensure that the features extracted contain rich global semantic information as well as local detail features. In addition, due to the different features extracted by the Transformer and CNN, noise may be introduced in the fusion of the two features, so different features need to be processed correspondingly during fusion. The fusion enhancement module (FEM) we propose fuses the features of the two branches step by step. A hybrid attention mechanism is used to carry out weighted fusion of different features. This progressive approach minimizes the differences between the features of the two branches so that the merged features retain the semantic and detail features extracted by the two branches to the greatest extent. Considering the loss of detailed information caused by repeated downsampling, we propose an edge refinement module (ERM) to address the need for accurate outline prediction. This module leverages salient features to obtain edge features and gradually refines the prediction results by incorporating these edge features. It makes full use of the connection between salient features and edge features and does not introduce additional edges to extract branches. Extensive experimental evaluations conducted on five benchmark tests demonstrate the superior performance of our method compared to other existing approaches. Code can be found at https://github.com/gfq1605694825/DSRNet-main. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bontempo, G.
AU  - Bolelli, F.
AU  - Porrello, A.
AU  - Calderara, S.
AU  - Ficarra, E.
TI  - A Graph-Based Multi-Scale Approach With Knowledge Distillation for WSI Classification
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 4
SP  - 1412
EP  - 1421
DO  - 10.1109/TMI.2023.3337549
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179117049&doi=10.1109%2fTMI.2023.3337549&partnerID=40&md5=06ac6a009d2b03ecbcd2027d50e6ef63
AB  - The usage of Multi Instance Learning (MIL) for classifying Whole Slide Images (WSIs) has recently increased. Due to their gigapixel size, the pixel-level annotation of such data is extremely expensive and time-consuming, practically unfeasible. For this reason, multiple automatic approaches have been raised in the last years to support clinical practice and diagnosis. Unfortunately, most state-of-the-art proposals apply attention mechanisms without considering the spatial instance correlation and usually work on a single-scale resolution. To leverage the full potential of pyramidal structured WSI, we propose a graph-based multi-scale MIL approach, DAS-MIL. Our model comprises three modules: i) a self-supervised feature extractor, ii) a graph-based architecture that precedes the MIL mechanism and aims at creating a more contextualized representation of the WSI structure by considering the mutual (spatial) instance correlation both inter and intra-scale. Finally, iii) a (self) distillation loss between resolutions is introduced to compensate for their informative gap and significantly improve the final prediction. The effectiveness of the proposed framework is demonstrated on two well-known datasets, where we outperform SOTA on WSI classification, gaining a +2.7% AUC and +3.7% accuracy on the popular Camelyon16 benchmark. © 2023 The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, J.
AU  - Chen, H.
TI  - Efficient Supervised Pretraining of Swin-Transformer for Virtual Staining of Microscopy Images
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 4
SP  - 1388
EP  - 1399
DO  - 10.1109/TMI.2023.3337253
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179053777&doi=10.1109%2fTMI.2023.3337253&partnerID=40&md5=6fb4948496b739eeeb0221b90fac7369
AB  - Fluorescence staining is an important technique in life science for labeling cellular constituents. However, it also suffers from being time-consuming, having difficulty in simultaneous labeling, etc. Thus, virtual staining, which does not rely on chemical labeling, has been introduced. Recently, deep learning models such as transformers have been applied to virtual staining tasks. However, their performance relies on large-scale pretraining, hindering their development in the field. To reduce the reliance on large amounts of computation and data, we construct a Swin-transformer model and propose an efficient supervised pretraining method based on the masked autoencoder (MAE). Specifically, we adopt downsampling and grid sampling to mask 75% of pixels and reduce the number of tokens. The pretraining time of our method is only 1/16 compared with the original MAE. We also design a supervised proxy task to predict stained images with multiple styles instead of masked pixels. Additionally, most virtual staining approaches are based on private datasets and evaluated by different metrics, making a fair comparison difficult. Therefore, we develop a standard benchmark based on three public datasets and build a baseline for the convenience of future researchers. We conduct extensive experiments on three benchmark datasets, and the experimental results show the proposed method achieves the best performance both quantitatively and qualitatively. In addition, ablation studies are conducted, and experimental results illustrate the effectiveness of the proposed pretraining method. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Varghese, A.J.
AU  - Bora, A.
AU  - Xu, M.
AU  - Karniadakis, G.E.
TI  - TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers
PY  - 2024
T2  - Neural Networks
VL  - 172
C7  - 106086
DO  - 10.1016/j.neunet.2023.12.040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181090464&doi=10.1016%2fj.neunet.2023.12.040&partnerID=40&md5=620a3d0d2cfb79cd90b938f8fe27ffc8
AB  - Dynamic graph embedding has emerged as a very effective technique for addressing diverse temporal graph analytic tasks (i.e., link prediction, node classification, recommender systems, anomaly detection, and graph generation) in various applications. Such temporal graphs exhibit heterogeneous transient dynamics, varying time intervals, and highly evolving node features throughout their evolution. Hence, incorporating long-range dependencies from the historical graph context plays a crucial role in accurately learning their temporal dynamics. In this paper, we develop a graph embedding model with uncertainty quantification, TransformerG2G, by exploiting the advanced transformer encoder to first learn intermediate node representations from its current state (t) and previous context (over timestamps [t−1,t−l], l is the length of context). Moreover, we employ two projection layers to generate lower-dimensional multivariate Gaussian distributions as each node's latent embedding at timestamp t. We consider diverse benchmarks with varying levels of “novelty” as measured by the TEA (Temporal Edge Appearance) plots. Our experiments demonstrate that the proposed TransformerG2G model outperforms conventional multi-step methods and our prior work (DynG2G) in terms of both link prediction accuracy and computational efficiency, especially for high degree of novelty. Furthermore, the learned time-dependent attention weights across multiple graph snapshots reveal the development of an automatic adaptive time stepping enabled by the transformer. Importantly, by examining the attention weights, we can uncover temporal dependencies, identify influential elements, and gain insights into the complex interactions within the graph structure. For example, we identified a strong correlation between attention weights and node degree at the various stages of the graph topology evolution. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zou, L.
AU  - Huang, Z.
AU  - Gu, N.
AU  - Wang, G.
TI  - GPT-COPE: A Graph-Guided Point Transformer for Category-Level Object Pose Estimation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 4
SP  - 2385
EP  - 2398
DO  - 10.1109/TCSVT.2023.3309902
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170545476&doi=10.1109%2fTCSVT.2023.3309902&partnerID=40&md5=64ac228a43ce6e91eb588416d3055bf1
AB  - Category-level object pose estimation aims to predict the 6D pose and 3D metric size of objects from given categories. Due to significant intra-class shape variations among different instances, existing methods have mainly focused on estimating dense correspondences between observed point clouds and their canonical representations, i.e., normalized object coordinate space (NOCS). Subsequently, a similarity transformation is applied to recover the object pose and size. Despite these efforts, current approaches still cannot fully exploit the intrinsic geometric features to individual instances, thus limiting their ability to handle objects with complex structures (i.e., cameras). To overcome this issue, this paper introduces GPT-COPE, which leverages a graph-guided point transformer to explore distinctive geometric features from the observed point cloud. Specifically, our GPT-COPE employs a Graph-Guided Attention Encoder to extract multiscale geometric features in a local-to-global manner and utilizes an Iterative Non-Parametric Decoder to aggregate the multiscale geometric features from finer scales to coarser scales without learnable parameters. After obtaining the aggregated geometric features, the object NOCS coordinates and shape are regressed through the shape prior adaptation mechanism, and the object pose and size are obtained using the Umeyama algorithm. The multiscale network design enables perceiving the overall shape and structural information of the object, which is beneficial to handle objects with complex structures. Experimental results on the NOCS-REAL and NOCS-CAMERA datasets demonstrate that our GPT-COPE achieves state-of-the-art performance and significantly outperforms existing methods. Furthermore, our GPT-COPE shows superior generalization ability compared to existing methods on the large-scale in-the-wild dataset Wild6D and achieves better performance on the REDWOOD75 dataset, which involves objects with unconstrained orientations. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qu, G.
AU  - Orlichenko, A.
AU  - Wang, J.
AU  - Zhang, G.
AU  - Xiao, L.
AU  - Zhang, K.
AU  - Wilson, T.W.
AU  - Stephen, J.M.
AU  - Calhoun, V.D.
AU  - Wang, Y.-P.
TI  - Interpretable Cognitive Ability Prediction: A Comprehensive Gated Graph Transformer Framework for Analyzing Functional Brain Networks
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 4
SP  - 1568
EP  - 1578
DO  - 10.1109/TMI.2023.3343365
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182369471&doi=10.1109%2fTMI.2023.3343365&partnerID=40&md5=b2d5fa46271c4fb618a4426184448284
AB  - Graph convolutional deep learning has emerged as a promising method to explore the functional organization of the human brain in neuroscience research. This paper presents a novel framework that utilizes the gated graph transformer (GGT) model to predict individuals' cognitive ability based on functional connectivity (FC) derived from fMRI. Our framework incorporates prior spatial knowledge and uses a random-walk diffusion strategy that captures the intricate structural and functional relationships between different brain regions. Specifically, our approach employs learnable structural and positional encodings (LSPE) in conjunction with a gating mechanism to efficiently disentangle the learning of positional encoding (PE) and graph embeddings. Additionally, we utilize the attention mechanism to derive multi-view node feature embeddings and dynamically distribute propagation weights between each node and its neighbors, which facilitates the identification of significant biomarkers from functional brain networks and thus enhances the interpretability of the findings. To evaluate our proposed model in cognitive ability prediction, we conduct experiments on two large-scale brain imaging datasets: the Philadelphia Neurodevelopmental Cohort (PNC) and the Human Connectome Project (HCP). The results show that our approach not only outperforms existing methods in prediction accuracy but also provides superior explainability, which can be used to identify important FCs underlying cognitive behaviors.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Sun, W.
AU  - Wu, H.
AU  - Zhou, Y.
AU  - Li, C.
AU  - Chen, Z.
AU  - Min, X.
AU  - Zhai, G.
AU  - Lin, W.
TI  - GMS-3DQA: Projection-Based Grid Mini-patch Sampling for 3D Model Quality Assessment
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 6
C7  - 178
DO  - 10.1145/3643817
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189239602&doi=10.1145%2f3643817&partnerID=40&md5=5a646508c38f39b5a92740cf179124eb
AB  - Nowadays, most three-dimensional model quality assessment (3DQA) methods have been aimed at improving accuracy. However, little attention has been paid to the computational cost and inference time required for practical applications. Model-based 3DQA methods extract features directly from the 3D models, which are characterized by their high degree of complexity. As a result, many researchers are inclined towards utilizing projection-based 3DQA methods. Nevertheless, previous projection-based 3DQA methods directly extract features from multi-projections to ensure quality prediction accuracy, which calls for more resource consumption and inevitably leads to inefficiency. Thus, in this article, we address this challenge by proposing a no-reference (NR) projection-based Grid Mini-patch Sampling 3D Model Quality Assessment (GMS-3DQA) method. The projection images are rendered from six perpendicular viewpoints of the 3D model to cover sufficient quality information. To reduce redundancy and inference resources, we propose a multi-projection grid mini-patch sampling strategy (MP-GMS), which samples grid mini-patches from the multi-projections and forms the sampled grid mini-patches into one quality mini-patch map (QMM). The Swin-Transformer tiny backbone is then used to extract quality-aware features from the QMMs. The experimental results show that the proposed GMS-3DQA outperforms existing state-of-the-art NR-3DQA methods on the point cloud quality assessment databases for both accuracy and efficiency. The efficiency analysis reveals that the proposed GMS-3DQA requires far less computational resources and inference time than other 3DQA competitors. The code is available at https://github.com/zzc-1998/GMS-3DQA.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xing, H.
AU  - Cai, P.
AU  - Liu, D.
AU  - Han, M.
AU  - Liu, J.
AU  - Le, Y.
AU  - Zhang, D.
AU  - Hu, Q.-N.
TI  - High-throughput prediction of enzyme promiscuity based on substrate-product pairs
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 2
C7  - bbae089
DO  - 10.1093/bib/bbae089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187967893&doi=10.1093%2fbib%2fbbae089&partnerID=40&md5=7b7fd87013d3df9fc1d1df3d934cb6a5
AB  - The screening of enzymes for catalyzing specific substrate-product pairs is often constrained in the realms of metabolic engineering and synthetic biology. Existing tools based on substrate and reaction similarity predominantly rely on prior knowledge, demonstrating limited extrapolative capabilities and an inability to incorporate custom candidate-enzyme libraries. Addressing these limitations, we have developed the Substrate-product Pair-based Enzyme Promiscuity Prediction (SPEPP) model. This innovative approach utilizes transfer learning and transformer architecture to predict enzyme promiscuity, thereby elucidating the intricate interplay between enzymes and substrate-product pairs. SPEPP exhibited robust predictive ability, eliminating the need for prior knowledge of reactions and allowing users to define their own candidate-enzyme libraries. It can be seamlessly integrated into various applications, including metabolic engineering, de novo pathway design, and hazardous material degradation. To better assist metabolic engineers in designing and refining biochemical pathways, particularly those without programming skills, we also designed EnzyPick, an easy-to-use web server for enzyme screening based on SPEPP. EnzyPick is accessible at http://www.biosynther.com/enzypick/. © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xue, J.
AU  - Wang, B.
AU  - Ji, H.
AU  - Li, W.
TI  - RT-Transformer: retention time prediction for metabolite annotation to assist in metabolite identification
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 3
C7  - btae084
DO  - 10.1093/bioinformatics/btae084
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186967888&doi=10.1093%2fbioinformatics%2fbtae084&partnerID=40&md5=6b987d433729c47e800e39a1561bbf78
AB  - Motivation: Liquid chromatography retention times prediction can assist in metabolite identification, which is a critical task and challenge in nontargeted metabolomics. However, different chromatographic conditions may result in different retention times for the same metabolite. Current retention time prediction methods lack sufficient scalability to transfer from one specific chromatographic method to another. Results: Therefore, we present RT-Transformer, a novel deep neural network model coupled with graph attention network and 1D-Transformer, which can predict retention times under any chromatographic methods. First, we obtain a pre-trained model by training RT-Transformer on the large small molecule retention time dataset containing 80 038 molecules, and then transfer the resulting model to different chromatographic methods based on transfer learning. When tested on the small molecule retention time dataset, as other authors did, the average absolute error reached 27.30 after removing not retained molecules. Still, it reached 33.41 when no samples were removed. The pretrained RT-Transformer was further transferred to 5 datasets corresponding to different chromatographic conditions and fine-tuned. According to the experimental results, RT-Transformer achieves competitive performance compared to state-of-the-art methods. In addition, RT-Transformer was applied to 41 external molecular retention time datasets. Extensive evaluations indicate that RT-Transformer has excellent scalability in predicting retention times for liquid chromatography and improves the accuracy of metabolite identification. Availability and implementation: The source code for the model is available at https://github.com/01dadada/RT-Transformer. The web server is available at https://huggingface.co/spaces/Xue-Jun/RT-Transformer. © 2024 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wenzel, M.
AU  - Grüner, E.
AU  - Strodthoff, N.
TI  - Insights into the inner workings of transformer models for protein function prediction
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 3
C7  - btae031
DO  - 10.1093/bioinformatics/btae031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188257443&doi=10.1093%2fbioinformatics%2fbtae031&partnerID=40&md5=3aa4f8732db95aa505e8c729d7c0ac9d
AB  - Motivation: We explored how explainable artificial intelligence (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too. Results: The approach enabled us to identify amino acids in the sequences that the transformers pay particular attention to, and to show that these relevant sequence parts reflect expectations from biology and chemistry, both in the embedding layer and inside of the model, where we identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations (e.g. transmembrane regions, active sites) across many proteins. Availability and Implementation: Source code can be accessed at https://github.com/markuswenzel/xai-proteins. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Yan, J.
AU  - Huang, L.
AU  - Fang, Y.
AU  - Wan, Z.
AU  - Liu, Y.
TI  - Perceptual Quality Assessment of Omnidirectional Images: A Benchmark and Computational Model
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 6
C7  - 175
DO  - 10.1145/3640344
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189472285&doi=10.1145%2f3640344&partnerID=40&md5=f2fe08cd153724e67e1f540c0957ceeb
AB  - Compared with traditional 2D images, omnidirectional images (also referred to as 360 images) have more complicated perceptual characteristics due to the particularities of imaging and display. How humans perceive omnidirectional images in an immersive environment and form the immersive quality of experience are important problems. Thus, it is crucial to measure the quality of omnidirectional images under different viewing conditions, which suffer from realistic distortions. In this article, we build a large-scale subjective assessment database for omnidirectional images and carry out a comprehensive psychophysical experiment to study the relationships between different factors (viewing conditions and viewing behaviors) and the perceptual quality of omnidirectional images. In addition, we collect both subjective ratings and head movement data. A thorough analysis of the collected subjective data is also provided, where we make several interesting findings. Moreover, with the proposed database, we propose a novel transformer-based omnidirectional image quality assessment model. To be consistent with the human viewing process, viewing conditions and behaviors are naturally incorporated into the proposed model. Specifically, the proposed model mainly consists of three parts: viewport sequence generation, multi-scale feature extraction, and perceptual quality prediction. Extensive experimental results conducted on the proposed database demonstrate the effectiveness of the proposed method over existing image quality assessment methods.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sang, W.
AU  - Zhang, H.
AU  - Kang, X.
AU  - Nie, P.
AU  - Meng, X.
AU  - Boulet, B.
AU  - Sun, P.
TI  - Dynamic multi-granularity spatial-temporal graph attention network for traffic forecasting
PY  - 2024
T2  - Information Sciences
VL  - 662
C7  - 120230
DO  - 10.1016/j.ins.2024.120230
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183973074&doi=10.1016%2fj.ins.2024.120230&partnerID=40&md5=8c852012ed38bc76e4ff18bb64ad34bd
AB  - Traffic forecasting, as the cornerstone of the development of intelligent transportation systems, plays a crucial role in facilitating accurate control and management of urban traffic. By treating sensors as nodes in a road network, recent research on modeling complex spatial-temporal graph structures has achieved notable advancements in traffic forecasting. However, limited by the increasing number of sensors and recorded data points, most of the recent studies on spatial-temporal graph neural network (STGNN) research concentrate on aggregating short-term (e.g. recent one-hour) traffic history to predict future data. Furthermore, almost all previous STGNNs neglect to incorporate the cyclical patterns that appear in the traffic historical data. For example, the cyclical patterns of traffic on the same day or hour of each week can help improve the accuracy of future traffic predictions. In this paper, we propose a novel Dynamic Multi-Granularity Spatial-Temporal Graph Attention Network (DmgSTGAT) framework for traffic forecasting, which leverages multi-granularity spatial-temporal correlations across different time-scales and variables to efficiently consider cyclical patterns in traffic data. We also design effective temporal encoding and transformer encoding layers to produce meaningful multi-granularity sensor-level, day-level, hour-level, and point-level representations. The multi-granularity spatial-temporal graph attention network can use the produced representations to extract useful but sparsely distributed patterns accurately, which also avoids the influence of extra noise from the long-term history. Experimental results on four real-world traffic datasets show that DmgSTGAT can achieve state-of-the-art performance with the help of multi-granularity cyclical patterns compared with various recent baselines. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Sang2024Dynamic
ER  -

TY  - JOUR
AU  - Ye, Z.
AU  - Li, S.
TI  - A transformer-based neural network framework for full names prediction with abbreviations and contexts
PY  - 2024
T2  - Data and Knowledge Engineering
VL  - 150
C7  - 102275
DO  - 10.1016/j.datak.2023.102275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181948659&doi=10.1016%2fj.datak.2023.102275&partnerID=40&md5=bad79400c6e9dce25cdc5a5b9b7d4a6d
AB  - With the rapid spread of information, abbreviations are used more and more common because they are convenient. However, the duplication of abbreviations can lead to confusion in many cases, such as information management and information retrieval. The resultant confusion annoys users. Thus, inferring a full name from an abbreviation has practical and significant advantages. The bulk of studies in the literature mainly inferred full names based on rule-based methods, statistical models, the similarity of representation, etc. However, these methods are unable to use various grained contexts properly. In this paper, we propose a flexible framework of Multi-attention mask Abbreviation Context and Full name language model, named MACF to address the problem. With the abbreviation and contexts as the inputs, the MACF can automatically predict a full name by generation, where the contexts can be variously grained. That is, different grained contexts ranging from coarse to fine can be selected to perform such complicated tasks in which contexts include paragraphs, several sentences, or even just a few keywords. A novel multi-attention mask mechanism is also proposed, which allows the model to learn the relationships among abbreviations, contexts, and full names, a process that makes the most of various grained contexts. The three corpora of different languages and fields were analyzed and measured with seven metrics in various aspects to evaluate the proposed framework. According to the experimental results, the MACF yielded more significant and consistent outputs than other baseline methods. Moreover, we discuss the significance and findings, and give the case studies to show the performance in real applications. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhongbo, Y.
AU  - Hien, P.L.
TI  - Pre-trained transformer model as a surrogate in multiscale computational homogenization framework for elastoplastic composite materials subjected to generic loading paths
PY  - 2024
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 421
C7  - 116745
DO  - 10.1016/j.cma.2024.116745
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182727188&doi=10.1016%2fj.cma.2024.116745&partnerID=40&md5=80c9dd7d9ce1527f4be3193ae97fcad8
AB  - A composite material typically exhibits complex behavior at the engineer scale, arising from the interactions between its underlying constituent phases, as well as the competitions between micro-processes. It is generally a daunting task to develop an engineering model to adequately capture the essential micro mechanisms that propagate onto the macro scale. To this end, the multiscale computational homogenization (FE2) method enables a consistent coupling across length scales, to give results that compare well with direct numerical simulations having the full micro-structural details, without the need for any constitutive assumptions nor calibrations at the macro scale. Despite its predictive capabilities, the typical computational homogenization method is still computationally too expensive for most practical problems, as the coupling between micro and macro scales are solved simultaneously during its numerical implementation. In this presentation, focusing on the elastoplastic behavior of fiber-reinforced composite, we address this bottleneck with an offline development of a microscopic surrogate model for a given micro-structure, to be incorporated into a standard nonlinear FE framework, for rapid online implementations at the macro scale. For the offline training phase, we adopt the transformer-based architecture within a pre-training and fine-tuning framework. The proposed pre-trained transformer model is capable of parallelizing computations to effectively capture global dependencies within the strain-stress data sequences. To reduce the data generation cost, a constructed source representative volume element (RVE) having a single central heterogeneity with an identical volume fraction with the target RVE is utilized, to rapidly generate a huge source dataset for a pre-training process. The performance of the surrogate model is first demonstrated by comparing its predictions under random loading paths against the reference homogenized RVE responses. Next, the surrogate model is incorporated into a macro FE framework, and its predictive capabilities illustrated via the generic loading of two specimens with different microstructures, each having a different loading–unloading path. Finally, a chunking method is discussed as a potential remedy for managing very long load sequences. © 2024 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yu, C.
AU  - Yan, G.
AU  - Yu, C.
AU  - Liu, X.
AU  - Mi, X.
TI  - MRIformer: A multi-resolution interactive transformer for wind speed multi-step prediction
PY  - 2024
T2  - Information Sciences
VL  - 661
C7  - 120150
DO  - 10.1016/j.ins.2024.120150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184143353&doi=10.1016%2fj.ins.2024.120150&partnerID=40&md5=867638330524054881240af333625cda
AB  - Wind speed prediction is crucial for managing energy consumption in wind farms. Traditional wind speed prediction techniques often overlook two essential characteristics of wind speed data: (a) the downsampled wind speed data can retain cyclic and trend information, which is valuable for the model. (b) Multi-resolution speed data exhibited distinct patterns, enabling the model to extract insights from various perspectives. Considering the above two characteristics, this paper presents a novel approach called the Multi-Resolution Interactive transformer (MRIformer), which consists of the ASI block and the MRI block. The ASI block utilizes two different attention mechanisms to extract temporal information and enhance interactive learning among subsequences while downsampling wind speed data. The MRI block utilizes a tree structure to stack multiple layers of ASI blocks, enabling the analysis of wind speed data at various resolutions. By incorporating residual connections and multi-head attention, the MRI block effectively fuses data with different resolutions. Comparative experiments on three real-world datasets led to the following conclusions. (a) MRIformer exceeded 14 state-of-the-art baselines on all datasets and achieved a performance improvement of over 7.5%. (b) The effectiveness of the designed structure is demonstrated through component replacement and ablation experiments. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:B; 
LB  - Yu2024MRIformer
ER  -

TY  - JOUR
AU  - Cai, Y.
AU  - Lv, J.
AU  - Li, R.
AU  - Huang, X.
AU  - Wang, S.
AU  - Bao, Z.
AU  - Zeng, Q.
TI  - Deqformer: High-definition and scalable deep learning probe design method
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 2
C7  - bbae007
DO  - 10.1093/bib/bbae007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184133747&doi=10.1093%2fbib%2fbbae007&partnerID=40&md5=a36ca9575e454297c7cde1e34a3f712d
AB  - Target enrichment sequencing techniques are gaining widespread use in the field of genomics, prized for their economic efficiency and swift processing times. However, their success depends on the performance of probes and the evenness of sequencing depth among each probe. To accurately predict probe coverage depth, a model called Deqformer is proposed in this study. Deqformer utilizes the oligonucleotides sequence of each probe, drawing inspiration from Watson-Crick base pairing and incorporating two BERT encoders to capture the underlying information from the forward and reverse probe strands, respectively. The encoded data are combined with a feed-forward network to make precise predictions of sequencing depth. The performance of Deqformer is evaluated on four different datasets: SNP panel with 38 200 probes, lncRNA panel with 2000 probes, synthetic panel with 5899 probes and HD-Marker panel for Yesso scallop with 11 000 probes. The SNP and synthetic panels achieve impressive factor 3 of accuracy (F3acc) of 96.24% and 99.66% in 5-fold cross-validation. F3acc rates of over 87.33% and 72.56% are obtained when training on the SNP panel and evaluating performance on the lncRNA and HD-Marker datasets, respectively. Our analysis reveals that Deqformer effectively captures hybridization patterns, making it robust for accurate predictions in various scenarios. Deqformer leads to a novel perspective for probe design pipeline, aiming to enhance efficiency and effectiveness in probe design tasks.  © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, Y.
AU  - Su, Y.
AU  - Deng, J.
AU  - Zhang, Y.
AU  - Wu, Q.
TI  - Adaptive Locally-Aligned Transformer for low-light video enhancement
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 240
C7  - 103916
DO  - 10.1016/j.cviu.2023.103916
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181961389&doi=10.1016%2fj.cviu.2023.103916&partnerID=40&md5=5c3d27d8cab84d263bceb56b19be05ca
AB  - Low-light enhancement is a crucial task that aims to enhance the under-exposed input in computer vision. While state-of-the-art static single-image enhancement methods have made remarkable progress, yet, few attempts are explored the spatial-temporal sequence problem in low-light video enhancement. In this paper, we propose a simple yet highly effective method, termed as Adaptive Locally-Aligned Transformer (ALAT) for low-light video enhancement based on visual transformers. ALAT consists of three parts: feature encoder, locally-aligned transformer block (LATB) and pyramid feature decoder. Specifically, the transformer block enables the network to model the long-range spatial and appearance dependencies in videos due to its self-attention parallel computing mechanism. However, different from some previous approaches directly using the vanilla transformer, we consider that locality is significant in low-level vision tasks since the misaligned contextual local features (i.e., edges, shapes) may affect the prediction quality. Therefore, the proposed LATB is designed to align the video pixel with its most relevant ones adaptively in the local region to preserve the regional content information. Furthermore, we publish a new real-world low-light video dataset, named ExpressWay, to fill the gaps in the lack of dynamic low-light video scenarios, which contains high-quality videos with moving objects in both dark- and bright-light conditions. We conduct experiments on five benchmarks under three comprehensive settings including synthesized, static and our proposed dynamic low-light video datasets. Extensive experimental results show that our ALAT can outperform the previous state-of-the-arts by a large margin of 0.20∼1.10dB. Our method can be also extended to other video enhancement applications. The project is available at https://github.com/y1wencao/LLVE-ALAT. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Dong, P.
AU  - Wang, B.
AU  - Cong, R.
AU  - Sun, H.-H.
AU  - Li, C.
TI  - Transformer with large convolution kernel decoder network for salient object detection in optical remote sensing images
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 240
C7  - 103917
DO  - 10.1016/j.cviu.2023.103917
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182428860&doi=10.1016%2fj.cviu.2023.103917&partnerID=40&md5=879da05c1915344a92c38119360ac538
AB  - Despite salient object detection in optical remote sensing images (ORSI-SOD) has made great strides in recent years, it is still a very challenging topic due to various scales and shapes of objects, cluttered backgrounds, and diverse imaging orientations. Most previous deep learning-based methods fails to effectively capture local and global features, resulting in ambiguous localization and semantic information and inaccurate detail and boundary prediction for ORSI-SOD. In this paper, we propose a novel Transformer with large convolutional kernel decoding network, named TLCKD-Net, which effectively models the long-range dependence that is indispensable for feature extraction of ORSI-SOD. First, we utilize Transformer backbone network to perceive global and local details of salient objects. Second, a large convolutional kernel decoding module based on self-attention mechanism is designed for different sizes of salient objects to extract feature information at different scales. Then, a large convolutional refinement and a Salient Feature Enhancement Module are used to recover and refine the saliency features to obtain high quality saliency maps. Extensive experiments on two public ORSI-SOD datasets show that our proposed method outperforms 16 state-of-the-art methods both qualitatively and quantitatively. In addition, a series of ablation studies demonstrate the effectiveness of different modules for ORSI-SOD. Our source code is publicly available at https://github.com/Dpw506/TLCKD-Net. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Ran, H.
AU  - Ren, J.
AU  - Sun, M.
TI  - PWDformer: Deformable transformer for long-term series forecasting
PY  - 2024
T2  - Pattern Recognition
VL  - 147
C7  - 110118
DO  - 10.1016/j.patcog.2023.110118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177217690&doi=10.1016%2fj.patcog.2023.110118&partnerID=40&md5=2dbf71aa477848fed67955472e23aa50
AB  - Long-term forecasting is of paramount importance in numerous scenarios, including predicting future energy, water, and food consumption. For instance, extreme weather events and natural disasters can profoundly impact infrastructure operations and pose severe safety concerns. Traditional CNN-based models often struggle to capture long-distance dependencies effectively. In contrast, Transformers-based models have shown significant promise in long-term forecasting. This paper investigates the long-term forecasting problem and identifies a common limitation in existing Transformer-based models: they tend to reduce computational complexity at the expense of time information aggregation capability. Moreover, the order of time series plays a crucial role in accurate predictions, but current Transformer-based models lack sensitivity to time series order, rendering them unreasonable. To address these issues, we propose a novel Deformable-Local (DL) aggregation mechanism. This mechanism enhances the model's ability to aggregate time information and allows the model to adaptively adjust the size of the time aggregation window. Consequently, the model can discern more complex time patterns, leading to more accurate predictions. Additionally, our model incorporates a Frequency Selection module to reinforce effective features and reduce noise. Furthermore, we introduce Position Weights to mitigate the order-insensitivity problem present in existing methods. In extensive evaluations of long-term forecasting tasks, we conducted benchmark tests on six datasets covering various practical applications, including energy, traffic, economics, weather, and disease. Our method achieved state-of-the-art (SOTA) results, demonstrating significant improvements. For instance, on the ETT dataset, our model achieved an average MSE improvement of approximately 19% and an average MAE improvement of around 27%. Remarkably, for predicted lengths of 96 and 192, we achieved outstanding MSE and MAE improvements of 32.1% and 30.9%, respectively. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, Y.
AU  - Hu, H.
AU  - Chen, W.
AU  - Yin, H.
AU  - Wu, J.
AU  - Hsieh, C.-Y.
AU  - He, Q.
AU  - Cao, J.
TI  - SynergyX: a multi-modality mutual attention network for interpretable drug synergy prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 2
C7  - bbae015
DO  - 10.1093/bib/bbae015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184772015&doi=10.1093%2fbib%2fbbae015&partnerID=40&md5=5918f1bfc2dfca3c0e1b815594ed968e
AB  - Discovering effective anti-tumor drug combinations is crucial for advancing cancer therapy. Taking full account of intricate biological interactions is highly important in accurately predicting drug synergy. However, the extremely limited prior knowledge poses great challenges in developing current computational methods. To address this, we introduce SynergyX, a multi-modality mutual attention network to improve anti-tumor drug synergy prediction. It dynamically captures cross-modal interactions, allowing for the modeling of complex biological networks and drug interactions. A convolution-augmented attention structure is adopted to integrate multi-omic data in this framework effectively. Compared with other state-of-the-art models, SynergyX demonstrates superior predictive accuracy in both the General Test and Blind Test and cross-dataset validation. By exhaustively screening combinations of approved drugs, SynergyX reveals its ability to identify promising drug combination candidates for potential lung cancer treatment. Another notable advantage lies in its multidimensional interpretability. Taking Sorafenib and Vorinostat as an example, SynergyX serves as a powerful tool for uncovering drug-gene interactions and deciphering cell selectivity mechanisms. In summary, SynergyX provides an illuminating and interpretable framework, poised to catalyze the expedition of drug synergy discovery and deepen our comprehension of rational combination therapy. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tuckute, G.
AU  - Sathe, A.
AU  - Srikant, S.
AU  - Taliaferro, M.
AU  - Wang, M.
AU  - Schrimpf, M.
AU  - Kay, K.
AU  - Fedorenko, E.
TI  - Driving and suppressing the human language network using large language models
PY  - 2024
T2  - Nature Human Behaviour
VL  - 8
IS  - 3
SP  - 544
EP  - 561
DO  - 10.1038/s41562-023-01783-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181495375&doi=10.1038%2fs41562-023-01783-7&partnerID=40&md5=c6afd022842ccb84147b4cfa6e69e639
AB  - Transformer models such as GPT generate human-like language and are predictive of human brain responses to language. Here, using functional-MRI-measured brain responses to 1,000 diverse sentences, we first show that a GPT-based encoding model can predict the magnitude of the brain response associated with each sentence. We then use the model to identify new sentences that are predicted to drive or suppress responses in the human language network. We show that these model-selected novel sentences indeed strongly drive and suppress the activity of human language areas in new individuals. A systematic analysis of the model-selected sentences reveals that surprisal and well-formedness of linguistic input are key determinants of response strength in the language network. These results establish the ability of neural network models to not only mimic human language but also non-invasively control neural activity in higher-level cortical areas, such as the language network. © The Author(s), under exclusive licence to Springer Nature Limited 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - AJG:4; zdy:None; 
LB  - Tuckute2024Driving
ER  -

TY  - JOUR
AU  - Zhu, Y.-H.
AU  - Liu, Z.
AU  - Liu, Y.
TI  - ULDNA: integrating unsupervised multi-source language models with LSTM-attention network for high-accuracy protein-DNA binding site prediction
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 2
C7  - bbae040
DO  - 10.1093/bib/bbae040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185128825&doi=10.1093%2fbib%2fbbae040&partnerID=40&md5=c7e85045b6129c2660cf4458fad0102a
AB  - Efficient and accurate recognition of protein-DNA interactions is vital for understanding the molecular mechanisms of related biological processes and further guiding drug discovery. Although the current experimental protocols are the most precise way to determine protein-DNA binding sites, they tend to be labor-intensive and time-consuming. There is an immediate need to design efficient computational approaches for predicting DNA-binding sites. Here, we proposed ULDNA, a new deep-learning model, to deduce DNA-binding sites from protein sequences. This model leverages an LSTM-attention architecture, embedded with three unsupervised language models that are pre-trained on large-scale sequences from multiple database sources. To prove its effectiveness, ULDNA was tested on 229 protein chains with experimental annotation of DNA-binding sites. Results from computational experiments revealed that ULDNA significantly improves the accuracy of DNA-binding site prediction in comparison with 17 state-of-the-art methods. In-depth data analyses showed that the major strength of ULDNA stems from employing three transformer language models. Specifically, these language models capture complementary feature embeddings with evolution diversity, in which the complex DNA-binding patterns are buried. Meanwhile, the specially crafted LSTM-attention network effectively decodes evolution diversity-based embeddings as DNA-binding results at the residue level. Our findings demonstrated a new pipeline for predicting DNA-binding sites on a large scale with high accuracy from protein sequence alone. © 2024 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Rong, D.
AU  - Zhao, Z.
AU  - Wu, Y.
AU  - Ke, B.
AU  - Ni, B.
TI  - Prediction of Myopia Eye Axial Elongation with Orthokeratology Treatment via Dense I2I Based Corneal Topography Change Analysis
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 3
SP  - 1149
EP  - 1164
DO  - 10.1109/TMI.2023.3331488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177059617&doi=10.1109%2fTMI.2023.3331488&partnerID=40&md5=79121671159c38f1a139d06a748f6b49
AB  - While orthokeratology (OK) has shown effective to slow the progression of myopia, it remains unknown how spatially distributed structural stress/tension applying to different regions affects the change of corneal geometry, and consecutive the outcome of myopia control, at fine-grained detail. Acknowledging that the underlying working mechanism of OK lens is essentially mechanics induced refractive parameter reshaping, in this study, we develop a novel mechanics rule guided deep image-to-image learning framework, which densely predicts patient's corneal topography change according to treatment parameters (lens geometry, wearing time, physiological parameters, etc.), and consecutively predicts the influence on eye axial length change after OK treatment. Encapsulated in a U-shaped multi-resolution map-to-map architecture, the proposed model features two major components. First, geometric and wearing parameters of OK lens are spatially encoded with convolutions to form a multi-channel input volume/tensor for latent encodings of external stress/tension applied to different regions of cornea. Second, these external latent force maps are progressively down-sampled and injected into this multi-scale architecture for predicting the change of corneal topography map. At each feature learning layer, we formally derive a mathematic framework that simulates the physical process of corneal deformation induced by lens-to-cornea interaction and corneal internal tension, which is reformulated into parameter learnable cross-attention/self-attention modules in the context of transformer architecture. A total of 1854 eyes of myopia patients are included in the study and the results show that the proposed model precisely predicts corneal topography change with a high PSNR as 28.45dB, as well as a significant accuracy gain for axial elongation prediction (i.e., 0.0276 in MSE). It is also demonstrated that our method provides interpretable associations between various OK treatment parameters and the final control effect. Our project code package is available at https://github.com/Rongdingyi/PhyIntNet.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, Y.
TI  - Progressive neural network for multi-horizon time series forecasting
PY  - 2024
T2  - Information Sciences
VL  - 661
C7  - 120112
DO  - 10.1016/j.ins.2024.120112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183576871&doi=10.1016%2fj.ins.2024.120112&partnerID=40&md5=e9c7b194665ffbf8344b6f6cef242c12
AB  - In this paper, we introduce ProNet, an novel deep learning approach designed for multi-horizon time series forecasting, adaptively blending autoregressive (AR) and non-autoregressive (NAR) strategies. Our method involves dividing the forecasting horizon into segments, predicting the most crucial steps in each segment non-autoregressively, and the remaining steps autoregressively. The segmentation process relies on latent variables, which effectively capture the significance of individual time steps through variational inference. In comparison to AR models, ProNet showcases remarkable advantages, requiring fewer AR iterations, resulting in faster prediction speed, and mitigating error accumulation. On the other hand, when compared to NAR models, ProNet takes into account the interdependency of predictions in the output space, leading to improved forecasting accuracy. Our comprehensive evaluation, encompassing four large datasets, and an ablation study, demonstrate the effectiveness of ProNet, highlighting its superior performance in terms of accuracy and prediction speed, outperforming state-of-the-art AR and NAR forecasting models. © 2024
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Lin2024Progressive
ER  -

TY  - JOUR
AU  - Lefebvre, G.
AU  - Elghazel, H.
AU  - Guillet, T.
AU  - Aussem, A.
AU  - Sonnati, M.
TI  - A new sentence embedding framework for the education and professional training domain with application to hierarchical multi-label text classification
PY  - 2024
T2  - Data and Knowledge Engineering
VL  - 150
C7  - 102281
DO  - 10.1016/j.datak.2024.102281
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183874133&doi=10.1016%2fj.datak.2024.102281&partnerID=40&md5=7fe28b59b94c6f9cd3af2d238b36d747
AB  - In recent years, Natural Language Processing (NLP) has made significant advances through advanced general language embeddings, allowing breakthroughs in NLP tasks such as semantic similarity and text classification. However, complexity increases with hierarchical multi-label classification (HMC), where a single entity can belong to several hierarchically organized classes. In such complex situations, applied on specific-domain texts, such as the Education and professional training domain, general language embedding models often inadequately represent the unique terminologies and contextual nuances of a specialized domain. To tackle this problem, we present HMCCCProbT, a novel hierarchical multi-label text classification approach. This innovative framework chains multiple classifiers, where each individual classifier is built using a novel sentence-embedding method BERTEPro based on existing Transformer models, whose pre-training has been extended on education and professional training texts, before being fine-tuned on several NLP tasks. Each individual classifier is responsible for the predictions of a given hierarchical level and propagates local probability predictions augmented with the input feature vectors to the classifier in charge of the subsequent level. HMCCCProbT tackles issues of model scalability and semantic interpretation, offering a powerful solution to the challenges of domain-specific hierarchical multi-label classification. Experiments over three domain-specific textual HMC datasets indicate the effectiveness of HMCCCProbT to compare favorably to state-of-the-art HMC algorithms in terms of classification accuracy and also the ability of BERTEPro to obtain better probability predictions, well suited to HMCCCProbT, than three other vector representation techniques. © 2024 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xian, R.
AU  - Xiong, X.
AU  - Peng, H.
AU  - Wang, J.
AU  - de Arellano Marrero, A.R.
AU  - Yang, Q.
TI  - Feature fusion method based on spiking neural convolutional network for edge detection
PY  - 2024
T2  - Pattern Recognition
VL  - 147
C7  - 110112
DO  - 10.1016/j.patcog.2023.110112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181700685&doi=10.1016%2fj.patcog.2023.110112&partnerID=40&md5=8429b1a73ee027776c59d5a639a3f6b0
AB  - NSNP-type neuron is a new type of neuron model inspired by nonlinear spiking mechanisms in nonlinear spiking neural P systems. In order to address the loss problem of edge detail information in edge detection methods based on deep learning, we propose a feature fusion method based on NSNP-type neurons. The architecture of this feature fusion method consists of two modules: feature extraction module and feature fusion module. In particular, the feature fusion module is composed of convolutional blocks constructed by NSNP-type neurons for multi-level feature fusions, and CoT blocks with Transformer style is introduced to extract rich contextual information from low-level features and high-level features. To fuse multi-level features and preserve contextual information, we design a new loss function that not only preserves feature prediction loss and fusion loss, but also considers contour-related and texture-related information. The proposed method is evaluated on BSDS500 and NYUDv2 data sets and compare it with 9 baseline methods and 12 CNN-based methods, and we achieve ODS of 0.808 and OIS of 0.827 on BSDS500. The comparison results demonstrate the advantages of the proposed method for edge detection. The source code is available at https://github.com/xhuph66/FF-CNSNP-master. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, D.
AU  - Hu, N.
AU  - Liang, P.
AU  - Swink, M.
TI  - Understanding the impact of trade policy effect uncertainty on firm-level innovation investment
PY  - 2024
T2  - Journal of Operations Management
VL  - 70
IS  - 2
SP  - 316
EP  - 340
DO  - 10.1002/joom.1285
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178390274&doi=10.1002%2fjoom.1285&partnerID=40&md5=a7bf3ab0152b3f4a71c626f5dca30d43
AB  - Drawing on real options and resource dependence theories, this study examines how firms adjust their innovation investments to address trade policy effect uncertainty (TPEU), a type of firm-specific, perceived environmental uncertainty capturing managers' difficulty in predicting the impacts of potential policy changes on business operations. To develop a context-dependent, time-varying measure of TPEU, we apply bidirectional encoder representations from transformers, an advanced deep learning technique. We analyze the texts of mandatory management discussion and analysis sections of annual reports from 3181 publicly listed Chinese firms. Our sample comprises 22,669 firm-year observations spanning the years 2007 to 2019. The econometric analyses show that firms experiencing higher TPEU will reduce innovation investments. This effect is stronger for firms facing lower competition, involving more foreign sales, and not owned by the state. These findings provide clarity on previously inconclusive results by showcasing the significant influence of policy effect uncertainty, as opposed to policy state uncertainty, on firms' decisions regarding innovation investments. Additionally, these findings underscore the importance of resource dependence factors as crucial contextual factors in this decision-making process. © 2023 Association for Supply Chain Management, Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - FMS:A; AJG:5; ZUFE:TOP; zdy:5; 
LB  - Chen2024Understanding
ER  -

TY  - JOUR
AU  - Fayad, I.
AU  - Ciais, P.
AU  - Schwartz, M.
AU  - Wigneron, J.-P.
AU  - Baghdadi, N.
AU  - de Truchis, A.
AU  - d'Aspremont, A.
AU  - Frappart, F.
AU  - Saatchi, S.
AU  - Sean, E.
AU  - Pellissier-Tanon, A.
AU  - Bazzi, H.
TI  - Hy-TeC: a hybrid vision transformer model for high-resolution and large-scale mapping of canopy height
PY  - 2024
T2  - Remote Sensing of Environment
VL  - 302
C7  - 113945
DO  - 10.1016/j.rse.2023.113945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183376304&doi=10.1016%2fj.rse.2023.113945&partnerID=40&md5=a5194a691d5dde353785720aebdb0dc8
AB  - Accurate and timely monitoring of forest canopy height is critical for assessing forest dynamics, biodiversity, carbon sequestration as well as forest degradation and deforestation. Recent advances in deep learning techniques, coupled with the vast amount of spaceborne remote sensing data offer an unprecedented opportunity to map canopy height at high spatial and temporal resolutions. Current techniques for wall-to-wall canopy height mapping correlate remotely sensed information from optical and radar sensors in the 2D space to the vertical structure of trees using lidar's 3D measurement abilities serving as height proxies. While studies making use of deep learning algorithms have shown promising performances for the accurate mapping of canopy height, they have limitations due to the type of architectures and loss functions employed. Moreover, mapping canopy height over tropical forests remains poorly studied, and the accurate height estimation of tall canopies is a challenge due to signal saturation from optical and radar sensors, persistent cloud cover, and sometimes limited penetration capabilities of lidar instruments. In this study, we map heights at 10 m resolution across the diverse landscape of Ghana with a new vision transformer (ViT) model, dubbed Hy-TeC, optimized concurrently with a classification (discrete) and a regression (continuous) loss function. This model achieves significantly higher accuracy than previously employed convolutional-based approaches (ConvNets) optimized with only a continuous loss function. Hy-TeC results show that our proposed discrete/continuous loss formulation significantly increases the sensitivity for very tall trees (i.e., > 35 m). Overall, Hy-TeC has significantly reduced bias (0.8 m) and higher accuracy (RMSE = 6.6 m) over tropical forests for which other approaches show poorer performance and oftentimes a saturation effect. The height maps generated by Hy-TeC also have better ground sampling distance and better sensitivity to sparse vegetation. Over these areas, Hy-TeC showed an RMSE of 3.1 m in comparison to a reference dataset while the baseline ConvNet model had an RMSE of 4.3 m. Hy-TeC, which was used to generate a height map of Ghana using free and open access remotely sensed data with Sentinel-2 and Sentinel-1 images as predictors and GEDI height measurements as calibration data, has the potential to be used globally. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Pu, B.
AU  - Liu, J.
AU  - Kang, Y.
AU  - Chen, J.
AU  - Yu, P.S.
TI  - MVSTT: A Multiview Spatial-Temporal Transformer Network for Traffic-Flow Forecasting
PY  - 2024
T2  - IEEE Transactions on Cybernetics
VL  - 54
IS  - 3
SP  - 1582
EP  - 1595
DO  - 10.1109/TCYB.2022.3223918
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144768753&doi=10.1109%2fTCYB.2022.3223918&partnerID=40&md5=d61a0231ea5ee5661dd965abd3bee2a8
AB  - Accurate traffic-flow prediction remains a critical challenge due to complicated spatial dependencies, temporal factors, and unpredictable events. Most existing approaches focus on single- or dual-view learning and thus face limitations in systematically learning complex spatial-temporal features. In this work, we propose a novel multiview spatial-temporal transformer (MVSTT) network that can effectively learn complex spatial-temporal domain correlations and potential patterns from multiple views. First, we examine a temporal view and design a short-range gated convolution component from a short-term subview, and a long-range gated convolution component from a long-term subview. These two components effectively aggregate knowledge of the temporal domain at multiple granularities and mine patterns of node evolution across time steps. Meanwhile, in the spatial view, we design a dual-graph spatial learning module that captures fixed and dynamic spatial dependencies of nodes, as well as the evolution patterns of edges, from the static and dynamic graph subviews, respectively. In addition, we further design a spatial-temporal transformer to mine different levels of spatial-temporal features through multiview knowledge fusion. Extensive experiments on four real-world traffic datasets show that our method consistently outperforms the state-of-the-art baseline. The code of MVSTT is available at https://github.com/JianSoL/MVSTT.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; FMS:B; AJG:3; zdy:3; 
LB  - Pu2024MVSTT
ER  -

TY  - JOUR
AU  - Moon, J.
AU  - Jeon, M.
AU  - Jeong, S.
AU  - Oh, K.-Y.
TI  - RoMP-transformer: Rotational bounding box with multi-level feature pyramid transformer for object detection
PY  - 2024
T2  - Pattern Recognition
VL  - 147
C7  - 110067
DO  - 10.1016/j.patcog.2023.110067
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175162527&doi=10.1016%2fj.patcog.2023.110067&partnerID=40&md5=bfd013ba1b4f06f73cf70e6ff7cbf421
AB  - This study proposes rotational bounding box with a multi-level feature pyramid transformer (RoMP-Transformer)—a fast and accurate one-stage deep neural network for object detection. The proposed RoMP-Transformer exhibits three characteristics. First, a rotational bounding box is utilized to minimize the effect of the background during the construction of feature maps, enhancing the robustness of the RoMP-Transformer. Second, the RoMP-Transformer employs a multi-level feature pyramid transformer by combining a multi-level feature pyramid network with a pyramid vision-transformer, effectively extracting high-quality features and achieving high accuracy. Third, the RoMP-Transformer executes bounding box optimization by minimizing the optimal intersection of union (IoU) loss by considering both the modified SKEW IoU and distance IoU. The modified SKEW IoU significantly accelerates the calculation, and the fused IoU calculation method improves prediction accuracy. Further, Bayesian optimization and weight lightening with half-tensor are performed to optimize the performance of the RoMP-Transformer for real-time applications. Experiments on three image sets—one on power transmission facilities, MSRA-TD500, and DOTA-v1.0—demonstrate that the proposed RoMP-Transformer outperforms other state-of-the-art neural networks in object detection in terms of accuracy, robustness, and calculation speed. Systematic analysis also reveals that the methods utilized by the RoMP-Transformer optimize object detection performance. The proposed architecture is expected to inspire further study of deep neural networks for object detection in real-world applications. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Long, C.
AU  - Yuan, H.
AU  - Fang, J.
AU  - Xian, X.
AU  - Liu, G.
AU  - Sheng, V.S.
AU  - Zhao, P.
TI  - Learning Global and Multi-granularity Local Representation with MLP for Sequential Recommendation
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 4
C7  - 87
DO  - 10.1145/3638562
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185802415&doi=10.1145%2f3638562&partnerID=40&md5=b066481b8e2ca586ee7f1cc203cd8a43
AB  - Sequential recommendation aims to predict the next item of interest to users based on their historical behavior data. Usually, users' global and local preferences jointly affect the final recommendation result in different ways. Most existing works use transformers to globally model sequences, which makes them face the dilemma of quadratic computational complexity when dealing with long sequences. Moreover, the scope setting of the user's local preference is usually static and single, and cannot cover richer multi-level local semantics. To this end, we proposed a parallel architecture for capturing global representation and Multi-granularity Local dependencies with MLP for sequential Recommendation (MLM4Rec). For global representation, we utilize modified MLP-Mixer to capture global information of user sequences due to its simplicity and efficiency. For local representation, we incorporate convolution into MLP and propose a multi-granularity local awareness mechanism for capturing richer local semantic information. Moreover, we introduced a weight pooling method to adaptively fuse local-global representations instead of directly concatenation. Our model has the advantages of low complexity and high efficiency thanks to its simple MLP structure. Experimental results on three public datasets demonstrate the effectiveness of our proposed model. Our code is available here. Copyright © 2024 held by the owner/author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Long2024Learning
ER  -

TY  - JOUR
AU  - Dai, K.
AU  - Xie, T.
AU  - Wang, K.
AU  - Jiang, Z.
AU  - Li, R.
AU  - Zhao, L.
TI  - OAMatcher: An overlapping areas-based network with label credibility for robust and accurate feature matching
PY  - 2024
T2  - Pattern Recognition
VL  - 147
C7  - 110094
DO  - 10.1016/j.patcog.2023.110094
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176116938&doi=10.1016%2fj.patcog.2023.110094&partnerID=40&md5=16ab17a57aef5fd6866aa8f0b78e420b
AB  - Local feature matching involves establishing accurate pixel-wise correspondences between an image pair, which is a critical component in several visual applications (e.g., visual localization). Recently, detector-free techniques have realized excellent performance in this task. However, existing methods tend to focus on the entire image without prioritizing overlapping regions, resulting in undesirable interference from non-overlapping areas during the descriptors enhancement process. Moreover, these approaches neglect unreliable ground-truth matching labels triggered by measurement noise in datasets, leading to sub-optimal network optimization. In this study, we develop a novel overlapping areas-based network OAMatcher to resolve these issues. For the first issue, OAMatcher employs an overlapping regions perception block (ORPB) that captures the overlapping areas of image pairs to filter out plentiful mismatches and circumvent interference from non-overlapping regions during descriptors enhancement process. Specifically, the ORPB first enhances the descriptors of all keypoints to mimic the human behaviour of scrutinizing entire images back and forth at the start of feature matching. Subsequently, the ORPB introduces an overlapping regions extraction block (OREB) that captures the keypoints within overlapping zones to mimic the humans behaviour of shifting the focus from the whole images to co-visible areas. After OREB, ORPB performs descriptors enhancement exclusively among the keypoints within these co-visible regions, ensuring minimal disturbances from non-overlapping areas. In addition, the ORPB confines the predicted matches strictly to co-visible regions, thus efficiently filtering out a significant number of mismatches in non-overlapping zones. For the second issue, OAMatcher proposes a labels weighting algorithm (LWA) that predicts the label credibility for ground-truth matching labels. LWA assigns low credibility to unreliable labels and utilizes the credibility to weight loss, effectively diminishing the influence of unreliable labels. Extensive experiments show that OAMatcher delivers excellent results for homography estimation, pose estimation, and visual localization tasks. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Mu, Y.
TI  - Multi-Granularity Interaction for Multi-Person 3D Motion Prediction
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 3
SP  - 1546
EP  - 1558
DO  - 10.1109/TCSVT.2023.3298755
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165920234&doi=10.1109%2fTCSVT.2023.3298755&partnerID=40&md5=83caa00b52c871e4d8c20bcfb81aad11
AB  - Multi-person 3D motion prediction is an emerging task that involves predicting the future 3D motion of multiple individuals based on current observations. In contrast to motion prediction for a single person, this task requires a strong emphasis on learning the interacting dynamics among multiple individuals. Broadly speaking, current methods can be categorized into two groups: The first group involves the straightforward adaptation of models originally developed for single-person scenarios to multi-person scenarios, which is evidently suboptimal. The second group focuses on utilizing off-the-shelf tools like graph convolutional networks to model interactions. While this approach has shown improved results, the interactions primarily consider entire human identities rather than finer details. This motivates the introduction of our novel solution to address this limitation and enhance the task's performance. In this work, we strive to craft a novel framework that can effectively address two key issues ignored in previous works, namely the multi-granularity interaction and time-varying inter-person dynamics. In implementation in accord with above aims, the proposed model has mainly comprised two modules: a person-level interaction module and a part-level interaction module. The former is designed to learn the holistic and dynamic interaction among multiple persons in a coarse-grained sense. Critically, we would emphasize that a unique trait of the former module is learning temporal dynamics. For example, it recognizes that two individuals exhibit a strong correlation during handshaking but less correlation after parting ways. The latter part-level interaction module learns the interaction between the body joints of different persons. This module operates at a more fine-grained level, distinguishing it from existing approaches. By aggregating information from both granularities, our model enables accurate motion prediction. To validate the effectiveness of the proposed model, we conducted comprehensive experiments on three benchmark datasets: 3DPW, CMU-Mocap, and MuPoTS-3D. The results of these evaluations unequivocally demonstrate the empirical superiority of our model compared to previous state-of-the-art methods.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Van Hilten, N.
AU  - Verwei, N.
AU  - Methorst, J.
AU  - Nase, C.
AU  - Bernatavicius, A.
AU  - Risselada, H.J.
TI  - PMIpred: a physics-informed web server for quantitative protein-membrane interaction prediction
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 2
C7  - btae069
DO  - 10.1093/bioinformatics/btae069
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185832770&doi=10.1093%2fbioinformatics%2fbtae069&partnerID=40&md5=8d5f9342b4a555904d3bd9b44d4b1e83
AB  - Motivation: Many membrane peripheral proteins have evolved to transiently interact with the surface of (curved) lipid bilayers. Currently, methods to quantitatively predict sensing and binding free energies for protein sequences or structures are lacking, and such tools could greatly benefit the discovery of membrane-interacting motifs, as well as their de novo design. Results: Here, we trained a transformer neural network model on molecular dynamics data for >50 000 peptides that is able to accurately predict the (relative) membrane-binding free energy for any given amino acid sequence. Using this information, our physics-informed model is able to classify a peptide's membrane-associative activity as either non-binding, curvature sensing, or membrane binding. Moreover, this method can be applied to detect membrane-interaction regions in a wide variety of proteins, with comparable predictive performance as state-of-the-art data-driven tools like DREAMM, PPM3, and MODA, but with a wider applicability regarding protein diversity, and the added feature to distinguish curvature sensing from general membrane binding.  © The Author(s) 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lee, S.
AU  - Kim, H.
TI  - Bidirectional de novo peptide sequencing using a transformer model
PY  - 2024
T2  - PLoS Computational Biology
VL  - 20
IS  - 2
C7  - e1011892
DO  - 10.1371/journal.pcbi.1011892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186141406&doi=10.1371%2fjournal.pcbi.1011892&partnerID=40&md5=03982c27c54d7ceb4b789405c9541c95
AB  - In proteomics, a crucial aspect is to identify peptide sequences. De novo sequencing methods have been widely employed to identify peptide sequences, and numerous tools have been proposed over the past two decades. Recently, deep learning approaches have been introduced for de novo sequencing. Previous methods focused on encoding tandem mass spectra and predicting peptide sequences from the first amino acid onwards. However, when predicting peptides using tandem mass spectra, the peptide sequence can be predicted not only from the first amino acid but also from the last amino acid due to the coexistence of b-ion (or a- or c-ion) and y-ion (or x- or z-ion) fragments in the tandem mass spectra. Therefore, it is essential to predict peptide sequences bidirectionally. Our approach, called NovoB, utilizes a Transformer model to predict peptide sequences bidirectionally, starting with both the first and last amino acids. In comparison to Casanovo, our method achieved an improvement of the average peptide-level accuracy rate of approximately 9.8% across all species. © 2024 Public Library of Science. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ye, J.
AU  - Zhong, B.
AU  - Liang, Q.
AU  - Zhang, S.
AU  - Li, X.
AU  - Ji, R.
TI  - Positive-Sample-Free Object Tracking via a Soft Constraint
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 3
SP  - 1364
EP  - 1375
DO  - 10.1109/TCSVT.2023.3294580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164675926&doi=10.1109%2fTCSVT.2023.3294580&partnerID=40&md5=84bde6444aedb75c179849c9a64e1048
AB  - Most of the existing bounding box-based trackers rely on a classification subnetwork and a regression subnetwork to predict the location and scale of the bounding box. They learn the classification subnetwork by processing each sample individually and applying the suggested classification confidence to produce the final prediction. They typically involve heuristic positive sample configurations, which inevitably introduce mislabelled training samples and therefore deteriorate their tracking performance. Moreover, the parallel prediction of the bounding box position and scale may lead to misalignment of classification and regression. To address these issues,we propose a simple yet effective soft constraint-based tracking framework without positive samples (named SoftCT). SoftCT adaptively senses the target's pixel position through a soft constraint mechanism, which eliminates potential performance gaps caused by artificially marking the target's pixel position. In addition, SoftCT computes the state of the bounding box by aggregating such positional information, thereby allowing the tracker to avoid misalignment in classification and regression due to uninformed communication. Specifically, SoftCT directly senses the position of the target pixel and fuses this information into the bounding box prediction, rather than requiring explicit annotation or regression of the target pixel. Extensive experiments on six tracking benchmarks including GOT-10k, TrackingNet, LaSOT, UAV123, LaSOText and TNL2K demonstrate that our tracker achieves state-of-the-art performance, confirming its effectiveness and efficiency.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yue, G.
AU  - Zhuo, G.
AU  - Yan, W.
AU  - Zhou, T.
AU  - Tang, C.
AU  - Yang, P.
AU  - Wang, T.
TI  - Boundary uncertainty aware network for automated polyp segmentation
PY  - 2024
T2  - Neural Networks
VL  - 170
SP  - 390
EP  - 404
DO  - 10.1016/j.neunet.2023.11.050
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178369759&doi=10.1016%2fj.neunet.2023.11.050&partnerID=40&md5=27e8541b1d6235c121a6418aefbb8387
AB  - Recently, leveraging deep neural networks for automated colorectal polyp segmentation has emerged as a hot topic due to the favored advantages in evading the limitations of visual inspection, e.g., overwork and subjectivity. However, most existing methods do not pay enough attention to the uncertain areas of colonoscopy images and often provide unsatisfactory segmentation performance. In this paper, we propose a novel boundary uncertainty aware network (BUNet) for precise and robust colorectal polyp segmentation. Specifically, considering that polyps vary greatly in size and shape, we first adopt a pyramid vision transformer encoder to learn multi-scale feature representations. Then, a simple yet effective boundary exploration module (BEM) is proposed to explore boundary cues from the low-level features. To make the network focus on the ambiguous area where the prediction score is biased to neither the foreground nor the background, we further introduce a boundary uncertainty aware module (BUM) that explores error-prone regions from the high-level features with the assistance of boundary cues provided by the BEM. Through the top-down hybrid deep supervision, our BUNet implements coarse-to-fine polyp segmentation and finally localizes polyp regions precisely. Extensive experiments on five public datasets show that BUNet is superior to thirteen competing methods in terms of both effectiveness and generalization ability. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xuan, P.
AU  - Gu, J.
AU  - Cui, H.
AU  - Wang, S.
AU  - Toshiya, N.
AU  - Liu, C.
AU  - Zhang, T.
TI  - Multi-scale topology and position feature learning and relationship-aware graph reasoning for prediction of drug-related microbes
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 2
C7  - btae025
DO  - 10.1093/bioinformatics/btae025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185166175&doi=10.1093%2fbioinformatics%2fbtae025&partnerID=40&md5=80dc03513497d9797cb16fe07a7e9347
AB  - Motivation: The human microbiome may impact the effectiveness of drugs by modulating their activities and toxicities. Predicting candidate microbes for drugs can facilitate the exploration of the therapeutic effects of drugs. Most recent methods concentrate on constructing of the prediction models based on graph reasoning. They fail to sufficiently exploit the topology and position information, the heterogeneity of multiple types of nodes and connections, and the long-distance correlations among nodes in microbe–drug heterogeneous graph. Results: We propose a new microbe–drug association prediction model, NGMDA, to encode the position and topological features of microbe (drug) nodes, and fuse the different types of features from neighbors and the whole heterogeneous graph. First, we formulate the position and topology features of microbe (drug) nodes by t-step random walks, and the features reveal the topological neighborhoods at multiple scales and the position of each node. Second, as the features of nodes are high-dimensional and sparse, we designed an embedding enhancement strategy based on supervised fully connected autoencoders to form the embeddings with representative features and the more discriminative node distributions. Third, we propose an adaptive neighbor feature fusion module, which fuses features of neighbors by the constructed position- and topology-sensitive heterogeneous graph neural networks. A novel self-attention mechanism is developed to estimate the importance of the position and topology of each neighbor to a target node. Finally, a heterogeneous graph feature fusion module is constructed to learn the long-distance correlations among the nodes in the whole heterogeneous graph by a relationship-aware graph transformer. Relationship-aware graph transformer contains the strategy for encoding the connection relationship types among the nodes, which is helpful for integrating the diverse semantics of these connections. The extensive comparison experimental results demonstrate NGMDA’s superior performance over five state-of-the-art prediction methods. The ablation experiment shows the contributions of the multi-scale topology and position feature learning, the embedding enhancement strategy, the neighbor feature fusion, and the heterogeneous graph feature fusion. Case studies over three drugs further indicate that NGMDA has ability in discovering the potential drug-related microbes. © 2024 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lin, W.-C.
AU  - Chen, A.
AU  - Song, X.
AU  - Weiskopf, N.G.
AU  - Chiang, M.F.
AU  - Hribar, M.R.
TI  - Prediction of multiclass surgical outcomes in glaucoma using multimodal deep learning based on free-text operative notes and structured EHR data
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 2
SP  - 456
EP  - 464
DO  - 10.1093/jamia/ocad213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182748952&doi=10.1093%2fjamia%2focad213&partnerID=40&md5=47a7859bf9e1b3cb4cbbc8fa2fab8f9a
AB  - Objective: Surgical outcome prediction is challenging but necessary for postoperative management. Current machine learning models utilize pre- and post-op data, excluding intraoperative information in surgical notes. Current models also usually predict binary outcomes even when surgeries have multiple outcomes that require different postoperative management. This study addresses these gaps by incorporating intraoperative information into multimodal models for multiclass glaucoma surgery outcome prediction. Materials and methods: We developed and evaluated multimodal deep learning models for multiclass glaucoma trabeculectomy surgery outcomes using both structured EHR data and free-text operative notes. We compare those to baseline models that use structured EHR data exclusively, or neural network models that leverage only operative notes. Results: The multimodal neural network had the highest performance with a macro AUROC of 0.750 and F1 score of 0.583. It outperformed the baseline machine learning model with structured EHR data alone (macro AUROC of 0.712 and F1 score of 0.486). Additionally, the multimodal model achieved the highest recall (0.692) for hypotony surgical failure, while the surgical success group had the highest precision (0.884) and F1 score (0.775). Discussion: This study shows that operative notes are an important source of predictive information. The multimodal predictive model combining perioperative notes and structured pre- and post-op EHR data outperformed other models. Multiclass surgical outcome prediction can provide valuable insights for clinical decision-making. Conclusions: Our results show the potential of deep learning models to enhance clinical decision-making for postoperative management. They can be applied to other specialties to improve surgical outcome predictions.  © 2023 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Lv, N.
AU  - Xiang, X.
AU  - Wang, X.
AU  - Qiao, Y.
AU  - Saddik, A.E.
TI  - Learning feature contexts by transformer and CNN hybrid deep network for weakly supervised person search
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 239
C7  - 103906
DO  - 10.1016/j.cviu.2023.103906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183765663&doi=10.1016%2fj.cviu.2023.103906&partnerID=40&md5=f7667698cbb37456b9949daebf34f9a3
AB  - Person search is a computer vision task that aims to locate and re-identify specific pedestrians in images captured by non-overlapping cameras. However, the identity annotation in person search is labor-intensive, especially as the amount of data increases. Therefore, more and more studies consider training person search models using weakly supervised learning with only location annotations. The context information is useful to improve feature representations in the absence of pedestrian identity as supervision. Existing weakly supervised person search methods focus on logic-driven contexts while ignoring feature contexts. In this paper, we propose a hybrid deep network for weakly supervised person search. The hybrid architecture consists of a Transformer-based feature extraction network and a fully convolution-based region recognition head network. The purpose is to enable the model to learn feature contexts at different levels. In our network, hierarchical vision Transformers are used to extract features in order to obtain discriminative representations of scene images. The context-enhanced head network is designed to integrate different features for candidate pedestrians. In addition, a pedestrian proposal network is proposed to improve the quality of predicted proposals. Experiments are conducted on the CUHK-SYSU and the PRW benchmarks to evaluate the effectiveness of the proposed method. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Yeung, W.
AU  - Soleymani, S.
AU  - Gravel, N.
AU  - Salcedo, M.
AU  - Li, S.
AU  - Kannan, N.
TI  - Using explainable machine learning to uncover the kinase–substrate interaction landscape
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 2
C7  - btae033
DO  - 10.1093/bioinformatics/btae033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184760683&doi=10.1093%2fbioinformatics%2fbtae033&partnerID=40&md5=a33b3608c8ede341306cce70cc0d647e
AB  - Motivation: Phosphorylation, a post-translational modification regulated by protein kinase enzymes, plays an essential role in almost all cellular processes. Understanding how each of the nearly 500 human protein kinases selectively phosphorylates their substrates is a foundational challenge in bioinformatics and cell signaling. Although deep learning models have been a popular means to predict kinase–substrate relationships, existing models often lack interpretability and are trained on datasets skewed toward a subset of well-studied kinases. Results: Here we leverage recent peptide library datasets generated to determine substrate specificity profiles of 300 serine/threonine kinases to develop an explainable Transformer model for kinase–peptide interaction prediction. The model, trained solely on primary sequences, achieved state-of-the-art performance. Its unique multitask learning paradigm built within the model enables predictions on virtually any kinase–peptide pair, including predictions on 139 kinases not used in peptide library screens. Furthermore, we employed explainable machine learning methods to elucidate the model’s inner workings. Through analysis of learned embeddings at different training stages, we demonstrate that the model employs a unique strategy of substrate prediction considering both substrate motif patterns and kinase evolutionary features. SHapley Additive exPlanation (SHAP) analysis reveals key specificity determining residues in the peptide sequence. Finally, we provide a web interface for predicting kinase–substrate associations for user-defined sequences and a resource for visualizing the learned kinase–substrate associations. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Tan, Y.
AU  - Shen, W.-D.
AU  - Wu, M.-Y.
AU  - Liu, G.-N.
AU  - Zhao, S.-X.
AU  - Chen, Y.
AU  - Yang, K.-F.
AU  - Li, Y.-J.
TI  - Retinal Layer Segmentation in OCT Images with Boundary Regression and Feature Polarization
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 2
SP  - 686
EP  - 700
DO  - 10.1109/TMI.2023.3317072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180704874&doi=10.1109%2fTMI.2023.3317072&partnerID=40&md5=7724dcfb365e36e9a63757daccf33746
AB  - The geometry of retinal layers is an important imaging feature for the diagnosis of some ophthalmic diseases. In recent years, retinal layer segmentation methods for optical coherence tomography (OCT) images have emerged one after another, and huge progress has been achieved. However, challenges due to interference factors such as noise, blurring, fundus effusion, and tissue artifacts remain in existing methods, primarily manifesting as intra-layer false positives and inter-layer boundary deviation. To solve these problems, we propose a method called Tightly combined Cross-Convolution and Transformer with Boundary regression and feature Polarization (TCCT-BP). This method uses a hybrid architecture of CNN and lightweight Transformer to improve the perception of retinal layers. In addition, a feature grouping and sampling method and the corresponding polarization loss function are designed to maximize the differentiation of the feature vectors of different retinal layers, and a boundary regression loss function is devised to constrain the retinal boundary distribution for a better fit to the ground truth. Extensive experiments on four benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance in dealing with problems of false positives and boundary distortion. The proposed method ranked first in the OCT Layer Segmentation task of GOALS challenge held by MICCAI 2022. The source code is available at https://www.github.com/tyb311/TCCT. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cai, H.
AU  - Lan, L.
AU  - Zhang, J.
AU  - Zhang, X.
AU  - Zhan, Y.
AU  - Luo, Z.
TI  - IoUformer: Pseudo-IoU prediction with transformer for visual tracking
PY  - 2024
T2  - Neural Networks
VL  - 170
SP  - 548
EP  - 563
DO  - 10.1016/j.neunet.2023.10.055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178995586&doi=10.1016%2fj.neunet.2023.10.055&partnerID=40&md5=7e504f2989972c81580e41de9261ee17
AB  - Siamese tracking has witnessed tremendous progress in tracking paradigm. However, its default box estimation pipeline still faces a crucial inconsistency issue, namely, the bounding box decided by its classification score is not always best overlapped with the ground truth, thus harming performance. To this end, we explore a novel simple tracking paradigm based on the intersection over union (IoU) value prediction. To first bypass this inconsistency issue, we propose a concise target state predictor termed IoUformer, which instead of default box estimation pipeline directly predicts the IoU values related to tracking performance metrics. In detail, it extends the long-range dependency modeling ability of transformer to jointly grasp target-aware interactions between target template and search region, and search sub-region interactions, thus neatly unifying global semantic interaction and target state prediction. Thanks to this joint strength, IoUformer can predict reliable IoU values near-linear with the ground truth, which paves a safe way for our new IoU-based siamese tracking paradigm. Since it is non-trivial to explore this paradigm with pleased efficacy and portability, we offer the respective network components and two alternative localization ways. Experimental results show that our IoUformer-based tracker achieves promising results with less training data. For its applicability, it still serves as a refinement module to consistently boost existing advanced trackers. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wei, S.
AU  - Lv, J.
AU  - Guo, Y.
AU  - Yang, Q.
AU  - Chen, X.
AU  - Zhao, Y.
AU  - Li, Q.
AU  - Zhuang, F.
AU  - Kou, G.
TI  - Combining intra-risk and contagion risk for enterprise bankruptcy prediction using graph neural networks
PY  - 2024
T2  - Information Sciences
VL  - 659
C7  - 120081
DO  - 10.1016/j.ins.2023.120081
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182456555&doi=10.1016%2fj.ins.2023.120081&partnerID=40&md5=581c064d5eb1e75ac21981408a3c8969
AB  - Predicting the bankruptcy risk of small and medium-sized enterprises (SMEs) is crucial for making decisions about loans. Existing studies in both finance and AI research fields, however, tend to only consider either the intra-risk or contagion risk of enterprises, ignoring their interactions and combinatorial effects. This study for the first time considers both types of risk and their joint effects in bankruptcy prediction. Specifically, we first propose an enterprise intra-risk encoder based on statistically significant enterprise risk indicators for its intra-risk learning. Then, we propose an enterprise contagion risk encoder based on an enterprise knowledge graph for its contagion risk embedding. In particular, the contagion risk encoder includes both the newly proposed Heterogeneous Hyper-Graph Neural Networks (HHGNN) and Hierarchical Graph Transformer Networks (HGTN). Using these two types of encoders, we design a unified framework to simultaneously capture intra-risk and contagion risk for bankruptcy prediction. To evaluate the model, we collect real-world multi-sources data on SMEs and build a novel benchmark dataset called SMEsD. We provide open access to the dataset, which is expected to further promote research on financial risk analysis. Experiments on SMEsD against twelve state-of-the-art baselines demonstrate the effectiveness of the proposed model for bankruptcy prediction. © 2024 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Wei2024Combining
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Mu, C.
AU  - Jiang, H.
AU  - Wang, Y.
AU  - Zhang, J.
AU  - Lin, F.
AU  - Zhou, K.
AU  - Liu, Q.
AU  - Chen, C.
TI  - HARDSEA: Hybrid Analog-ReRAM Clustering and Digital-SRAM In-Memory Computing Accelerator for Dynamic Sparse Self-Attention in Transformer
PY  - 2024
T2  - IEEE Transactions on Very Large Scale Integration (VLSI) Systems
VL  - 32
IS  - 2
SP  - 269
EP  - 282
DO  - 10.1109/TVLSI.2023.3337777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182355525&doi=10.1109%2fTVLSI.2023.3337777&partnerID=40&md5=224fea24634b7d64b9f635363270f189
AB  - Self-attention-based transformers have outperformed recurrent and convolutional neural networks (RNN/ CNNs) in many applications. Despite the effectiveness, calculating self-attention is prohibitively costly due to quadratic computation and memory requirements. To solve this challenge, this article proposes a hybrid analog-ReRAM and digital-SRAM in-memory computing accelerator (HARDSEA), a computing-in-memory (CIM) accelerator supporting self-attention in transformer applications. To trade off between energy efficiency and algorithm accuracy, HARDSEA features an algorithm-architecture-circuit codesign. A product-quantization-based scheme dynamically facilitates self-attention sparsity by predicting lightweight token relevance. A hybrid in-memory computing architecture employs both high-efficiency analog ReRAM-CIM and high-precision digital SRAM-CIM to implement the proposed new scheme. The ReRAM-CIM, whose precision is sensitive to circuit nonidealities, takes charge of token relevance prediction where only computing monotonicity is demanded. The SRAM-CIM, utilized for exact sparse attention computing, is reorganized as an on-memoryboundary computing scheme, thus adapting to irregular sparsity patterns. In addition, we propose a time-domain winner-take-all (WTA) circuit to replace the expensive ADCs in ReRAM-CIM macros. Experimental results show that HARDSEA prunes BERT and GPT-2 models to 12% 33% sparsity without accuracy loss, achieving 13.5× 28.5× speedup and 291.6× 1894.3× energy efficiency over GPU. Compared to state-of-the-art transformer accelerators, HARDSEA has 1.2× 14.9× better energy efficiency at the same level of throughput.  © 1993-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ali, A.
AU  - Xia, Y.
AU  - Umer, Q.
AU  - Osman, M.
TI  - BERT based severity prediction of bug reports for the maintenance of mobile applications
PY  - 2024
T2  - Journal of Systems and Software
VL  - 208
C7  - 111898
DO  - 10.1016/j.jss.2023.111898
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177209975&doi=10.1016%2fj.jss.2023.111898&partnerID=40&md5=00dbb945efc3e30a8ca3648181df57ee
AB  - Mobile application maintenance is crucial to ensuring the accurate operation and continuous improvement of mobile applications (mobile apps). To effectively address issues and enhance the user experience, developers utilize issue-tracking systems that gather bug reports to refine mobile apps. Users can submit bugs through these systems, allowing them to determine the severity of each reported issue. The severity level plays a pivotal role in prioritizing bug resolution, enabling developers to address critical bugs promptly. Nonetheless, manually assessing the severity of each issue can be laborious and prone to errors. To overcome this challenge, this paper presents Bidirectional Encoder Representations from Transformers (BERT) based severity prediction of bug reports (called BERT-SBR) that leverages a deep neural network for automatic bug severity classification for mobile app maintenance. We collect the publicly available mobile apps bug reports dataset from the Hugging Face. BERT-SBR first computes the sentiment of reporters of bug reports and preprocesses them by leveraging BertTokenizer input formatting techniques. Next, it passes the formatted text and computed sentiment of each bug report to generate word embeddings. Then, it introduces a fine-tuned BERT classifier for bug report severity prediction. After that, it passes the generated word embeddings to the fine-tuned BERT classifier for training and testing. Finally, the proposed classifier's performance is evaluated. The BERT-SBR assessment results confirm that the fine-tuned BERT classifies bug reports significantly more effectively than other deep learning classifiers. On average, BERT-SBR achieves a remarkable improvement of 40.43%, 67.78%, 40.71%, and 58.14% in the accuracy, precision, recall, and f-measure. This indicates its superiority in accurately predicting the severity of bug reports for mobile application maintenance. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Hu, X.
AU  - Zhong, B.
AU  - Liang, Q.
AU  - Zhang, S.
AU  - Li, N.
AU  - Li, X.
AU  - Ji, R.
TI  - Transformer Tracking via Frequency Fusion
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 2
SP  - 1020
EP  - 1031
DO  - 10.1109/TCSVT.2023.3289624
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163548129&doi=10.1109%2fTCSVT.2023.3289624&partnerID=40&md5=9725c6d72dcd7e5c27a7be555f6c1a9c
AB  - Transformer has achieved impressive progress in visual tracking due to their capability of global modeling, which enables them to learn low-frequency features(i.e., high-level semantic information). However, it seems to overlook the high-frequency features(i.e., low-level texture and edge information) which are crucial to identify different intra-class object instances in the tracking task. To address this issue, we propose a transformer based tracker via frequency fusion perspective that investigated whether high-frequency and low-frequency features can be effectively combined to achieve robust tracking. Specifically, we design a simple yet effective two-stage fusion strategy and use an appropriate frequency fusion strategy in tracking process of each stage so as to make full use of frequency domain information. In the feature extraction stage, we use wavelet decomposition of high-frequency subbands to solve the performance loss caused by the transformer's catastrophic forgetting of high-frequency information. In the prediction head stage, we use a variety of wavelet decomposition subbands to model the multi-frequency information. The two-stage fusion strategy makes our model extract more balanced and beneficial multi-frequency information, enabling it to effectively capture target texture information and local edge information while also being sensitive to global information. Extensive experiments on six challenging benchmarks (i.e., LaSOT ext, UAV123, TNL2K, LaSOT, TrackingNet, and GOT-10k) demonstrates the superior performance of our tracker.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Yang, G.
AU  - Zuo, W.
AU  - Zang, T.
TI  - DPDFormer: A Coarse-to-Fine Model for Monocular Depth Estimation
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 5
C7  - 139
DO  - 10.1145/3638559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185220479&doi=10.1145%2f3638559&partnerID=40&md5=36ad11afedbeb399776c6422a7e5d762
AB  - Monocular depth estimation attracts great attention from computer vision researchers for its convenience in acquiring environment depth information. Recently classification-based MDE methods show its promising performance and begin to act as an essential role in many multi-view applications such as reconstruction and 3D object detection. However, existed classification-based MDE models usually apply fixed depth range discretization strategy across a whole scene. This fixed depth range discretization leads to the imbalance of discretization scale among different depth ranges, resulting in the inexact depth range localization. In this article, to alleviate the imbalanced depth range discretization problem in classification-based monocular depth estimation (MDE) method we follow the coarse-to-fine principle and propose a novel depth range discretization method called depth post-discretization (DPD). Based on a coarse depth anchor roughly indicating the depth range, the DPD generates the depth range discretization adaptively for every position. The depth range discretization with DPD is more fine-grained around the actual depth, which is beneficial for locating the depth range more precisely for each scene position. Besides, to better manage the prediction of the coarse depth anchor and depth probability distribution for calculating the final depth, we design a dual-decoder transformer-based network, i.e., DPDFormer, which is more compatible with our proposed DPD method. We evaluate DPDFormer on popular depth datasets NYU Depth V2 and KITTI. The experimental results prove the superior performance of our proposed method.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Li, G.
AU  - Shi, J.
AU  - Xi, J.
TI  - Weighted Guided Optional Fusion Network for RGB-T Salient Object Detection
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 5
C7  - 136
DO  - 10.1145/3624984
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185335598&doi=10.1145%2f3624984&partnerID=40&md5=4f0e359679a0f929201ceaf018d4ed81
AB  - There is no doubt that the rational and effective use of visible and thermal infrared image data information to achieve cross-modal complementary fusion is the key to improving the performance of RGB-T salient object detection (SOD). A meticulous analysis of the RGB-T SOD data reveals that it mainly consists of three scenarios in which both modalities (RGB and T) have a significant foreground and only a single modality (RGB or T) is disturbed. However, existing methods are obsessed with pursuing more effective cross-modal fusion based on treating both modalities equally. Obviously, the subjective use of equivalence has two significant limitations. Firstly, it does not allow for practical discrimination of which modality makes the dominant contribution to performance. While both modalities may have visually significant foregrounds, differences in their imaging properties will result in distinct performance contributions. Secondly, in a specific acquisition scenario, a pair of images with two modalities will contribute differently to the final detection performance due to their varying sensitivity to the same background interference. Intelligibly, for the RGB-T saliency detection task, it would be more reasonable to generate exclusive weights for the two modalities and select specific fusion mechanisms based on different weight configurations to perform cross-modal complementary integration. Consequently, we propose a weighted guided optional fusion network (WGOFNet) for RGB-T SOD. Specifically, a feature refinement module is first used to perform an initial refinement of the extracted multilevel features. Subsequently, a weight generation module (WGM) will generate exclusive network performance contribution weights for each of the two modalities, and an optional fusion module (OFM) will rely on this weight to perform particular integration of cross-modal information. Simple cross-level fusion is finally utilized to obtain the final saliency prediction map. Comprehensive experiments on three publicly available benchmark datasets demonstrate the proposed WGOFNet achieves superior performance compared with the state-of-the-art RGB-T SOD methods. The source code is available at: https://github.com/WJ-CV/WGOFNet. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Wu, S.
AU  - Wang, B.
AU  - Yang, M.
AU  - Wu, Z.
AU  - Yao, Y.
AU  - Wei, Z.
TI  - Two-stage fine-grained image classification model based on multi-granularity feature fusion
PY  - 2024
T2  - Pattern Recognition
VL  - 146
C7  - 110042
DO  - 10.1016/j.patcog.2023.110042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174442880&doi=10.1016%2fj.patcog.2023.110042&partnerID=40&md5=13f941c5ed2702f06bd74b1a34ab1ca9
AB  - Fine-grained visual classification (FGVC) is a difficult task due to the challenges of discriminative feature learning. Most existing methods directly use the final output of the network which always contains the global feature with high-level semantic information. However, the differences between fine-grained images are reflected in subtle local regions which often appear in the front of the network. When the texture of the background and object are similar or the proportion of the background is too large, the prediction will be greatly affected. In order to solve the above problems, this paper proposes multi-granularity feature fusion module (MGFF) and two-stage classification based on Vision-Transformer (ViT). The former comprehensively represents images by fusing features of different granularities, thus avoiding the limitations of single-scale features. The latter leverages the ViT model to separate the object from the background at a very small cost, thereby improving the accuracy of the prediction. We conduct comprehensive experiments and achieves the best performance in two fine-grained tasks on CUB-200-2011 and NA-Birds. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Li, X.
AU  - Yuan, H.
AU  - Yang, Y.
AU  - Zhang, L.
TI  - Multi-Task Learning With Multi-Query Transformer for Dense Prediction
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 2
SP  - 1228
EP  - 1240
DO  - 10.1109/TCSVT.2023.3292995
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164447233&doi=10.1109%2fTCSVT.2023.3292995&partnerID=40&md5=42901e84e799963ba2654de73fe825a7
AB  - Previous multi-task dense prediction studies developed complex pipelines such as multi-modal distillations in multiple stages or searching for task relational contexts for each task. The core insight beyond these methods is to maximize the mutual effects of each task. Inspired by the recent query-based Transformers, we propose a simple pipeline named Multi-Query Transformer (MQTransformer) that is equipped with multiple queries from different tasks to facilitate the reasoning among multiple tasks and simplify the cross-task interaction pipeline. Instead of modeling the dense per-pixel context among different tasks, we seek a task-specific proxy to perform cross-task reasoning via multiple queries where each query encodes the task-related context. The MQTransformer is composed of three key components: shared encoder, cross-task query attention module and shared decoder. We first model each task with a task-relevant query. Then both the task-specific feature output by the feature extractor and the task-relevant query are fed into the shared encoder, thus encoding the task-relevant query from the task-specific feature. Secondly, we design a cross-task query attention module to reason the dependencies among multiple task-relevant queries; this enables the module to only focus on the query-level interaction. Finally, we use a shared decoder to gradually refine the image features with the reasoned query features from different tasks. Extensive experiment results on two dense prediction datasets (NYUD-v2 and PASCAL-Context) show that the proposed method is an effective approach and achieves state-of-the-art results. Code and models are available at https://github.com/yangyangxu0/MQTransformer.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, H.
AU  - Zhou, J.T.
AU  - Ong, Y.-S.
TI  - Word2Pix: Word to Pixel Cross-Attention Transformer in Visual Grounding
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 2
SP  - 1523
EP  - 1533
DO  - 10.1109/TNNLS.2022.3183827
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133785024&doi=10.1109%2fTNNLS.2022.3183827&partnerID=40&md5=b39c6367bfb1ceac4ddd0aaa49fb9e77
AB  - Current one-stage methods for visual grounding encode the language query as one holistic sentence embedding before fusion with visual features for target localization. Such a formulation provides insufficient ability to model query at the word level, and therefore is prone to neglect words that may not be the most important ones for a sentence but are critical for the referred object. In this article, we propose Word2Pix: a one-stage visual grounding network based on the encoder-decoder transformer architecture that enables learning for textual to visual feature correspondence via word to pixel attention. Each word from the query sentence is given an equal opportunity when attending to visual pixels through multiple stacks of transformer decoder layers. In this way, the decoder can learn to model the language query and fuse language with the visual features for target prediction simultaneously. We conduct the experiments on RefCOCO, RefCOCO+, and RefCOCOg datasets, and the proposed Word2Pix outperforms the existing one-stage methods by a notable margin. The results obtained also show that Word2Pix surpasses the two-stage visual grounding models, while at the same time keeping the merits of the one-stage paradigm, namely, end-to-end training and fast inference speed. Code is available at https://github.com/azurerain7/Word2Pix.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qaraei, M.
AU  - Babbar, R.
TI  - Meta-classifier free negative sampling for extreme multilabel classification
PY  - 2024
T2  - Machine Learning
VL  - 113
IS  - 2
SP  - 675
EP  - 697
DO  - 10.1007/s10994-023-06468-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177094024&doi=10.1007%2fs10994-023-06468-w&partnerID=40&md5=525baedb0c316f55247e55b19bc5ec94
AB  - Negative sampling is a common approach for making the training of deep models in classification problems with very large output spaces, known as extreme multilabel classification (XMC) problems, tractable. Negative sampling methods aim to find per instance negative labels with higher scores, known as hard negatives, and limit the computations of the negative part of the loss to these labels. Two well-known methods for negative sampling in XMC models are meta-classifier-based and Maximum Inner product Search (MIPS)-based adaptive methods. Owing to their good prediction performance, methods which employ a meta classifier are more common in contemporary XMC research. On the flip side, they need to train and store the meta classifier (apart from the extreme classifier), which can involve millions of additional parameters. In this paper, we focus on the MIPS-based methods for negative sampling. We highlight two issues which may prevent deep models trained by these methods to undergo stable training. First, we argue that using hard negatives excessively from the beginning of training leads to unstable gradient. Second, we show that when all the negative labels in a MIPS-based method are restricted to only those determined by MIPS, training is sensitive to the length of intervals for pre-processing the weights in the MIPS method. To mitigate the aforementioned issues, we propose to limit the labels selected by MIPS to only a few and sample the rest of the needed labels from a uniform distribution. We show that our proposed MIPS-based negative sampling can reach the performance of LightXML, a transformer-based model trained by a meta classifier, while there is no need to train and store any additional classifier. The code for our experiments is available at https://github.com/xmc-aalto/mips-negative-sampling . © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tipirneni, S.
AU  - Zhu, M.
AU  - Reddy, C.K.
TI  - StructCoder: Structure-Aware Transformer for Code Generation
PY  - 2024
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 18
IS  - 3
C7  - 70
DO  - 10.1145/3636430
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182592552&doi=10.1145%2f3636430&partnerID=40&md5=83d3c6b1e1501d6e397d1f403653db6e
AB  - There has been a recent surge of interest in automating software engineering tasks using deep learning. This article addresses the problem of code generation, in which the goal is to generate target code given source code in a different language or a natural language description. Most state-of-the-art deep learning models for code generation use training strategies primarily designed for natural language. However, understanding and generating code requires a more rigorous comprehension of the code syntax and semantics. With this motivation, we develop an encoder-decoder Transformer model in which both the encoder and decoder are explicitly trained to recognize the syntax and dataflow in the source and target codes, respectively. We not only make the encoder structure aware by leveraging the source code's syntax tree and dataflow graph, but we also support the decoder in preserving the syntax and dataflow of the target code by introducing two novel auxiliary tasks: Abstract Syntax Tree (AST) path prediction and dataflow prediction. To the best of our knowledge, this is the first work to introduce a structure-aware Transformer decoder that models both syntax and dataflow to enhance the quality of generated code. The proposed StructCoder model achieves state-of-the-art performance on code translation and text-to-code generation tasks in the CodeXGLUE benchmark and improves over baselines of similar size on the APPS code generation benchmark. Our code is publicly available at https://github.com/reddy-lab-code-research/StructCoder/.  © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Tipirneni2024StructCoder
ER  -

TY  - JOUR
AU  - Jaffari, Z.H.
AU  - Abbas, A.
AU  - Kim, C.-M.
AU  - Shin, J.
AU  - Kwak, J.
AU  - Son, C.
AU  - Lee, Y.-G.
AU  - Kim, S.
AU  - Chon, K.
AU  - Cho, K.H.
TI  - Transformer-based deep learning models for adsorption capacity prediction of heavy metal ions toward biochar-based adsorbents
PY  - 2024
T2  - Journal of Hazardous Materials
VL  - 462
C7  - 132773
DO  - 10.1016/j.jhazmat.2023.132773
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174729571&doi=10.1016%2fj.jhazmat.2023.132773&partnerID=40&md5=f56008d87ab430532166cf4fb0cdec7a
AB  - Biochar adsorbents synthesized from food and agricultural wastes are commonly applied to eliminate heavy metal (HM) ions from wastewater. However, biochar's diverse characteristics and varied experimental conditions make the accurate estimation of their adsorption capacity (qe) challenging. Herein, various machine-learning (ML) and three deep learning (DL) models were built using 1518 data points to predict the qe of HM on various biochars. The recursive feature elimination technique with 28 inputs suggested that 14 inputs were significant for model building. FT-transformer with the highest test R2 (0.98) and lowest root mean square error (RMSE) (0.296) and mean absolute error (MAE) (0.145) outperformed various ML and DL models. The SHAP feature importance analysis of the FT-transformer model predicted that the adsorption conditions (72.12%) were more important than the pyrolysis conditions (25.73%), elemental composition (1.39%), and biochar's physical properties (0.73%). The two-feature SHAP analysis proposed the optimized process conditions including adsorbent loading of 0.25 g, initial concentration of 12 mg/L, and solution pH of 9 using phosphoric-acid pre-treated biochar synthesized from banana-peel with a higher O/C ratio. The t-SNE technique was applied to transform the 14-input matrix of the FT-Transformer into two-dimensional data. Finally, we outlined the study's environmental implications. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 30
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Vairetti, C.
AU  - Aránguiz, I.
AU  - Maldonado, S.
AU  - Karmy, J.P.
AU  - Leal, A.
TI  - Analytics-driven complaint prioritisation via deep learning and multicriteria decision-making
PY  - 2024
T2  - European Journal of Operational Research
VL  - 312
IS  - 3
SP  - 1108
EP  - 1118
DO  - 10.1016/j.ejor.2023.08.027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171162315&doi=10.1016%2fj.ejor.2023.08.027&partnerID=40&md5=50533b37c9e380abca955c4b4a5c1fe3
AB  - Complaint analysis is an essential business analytics application because complaints have a strong influence on customer satisfaction (CSAT). However, the process of categorising and prioritising complaints manually can be extremely time consuming for large companies. In this paper, we propose a framework for automatic complaint labelling and prioritisation using text analytics and operational research techniques. The labelling step of the training set is performed using a simple weighting approach from the multiple-criteria decision-making (MCDM) literature, while transformer-based deep learning (DL) techniques are used for text classification. We define two priority classes, namely, urgent complaints and other claims, and develop a system for automatic complaint categorisation. Our experimental results show that excellent predictive performance can be achieved with state-of-the-art text classification models. In particular, BETO, a bidirectional encoder representations from transformers (BERT) model trained on a large Spanish corpus, reaches an accuracy (ACCU) and area under the curve (AUC) of 92.1% and 0.9785, respectively. This positive result translates into a successful complaint prioritisation scheme, which improves CSAT and reduces the churn rate. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Vairetti2024Analytics-driven
ER  -

TY  - JOUR
AU  - Bernabe, P.
AU  - Gotlieb, A.
AU  - Legeard, B.
AU  - Marijan, D.
AU  - Sem-Jacobsen, F.O.
AU  - Spieker, H.
TI  - Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 2
SP  - 1166
EP  - 1177
DO  - 10.1109/TITS.2023.3322690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174799109&doi=10.1109%2fTITS.2023.3322690&partnerID=40&md5=7932ecfa3f3fe064a584b286e9a54436
AB  - In maritime traffic surveillance, detecting illegal activities, such as illegal fishing or transshipment of illicit products is a crucial task of the coastal administration. In the open sea, one has to rely on Automatic Identification System (AIS) message transmitted by on-board transponders, which are captured by surveillance satellites. However, insincere vessels often intentionally shut down their AIS transponders to hide illegal activities. In the open sea, it is very challenging to differentiate intentional AIS shutdowns from missing reception due to protocol limitations, bad weather conditions or restricting satellite positions. This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models. Using historical data, the trained model predicts if a message should be received in the upcoming minute or not. Afterwards, the model reports on detected anomalies by comparing the prediction with what actually happens. Our method can process AIS messages in real-time, in particular, more than 500 Millions AIS messages per month, corresponding to the trajectories of more than 60 000 ships. The method is evaluated on 1-year of real-world data coming from four Norwegian surveillance satellites. Using related research results, we validated our method by rediscovering already detected intentional AIS shutdowns.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Bernabe2024Detecting
ER  -

TY  - JOUR
AU  - Yelleni, S.H.
AU  - Kumari, D.
AU  - Srijith, P.K.
AU  - Krishna Mohan, C.
TI  - Monte Carlo DropBlock for modeling uncertainty in object detection
PY  - 2024
T2  - Pattern Recognition
VL  - 146
C7  - 110003
DO  - 10.1016/j.patcog.2023.110003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173893757&doi=10.1016%2fj.patcog.2023.110003&partnerID=40&md5=afc6fb075aba71b19ac4a8fb259599fc
AB  - With the advancements made in deep learning, computer vision problems have seen a great improvement in performance. However, in many real-world applications such as autonomous driving vehicles, the risk associated with incorrect predictions of objects or segmentation of images is very high. Standard deep learning models for object detection and segmentation such as YOLO models are often overconfident in their predictions and do not take into account the uncertainty in predictions on out-of-distribution data. In this work, we propose an efficient and effective approach, Monte-Carlo DropBlock (MC-DropBlock), to model uncertainty in YOLO and convolutional vision Transformers for object detection. The proposed approach applies drop-block during training time and testing time on the convolutional layer of the deep learning models such as YOLO and convolutional transformer. We theoretically show that this leads to a Bayesian convolutional neural network capable of capturing the epistemic uncertainty in the model. Additionally, we capture the aleatoric uncertainty in the data using a Gaussian likelihood. We demonstrate the effectiveness of the proposed approach on modeling uncertainty in object detection and segmentation tasks using out-of-distribution experiments. Experimental results show that MC-DropBlock improves the generalization, calibration, and uncertainty modeling capabilities of YOLO models and convolutional Transformer models for object detection and segmentation. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, J.
AU  - Wang, Z.
AU  - Wang, G.
AU  - Huang, B.
AU  - Yang, Y.
AU  - Tu, W.
TI  - Auxiliary Information Guided Self-Attention for Image Quality Assessment
PY  - 2024
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 4
C7  - 119
DO  - 10.1145/3635716
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182602523&doi=10.1145%2f3635716&partnerID=40&md5=d3b2ab529c3f57bef7761db24dd416f0
AB  - Image quality assessment (IQA) is an important problem in computer vision with many applications. We propose a transformer-based multi-Task learning framework for the IQA task. Two subtasks: constructing an auxiliary information error map and completing image quality prediction, are jointly optimized using a shared feature extractor. We use visual transformers (ViT) as a feature extractor for feature extraction and guide ViT to focus on image quality-related features by building auxiliary information error map subtask. In particular, we propose a fusion network that includes a channel focus module. Unlike the fusion methods commonly used in previous IQA methods, we use the fusion network, including the channel attention module, to fuse the auxiliary information error map features with the image features, which facilitates the model to mine the image quality features for more accurate image quality assessment. And by jointly optimizing the two subtasks, ViT focuses more on extracting image quality features and building a more precise mapping from feature representation to quality score. With slight adjustments to the model, our approach can be used in both no-reference (NR) and full-reference (FR) IQA environments. We evaluate the proposed method in multiple IQA databases, showing better performance than state-of-The-Art FR and NR IQA methods.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Lang, R.
AU  - Li, R.
AU  - Zhang, J.
TI  - NRTR: Neuron Reconstruction with Transformer from 3D Optical Microscopy Images
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 2
SP  - 886
EP  - 898
DO  - 10.1109/TMI.2023.3323466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174811022&doi=10.1109%2fTMI.2023.3323466&partnerID=40&md5=b4fd98dcf708fd5c25b316dc4e0a9595
AB  - The neuron reconstruction from raw Optical Microscopy (OM) image stacks is the basis of neuroscience. Manual annotation and semi-automatic neuron tracing algorithms are time-consuming and inefficient. Existing deep learning neuron reconstruction methods, although demonstrating exemplary performance, greatly demand complex rule-based components. Therefore, a crucial challenge is designing an end-to-end neuron reconstruction method that makes the overall framework simpler and model training easier. We propose a Neuron Reconstruction Transformer (NRTR) that, discarding the complex rule-based components, views neuron reconstruction as a direct set-prediction problem. To the best of our knowledge, NRTR is the first image-to-set deep learning model for end-to-end neuron reconstruction. The overall pipeline consists of the CNN backbone, Transformer encoder-decoder, and connectivity construction module. NRTR generates a point set representing neuron morphological characteristics for raw neuron images. The relationships among the points are established through connectivity construction. The point set is saved as a standard SWC file. In experiments using the BigNeuron and VISoR-40 datasets, NRTR achieves excellent neuron reconstruction results for comprehensive benchmarks and outperforms competitive baselines. Results of extensive experiments indicate that NRTR is effective at showing that neuron reconstruction is viewed as a set-prediction problem, which makes end-to-end model training available. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, G.
AU  - Wang, R.
AU  - Liu, Y.
AU  - Zhu, Z.
AU  - Gao, C.
AU  - Liu, L.
AU  - Sang, N.
TI  - An Adaptive Post-Processing Network With the Global-Local Aggregation for Semantic Segmentation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 2
SP  - 1159
EP  - 1173
DO  - 10.1109/TCSVT.2023.3292156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164388132&doi=10.1109%2fTCSVT.2023.3292156&partnerID=40&md5=a52700030c6e8a42b70e63c3de273161
AB  - Current semantic segmentation methods mainly focus on modeling the context of the global image to obtain high-quality segmentation results. However, they ignore the role of local image patches, which contain complementary and effective context information. In this paper, we propose an adaptive post-processing network (APPNet) for semantic segmentation based on the predictions of current methods in the global image and local image patches. The key point of APPNet is the global-local aggregation module, which models the context between global predictions and local predictions to generate accurate pixel-wise representation. Furthermore, we develop an adaptive points replacement module to compensate for the lack of fine detail in global prediction and the overconfidence in local predictions. Our method can be readily integrated into existing segmentation methods (i.e., ConvNeXt, HRNet, ViT-Adapter) with little memory and without extra modification in current models. We empirically demonstrate our method brings performance improvements across diverse datasets (i.e., Cityscapes, ADE20K, PASCAL-Context, COCO-Stuff). The code and models will be publicly available at https://github.com/zhu-gl-ux/APPN.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fu, M.
AU  - Tantithamthavorn, C.
AU  - Le, T.
AU  - Kume, Y.
AU  - Nguyen, V.
AU  - Phung, D.
AU  - Grundy, J.
TI  - AIBugHunter: A Practical tool for predicting, classifying and repairing software vulnerabilities
PY  - 2024
T2  - Empirical Software Engineering
VL  - 29
IS  - 1
C7  - 4
DO  - 10.1007/s10664-023-10346-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177178535&doi=10.1007%2fs10664-023-10346-3&partnerID=40&md5=a2dc8557c9f85d763a69284ed60d482a
AB  - Many Machine Learning(ML)-based approaches have been proposed to automatically detect, localize, and repair software vulnerabilities. While ML-based methods are more effective than program analysis-based vulnerability analysis tools, few have been integrated into modern Integrated Development Environments (IDEs), hindering practical adoption. To bridge this critical gap, we propose in this article AIBugHunter, a novel Machine Learning-based software vulnerability analysis tool for C/C++ languages that is integrated into the Visual Studio Code (VS Code) IDE. AIBugHunter helps software developers to achieve real-time vulnerability detection, explanation, and repairs during programming. In particular, AIBugHunter scans through developers’ source code to (1) locate vulnerabilities, (2) identify vulnerability types, (3) estimate vulnerability severity, and (4) suggest vulnerability repairs. We integrate our previous works (i.e., LineVul and VulRepair) to achieve vulnerability localization and repairs. In this article, we propose a novel multi-objective optimization (MOO)-based vulnerability classification approach and a transformer-based estimation approach to help AIBugHunter accurately identify vulnerability types and estimate severity. Our empirical experiments on a large dataset consisting of 188K+ C/C++ functions confirm that our proposed approaches are more accurate than other state-of-the-art baseline methods for vulnerability classification and estimation. Furthermore, we conduct qualitative evaluations including a survey study and a user study to obtain software practitioners’ perceptions of our AIBugHunter tool and assess the impact that AIBugHunter may have on developers’ productivity in security aspects. Our survey study shows that our AIBugHunter is perceived as useful where 90% of the participants consider adopting our AIBugHunter during their software development. Last but not least, our user study shows that our AIBugHunter can enhance developers’ productivity in combating cybersecurity issues during software development. AIBugHunter is now publicly available in the Visual Studio Code marketplace. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Gong, H.
TI  - A Dual-Attention Learning Network with Word and Sentence Embedding for Medical Visual Question Answering
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 2
SP  - 832
EP  - 845
DO  - 10.1109/TMI.2023.3322868
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174830728&doi=10.1109%2fTMI.2023.3322868&partnerID=40&md5=45d49b05ea2d5ab5fe8b90e153a8ec8a
AB  - Research in medical visual question answering (MVQA) can contribute to the development of computer-aided diagnosis. MVQA is a task that aims to predict accurate and convincing answers based on given medical images and associated natural language questions. This task requires extracting medical knowledge-rich feature content and making fine-grained understandings of them. Therefore, constructing an effective feature extraction and understanding scheme are keys to modeling. Existing MVQA question extraction schemes mainly focus on word information, ignoring medical information in the text, such as medical concepts and domain-specific terms. Meanwhile, some visual and textual feature understanding schemes cannot effectively capture the correlation between regions and keywords for reasonable visual reasoning. In this study, a dual-attention learning network with word and sentence embedding (DALNet-WSE) is proposed. We design a module, transformer with sentence embedding (TSE), to extract a double embedding representation of questions containing keywords and medical information. A dual-attention learning (DAL) module consisting of self-attention and guided attention is proposed to model intensive intramodal and intermodal interactions. With multiple DAL modules (DALs), learning visual and textual co-attention can increase the granularity of understanding and improve visual reasoning. Experimental results on the ImageCLEF 2019 VQA-MED (VQA-MED 2019) and VQA-RAD datasets demonstrate that our proposed method outperforms previous state-of-the-art methods. According to the ablation studies and Grad-CAM maps, DALNet-WSE can extract rich textual information and has strong visual reasoning ability. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, M.
AU  - Tu, Z.
AU  - Su, T.
AU  - Wang, X.
AU  - Xu, X.
AU  - Wang, Z.
TI  - BehaviorNet: A Fine-grained Behavior-aware Network for Dynamic Link Prediction
PY  - 2024
T2  - ACM Transactions on the Web
VL  - 18
IS  - 2
C7  - 25
DO  - 10.1145/3580514
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190585545&doi=10.1145%2f3580514&partnerID=40&md5=2d1b4a4c9221dcf1934b1a0b7aa2aea6
AB  - Dynamic link prediction has become a trending research subject because of its wide applications in the web, sociology, transportation, and bioinformatics. Currently, the prevailing approach for dynamic link prediction is based on graph neural networks, in which graph representation learning is the key to perform dynamic link prediction tasks. However, there are still great challenges because the structure of graphs evolves over time. A common approach is to represent a dynamic graph as a collection of discrete snapshots, in which information over a period is aggregated through summation or averaging. This way results in some fine-grained time-related information loss, which further leads to a certain degree of performance degradation. We conjecture that such fine-grained information is vital because it implies specific behavior patterns of nodes and edges in a snapshot. To verify this conjecture, we propose a novel fine-grained behavior-aware network (BehaviorNet) for dynamic network link prediction. Specifically, BehaviorNet adapts a transformer-based graph convolution network to capture the latent structural representations of nodes by adding edge behaviors as an additional attribute of edges. GRU is applied to learn the temporal features of given snapshots of a dynamic network by utilizing node behaviors as auxiliary information. Extensive experiments are conducted on several real-world dynamic graph datasets, and the results show significant performance gains for BehaviorNet over several state-of-the-art (SOTA) discrete dynamic link prediction baselines. Ablation study validates the effectiveness of modeling fine-grained edge and node behaviors. © 2024 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ni, X.
AU  - Yuan, L.
AU  - Lv, K.
TI  - Efficient Single-Object Tracker Based on Local-Global Feature Fusion
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 2
SP  - 1114
EP  - 1122
DO  - 10.1109/TCSVT.2023.3290868
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163565530&doi=10.1109%2fTCSVT.2023.3290868&partnerID=40&md5=b7e749645be11012e52ba34f64f7b6fa
AB  - Since Vision Transformers (ViTs) are introduced into computer vision, they have developed rapidly in a variety of visual tasks. Recently, they have been gradually applied to visual tracking. The Transformer can adaptively capture the global similarity comparisons of target objects and search regions, which has achieved competitive performance results. However, Transformer architectures often require a large amount of training data and computing resources, and lack prior knowledge of inductive biases that existed in images. The advantages of convolutional neural networks (CNNs) in extracting local similarities are not fully exploited. To resolve these problems, we propose a lightweight tracking architecture, combining CNN and Transformer in the feature fusion stage. Specifically, Local-Global Feature Interaction (LGFI) module and Feature Cross-Fusion (FCF) module are the key components in our approach. In the LGFI module, the proposed method includes a Transformer global information network and a Transformer-like CNN local information network for simultaneous global scope dependency establishment and local feature similarity enhancement, then aggregates their feature results together. In the FCF module, the proposed method includes a multi-head cross-attention and a convolutional feedforward network for feature fusion of templates and search regions. Finally, we use the classification and regression head to predict the exact location of the target. Extensive experiments demonstrate that, our method achieves better tracking performance than the baseline method, when both methods are trained with fewer data. Meanwhile, without any extra training data, the proposed method also obtains comparable results with other state-of-the-art trackers on six challenging benchmarks, including GOT-10k, LaSOT, TrackingNet, OTB100, UAV123, and NFS. Furthermore, our model is lightweight compared with the baseline method, with fewer parameters and lower FLOPs, while running at real-time speed.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Zhong, B.
AU  - Chen, Y.
TI  - Motion-Driven Tracking via End-to-End Coarse-to-Fine Verifying
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 2
SP  - 1007
EP  - 1019
DO  - 10.1109/TCSVT.2023.3289620
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163488019&doi=10.1109%2fTCSVT.2023.3289620&partnerID=40&md5=4d6ad03cddc82e86679746fc248ca493
AB  - Target appearance and motion variations are the primary challenges in visual tracking. To tackle these challenges, top-performing trackers commonly rely on constructing complex appearance or motion models. However, the efficacy of these models in enhancing track performance can be limited by the lack of effective and seamless integration. The utilization of simplistic handcrafted fusion methods may even exacerbate the issue, resulting in a decline in tracking performance. To address this issue, we propose an end-to-end coarse-to-fine verifying approach in our motion-driven tracker. At the coarse level, we developed a motion prediction module (MPM) that efficiently extracts and utilizes motion information by leveraging the differences between adjacent frames. The MPM constructs not only a position prior for the decoder but also hybrid features that combine both motion and appearance. At the fine level, we employ a deformable transformer-based appearance model to accurately verify a local region centered on the predicted locations from the MPM. To further enhance the generalization capability of our tracker, we propose the use of an instance domain discriminator (IDD) during the training phase. This discriminator is based on domain adaptation theory and aims to sharpen the distinction between the target and other instances, thereby improving the robustness of tracking. Experimental results on five popular benchmarks, including GOT10k, LaSOT, TrackingNet, OTB, and VOT, validate the effectiveness of our proposed tracker.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, G.
AU  - Wang, Y.
AU  - Chen, Y.
AU  - Yang, G.
AU  - Yao, L.
AU  - Zhang, X.
AU  - Li, H.
AU  - Li, G.
TI  - An Oriented Ship Detection Method of Remote Sensing Image with Contextual Global Attention Mechanism and Lightweight Task-Specific Context Decoupling
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
DO  - 10.1109/TGRS.2024.3520658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212869725&doi=10.1109%2fTGRS.2024.3520658&partnerID=40&md5=6a4f18741e544c1b5b4b5801a7c1ca0e
AB  - Ship detection in remote sensing images has been attracting a lot of attention due to its great application value in both military and civilian fields. However, ships in high-resolution remote sensing images are characterized by the remarkable features of multi-scale, arbitrary orientation and dense arrangement, which is a great challenge for fast and accurate target detection. In order to solve problems, we propose a YOLOV5-based oriented ship detection method of remote sensing image with contextual global attention mechanism and lightweight task-specific context decoupling (CGTC-RYOLO) in this paper. First, a cross-stage partial context transformer (CSP-COT) module is introduced to capture global contextual spatial relations using multi-head self-attention to verify their implications in implicit dependencies. Second, we propose an angle classification prediction branch in the YOLOV5 head network for detecting targets in any direction and design probability and distribution loss function (PrfoIoU) to optimize the regression effect. Third, the lightweight task-specific context decoupling (LTSCODE) for target detection is employed to replace the original head in the YOLOV5 model, which is used to solve the accuracy problem caused by YOLOV5's hybridization of classification and localization. Ablation experiments demonstrate the importance and effectiveness of each module. Compared with the benchmark model, the CGTC-RYOLO has the 5.9%, 3.7%, and 4.3% mAP improvements on the DOTA-ship dataset, the HRSC2016 dataset, and the UCAS-AOD dataset, respectively. Moreover, the model's generalization is also validated. Compared with state-of-the-art methods, the CGTC-RYOLO can achieve better accuracy and less parameters. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Rahardja, S.
TI  - Rethinking Affine Transform for Efficient Image Enhancement: A Color Space Perspective
PY  - 2024
T2  - IEEE Transactions on Multimedia
DO  - 10.1109/TMM.2024.3521826
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213837430&doi=10.1109%2fTMM.2024.3521826&partnerID=40&md5=ad3325c4cf53c9f3c9418fcd77b7a504
AB  - In recent years, we have observed significant advancements in learning-based techniques for image-enhancement tasks. However, most of the existing methods are either purely based on image-to-image convolutional neural networks, which cannot handle high-resolution images in real-time, or resort to 3D Lookup Tables, which fall short of local tone adjustments. In this paper, we rethink affine transform through a color space perspective, and then propose AttnBL (Attentional Bilateral Grid Learning), a novel hybrid image enhancement algorithm to process ultra-high-definition images in real-time. Our algorithm consists of two paths, the low-resolution chroma prediction path that aims to learn the chroma coefficients and the full-resolution luma adaptation path that aims to preserve brightness details. Specifically, we propose a carefully designed hierarchical transformer to capture the global information in an efficient way and introduce a feature extraction module to adaptively learn a luma guidance for bilateral upsampling. Our algorithm can process a 4K-resolution image in 20 milliseconds. This efficiency provides a practical solution for high resolution real-time preview. Without bells and whistles, our model outperforms previous state-of-the-art methods on two well-known datasets in image enhancement tasks both quantitatively and qualitatively. Our analysis also provides some interesting findings that may enlighten further studies.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Min, L.
AU  - Fan, Z.
AU  - Wang, S.
AU  - Dou, F.
AU  - Li, X.
AU  - Wang, B.
TI  - Adaptive Fusion Learning for Compositional Zero-Shot Recognition
PY  - 2024
T2  - IEEE Transactions on Multimedia
DO  - 10.1109/TMM.2024.3521852
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213251812&doi=10.1109%2fTMM.2024.3521852&partnerID=40&md5=35c55427d6ef7956890cb1eab790a444
AB  - Compositional Zero-Shot Learning (CZSL) aims to learn visual concepts (i.e., attributes and objects) from seen compositions and combine them to predict unseen compositions. Existing visual encoders in CZSL typically use traditional visual encoders (i.e., CNN and Transformer) or image encoders from Visual-Language Models (VLMs) to encode image features. However, traditional visual encoders need more multi-modal textual information, and image encoders of VLMs exhibit dependence on pre-training data, making them less effective when used independently for predicting unseen compositions. To overcome this limitation, we propose a novel approach based on the joint modeling of traditional visual encoders and VLMs visual encoders to enhance the prediction ability for uncommon and unseen compositions. Specifically, we design an adaptive fusion module that automatically adjusts the weighted parameters of similarity scores between traditional and VLMs methods during training, and these weighted parameters are inherited during the inference process. Given the significance of disentangling attributes and objects, we design a Multi-Attribute Object Module that, during the training phase, incorporates multiple pairs of attributes and objects as prior knowledge, leveraging this rich prior knowledge to facilitate the disentanglement of attributes and objects. Building upon this, we select the text encoder from VLMs to construct the Adaptive Fusion Network. We conduct extensive experiments on the Clothing16K, UT-Zappos50K, and C-GQA datasets, achieving excellent performance on the Clothing16K and UT-Zappos50K datasets. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ouyang, N.
AU  - Ao, L.
AU  - Cai, Q.
AU  - Wan, W.
AU  - Ren, X.
AU  - He, X.
AU  - Sheng, K.
TI  - Graph Transformer-Based Dynamic Edge Interaction Encoding for Traffic Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3513325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213062416&doi=10.1109%2fTITS.2024.3513325&partnerID=40&md5=be7449d020af8e15f696c32e0ef70f8b
AB  - Traffic prediction is an essential function of intelligent transportation system for traffic control and autonomous driving. Most existing methods encode traffic spatial and temporal data separately, and then design a feature fusion module to correlate spatial and temporal features. However, spatial information is often static, and repetitive static spatial encoding leads to waste of resources, especially in large-scale traffic network prediction. In this paper, we propose a dynamic edge interaction encoding method for spatio-temporal features based on inverse Transformer (iTransformer) and Graph Transformer, named iTPGT-former. The dynamic edge interaction process is designed to embed dynamic temporal features into static edges via a convolutional embedding module. To enhance the Graph Transformer, a relative position encoding strategy based on the self-attentive score of the positive definite kernel (PDK) on graphs and a method for graph substructure encoding (GSE) via enumeration of paths are introduced. In the experimental and discussion session, the iTPGT-former is considered for accuracy, parameters, inference speed, and rich ablation experiments are provided based on six publicly available traffic datasets. The results show that iTPGT-former outperforms the baseline model in both traffic flow and traffic speed prediction. The maximum improvement is achieved in the METR-LA 60-min speed prediction task, with 15.2% reduction in Mean Absolute Percentage Error (MAPE). In addition, the inference of iTPGT-former is significantly faster than the GCN-based method. Our implementation of the iTPGT-former is available at https://github.com/ouyangnann/iTPGTN-former. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Ouyang2024Graph
ER  -

TY  - JOUR
AU  - Xiao, H.
AU  - Kang, W.
AU  - Liu, H.
AU  - Li, Y.
AU  - He, Y.
TI  - Semantic Scene Completion via Semantic-aware Guidance and Interactive Refinement Transformer
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3518493
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212763209&doi=10.1109%2fTCSVT.2024.3518493&partnerID=40&md5=1f19e1d0fb6d78a0a062f0d8fe75a679
AB  - Predicting per-voxel occupancy status and corresponding semantic labels in 3D scenes is pivotal to 3D intelligent perception in autonomous driving. In this paper, we propose a novel semantic scene completion framework that can generate complete 3D volumetric semantics from a single image at a low cost. To the best of our knowledge, this is the first endeavor specifically aimed at mitigating the negative impacts of incorrect voxel query proposals caused by erroneous depth estimates and enhancing interactions for positive ones in camera-based semantic scene completion tasks. Specifically, we present a straightforward yet effective Semantic-aware Guided (SAG) module, which seamlessly integrates with task-related semantic priors to facilitate effective interactions between image features and voxel query proposals in a plug-and-play manner. Furthermore, we introduce a set of learnable object queries to better perceive objects within the scene. Building on this, we propose an Interactive Refinement Transformer (IRT) block, which iteratively updates voxel query proposals to enhance the perception of semantics and objects within the scene by leveraging the interaction between object queries and voxel queries through query-to-query cross-attention. Extensive experiments demonstrate that our method outperforms existing state-of-the-art approaches, achieving overall improvements of 0.30 and 2.74 in mIoU metric on the SemanticKITTI and SSCBench-KITTI-360 validation datasets, respectively, while also showing superior performance in the aspect of small object generation. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Orfanoudakis, S.
AU  - Diaz-Londono, C.
AU  - Yilmaz, Y.E.
AU  - Palensky, P.
AU  - Vergara, P.P.
TI  - EV2Gym: A Flexible V2G Simulator for EV Smart Charging Research and Benchmarking
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3510945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212602311&doi=10.1109%2fTITS.2024.3510945&partnerID=40&md5=70772c4f6d178e08164a80f2d74f22ff
AB  - As electric vehicle (EV) numbers rise, concerns about the capacity of current charging and power grid infrastructure grow, necessitating the development of smart charging solutions. While many smart charging simulators have been developed in recent years, only a few support the development of Reinforcement Learning (RL) algorithms in the form of a Gym environment, and those that do usually lack depth in modeling Vehicle-to-Grid (V2G) scenarios. To address the aforementioned issues, this paper introduces EV2Gym, a realistic simulator platform for the development and assessment of small and large-scale smart charging algorithms within a standardized platform. The proposed simulator is populated with comprehensive EV, charging station, power transformer, and EV behavior models validated using real data. EV2Gym has a highly customizable interface empowering users to choose from pre-designed case studies or craft their own customized scenarios to suit their specific requirements. Moreover, it incorporates a diverse array of RL, mathematical programming, and heuristic algorithms to speed up the development and benchmarking of new solutions. By offering a unified and standardized platform, EV2Gym aims to provide researchers and practitioners with a robust environment for advancing and assessing smart charging algorithms.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Orfanoudakis2024EV2Gym
ER  -

TY  - JOUR
AU  - Yu, H.
AU  - Hou, Y.
AU  - Pei, W.
AU  - Ong, Y.-S.
AU  - Zhang, Q.
TI  - DivDiff: A Conditional Diffusion Model for Diverse Human Motion Prediction
PY  - 2024
T2  - IEEE Transactions on Multimedia
DO  - 10.1109/TMM.2024.3521821
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213716486&doi=10.1109%2fTMM.2024.3521821&partnerID=40&md5=c06f76a03765390630991f3f9ae5a8a4
AB  - Diverse human motion prediction (HMP) aims to predict multiple plausible future motions given an observed human motion sequence. It is a challenging task due to the diversity of potential human motions while ensuring an accurate description of future human motions. Current solutions are either low-diversity or limited in expressiveness. Recent denoising diffusion probabilistic models (DDPM) demonstrate promising performance in various generative tasks. However, introducing DDPM directly into diverse HMP incurs some issues. While DDPM can enhance the diversity of potential human motion patterns, the predicted human motions gradually become implausible over time due to significant noise disturbances in the forward process of DDPM. This phenomenon leads to the predicted human motions being unrealistic, seriously impacting the quality of predicted motions and restricting their practical applicability in real-world scenarios. To alleviate this, we propose a novel conditional diffusion-based generative model, called DivDiff, to predict more diverse and realistic human motions. Specifically, the DivDiff employs DDPM as our backbone and incorporates Discrete Cosine Transform (DCT) and Transformer mechanisms to encode the observed human motion sequence as a condition to instruct the reverse process of DDPM. More importantly, we design a diversified reinforcement sampling function (DRSF) to enforce human skeletal constraints on the predicted human motions. DRSF utilizes the acquired information from human skeletal as prior knowledge, thereby reducing significant disturbances introduced during the forward process. Extensive results received in the experiments on two widely-used datasets (Human3.6M and HumanEva-I) demonstrate that our model obtains competitive performance on both diversity and accuracy. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ke, J.
AU  - Wang, D.
AU  - Chen, J.-C.
AU  - Jhuo, I.-H.
AU  - Lin, C.-W.
AU  - Lin, Y.-Y.
TI  - Make Graph-based Referring Expression Comprehension Great Again through Expression-guided Dynamic Gating and Regression
PY  - 2024
T2  - IEEE Transactions on Multimedia
DO  - 10.1109/TMM.2024.3521844
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213211434&doi=10.1109%2fTMM.2024.3521844&partnerID=40&md5=38cc02c880283d08490dd2b6a75e2104
AB  - One common belief is that with complex models and pre-training on large-scale datasets, transformer-based methods for referring expression comprehension (REC) perform much better than existing graph-based methods. We observe that since most graph-based methods adopt an off-the-shelf detector to locate candidate objects (i.e., regions detected by the object detector), they face two challenges that result in subpar performance: (1) the presence of significant noise caused by numerous irrelevant objects during reasoning, and (2) inaccurate localization outcomes attributed to the provided detector. To address these issues, we introduce a plug-and-adapt module guided by sub-expressions, called dynamic gate constraint (DGC), which can adaptively disable irrelevant proposals and their connections in graphs during reasoning. We further introduce an expression-guided regression strategy (EGR) to refine location prediction. Extensive experimental results on the RefCOCO, RefCOCO+, RefCOCOg, Flickr30K, RefClef, and Ref-reasoning datasets demonstrate the effectiveness of the DGC module and the EGR strategy in consistently boosting the performances of various graph-based REC methods. Without any pretaining, the proposed graph-based method achieves better performance than the state-of-the-art (SOTA) transformer-based methods. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lee, K.
AU  - Seo, H.
AU  - Kim, S.
AU  - An, B.S.
AU  - Park, S.
AU  - Jeon, Y.
AU  - Lee, E.C.
TI  - Quality-Based rPPG Compensation With Temporal Difference Transformer for Camera-Based Driver Monitoring
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3504605
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214291447&doi=10.1109%2fTITS.2024.3504605&partnerID=40&md5=3eae991b4988f05c4ddf907d3a219769
AB  - Remote photoplethysmography (rPPG) is a method for monitoring pulse signal by utilizing a camera sensor to capture a facial video including variations in blood flow beneath the skin. Recently, rPPG advancements have enabled the measurement of an individual’s heart rate with a Root Mean Square Error (RMSE) of approximately 1.0 in controlled indoor environments. However, when applied in car dataset including driving environments, the RMSE of rPPG measurements significantly increases to over 9.07. This limitation, caused by motion-related artifacts and fluctuations in ambient illumination, becomes particularly noticeable while driving, resulting in a Percentage of Time that Error is less than 6 beats per minute (PTE6) of up to 65.1%. To address these limitations, we focus on the assessment of rPPG noise, with an emphasis on evaluating noise components within facial video and quantifying quality of the rPPG measurement. In this paper, we propose a deep learning framework that infers rPPG signal and quality based on video vision transformer. the proposed method demonstrates that the top 10% quality measurements yield PTE6 of 91.98% and 99.59% in driving and garage environments, respectively. Additionally, we introduce a quality-based rPPG compensation method that improves accuracy in driving environments by predicting rPPG quality based on noise assessment. This compensation method demonstrates superior accuracy compared to the current state-of-the-art, achieving a PTE6 of 68.24% in driving scenarios. © 2024 IEEE. All rights reserved, including rights for text and data mining, and training of artificial intelligence.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Lee2024Quality-Based
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Mei, S.
AU  - Ma, M.
AU  - Liu, Y.
AU  - Su, Y.
TI  - HTACPE: A Hybrid Transformer with Adaptive Content and Position Embedding for Sample Learning Efficiency of Hyperspectral Tracker
PY  - 2024
T2  - IEEE Transactions on Multimedia
DO  - 10.1109/TMM.2024.3521819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214308235&doi=10.1109%2fTMM.2024.3521819&partnerID=40&md5=9359a207a8235764274c3e271f1febe0
AB  - Transformer architecture has demonstrated significant potential in hyperspectral object tracking by leveraging global correlation learning to accurately represent the data distribution. However, existing hyperspectral object trackers based on transformer models typically rely on costly pre-trained models, making them prone to crashing due to overfitting when tuned on small-scale hyperspectral videos, greatly limiting their performance. To address this challenge, in this paper, a Hybrid Transformer with Adaptive Content and Position Embedding (HTACPE) tracker is proposed to improve the learning efficiency of the tracking model, and fully explore the spectral-spatial information. Specifically, an Adaptive Content and Position Embedding Module (ACPEM) is designed to dynamically learn the balance between focusing on positional and content-based information, which allows the model to effectively handle datasets of various sizes. To enhance the spectral-spatial information, a Spectral Grouping Module (SGM) is designed to learn the highfrequency information in complex scenarios, thereby enhancing diversified features. It operates in parallel with the ACPEM feature learning module. Furthermore, a Dynamic Reliability Refinement Module (DRRM) is incorporated to address challenges related to accurate object position perception, iteratively refining prediction parameters to enhance the reliability of the model. Extensive experiments demonstrate that the proposed HTACPE achieves satisfactory tracking performance both qualitatively and quantitatively, especially with insufficient training data.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, K.
AU  - Zhao, C.
AU  - Yuan, C.
TI  - Efficiently Adapt to New Dynamic via Meta-Model
PY  - 2024
T2  - Journal of Artificial Intelligence Research
VL  - 81
SP  - 579
EP  - 617
DO  - 10.1613/jair.1.16373
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212297645&doi=10.1613%2fjair.1.16373&partnerID=40&md5=f9ec17e4748decd663e2f70a6f9d0b9a
AB  - We delve into the realm of offline meta-reinforcement learning (OMRL), a practical paradigm in the field of reinforcement learning that leverages offline data to adapt to new tasks. While prior approaches have not explored the utilization of context-based dynamical models to tackle OMRL problems, our research endeavors to fill this gap. Our investigation uncovers shortcomings in existing context-based methods, primarily related to distribution shifts during offline learning and challenges in establishing stable task representations. To address these issues, we formulate the problem as Hidden-Parameter MDPs and propose a framework for effective model adaptation using meta-models plus latent variables, which is inferred by the transformer-based system recognition module trained in an unsupervised fashion. Through extensive experimentation encompassing diverse simulated robotics and control tasks, we validate the efficacy of our approach and demonstrate its superior generalization ability compared to existing schemes, and explore multiple strategies for obtaining policies with personalized models. Our method achieves a model with reduced prediction error, outperforming previous methods in policy performance, and facilitating efficient adaptation when compared to prior dynamic model generalization methods and OMRL algorithms. ©2024 The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Chen, X.
AU  - Yang, J.
TI  - Edge-Enhanced Heterogeneous Graph Transformer With Priority-Based Feature Aggregation for Multi-Agent Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3509954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212754368&doi=10.1109%2fTITS.2024.3509954&partnerID=40&md5=db106f3ae35001a206f5140104f795f5
AB  - Trajectory prediction, which aims to predict the future positions of all agents in a crowd scene, given their past trajectories, plays a vital role in improving the safety of autonomous driving vehicles. For heterogeneous agents, it is imperative to account for the gap in feature distribution differences between agents in different categories. Besides, exploring the reference relationship between the future motions of agents is crucial yet overlooked in previous trajectory prediction methods. To tackle these challenges, we propose an edge-enhanced heterogeneous graph Transformer with priority-based feature aggregation for multi-modal trajectory prediction. Specifically, a new edge-enhanced heterogeneous interaction module that carries relative position information via edges is proposed to explore the complex interaction among agents. Additionally, we propose the concept of priority during the decoding phase and the corresponding measuring method, based on which a priority-based feature aggregation module is presented to enable referencing between agents, allowing for a more reasonable trajectory generation process. Additionally, we design an effective feature fusion method based on state refinement LSTM so that temporal and social features can be well integrated while accounting for their roles in trajectory prediction. Extensive experimental results on public datasets demonstrate that our approach outperforms the state-of-the-art baseline methods, confirming the effectiveness of our proposed method. The source code of our EPHGT model will be publicly released at https://github.com/xbchen82/EPHGT. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024Edge-Enhanced
ER  -

TY  - JOUR
AU  - Jiang, F.
AU  - Huang, B.
AU  - Wu, H.
AU  - Feng, D.
AU  - Zhou, Y.
AU  - Zhang, M.
AU  - Gong, M.
AU  - Zhao, W.
AU  - Guan, Z.
TI  - Change Masked Modality Alignment Network for Multimodal Change Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
DO  - 10.1109/TGRS.2024.3516001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212575128&doi=10.1109%2fTGRS.2024.3516001&partnerID=40&md5=24fe0a5af7a3885f1979f06622486acc
AB  - Using multimodal remote sensing images for change detection (CD) can significantly improve the feasibility and reliability in challenging environments. However, the differences in imaging mechanisms make multimodal images highly heterogeneous. A key challenge for multimodal CD (MCD) is that the heterogeneity of the modalities and changes in ground objects are intertwined during processing. To address this issue, this paper proposes a Change Masked Modality Alignment Network (CMMAN), which uses a multi-task framework consisting of one CD branch and two Image Modal Transformation (IMT) branches. Specifically, to ensure a unified feature space, bi-temporal multimodal images are first input into the same Swin-Transformer-based encoder. The extracted features are then fed simultaneously into the CD branch and separately into the two IMT branches. In the CD branch, the decoder is also designed based on the Swin-Transformer, and a weakly modality-correlated feature enhancement module is introduced to mitigate the interference of modality heterogeneity on CD. For the two IMT branches, both employ a generative adversarial network to transform between modalities and the distributions of features from different modalities are aligned through simultaneous optimization. Uniquely, the change probability map predicted by the CD branch is utilized to mask the change regions in IMT, further decoupling ground object changes and modal heterogeneity. Experimental results on multiple public datasets demonstrate that the proposed CMMAN significantly improves MCD performance and shows good compatibility and portability with various common backbone networks.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xue, D.
AU  - Qian, S.
AU  - Fang, Q.
AU  - Xu, C.
TI  - LININ: Logic Integrated Neural Inference Network for Explanatory Visual Question Answering
PY  - 2024
T2  - IEEE Transactions on Multimedia
DO  - 10.1109/TMM.2024.3521709
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213457734&doi=10.1109%2fTMM.2024.3521709&partnerID=40&md5=d3a2c2845d884579a450a4f7fff6238a
AB  - Explanatory Visual Question Answering (EVQA) is a recently proposed multimodal reasoning task consisting of answering the visual question and generating multimodal explanations for the reasoning processes. Unlike traditional Visual Question Answering (VQA) task that only aims at predicting answers for visual questions, EVQA also aims to generate user-friendly explanations to improve the explainability and credibility of reasoning models. To date, existing methods for VQA and EVQA ignore the prompt in the question and enforce the model to predict the probabilities of all answers. Moreover, existing EVQA methods ignore the complex relationships among question words, visual regions, and explanation tokens. Therefore, in this work, we propose a Logic Integrated Neural Inference Network (LININ) to restrict the range of candidate answers based on first-order-logic (FOL) and capture cross-modal relationships to generate rational explanations. Firstly, we design a FOL-based question analysis program to fetch a small number of candidate answers. Secondly, we utilize a multimodal transformer encoder to extract visual and question features, and conduct the prediction on candidate answers. Finally, we design a multimodal explanation transformer to construct cross-modal relationships and generate rational explanations. Comprehensive experiments on benchmark datasets demonstrate the superiority of LININ compared with the state-of-the-art methods for EVQA.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xing, Y.
AU  - Yang, S.
AU  - Wang, S.
AU  - Zhang, S.
AU  - Liang, G.
AU  - Zhang, X.
AU  - Zhang, Y.
TI  - MS-DETR: Multispectral Pedestrian Detection Transformer With Loosely Coupled Fusion and Modality-Balanced Optimization
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 20628
EP  - 20642
DO  - 10.1109/TITS.2024.3450584
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210918883&doi=10.1109%2fTITS.2024.3450584&partnerID=40&md5=2e39702428fa2c56183318049f842c78
AB  - Multispectral pedestrian detection is an important task for many around-the-clock applications, since the visible and thermal modalities can provide complementary information especially under low light conditions. Due to the presence of two modalities, misalignment and modality imbalance are the most significant issues in multispectral pedestrian detection. In this paper, we propose MultiSpectral pedestrian DEtection TRansformer (MS-DETR) to fix above issues. MS-DETR consists of two modality-specific backbones and Transformer encoders, followed by a multi-modal Transformer decoder, and the visible and thermal features are fused in the multi-modal Transformer decoder. To well resist the misalignment between multi-modal images, we design a loosely coupled fusion strategy by sparsely sampling some keypoints from multi-modal features independently and fusing them with adaptively learned attention weights. Moreover, based on the insight that not only different modalities, but also different pedestrian instances tend to have different confidence scores to final detection, we further propose an instance-aware modality-balanced optimization strategy, which preserves visible and thermal decoder branches and aligns their predicted slots through an instance-wise dynamic loss. Our end-to-end MS-DETR shows superior performance on the challenging KAIST, CVC-14 and LLVIP benchmark datasets. The source code is available at https://github.com/YinghuiXing/MS-DETR. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Xing2024MS-DETR
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Sun, J.
TI  - UniSTAD: An Unified Triple-Tower Students-Teacher Model for Multi-Class Anomaly Detection and Localization
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3507097
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210953808&doi=10.1109%2fTCSVT.2024.3507097&partnerID=40&md5=dc8b95e08c471b288ac786089b518c33
AB  - Despite the rapid advancements in the unsupervised anomaly detection and localization, most existing methods require to train different models for different categories, leading to increased computational and memory demands for real application with the number of classes grows. A more practical task is to detect anomalies from different categories using one unified model. However, this unified setting is challenging for modeling the multi-class normal feature representation due to the diversity of data categories, and the existing methods often drop in performance under this setting. In this work, we propose UniSTAD, a novel and effective unified method for multi-class anomaly detection and localization, using a transformer-based triple-tower students-teacher model. The triple-tower design contains global and local student models, respectively predicting features from global and local context features. UniSTAD learns the feature representation of normal data by joint distilling features to pre-trained teacher model, and enforcing the global/local context-based feature reconstruction and consistency. In the inference stage, UniSTAD identifies anomalous regions where expected feature consistencies are broken. Additionally, we integrate an untrained, category-agnostic localization refinement module, further improving multi-class anomaly detection and localization performance. Evaluated on real-world industrial datasets, UniSTAD demonstrates the state-of-the-art performance, validating its efficacy for multi-class anomaly detection and localization.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Yang, Q.
AU  - Shan, Z.
AU  - Xu, Y.
TI  - Asynchronous Feedback Network for Perceptual Point Cloud Quality Assessment
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3510733
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211245454&doi=10.1109%2fTCSVT.2024.3510733&partnerID=40&md5=e3df69f4e21566002b1b3f80510aaeed
AB  - Recent years have witnessed the success of the deep learning-based technique in research of no-reference point cloud quality assessment (NR-PCQA). For a more accurate quality prediction, many previous studies have attempted to capture global and local features in a bottom-up manner, but ignored the interaction and promotion between them. To solve this problem, we propose a novel asynchronous feedback quality prediction network (AFQ-Net). Motivated by human visual perception mechanisms, AFQ-Net employs a dual-branch structure to deal with global and local features, simulating the left and right hemispheres of the human brain, and constructs a feedback module between them. Specifically, the input point clouds are first fed into a transformer-based global encoder to generate the attention maps that highlight these semantically rich regions, followed by being merged into the global feature. Then, we utilize the generated attention maps to perform dynamic convolution for different semantic regions and obtain the local feature. Finally, a coarse-to-fine strategy is adopted to merge the two features into the final quality score. We conduct comprehensive experiments on three datasets and achieve superior performance over the state-of-the-art approaches on all of these datasets. The code will be available at https://github.com/zhangyujie-1998/AFQ-Net.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ren, R.
AU  - Shi, P.
AU  - Jia, P.
AU  - Kim, J.
TI  - An Unsupervised Learning Approach for Pavement Distress Diagnosis via Siamese Networks
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3500030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210935529&doi=10.1109%2fTITS.2024.3500030&partnerID=40&md5=9714fcc7b16d1d99ed4806c573ee2591
AB  - Accurate, automated diagnosis of pavement distress is essential for effective roadway maintenance but presents considerable challenges. Supervised learning methods are constrained by limited labeled data, while existing unsupervised representation learning approaches are difficult to capture the fine-grained details needed for precise pixel-level segmentation in pavement images with similar backgrounds. To address these limitations, we propose a novel unsupervised approach for pavement distress segmentation that employs a new pretext task within Siamese networks. Our method integrates an explicit prediction head and a high-dimensional cross-entropy loss, enabling implicit class labeling and enhancing fine-grained recognition of distress patterns. Additionally, vision transformers are employed to leverage self-attention mechanisms, facilitating accurate segmentation of foreground distress regions. Experimental results demonstrate that our approach outperforms existing unsupervised representation learning and anomaly detection methods. Notably, when used to pre-train backbone networks such as ResNet-50, our method yields higher accuracy and faster convergence on downstream supervised tasks compared to pre-training on the labeled ImageNet dataset. The proposed method holds promise for advancing pavement maintenance decision-making and enhancing the performance of traditional supervised deep learning models.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Ren2024Unsupervised
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Yu, L.
AU  - Liu, R.
AU  - Xie, H.
TI  - A Detail-Aware Transformer to Generalisable Face Forgery Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3509693
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211203895&doi=10.1109%2fTCSVT.2024.3509693&partnerID=40&md5=5d6ce19cbaf721acecc37da6ebf07e5b
AB  - Generalisable face forgery detectors strive to detect forgeries generated by unseen manipulations. Recently advanced detection methods have managed to capture subtle blending traces, but their neglect of the diversity of blending traces in different regions leads to limited generalization. Towards this, transformer with global receptive fields and dynamic weight mechanism is a promising solution, but vanilla transformer is weak at capturing subtle blending traces. In this paper, we propose a novel Detail-Aware Transformer (DAT) able to focus on both diverse and subtle blending traces caused by inconsistencies in the low-level image details. The intrinsic multi-head self-attention mechanism of the transformer allows our DAT to adaptively capture diverse blending traces in different regions. Furthermore, we improve the transformer's capability of capturing subtle blending traces by two inference overhead-free measures, i.e., self-supervised pre-training based on patch augmentation and region-level contrastive learning. Specifically, the self-supervised pre-training encourages the model to focus on the inconsistencies in low-level image details through a patch number prediction task. The region-level contrastive learning employs a contrastive loss on representations of regions with different low-level details to further improve the transformer's ability to handle subtle blending traces. Extensive experiments show that our method substantially improves the generalization performance and outperforms the state-of-the-art methods on CDF, DFDC, DFDCP, FFIW, and WildDeepfake datasets.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Wu, H.
AU  - Jiang, Q.
TI  - MDNet: Mamba-Effective Diffusion-Distillation Network for RGB-Thermal Urban Dense Prediction
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3508058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210970261&doi=10.1109%2fTCSVT.2024.3508058&partnerID=40&md5=ca80624916b13f94701fad156811e908
AB  - In recent years, significant progress has been achieved in urban dense prediction tasks, particularly with advancements in deep learning models and novel architectures that enhance segmentation accuracy and computational efficiency. However, the following challenges persist: i) Existing modal fusion methods typically adopt convolutional neural networks (CNNs) or transformer (Trans)-based methods, which lead to inadequate global modeling or excessive computation owing to the introduction of quadratic complexity modeling; and ii) existing dense prediction networks typically utilize discriminative networks (codecs), which result in networks with insufficient discriminative properties. To address these issues, we propose the Mamba-effective diffusion-distillation network (MDNet) for RGB-thermal urban dense prediction. First, a new Mamba-effective fusion module is proposed, which efficiently models long-range pixel-level features using Mamba and generates pixel-level adaptive weights to fully utilize complementary modal information. Second, inspired by human self-reflection, a new diffusion self-distillation (DSD) strategy is proposed. The DSD generates coarse-grained binary semantic information via conditional multimodal image diffusion, which serves as self-distillation labels to improve the discriminative properties of the network. Experimental results demonstrate that the proposed MDNet achieves state-of-the-art performance on the MFNet dataset with fewer parameters and reduced computational effort. Extended experiments on the PST900 dataset further illustrate the effectiveness and generalizability of MDNet. The source code and results are available at https://github.com/Tortoisewhp/MDNet.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Yang, J.
AU  - Wu, X.
AU  - Zhou, W.
AU  - Wang, Y.
TI  - ETR: Enhancing Taillight Recognition via Transformer-Based Video Classification
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3509394
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212131845&doi=10.1109%2fTITS.2024.3509394&partnerID=40&md5=3db36f3ab1a33360b38eb77982db7009
AB  - In autonomous driving, efficiently and accurately recognizing taillight states using dashcams is essential for interpreting other vehicles' intentions. Recent video-based taillight recognition methods outperform earlier image-based approaches. However, they face challenges in efficiently integrating spatiotemporal information and managing high computational costs. In this paper, we introduce ETR, an accurate and efficient Transformer-based video classification model designed to enhance taillight recognition. Specifically, we first design a lightweight backbone to extract temporal and spatial features from videos and generate queries with prior information. Next, we develop a hierarchical progressive Transformer decoder that integrates feature maps from different levels of the backbone to enhance the model's global information. Finally, we employ a classification head to predict the taillight state of the video. Additionally, we introduce a public dataset, ETR-Taillights, to address the current lack of open datasets for vehicle taillight recognition. The dataset contains 28,799 dashcam video clips, making it the largest public taillight recognition dataset. Experiments show that our method achieves a 91.69% F-measure on the ETR-Taillights dataset, surpassing the latest taillight recognition methods, VIF by 6.94% and CNN-LSTM by 10.82%. Additionally, it achieves an inference speed of 45.06 FPS, being 3.6 times faster than VIF. Furthermore, we conduct real-world road tests to demonstrate our method's robustness and effectiveness in practical scenarios. Our model and dataset are available at https://github.com/yang590/ vehicle-taillight.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024ETR
ER  -

TY  - JOUR
AU  - Yi, Y.
AU  - Zhang, G.
AU  - Jiang, H.
TI  - Online Digital Twin-Empowered Content Resale Mechanism in Age of Information-Aware Edge Caching Networks
PY  - 2024
T2  - IEEE Transactions on Communications
DO  - 10.1109/TCOMM.2024.3511940
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211454334&doi=10.1109%2fTCOMM.2024.3511940&partnerID=40&md5=7c8f7c7e64b0078bdda133978e9b0105
AB  - For users requesting popular contents from content providers, edge caching can alleviate backhaul pressure and enhance the quality of experience of users. Recently there is also a growing concern about content freshness that is quantified by age of information (AoI). Therefore, AoI-aware online caching algorithms are required, which is challenging because the content popularity is usually unknown in advance and may vary over time. In this paper, we propose an online digital twin (DT) empowered content resale mechanism in AoI-aware edge caching networks. We aim to design an optimal two-timescale caching strategy to maximize the utility of an edge network service provider (ENSP). The formulated optimization problem is non-convex and NP-hard. To tackle this intractable problem, we propose a DT-assisted Online Caching Algorithm (DT-OCA). In specific, we first decompose our formulated problem into a series of subproblems, each handling a cache period. For each cache period, we use a DT-based prediction method to effectively capture future content popularity, and develop an online caching strategy. Competitive ratio analysis and extensive experimental results demonstrate that our algorithm has promising performance, and outperforms other benchmark algorithms. Insightful observations are also found and discussed.  © 1972-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gan, J.
AU  - Yang, Q.
AU  - Zhang, D.
AU  - Li, L.
AU  - Qu, X.
AU  - Ran, B.
TI  - A Novel Voronoi-Based Spatio-Temporal Graph Convolutional Network for Traffic Crash Prediction Considering Geographical Spatial Distributions
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 21723
EP  - 21736
DO  - 10.1109/TITS.2024.3452275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210928952&doi=10.1109%2fTITS.2024.3452275&partnerID=40&md5=432249850475a596e4059279fd33c9d3
AB  - Accurately predicting the probability of crashes is crucial for preventing traffic crashes and mitigating their impacts. However, the imbalance in crash data, irregular road network structures, and heterogeneity in multi-source data pose significant challenges. To address these issues, this study introduces a spatio-temporal graph convolutional network traffic crash prediction model based on Voronoi diagrams that considers geographical spatial distribution. Initially, this study introduces a spatial partitioning method based on Voronoi diagrams, grounded on the geographic spatial distribution characteristics of traffic crashes. It constructs a novel graph structure with spatial units within Voronoi diagrams as nodes and the shared length of different road types between units as edges. This graph structure integrates the spatial distribution characteristics of crashes with the graph structure, substantially contributing to addressing the zero-inflation problem inherent in spatial units constructed on a grid basis. Subsequently, the study employs a GCN (Graph Convolutional Network) and Transformer encoder to build the VSTGCN (Voronoi-Based Spatio-Temporal Graph Convolutional Network) crash prediction model, evaluating its effectiveness using real data from New York City. Comparisons with eight baseline models demonstrate that VSTGCN outperforms them in all evaluation metrics. Moreover, the paper conducts model ablation studies from different perspectives, such as feature modules and graph structure composition, revealing that the chosen spatial, temporal, and spatio-temporal features significantly influence the model's predictive performance, with spatial features having the most substantial impact. Finally, the novel graph structure based on Voronoi diagrams proposed in this study shows a clear advantage in model effectiveness compared to traditional graph structures. This research can effectively handle complex crash data structures and accurately predict crash probabilities, providing a reliable basis for developing measures to prevent crashes and alleviate their impacts. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Gan2024Novel
ER  -

TY  - JOUR
AU  - Zhou, J.
AU  - Yang, J.
AU  - Wu, X.
AU  - Zhou, W.
AU  - Wang, Y.
TI  - TrVLR: A Transformer-Based Vehicle Light Recognition Method in Vehicle Inspection
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 19995
EP  - 20005
DO  - 10.1109/TITS.2024.3447586
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210990315&doi=10.1109%2fTITS.2024.3447586&partnerID=40&md5=8cf7d8200a9490410fe3ac38317c5328
AB  - Vehicle light inspection is a crucial aspect of vehicle inspection, as vehicle lights play a vital role in understanding vehicle behavior. Due to diverse ambient illumination, non-uniform vehicle light standards, and complex light states, existing vehicle light recognition methods perform poorly, especially in turn signals. To realize intelligent vehicle light inspection, an accurate and real-time intelligent vehicle light recognition method is urgently needed. To address this issue, we propose a Transformer-based vehicle light recognition method, TrVLR, which effectively models sequential information and global relationships of the vehicle light image sequence, resulting in precise recognition. Specifically, we first utilize a convolutional neural network (CNN) backbone to extract features from vehicle light area video. Then, we adopt a Transformer encoder to encapsulate the long sequential information of the entire video. Next, a Transformer decoder is used to contextualize each image throughout the video and output the classification information of each image. Finally, we predict the state of the lights in each image by feed-forward networks (FFNs). Experiments demonstrate that our method obtains state-of-the-art results in headlights, taillights, and turn signals with F-measures of 93.34%, 91.64%, and 88.17%, respectively. Notably, TrVLR surpasses CNN-LSTM by 7.01% in turn signal recognition. Our method has been successfully applied to intelligent vehicle light inspection, and the video demo is shown at https://www.youtube.com/watch?v=p8E78Pwkcxo. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024TrVLR
ER  -

TY  - JOUR
AU  - Yan, H.
AU  - Ma, A.
AU  - Zhong, Y.
TI  - Progressive Symmetric Registration for Multimodal Remote Sensing Imagery
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
DO  - 10.1109/TGRS.2024.3514305
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211694744&doi=10.1109%2fTGRS.2024.3514305&partnerID=40&md5=ec50d24eabb99d4d853093e823c4add8
AB  - Image registration forms the foundation of collaborative processing in multimodal remote sensing imagery (MRSI). However, high-resolution MRSIs frequently display complex distortions due to imaging characteristics and terrain variations, with both global and local distortions present. Effectively addressing these complex distortions necessitates the identification of uniformly and densely distributed corresponding points across the entire image. Existing methods primarily focus on global affine distortions and often extract only sparse and unevenly distributed corresponding points, which makes the effective handling of these coexisting distortions a significant challenge. To address this problem, we propose a progressive symmetric registration learning network (PSRNet) for MRSIs. In PSRNet, multimodal remote sensing image registration (MRSIR) is redefined as a symmetric dense regression task, differing from the traditional pipeline that concentrates on unidirectional sparse transformation parameter prediction. Specifically, PSRNet consists of three primary components: 1) A multi-scale feature projector, which employs a dual-branch structure with non-shared weights to achieve modality-specific representation of different modal images across multiple scales; 2) A progressive cross-modal transformer to further mine modality-invariant features and progressively predict symmetric deformation fields; and 3) A symmetric consistency loss function capable of elegantly achieving high-precision reversible alignment of image pairs, encompassing endpoint error loss, bidirectional alignment loss, and smoothness loss. Experimental results demonstrate that PSRNet achieves more comprehensive and advanced registration performance on our self-constructed large-scale high-resolution multimodal remote sensing image registration dataset, which includes complex global-local geometric distortions and significant nonlinear radiometric differences (NRD).  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Ling, X.
AU  - Xue, Y.
AU  - Luo, W.
AU  - Zhu, L.
AU  - Qin, F.
AU  - Zhou, Y.
AU  - Huang, Y.
TI  - Precipitation Nowcasting Using Diffusion Transformer with Causal Attention
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4709916
DO  - 10.1109/TGRS.2024.3510693
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211245771&doi=10.1109%2fTGRS.2024.3510693&partnerID=40&md5=ef763ac6df5375c9e189acf6ba1a8d4f
AB  - Short-term precipitation forecasting remains challenging due to the difficulty in capturing long-term spatiotemporal dependencies. Current deep learning methods fall short in establishing effective dependencies between conditions and forecast results, while also lacking interpretability. To address this issue, we propose a precipitation nowcasting using a diffusion transformer with causal attention (DTCA) model. Our model leverages the transformer and combines causal attention mechanisms to establish spatiotemporal queries between conditional information (causes) and forecast results (results). This design enables the model to effectively capture long-term dependencies, allowing forecast results to maintain strong causal relationships with input conditions over a wide range of time and space. We explore four variants of spatiotemporal information interactions for DTCA, demonstrating that global spatiotemporal labeling interactions yield the best performance. In addition, we introduce a channel-to-batch shift (CTBS) operation to further enhance the model's ability to represent complex rainfall dynamics. We conducted experiments on two datasets. Compared to state-of-the-art U-Net-based methods, our approach improved the critical success index (CSI) for predicting heavy precipitation by approximately 15% and 8%, respectively, achieving state-of-the-art performance. Our project is open source and available on GitHub at: https://github.com/ybu-lxd/DTCA. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, J.
AU  - Li, K.
AU  - Liang, Y.
AU  - Sun, L.
AU  - Yan, J.
AU  - Wu, Y.
TI  - Rethinking Urban Mobility Prediction: A Multivariate Time Series Forecasting Approach
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2024.3498054
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210991851&doi=10.1109%2fTITS.2024.3498054&partnerID=40&md5=7c7552078f2f94fa5f33bd2ab983d999
AB  - Long-term urban mobility predictions play a crucial role in the effective management of urban facilities and services. Conventionally, urban mobility data has been structured as spatiotemporal videos, treating longitude and latitude grids as fundamental pixels. Consequently, video prediction methods, relying on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), have been instrumental in this domain. In our research, we introduce a fresh perspective on urban mobility prediction. Instead of oversimplifying urban mobility data as traditional video data, we regard it as a complex multivariate time series. This perspective involves treating the time-varying values of each grid in each channel as individual time series. To tackle the prediction of these time series, we present the Super-Multivariate Urban Mobility Transformer (SUMformer), which utilizes a specially designed attention mechanism to calculate temporal and cross-variable correlations and reduce computational costs stemming from a large number of time series. SUMformer also employs low-frequency filters to extract essential information for long-term predictions. Furthermore, SUMformer is structured with a temporal patch merge mechanism, forming a hierarchical framework that enables the capture of multi-scale correlations. Consequently, it excels in urban mobility pattern modeling and long-term prediction, outperforming current state-of-the-art methods across five real-world datasets. The code is available at: https://github.com/Chengyui/SUMformer.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Cheng2024Rethinking
ER  -

TY  - JOUR
AU  - Tao, W.
AU  - Liu, H.
AU  - Xu, J.
AU  - Dai, Q.
AU  - Zhou, J.
AU  - Wen, H.
AU  - Chen, Z.
TI  - Collaboration or Competition: An Infomax-Based Period-Aware Transformer for Ticket-Grabbing Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 19757
EP  - 19769
DO  - 10.1109/TITS.2024.3450610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210972779&doi=10.1109%2fTITS.2024.3450610&partnerID=40&md5=304c70a2c70ffda27288ebe253991c9b
AB  - Helping users to grab train tickets during a travel peak is a very important service provided by many mainstream online travel platforms (OTPs), e.g., booking.com, Ctrip.com, and Alibaba Fliggy, which greatly enriches the experience for platform users. To optimize such train ticket-grabbing service, a vital accompanying task is to predict the train ticket-grabbing success rates for users during their train ticket-grabbing process to help them make decisions. Although many endeavours have been made towards the traffic prediction problem, none of them was dedicated to solving the ticket-grabbing issue. That is, prior methods ignored the unique properties exhibited in the ticket-grabbing scenario, such as the specific spatial relationship between stations and trains, the collaboration and competition relationships between different routes, and the temporal periodic pattern in ticket-grabbing. In this paper, we propose a novel Infomax-based Period-aware Transformer (IPT) tailored for predicting the success rate of train ticket-grabbing that will be displayed on OTPs, which is to our best knowledge the first attempt along this line. IPT contains three modules: i) a multi-view node embedding module, which serves to model the special spatial relationships between stations and trains by employing the intra- and inter-graph aggregation layers; ii) an infomax-based graph representation learning module, which aims to learn a high-level node embedding by training a discriminator to distinguish different types of edges in the route graph; iii) a period-aware Transformer module, which intends to discover the ticket-grabbing temporal periodic dependencies by designing a periodic activation function. Extensive offline and online evaluations on a real-world dataset show that IPT substantially outperforms state-of-the-art baselines. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Tao2024Collaboration
ER  -

TY  - JOUR
AU  - Lang, B.
AU  - Li, X.
AU  - Chuah, M.C.
TI  - BEV-TP: End-to-End Visual Perception and Trajectory Prediction for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 18537
EP  - 18546
DO  - 10.1109/TITS.2024.3433591
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208807362&doi=10.1109%2fTITS.2024.3433591&partnerID=40&md5=e7ccd7f03435c65940470b0342f9f833
AB  - For autonomous vehicles (AVs), the ability for effective end-to-end perception and future trajectory prediction is critical in planning a safe automatic maneuver. In the current AVs systems, perception and prediction are two separate modules. The prediction module receives only a restricted amount of information from the perception module. Furthermore, perception errors will propagate into the prediction module, ultimately having a negative impact on the accuracy of the prediction results. In this paper, we present a novel framework termed BEV-TP, a visual context-guided center-based transformer network for joint 3D perception and trajectory prediction. BEV-TP exploits visual information from consecutive multi-view images and context information from HD semantic maps, to predict better objects’ centers whose locations are then used to query visual features and context features via the attention mechanism. Generated agent queries and map queries facilitate learning of the transformer module for further feature aggregation. Finally, multiple regression heads are used to perform 3D bounding box detection and future velocity prediction. This center-based approach achieves a differentiable, simple, and efficient E2E trajectory prediction framework. Extensive experiments conducted on the nuScenes dataset demonstrate the effectiveness of BEV-TP over traditional pipelines with sequential paradigms. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Lang2024BEV-TP
ER  -

TY  - JOUR
AU  - Zhang, Q.
AU  - Chen, L.
AU  - Shang, W.
TI  - Cross Dense Feature Learning with Task Guidance for Few-Shot Classification
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3504542
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210071789&doi=10.1109%2fTCSVT.2024.3504542&partnerID=40&md5=07e57270eb99eb7f439d3b60a4a5241b
AB  - Few-shot classification aims to develop a classifier that adapts to new tasks using only a limited number of labeled images. To overcome the limitation of lacking training images in few-shot image classification, dense features have been extensively utilized to represent images by providing more subtle and discriminative clues. However, dense feature based methods are still facing challenges despite leveraging local details in images. Primarily, these methods deal with the support set images in each category independently, which ignores the information across different categories. Furthermore, dense features suffer from background noise, when performing similarity calculations based on a large number of dense feature pairs, these methods are susceptible to interference from task-irrelevant feature pairs. In this paper, we propose a cross dense feature learning with task guidance method to address the aforementioned issues. The key components of our method include two aspects. Firstly, a dense feature extraction approach based on transformer is proposed, aiming to better utilize inter-class information within the support set. We design two types of cross-attention mechanisms to get the across information among different categories for a better representation of dense features, named Support-Support Attention(SSA) and Support-Query Attention(SQA). Secondly, a task-relevant model is trained for dense feature pairs similarity calculating, aiming to filter out feature pairs that contribute more effectively to classification. Then we can get the final similarity to predict the label of query image through summarizing weighted local similarity. The experimental results prove that our method achieves a promising improvement for few-shot classification by taking information across different categories and task attention similarity into consideration.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Yan, Q.
AU  - Bashmachnikov, I.
AU  - Huang, K.
AU  - Mu, F.
AU  - Zhang, Z.
AU  - Xu, M.
AU  - Zhao, J.
TI  - MFDA: Unified Multi-Task Architecture for Cross-Scene Sea Ice Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4303221
DO  - 10.1109/TGRS.2024.3491190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208975830&doi=10.1109%2fTGRS.2024.3491190&partnerID=40&md5=a084105c69f93d8e61a90e5c0bc3a9c3
AB  - Although the extensive research has been conducted on retrieving sea ice variables from synthetic aperture radar (SAR) and multimodal remote sensing data, cross-scene retrieval using regional training models remains a significant challenge. Previous studies have employed multi-task learning (MTL) but have not sufficiently explored the interplay between network architectures and multi-task performance. Moreover, self-supervised learning (SSL) has shown promise in improving tasks with limited training samples, though its potential in sea ice variable retrieval requires further study. To address the challenge of cross-scene retrieval of sea ice variables, we introduce a novel and effective method called multimodal fusion domain adaptation (MFDA), which combines three key strategies: 1) employ SSL methods for multimodal data to pretrain the model, improving its noise sensitivity and promoting a hierarchical understanding of multimodality; 2) propose a unified convolutional and Transformer-based data fusion architecture to enhance the integration of multimodal data and improve semantic understanding; and 3) incorporate a domain adaptation module between the multimodal encoder and the multi-task decoding predictor to facilitate the model's understanding of the semantic gaps between different regional environments. The performance of the proposed MFDA has been extensively evaluated on the Ai4Arctic dataset. The experimental results demonstrate that MFDA achieves superior performance compared with other state-of-the-art (SOTA) sea ice classification approaches for the task of cross-scene sea ice retrieval. The code will be made available at: https://github.com/yuweikong/MFDA. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yao, L.
AU  - Wang, Y.
AU  - Liu, M.
AU  - Chau, L.-P.
TI  - SGIFormer: Semantic-guided and Geometric-enhanced Interleaving Transformer for 3D Instance Segmentation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3498041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209710865&doi=10.1109%2fTCSVT.2024.3498041&partnerID=40&md5=8080a8d40579072bedcb610fadb9789d
AB  - In recent years, transformer-based models have exhibited considerable potential in point cloud instance segmentation. Despite the promising performance achieved by existing methods, they encounter challenges such as instance query initialization problems and excessive reliance on stacked layers, rendering them incompatible with large-scale 3D scenes. This paper introduces a novel method, named SGIFormer, for 3D instance segmentation, which is composed of the Semantic-guided Mix Query (SMQ) initialization and the Geometric-enhanced Interleaving Transformer (GIT) decoder. Specifically, the principle of our SMQ initialization scheme is to leverage the predicted voxel-wise semantic information to implicitly generate the scene-aware query, yielding adequate scene prior and compensating for the learnable query set. Subsequently, we feed the formed overall query into our GIT decoder to alternately refine instance query and global scene features for further capturing fine-grained information and reducing complex design intricacies simultaneously. To emphasize geometric property, we consider bias estimation as an auxiliary task and progressively integrate shifted point coordinates embedding to reinforce instance localization. SGIFormer attains state-of-the-art performance on ScanNet V2, ScanNet200, S3DIS datasets, and the challenging high-fidelity ScanNet++ benchmark, striking a balance between accuracy and efficiency. The code, weights, and demo videos are publicly available at https://rayyoh.github.io/SGIFormer/.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Deng, B.
AU  - Duan, P.
AU  - Lu, X.
AU  - Wang, Z.
AU  - Kang, X.
TI  - Hyperspectral and SAR Image Classification via Graph Convolutional Fusion Network
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5538611
DO  - 10.1109/TGRS.2024.3492387
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209360421&doi=10.1109%2fTGRS.2024.3492387&partnerID=40&md5=218b46cc9a074a997906ba08f70032ee
AB  - Hyperspectral and synthetic aperture radar (SAR) image classification, aiming to merge multisource information to boost the precision and reliability of land cover classification, has gained increasing attention. Nevertheless, current techniques still exhibit certain limitations in extracting discriminative features and integrating heterogeneous features. In this work, a graph convolutional fusion network (GCFNet) is proposed for hyperspectral and SAR image classification. First, a spectral residual neural network is employed to extract the spectrum information. Then, a dual-branch graph convolutional network (GCN) is developed to extract the spatial information from hyperspectral and SAR images. Finally, a cross-contextual transformer fusion module is created to merge the spectral and spatial information followed by a dense layer to yield the final prediction outcome. To confirm the performance of the GCFNet, experiments on three datasets (e.g., Berlin, Augsburg, and Yellow River) demonstrate that the GCFNet significantly surpasses other representative methods. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Wang, Z.
AU  - Luo, F.
AU  - Guo, T.
AU  - Yang, F.
AU  - Gao, X.
TI  - ESMS-Net: Enhancing Semantic-Mask Segmentation Network With Pyramid Atrousformer for Remote Sensing Image
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5650414
DO  - 10.1109/TGRS.2024.3504733
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210357914&doi=10.1109%2fTGRS.2024.3504733&partnerID=40&md5=7f2339d7719606f54f89db514a45f2cb
AB  - Transformers has gained widespread adoption in remote sensing image (RSI) segmentation. However, RSI has densely overlapping terrain and significant shadow, making it challenging to segment the blended boundaries of terrains that are the hard classes. Currently, most transformer-based methods construct the self-attention with a sliding window, which influences the feature receptive fields to conquer the intersecting and overlapping objects. Additionally, they often rarely focus specifically on the representation of these hard segmentation objects. To overcome these challenges, we propose a novel Enhancing Semantic Mask Segmentation Network (ESMS-Net) framework including a local-global joint encoder, an auxiliary enhanced encoder, and a multiscale dense decoder. In the local-global joint encoder, we construct a Pyramid Pooling AtrousFormer (PPAFormer) that performs the self-attention with a pyramid-structured atrous sliding window, which enhances the range of receptive fields and the global representation performance. Meanwhile, we construct the dual-feature fusion module (DFFM) and multilevel feature weighted fusion (MFWF) in the multiscale dense decoder to reduce information loss and facilitate the interaction of deep semantic information. For the auxiliary enhanced encoder, we develop a semantic mask based on the predicted results to maintain the hard segmentation classes, and then use the same structure as the first two stages of the local-global joint encoder to learn the hard regions again. Extensive experiments demonstrate the proposed ESMS-Net can achieve significant improvements for segmentation performance compared with the state-of-the-art methods on the ISPRS-Vaihingen and Potsdam datasets. The code will be available at https://github.com/Wzysaber/ESMS-Net.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Luo, Z.
AU  - Zhu, Q.
AU  - Peng, S.
AU  - Ran, L.
AU  - Wang, L.
AU  - Chen, Y.
AU  - Hu, Z.
AU  - Luo, J.
TI  - A Road-detail Preserving Framework for Urban Road Extraction from VHR Remote Sensing Imagery
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
DO  - 10.1109/TGRS.2024.3495508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209373501&doi=10.1109%2fTGRS.2024.3495508&partnerID=40&md5=e2c9b9f672bf102fd182901af5f472f0
AB  - Automatic road extraction has gained significant attention in urban navigation, sustainable transport, and disaster response. Conventional convolutional neural networks operate within the local receptive field, limiting their capacity to represent potential global relations between roads and surroundings. In addition, edge is important topological information for road targets. Several works focus on predicting precise boundaries to enhance road extraction. But over-fitted edges and the course integration between features of different network layers may lead to loss of local details and incorrect road segmentation results. Therefore, Road-detail Preserving Mapper (RoadDP-Mapper) framework is proposed. First, RoadDP-Mapper employs a hierarchical transformer as the encoder to enable local-to-global reasoning. The Asymmetric up-sampling layers (APLs) are introduced to enhance the model's capability to perceive and reconstruct critical road detail information. Second, a road edge-constrained branch with a detail preservation module (DPM) is devised to amplify the distinction between roads and backgrounds by extracting and preserving explicit class boundary details. The proposed joint loss inspires the transformer to capture the contextual spatial relationships while preserving the fine-grained features of the road. We evaluated our framework on the DeepGlobe dataset and self-annotated images from 10 representative cities in China. The proposed framework has demonstrated its effectiveness by significantly reducing both missed detections and false alarms in road extraction. Furthermore, spatial transfer experiments have confirmed the generalizability of RoadDP-Mapper for large-scale road mapping. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, H.
AU  - Zheng, X.
AU  - Liu, Q.
AU  - Zhou, L.
AU  - Huang, C.
AU  - Hu, M.
AU  - Wang, C.
AU  - Li, K.
AU  - Wang, D.
AU  - Li, D.
TI  - A Spatial–Temporal Predictive Transformer Network for Level-3 Autonomous Vehicle Decision-Making
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
DO  - 10.1109/TNNLS.2024.3487838
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208714292&doi=10.1109%2fTNNLS.2024.3487838&partnerID=40&md5=c33747580553540f2f388e72b9224269
AB  - This study explores the effect of takeover time (TOT) on decision-making for Level-3 autonomous vehicles (L3-AVs). The existing research on L3-AV lacks an in-depth analysis of the mechanisms affecting TOT, ignores the importance of spatial and temporal variations in features for TOT prediction, and also lacks consideration of TOT in downstream trajectory planning tasks. This study proposed an exponential smoothing transformers (ETS) former model for TOT prediction, and then, the spatial–temporal predictive transformer (ST-Preformer) was employed to forecast the trajectories of surrounding vehicles, assess lane availability, and determine lane-changing probabilities. Ultimately, these evaluations contribute to the decision-making process of L3-AVs. The findings showed that the ETSformer was able to explain more than 83% of the characteristics of the TOT distribution in the TOT prediction task, effectively reducing the absolute percentage error by 0.7%, based on which the decision-making framework was able to make safe and comfortable optimal decisions. Decision-making is closely related to driving conditions and the surrounding traffic state, and TOT has a critical impact on the safety and stability of decision-making. A comprehensive understanding the impact of TOT on decision-making can help improve the safety of autonomous driving and provide guidance for improving decision-making techniques. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, Y.
AU  - Yang, J.
AU  - Luo, L.
TI  - United Domain Cognition Network for Salient Object Detection in Optical Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5650114
DO  - 10.1109/TGRS.2024.3497579
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209373865&doi=10.1109%2fTGRS.2024.3497579&partnerID=40&md5=353ed23494d86d2038051e23780082fd
AB  - Recently, deep learning-based salient object detection (SOD) in optical remote sensing images (ORSIs) have achieved significant breakthroughs. We observe that existing ORSIs-SOD methods consistently center around optimizing pixel features in the spatial domain, progressively distinguishing between backgrounds and objects. However, pixel information represents local attributes, which are often correlated with their surrounding context. Even with strategies expanding the local region, spatial features remain biased toward local characteristics, lacking the ability of global perception. To address this problem, we introduce the Fourier transform that generate global frequency features and achieve an image-size receptive field. To be specific, we propose a novel united domain cognition network (UDCNet) to jointly explore the global-local information in the frequency and spatial domains. Technically, we first design a frequency-spatial domain transformer (FSDT) block that mutually amalgamates the complementary local spatial and global frequency features to strength the capability of initial input features. Furthermore, a dense semantic excavation (DSE) module is constructed to capture higher level semantic for guiding the positioning of remote sensing objects. Finally, we devise a dual-branch joint optimization (DJO) decoder that applies the saliency and edge branches to generate high-quality representations for predicting salient objects. Experimental results demonstrate the superiority of the proposed UDCNet method over 24 state-of-the-art models, through extensive quantitative and qualitative comparisons in three widely used ORSIs-SOD datasets. The source code is available at: https://github.com/CSYSI/UDCNet.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Zhi, X.
AU  - Hu, J.
AU  - Yu, L.
AU  - Han, Q.
AU  - Chen, W.
AU  - Zhang, W.
TI  - LMAFormer: Local Motion Aware Transformer for Small Moving Infrared Target Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5008117
DO  - 10.1109/TGRS.2024.3502663
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210101737&doi=10.1109%2fTGRS.2024.3502663&partnerID=40&md5=c81944259822fe1070f263ac242fa78a
AB  - In temporal infrared small target detection, it is crucial to leverage the disparities in spatiotemporal characteristics between the target and the background to distinguish the former. However, remote imaging and the relative motion between the detection platform and the background cause significant coupling of spatiotemporal characteristics, making target detection highly challenging. To address these challenges, we propose a network named LMAFormer. First, we introduce a local motion-aware spatiotemporal attention mechanism that aligns and enhances multiframe features to extract local spatiotemporal salient features of targets while avoiding interference from moving backgrounds. Second, we employ a multiscale fusion transformer encoder that computes self-attention weights across and within scales during encoding, to establish multiscale correlations among different regions of temporal images, enabling motion background modeling. Last, we propose a multiframe joint query decoder. The shallowest feature map after multiscale feature propagation is mapped to initial query weights, which are refined through grouped convolutions to generate grouped query vectors. These are jointly optimized to encapsulate rich multiframe details, strengthening motion background modeling and target feature representation, improving prediction accuracy. Experimental results on the NUDT-MIRSDT, IRDST, and the established TSIRMT datasets demonstrate that our network outperforms state-of-the-art (SOTA) methods. Our code and dataset will be available at https://github.com/lifier/LMAFormer. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Glaser, P.
AU  - Hu, X.
AU  - Willner, K.
AU  - Zheng, Y.
AU  - Damme, F.
AU  - Bruzzone, L.
AU  - Oberst, J.
TI  - ELunarDTMNet: Efficient Reconstruction of High-Resolution Lunar DTM From Single-View Orbiter Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4601820
DO  - 10.1109/TGRS.2024.3501153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210103474&doi=10.1109%2fTGRS.2024.3501153&partnerID=40&md5=1c7da5f25c575769f3c97bd5059eb75c
AB  - High-resolution digital terrain models (DTMs) are critical for supporting planetary exploration missions and advancing scientific research. Recently, deep learning (DL) techniques have been applied to reconstruct high-resolution DTMs from single-view orbiter optical images, particularly for the Moon. However, DL-based methods face challenges in retrieving high-quality multiscale topographic features, especially in regions with irregular terrains or significant relief. Additionally, their generalization capability across diverse datasets is rarely evaluated. In this article, we propose an efficient DL-based single-view method with a coarse-resolution DTM as a constraint for high-quality lunar DTM reconstruction, named ELunarDTMNet. This approach introduces a hierarchical transformer-based backbone with a residual-connected mechanism, specifically designed to capture and integrate multiscale features from single-view lunar images, thereby enhancing prediction accuracy. Meanwhile, given the diverse and complex surface relief, new elevation normalization strategies are proposed to preserve terrain feature contrast while accommodating different elevation distributions. Our method performs well on diverse lunar landscapes with various topographic features and elevation changes. It outperforms the existing DL-based methods in accuracy and detail, effectively addressing their encountered challenges. Moreover, the proposed method achieves effective resolutions similar to those of the shape-from-shading (SFS) technique for subtle-scale terrain retrieval, but with enhanced elevation accuracy, illumination robustness, and approximately 850× faster processing speed. Trained with the lunar reconnaissance orbiter (LRO) narrow angle camera (NAC) images, our model shows superior performance on other high-resolution lunar orbiter images, such as Chang'E-2 imagery.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Dou, J.
AU  - Merghadi, A.
AU  - Liang, W.
AU  - Dong, A.
AU  - Xiong, D.
AU  - Zhang, L.
TI  - Advanced Prediction of Landslide Deformation Through Temporal Fusion Transformer and Multivariate Time-Series Clustering of InSAR: Insights From the Badui Region, Eastern Tibet
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4514219
DO  - 10.1109/TGRS.2024.3504241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210291425&doi=10.1109%2fTGRS.2024.3504241&partnerID=40&md5=0dc6376cca8c3bc7637ce36dc23a264e
AB  - This study focuses on the Badui region in eastern Tibet, an area with complex topography featuring numerous valleys, ravines, and frequent geological hazards. Given the economic expansion in this region, advanced techniques are essential for analyzing the distribution of geological hazards and developing early warnings of geological hazards. The research employs enhanced small baseline subset interferometric synthetic aperture radar (ESBAS-InSAR) technology, which provides more ascending and descending data than traditional small baseline subset-InSAR (SBAS-InSAR), allowing reprojection into vertical and horizontal components. Following dimensionality reduction through principal component analysis (PCA) and k-means clustering, the horizontal displacements were categorized into four clusters, and the vertical displacements were categorized into five clusters. Time-series data of vertical and horizontal displacements, rainfall, and normalized difference vegetation index (NDVI) were then used to assess 16 displacement prediction models. The temporal fusion transformer (TFT) model demonstrated the best predictive performance. To further improve accuracy, 11 static variables such as clusters, elevation, slope, aspect, distance from faults, time-varying known categorical variable, and earthquake times, were added as the TFT input variables. Results indicate that the optimized TFT model reduces the root-mean-square error (RMSE) from 3.4842 to 2.1707, the mean absolute percentage error (MAPE) from 2625.6399 to 2154.5505, and the mean absolute error (MAE) from 2.4392 to 2.3731. Overall, this study provides a framework for multivariate, multistep forecasting of diverse deformation modes across large areas and identifies distinct landslide deformation patterns through clustering, thereby enhancing the prediction of landslide deformation. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, M.
AU  - Li, S.
AU  - Yang, J.
TI  - Transformer Tracking for Satellite Video: Matching, Propagation, and Prediction
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5649216
DO  - 10.1109/TGRS.2024.3501380
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210071053&doi=10.1109%2fTGRS.2024.3501380&partnerID=40&md5=9dc7d1c7c7152469014c7fc40feb5ff4
AB  - Recently, transformer-based trackers have brought overwhelming advantages in general video. However, their performance in satellite video has been hindered by insufficient satellite-specific training and a lack of designs tailored to satellite targets and scene characteristics. To tackle these challenges, we propose a novel transformer-based tracking framework for satellite video object tracking: Transformer Matching, Propagation, and Prediction (TransMPP). TransMPP combines three stages: static matching, dynamic propagation, and prediction, to ensure accurate tracking in satellite videos. Specifically, the Matching model uses a one-stream pipeline for simultaneous feature extraction and relationship modeling across extensive search and template areas, thereby improving foreground and background discrimination capabilities. In addition, the Propagation and Prediction models enhance temporal modeling capabilities through local long-term and short-term feature propagation and global sequence prediction, respectively, boosting tracking robustness. Moreover, to ensure a fair comparison and evaluation, we also developed SatSOT-train, a large-scale training dataset for the SatSOT benchmark. After comprehensive training, TransMPP demonstrates state-of-the-art (SOTA) performance on the SatSOT dataset, achieving an area under the curve (AUC) score of 59.9% and a precision score of 71.5%, bringing improvements of 6.3% and 5.3%, respectively. The code will be available at https://github.com/DonDominic/TransMPP.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pan, G.
AU  - Wu, Q.
AU  - Zhou, B.
AU  - Li, J.
AU  - Wang, W.
AU  - Ding, G.
AU  - Yau, D.K.Y.
TI  - Spectrum Prediction With Deep 3D Pyramid Vision Transformer Learning
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
DO  - 10.1109/TWC.2024.3495812
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210291997&doi=10.1109%2fTWC.2024.3495812&partnerID=40&md5=5dfbd59dcc60faf55a64a42a5da9d63e
AB  - In this paper, we propose a deep learning (DL)-based task-driven spectrum prediction framework, named DeepSPred. The DeepSPred comprises a feature encoder and a task predictor, where the encoder extracts spectrum usage pattern features, and the predictor configures different networks according to the task requirements to predict future spectrum. Based on the DeepSPred, we first propose a novel 3D spectrum prediction method combining a flow processing strategy with 3D vision Transformer (ViT, i.e., Swin) and a pyramid to serve possible applications such as spectrum monitoring task, named 3D-SwinSTB. 3D-SwinSTB unique 3D Patch Merging ViT-to-3D ViT Patch Expanding and pyramid designs help the model accurately learn the potential correlation of the evolution of the spectrogram over time. Then, we propose a novel spectrum occupancy rate (SOR) method by redesigning a predictor consisting exclusively of 3D convolutional and linear layers to serve possible applications such as dynamic spectrum access (DSA) task, named 3D-SwinLinear. Unlike the 3D-SwinSTB output spectrogram, 3D-SwinLinear projects the spectrogram directly as the SOR. Finally, we employ transfer learning (TL) to ensure the applicability of our two methods to diverse spectrum services. The results show that our 3D-SwinSTB outperforms recent benchmarks by more than 5%, while our 3D-SwinLinear achieves a 90% accuracy, with a performance improvement exceeding 10%.  © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Chen, H.
AU  - Bai, L.
AU  - Li, W.
AU  - Ouyang, W.
AU  - Zou, Z.
AU  - Shi, Z.
TI  - MambaDS: Near-Surface Meteorological Field Downscaling with Topography Constrained Selective State-Space Modeling
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4112615
DO  - 10.1109/TGRS.2024.3496895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209387522&doi=10.1109%2fTGRS.2024.3496895&partnerID=40&md5=4f94a1ab5bc069f2644c1a369bcaab17
AB  - In an era of frequent extreme weather and global warming, obtaining precise, fine-grained near-surface weather forecasts is increasingly essential for human activities. Downscaling (DS), a crucial task in meteorological forecasting and remote sensing, enables the reconstruction of high-resolution meteorological states for target regions from global-scale forecast results. Previous downscaling methods, inspired by convolutional neural network (CNN) and Transformer-based super-resolution (SR) models, lacked tailored designs for meteorology and encountered structural limitations. Notably, they failed to efficiently integrate topography, a crucial prior to the downscaling process. In this article, we address these limitations by pioneering the selective state-space model (SSM) into the meteorological field downscaling and propose a novel model called MambaDS. This model retains the advantages of Mamba in long-range dependency modeling and linear computational complexity while enhancing the learning ability of multivariate correlation. In addition, by designing an efficient topography constraint layer, this prior information can be used more efficiently than ever before. Through extensive experiments in both China mainland and the continental United States (CONUS), we validated that our proposed MambaDS achieves state-of-the-art (SOTA) results in three different types of meteorological field downscaling settings. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lovanshi, M.
AU  - Tiwari, V.
AU  - Ingle, R.
AU  - Jain, S.
TI  - Fusion of Temporal Transformer and Spatial Graph Convolutional Network for 3-D Skeleton-Parts-Based Human Motion Prediction
PY  - 2024
T2  - IEEE Transactions on Human-Machine Systems
VL  - 54
IS  - 6
SP  - 788
EP  - 797
DO  - 10.1109/THMS.2024.3452133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210075262&doi=10.1109%2fTHMS.2024.3452133&partnerID=40&md5=50fbb7ae9f4b5eb30449b58c6b42d10c
AB  - The field of human motion prediction has gained prominence, finding applications in various domains such as intelligent surveillance and human-robot interaction. However, predicting full-body human motion poses challenges in capturing joint interactions, handling diverse movement patterns, managing occlusions, and ensuring real-time performance. To address these challenges, the proposed model adopts a skeleton-parted strategy to dissect the skeleton structure, enhancing coordination and fusion between body parts. This novel method combines transformer-enabled graph convolutional networks for predicting human motion in 3-D skeleton data. It integrates a temporal transformer (T-Transformer) for comprehensive temporal feature extraction and a spatial graph convolutional network (S-GCN) for capturing spatial characteristics of human motion. The model's performance is evaluated on two comprehensive human motion datasets, Human3.6M and CMU motion capture (CMU Mocap), containing numerous videos encompassing short and long human motion sequences. Results indicate that the proposed model outperforms state-of-the-Art methods on both datasets, significantly improving the average mean per joint positional error (avg-MPJPE) by 3.50% and 11.45% for short-term and long-term motion prediction, respectively. Similarly, on the CMU Mocap dataset, it achieves avg-MPJPE improvements of 2.69% and 1.05% for short-Term and long-Term motion prediction, respectively, demonstrating its superior accuracy in predicting human motion over extended periods. The study also investigates the impact of different numbers of T-Transformers and S-GCNs and explores the specific roles and contributions of the T-Transformer, S-GCN, and cross-part components.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Huang, A.
AU  - Luo, Q.
AU  - Guan, W.
TI  - Local-Perception-Enhanced Spatial-Temporal Evolving Graph Transformer Network: Citywide Demand Prediction of Taxi and Ride-Hailing
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 17105
EP  - 17121
DO  - 10.1109/TITS.2024.3450846
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209990432&doi=10.1109%2fTITS.2024.3450846&partnerID=40&md5=38ef45a7da1d1bdd508fd8347414617d
AB  - Accurate prediction of demand for traditional taxi and ride-hailing services is crucial for addressing supply-demand imbalances. However, recent studies based on global adaptive graphs, local spatial-temporal graphs, and self-attention mechanisms struggle to effectively capture the dynamic and intricate relations in demand. Moreover, existing dynamic graph generators face challenges in efficiently producing high-quality graphs to learn the diverse interactions among zones along time axis and their shared patterns spanning various time scales. To solve these challenges, we propose a novel Local-Perception-Enhanced Spatial-Temporal Evolving Graph Transformer Network (LPE-STGTN), aimed at improving the effectiveness and efficiency of extracting intricate local dependencies in taxi demand. Specifically, we elaborately design a spatial-temporal evolving graph generator to absorb shared and diversified inter-zone relations across different temporal periodicities and specific interactions among zones within each time step. Furthermore, an attention free transformer with local context (AFT-local) is introduced to effectively learn the correlations between adjacent time steps. Extensive experiments on three taxi datasets of New York and Beijing are carried out to evaluate the superior performance of our model. Compared with the most competitive baseline, our model achieves a balance between effectiveness and efficiency on three datasets, with average training time reduction of 70.66% and average performance improvement of 1.96%.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2024Local-Perception-Enhanced
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Wang, B.
AU  - Zhao, Y.
AU  - Yuan, Y.
AU  - Zhou, T.
AU  - Li, Z.
TI  - Collaborative Multimodal Fusion Network for Multiagent Perception
PY  - 2024
T2  - IEEE Transactions on Cybernetics
DO  - 10.1109/TCYB.2024.3491756
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209947163&doi=10.1109%2fTCYB.2024.3491756&partnerID=40&md5=8b9b1b556991f70e61e805891ad184da
AB  - With the increasing popularity of autonomous driving systems and their applications in complex transportation scenarios, collaborative perception among multiple intelligent agents has become an important research direction. Existing single-agent multimodal fusion approaches are limited by their inability to leverage additional sensory data from nearby agents. In this article, we present the collaborative multimodal fusion network (CMMFNet) for distributed perception in multiagent systems. CMMFNet first extracts modality-specific features from LiDAR point clouds and camera images for each agent using dual-stream neural networks. To overcome the ambiguity in-depth prediction, we introduce a collaborative depth supervision module that projects dense fused point clouds onto image planes to generate more accurate depth ground truths. We then present modality-aware fusion strategies to aggregate homogeneous features across agents while preserving their distinctive properties. To align heterogeneous LiDAR and camera features, we introduce a modality consistency learning method. Finally, a transformer-based fusion module dynamically captures cross-modal correlations to produce a unified representation. Comprehensive evaluations on two extensive multiagent perception datasets, OPV2V and V2XSet, affirm the superiority of CMMFNet in detection performance, establishing a new benchmark in the field.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; AJG:3; zdy:3; 
LB  - Zhang2024Collaborative
ER  -

TY  - JOUR
AU  - Dong, Y.
AU  - Pan, Y.
AU  - Wang, D.
AU  - Chen, A.
TI  - Traffic Load Simulation for Long-Span Bridges Using a Transformer Model Incorporating In-Lane Transverse Vehicle Movements
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 15600
EP  - 15613
DO  - 10.1109/TITS.2024.3452106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209389559&doi=10.1109%2fTITS.2024.3452106&partnerID=40&md5=fed3d4a97fd68abf708acb408e5475ae
AB  - Traffic load simulation (TLS) is critical for the design and assessment of long-span bridges. Traditional methods, such as Monte-Carlo sampling and Cellular Automaton, rely on actual traffic data for load generation and evolution. However, they often overlook in-lane transverse movements, which are vital for precise bridge component assessment. This paper presents a TLS framework that incorporates in-lane transverse movements for long-span bridges. We select eight parameters as input features for a Transformer-based deep learning model, designed to predict both longitudinal and transverse vehicle speeds. The TLS process begins with spatial-temporal traffic load monitoring on the target bridge. Monte-Carlo sampling generates vehicle data, and the trained Transformer model simulates traffic evolution. A case study on a 1490-meter main-span suspension bridge illustrates the proposed method. Traffic trajectories were captured using a multi-vision system and reconstructed to minimize errors. The Transformer model was trained with optimized hyperparameters, enabling the completion of TLS on the entire bridge deck. We also compare the performance of other deep learning models, evaluate the accuracy of transverse distribution in TLS, and discuss its potential applications in future bridge assessments. The proposed TLS method enhances current practices by accurately simulating transverse vehicle positions on bridge decks, thereby improving the fidelity of microscopic traffic simulations and enabling more precise fatigue damage assessments of bridge components.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Dong2024Traffic
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Zhang, C.
AU  - Liang, X.
AU  - Han, Z.
AU  - Li, Y.
AU  - Yang, C.
AU  - Gui, W.
AU  - Gao, W.
AU  - Wang, X.
AU  - Li, X.
TI  - Attention Mono-depth: attention-enhanced transformer for monocular depth estimation of volatile kiln burden surface
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3479412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207398554&doi=10.1109%2fTCSVT.2024.3479412&partnerID=40&md5=bb8a97840221bb17f906a10799bd8d7c
AB  - Accurate estimation of burden surface depth plays a crucial role in constructing the temperature field and optimizing reaction control in volatile kilns. However, most image-based depth estimation techniques require high-quality input images and achieve limited accuracy, which restrict their applications in actual harsh working conditions such as high temperature, heavy dust and dense smoke. In this study, a deep learning-based monocular depth estimation model is proposed to measure the burden surface depth in the volatile kiln head zone. The proposed model integrates an encoder-decoder network with an attention module. The encoder-decoder network outputs a set of deep semantic features, while the attention module intelligently fuses multi-level features to predict a probability distribution over depth intervals for each pixel. A volatile kiln prototype is designed and constructed to generate image datasets of the kiln head zone which approximate real data collected from industrial production sites. Results demonstrate that the proposed model has a depth prediction error of RMSE = 11.008 mm for the burden surface region, outperforming state-of-the-art neural networks and the traditional depth-from-defocus method. Code and datasets are available at https://github.com/LLLcong/Attention-MonoDepth.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Kang, Z.
AU  - Liu, J.
AU  - Lin, Y.
AU  - Yu, Y.
AU  - Li, J.
TI  - A Multitask CNN-Transformer Network for Semantic Change Detection from Bitemporal Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5647215
DO  - 10.1109/TGRS.2024.3486787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208261876&doi=10.1109%2fTGRS.2024.3486787&partnerID=40&md5=ccd1f9f4537f5a971aab2013c723dec6
AB  - Bitemporal remote sensing (RS) semantic change detection (SCD) involves discerning and categorizing changes in the same geographical area across two RS images taken at different times. High-performance SCD approaches typically address this task using multitask networks that simultaneously handle binary change detection (BCD) and semantic segmentation (SS). Despite significant advancements in SCD research, constructing a multitask network that fully explores the correlation between BCD and SS remains challenging. To address this, we propose a novel approach called the multitask CNN-transformer network (MCTNet), tailored for SCD using bitemporal RS images. Our Siamese network simultaneously tackles SS and BCD via three subnetworks: two for SS and one for BCD. The methodology begins with a multiscale convolutional neural network (CNN) extracting local features from input images, and converting them into tokens. A Transformer module with an encoder-decoder architecture then captures long-range dependencies among these visual tokens. The extracted features are subsequently passed to multitask heads, generating predicted outputs. To ensure that the BCD results remain consistent regardless of the order of images in the input pair, we introduce spatiotemporal feature learning (SFL), enabling the acquisition of temporal-symmetric representations for BCD. Extensive experimental validation on the WHU-CD, SECOND, and HRSCD datasets demonstrates the effectiveness and efficiency of MCTNet for both SS and BCD tasks. The source code for this article will be published on GitHub in the future https://github.com/kangziwen1/MCTNet. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yan, T.
AU  - Meng, H.
AU  - Parada-Cabaleiro, E.
AU  - Tao, J.
AU  - Li, T.
AU  - Schuller, B.W.
TI  - A Residual Multi-Scale Convolutional Neural Network with Transformers for Speech Emotion Recognition
PY  - 2024
T2  - IEEE Transactions on Affective Computing
DO  - 10.1109/TAFFC.2024.3481253
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207335814&doi=10.1109%2fTAFFC.2024.3481253&partnerID=40&md5=9339addce86a16e13af94f608d35d07b
AB  - The great variety of human emotional expression as well as the differences in the ways they perceive and annotate them make Speech Emotion Recognition (SER) an ambiguous and challenging task. With the development of deep learning, long-term progress has been made in SER systems. However, the existing convolutional neural networks present certain limitations, such as their inability to well capture features, which contain important emotional information. Moreover, the position encoding in the Transformer structure is relatively fixed and only encodes the time domain dimension, which cannot effectively obtain the position information of discriminative features in the frequency domain dimension. In order to overtake these limitations, we propose an end-to-end Residual Multi-Scale Convolutional Neural Networks (RMSCNN) with Transformer model network. Simultaneously, to further validate the effectiveness of RMSCNN in extracting multi-scale features and delivering pertinent emotion localization data, we developed the RMSC_down network in conjunction with the Wav2Vec 2.0 model. The results of the prediction of Arousal, Valence and Dominance on the popular corpora demonstrate the superiority and robustness of our approach for SER , showing an improvement of the recognition accuracy in the public dataset MSP-Podcast 1.9 version. The code is available at this GitHub. © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Astuti, L.
AU  - Lin, Y.-C.
AU  - Chiu, C.-H.
AU  - Chen, W.-H.
TI  - Predicting Vulnerable Road User Behavior With Transformer-Based Gumbel Distribution Networks
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
DO  - 10.1109/TASE.2024.3476382
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207434298&doi=10.1109%2fTASE.2024.3476382&partnerID=40&md5=4ce364f3adaca4ff257b662a7f739a35
AB  - This study introduces the crossing intention and trajectory with the Transformer networks (CITraNet) prediction model to process multimodal input data of vulnerable road users (VRUs), such as pedestrians and bicyclists, whose behavior is inherently unpredictable. Unlike traditional approaches that rely on sequence transduction and Gaussian distribution-based models, CITraNet employs Transformer networks and Gumbel distribution. First, we utilize multi-head attention and feed-forward layers to extract hidden features from historically observed data to allow effective parallelization and handling of long-range dependencies. Second, CITraNet features an innovative Transformer-based Gumbel distribution network that significantly enhances the model's ability to accurately predict all possible trajectories using extreme value theory, which replaces the conventional Gaussian distribution models that struggle with discrete and non-linear data. The effectiveness and accuracy of CITraNet are validated on the Taiwan pedestrian (TaPed) dataset, as well as the publicly available JAAD and PIE datasets. The model's deterministic and stochastic trajectory predictions are assessed over short (0.5s), medium (1.0s), and long (1.5s) intervals, crucial for gauging predictive accuracy across varying durations. The results demonstrate that CITraNet outperforms previous benchmarks Note to Practitioners - This study advances the capabilities of advanced driver assistance systems (ADAS) by introducing a vision-based, risk-aware method to predict the future crossing intentions and trajectories of pedestrians and bicyclists. While current ADAS technologies, such as pedestrian collision warning (PCW) systems, excel at detection, they fall short in predicting trajectories and intentions. This limitation can lead to inadequate braking response times and distances, increasing the risk of accidents. Our approach offers timely predictions that enable automatic braking systems to stop vehicles safely, thereby preventing collisions with an early collision warning. This innovation presents significant business opportunities in the development of hardware and software vision components for vehicle manufacturers, automotive component suppliers, and chip designers. However, a notable limitation of our current model is its exclusive focus on pedestrians as traffic agents. Future enhancements will aim to incorporate social interactions among all traffic participants, including vehicles and motorcyclists, to deliver a more comprehensive safety solution.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, T.-B.
AU  - Su, Y.-T.
AU  - Song, D.
AU  - Li, W.-H.
AU  - Wei, Z.-Q.
AU  - Liu, A.-A.
TI  - Multi-Scale Spatial-Temporal Transformer for Meteorological Variable Forecasting
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3487965
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208402675&doi=10.1109%2fTCSVT.2024.3487965&partnerID=40&md5=47d389fdd9ab3b701f52d20ec5a1db4c
AB  - Frequent occurrences of marine extreme climate and weather events pose significant threats to human life and property, underscoring the practical significance of meteorological data forecasting methods. Notably, significant advancements in meteorological forecasting fields have been achieved by data-driven deep learning techniques, which leverage observed meteorological datasets and employ deep networks to capture complex patterns. However, challenges remain in accurately extracting local details and capturing spatial-temporal correlations when dealing with multiple meteorological forecasting tasks that exhibits diverse temporal and spatial scales. Hence, in this paper, we propose a Multi-Scale Spatial Temporal Transformer (MS-STT) framework to achieve efficient and accurate meteorological data forecasting. Specifically, to achieve more detailed and multi-scale representation of meteorological data, we design the regionally coherent encoding strategy and multi-scale feature aggregation for visual representation. To enhance the multi-scale ability in terms of learning spatial-temporal correlations, we propose a multi-scale spatial-temporal transformer network, which integrates a multi-scale spatial transformer to learn the spatial association between local patches and multi-scale regions and a temporal transformer to learn the temporal dynamic evolution properties. Extensive quantitative and qualitative experiments on three popular spatial temporal forecasting tasks validate the effectiveness of the proposed method. In particular, compared to the representative data-driven deep learning ENSO forecasting method Earthformer, our approach achieves a 3.7% performance improvement with only one-third of the parameters.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Fan, Z.
AU  - Shen, Y.
AU  - Li, Y.
AU  - An, Y.
AU  - Tan, X.
TI  - MAEMOT: Pretrained MAE-Based Antiocclusion 3-D Multiobject Tracking for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
DO  - 10.1109/TNNLS.2024.3480148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208409993&doi=10.1109%2fTNNLS.2024.3480148&partnerID=40&md5=79bdc628a0d4a3788609bacac3aed636
AB  - The existing 3-D multiobject tracking (MOT) methods suffer from object occlusion in real-world traffic scenes. However, previous works have faced challenges in providing a reasonable solution to the fundamental question: 'How can the interference of the perception data loss caused by occlusion be overcome?' Therefore, this article attempts to provide a reasonable solution by developing a novel pretrained movement-constrained masked autoencoder (M-MAE) for an antiocclusion 3-D MOT called MAEMOT. Specifically, for the pretrained M-MAE, this article adopts an efficient multistage transformer (MST) encoder and a spatiotemporal-based motion decoder to predict and reconstruct occluded point cloud data, following the properties of object motion. Afterward, the well-trained M-MAE model extracts the global features of occluded objects, ensuring that the features of the intraobjects between interframes are as consistent as possible throughout the spatiotemporal sequence. Next, a proposal-based geometric graph aggregation (PG2 A) module is utilized to extract and fuse the spatial features of each proposal, producing refined region-of-interest (RoI) components. Finally, this article designs an object association module that combines geometric and corner affinities, which helps to match the predicted occlusion objects more robustly. According to an extensive evaluation, the proposed MAEMOT method can effectively overcome the interference of occlusion and achieve improved 3-D MOT performance under challenging conditions. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fan, S.
AU  - Gao, W.
AU  - Li, G.
TI  - Point-MPP: Point Cloud Self-Supervised Learning from Masked Position Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
DO  - 10.1109/TNNLS.2024.3479309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207806799&doi=10.1109%2fTNNLS.2024.3479309&partnerID=40&md5=939a9cc4d6cd1c5da8b36f9d6f911d02
AB  - Masked autoencoding has gained momentum for improving fine-tuning performance in many downstream tasks. However, it tends to focus on low-level reconstruction details, lacking high-level semantics and resulting in weak transfer capability. This article presents a novel jigsaw puzzle solver inspired by the idea that predicting the positions of disordered point cloud patches provides more semantic information, similar to how children learn by solving jigsaw puzzles. Our method adopts the mask-then-predict paradigm, erasing the positions of selected point patches rather than their contents. We first partition input point clouds into irregular patches and randomly erase the positions of some patches. Then, a Transformer-based model is used to learn high-level semantic features and regress the positions of the masked patches. This approach forces the model to focus on learning transfer-robust semantics while paying less attention to low-level details. To tie the predictions within the encoding space, we further introduce a consistency constraint on their latent representations to encourage the encoded features to contain more semantic cues. We demonstrate that a standard Transformer backbone with our pretraining scheme can capture discriminative point cloud semantic information. Furthermore, extensive experiments indicate that our method outperforms the previous best competitor across six popular downstream vision tasks, achieving new state-of-the-art performance. Codes will be available at https://git.openi.org.cn/OpenPointCloud/Point-MPP.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - She, Y.
AU  - Li, P.
AU  - Wei, M.
AU  - Liang, D.
AU  - Chen, Y.
AU  - Xie, H.
AU  - Lee Wang, F.
TI  - eViTBins: Edge-Enhanced Vision-Transformer Bins for Monocular Depth Estimation on Edge Devices
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 20320
EP  - 20334
DO  - 10.1109/TITS.2024.3480114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207947117&doi=10.1109%2fTITS.2024.3480114&partnerID=40&md5=5268849ebf939e5490798c7c9defb23a
AB  - Monocular depth estimation (MDE) remains a fundamental yet not well-solved problem in computer vision. Current wisdom of MDE often achieves blurred or even indistinct depth boundaries, degenerating the quality of vision-based intelligent transportation systems. This paper presents an edge-enhanced vision transformer bins network for monocular depth estimation, termed eViTBins. eViTBins has three core modules to predict monocular depth maps with exceptional smoothness, accuracy, and fidelity to scene structures and object edges. First, a multi-scale feature fusion module is proposed to circumvent the loss of depth information at various levels during depth regression. Second, an image-guided edge-enhancement module is proposed to accurately infer depth values around image boundaries. Third, a vision transformer-based depth discretization module is introduced to comprehend the global depth distribution. Meanwhile, unlike most MDE models that rely on high-performance GPUs, eViTBins is optimized for seamless deployment on edge devices, such as NVIDIA Jetson Nano and Google Coral SBC, making it ideal for real-time intelligent transportation systems applications. Extensive experimental evaluations corroborate the superiority of eViTBins over competing methods, notably in terms of preserving depth edges and global depth representations.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - She2024eViTBins
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Shen, X.
AU  - Chen, X.
AU  - Yu, Z.
AU  - Ren, B.
AU  - Yang, H.
AU  - Zhang, X.-Y.
AU  - Zhou, Y.
TI  - CQformer: Learning Dynamics Across Slices in Medical Image Segmentation
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
DO  - 10.1109/TMI.2024.3477555
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207697694&doi=10.1109%2fTMI.2024.3477555&partnerID=40&md5=fd8af5d679dadf2bf6ad9f410ae1419f
AB  - Prevalent studies on deep learning-based 3D medical image segmentation capture the continuous variation across 2D slices mainly via convolution, Transformer, inter-slice interaction, and time series models. In this work, via modeling this variation by an ordinary differential equation (ODE), we propose a cross instance query-guided Transformer architecture (CQformer) that leverages features from preceding slices to improve the segmentation performance of subsequent slices. Its key components include a cross-attention mechanism in an ODE formulation, which bridges the features of contiguous 2D slices of the 3D volumetric data. In addition, a regression head is employed to shorten the gap between the bottleneck and the prediction layer. Extensive experiments on 7 datasets with various modalities (CT, MRI) and tasks (organ, tissue, and lesion) demonstrate that CQformer outperforms previous state-of-the-art segmentation algorithms on 6 datasets by 0.44%-2.45%, and achieves the second highest performance of 88.30% on the BTCV dataset. The code will be publicly available after acceptance.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zheng, X.
AU  - Bagloee, S.A.
AU  - Sarvi, M.
TI  - TRECK: Long-Term Traffic Forecasting with Contrastive Representation Learning
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 16964
EP  - 16977
DO  - 10.1109/TITS.2024.3421328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208705660&doi=10.1109%2fTITS.2024.3421328&partnerID=40&md5=5b8cc29a97b55aed0d5debb079db0762
AB  - Recent research mainly applies deep learning (DL) methods to short-term traffic forecasting. However, there is a growing interest in long-term forecasting, which allows action optimization at more steps in the future. Motivated by the encouraging success of contrastive representation learning, we propose a powerful and light framework, namely, Traffic Representation Extraction with Contrastive learning frameworK (TRECK), to improve traffic forecasting performance, especially for longer prediction terms. TRECK i) learns disentangled seasonal representations with contrastive learning, ii) enhances the learning of event data with entity embedding and iii) improves generalization and encourages obtaining more effective representations for the forecasting task through multi-task learning. TRECK can be directly applied to typical sequence-to-sequence DL prediction models. We evaluate TRECK when integrated with vanilla base models (RNN and BiLSTM) on large-size and real-world datasets. Experimental results show that TRECK can considerably boost the performance of base models and offer them the capability of handling increasing forecasting horizons. With TRECK, even a naive model like RNN can outperform state-of-the-art Transformer-based and GNN-based methods. Moreover, while avoiding any laborious feature design, the representations extracted by TRECK are more desirable than hand-crafted time features, yielding an 18.69% lower average MAE. Further analysis highlights its efficacy in diverse traffic conditions and in generating prediction intervals. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zheng2024TRECK
ER  -

TY  - JOUR
AU  - Qin, H.
AU  - Xie, W.
AU  - Li, Y.
AU  - Du, Q.
TI  - HTD-TS3: Weakly Supervised Hyperspectral Target Detection Based on Transformer via Spectral-Spatial Similarity
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 16816
EP  - 16830
DO  - 10.1109/TNNLS.2023.3298145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208204654&doi=10.1109%2fTNNLS.2023.3298145&partnerID=40&md5=a9448ba8fc627b3acb9e38ae93179a73
AB  - As an advanced technique in remote sensing, hyperspectral target detection (HTD) is widely concerned in civilian and military applications. However, the limitation of prior and heterogeneous backgrounds makes HTD models sensitive to data corruption under various interference from the environment. In this article, a novel united HTD framework based on the concept of transformer is proposed to extract [HTD based on transformer via spectral-spatial similarity (HTD-TS3)] under weak supervision, which opens up more flexible ways to study HTD. For the first time, the transformer mechanism is introduced into the HTD task to extract spectral and spatial features in a unified optimization procedure. By modeling long-range dependence among spectra, it realizes spectral-spatial joint inference based on long-range context, which addresses the issues of insufficient utilization of spatial information. To provide samples for weakly supervised learning (WSL), the coarse sample selection and spectral sequence construction in an efficient way are proposed, which makes full use of limited prior information. Finally, an exponential constrained nonlinear function is adopted to acquire pixel-level prediction via combining discriminative spectral-spatial features and coarse spatial information. Experiments on real hyperspectral images (HSIs) captured by different sensors at various scenes verify the effectiveness and efficiency of HTD-TS3.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Jia, T.
AU  - Wang, H.
AU  - Ma, B.
AU  - Lu, H.
AU  - Lin, S.
AU  - Cai, D.
AU  - Chen, D.
TI  - AO-DETR: Anti-Overlapping DETR for X-Ray Prohibited Items Detection
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
DO  - 10.1109/TNNLS.2024.3487833
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208658330&doi=10.1109%2fTNNLS.2024.3487833&partnerID=40&md5=3f8d35eabe4f4548f70afc65dc614163
AB  - Prohibited item detection in X-ray images is one of the most essential and highly effective methods widely employed in various security inspection scenarios. Considering the significant overlapping phenomenon in X-ray prohibited item images, we propose an anti-overlapping detection transformer (AO-DETR) based on one of the state-of-the-art (SOTA) general object detectors, DETR with improved denoising anchor boxes (DINO). Specifically, to address the feature coupling issue caused by overlapping phenomena, we introduce the category-specific one-to-one assignment (CSA) strategy to constrain category-specific object queries in predicting prohibited items of fixed categories, which can enhance their ability to extract features specific to prohibited items of a particular category from the overlapping foreground–background features. To address the edge blurring problem caused by overlapping phenomena, we propose the look forward densely (LFD) scheme, which improves the localization accuracy of reference boxes in mid-to-high-level decoder layers and enhances the ability to locate blurry edges of the final layer. Similar to DINO, our AO-DETR provides two different versions with distinct backbones, tailored to meet diverse application requirements. Extensive experiments on the PIXray, OPIXray, and HIXray datasets demonstrate that the proposed method surpasses the SOTA object detectors, indicating its potential applications in the field of prohibited item detection. The source code will be available at: https://github.com/Limingyuan001/AO-DETR. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Zhang, S.
AU  - Yuan, W.
AU  - Quek, T.Q.S.
TI  - Transformer-Empowered Predictive Beamforming for Rate-Splitting Multiple Access in Non-Terrestrial Networks
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 12
SP  - 19776
EP  - 19788
DO  - 10.1109/TWC.2024.3486673
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208410045&doi=10.1109%2fTWC.2024.3486673&partnerID=40&md5=b24e779fcf869a6cf73d17db47381651
AB  - Existing Rate-Splitting Multiple Access (RSMA) techniques offer a promise for Non-Terrestrial Networks (NTNs) by managing interference and ensuring reliable data transmission. However, precoder design remains a crucial bottleneck, demanding accurate Channel State Information (CSI) feedback and complex optimization, which are challenging in practical deployment. Motivated by this, this paper proposes a novel Deep Learning (DL)-based method to predict the precoder design from the historical CSI directly. In particular, we first establish a predictive beamforming protocol for precoder design using historical CSI, bypassing the need for constant feedback and reducing complexity. Subsequently, we formulate a general problem for precoder design, with the Weighted Ergodic Sum Rate (WESR) serving as the objective function. Solving this problem is particularly challenging due to the dynamic nature of wireless channels in NTNs. To address this, we designed a fusion model, named TranCN, which harnesses the strengths of Transformers and Convolutional Neural Networks (CNNs) to extract spatial-temporal features from historical CSI, thereby enhancing precoder performance. Simulation results demonstrate that our predictive beamforming scheme enables RSMA to adapt to dynamic channel conditions using historical CSI, surpassing baseline methods and improving data transmission resilience. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, J.
AU  - Zhuo, F.
AU  - Sun, Q.
AU  - Li, Q.
AU  - Hua, Y.
AU  - Zhao, J.
TI  - DSFormer-LRTC: Dynamic Spatial Transformer for Traffic Forecasting With Low-Rank Tensor Compression
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 16323
EP  - 16335
DO  - 10.1109/TITS.2024.3436523
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204807390&doi=10.1109%2fTITS.2024.3436523&partnerID=40&md5=12701bfe51d531b26ee1e48ebfd48f02
AB  - Traffic flow forecasting is challenging due to the intricate spatio-temporal correlations in traffic patterns. Previous works captured spatial dependencies based on graph neural networks and used fixed graph construction methods to characterize spatial relationships, which limits the ability of models to capture dynamic and long-range spatial dependencies. Meanwhile, prior studies did not consider the issue of a large number of redundant parameters in traffic prediction models, which not only increases the storage cost of the model but also reduces its generalization ability. To address the above challenges, we propose a Dynamic Spatial Transformer for Traffic Forecasting with Low-Rank Tensor Compression (DSFormer-LRTC). Specifically, we constructed a global spatial Transformer to capture remote spatial dependencies, and a distance-based mask matrix is used in local spatial Transformer to enhance the adjacent spatial influence. To reduce the complexity of the model, the model adopts a design that separates temporal and spatial. Meanwhile, we introduce low-rank tensor decomposition to reconstruct the parameter matrix in Transformer module to compress the proposed model. Experimental results show that DSFormer-LRTC achieves state-of-the-art performance on four real-world datasets. The experimental analysis of attention matrix also proves that the model can learn dynamic and distant spatial features. Finally, the compressed model parameters reduce the original parameter size by two-thirds, while significantly outperforming the baseline model in terms of computational efficiency.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhao2024DSFormer-LRTC
ER  -

TY  - JOUR
AU  - Deng, F.
AU  - Liang, R.
AU  - Luo, W.
AU  - Zhang, G.
TI  - Deep Learning Segmentation of Seismic Facies Based on Proximity Constraint Strategy: Innovative Application of UMA-Net Model
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5929517
DO  - 10.1109/TGRS.2024.3468869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205304684&doi=10.1109%2fTGRS.2024.3468869&partnerID=40&md5=5ab98615bb4ae971157bd43b631babf0
AB  - Intelligent seismic facies segmentation has recently gained significant attention, particularly with the application of deep learning technologies. However, existing methods face considerable challenges when processing complex seismic data, often due to their reliance on simplistic image mapping that fails to capture intricate geological structures and spatial relationships. Unlike natural image segmentation, seismic facies segmentation requires a global perspective that accounts for these complexities. To address these limitations, we propose the UMA-Net model, which integrates a U-shaped encoder-decoder structure with a mix-Transformer (MiT) and an attention-enhanced convolution module (AECM) to enhance global feature extraction and seismic information acquisition. A key innovation of this study is the proximity constraint strategy (PCS), which shifts the focus from traditional mapping to predicting geological targets by analyzing variations in adjacent seismic data. This approach significantly improves phase boundary identification and reduces phase confusion, offering a novel solution to the challenges of seismic facies segmentation. Experimental results demonstrate that UMA-Net outperforms state-of-The-Art networks in metrics such as pixel accuracy (PA) and intersection over union (IoU). Applied to seismic data from the F3 Netherlands work area, UMA-Net enhances segmentation accuracy while reducing reliance on labeled datasets, making it applicable to other regions facing similar geological challenges. This study not only advances the accuracy and efficiency of seismic interpretation but also opens new avenues for deep learning applications in seismic facies segmentation, particularly in improving model generalization across diverse geological settings.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, L.
AU  - Zhu, R.
AU  - Deng, J.
AU  - Song, Z.
AU  - Yang, W.
AU  - Zhang, T.
TI  - Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3476952
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207107906&doi=10.1109%2fTCSVT.2024.3476952&partnerID=40&md5=e200bbe492b925f8aa0ae108865715b9
AB  - Monocular depth estimation aims to infer a dense depth map from a single image, which is a fundamental and prevalent task in computer vision. Many previous works have shown impressive depth estimation results through carefully designed network structures, but they usually ignore the planar information and therefore perform poorly in low-texture areas of indoor scenes. In this paper, we propose Plane2Depth, which adaptively utilizes plane information to improve depth prediction within a hierarchical framework. Specifically, in the proposed plane guided depth generator (PGDG), we design a set of plane queries as prototypes to softly model planes in the scene and predict per-pixel plane coefficients. Then the predicted plane coefficients can be converted into metric depth values with the pinhole camera model. In the proposed adaptive plane query aggregation (APGA) module, we introduce a novel feature interaction approach to improve the aggregation of multi-scale plane features in a top-down manner. Extensive experiments show that our method can achieve outstanding performance, especially in low-texture or repetitive areas. Furthermore, under the same backbone network, our method outperforms the state-of-the-art methods on the NYU-Depth-v2 dataset, achieves competitive results with state-of-the-art methods KITTI dataset and can be generalized to unseen scenes effectively.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mao, Y.
AU  - Zhang, J.
AU  - Wan, Z.
AU  - Tian, X.
AU  - Li, A.
AU  - Lv, Y.
AU  - Dai, Y.
TI  - Generative Transformer for Accurate and Reliable Salient Object Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3469286
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205319292&doi=10.1109%2fTCSVT.2024.3469286&partnerID=40&md5=a5ca16577a2dfa57dfd3bce5c193d1cf
AB  - We explore the impact of transformers on accurate and reliable salient object detection. For accuracy, we integrate the transformer with a deterministic model and delineate its advantages in structural modeling. Regarding reliability, we address the transformer's tendency to produce overly confident, incorrect predictions. To gauge reliability implicitly, we introduce a latent variable model within the transformer framework, termed the inferential generative adversarial network (iGAN). The stochastic nature of the latent variable facilitates the estimation of predictive uncertainty, which serves as an auxiliary measure of the model's prediction reliability. Different from the conventional GAN, which defines the distribution of the latent variable as fixed standard normal distribution N (0, I). The proposed 'iGAN' infers the latent variable by gradient-based Markov Chain Monte Carlo (MCMC), namely Langevin dynamics, leading to an input-dependent latent variable model. We apply our proposed iGAN to fully supervised salient object detection, explaining that iGAN within the transformer framework leads to both accurate and reliable salient object detection. The source code and experimental results are publicly available via our project page: https://npucvr.github.io/TransformerSOD. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Sun, F.
AU  - Zhou, H.
AU  - Xie, Y.
AU  - Li, Z.
AU  - Zhu, L.
TI  - Multi-weather restoration: An efficient prompt-guided convolution architecture
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3469190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205435708&doi=10.1109%2fTCSVT.2024.3469190&partnerID=40&md5=acea736b236e630970f25feddf5424aa
AB  - Addressing degraded weather conditions plays a vital role in practical applications. Many existing restoration approaches are limited to specific weather types, which limits their applicability to different weather scenarios. Advanced technologies, encompassing Transformer and diffusion model, have been harnessed to confront this challenge. However, these methods often heighten network complexity and prolong inference duration. To this end, we present MW-ConvNet, a U-shaped convolution-based network for multi-weather restoration. Specifically, the MW-Enc block and MW-Dec block are introduced to achieve simple yet strong feature extraction, which rely entirely on traditional 2D convolution. To improve adaptability to multiple weather conditions, a prompt generation module is designed to generate a representative weather prompt at the encoder's terminus. Drawing inspiration from style transfer, the weather prompt is used to guide the decoder learning through a progressive restoration procedure. For future high-fidelity restoration, we introduce frequency separation through wavelet pooling blocks in encoder phase and corresponding up-sampling blocks in decoder phase. The segregated treatment of low-frequency and high-frequency features curbs the loss of textural information during network computation. It also future improves the quality and accuracy of generated weather prompt. Extensive experiments demonstrate that the proposed MW-ConvNet obtains superior performance compared to state-of-the-art methods across both weather-specific and real-world restoration tasks. Significantly, our method achieves an impressive inference speed of 0.12 seconds per 256x256 image, outpacing transformer-based and diffusion-based models.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Valsesia, D.
AU  - Bianchi, T.
AU  - Magli, E.
TI  - Onboard Deep Lossless and Near-Lossless Predictive Coding of Hyperspectral Images with Line-Based Attention
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5532714
DO  - 10.1109/TGRS.2024.3465043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204737915&doi=10.1109%2fTGRS.2024.3465043&partnerID=40&md5=23a2db72cfa0f5ed2d624db9b6a450c3
AB  - Deep learning methods have traditionally been difficult to apply to compression of hyperspectral images onboard spacecrafts due to the large computational complexity needed to achieve adequate representational power, as well as the lack of suitable datasets for training and testing. In this article, we depart from the traditional autoencoder approach, and we design a predictive neural network, called line receptance weighted key value (LineRWKV), which works recursively line by line to limit memory consumption. In order to achieve that, we adopt a novel hybrid attentive-recursive operation that combines the representational advantages of Transformers with the linear complexity and recursive implementation of recurrent neural networks (RNNs). The compression algorithm performs the prediction of each pixel using LineRWKV, followed by entropy coding of the residual. Experiments on multiple datasets show that LineRWKV is highly memory-efficient, significantly outperforms state-of-The-Art deep learning methods, and is the first deep learning approach to outperform CCSDS-123.0-B-2 at lossless and near-lossless compression. Promising throughput results are also evaluated on a 7-W embedded system.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, X.
AU  - Chen, Z.
AU  - Zhang, X.
AU  - Wang, G.
TI  - Context-Aware Content Interaction: Grasp Subtle Clues for Fine-Grained Aircraft Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5641319
DO  - 10.1109/TGRS.2024.3464851
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204707211&doi=10.1109%2fTGRS.2024.3464851&partnerID=40&md5=b8b741f748aa04f6484a96a1d5c26d7b
AB  - The fine-grained object detection, capable of identifying subcategories or types, is thriving in remote sensing scenes. In practice, most existing fine-grained detectors are derived from the two-stage R-CNN paradigm with intricate anchor boxes, focusing on refining features of region of interest (RoI) to boost performance, which often incurs a redundant process. In contrast, the one-stage, anchor-free paradigm possesses a simple yet effective pipeline, but its exploration in fine-grained detections is still far from sufficient. In this article, we propose a one-stage, anchor-free fine-grained detector for remote sensing aircraft recognition. We initially delve into predominant issues when extending the one-stage framework to conduct fine-grained detections, typified by severe interclass confusion and inferior performance in rare categories. Then, we design a fine-grained classification branch, including a region-to-region context distributor (R2CD), a class-aware decoupled focal loss (CDFL), and a cross-shaped sample space (CS3), to address these hindrances. Specifically, the R2CD flexibly integrates the sparse attention mechanism with mask prediction operations to conduct region-level content interactions separately within the foreground and background of feature maps, significantly alleviating the interclass confusion by enhancing subtle features; the CDFL employs dynamic modulation factors driven by optimization gradients to regulate loss contributions across categories while optimizing category-specific heatmaps, thus prioritizing rare categories with hard samples; the CS3 attains a preferable assignment strategy of positive and negative samples by incorporating structure prior, facilitating the capture of foreground features. Extensive experiments conducted on the MAR20 and FAIRPlane11 datasets demonstrate that our model excels at distinguishing fine-grained categories and is well-suited for performing fine-grained detection tasks.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liu, S.
AU  - Zhang, Y.
AU  - Liu, X.
AU  - Xia, M.
TI  - A Ladder Water Level Prediction Model for the Yangtze River Based on Transfer Learning and Transformer
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4211511
DO  - 10.1109/TGRS.2024.3478249
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207032312&doi=10.1109%2fTGRS.2024.3478249&partnerID=40&md5=daa538901665c6dd664f04297600fc66
AB  - Water level prediction is of great importance in alleviating the increasing water scarcity and preventing frequent floods. However, current water level prediction models do not consider the spatial and temporal features in water levels at monitoring stations. This study proposes a ladder water level prediction model for the Yangtze River based on transfer learning and Transformer to obtain more accurate predictions of water levels under tidal interactions. Our model utilizes the attention mechanism of the Transformer and incorporates spatial features and correlations of water level variations at the tidal limit of rivers. In addition, transfer learning is employed to explore and analyze the temporal characteristics of the wet season and dry season. Numerical experiments conducted at monitoring stations in the lower reach of the Yangtze River in China validate the effectiveness of our model. In 24-h water level prediction, our model achieves an average reduction of 52.14% in mean absolute error (MAE), 52.99% in root mean square error (RMSE), and an average increase of 5.70% in the pass rate within ±0.3 m compared to existing studies.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, W.
AU  - Cao, J.
AU  - Xie, J.
AU  - Yang, S.
AU  - Pang, Y.
TI  - CLIP-VIS: Adapting CLIP for Open-Vocabulary Video Instance Segmentation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3474698
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207109603&doi=10.1109%2fTCSVT.2024.3474698&partnerID=40&md5=46c11c3750969d8c4f1532ec0cc7ba4a
AB  - Open-vocabulary video instance segmentation strives to segment and track instances belonging to an open set of categories in a videos. The vision-language model Contrastive Language-Image Pre-training (CLIP) has shown robust zero-shot classification ability in image-level open-vocabulary tasks. In this paper, we propose a simple encoder-decoder network, called CLIP-VIS, to adapt CLIP for open-vocabulary video instance segmentation. Our CLIP-VIS adopts frozen CLIP and introduces three modules, including class-agnostic mask generation, temporal topK-enhanced matching, and weighted open-vocabulary classification. Given a set of initial queries, class-agnostic mask generation introduces a pixel decoder and a transformer decoder on CLIP pre-trained image encoder to predict query masks and corresponding object scores and mask IoU scores. Then, temporal topK-enhanced matching performs query matching across frames using the K mostly matched frames. Finally, weighted open-vocabulary classification first employs mask pooling to generate query visual features from CLIP pre-trained image encoder, and second performs weighted classification using object scores and mask IoU scores. Our CLIP-VIS does not require the annotations of instance categories and identities. The experiments are performed on various video instance segmentation datasets, which demonstrate the effectiveness of our proposed method, especially for novel categories. When using ConvNeXt-B as backbone, our CLIP-VIS achieves the AP and APn scores of 32.2% and 40.2% on the validation set of LV-VIS dataset, which outperforms OV2Seg by 11.1% and 23.9% respectively. We will release the source code and models at https://github.com/zwq456/CLIP-VIS.git.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Zhang, L.
AU  - Cen, Y.
AU  - Song, R.
AU  - Qi, W.
AU  - Huang, C.
TI  - Exploring Conflict-Matching Learning With Temporal Weight-Sharing and Bandwise Spatial-Interacting Transformer for Hyperspectral Change Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5531916
DO  - 10.1109/TGRS.2024.3465537
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205147903&doi=10.1109%2fTGRS.2024.3465537&partnerID=40&md5=d1d2d2d1bbd31d7890d8fccddbf22275
AB  - Hyperspectral imagery is valuable for accurate detection of land-cover changes within a consistent area across time. However, current training paradigms for hyperspectral change detection (CD) are usually in supervised form which are not consistent to heavy labeling cost reality. Moreover, current deep learning methods face limitations due to insufficient temporal dependencies' sharing and inadequate densely bandwise spatial position dependencies. To tackle these challenges, we introduce an innovative semi-supervised training paradigm called Conflict HyperMatch and a deep learning model called temporal weight-sharing and bandwise spatial interacting transformer (TWBSIT) for hyperspectral CD. The key contributions of this study are as follows: 1) introduction of the Conflict HyperMatch training schedule, which relies on representation discrepancy and weak-to-strong prediction consistency, to improve the sample leveraging of both labeled and unlabeled data; 2) weight-sharing interacting temporal attention (WITA) module is contributed to capture shared temporal interactions and resemblances; and 3) bandwise cross-spatial attention (BCSA) module is introduced to achieve a more extensive spatial perception of the specific central image patch. Extensive experiments conducted on three real datasets validate the effectiveness of the proposed TWBSIT model based on Conflict HyperMatch in leveraging both labeled and unlabeled samples for hyperspectral CD. This method notably decreases the requirement for labeled training samples and surpasses the performance of many existing hyperspectral CD methods.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Wang, S.
AU  - Zhu, J.
AU  - Xie, X.
AU  - Zhang, L.
TI  - Domain Adaptation Transformer for Unsupervised Driving-Scene Segmentation in Adverse Conditions
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 21129
EP  - 21141
DO  - 10.1109/TITS.2024.3461468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206256633&doi=10.1109%2fTITS.2024.3461468&partnerID=40&md5=6e319c7bf64b908829a1241c6728e9a8
AB  - Semantic segmentation in driving scenarios is important for modern autonomous driving technology. While the existing methods have shown promising results in segmenting normal-condition images, their performance in adverse scenes remains unsatisfactory due to limited visual field and lack of annotation. To address this issue, we propose an unsupervised domain adaptation semantic segmentation method with the transformer architecture, namely ACSegFormer, for driving-scene adverse conditions, aiming at mining image features in visually restricted scenes. Three effective training strategies are proposed in ACSegFormer to learn the latent image context relations and to reduce the gaps between different domains: an entropy-based pseudo label correction scheme that refines the target domain predictions with the normal reference predictions, an optimal transport-based inter-domain alignment module that performs domain alignment on the outputs of transformer encoder, and a masked context learning module that enhances the model's ability to perceive the missing information of target domain image. Our ACSegFormer has no additional training parameters on top of the existing transformer segmentation framework, which can be easily used for self-training-based unsupervised domain adaptation approaches. The experimental results show that our ACSegFormer achieves state-of-the-art performance on driving-scene segmentation benchmarks in adverse conditions, including Dark Zurich and ACDC. Codes and models are available at https://github.com/wenyyu/ACSegFormer. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Liu2024Domain
ER  -

TY  - JOUR
AU  - Erhard, L.
AU  - Hanke, S.
AU  - Remer, U.
AU  - Falenska, A.
AU  - Heiberger, R.H.
TI  - PopBERT.Detecting Populism and Its Host Ideologies in the German Bundestag
PY  - 2024
T2  - Political Analysis
DO  - 10.1017/pan.2024.12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206297389&doi=10.1017%2fpan.2024.12&partnerID=40&md5=a571a38aac78b1bac4b3e1ef5b8794b7
AB  - The rise of populism concerns many political scientists and practitioners, yet the detection of its underlying language remains fragmentary.This paper aims to provide a reliable, valid, and scalable approach to measure populist rhetoric.For that purpose, we created an annotated dataset based on parliamentary speeches of the German Bundestag (2013-2021).Following the ideational definition of populism, we label moralizing references to “the virtuous people” or “the corrupt elite” as core dimensions of populist language.To identify, in addition, how the thin ideology of populism is “thickened,” we annotate how populist statements are attached to left-wing or right-wing host ideologies.We then train a transformer-based model (PopBERT) as a multilabel classifier to detect and quantify each dimension.A battery of validation checks reveals that the model has a strong predictive accuracy, provides high qualitative face validity, matches party rankings of expert surveys, and detects out-of-sample text snippets correctly.PopBERT enables dynamic analyses of how German-speaking politicians and parties use populist language as a strategic device.Furthermore, the annotator-level data may also be applied in cross-domain applications or to develop related classifiers. © The Author(s), 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Christ, L.
AU  - Amiriparian, S.
AU  - Kathan, A.
AU  - Muller, N.
AU  - Konig, A.
AU  - Schuller, B.W.
TI  - Towards Multimodal Prediction of Spontaneous Humor: A Novel Dataset and First Results
PY  - 2024
T2  - IEEE Transactions on Affective Computing
DO  - 10.1109/TAFFC.2024.3475736
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207140767&doi=10.1109%2fTAFFC.2024.3475736&partnerID=40&md5=cf0ae5360f6618aff481e99e8c6aa708
AB  - Humor is a substantial element of human social behavior, affect, and cognition. Its automatic understanding can facilitate a more naturalistic human-AI interaction. Current methods of humor detection have been exclusively based on staged data, making them inadequate for 'real-world' applications. We contribute to addressing this deficiency by introducing the novel Passau-Spontaneous Football Coach Humor (Passau-SFCH) dataset, comprising about 11 hours of recordings. The Passau-SFCH dataset is annotated for the presence of humor and its dimensions (sentiment and direction) as proposed in Martin's Humor Style Questionnaire. We conduct a series of experiments employing pretrained Transformers, convolutional neural networks, and expert-designed features. The performance of each modality (text, audio, video) for spontaneous humor recognition is analyzed and their complementarity is investigated. Our findings suggest that for the automatic analysis of humor and its sentiment, facial expressions are most promising, while humor direction can be best modeled via text-based features. Further, we experiment with different multimodal approaches to humor recognition, including decision-level fusion and MulT, a multimodal Transformer approach. In this context, we propose a novel multimodal architecture that yields the best overall results. Finally, we make our code publicly available at https://www.github.com/lc0197/passau-sfch. The Passau-SFCH dataset is available upon request.  © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, W.
AU  - Hu, W.
AU  - Chen, X.
AU  - Yuan, W.
AU  - Wang, Y.
AU  - Zhang, Y.
AU  - Han, Z.
TI  - Tri-Modal Transformers with Mixture-of-Modality-Experts for Social Media Prediction
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3474101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207019690&doi=10.1109%2fTCSVT.2024.3474101&partnerID=40&md5=497ba2527746b009dd7ebce1ff35efc4
AB  - With billions of users worldwide, accurately predicting social media popularity is crucial for assessing user behavior, forecasting trends, and enhancing social interactions and business strategies. However, this task presents significant challenges. Firstly, the extraction of valuable insights is complicated by the presence of tri-modal data (visual, text, structured) and pervasive noise. Secondly, the applicability of knowledge acquired during the pre-training phase is often limited due to discrepancies with downstream prediction tasks during the fine-tuning phase. Existing methods for Social Media Popularity Prediction (SMPP), including traditional models and Visual-and-language Models (VLMs), struggle to overcome these challenges, thereby failing to achieve satisfactory accuracy. To tackle these challenges, we propose a novel approach named Tri-Modal Transformers with Mixture-of-Modality-Experts (TTME) for SMPP. TTME integrates Artificial Intelligence Generated Content to mitigate data noise and incorporate a mix of Modality Experts in pre-training phases to effectively utilize tri-modal data. Moreover, to address training disparity, we explore strategies for downstream task adaptation including the integration of diverse pre-training experts and the implementation of DistillSoftmax. Through empirical evaluation, we demonstrate that the TTME significantly improves the accuracy of social media popularity predictions, effectively utilizes tri-modal data with noise, and enhances transferring knowledge from pre-training to downstream tasks.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shi, B.
AU  - Feng, L.
AU  - He, H.
AU  - Hao, Y.
AU  - Peng, Y.
AU  - Liu, M.
AU  - Liu, Y.
AU  - Liu, J.
TI  - A Physics-Guided Attention-Based Neural Network for Sea Surface Temperature Prediction
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4210413
DO  - 10.1109/TGRS.2024.3457039
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204006517&doi=10.1109%2fTGRS.2024.3457039&partnerID=40&md5=26af47bf494a32b61bc82c34cff06229
AB  - Accurate prediction of sea surface temperature (SST) is crucial in the field of oceanography, as it has a significant impact on various physical, chemical, and biological processes in the marine environment. In this study, we propose a physics-guided attention-based neural network (PANN) to address the spatiotemporal SST prediction problem. The PANN model incorporates data-driven spatiotemporal convolution operations and the underlying physical dynamics of SSTs using a cross-attention mechanism. First, we construct a spatiotemporal convolution module (SCM) using convolutional long short-term memory (ConvLSTM) to capture the spatial and temporal correlations present in the time series of the SST data. We then introduce a physical constraint module (PCM) to mimic the transport dynamics in fluids based on data assimilation techniques used to solve partial differential equations (PDEs). Consequently, we employ an attention fusion module (AFM) to effectively combine the data-driven and PDE-constrained predictions obtained from the SCM and PCM, aiming at enhancing the accuracy of the predictions. To evaluate the performance of the proposed model, we conduct short-term SST forecasts in the East China Sea (ECS) with forecast lead times ranging from one to ten days, by comparing it with several state-of-the-art models, including ConvLSTM, PredRNN, temporal convolutional transformer network (TCTN), convolutional gated recurrent unit (ConvGRU), and SwinLSTM. The experimental results demonstrate that our proposed model outperforms these models in terms of multiple evaluation metrics for short-term predictions.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hou, J.
AU  - Ji, Z.
AU  - Yang, J.
AU  - Zheng, F.
TI  - Bidirectional Error-Aware Fusion Network for Video Inpainting
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3454641
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203491848&doi=10.1109%2fTCSVT.2024.3454641&partnerID=40&md5=9f9ff2a508b8cb8a87111b9d339fe641
AB  - Existing video inpainting approaches tend to adopt vision transformers with rare customized designs, which poses two limitations. Firstly, the conventional self-attention mechanism treats tokens from invalid and valid regions equally and mingles them, which may incur blurriness. Secondly, these approaches merely employ forward frames as references, while ignoring the past inpainted frames, which are also valuable in enhancing temporal consistency and offering more available information. In this paper, we propose a new video inpainting network, called Bidirectional Error-Aware Fusion Network (BEAF-Net). Concretely, on one hand, we propose a tailored Error-Aware Transformer (EAT) that discerns different tokens by assigning dynamic weights to bridle the use of erroneous tokens. Meanwhile, each EAT is equipped with a Spatial Feature Enhancement (SFE) layer to synthesize features with multi-scales. On the other hand, we apply a pair of EATs to utilize forward reference frames and past inpainted frames simultaneously, and a proposed Bidirectional Fusion (BiF) layer is exerted to blend the aggregation results adaptively. By coupling these novel designs, our proposed BEAF-Net completely leverages the location priors, multi-scale perception, and past predictions to produce more faithful and consistent inpainting results. We corroborate our BEAF-Net on two commonly-used video inpainting datasets: DAVIS and Youtube-VOS, where the experimental results demonstrate BEAF-Net compares favorably with state-of-the-art solutions. Video examples can be found at https://github.com/JCATCV/BEAF-Net.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Wei, S.
AU  - Zhou, Y.
AU  - Luo, M.
AU  - Yu, W.
AU  - Ji, S.
TI  - P2PFormer: A Primitive-to-Polygon Method for Regular Building Contour Extraction From Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4414012
DO  - 10.1109/TGRS.2024.3459011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204184719&doi=10.1109%2fTGRS.2024.3459011&partnerID=40&md5=76c6c1ec3dca30273cfacc20e291e797
AB  - Extracting building contours from remote sensing imagery is a significant challenge due to buildings' complex and diverse shapes, occlusions, and noise. Existing methods often struggle with irregular contours, rounded corners, and redundancy points, necessitating extensive postprocessing to produce regular polygonal building contours. To address these challenges, we introduce a novel, streamlined pipeline that generates regular building contours without postprocessing. Our approach begins with the segmentation of generic geometric primitives (which can include vertices, lines, and corners), followed by the prediction of their sequence. This allows for the direct construction of regular building contours by sequentially connecting the segmented primitives. Building on this pipeline, we developed primitive-to-polygon using transformer (P2PFormer), which uses a transformer-based architecture to segment geometric primitives and predict their order. To enhance the segmentation of primitives, we introduce a unique representation called group queries. This representation comprises a set of queries and a singular query position, which improve the focus on multiple midpoints of primitives and their efficient linkage. Furthermore, we propose an innovative implicit update strategy for the query position embedding aimed at sharpening the focus of queries on the correct positions and, consequently, enhancing the quality of primitive segmentation. Our experiments demonstrate that P2PFormer achieves new state-of-the-art (SOTA) performance on the WHU, CrowdAI, and WHU-Mix datasets, surpassing the previous SOTA PolyWorld by a margin of 2.7 AP and 6.5 AP75 on the largest CrowdAI dataset. We intend to make the code and trained weights publicly available to promote their use and facilitate further research. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Wang, M.
AU  - Wang, J.
AU  - Wang, Y.
AU  - Chu, X.
TI  - Long short-term search session-based document re-ranking model
PY  - 2024
T2  - Knowledge and Information Systems
DO  - 10.1007/s10115-024-02205-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203453542&doi=10.1007%2fs10115-024-02205-4&partnerID=40&md5=1435f17b736dba9e848631a124f3f46e
AB  - Document re-ranking is a core task in session search. However, most existing methods only focus on the short-term session and ignore the long-term history sessions. This leads to inadequate understanding of the user’s search intent, which affects the performance of model re-ranking. At the same time, these methods have weaker capability in understanding user queries. In this paper, we propose a long short-term search session-based re-ranking model (LSSRM). Firstly, we utilize the BERT model to predict the topic relevance between the query and candidate documents, in order to improve the model’s understanding of user queries. Secondly, we initialize the reading vector with topic relevance and use the personalized memory encoder module to model the user’s long-term search intent. Thirdly, we input the user’s current session interaction sequence into Transformer to obtain the vector representation of the user’s short-term search intent. Finally, the user’s search intent and topical relevance information are hierarchically fused to obtain the final document ranking scores. Then re-rank the documents according to this score. We conduct extensive experiments on two real-world session datasets. The experimental results show that our method outperforms the baseline models for the document re-ranking task. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Wang, H.
AU  - Xi, Z.
AU  - Wang, L.
AU  - Chen, C.
AU  - Guo, T.
AU  - Yan, M.
AU  - Wang, T.
TI  - Multitask Learning-Driven Physics-Guided Deep Learning Magnetotelluric Inversion
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5926416
DO  - 10.1109/TGRS.2024.3457893
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203988679&doi=10.1109%2fTGRS.2024.3457893&partnerID=40&md5=a8d1bc60d187eb58403f11bab8fd6c73
AB  - An ongoing trend seeking to incorporate forward modeling, which involves the physical laws of wave propagation, into the network architecture to improve the generalization capability of the deep learning (DL) inversion method has showcased promising applications. However, directly embedding the time-consuming 2-D magnetotelluric (MT) forward modeling solved by conventional numerical algorithms to facilitate physics-guided DL MT inversion, which usually necessitates millions of forward operations during a complete training session, is challenging. Hence, in this work, we develop a physics-guided DL inversion method (PGWNet) by constructing a W-shaped DL model and performing a multitask learning strategy. The DL model consists of one encoder and two decoders, where the two decoders are independent of each other and share the encoder. During the training process, two decoders are first optimized independently by minimizing the model misfit, quantifying the discrepancy between the predicted and labeled resistivity models, and the data misfit, quantifying the discrepancy between the predicted and labeled MT responses, respectively. When model and data misfits backpropagate to the encoder, they are combined to jointly optimize the encoder. Moreover, to ensure practical application effect, this work builds a set of random synthetic resistivity models with gradually varying resistivity values to delineate realistic subsurface structures. We substantiate the developed PGWNet inversion method using synthetic and actual MT data and benchmark it against a fully data-driven DL inversion method and the conventional least-squares regularization inversion method. It is anticipated to promote the practicability and applicability of the DL inversion method in practical MT prospecting scenarios.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Yokoya, N.
AU  - Gu, X.
AU  - Tian, Q.
AU  - Bruzzone, L.
TI  - Local-to-Global Cross-Modal Attention-Aware Fusion for HSI-X Semantic Segmentation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5531817
DO  - 10.1109/TGRS.2024.3465030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203716108&doi=10.1109%2fTGRS.2024.3465030&partnerID=40&md5=15943edff21ff1c07361d0d00b8d0087
AB  - Hyperspectral image (HSI) classification has recently reached its performance bottleneck. Multimodal data fusion is emerging as a promising approach to overcome this bottleneck by providing rich complementary information from the supplementary modality (X-modality). However, achieving comprehensive cross-modal interaction and fusion that can be generalized across different sensing modalities is challenging due to the disparity in imaging sensors, resolution, and content of different modalities. In this study, we propose a local-to-global cross-modal attention-aware fusion (LoGoCAF) framework for HSI-X segmentation. LoGoCAF adopts a two-branch semantic segmentation architecture to learn information from HSI and X modalities. The pipeline of LoGoCAF consists of a local-to-global encoder and a lightweight all multilayer perceptron (ALL-MLP) decoder. In the encoder, convolutions are used to encode local and high-resolution fine details in shallow layers, while transformers are used to integrate global and low-resolution coarse features in deeper layers. The ALL-MLP decoder aggregates information from the encoder for feature fusion and prediction. In particular, two cross-modality modules, the feature enhancement module (FEM) and the feature interaction and fusion module (FIFM), are introduced in each encoder stage. The FEM is used to enhance complementary information by combining information from the other modality across direction-aware, position-sensitive, and channel-wise dimensions. With the enhanced features, the FIFM is designed to promote cross-modality information interaction and fusion for the final semantic prediction. Extensive experiments demonstrate that our LoGoCAF achieves superior performance and generalizes well on various multimodal datasets. Code is available at https://github.com/xumzhang.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, H.
AU  - Sun, L.
AU  - Du, B.
AU  - Lv, W.
TI  - Learning Joint 2-D and 3-D Graph Diffusion Models for Complete Molecule Generation
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 9
SP  - 11857
EP  - 11871
DO  - 10.1109/TNNLS.2024.3416328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203303541&doi=10.1109%2fTNNLS.2024.3416328&partnerID=40&md5=877610669d525758fecdc9e459e5a7c7
AB  - Designing new molecules is essential for drug discovery and material science. Recently, deep generative models that aim to model molecule distribution have made promising progress in narrowing down the chemical research space and generating high-fidelity molecules. However, current generative models only focus on modeling 2-D bonding graphs or 3-D geometries, which are two complementary descriptors for molecules. The lack of ability to jointly model them limits the improvement of generation quality and further downstream applications. In this article, we propose a joint 2-D and 3-D graph diffusion model (JODO) that generates geometric graphs representing complete molecules with atom types, formal charges, bond information, and 3-D coordinates. To capture the correlation between 2-D molecular graphs and 3-D geometries in the diffusion process, we develop a diffusion graph transformer (DGT) to parameterize the data prediction model that recovers the original data from noisy data. The DGT uses a relational attention mechanism that enhances the interaction between node and edge representations. This mechanism operates concurrently with the propagation and update of scalar attributes and geometric vectors. Our model can also be extended for inverse molecular design targeting single or multiple quantum properties. In our comprehensive evaluation pipeline for unconditional joint generation, the experimental results show that JODO remarkably outperforms the baselines on the QM9 and GEOM-Drugs datasets. Furthermore, our model excels in few-step fast sampling, as well as in inverse molecule design and molecular graph generation. Our code is provided in https://github.com/GRAPH-0/JODO.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, C.
AU  - Zhao, J.
AU  - Li, L.
AU  - Jiao, L.
AU  - Liu, F.
AU  - Yang, S.
TI  - Automatic Graph Topology-Aware Transformer
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
DO  - 10.1109/TNNLS.2024.3440269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204489757&doi=10.1109%2fTNNLS.2024.3440269&partnerID=40&md5=32d2593e6728cdb146e00e994def5d07
AB  - Existing efforts are dedicated to designing many topologies and graph-aware strategies for the graph Transformer, which greatly improve the model's representation capabilities. However, manually determining the suitable Transformer architecture for a specific graph dataset or task requires extensive expert knowledge and laborious trials. This article proposes an evolutionary graph Transformer architecture search (EGTAS) framework to automate the construction of strong graph Transformers. We build a comprehensive graph Transformer search space with the micro-level and macro-level designs. EGTAS evolves graph Transformer topologies at the macro level and graph-aware strategies at the micro level. Furthermore, a surrogate model based on generic architectural coding is proposed to directly predict the performance of graph Transformers, substantially reducing the evaluation cost of evolutionary search. We demonstrate the efficacy of EGTAS across a range of graph-level and node-level tasks, encompassing both small-scale and large-scale graph datasets. Experimental results and ablation studies show that EGTAS can construct high-performance architectures that rival state-of-the-art manual and automated baselines.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, Y.
AU  - Liang, Z.
AU  - Liu, X.
AU  - Hou, Q.
AU  - Cheng, M.-M.
TI  - Reformulating Classification as Image-Class Matching for Class Incremental Learning
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2024.3462734
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204561469&doi=10.1109%2fTCSVT.2024.3462734&partnerID=40&md5=7066942624c0a081bfc274a5271592af
AB  - Class incremental learning (CIL) sequentially increases the number of classes, which often leads to catastrophic forgetting when fine-tuning on new classes. Existing approaches typically employ linear classifiers and expand them to accommodate new classes. However, conducting conventional classification inherently introduces feature drift in the image space upon the introduction of new classifiers, potentially disrupting the established distributions, and resulting in forgetting. In this paper, we propose a novel insight to reformulate the conventional classification as image-class matching (ICM) to mitigate the disruption. ICM independently encodes the image and the category and allows for the sharing of a matching classifier across all tasks, effectively stabilizing the feature space during the CIL process. To apply ICM to CIL, we introduce the Binary Matching Classification (BMC) framework, which employs cross attention to encode the matching relationship between images and each category to predict matching scores. When learning new tasks, BMC only requires the addition of category inputs without any structural changes. Moreover, we present a series of strategies to enhance the adaptation of BMC to CIL. Through simple regularization, our BMC framework achieves outstanding performance on various benchmarks including CIFAR-100, ImageNet-100, and ImageNet-1000 datasets. Our code is available at https://github.com/Ethanhuhuhu/BMC.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, H.
AU  - Chen, G.
AU  - Zhao, H.
AU  - Jiang, D.
AU  - Zhang, X.
AU  - Tian, Q.
AU  - Knoll, A.
TI  - SDPT: Semantic-Aware Dimension-Pooling Transformer for Image Segmentation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 15934
EP  - 15946
DO  - 10.1109/TITS.2024.3417813
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203146661&doi=10.1109%2fTITS.2024.3417813&partnerID=40&md5=7214e77593b55b9c92ca2ba67dd56709
AB  - Image segmentation plays a critical role in autonomous driving by providing vehicles with a detailed and accurate understanding of their surroundings. Transformers have recently shown encouraging results in image segmentation. However, transformer-based models are challenging to strike a better balance between performance and efficiency. The computational complexity of the transformer-based models is quadratic with the number of inputs, which severely hinders their application in dense prediction tasks. In this paper, we present the semantic-aware dimension-pooling transformer (SDPT) to mitigate the conflict between accuracy and efficiency. The proposed model comprises an efficient transformer encoder for generating hierarchical features and a semantic-balanced decoder for predicting semantic masks. In the encoder, a dimension-pooling mechanism is used in the multi-head self-attention (MHSA) to reduce the computational cost, and a parallel depth-wise convolution is used to capture local semantics. Simultaneously, we further apply this dimension-pooling attention (DPA) to the decoder as a refinement module to integrate multi-level features. With such a simple yet powerful encoder-decoder framework, we empirically demonstrate that the proposed SDPT achieves excellent performance and efficiency on various popular benchmarks, including ADE20K, Cityscapes, and COCO-Stuff. For example, our SDPT achieves 48.6% mIOU on the ADE20K dataset, which outperforms the current methods with fewer computational costs. The codes can be found at https://github.com/HuCaoFighting/SDPT.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Cao2024SDPT
ER  -

TY  - JOUR
AU  - Zhu, C.
AU  - Ma, X.
AU  - D'Urso, P.
AU  - Qian, Y.
AU  - Ding, W.
AU  - Zhan, J.
TI  - Long-Term Multivariate Time-Series Forecasting Model Based on Gaussian Fuzzy Information Granules
PY  - 2024
T2  - IEEE Transactions on Fuzzy Systems
VL  - 32
IS  - 11
SP  - 6424
EP  - 6438
DO  - 10.1109/TFUZZ.2024.3449769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202756366&doi=10.1109%2fTFUZZ.2024.3449769&partnerID=40&md5=f4aef59c8f3aebc8bf44b031a299ccd4
AB  - Long-term forecasting of multivariate time series has been an important research issue in the field of data mining and knowledge discovery. Fuzzy information granularity is used as an effective tool to handle long-term forecasting of time series. On account of its good interpretability and effect, it has received the attention of more and more scholars. However, although the method has been universally used in univariate time series, its application for multivariate time series has received little attention. In order to utilize the advantages of fuzzy information granularity and fill its gap in solving multivariate time-series forecasting problems. In view of this purpose, we design a long-term multivariate time-series forecasting modeling framework in light of Gaussian fuzzy information granules. The model includes a granulation method of under multivariate time series, as well as a neural network model that combines the backpropagation neural network, long short-term memory neural network, and transformer for long-term prediction, in which there is a fuzzy information granule segmentation method with polynomials as the core line and a new representation method for fuzzy information granules. We carry out experimental evaluations using eight publicly available time-series data, and the results show that our model is able to perform long-term forecasting of multivariate time series with a high satisfactory accuracy. © 1993-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pei, J.
AU  - Guo, D.
AU  - Zhang, J.
AU  - Lin, M.
AU  - Jin, Y.
AU  - Heng, P.
TI  - S2Former-OR: Single-Stage Bi-Modal Transformer for Scene Graph Generation in OR
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
SP  - 1
EP  - 1
DO  - 10.1109/TMI.2024.3444279
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201480529&doi=10.1109%2fTMI.2024.3444279&partnerID=40&md5=970054e52eb0df9f4301f0ad95b46bb5
AB  - Scene graph generation (SGG) of surgical procedures is crucial in enhancing holistically cognitive intelligence in the operating room (OR). However, previous works have primarily relied on multi-stage learning, where the generated semantic scene graphs depend on intermediate processes with pose estimation and object detection. This pipeline may potentially compromise the flexibility of learning multimodal representations, consequently constraining the overall effectiveness. In this study, we introduce a novel single-stage bi-modal transformer framework for SGG in the OR, termed, <italic>S</italic>2Former-OR, aimed to complementally leverage multi-view 2D scenes and 3D point clouds for SGG in an end-to-end manner. Concretely, our model embraces a View-Sync Transfusion scheme to encourage multi-view visual information interaction. Concurrently, a Geometry-Visual Cohesion operation is designed to integrate the synergic 2D semantic features into 3D point cloud features. Moreover, based on the augmented feature, we propose a novel relation-sensitive transformer decoder that embeds dynamic entity-pair queries and relational trait priors, which enables the direct prediction of entity-pair relations for graph generation without intermediate steps. Extensive experiments have validated the superior SGG performance and lower computational cost of <italic>S</italic>2<italic>Former-OR</italic> on 4D-OR benchmark, compared with current OR-SGG methods, <italic>e.g</italic>., 3 percentage points Precision increase and 24.2M reduction in model parameters. We further compared our method with generic single-stage SGG methods with broader metrics for a comprehensive evaluation, with consistently better performance achieved. Our source code can be made available at: https://github.com/PJLallen/S2Former-OR. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kakhani, N.
AU  - Rangzan, M.
AU  - Jamali, A.
AU  - Attarchi, S.
AU  - Kazem Alavipanah, S.
AU  - Mommert, M.
AU  - Tziolas, N.
AU  - Scholten, T.
TI  - SSL-SoilNet: A Hybrid Transformer-Based Framework With Self-Supervised Learning for Large-Scale Soil Organic Carbon Prediction
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4509915
DO  - 10.1109/TGRS.2024.3446042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201780433&doi=10.1109%2fTGRS.2024.3446042&partnerID=40&md5=56b327d3e3e29760f7a76ac878bd14fa
AB  - Soil organic carbon (SOC) constitutes a fundamental component of terrestrial ecosystem functionality, playing a pivotal role in nutrient cycling, hydrological balance, and erosion mitigation. Precise mapping of SOC distribution is imperative for the quantification of ecosystem services, notably carbon sequestration and soil fertility enhancement. Digital soil mapping (DSM) leverages statistical models and advanced technologies, including machine learning (ML), to accurately map soil properties, such as SOC, utilizing diverse data sources like satellite imagery, topography, remote sensing indices, and climate series. Within the domain of ML, self-supervised learning (SSL), which exploits unlabeled data, has gained prominence in recent years. This study introduces a novel approach that aims to learn the geographical link between multimodal features via self-supervised contrastive learning, employing pretrained Vision Transformers (ViT) for image inputs and Transformers for climate data, before fine-tuning the model with ground reference samples. The proposed approach has undergone rigorous testing on two distinct large-scale datasets, with results indicating its superiority over traditional supervised learning models, which depends solely on labeled data. Furthermore, through the utilization of various evaluation metrics (e.g., root-mean-square error (RMSE), mean absolute error (MAE), concordance correlation coefficient (CCC), etc.), the proposed model exhibits higher accuracy when compared to other conventional ML algorithms like random forest and gradient boosting. This model is a robust tool for predicting SOC and contributes to the advancement of DSM techniques, thereby facilitating land management and decision-making processes based on accurate information. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, S.
AU  - Fan, F.
TI  - STINet: Vegetation Changes Reconstruction Through a Transformer-Based Spatiotemporal Fusion Approach in Remote Sensing
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4412116
DO  - 10.1109/TGRS.2024.3443258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201274219&doi=10.1109%2fTGRS.2024.3443258&partnerID=40&md5=3545913ccc962ef27e616eb845f0cc70
AB  - Filling gaps in high-resolution satellite imagery is essential for tracking vegetation changes over time. Spatiotemporal fusion (STF) aims to create fusion products that improve both spatial resolution and temporal coverage by using images from various remote sensing sources. However, most existing STF methods rely on the assumption that reflectance values for the same land-cover type remain constant between base and prediction dates, a premise often invalidated by the variability in vegetation disturbance and recovery scenarios, where differences in disturbance intensity, patterns, and phenological stages challenge this uniformity. Therefore, we propose a novel Transformer-based method, the spatiotemporal integration network (STINet), which is effective in fusing multiscale spatiotemporal dynamic features. STINet is structured around three key components. The feature fusion (FF) block effectively integrates multiscale spatiotemporal information into a deep learning (DL) framework. The adaptive feature extraction (AFE) block significantly improves the precision of pixel-level features, essential for detecting subtle changes in diverse vegetation patterns. The spatiotemporal-wise multihead self-attention (ST-MSA) module through its innovative self-attention mechanism across spatiotemporal dimensions, facilitated the reconstruction of vegetation dynamics. To verify the effectiveness and robustness of the proposed method, we conducted experiments in three carefully selected scenarios using multisensor and multitemporal imagery to reconstruct the dynamic changes in vegetation due to various disturbances and recovery processes. Compared to the four typical fusion methods [enhanced spatial and temporal adaptive reflectance fusion model (ESTARFM), flexible spatiotemporal data fusion method (FSDAF), extended super-resolution convolutional neural network (ESRCNN), and multiscene spatiotemporal fusion network (MUSTFN)], STINet achieved the best performance in preserving both spatial texture and spectral value. Furthermore, we showcased the applicability and effectiveness of STINet in accurately capturing phenological changes and distinguishing various farming activities.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pan, J.
AU  - He, C.
AU  - Huang, W.
AU  - Cao, J.
AU  - Tong, M.
TI  - Wavelet Tree Transformer: Multihead Attention with Frequency-Selective Representation and Interaction for Remote Sensing Object Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5637023
DO  - 10.1109/TGRS.2024.3442575
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201308339&doi=10.1109%2fTGRS.2024.3442575&partnerID=40&md5=8aa364ea541d16f38bf8c493d442b045
AB  - Vision Transformer has achieved remarkable success in image recognition tasks owing to its global modeling ability. However, the quadratic computational complexity becomes a prominent issue when dealing with high-resolution remote sensing images. Numerous studies have explored the potential of spectral analysis to reveal for more discriminative features. However, neural network exhibit frequency tendency, and different features are interested in different frequencies. Unfortunately, there is no well-established criterion for selecting appropriate frequency representations. To address these issues, a novel wavelet tree head attention (WTHA-ViT) model is proposed which combines a tree structure on the wavelet frequencies with multihead attention in the Transformer encoder, possessing the ability to interact with cross-combinations of short and long-range as well as high and low-frequency components. First, we construct a wavelet tree reduction module (WTRM) based on the wavelet tree structure, utilizing the wavelet decomposition to retain frequency features suitable for each patch, which enables global modeling with various frequency components while reducing computational complexity. Second, guided by channel correlations, we propose the channel lifting scheme multihead attention (CLSMHA) to model the importance on the heads of multihead attention and focus on the more salient head features. Finally, our WTHA-ViT can replace the backbone of detection networks for dense prediction tasks. Extensive experiments on DOTA-V1.0 and HRSID datasets demonstrate that our model exhibits superior performance and robustness compared to state-of-the-art networks. Besides, we evaluate the transferability of the model on DIOR and LEVIR datasets and verify its generalization ability. The code is available at https://github.com/conquer-pan/WTHA-ViT.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, G.
AU  - Liu, M.
AU  - Li, L.
TI  - A Spatiotemporal fusion Transformer model for Chlorophyll-a concentrations prediction over large areas with satellite time series data
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
SP  - 1
EP  - 1
DO  - 10.1109/TGRS.2024.3451999
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202741491&doi=10.1109%2fTGRS.2024.3451999&partnerID=40&md5=79a35cb0dcc3937fec9c80b9478fbb00
AB  - Predicting Chlorophyll-a (Chla) is essential to support the marine environment changes, marine ecosystem health, and provide early warning of algae blooms. The development of learning-based methods has facilitated Chla prediction research. Still, most of the current methods can only predict short-term Chla changes in small areas, which is limited by the ability of the model to exploit spatiotemporal dependencies. Thus, this paper proposes a spatiotemporal fusion Transformer prediction model (STF_Transformer) to predict relatively long-term Chla changes (15 days ahead). This model utilizes temporal and spatial Transformer modules to extract the temporal and spatial correlations of the input spatiotemporal sequences, which are then fused to predict the 15-day Chla. The experimental results show that the proposed model has the optimal performance compared to the existing methods (e.g. CNN, LSTM, and ConvLSTM), with Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) less than 0.61 mg/m3, 0.315 mg/m3 and 22.5%, respectively, for 15 days Chla prediction in a large area (including Bohai, Yellow, and East China Sea). In addition, the temporal and spatial prediction results of the proposed model show that the predicted Chla has consistent temporal and spatial patterns with the observed Chla. This study indicates that the proposed STF_Transformer model can provide a highly accurate prediction of Chla over a large area in the relatively long term (15 days), providing data and technical support for marine ecosystem-related applications. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Fu, Q.
AU  - Kun, Z.
AU  - Liu, G.
AU  - Huang, H.
TI  - Enhancing transparent object matting using predicted definite foreground and background
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
SP  - 1
EP  - 1
DO  - 10.1109/TCSVT.2024.3452512
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202771564&doi=10.1109%2fTCSVT.2024.3452512&partnerID=40&md5=1793f5537cb896bca1b2fa024556051a
AB  - Natural image matting is a widely used image processing technique that extracts foreground by predicting the alpha values of the unknown region based on the alpha values of the known foreground and background regions. However, existing image matting methods may not yield the most optimal results when applied to images containing transparent objects because the known foreground region is small or even absent. To address this shortcoming, in this paper, we propose a novel method named Transparent Object Matting using Predicted Definite Foreground and Background (TOM-PDFB), which can explore and utilize the definite foreground and background in the unknown region. For this purpose, a newly developed foreground-background confidence estimator is applied to predict the confidence level of the definite foreground and the definite background, thus providing the priors required for transparent object matting. Next, foreground-background guided progressive refinement network developed as a part of this work is adopted to incorporate the estimated definite foreground and background into the alpha matte refinement process. Extensive experimental results demonstrate that the TOM-PDFB outperforms state-of-the-art methods when applied to transparent objects. Project page: https://github.com/fuqian95/TOM-PDFB. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ye, Z.
AU  - Liu, Y.
AU  - Peng, Y.
TI  - MAAN: Memory-Augmented Auto-Regressive Network for Text-Driven 3D Indoor Scene Generation
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 11057
EP  - 11069
DO  - 10.1109/TMM.2024.3443657
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202729196&doi=10.1109%2fTMM.2024.3443657&partnerID=40&md5=a5f8de6b079b373df5c5ac570960d174
AB  - The objective of text-driven 3D indoor scene generation is to automatically generate and arrange the objects to form a 3D scene that accurately captures the semantics detailed in the given text description. Existing approaches are mainly guided by specific object categories and room layout to generate and position objects like furniture within 3D indoor scenes. However, few methods harness the potential of the text description to precisely control both spatial relationships and object combinations. Consequently, these methods lack a robust mechanism for determining accurate object attributes necessary to craft a plausible 3D scene that maintains consistent spatial relationships in alignment with the provided text description. To tackle these issues, we propose the Memory-Augmented Auto-regressive Network (MAAN), which is a text-driven method for synthesizing 3D indoor scenes with controllable spatial relationships and object compositions. Firstly, we propose a memory-augmented network to help the model decide the attributes of the objects, such as 3D coordinates, rotation and size, which improves the consistency of the object spatial relations with text descriptions. Our approach constructs a memory context to select relevant objects within the scene, which provides spatial information that aids in generating the new object with the correct attributes. Secondly, we develop a prior attribute prediction network to learn how to generate a complete scene with suitable and reasonable object compositions. This prior attribute prediction network adopts a pre-training strategy to extract composition priors from existing scenes, which enables the organization of multiple objects to form a reasonable scene and keeps the object relations according to the text descriptions. We conduct experiments on three different room types (bedroom, living room, and dining room) on the 3D-FRONT dataset. The results of these experiments underscore the accuracy of our method in governing spatial relationships among objects, showcasing its superior flexibility compared to existing techniques. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Jiao, L.
AU  - Li, Y.
AU  - Liu, X.
AU  - Li, L.
AU  - Chen, P.
AU  - Liu, F.
AU  - Yang, S.
TI  - High-Order Relation Learning Transformer for Satellite Video Object Tracking
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5637415
DO  - 10.1109/TGRS.2024.3444820
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201602283&doi=10.1109%2fTGRS.2024.3444820&partnerID=40&md5=e2904c6137fed158a8637420aafff42c
AB  - Surrounding contexts are generally perceived as interfering with object tracking in satellite videos, leading to model drift. From another perspective, they can also be seen as reference objects of the tracked target, the dynamic interactions between them could provide essential information. In this article, a high-order relation learning transformer (HRLT) is proposed for satellite video object tracking, which not only models the high-order interactions of different target-context pairs but also reasons the associations between these high-order relations across multiple frames. First, a spatial high-order relation reasoning (SHR2) module is designed to model the high-order interactions between the target and scene contexts. Second, a temporal high-order relation reasoning (THR2) module is proposed to associate and reason these spatial high-order relations across multiple frames. Third, historical high-order relations are collected to provide more reasoning bases for the current frame prediction. Finally, qualitative and quantitative evaluations are performed on the SV248S, SkySat, and VISO datasets. The results show that HRLT outperforms 20 popular methods in different challenging scenarios.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Luo, J.
AU  - Li, Y.
AU  - Pan, Y.
AU  - Yao, T.
AU  - Feng, J.
AU  - Chao, H.
AU  - Mei, T.
TI  - Exploring Vision-Language Foundation Model for Novel Object Captioning
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
SP  - 1
EP  - 1
DO  - 10.1109/TCSVT.2024.3452437
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202703106&doi=10.1109%2fTCSVT.2024.3452437&partnerID=40&md5=76d1ccb4aa8096cf0e943ad18c6cd652
AB  - It is always well believed that pre-trained vision-language foundation models (e.g., CLIP) would substantially facilitate vision-language tasks. Nevertheless, there has been less evidence in support of the idea on describing novel objects in images. In this paper, we propose the Novel Object Transformer with CLIP (NOTC), a Transformer-based model that innovatively exploits the powerful vision-language representation ability of CLIP to enhance novel object captioning model&#x2019;s training and sentence decoding processes. Technically, given the primary bag-of-objects extracted by Faster R-CNN, NOTC first capitalize on an object distiller module to emphasize the most salient objects and infer the missing novel ones. The refined object words are additionally fed into the object-centric word predictor to generate sentence word-by-word. During training, we design a CLIP-based self-critical sequence training paradigm to select visually-grounded sampled sentence with higher CLIP score reward, which enables a joint training process of captioning model over out-domain training images with novel objects. Moreover, at inference, a new CLIP beam search algorithm is devised to enforce the existence of novel objects and encourage the partial word sequences with higher CLIP scores, thereby decoding both visually-grounded and comprehensive sentences. Extensive experiments are conducted on <italic>held-out</italic> COCO and nocaps datasets, and competitive performances are reported when compared to state-of-the-art approaches. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Yu, Y.
AU  - Takasu, A.
TI  - Controllable Syllable-Level Lyrics Generation From Melody With Prior Attention
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 11083
EP  - 11094
DO  - 10.1109/TMM.2024.3443664
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201630348&doi=10.1109%2fTMM.2024.3443664&partnerID=40&md5=80119aef0402df34334b06143a191ebf
AB  - Melody-to-lyrics generation, which is based on syllable-level generation, is an intriguing and challenging topic in the interdisciplinary field of music, multimedia, and machine learning. Many previous research projects generate word-level lyrics sequences due to the lack of alignments between syllables and musical notes. Moreover, controllable lyrics generation from melody is also less explored but important for facilitating humans to generate diverse desired lyrics. In this work, we propose a controllable melody-to-lyrics model that is able to generate syllable-level lyrics with user-desired rhythm. An explicit n-gram (EXPLING) loss is proposed to train the Transformer-based model to capture the sequence dependency and alignment relationship between melody and lyrics and predict the lyrics sequences at the syllable level. A prior attention mechanism is proposed to enhance the controllability and diversity of lyrics generation. Experiments and evaluation metrics verified that our proposed model has the ability to generate higher-quality lyrics than previous methods and the feasibility of interacting with users for controllable and diverse lyrics generation. We believe this work provides valuable insights into human-centered AI research in music generation tasks. The source codes for this work will be made publicly available for further reference and exploration.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, M.
AU  - Qiu, H.
AU  - Wang, L.
AU  - Cheng, H.
AU  - Zhao, T.
AU  - Li, H.
TI  - Oriented-DINO: Angle Decoupling Prediction and Consistency Optimizing for Oriented Detection Transformer
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5638315
DO  - 10.1109/TGRS.2024.3450200
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202769389&doi=10.1109%2fTGRS.2024.3450200&partnerID=40&md5=d991ab8e794a284a6017fc511d69ef84
AB  - Considering the arbitrary orientation of remote sensing objects, accurate angle prediction plays a crucial role in achieving precise oriented object detection (OOD) of aerial scenes. Existing transformer-based methods typically adopt an iterative refinement mechanism to update angle prediction and perform bipartite graph matching based on the combined matching costs. However, these methods may suffer from angle error accumulation across decoder layers and inconsistency between the L1 cost and the rotated intersection-of-union (IoU) cost, thus resulting in inaccurate angle prediction. To address these problems, this article proposes a novel transformer-based OOD method named Oriented-DINO (ODINO), which comprises three important components: error-mitigating angle decoupling prediction (EADP) module, nonlinear angle-conversion consistency optimizer (NACO), and query-driven diversity (QD) loss. To mitigate the angle error, the EADP module decouples angle prediction from the iterative box refinement process and uses independent branches to directly predict the angle. To address the issue of inconsistent matching, the NACO module uses a nonlinear function for angle conversion in matching cost calculation. This approach effectively alleviates the matching cost discrepancy in angle boundary case, while preserving the consistency in other instances. To avoid highly overlapped predictions triggered by similar queries, we introduce the QD loss to encourage the generation of diverse object queries, thus avoiding redundant predictions and enhancing prediction accuracy. Extensive experimental results demonstrate that our method achieves superior performance on OOD task.  © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Goncalves, L.
AU  - Leem, S.
AU  - Lin, W.
AU  - Sisman, B.
AU  - Busso, C.
TI  - Versatile Audio-Visual Learning for Emotion Recognition
PY  - 2024
T2  - IEEE Transactions on Affective Computing
SP  - 1
EP  - 14
DO  - 10.1109/TAFFC.2024.3433386
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199573555&doi=10.1109%2fTAFFC.2024.3433386&partnerID=40&md5=86053eca6d23d9791f2ad5d51068f82e
AB  - Most current audio-visual emotion recognition models lack the flexibility needed for deployment in practical applications. We envision a multimodal system that works even when only one modality is available and can be implemented interchangeably for either predicting emotional attributes or recognizing categorical emotions. Achieving such flexibility in a multimodal emotion recognition system is difficult due to the inherent challenges in accurately interpreting and integrating varied data sources. It is also a challenge to robustly handle missing or partial information while allowing direct switch between regression or classification tasks. This study proposes a versatile audio-visual learning (VAVL) framework for handling unimodal and multimodal systems for emotion regression or emotion classification tasks. We implement an audio-visual framework that can be trained even when audio and visual paired data is not available for part of the training set (i.e., audio only or only video is present). We achieve this effective representation learning with audio-visual shared layers, residual connections over shared layers, and a unimodal reconstruction task. Our experimental results reveal that our architecture significantly outperforms strong baselines on the CREMA-D, MSP-IMPROV, and CMU-MOSEI corpora. Notably, VAVL attains a new state-of-the-art performance in the emotional attribute prediction task on the MSP-IMPROV corpus. Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tran, T.V.T.
AU  - Hy, T.S.
TI  - Protein Design by Directed Evolution Guided by Large Language Models
PY  - 2024
T2  - IEEE Transactions on Evolutionary Computation
SP  - 1
EP  - 1
DO  - 10.1109/TEVC.2024.3439690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200825151&doi=10.1109%2fTEVC.2024.3439690&partnerID=40&md5=bdac6ac3c132fb7d3f5f62c01058878a
AB  - Directed evolution, a strategy for protein engineering, optimizes protein properties (i.e., fitness) by a rigorous and resource-intensive process of screening or selecting among a vast range of mutations. By conducting an in silico screening of sequence properties, machine learning-guided directed evolution (MLDE) can expedite the optimization process and alleviate the experimental workload. In this work, we propose a general MLDE framework in which we apply recent advancements of Deep Learning in protein representation learning and protein property prediction to accelerate the searching and optimization processes. In particular, we introduce an optimization pipeline that utilizes Large Language Models (LLMs) to pinpoint the mutation hotspots in the sequence and then suggest replacements to improve the overall fitness. Our experiments have shown the superior efficiency and efficacy of our proposed framework in the conditional protein generation, in comparision with other state-of-the-art baseline algorithms. We expect this work will shed a new light on not only protein engineering but also on solving combinatorial problems using data-driven methods. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; AJG:4; zdy:4; 
LB  - Tran2024Protein
ER  -

TY  - JOUR
AU  - Lin, J.
AU  - Shen, J.
AU  - Yang, X.
AU  - Fu, H.
AU  - Zhang, Q.
AU  - Li, P.
AU  - Sheng, B.
AU  - Wang, L.
AU  - Zhu, L.
TI  - Learning Motion-Guided Multi-Scale Memory Features for Video Shadow Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 12
SP  - 12288
EP  - 12300
DO  - 10.1109/TCSVT.2024.3424219
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199568259&doi=10.1109%2fTCSVT.2024.3424219&partnerID=40&md5=13b309186345da3722354b614f5a5e60
AB  - Natural images often contain multiple shadow regions, and existing video shadow detection methods tend to fail in fully identifying all shadow regions, since they mainly learned temporal features at single-scale and single memory. In this work, we develop a novel convolutional neural network (CNN) to learn motion-guided multi-scale memory features to obtain multi-scale temporal information based on multiple network memories for boosting video shadow detection. To do so, our network first constructs three memories (i.e., a global memory, a local memory, and a motion memory) to combine spatial context and object motion for detecting shadows. Based on these three memories, we then devise a multi-scale motion-guided long-short transformer (MMLT) module to learn multi-scale temporal and motion memory features for predicting a shadow detection map of the input video frame. Our MMLT module includes a dense-scale long transformer (DLT), a dense-scale short transformer (DST), and a dense-scale motion transformer (DMT) to read three memories for learning multi-scale transformer features. Our DLT, DST, and DMT consist of a set of memory-read pooling attention (MPA) blocks and densely connect these output features of multiple MPA blocks to learn multi-scale transformer features since the scales of these output features are varied. By doing so, we can more accurately identify multiple shadow regions with different sizes from the input video. Moreover, we devise a self-supervised pretext task to pre-training the feature encoder for enhancing the downstream video shadow detection. Experimental results on three benchmark datasets show that our video shadow detection network quantitatively and qualitatively outperforms 26 state-of-the-art methods. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, D.
AU  - Li, M.
AU  - Qu, L.
AU  - Yang, K.
AU  - Zhai, P.
AU  - Wang, S.
AU  - Zhang, L.
TI  - Asynchronous Multimodal Video Sequence Fusion via Learning Modality-Exclusive and -Agnostic Representations
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 12
SP  - 12360
EP  - 12375
DO  - 10.1109/TCSVT.2024.3435561
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200213628&doi=10.1109%2fTCSVT.2024.3435561&partnerID=40&md5=88b184cb4a878b7a95480c4ee1d84db9
AB  - Understanding human intentions (e.g., emotions) from videos has received considerable attention recently. Video streams generally constitute a blend of temporal data stemming from distinct modalities, including natural language, facial expressions, and auditory clues. Despite the impressive advancements of previous works via attention-based paradigms, the inherent temporal asynchrony and modality heterogeneity challenges remain in multimodal sequence fusion, causing adverse performance bottlenecks. To tackle these issues, we propose a Multimodal fusion approach for learning modality-Exclusive and modality-Agnostic representations (MEA) to refine multimodal features and leverage the complementarity across distinct modalities. On the one hand, MEA introduces a predictive self-attention module to capture reliable context dynamics within modalities and reinforce unique features over the modality-exclusive spaces. On the other hand, a hierarchical cross-modal attention module is designed to explore valuable element correlations among modalities over the modality-agnostic space. Meanwhile, a double-discriminator strategy is presented to ensure the production of distinct representations in an adversarial manner. Eventually, we propose a decoupled graph fusion mechanism to enhance knowledge exchange across heterogeneous modalities and learn robust multimodal representations for downstream tasks. Numerous experiments are implemented on three multimodal datasets with asynchronous sequences. Systematic analyses show the necessity of our approach. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qiu, L.
AU  - Xie, F.
AU  - Liu, C.
AU  - Wang, K.
AU  - Song, X.
AU  - Shi, Z.
TI  - Remote Sensing Image Rectangling with Iterative Warping Kernel Self-Correction Transformer
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4707117
DO  - 10.1109/TGRS.2024.3441246
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200822690&doi=10.1109%2fTGRS.2024.3441246&partnerID=40&md5=f20a3a168d1fdd10ddb9f3eb86f6444a
AB  - Stitched remote sensing images often exhibit irregular boundaries, which can be frustrating for general users and detrimental to downstream tasks such as object detection and segmentation. However, this issue has received insufficient attention and remains unexplored within the remote sensing domain. In this study, we investigate mesh-based rectangling techniques for remote sensing images, aiming to produce rectangular outputs while preserving the original field-of-view (FoV) and avoiding the introduction of unreliable content. Observing that prior rectangling algorithms tend to generate unsatisfactory boundaries or discernible distortions, that is, under-rectangling or over-rectangling, we propose the concept of a warping kernel associated with mesh deformations to account for these phenomena. Consequently, we introduce the iterative warping kernel self-correction transformer (IWKFormer), designed to enhance warping kernel estimation and generate superior rectangular outcomes. It primarily comprises two components: a mesh feature extractor built upon the partial swin transformer block (PSTB) and a corrector module using the swin transformer block (STB). These modules collaborate to derive warping kernels implicitly. The extractor extracts latent features pertinent to mesh deformation, whereas the corrector iteratively refines the warping kernel estimation to improve the ultimate prediction. Furthermore, to bolster further research, we have constructed an aerial imagery stitching rectangling dataset (AIRD), featuring a wide array of stitching scenes. Extensive experimentation on the AIRD demonstrates that our method yields visually appealing and naturally rectangled images, achieving state-of-the-art performance. The code and data will be available at https://github.com/yyywxk/IWKFormer.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, G.
AU  - Tang, Y.
AU  - Zhang, C.
AU  - Zheng, X.
AU  - Zhao, Y.
TI  - Entity Dependency Learning Network with Relation Prediction for Video Visual Relation Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 12
SP  - 12425
EP  - 12436
DO  - 10.1109/TCSVT.2024.3437437
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200273885&doi=10.1109%2fTCSVT.2024.3437437&partnerID=40&md5=dd5c078ec711322fa03cbfec0749328f
AB  - Video Visual Relation Detection (VidVRD) is a pivotal task in the field of video analysis. It involves detecting object trajectories in videos, predicting potential dynamic relation between these trajectories, and ultimately representing these relationships in the form of <subject, predicate, object> triplets. Correct prediction of relation is vital for VidVRD. Existing methods mostly adopt the simple fusion of visual and language features of entity trajectories as the feature representation for relation predicates. However, these methods do not take into account the dependency information between the relation predication and the subject and object within the triplet. To address this issue, we propose the entity dependency learning network(EDLN), which can capture the dependency information between relation predicates and subjects, objects, and subject-object pairs. It adaptively integrates these dependency information into the feature representation of relation predicates. Additionally, to effectively model the features of the relation existing between various object entities pairs, in the context encoding phase for relation predicate features, we introduce a fully convolutional encoding approach as a substitute for the self-attention mechanism in the Transformer. Extensive experiments on two public datasets demonstrate the effectiveness of the proposed EDLN.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Zhang, Y.
AU  - Zhang, J.
AU  - Qian, X.
AU  - Gong, C.
AU  - Sun, K.
AU  - Ding, Z.
AU  - Wang, X.
AU  - Li, Z.
AU  - Liu, Z.
AU  - Shen, D.
TI  - Prototype Learning Guided Hybrid Network for Breast Tumor Segmentation in DCE-MRI
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
SP  - 1
EP  - 1
DO  - 10.1109/TMI.2024.3435450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200204508&doi=10.1109%2fTMI.2024.3435450&partnerID=40&md5=3d878ef9a0f2a7e91b54c986e5abf528
AB  - Automated breast tumor segmentation on the basis of dynamic contrast-enhancement magnetic resonance imaging (DCE-MRI) has shown great promise in clinical practice, particularly for identifying the presence of breast disease. However, accurate segmentation of breast tumor is a challenging task, often necessitating the development of complex networks. To strike an optimal tradeoff between computational costs and segmentation performance, we propose a hybrid network via the combination of convolution neural network (CNN) and transformer layers. Specifically, the hybrid network consists of a encoder-decoder architecture by stacking convolution and deconvolution layers. Effective 3D transformer layers are then implemented after the encoder subnetworks, to capture global dependencies between the bottleneck features. To improve the efficiency of hybrid network, two parallel encoder sub-networks are designed for the decoder and the transformer layers, respectively. To further enhance the discriminative capability of hybrid network, a prototype learning guided prediction module is proposed, where the category-specified prototypical features are calculated through online clustering. All learned prototypical features are finally combined with the features from decoder for tumor mask prediction. The experimental results on private and public DCE-MRI datasets demonstrate that the proposed hybrid network achieves superior performance than the state-of-the-art (SOTA) methods, while maintaining balance between segmentation accuracy and computation cost. Moreover, we demonstrate that automatically generated tumor masks can be effectively applied to identify HER2-positive subtype from HER2-negative subtype with the similar accuracy to the analysis based on manual tumor segmentation. The source code is available at https://github.com/ZhouL-lab/ PLHN. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shi, S.
AU  - Li, B.
AU  - Zhang, L.
AU  - Kuang, K.
AU  - Wu, S.
AU  - Feng, T.
AU  - Yan, Y.
AU  - Du, Z.
TI  - Causality-Guided Stepwise Intervention and Reweighting for Remote Sensing Image Semantic Segmentation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5633517
DO  - 10.1109/TGRS.2024.3432397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199405392&doi=10.1109%2fTGRS.2024.3432397&partnerID=40&md5=7772adb55c46010532bf6bf6f68148cf
AB  - Semantic segmentation is one of the most significant tasks in remote sensing (RS) image interpretation, which focuses on learning global and local information to infer the semantic label of each pixel. Previous studies devise encoder-decoder structured deep learning (DL) models to extract global and local features from RS images with the help of pretraining knowledge to predict semantic labels. However, due to the common heterogeneity between the data for pretraining and the data to be semantically segmented, these models fail to learn general features appropriate to RS datasets. In this article, we propose a novel formulation of the above problem from a causal perspective, where the learned features from pretrained models result from causality and spurious correlations, and only the former carries general information that remains invariant regardless of the exact task and dataset. Based on the above formulation, we propose stepwise intervention and reweighting (SIR). It can reduce the confounding bias introduced by the pretraining knowledge and improve the model's ability to learn general features, making semantic segmentation of RS images benefit more from pretraining. Besides, we conduct a detailed theoretical analysis of our methods and conduct extensive experiments on two widely used public RS datasets. Experimental results demonstrate that applying SIR to encoder-decoder semantic segmentation models achieves performance improvements, proving the effectiveness and application values of the proposed method.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qiao, X.
AU  - Huang, W.
TI  - WaveTransNet: A Transformer-Based Network for Global Significant Wave Height Retrieval From Spaceborne GNSS-R Data
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4208011
DO  - 10.1109/TGRS.2024.3433397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199513550&doi=10.1109%2fTGRS.2024.3433397&partnerID=40&md5=14119b105790151869b2ccffb8929b82
AB  - Global Navigation Satellite System Reflectometry (GNSS-R) is a novel remote sensing technique for global significant wave heights (SWHs) observation. Previous studies have illustrated the efficacy of deep learning methods in SWH retrieval from GNSS-R data. However, most of these methods rely on convolutional layers to extract features from delay Doppler maps (DDMs), facing the limitations imposed by the fixed receptive field. To address this issue, in this study, a transformer-based network called WaveTransNet is proposed for SWH retrieval from GNSS-R data. Specifically, the transformer encoder block is exploited to capture long-range dependencies from DDMs. In addition, an attention mechanism-aided ancillary parameters feature extraction branch is devised to extract discriminative features from ancillary parameters, including geometry-related and map-related parameters. The developed model is evaluated on the Cyclone Global Navigation Satellite System (CYGNSS) dataset, and the experimental results demonstrate its improved performance. Compared with the European Center for Medium-Range Weather Forecasts (ECMWF) reanalysis data, it achieves a root mean square difference (RMSD) of 0.443 and 0.444 m when National Data Buoy Center (NDBC) buoy data are used for evaluation. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tian, T.
AU  - Raj, A.
AU  - Missi Xavier, B.
AU  - Zhang, Y.
AU  - Wu, F.-Y.
AU  - Yang, K.
TI  - A Multi-Task Learning Framework for Underwater Acoustic Channel Prediction: Performance Analysis on Real-World Data
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 11
SP  - 15930
EP  - 15944
DO  - 10.1109/TWC.2024.3435018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200810443&doi=10.1109%2fTWC.2024.3435018&partnerID=40&md5=e8d652f51fbe29f83d8d5386d054269e
AB  - In the rapidly advancing field of Underwater Acoustic Communication (UAC), channel prediction remains a major challenge, exacerbated by the complicated nature of ocean environments. This paper introduces an innovative Multi- Task Learning (MTL) framework for time-varying Underwater Acoustic (UWA) channel prediction. By decomposing the highdimensional Channel Impulse Response (CIR) prediction into interconnected tasks, the proposed framework leverages a Shared Feature Learning (SFL) layer, capturing intricate dependencies underlying UWA channels. To validate its efficacy, we conducted thorough evaluations, leveraging real-world data from two distinct at-sea experiments conducted in Wuyuan Bay, China. A comprehensive comparative study of various configurations for the SFL layer, ranging from commonly used Recurrent Neural Network (RNN)-based models to the more advanced transformer structure, further underscores the flexibility and broad applicability of our MTL framework for handling various challenging UWA environments. © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Q.
AU  - He, F.
AU  - Wang, G.
AU  - Bai, X.
AU  - Cheng, L.
AU  - Ning, X.
TI  - Dual Guidance Enabled Fuzzy Inference for Enhanced Fine-Grained Recognition
PY  - 2024
T2  - IEEE Transactions on Fuzzy Systems
SP  - 1
EP  - 14
DO  - 10.1109/TFUZZ.2024.3427654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199030871&doi=10.1109%2fTFUZZ.2024.3427654&partnerID=40&md5=202094ea2dd5d91713b5aa799ed3097c
AB  - In the field of Fine-Grained Visual Recognition (FGVR), the ability to resolve minute and often subtle differences between highly similar object categories is paramount. The advent of Vision Transformers (ViTs) has marked a significant advancement in this domain, primarily due to their capacity to model the intricate interdependencies among object parts represented as image patches. However, their inherent singlescale processing limitation hampers their effectiveness in FGVR tasks. Furthermore, the challenge of uncertainty inherent in FGVR tasks remains unresolved, necessitating the development of methods that bolster the robustness of these models, particularly across varying scales of visual features. We introduce a new plugin module that can be seamlessly integrated into ViT, called Dual Guidance Enabled Fuzzy Inference (DGEFI), which combines fuzzy inference with dual guidance mechanisms. Dual guidance includes scale-aware guidance and probability guidance. The former strengthens the model&#x0027;s focus on salient scales, and the latter refines the distinction between similar categories by optimizing intra-class compactness and inter-class separability. Fuzzy inference enables the model to adaptively tweak the influence of distinct scales in the final decision-making phase, thereby enhancing the overall accuracy of recognition tasks. We demonstrate the versatility and efficacy of our DGEFI module by integrating it into several leading ViT backbones, including ViT, Swin, Mvitv2, and EVA-02. Empirical results exhibit exceptional performance gains, with the integration of DGEFI into EVA- 02 remarkable accuracy improvements, reaching 93.6&#x0025; on the CUB-200-2011 dataset and 94.5 respectively improving over the state-of-the-art method 0.5&#x0025; and 1.5&#x0025;. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bai, L.
AU  - Wang, H.
AU  - Zhang, X.
AU  - Qin, W.
AU  - Liu, B.
AU  - Du, S.
TI  - AP-Semi: Improving the Semi-Supervised Semantic Segmentation for VHR Images Through Adaptive Data Augmentation and Prototypical Sample Guidance
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5631813
DO  - 10.1109/TGRS.2024.3423010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198343474&doi=10.1109%2fTGRS.2024.3423010&partnerID=40&md5=2de7bcf3387f53c150958576a28c69b8
AB  - — As a method that can incorporate unlabeled data into model training, semi-supervised semantic segmentation (SSS) can mitigate the burden of manual annotation in geographic mapping tasks with very-high-resolution (VHR) images. Various SSS approaches have been proposed for VHR images, but most of them either rely on complex models or additional training procedures, increasing the computation cost. In this study, we propose a simple-yet-effective SSS approach named AP-semi for VHR images, which neither increases the number of learnable parameters nor introduces additional training steps. First, since data augmentation can influence the training data and process significantly, we refine the traditional CutMix transformation, an important data augmentation strategy, by generating adaptively sized cut boxes, optimizing the intensity of perturbation and making it better suited for the training phase. Second, in order to make all the unlabeled samples contribute to the model training, we design a prototype-based feature-level consistency loss, which can enforce the consistency of model predictions in the feature space. By combining the adaptive data augmentation strategy and prototype-based loss, AP-semi can achieve impressive results with a limited number of labeled samples, surpassing several baseline models in extensive experiments. Through experiments, we find that AP-semi can adapt to both convolutional neural networks (CNNs)- and transformer-based segmentation models. In the simulation experiment mimicking the routine operations in geographic mapping tasks, AP-semi demonstrates significant time-saving benefits. © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Duan, S.
AU  - Leng, Y.
AU  - Song, R.
AU  - Li, Y.
AU  - Du, Q.
TI  - Residual Mask in Cascaded Convolutional Transformer for Spectral Reconstruction
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5523615
DO  - 10.1109/TGRS.2024.3427633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198706127&doi=10.1109%2fTGRS.2024.3427633&partnerID=40&md5=cf90c2880fb8bb3a2b868e2245f8a648
AB  - A significant challenge of spectral reconstruction (SR) task is the lower performance reconstructed in foreground regions compared to background regions, which can be attributed to the marked difference in diversity of objects and disparity of adjacent scene characteristics. Moreover, the reconstruction of edge regions is often fraught with substantial errors due to the transitional nature of these regions, an issue conventional single convolutional neural networks (CNNs) and transformers struggle to handle. To address these challenges, we introduce the residual mask in cascaded convolutional transformer (RC2T) to iteratively improve the reconstruction of hyperspectral images (HSIs). Specifically, we propose a residual-predict mask generator (RMG) to generate a residual mask that retains band properties to separate feature with different complexities. Meanwhile, to achieve band expansion of mask features within the autoencoder, we approximate it to a Markov process and exploit the multistage spectral-aware Markov transfer (MMT) for its lightweight implementation. Next, we introduce the parallel convolutional multihead self-attention module (PSM), in which CNN runs parallel to the transformer to handle simple and complex features separately. Additionally, the residual mask loss function uses the established relationship between complexity of feature and reconstruction accuracy to generate residual mask in a self-supervised manner for providing complex high-frequency prior. We have validated our approach using three published datasets (NTIRE 2020 'Clean' track, NTIRE 2022, and CAVE). Additionally, we also conducted experiments with the proposed method on remote sensing dataset grss_dfc_2018 and a satellite-borne remote sensing dataset, achieving optimal performance. The experimental results demonstrate that our RC2T method is state-of-the-art (SOTA) in the field of SR.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, Y.
AU  - Zhao, X.
AU  - Li, C.
AU  - Tang, J.
AU  - Huang, Z.
TI  - Long-Term Motion-Assisted Remote Sensing Object Tracking
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5407514
SP  - 1
EP  - 14
DO  - 10.1109/TGRS.2024.3429497
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198749379&doi=10.1109%2fTGRS.2024.3429497&partnerID=40&md5=74b782fc241f50fa2e23330978e154a3
AB  - Remote sensing object tracking has gained significant attention due to its wide range of applications including surveillance and motion analysis. However, it faces various challenges such as low resolution, low contrast, blurring, and occlusion, which impede its development at a significantly slower pace compared to object tracking methods for general scenes. The challenges of low resolution, low contrast, and blurring result in weak target features, while the occlusion challenge poses a problem for target search range and tracker discrimination in subsequent frames. To address these issues, we propose a novel long-term motion-assisted framework, which can effectively mine long-term motion information and use an evaluation scheme for robust remote sensing object tracking. Specifically, we design a long-term motion feature mining module (LMFM), which efficiently calculates the long-term motion information by integrating previous motion features in a temporal-iterative manner to alleviate the problem of weak features caused by low resolution, low contrast, and blurring. Moreover, we design an evaluation scheme that combines the motion trajectory model, target classification scores, and predicted target positions to handle the issue of massive occlusion or target loss. Extensive experiments on the SatSOT, SV248S, and VISO datasets show that our approach outperforms state-of-the-art (SOTA) trackers. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, S.
AU  - Chen, H.
AU  - Zhang, X.
AU  - Xiao, P.
AU  - Bai, L.
AU  - Ouyang, W.
TI  - RS-Mamba for Large Remote Sensing Image Dense Prediction
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5633314
DO  - 10.1109/TGRS.2024.3425540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198302240&doi=10.1109%2fTGRS.2024.3425540&partnerID=40&md5=3832441726f8cc59fb4a1e6a5e38ca1f
AB  - Context modeling is critical for remote sensing image dense prediction tasks. Nowadays, the growing size of very-high-resolution (VHR) remote sensing images poses challenges in effectively modeling context. While transformer-based models possess global modeling capabilities, they encounter computational challenges when applied to large VHR images due to their quadratic complexity. The conventional practice of cropping large images into smaller patches results in a notable loss of contextual information. To address these issues, we propose the remote sensing Mamba (RSM) for dense prediction tasks in large VHR remote sensing images. RSM is specifically designed to capture the global context of remote sensing images with linear complexity, facilitating the effective processing of large VHR images. Considering that the land covers in remote sensing images are distributed in arbitrary spatial directions due to characteristics of remote sensing over-head imaging, the RSM incorporates an omnidirectional selective scan module (OSSM) to globally model the context of images in multiple directions, capturing large spatial features from various directions. We designed simple yet effective models based on RSM, achieving state-of-the-art performance on dense prediction tasks in VHR remote sensing images without fancy training strategies. Extensive experiments on semantic segmentation (SS) and change detection (CD) tasks across various land covers demonstrate the effectiveness of the proposed RSM. Leveraging the linear complexity and global modeling capabilities, RSM achieves better efficiency and accuracy than transformer-based models on large remote sensing images. Interestingly, we also demonstrated that our model generally performs better with a larger image size on dense prediction tasks. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Liu, C.
TI  - Real-Time Pavement Damage Detection With Damage Shape Adaptation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 18954
EP  - 18963
DO  - 10.1109/TITS.2024.3416508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197590813&doi=10.1109%2fTITS.2024.3416508&partnerID=40&md5=71d8296607b63b305cd340da03347e06
AB  - Intelligent detection of pavement damage is crucial to road maintenance. Timely identification of cracks and potholes helps prolong the road service life. Current detection models fail to balance accuracy and speed. In this study, we propose a fast damage detection algorithm named FPDDN to achieve real-time and high-accuracy pavement damage detection. FPDDN integrates the deformable transformer, D2f block, and SFB module to predict pavement damage of different sizes in multiple branches. The deformable transformer allows the FPDDN to exhibit adaptability to geometric variations in road defects, thereby improving the detection accuracy of irregular defects such as cracks. D2f block is mainly used to lightweight the network and increase the inference speed. The SFB module can significantly decrease the loss of information during downsampling of small-sized objects. This integration enhances the model's ability to extract global damage features, reduces the loss of information on small-scale defects, and improves the synergy between deep and shallow feature layers. The model's performance was evaluated using the RDD2022 dataset, focusing on inference speed and detection accuracy. When compared to state-of-the-art models such as YOLO v8, FPDDN has a parameter count that is only one-fifth of that of YOLO v8x, yet it surpasses YOLO v8x in detection accuracy. The FPDDN achieved an F1 score of 0.601 and a mAP50 of 0.610 on the RDD2022 dataset, outperforming the compared models. Additionally, the algorithm achieved a balance between accuracy and speed with an inference speed of 1.8ms for pavement damage detection.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2024Real-Time
ER  -

TY  - JOUR
AU  - Yu, W.
AU  - Zhang, X.
AU  - Das, S.
AU  - Xiang Zhu, X.
AU  - Ghamisi, P.
TI  - MaskCD: A Remote Sensing Change Detection Network Based on Mask Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5631316
DO  - 10.1109/TGRS.2024.3424300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197482535&doi=10.1109%2fTGRS.2024.3424300&partnerID=40&md5=22416aadb9718c7c7925f0d4d101955c
AB  - Change detection (CD) from remote sensing (RS) images using deep learning has been widely investigated in the literature. It is typically regarded as a pixelwise labeling task that aims to classify each pixel as changed or unchanged. Although per-pixel classification networks in encoder-decoder structures have shown dominance, they still suffer from imprecise boundaries and incomplete object delineation at various scenes. For high-resolution RS images, partly or totally changed objects are more worthy of attention rather than a single pixel. Therefore, we revisit the CD task from the mask prediction and classification perspective and propose mask classification-based CD (MaskCD) to detect changed areas by adaptively generating categorized masks from input image pairs. Specifically, it utilizes a cross-level change representation perceiver (CLCRP) to learn multiscale change-aware representations and capture spatiotemporal relations from encoded features by exploiting deformable multihead self-attention (DeformMHSA). Subsequently, a masked cross-attention-based detection transformers (MCA-DETRs) decoder is developed to accurately locate and identify changed objects based on masked cross-attention and self-attention (SA) mechanisms. It reconstructs the desired changed objects by decoding the pixelwise representations into learnable mask proposals and making final predictions from these candidates. Experimental results on five benchmark datasets demonstrate the proposed approach outperforms other state-of-the-art models. Codes and pretrained models are available online at: https://github.com/EricYu97/MaskCD.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gu, W.
AU  - Xiao, H.
AU  - Zhao, X.
AU  - Kang, W.
TI  - EA-MVSNet: Learning Error-Awareness for Enhanced Multi-View Stereo
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 12
SP  - 12127
EP  - 12141
DO  - 10.1109/TCSVT.2024.3430115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199060342&doi=10.1109%2fTCSVT.2024.3430115&partnerID=40&md5=597ec47fa649c632affa9344708b6e76
AB  - Multi-view stereo (MVS) aims to reconstruct the dense 3D geometry of a scene by processing and relating images captured from different viewpoints. Despite impressive successes, most existing techniques simply supervise cost volumes or depth maps through conventional classification or regression methods, thereby inadequately exploring the depth representation's full potential. Moreover, reconstructing areas with occlusions or weak textures continues to be a long-standing challenge within MVS. Another critical issue, frequently neglected, is the potential inaccuracy of ground truth depths, as evidenced in datasets like DTU. To address these problems, we introduce EA-MVSNet, an innovative error-aware MVS framework designed to enhance depth prediction. The key contributions of this work include three parts: (1) We present a novel error-aware depth representation that enhances depth prediction accuracy through error-aware learning, thereby improving reconstruction quality. (2) We develop a Deformable Feature Pyramid Network (DFPN), meticulously designed to augment reconstruction details in occluded and texture-deficient areas. (3) We introduce a cross-view consistency guidance module into the learning process, effectively mitigating the detrimental effects of ground truth depth inaccuracies and fostering faster convergence. Comprehensive experiments on the DTU dataset and Tanks and Temples dataset validate the superiority of our EA-MVSNet. Compared to the preceding UniMVSNet, EA-MVSNet achieves a notable 7.6% decrease in overall reconstruction error on the DTU dataset, and boosts the mean F-score by 3.0% and 4.1% in the intermediate and advanced groups of the Tanks and Temples dataset, respectively, surpassing most recent state-of-the-art methods.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mineo, R.
AU  - Salanitri, F.P.
AU  - Bellitto, G.
AU  - Kavasidis, I.
AU  - Filippo, O.D.
AU  - Millesimo, M.
AU  - Ferrari, G.M.D.
AU  - Aldinucci, M.
AU  - Giordano, D.
AU  - Palazzo, S.
AU  - D'Ascenzo, F.
AU  - Spampinato, C.
TI  - A Convolutional-Transformer Model for FFR and iFR Assessment from Coronary Angiography
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 8
SP  - 2866
EP  - 2877
DO  - 10.1109/TMI.2024.3383283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197514990&doi=10.1109%2fTMI.2024.3383283&partnerID=40&md5=d705a56c236c3ccd37a233232ca928b2
AB  - The quantification of stenosis severity from X-ray catheter angiography is a challenging task. Indeed, this requires to fully understand the lesion's geometry by analyzing dynamics of the contrast material, only relying on visual observation by clinicians. To support decision making for cardiac intervention, we propose a hybrid CNN-Transformer model for the assessment of angiography-based non-invasive fractional flow-reserve (FFR) and instantaneous wave-free ratio (iFR) of intermediate coronary stenosis. Our approach predicts whether a coronary artery stenosis is hemodynamically significant and provides direct FFR and iFR estimates. This is achieved through a combination of regression and classification branches that forces the model to focus on the cut-off region of FFR (around 0.8 FFR value), which is highly critical for decision-making. We also propose a spatio-temporal factorization mechanisms that redesigns the transformer's self-attention mechanism to capture both local spatial and temporal interactions between vessel geometry, blood flow dynamics, and lesion morphology. The proposed method achieves state-of-the-art performance on a dataset of 778 exams from 389 patients. Unlike existing methods, our approach employs a single angiography view and does not require knowledge of the key frame; supervision at training time is provided by a classification loss (based on a threshold of the FFR/iFR values) and a regression loss for direct estimation. Finally, the analysis of model interpretability and calibration shows that, in spite of the complexity of angiographic imaging data, our method can robustly identify the location of the stenosis and correlate prediction uncertainty to the provided output scores.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, Q.
AU  - Zhang, Y.
AU  - Yang, Z.
AU  - Shikh-Bahaei, M.R.
TI  - Deep Learning for Secure UAV Swarm Communication Under Malicious Attacks
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 10
SP  - 14879
EP  - 14894
DO  - 10.1109/TWC.2024.3419923
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197494826&doi=10.1109%2fTWC.2024.3419923&partnerID=40&md5=76ebce5ca0a0a586ac5fd0450679af42
AB  - Unmanned aerial vehicle (UAV) swarms have become a promising solution to enhance modern wireless communication in complicated environments. However, due to the existence of real-world malicious attacks, the performance of prediction and optimisation methods used for UAV swarms are easily degraded. In this paper, we propose a novel deep learning-based user mobility prediction, user assignment and drone position optimisation scheme for a UAV swarm-enabled wireless communication system in the presence of malicious Global Navigation Satellite System (GNSS) spoofing attackers. Specifically, a robust deep learning-based user mobility prediction model, namely denoising autoencoder recurrent transformer (DART), is designed. Additionally, two efficient user assignment and drone position optimisation methods are proposed. The proposed deep learning model forecasts user locations, on which we construct and solve assignment and position optimisation problems. Simulation results show that the proposed deep learning-based prediction-optimisation scheme can provide up to 30% higher overall sum rate compared with the adversarially trained long short-term memory (LSTM) baseline and almost double the overall sum rate compared with the vanilla LSTM baseline. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, J.
AU  - Sun, H.
AU  - Han, J.
AU  - Song, B.
AU  - Chi, Y.
AU  - Song, B.
TI  - Multitask Fine-Grained Feature Mining for Multilabel Remote Sensing Image Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5632717
DO  - 10.1109/TGRS.2024.3426473
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198401489&doi=10.1109%2fTGRS.2024.3426473&partnerID=40&md5=515ff8102ba19bcfe31a75c477af2b0a
AB  - Multilabel remote sensing image classification can provide comprehensive object-level semantic descriptions of remote sensing images. However, most existing methods cannot fully mine the fine-grained features of images and labels, resulting in low classification accuracy. To address this issue, we propose a novel multitask framework for multilabel remote sensing image classification. The framework establishes the class-specific feature extraction as a binary classification auxiliary task to assist the main multilabel classification task, which can improve the model's local and global feature extraction ability. Meanwhile, the framework updates the label correlation graph using the graph transformer layer to accurately identify label node pairs with potential correlation, which effectively mines the correlation of multiple labels to generate more accurate label co-occurrence embedding for image label prediction. Experimental results on UCM, AID, and DFC15 multilabel datasets show that the proposed method outperforms existing state-of-the-art methods.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, N.
AU  - Zhang, T.
AU  - Tian, H.
AU  - Liu, A.-A.
TI  - Rule-Driven News Captioning
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 11
SP  - 11657
EP  - 11667
DO  - 10.1109/TCSVT.2024.3426655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198365086&doi=10.1109%2fTCSVT.2024.3426655&partnerID=40&md5=1db386ec07f2c2409aad06c5fc56cbc2
AB  - News captioning task aims to generate sentences by describing named entities or concrete events for an image with its news article. Existing methods have achieved remarkable results by relying on the large-scale pre-trained models, which primarily focus on the correlations between the input news content and the output predictions. However, the news captioning requires adhering to some fundamental rules of news reporting, such as accurately describing the individuals and actions associated with the event. In this paper, we propose the rule-driven news captioning method, which can generate image descriptions following designated rule signal. Specifically, we first design the news-aware semantic rule for the descriptions. This rule incorporates the primary action depicted in the image (e.g., "performing") and the roles played by named entities involved in the action (e.g., "Agent"and "Place"). Second, we inject this semantic rule into the large-scale pre-trained model, BART, with the prefix-tuning strategy, where multiple encoder layers are embedded with news-aware semantic rule. Finally, we can effectively guide BART to generate news sentences that comply with the designated rule. Extensive experiments on two widely used datasets (i.e., GoodNews and NYTimes800k) demonstrate the effectiveness of our method. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Shao, M.
AU  - Wan, Y.
AU  - Meng, L.
AU  - Cao, X.
AU  - Wang, S.
TI  - Boundary-Aware Spatial and Frequency Dual-Domain Transformer for Remote Sensing Urban Images Segmentation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5637718
DO  - 10.1109/TGRS.2024.3430081
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198754369&doi=10.1109%2fTGRS.2024.3430081&partnerID=40&md5=257d0acda1f22f5989a7d98c68003245
AB  - Semantic segmentation of remote sensing (RS) images refers to labeling each pixel with a class to identify objects or land cover types. Existing mainstream spatial-domain semantic segmentation methods are mainly categorized into convolutional neural network (CNN)-based and vision transformer (ViT)-based approaches. The former excels at capturing local features, while the latter is adept at extracting global features. Several recent approaches consider combining CNN and ViT to efficiently capture local and global features. However, these approaches still struggle to capture complete features of the RS images, resulting in inaccurate segmentation. To address this issue, we introduce the fast Fourier transform (FFT), which transforms images into the frequency domain for feature extraction, acquiring the image-size receptive field that can complement spatial-domain methods. Based on this, we propose a boundary-aware spatial and frequency dual-domain transformer, termed dual-domain transformer. Specifically, our dual-domain transformer incorporates a dual-domain mixer (DualM), where the spatial-domain branch combines depthwise convolution and the attention mechanism to extract local and global features effectively, while the frequency-domain branch uses FFT to extract image-size features. The two branches complement each other, enabling a more comprehensive feature extraction of RS images. Meanwhile, a boundary-guided training strategy utilizing a boundary-aware module (BAM) is devised to constrain the model extract and predict boundary detail texture, which is an auxiliary task. In addition, the decoder incorporates a scale-feature fusion module (SFM) for adaptive information fusion between the encoder and decoder. Comprehensive experiments on the Zeebrugge and ISPRS datasets, including Vaihingen and Potsdam, showcase that the dual-domain transformer significantly outperforms state-of-the-art (SOTA) methods.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wen, C.
AU  - Ye, M.
AU  - Li, H.
AU  - Chen, T.
AU  - Xiao, X.
TI  - Concept-based Lesion Aware Transformer for Interpretable Retinal Disease Diagnosis
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
SP  - 1
EP  - 1
DO  - 10.1109/TMI.2024.3429148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198757514&doi=10.1109%2fTMI.2024.3429148&partnerID=40&md5=63f512226f3a0853b71bed1c3c337d2b
AB  - Existing deep learning methods have achieved remarkable results in diagnosing retinal diseases, showcasing the potential of advanced AI in ophthalmology. However, the black-box nature of these methods obscures the decision-making process, compromising their trustworthiness and acceptability. Inspired by the concept-based approaches and recognizing the intrinsic correlation between retinal lesions and diseases, we regard retinal lesions as concepts and propose an inherently interpretable framework designed to enhance both the performance and explainability of diagnostic models. Leveraging the transformer architecture, known for its proficiency in capturing long-range dependencies, our model can effectively identify lesion features. By integrating with image-level annotations, it achieves the alignment of lesion concepts with human cognition under the guidance of a retinal foundation model. Furthermore, to attain interpretability without losing lesion-specific information, our method employs a classifier built on a cross-attention mechanism for disease diagnosis and explanation, where explanations are grounded in the contributions of human-understandable lesion concepts and their visual localization. Notably, due to the structure and inherent interpretability of our model, clinicians can implement concept-level interventions to correct the diagnostic errors by simply adjusting erroneous lesion predictions. Experiments conducted on four fundus image datasets demonstrate that our method achieves favorable performance against state-of-the-art methods while providing faithful explanations and enabling conceptlevel interventions. Our code is publicly available at https://github.com/Sorades/CLAT. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tong, H.
AU  - Kong, L.
AU  - Liu, J.
AU  - Gao, S.
AU  - Xu, Y.
AU  - Chen, Y.
TI  - Segmented Frequency-Domain Correlation Prediction Model for Long-Term Time Series Forecasting Using Transformer
PY  - 2024
T2  - IET Software
VL  - 2024
IS  - 1
C7  - 2920167
DO  - 10.1049/2024/2920167
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197695875&doi=10.1049%2f2024%2f2920167&partnerID=40&md5=dc0cc681a2b91d376cd3a084c0799532
AB  - Long-term time series forecasting has received significant attention from researchers in recent years. Transformer model-based approaches have emerged as promising solutions in this domain. Nevertheless, most existing methods rely on point-by-point self-attention mechanisms or employ transformations, decompositions, and reconstructions of the entire sequence to capture dependencies. The point-by-point self-attention mechanism becomes impractical for long-term time series forecasting due to its quadratic complexity with respect to the time series length. Decomposition and reconstruction methods may introduce information loss, leading to performance bottlenecks in the models. In this paper, we propose a Transformer-based forecasting model called NPformer. Our method introduces a novel multiscale segmented Fourier attention mechanism. By segmenting the long-term time series and performing discrete Fourier transforms on different segments, we aim to identify frequency-domain correlations between these segments. This allows us to capture dependencies more effectively. In addition, we incorporate a normalization module and a desmoothing factor into the model. These components address the problem of oversmoothing that arises in sequence decomposition methods. Furthermore, we introduce an isometry convolution method to enhance the prediction accuracy of the model. The experimental results demonstrate that NPformer outperforms other Transformer-based methods in long-term time series forecasting. Copyright © 2024 Haozhuo Tong et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Zhang, L.
AU  - Zhang, P.
AU  - Zhuge, Y.
AU  - Wu, J.
AU  - Yu, H.
AU  - Lu, H.
TI  - Learning Local-Global Representation for Scribble-Based RGB-D Salient Object Detection via Transformer
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 11
SP  - 11592
EP  - 11604
DO  - 10.1109/TCSVT.2024.3424651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198312271&doi=10.1109%2fTCSVT.2024.3424651&partnerID=40&md5=6dd35e061dd63431a8f2975184736042
AB  - Manual scribbles have been introduced to RGB-D Salient Object Detection (SOD) as a credible indicator for salient regions and backgrounds, helping to strike a balance between detection accuracy and labeling efficiency. Previous works address this task by constructing loss functions on semantics, edges, and structures to distinguish salient pixels from the background. However, using local representations extracted by CNNs or Transformers and the incomplete scribble annotations are ineffective in capturing the global contexts of salient objects, and thus cause inaccurate predictions in cluttered regions. In this paper, we propose a local-global representation learning framework by incorporating multi-perception information to boost scribble-based RGB-D SOD. Our system is composed of three sub-modules: Local Representation Aggregation (LRA), Global Representation Initialization (GRI) and Dual Transformer Decoder (DTD). The LRA module first conducts integration of multi-scale, multi-modal local representations extracted from RGB images and depth maps. The GRI module then learns inter- and intra-image representations to capture the global contexts of salient regions from different aspects. Finally, the DTD module alternately updates local-global representations through a dual Transformer architecture. Experimental results on six benchmarks demonstrate that the proposed method performs favorably against state-of-the-art scribble-based RGB-D SOD approaches and is competitive with the fully-supervised approaches. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Huang, B.
AU  - Jia, B.
AU  - Gao, Y.
AU  - Qiao, J.
TI  - MAS-DSO: Advancing Direct Sparse Odometry With Multi-Attention Saliency
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 17468
EP  - 17481
DO  - 10.1109/TITS.2024.3414171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197643507&doi=10.1109%2fTITS.2024.3414171&partnerID=40&md5=6f7876b1146e26ecc718c53f7ba2e142
AB  - Visual odometry (VO) is a critical component of simultaneous localization and mapping (SLAM) with extensive applications in robot navigation and beyond. However, prevalent VO methods often underperform in intricate environments with dynamic textures, insufficient lighting, and rapid rotational movements, primarily due to constrained feature selection and inadequate image structure comprehension. To address these challenges, this paper proposes a novel VO framework, termed Multi-Attention Saliency Direct Sparse Odometry (MAS-DSO). Specifically, MAS-DSO significantly bolsters performance and robustness through accurate recognition of visually salient regions and deep understanding of image structures. With regard to the problem of limited feature selection, we propose a Saliency Transformer Generative Adversarial Network (STRGAN) based on a multi-attention mechanism, narrowing the feature selection scope and enhancing its accuracy. Addressing the issue of limited understanding of image structure, we introduce a robust method for gradient computation to accurately determine the gradient values of features. Building on this, we have designed a dynamic gradient weight adjustment strategy that takes into account both the gradient magnitude and local image structure, thereby achieving precise gradient weight distribution. Comprehensive quantitative evaluations on the ICL-NUIM and TUM monoVO datasets reveal that MAS-DSO not only outperforms SalientDSO, DSO, and ORB-SLAM in performance metrics but also significantly surpasses other methods in saliency prediction performance and mapping quality. In conclusion, MAS-DSO not only augments feature selection efficiency but also enhances the processing prowess for diverse images in complex settings.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Li2024MAS-DSO
ER  -

TY  - JOUR
AU  - Xiao, J.
AU  - Li, S.
AU  - Lin, T.
AU  - Zhu, J.
AU  - Yuan, X.
AU  - Feng, D.D.
AU  - Sheng, B.
TI  - Multi-Label Chest X-Ray Image Classification With Single Positive Labels
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 12
SP  - 4404
EP  - 4418
DO  - 10.1109/TMI.2024.3421644
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197489921&doi=10.1109%2fTMI.2024.3421644&partnerID=40&md5=b1011665b2b507bd3653bfa62e074488
AB  - Deep learning approaches for multi-label Chest X-ray (CXR) images classification usually require large-scale datasets. However, acquiring such datasets with full annotations is costly, time-consuming, and prone to noisy labels. Therefore, we introduce a weakly supervised learning problem called Single Positive Multi-label Learning (SPML) into CXR images classification (abbreviated as SPML-CXR), in which only one positive label is annotated per image. A simple solution to SPML-CXR problem is to assume that all the unannotated pathological labels are negative, however, it might introduce false negative labels and decrease the model performance. To this end, we present a Multi-level Pseudo-label Consistency (MPC) framework for SPML-CXR. First, inspired by the pseudo-labeling and consistency regularization in semi-supervised learning, we construct a weak-to-strong consistency framework, where the model prediction on weakly-augmented image is treated as the pseudo label for supervising the model prediction on a strongly-augmented version of the same image, and define an Image-level Perturbation-based Consistency (IPC) regularization to recover the potential mislabeled positive labels. Besides, we incorporate Random Elastic Deformation (RED) as an additional strong augmentation to enhance the perturbation. Second, aiming to expand the perturbation space, we design a perturbation stream to the consistency framework at the feature-level and introduce a Feature-level Perturbation-based Consistency (FPC) regularization as a supplement. Third, we design a Transformer-based encoder module to explore the sample relationship within each mini-batch by a Batch-level Transformer-based Correlation (BTC) regularization. Extensive experiments on the CheXpert and MIMIC-CXR datasets have shown the effectiveness of our MPC framework for solving the SPML-CXR problem.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fang, X.
AU  - Yang, H.
AU  - Shi, L.
AU  - Wang, Y.
AU  - Li, L.
TI  - BERT-Based Semantic-Aware Heterogeneous Graph Embedding Method for Enhancing App Usage Prediction Accuracy
PY  - 2024
T2  - IEEE Transactions on Human-Machine Systems
VL  - 54
IS  - 4
SP  - 465
EP  - 474
DO  - 10.1109/THMS.2024.3412273
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197659124&doi=10.1109%2fTHMS.2024.3412273&partnerID=40&md5=5b974f2ab42afdf3480bc1e01734b425
AB  - With the widespread adoption of smartphones and mobile Internet, understanding user behavior and improving user experience are critical. This article introduces semantic-aware (SA)-BERT, a novel model that integrates spatio-temporal and semantic information to represent App usage effectively. Leveraging BERT, SA-BERT captures rich contextual information. By introducing a specific objective function to represent the cooccurrence of App-time-location paths, SA-BERT can effectively model complex App usage structures. Based on this method, we adopt the learned embedding vectors in App usage prediction tasks. We evaluate the performance of SA-BERT using a large-scale real-world dataset. As demonstrated in the numerous experimental results, our model outperformed other strategies evidently. In terms of the prediction accuracy, we achieve a performance gain of 34.9% compared with widely used the SA representation learning via graph convolutional network (SA-GCN), and 134.4% than the context-aware App usage prediction with heterogeneous graph embedding. In addition, we reduced 79.27% training time compared with SA-GCN.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Song, T.
AU  - Bai, S.
AU  - Yang, F.
AU  - Gao, C.
AU  - Chen, H.
AU  - Li, J.
TI  - Exploring Hybrid Contrastive Learning and Scene-to-Label Information for Multilabel Remote Sensing Image Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5631214
DO  - 10.1109/TGRS.2024.3422031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197473572&doi=10.1109%2fTGRS.2024.3422031&partnerID=40&md5=689b65edf83c17d2fdd7b34185e8ee86
AB  - Multilabel remote sensing (RS) image classification aims to predict multiple semantic labels from an RS image. Previous methods [e.g., graph convolution networks (GCNs)] focus on mining the relationships of multiple labels, neglecting that the scene information is closely related to labels. To remedy this deficiency, in this article we propose a novel end-to-end deep neural network for multilabel RS image classification. In the proposed network, we use the GCN as the base model and introduce several new components to improve the classification performance. First, we explore hybrid contrastive learning (CL), including supervised transformation-based CL and unsupervised mix-based CL, to explicitly learn discriminative scene representations. Then, we apply the GCN-based classifier to the learned scene representations to obtain initial label prediction scores. Meanwhile, we pass the scene representations to a softmax layer to predict the probability that each image belongs to each specific scene class and use the scene-to-label information with the law of total probability to calibrate the initial label prediction scores. Finally, we incorporate CL, scene classification, and multilabel classification into a unified learning framework using uncertainty to weigh different losses. Experimental results on two benchmark RS datasets demonstrate the superiority of our proposed network for multilabel image classification. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, C.
AU  - Sun, Z.
AU  - Lv, Q.
AU  - Min, L.
AU  - Zhang, Y.
TI  - VS-TransGRU: A Novel Transformer-GRU-Based Framework Enhanced by Visual-Semantic Fusion for Egocentric Action Anticipation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 11
SP  - 11605
EP  - 11618
DO  - 10.1109/TCSVT.2024.3425598
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198316769&doi=10.1109%2fTCSVT.2024.3425598&partnerID=40&md5=a22d848356188f0595e8d34813f862ab
AB  - Egocentric action anticipation is a challenging task that aims to make advanced predictions of future actions from current and historical observations in the first-person view. Most existing methods focus on improving the model architecture and loss function based on the visual input and recurrent neural network to boost the anticipation performance. However, these methods, which merely consider visual information and rely on a single network architecture, gradually reach a performance plateau. In order to fully understand what has been observed and capture the dependencies between current observations and future actions well enough, we propose a novel visual-semantic fusion enhanced and Transformer-GRU-based action anticipation framework in this paper. Firstly, high-level semantic information is introduced to improve the performance of action anticipation for the first time. We propose to use the semantic features generated based on the class labels or directly from the visual observations to augment the original visual features. Secondly, to take advantage of both the parallel and autoregressive models, we design a Transformer-based encoder for long-term sequential modeling and a GRU-based decoder for flexible iteration decoding. This hybrid architecture allows for better performance with fewer parameters and computations. Thirdly, an effective visual-semantic fusion module is proposed to make up for the semantic gap and fully utilize the complementarity of different modalities. Extensive experiments on two large-scale first-person view datasets and two third-person datasets validate the effectiveness of our proposed method, which achieves new state-of-the-art performance, outperforming previous approaches by a large margin. The code will be released after acceptance at https://github.com/sunze992/VS-TransGRU. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Dong, S.
AU  - Hao, J.
AU  - Zeng, L.
AU  - Yang, X.
AU  - Wang, L.
AU  - Ji, C.
AU  - Zhong, Z.
AU  - Chen, S.
AU  - Fu, K.
TI  - A Deep Learning Object Detection Method for Fracture Identification Using Conventional Well Logs
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5920716
DO  - 10.1109/TGRS.2024.3427364
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198374722&doi=10.1109%2fTGRS.2024.3427364&partnerID=40&md5=3e83304e9682ccd58c5084917050c311
AB  - Reservoir characterization struggles with identifying fractures, a typical imbalance classification problem. To handle this issue, a novel approach called fracture identification by sliding windows and you only look once (YOLO) (FISY) is proposed. FISY utilizes YOLO, a fast and accurate object detection neural network, to transform fracture identification into an abnormality detection task. Conventional well logs from specific interval formations are used as the detected image, and adjacent depth intervals enhance the analysis. Image samples are generated via a sliding window approach. YOLO detects the minority abnormality class (fractures), addressing data imbalance issues. Each depth sample undergoes multiple scans, and the probability superposition of the sliding window approach reduces forecast uncertainty. To assess FISY, a dataset from carbonate reservoirs in the Asmari Formation, Middle East, was used. The mean average precision (mAP) evaluation metric, combining precision and recall, assesses FISY's performance in object detection. Among five-scaled FISY, XLarge demonstrates the highest mAP at 99.16%, with a rapid prediction time of 4 ms/image. In blind well tests, FISY surpasses fracture identification by sliding window (FIS) + Transformer (TF) (TF replacing YOLO in the FISY), synthetic minority oversampling technique (SMOTE) + support vector machine (SVM), and SMOTE + random forests (RFs) by over 13% in F1 score, showcasing its efficacy in fracture identification. To further assess FISY's generalization across various lithologies, an experiment with a clastic reservoir dataset in the Ordos Basin in China reveals FISY's good performance (mAP 87.5%). © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, A.
AU  - Xiao, Y.
AU  - Liu, C.
AU  - Tan, M.
AU  - Cao, Z.
TI  - Lightweight LiDAR-Camera Alignment With Homogeneous Local-Global Aware Representation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 11
SP  - 15922
EP  - 15933
DO  - 10.1109/TITS.2024.3409397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196087930&doi=10.1109%2fTITS.2024.3409397&partnerID=40&md5=0d95bcdb53cfa3af582d578338454f00
AB  - In this paper, a novel LiDAR-Camera Alignment (LCA) method using homogeneous local-global spatial aware representation is proposed. Compared with the state-of-the-art methods (e.g., LCCNet), our proposition holds 2 main superiorities. First, homogeneous multi-modality representation learned with a uniform CNN model is applied along the iterative prediction stages, instead of the state-of-the-art heterogeneous counterparts extracted from the separated modality-wise CNN models within each stage. In this way, the model size can be significantly decreased (e.g., 12.39M (ours) vs. 333.75M (LCCNet)). Meanwhile, within our proposition the interaction between LiDAR and camera data is built during feature learning to better exploit the descriptive clues, which has not been well concerned by the existing approaches. Secondly, we propose to equip the learned LCA representation with local-global spatial aware capacity via encoding CNN’s local convolutional features with Transformer’s non-local self-attention manner. Accordingly, the local fine details and global spatial context can be jointly captured by the encoded local features. And, they will be jointly used for LCA. On the other hand, the existing methods generally choose to reveal the global spatial property via intuitively concatenating the local features. Additionally at the initial LCA stage, LiDAR is roughly aligned with camera by our pre-alignment method, according to the point distribution characteristics of its 2D projection version with the initial extrinsic parameters. Although its structure is simple, it can essentially alleviate LCA’s difficulty for the consequent stages. To better optimize LCA, a novel loss function that builds the correlation between translation and rotation loss items is also proposed. The experiments on KITTI data verifies the superiority of our proposition both on effectiveness and efficiency. The source code will be released at https://github.com/Zaf233/Light-weight-LCA upon acceptance. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhu2024Lightweight
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Ling, Q.
TI  - FDNet: Frequency Decomposition Network for Learned Image Compression
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 11
SP  - 11241
EP  - 11255
DO  - 10.1109/TCSVT.2024.3415823
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196545131&doi=10.1109%2fTCSVT.2024.3415823&partnerID=40&md5=48a1e76cbef7c16020fd9b3e6b312f9a
AB  - Recently learned image compression methods have achieved better rate-distortion performance than traditional non-learning image compression standards. Some previous image compression methods combine the local modeling capability of CNN with the long-range attention of Transformer to generate the latent representation. However, previous methods ignored the fact that Transformer pays attention to low-frequency feature learning while CNN focuses on high-frequency feature learning, resulting in insufficient fusion of these two structures. In this paper, we propose a novel image compression method with Frequency Decomposition Network (FDNet), which processes low-frequency and high-frequency components in different ways. More specifically, FDNet initially implements a dynamic frequency filter to adaptively decompose the features into low-frequency and high-frequency components. As invertible neural networks do not lose any information during the feature transformation and can be implemented by CNN residual networks, the invertible neural network block (INNB) is used to extract high-frequency local information. Then FDNet takes a hybrid attention block (HAB), which is composed of window-based multi-head self-attention (W-MSA) and channel attention, to extract window-based and global spatial low-frequency information. Besides, previous channel entropy models adopt CNN networks to remove high-frequency redundancy of the latent representation. However, there exists low-frequency redundancy between different channels of the latent representation. To solve this issue, FDNet further introduces the hybrid attention block to the channel entropy model. W-MSA and channel attention of the hybrid attention block can remove the window-based and global low-frequency redundancy, respectively. Extensive experiments demonstrate that FDNet achieves promising rate-distortion performance on the Kodak, CLIC and Tecnick datasets. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, Z.
AU  - Dong, X.
AU  - Wang, Y.
AU  - Wang, J.
AU  - Chen, Y.
AU  - Hu, C.
TI  - MDTNet: Multiscale Deformable Transformer Network With Fourier Space Losses Toward Fine-Scale Spatiotemporal Precipitation Nowcasting
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4106417
DO  - 10.1109/TGRS.2024.3414934
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196060283&doi=10.1109%2fTGRS.2024.3414934&partnerID=40&md5=ed3a5831b57a52251da2dc4516260ea8
AB  - Deep learning (DL)-based precipitation nowcasting algorithms have garnered significant attention in recent years. However, the presence of variable spatial scales in precipitation patterns poses challenges for methods that solely focus on capturing spatiotemporal correlations at a single scale. Moreover, current DL-based algorithms tend to model short-term (e.g., 10-min time span) rainfall locally neglecting long-term, global (e.g., 2-h time span) life-cycle evolution. Furthermore, widely used pixel-wise losses are prone to produce low effective-spatial-resolution predictions. To this end, we introduce a multiscale deformable transformer network to leverage echo contexts from image patches of varying spatial scales. Meanwhile, a multihead deformable self-attention mechanism is introduced for capturing precipitation spatiotemporal dynamics in a global manner. Moreover, to improve the spatial resolution of predictions, the Fourier space regularization and adversarial losses are proposed by narrowing the discrepancy of the Fourier spectra of predictions and references. Thanks to the introduced loss function, our model generates highly effective spatial-resolution predictions with abundant details. Extensive experiments on two real datasets show the substantial superiority of our method in terms of critical success index (CSI) compared to recent competitive approaches. At the same time, our predictions have more realistic precipitation details and significantly better fidelity. For example, on a vertically integrated liquid (VIL) product dataset, compared to baseline methods, our approach reduces the Fréchet inception distance (FID) value by a factor of 2sim 4 while improves the CSI score by 3%~5% approximately. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, Y.
AU  - Xu, M.
AU  - Jiang, L.
AU  - Deng, X.
AU  - Zhou, J.
AU  - Chen, G.
AU  - Sigal, L.
TI  - Proposal With Alignment: A Bi-Directional Transformer for 360° Video Viewport Proposal
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 11
SP  - 11423
EP  - 11437
DO  - 10.1109/TCSVT.2024.3419910
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197045017&doi=10.1109%2fTCSVT.2024.3419910&partnerID=40&md5=6f0f79ba9505c60d63935cb985a7391d
AB  - People normally watch 360 ° videos through a head-mounted display, inside which only the content of viewports can be seen. Therefore, viewport proposal, referring to detecting potential viewport candidates, plays an important role in many 360 ° video processing tasks. In this paper, we advance the viewport proposal by further aligning the predicted viewports across frames for individual subject. This provides a better methodology and a deeper perspective to learn the human perceptual behaviours on 360 ° videos. Specifically, we first analyze three 360 ° video datasets and obtain several findings on human consistency, objectness and motion of viewports. Inspired by these findings, we propose a bi-directional transformer approach, named BiT, for 360 ° video viewport proposal and alignment. Specifically, BiT is composed of a multi-level residual module, a bi-directional encoder-decoder module and a spherical matching module. This way, the viewports can be well proposed and aligned via considering multi-level, bi-directional and non-local information. Moreover, the aligned viewports by BiT are used to refine the viewports and improve viewport proposal accuracy in return. Finally, we validate that our BiT approach is superior on viewport proposal, compared with the state-of-the-art approaches. Besides, the aligned viewports from BiT is verified to be effective in multiple applications, such as saliency prediction, trajectory prediction and perceptual video compression. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Geng, S.
AU  - Ma, G.
AU  - Zhu, L.
AU  - Liu, Q.
TI  - An Improvement Multitask Transformer Network for Dual-Polarization Radar Extrapolation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5108015
DO  - 10.1109/TGRS.2024.3420417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197029912&doi=10.1109%2fTGRS.2024.3420417&partnerID=40&md5=9ed4765a2bd98f582b81f96780f452d0
AB  - Severe convective weather, a meteorological phenomenon, is distinguished by its abrupt initiation, swift propagation, extreme atmospheric conditions, and formidable capacity for destruction, all of which have a significant impact on human productivity and livelihoods. In this study, we introduce an improved multitask transformer-based algorithm, MT-Transformer, for predicting parameters related to dual-polarization radar. These parameters encompass radar reflectivity Zh, differential reflectivity Zdr, and specific differential phase Kdp so that more information about the dynamic structure of convective storms can be obtained. MT-Transformer has the following main improvements. First, to overcome the insensitivity of the transformer to high-frequency information, before the data are fed into the transformer, 2-D convolution operation is used for the downscaling and image feature extraction. Second, for the input side of the Transformer decoder, we develop the future feature extraction (FFE) module for multiscale feature prediction, which is a structure for capturing the global multiscale contextual information of multivariate. Third, the fully connected structure in the feedforward network is replaced by a 3-D convolution layer, which can effectively extract the spatiotemporal information of precipitation. The quantitative results demonstrate a reduction in the root-mean-square error (RMSE) values for Zh, Zdr, and Kdp by 14.48%, 3.47%, and 6.91%, respectively, in comparison to those of the second-best MIM model for a 1-h forecast duration. 1558-0644  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wei, R.
AU  - Li, B.
AU  - Zhong, F.
AU  - Mo, H.
AU  - Dou, Q.
AU  - Liu, Y.
AU  - Sun, D.
TI  - Absolute Monocular Depth Estimation on Robotic Visual and Kinematics Data via Self-Supervised Learning
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
SP  - 1
EP  - 14
DO  - 10.1109/TASE.2024.3409392
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195407802&doi=10.1109%2fTASE.2024.3409392&partnerID=40&md5=f1891781534f1dc5ee9a1d95eede8ef7
AB  - Accurate estimation of absolute depth from a monocular endoscope is a fundamental task for automatic navigation systems in robotic surgery. Previous works solely rely on uni-modal data (<italic>i.e.</italic>, monocular images), which can only estimate depth values arbitrarily scaled with the real world. In this paper, we present a novel framework, SADER, which explores vision and robot kinematics to estimate the high-quality absolute depth for monocular surgical scenes. To jointly learn the multi-modal data, we introduce a self-distillation based two-stage training policy in the framework. In the first stage, a boosting depth module based on vision transformer is proposed to improve the relative depth estimation network that is trained in a self-supervised method. Then, we develop an algorithm to automatically compute the scale from robot kinematics. By coupling the scale and relative depth data, pseudo absolute depth labels for all images are yielded. In the second stage, we re-train the network with 3D loss supervised by pseudo labels. To make our method generalize to different endoscopes, the learning of endoscopic intrinsics is integrated into the network. In addition, we did cadaver experiments to collect new surgical depth estimation data about robotic laparoscopy for evaluation. Experimental results on public SCARED and cadaver data demonstrate that the SADER outperforms previous state-of-art even stereo-based methods with an accuracy error under 1.90 mm, proving the feasibility of our approach to recover the absolute depth with monocular inputs. <italic>Note to Practitioners</italic>&#x2014;This paper aims to solve the problem of absolute monocular depth estimation in automatic surgical navigation by leveraging the multi-modal data from the robot-based endoscopic system. Accurate depth perception with real scales of the monocular scene is essential for the control of surgical robots in automatic navigation. However, current methods can only predict the relative depth of the surgical scene using monocular images. In this article, we propose a self-supervised learning-based method to achieve high-quality absolute depth estimation of monocular endoscopic images. It neither needs manual data annotation, nor other imaging modalities. The experiments extensively validate the feasibility and high performance of our framework for absolute depth estimation on monocular endoscopes. This absolute depth perception framework can be potentially encapsulated into the automatic navigation system in the near future. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jiang, P.
AU  - Deng, F.
AU  - Wang, X.
AU  - Luo, W.
AU  - Ye, C.
TI  - 3-D Seismic First Break Picking Based on Two-Channel Mask Strategy
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5918115
DO  - 10.1109/TGRS.2024.3412673
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196086513&doi=10.1109%2fTGRS.2024.3412673&partnerID=40&md5=8237ac034f51bc92c45fe2c60912b81b
AB  - In recent years, much attention has been paid to using deep learning techniques for land seismic first break (FB) picking. Among these, the deep learning-based 3-D FB picking method has shown stronger noise resistance than the 2-D method, as it simultaneously considers the correlation of FBs in both crossline and inline directions. In existing studies, whether using 2-D or 3-D methods, they are often regarded as a binary semantic segmentation problem of pre- and post-FB (PPFB). The FB time is determined by dividing the image with a binary classification mask. However, due to the instability of the decision threshold setting of the PPFB mask strategy, different thresholds can cause different FB picking results. Considering this, we propose a two-channel (2C) mask strategy that utilizes the feature interaction between a strip-like mask and a line-like mask to predict the confidence of FBs in seismic traces, thus realizing the FB picking with uniqueness. In addition, to enhance the global feature acquisition capability of the network, we construct a 3-D FB picking network USwinNet based on Swin Transformer, which establishes a larger receptive field through a multistage self-attention (SA) mechanism. Experimental results demonstrate that our method significantly improves the picking accuracy compared to existing methods. It also exhibits strong generalization capabilities, making it more suitable for practical engineering under complex geological conditions.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Lin, D.
AU  - Li, C.
AU  - Tu, Z.
AU  - Luo, B.
TI  - Alignment-Free RGBT Salient Object Detection: Semantics-Guided Asymmetric Correlation Network and a Unified Benchmark
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 10692
EP  - 10707
DO  - 10.1109/TMM.2024.3410542
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195422578&doi=10.1109%2fTMM.2024.3410542&partnerID=40&md5=31939bf1368dbc4b25dc1ecb8433c44b
AB  - RGB and Thermal (RGBT) Salient Object Detection (SOD) aims to achieve high-quality saliency prediction by exploiting the complementary information of visible and thermal image pairs, which are initially captured in an unaligned manner. However, existing methods are tailored for manually aligned image pairs, which are labor-intensive, and directly applying these methods to original unaligned image pairs could significantly degrade their performance. In this paper, we make the first attempt to address RGBT SOD for initially captured RGB and thermal image pairs without manual alignment. Specifically, we propose a Semantics-guided Asymmetric Correlation Network (SACNet) that consists of two novel components: 1) an asymmetric correlation module utilizing semantics-guided attention to model cross-modal correlations specific to unaligned salient regions; 2) an associated feature sampling module to sample relevant thermal features according to the corresponding RGB features for multi-modal feature integration. In addition, we construct a unified benchmark dataset called UVT2000, containing 2000 RGB and thermal image pairs directly captured from various real-world scenes without any alignment, to facilitate research on alignment-free RGBT SOD. Extensive experiments on both aligned and unaligned datasets demonstrate the effectiveness and superior performance of our method. © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Wu, B.
AU  - Wei, C.
AU  - Yan, X.
TI  - InverMulT-STP: Closed-Loop Transformer Seismic AVA Inversion With Synthetic Data Style Transfer Pretraining
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4507418
DO  - 10.1109/TGRS.2024.3409450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195425583&doi=10.1109%2fTGRS.2024.3409450&partnerID=40&md5=be2b0acde7a6afd077d0e46b5dec557e
AB  - Prestack seismic data amplitude variation with angle (AVA) inversion is critical in identifying oil and gas reservoirs. Recently, deep learning (DL) has gained significant popularity in AVA multiparameter inversion, often employing 1-D network on a trace-by-trace basis. However, the limited availability of well-log data (label) and the inability of 1-D network to capture spatial features result in predictions with inadequate lateral stability and structural consistency. At the same time, the adoption of multiple single-task learning strategy leads to low efficiency and weak generalization in multiparameter inversion. To address these challenges, we propose InverMulT-STP, a 2-D multitask closed-loop Transformer with synthetic data style transfer pretraining for prestack AVA inversion. The proposed semi-supervised learning (SSL) paradigm combines multitask learning (MTL) and transfer learning strategies to improve prestack AVA inversion. Specifically, the multitask closed-loop Transformer (InverMulT) utilizes a Transformer-based encoder-decoder architecture to extract comprehensive spatial structure information from angle gathers, enabling simultaneous and accurate multiparameter inversion. We enhance the cycle-consistency loss and introduce learned perceptual image patch similarity (LPIPS) as the criterion to achieve more detailed structures in the inversion results. To make balance on the inversion of different parameters, an adaptive weight update method (AWUM) is introduced for the weighting of each task in loss functions. To improve generalization on field data, neural style transfer (NST) is employed to generate the realistic synthetic dataset for network pretraining. From both synthetic and field data experiments, the inversion results show that the proposed method outperforms several existing DL inversion methods and commercial software.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, D.
AU  - Liu, J.
AU  - Ma, L.
AU  - Liu, R.
AU  - Fan, X.
TI  - Improving Misaligned Multi-Modality Image Fusion With One-Stage Progressive Dense Registration
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 11
SP  - 10944
EP  - 10958
DO  - 10.1109/TCSVT.2024.3412743
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196118168&doi=10.1109%2fTCSVT.2024.3412743&partnerID=40&md5=3f0f6d2051aba111dbdf53bfea3b179d
AB  - Misalignments between multi-modality images pose challenges in image fusion, manifesting as structural distortions and edge ghosts. Existing efforts commonly resort to registering first and fusing later, typically employing two separate stages for registration, i.e., coarse registration and fine registration. Both stages directly estimate the respective target deformation fields. This paper contends that the separate two-stage registration lacks compactness, and the direct estimation of their target deformation fields falls short in accuracy. To tackle these challenges, we introduce IMF, a framework for improving misaligned multi-modality image fusion. Central to IMF is a One-stage Progressive Dense Registration (OPDR) scheme, which accomplishes the coarse-to-fine registration through only a one-stage optimization. Specifically, two pivotal components are involved in OPDR, a dense Deformation Field Fusion (DFF) module and a Progressive Feature Fine (PFF) module. The DFF aggregates the predicted multi-scale deformation sub-fields at the current scale, while the PFF progressively refines the remaining misaligned features. Together, they effectively and accurately estimate the final deformation fields. In addition, we develop a Transformer-Conv-based Fusion (TCF) subnetwork that considers local and long-range feature dependencies, allowing us to capture more informative features from the registered infrared and visible images for the generation of high-quality fused images. Extensive experimental analysis demonstrates the superiority of the proposed method in the fusion of misaligned cross-modality images. The code will be available at https://github.com/wdhudiekou/IMF. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Jiao, L.
AU  - Li, L.
AU  - Liu, X.
AU  - Liu, F.
AU  - Yang, S.
TI  - Effective and Robust: A Discriminative Temporal Learning Transformer for Satellite Videos
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4705416
DO  - 10.1109/TGRS.2024.3411714
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196115294&doi=10.1109%2fTGRS.2024.3411714&partnerID=40&md5=1c709a5a38a784bfc11ff34d49e60ad5
AB  - Robust feature learning has always been a research hotspot in dynamic temporal tasks. It makes the model almost unaffected by some challenging properties. The sequential nature of the transformer means attractive for temporal learning tasks, making it perform well in the video field. It is a current research hotspot for learning effective features by utilizing the target motion trends in satellite videos with multiple attributes, such as similar objects (SOBs) interference and occlusion. In this article, a novel discriminative temporal learning transformer tracker (DTLTracker) is introduced to characterize the dynamic target information for satellite videos. A discriminative transformer (DT) is proposed to comprehensively explore the dynamic target features with multiple attention mechanisms. It focuses on the primary information of the search area, making the target more discriminative. A fast convergence (FC) filter is designed to accelerate the weights convergence in calculating the target correlation operation, thereby ensuring the efficiency of model learning. The effectiveness and convergence have been demonstrated for the proposed optimization method. Additionally, a motion prior correction (MPC) module is constructed to utilize temporal information for target tracklet prediction, assisting the tracker in predicting the correct target. Numerous experiments are performed on three satellite videos to verify the effectiveness and feasibility of the proposed DTLTracker. It shows robustness compared to the state-of-the-art trackers on some challenging properties.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - You, M.
AU  - Meng, X.
AU  - Liu, Q.
AU  - Shao, F.
AU  - Fu, R.
TI  - CIG-STF: Change Information Guided Spatiotemporal Fusion for Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5405815
DO  - 10.1109/TGRS.2024.3412118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196504739&doi=10.1109%2fTGRS.2024.3412118&partnerID=40&md5=fc9dd04e6d494d48b196cf7b158fdb6a
AB  - Spatiotemporal fusion has been attracting increasing attention in remote sensing applications, such as environmental monitoring and land cover change detection, due to its excellent ability to obtain high spatial and temporal resolution images. The land cover change has always been a great challenge in spatiotemporal fusion. Although most spatiotemporal fusion methods have demonstrated satisfactory performance in addressing phenological changes, the performance in terms of abrupt land cover type changes, such as floods or mudslides, falls short. To alleviate this issue, we propose a change information guided spatiotemporal fusion (CIG-STF) method. The proposed CIG-STF integrates change detection and spatiotemporal fusion in a unified framework, by taking advantage of change detection in capturing land cover changes to assist spatiotemporal fusion. Specifically, the CIG-STF comprises three modules: multiscale dilated feature extractor module (MDFE), spatiotemporal fusion-change detection integrated module (STF-CD), and reconstruction module. The MDFE employs multiscale dilated convolutions to comprehensively extract features, to prevent crucial information loss by increasing the convolutional receptive field. In the STF-CD, a change detection module on attention strategy is integrated into the spatiotemporal fusion task, by excavating land cover changes to further enhance the fusion performance. In addition, we design a dynamic decay loss function to further leverage change information, ensuring the accuracy of both change information and prediction results. The experiments were verified on the publicly available LGC and Daxing datasets with manual change labels. The experimental results demonstrate the superior performance of the proposed CIG-STF in both phenological variations and land cover type changes.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, Z.
AU  - Jiang, Y.
AU  - Jing, X.
AU  - Zheng, H.
TI  - Study on Geomagnetic Observations Associated With Three Major Earthquakes in Southwest China Through a Novel Deep Learning Framework
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 2005118
DO  - 10.1109/TGRS.2024.3411705
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196093874&doi=10.1109%2fTGRS.2024.3411705&partnerID=40&md5=f5ecd3772549f4543464835ee5252f73
AB  - A novel method for detecting geomagnetic anomalies is proposed using a deep learning (DL) framework based on transformer architecture, which benefits from the self-attention mechanism therein that can assign attention weights to important features from the entire sequence. Given the rarity and variability of seismo-geomagnetic anomalies, it is difficult to establish correlations between anomalies and most data for seismic quiet periods. Thereby, we propose an anomaly transformer for the geomagnetism model (ATGM) with a two-branch structure to extract the sequence features and distribution features of anomalies. The first branch, termed sequence offset, measures whether geomagnetic sequences deviate from normal temporal dependencies. The second branch is distribution offset, to further assess the difference between the geomagnetic high-frequency data distribution and a prior distribution through its learnable kernel function. Finally, the ATGM is applied to analyze the preearthquake geomagnetic observations of the 2008 Wenchuan Ms 8.0 earthquake, the 2013 Lushan Ms 7.0 earthquake, and the 2014 Kangding Ms 6.5 earthquake. Significant anomalies could be extracted, occurring about 30-70 days before the earthquakes. Further comparing the sigmoidal-shaped growth in the cumulative numbers of preearthquake anomalies with the linear growth exhibited during normal periods and at distant stations, we can clearly distinguish the uniqueness and significance of the extracted anomalies. In addition, during the anomaly periods, the seismic activities and the strain observations around the epicenters also confirm the existence of abnormal underground activity preceding the earthquakes. Our proposed ATGM achieves a combined representation of manually designed and data-driven learned features, as well as develops preearthquake anomaly detection technology.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, X.
AU  - Li, J.
AU  - Cao, J.
AU  - Tang, D.
AU  - Liu, J.
AU  - Liu, B.
TI  - Semantic-Guided Representation Enhancement for Multi-Label Image Classification
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 10
SP  - 10036
EP  - 10049
DO  - 10.1109/TCSVT.2024.3408256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195426501&doi=10.1109%2fTCSVT.2024.3408256&partnerID=40&md5=9efa9805f0b5fa681eb8fb888a3ff11b
AB  - Multi-label image classification is an essential yet challenging task that requires to recognize multiple objects of images. To this end, recent studies have sought to acquire visual representations for each label by attention models, and then train binary classifiers for prediction. However, these methods have two major drawbacks: 1) They rely heavily on the precise alignments between two modalities, which is still challenging for current attention models; 2) They ignore patch-level representations rich in local object features, which are also of great importance for label recognition. In this paper, we propose a semantic-guided representation enhancement framework, which augments patch-level representations with object-level representations for robust label recognition. Concretely, the proposed framework consists of two significant components: 1) an inter-modal attention module that accounts for coarsely locating object regions and producing object-level representations for each label; 2) an intra-modal attention module that aggregates object representations to enhance patch representations based on their correlations. In this way, both local clues and global glances of objects are fully exploited simultaneously, rather than relying solely on object-level representations obtained by the inter-modal attention, thus improving the performance of label recognition. Experimental results show that our framework outperforms the state-of-the-art methods by 0.5%, 0.6%, 0.7% and 0.8% in mAP on Pascal VOC 2007, Microsoft COCO, NUS-WIDE and Visual Genome datasets, respectively. Codes and models are available on https://github.com/jasonseu/SGRE.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, L.
AU  - Cheng, J.
AU  - Wang, X.
AU  - Su, H.
AU  - Yang, H.
AU  - Yuan, H.
AU  - Korhonen, J.
TI  - 3DTA: No-Reference 3D Point Cloud Quality Assessment With Twin Attention
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 10489
EP  - 10502
DO  - 10.1109/TMM.2024.3407698
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194892251&doi=10.1109%2fTMM.2024.3407698&partnerID=40&md5=113ab19cbd443f4c830e6d72d9c701fb
AB  - Point clouds are rapidly gaining popularity in many practical applications, and point cloud quality assessment (PCQA) is an important research topic that helps us measure and improve the visual experience in applications using point clouds. Research on full-reference (FR) PCQAs has recently made impressive progress, and research on no-reference (NR) PCQAs has also gradually increased. However, the performance of the prior NR PCQA methods still suffers from weak generalization ability and lower accuracy than the FR metrics in general. In this work, we propose a two-stage sampling method that can reasonably represent a whole point cloud, making it possible to efficiently calculate the point cloud quality. For quality prediction, we designed a twin-attention-based transformer PCQA model (3DTA), which uses the data of the two-stage sampling method as input and directly outputs the predicted quality score. Our model is accurate and widely applicable, and it has a simple and flexible structure. Experimental results show that in most cases, the proposed 3DTA model substantially outperforms the benchmark NR methods. The accuracy of the proposed method is competitive even against that of the FR method, which makes 3DTA a strong candidate for the PCQA task, regardless of the reference availability. © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Liu, J.
AU  - Tan, H.
AU  - Lou, J.
AU  - Liu, X.
AU  - Zhou, W.
AU  - Liu, H.
TI  - Blind Image Quality Assessment via Adaptive Graph Attention
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 10
SP  - 10299
EP  - 10309
DO  - 10.1109/TCSVT.2024.3405789
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194867700&doi=10.1109%2fTCSVT.2024.3405789&partnerID=40&md5=3eee612489b26f69cf8dabaf5e908596
AB  - Recent advancements in blind image quality assessment (BIQA) are primarily propelled by deep learning technologies. While leveraging transformers can effectively capture long-range dependencies and contextual details in images, the significance of local information in image quality assessment can be undervalued. To address this challenging problem, we propose a novel feature enhancement framework tailored for BIQA. Specifically, we devise an Adaptive Graph Attention (AGA) module to simultaneously augment both local and contextual information. It not only refines the post-transformer features into an adaptive graph, facilitating local information enhancement, but also exploits interactions amongst diverse feature channels. The proposed technique can better reduce redundant information introduced during feature updates compared to traditional convolution layers, streamlining the self-updating process for feature maps. Experimental results show that our proposed model outperforms state-of-the-art BIQA models in predicting the perceived quality of images. The code is available at https://github.com/sky-whs/AGAIQA.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, K.
AU  - Zhang, B.
AU  - Lu, J.
AU  - Yan, H.
TI  - Toward Integrity and Detail with Ensemble Learning for Salient Object Detection in Optical Remote-Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5624615
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3400032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193222623&doi=10.1109%2fTGRS.2024.3400032&partnerID=40&md5=3be6527e17b6fcca307237ef7fd572eb
AB  - Optical remote-sensing image salient object detection (ORSI-SOD) poses significant challenges due to complicated object variances and interfering surroundings. Although existing methods have achieved impressive performance, they encounter difficulties in balancing deep and shallow features, leading to limitations in preserving object integrity and edge detail. To address this, we propose the integrated and detailed ensemble learning (IDEL) framework, which incorporates hierarchical branches with deep supervision. By divide-and-conquer, each branch captures information with a specific granularity, while the fusion module combines all outputs to generate the final saliency maps. To ensure the effectiveness of ensemble learning, IDEL is designed to satisfy two necessary conditions: the weak learner property and branch independence. Firstly, we utilize the Transformer blocks with a global receptive field and purify intermediate features with the deep supervision module (DSM) to enhance the performance of each branch. Secondly, we disentangle multiple branches through hardness-aware weights and hierarchical supervision labels, allowing them to learn distinct features. Qualitative visualizations demonstrate the effectiveness of each module, and extensive experimental results conducted on three popular ORSI datasets confirm the superiority of IDEL compared to other state-of-the-art (SOTA) counterparts.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, J.
AU  - Liang, G.
AU  - Zhang, R.
TI  - LTTrack: Rethinking the Tracking Framework for Long-Term Multi-Object Tracking
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 10
SP  - 9866
EP  - 9881
DO  - 10.1109/TCSVT.2024.3404275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194044176&doi=10.1109%2fTCSVT.2024.3404275&partnerID=40&md5=591de1431dd9f636e333ee07e3672ef0
AB  - Long-term tracking is a commonly overlooked yet practical scenario in multi-object tracking. Handling occlusion and re-identifying long-lost targets are the main challenges for effective long-term tracking. In occlusion scenarios, both appearance and motion features can be unreliable, leading to association failure. For long-lost targets, predicting their long-term motion suffers from severe error accumulation, making the target re-identification challenging. In this paper, we propose a multi-object tracker called LTTrack for long-term tracking. For occlusion handling, we develop the Position-Based Association (PBA) module, which encodes relative and absolute positions as interaction and motion features for association. With interaction features, PBA can handle occlusion scenes where appearance and motion features are unreliable. For long-lost target re-identification, the Long-Term Motion (LTM) model is devised. By encoding long-term motion trends of targets for long-term motion prediction, LTM alleviates the error accumulation problem. Moreover, to prevent the erroneous deletion of long-lost tracks, we propose the Zombie Track Re-Match (ZTRM) strategy to re-identify long-lost targets so that they will neither be prematurely deleted nor disrupt the association of other tracks. Extensive experiments conducted on MOT17, MOT20, and DanceTrack demonstrate that LTTrack achieves performance comparable to state-of-the-art methods. The code and models are available at https://github.com/Lin-Jiaping/LTTrack.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Dong, Z.
AU  - Liu, Z.
AU  - Cong, R.
AU  - Fang, T.
AU  - Shao, X.
AU  - Kwong, S.
TI  - UAFer: A Unified Model for Class-Agnostic Binary Segmentation With Uncertainty-Aware Feature Reassembly
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 10
SP  - 9836
EP  - 9851
DO  - 10.1109/TCSVT.2024.3403264
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194054159&doi=10.1109%2fTCSVT.2024.3403264&partnerID=40&md5=625ca47aac15b7c07786f2f70e46f78a
AB  - Class-agnostic binary segmentation identifies objects that are similar or very different from the complex background, including salient object detection (SOD) and camouflage object detection (COD). Most existing models only focus on a specific type of foreground and background segmentation by employing the global modeling ability of transformers, without explicitly explaining or eliminating the discrepancy between these two different distributions. They also suffer from inefficient local feature learning and inadequate feature aggregation. To make binary segmentation research more accessible and trivially generalized, we introduce a novel unified uncertainty-aware paradigm, called uncertainty-aware feature reassembly (UAFer). Specifically, the Spatial Feature Reassembly (SFR) module is presented to formulate the uncertainty of binary segmentation map as the variance of generalized Bernoulli distribution and entropy from two perspectives. Our transformer-based model is then trained to prioritize regions of higher certainty, obtaining more confident and accurate predictions during the feature upsampling. Moreover, the Channel Feature Reassembly (CFR) with adjacent feature aggregation is designed to facilitate an iterative exploration of channel integrity. This iterative learning process enhances the interaction of neighboring channel features; thus, improving universal object information decoding efficiency. Extensive quantitative and qualitative evaluations demonstrate that our proposed UAFer consistently outperforms the state-of-the-art models across three challenging domains including SOD, COD, and polyp segmentation (POLYP). The implementation codes for our approach will be publicly available at https://github.com/zihaodong/UAFR.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Fu, M.
AU  - Song, W.
AU  - Yang, Y.
AU  - Alahi, A.
TI  - Dynamic Voxels Based on Ego-Conditioned Prediction: An Integrated Spatio-Temporal Framework for Motion Planning
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 10
SP  - 14973
EP  - 14985
DO  - 10.1109/TITS.2024.3398008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194083536&doi=10.1109%2fTITS.2024.3398008&partnerID=40&md5=d00fc0d75f9cbbcbbdea0f5e25d24901
AB  - Prediction is a vital component of motion planning for autonomous vehicles (AVs). By reasoning about the possible behavior of other target agents, the ego vehicle (EV) can navigate safely, efficiently, and politely. However, most of the existing work overlooks the interdependencies of the prediction and planning module, only connecting them in a sequential pipeline or underexploring the prediction results in the planning module. In this work, we propose a framework that integrates the prediction and planning module with three highlights. First, we propose an ego-conditioned model for causal prediction, with the introduced edge-featured graph transformer model, the impact the ego future maneuver poses to the target vehicles is demonstrated. Second, we develop a motion planner based on 'dynamic voxels' in the spatio-temporal domain, enabling the time-to-collision criterion evaluation and the optimal trajectory generation in continuous space. Third, the prediction and planning modules are coupled in a closed-loop and efficient form. Specifically, taking each maneuver as a cluster, representative trajectory primitives are generated for conditional prediction, and conversely, prediction results are used to score the primitives as guidance, which alleviates the duplicated callback of the prediction module. The simulations are conducted in overtaking, merging, unprotected left turns, and also scenarios with imperfect social behaviors. The comparison studies demonstrate the better safety assurance and efficiency of the proposed model, and the ablation experiments further reveal the effectiveness of the new ideas. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2024Dynamic
ER  -

TY  - JOUR
AU  - Ren, W.
AU  - Luo, J.
AU  - Jiang, W.
AU  - Qu, L.
AU  - Han, Z.
AU  - Tian, J.
AU  - Liu, H.
TI  - Learning Self- and Cross-Triplet Context Clues for Human-Object Interaction Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 10
SP  - 9760
EP  - 9773
DO  - 10.1109/TCSVT.2024.3402247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193523402&doi=10.1109%2fTCSVT.2024.3402247&partnerID=40&md5=7fb960c6d5c9041739d25dca36750232
AB  - Human-Object Interaction (HOI) detection aims to infer interactions between humans and objects, and it is very important for scene analysis and understanding. The existing methods usually focus on exploring instance-level (e.g., object appearance) or interaction-level (e.g., action semantic) features to conduct interaction prediction. However, most of these methods only consider the self-triplet feature aggregation, which may lead to learning ambiguity without exploring the cross-triplet context exchange. In this paper, from both visual and textual perspectives, we propose a novel method to jointly explore self- and cross-triplet interaction context clues for HOI detection. First, we employ a graph neural network to perform self-triplet aggregation, where human and object features represent graph nodes and visual interaction feature and textual prior knowledge are acted as two different edges. Furthermore, we also attempt to explore cross-triplet context exchange by incorporating symbiotic and layout relationships among different HOI triplets. Extensive experiments on two benchmarks demonstrate that our proposed method outperforms the state-of-the-art ones and achieves the impressive performance of 40.32 mAP on HICO-DET and 69.1 mAP on V-COCO datasets, respectively. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Chang, F.
AU  - Liu, C.
AU  - Wang, B.
AU  - Liu, Z.
TI  - TODO-Net: Temporally Observed Domain Contrastive Network for 3-D Early Action Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 12
DO  - 10.1109/TNNLS.2024.3394254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193282923&doi=10.1109%2fTNNLS.2024.3394254&partnerID=40&md5=ccf32e71bf56d65b37daac4975d2cebd
AB  - Early action prediction aiming to recognize which classes the actions belong to before they are fully conveyed is a very challenging task, owing to the insufficient discrimination information caused by the domain gaps among different temporally observed domains. Most of the existing approaches focus on using fully observed temporal domains to &#x201C;guide&#x201D; the partially observed domains while ignoring the discrepancies between the harder low-observed temporal domains and the easier highly observed temporal domains. The recognition models tend to learn the easier samples from the highly observed temporal domains and may lead to significant performance drops on low-observed temporal domains. Therefore, in this article, we propose a novel temporally observed domain contrastive network, namely, TODO-Net, to explicitly mine the discrimination information from the hard actions samples from the low-observed temporal domains by mitigating the domain gaps among various temporally observed domains for 3-D early action prediction. More specifically, the proposed TODO-Net is able to mine the relationship between the low-observed sequences and all the highly observed sequences belonging to the same action category to boost the recognition performance of the hard samples with fewer observed frames. We also introduce a temporal domain conditioned supervised contrastive (TD-conditioned SupCon) learning scheme to empower our TODO-Net with the ability to minimize the gaps between the temporal domains within the same action categories, meanwhile pushing apart the temporal domains belonging to different action classes. We conduct extensive experiments on two public 3-D skeleton-based activity datasets, and the results show the efficacy of the proposed TODO-Net. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Zhang, S.
AU  - Mao, Y.
AU  - Yeung, L.K.
AU  - Clerckx, B.
AU  - Quek, T.Q.S.
TI  - Transformer-Based Channel Prediction for Rate-Splitting Multiple Access-Enabled Vehicle-to-Everything Communication
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 10
SP  - 12717
EP  - 12730
DO  - 10.1109/TWC.2024.3395670
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192720869&doi=10.1109%2fTWC.2024.3395670&partnerID=40&md5=ced6400b95f1a3be86660eb6c0a4576c
AB  - The growth of vehicular applications will inevitably require Base Stations (BSs) to simultaneously serve more Connected Vehicles (CVs) within limited bandwidth resources, which imposes a great challenge in interference management. Effective management of this interference is crucial for reliable Vehicle-to-Everything (V2X) communication, and necessitates accurate Channel State Information at the Transmitter (CSIT). In practice, the dynamic and unpredictable nature of CV movements prevents BS from obtaining perfect CSIT, leading to outdated information and threatening communication performance. In this study, we propose a Rate-Splitting Multiple Access (RSMA)-enabled V2X communication system to efficiently manage interference channels. We leverage a 1-layer RSMA scheme to relax the stringent requirement for perfect CSIT and enhance robustness to outdated information. Furthermore, we introduce Gruformer, a transformer-based model for improved CSIT prediction utilizing historical data. While longer forecasting horizons decrease accuracy, we present a game theory-based approach that significantly reduces processing time for power allocation, enabling timely decisions before CSIT becomes outdated. Simulation results reveal that Gruformer allows for more accurate predictions during rapid changes in channel conditions. Leveraging this high-quality CSIT, the proposed V2X system achieves a 20% increase in Weighted Ergodic Sum-Rate (WESR). Furthermore, the game theory-based approach delivers a 60% reduction in processing time while maintaining near-optimal performance. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lang, X.
AU  - Li, C.
AU  - Wang, M.
AU  - Li, X.
TI  - Semi-Supervised Seismic Impedance Inversion With Convolutional Neural Network and Lightweight Transformer
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4506511
SP  - 1
EP  - 11
DO  - 10.1109/TGRS.2024.3401225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193295327&doi=10.1109%2fTGRS.2024.3401225&partnerID=40&md5=1d171aa5d7594fb6d806a92e3b6fd9a2
AB  - Seismic impedance inversion has yielded significant results through the use of deep learning. Currently, convolutional module-based networks also achieve noteworthy results. However, deep learning requires a large amount of labeled data for training to enhance inversion accuracy. In addition, the deep learning method, being end-to-end, overlooks forward and adjoint problem knowledge during seismic impedance inversion and fails to integrate geophysical constraints. Therefore, this article proposes a semi-supervised deep learning method to address these issues. Specifically, this method includes an inverse model and a forward model. The inverse model, a deep learning fusion model named CLWTNet, combines a multiscale convolutional neural network (MSCNN) and a lightweight transformer. CLWTNet captures multiscale local and global information, addressing the limitations of traditional convolutional networks that only capture partial information due to their limited receptive fields. Moreover, CLWTNet uses dilated convolution, transposed self-attention, and residual modules to enhance computational efficiency and stability. The forward model, a 1-D convolutional network, generates seismic traces from predicted impedances. These traces are then compared with the input seismic traces to inform the learning process of the inverse model. This approach also mitigates the challenge of limited labeled data. Testing with the SEAM synthetic model and field data demonstrates that the prediction accuracy and lateral continuity of the network surpass that of similar neural networks. In field dataset tests, this network demonstrates superior performance over three similar networks in predicting impedance. The network is characterized by its excellent lateral continuity and high resolution. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xiao, S.
AU  - Zhang, S.
AU  - Huang, L.
AU  - Wang, W.-Q.
TI  - Trans-NLM Network for SAR Image Despeckling
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5211912
SP  - 1
EP  - 12
DO  - 10.1109/TGRS.2024.3397325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192756084&doi=10.1109%2fTGRS.2024.3397325&partnerID=40&md5=3fe531fd0bc1be21106d3ad49a534640
AB  - Image despeckling is important to synthetic aperture radar (SAR) image restoration and related downstream tasks. Because existing SAR image denoising algorithms are difficult to simultaneously achieve high performance, efficiency, and interpretability, in this article, we propose a new image denoising method, namely, Trans-NLM, which incorporates the Transformer architecture into traditional nonlocal means (NLMs) filtering-based denoising algorithm. In doing so, the SAR image despeckling performance is enhanced, while the algorithm interpretability is retained. First, each pixel and its surrounding pixels are simultaneously mapped to a high-dimensional space as a neighborhood matrix through a shallow fully connected layer. Then, positional encodings are added to the neighborhood matrix, which is further mapped to the internal vectors Key, Query, and Value. The final vector representation of each pixel is also calculated according to the multihead attention mechanism. Finally, the representation vector is passed through a shallow fully connected layer for data dimension reduction to predict the corresponding pixel value. Moreover, layer normalization and residual learning are applied to accelerate the convergence. Experiments on both simulated and real SAR data demonstrate that compared with representative denoising models, for example, NLM, fastNLM, SAR-CNN, CNN-NLM, and MONet, the proposed Trans-NLM exhibits better performance in despeckling enhancement and efficiency simultaneously, along with more explainable inference process and transfer learning capability.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tan, Z.
AU  - Zhang, L.
AU  - Lv, Y.
AU  - Ma, Y.
AU  - Lu, H.
TI  - GroupMorph: Medical Image Registration via Grouping Network With Contextual Fusion
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 11
SP  - 3807
EP  - 3819
DO  - 10.1109/TMI.2024.3400603
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193221227&doi=10.1109%2fTMI.2024.3400603&partnerID=40&md5=0501835175d42e26f683a7a0228c1800
AB  - Pyramid-based deformation decomposition is a promising registration framework, which gradually decomposes the deformation field into multi-resolution subfields for precise registration. However, most pyramid-based methods directly produce one subfield per resolution level, which does not fully depict the spatial deformation. In this paper, we propose a novel registration model, called GroupMorph. Different from typical pyramid-based methods, we adopt the grouping-combination strategy to predict deformation field at each resolution. Specifically, we perform group-wise correlation calculation to measure the similarities of grouped features. After that, n groups of deformation subfields with different receptive fields are predicted in parallel. By composing these subfields, a deformation field with multi-receptive field ranges is formed, which can effectively identify both large and small deformations. Meanwhile, a contextual fusion module is designed to fuse the contextual features and provide the inter-group information for the field estimator of the next level. By leveraging the inter-group correspondence, the synergy among deformation subfields is enhanced. Extensive experiments on four public datasets demonstrate the effectiveness of GroupMorph. Code is available at https://github.com/TVayne/GroupMorph. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lan, M.
AU  - Rong, F.
AU  - Jiao, H.
AU  - Gao, Z.
AU  - Zhang, L.
TI  - Language Query-Based Transformer With Multiscale Cross-Modal Alignment for Visual Grounding on Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5626513
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2024.3407598
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194832770&doi=10.1109%2fTGRS.2024.3407598&partnerID=40&md5=23833284102fb23794388c59a4eba4fe
AB  - Visual grounding for remote sensing images (RSVG) aims to localize the referred objects in the remote sensing (RS) images according to a language expression. Existing methods tend to align visual and text features followed by concatenation and then employ a fusion Transformer to learn a token representation for final target localization. However, simple fusion Transformer structure fails to sufficiently learn the location representation of referred object from the multimodal features. Inspired by the detection transformer (DETR), in this article, we propose a novel language query-based Transformer framework for RSVG termed LQVG. Specifically, we adopt the extracted sentence-level text features as the queries, called language queries, to retrieve and aggregate representation information of the referred object from the multiscale visual features in the Transformer decoder. The language queries are then converted into object embeddings for final coordinate prediction of referred object. Besides, a multiscale cross-modal alignment (MSCMA) module is devised before the multimodal Transformer to enhance the semantic correlation between the visual and text features, thus facilitating the cross-modal decoding process to generate more precise object representation. Moreover, a new RSVG dataset named RSVG-HR is built to evaluate the performance of the RSVG approaches on very high-resolution RS images with inconspicuous objects. Experimental results on two benchmark datasets demonstrate that our proposed method significantly surpasses the comparison methods and achieves state-of-the-art performance. The dataset and code are available at https://github.com/LANMNG/LQVG.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, X.
AU  - Wang, Y.
AU  - Wang, Y.
TI  - Symbolic Music Generation From Graph-Learning-Based Preference Modeling and Textual Queries
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 10545
EP  - 10558
DO  - 10.1109/TMM.2024.3408060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194872283&doi=10.1109%2fTMM.2024.3408060&partnerID=40&md5=c784edfae63eb858c43a6a33c590e8bc
AB  - This paper investigates the domain of automatic music generation (AMG) and its capacity to produce music that is aligned with user preferences. The incorporation of user music preference (UMP) awareness in AMG technology has the potential to reduce reliance on musicians and domain experts while encouraging users to engage in activities that promote human health and potential. Current research in AMG has been limited to the qualitative control of a constrained set of attributes in the generated music such as selecting a genre from a given list. This constraint makes it challenging to develop music that is both aligned with UMP and suitable for practical text query-based applications. To address this challenge, we propose to apply deep-graph-networks on music community data, jointly modeling UMP and music features. Moreover, users’ textual descriptions of expected music can be transformed into graphs that are compatible with UMPs. Node embeddings representing user queries’ connotation are extracted to condition the music generator. The results on objective and subjective metrics demonstrate a significant improvement in UMP accuracy by 31.3%, UMP-aware AMG by 63.5%, and text-to-music AMG effectiveness by 76.5%. Our detailed analysis indicates that the generated music aligns best with queries comprised of short sentences and commonly used words. © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Liang, F.
AU  - Chen, L.
AU  - Liu, H.
AU  - Song, Q.
AU  - Vivone, G.
AU  - Chanussot, J.
TI  - MeSAM: Multiscale Enhanced Segment Anything Model for Optical Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5623515
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3398038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192779563&doi=10.1109%2fTGRS.2024.3398038&partnerID=40&md5=cb106d7cbcbeaa0c559af3ab56d6e938
AB  - Segment anything model (SAM) has been widely applied to various downstream tasks for its excellent performance and generalization capability. However, SAM exhibits three limitations related to remote sensing (RS) semantic segmentation task: 1) the image encoders excessively lose high-frequency information, such as object boundaries and textures, resulting in rough segmentation masks; 2) due to being trained on natural images, SAM faces difficulty in accurately recognizing objects with large-scale variations and uneven distribution in RS images; and 3) the output tokens used for mask prediction are trained on natural images and not applicable to RS image segmentation. In this article, we explore an efficient paradigm for applying SAM to the semantic segmentation of RS images. Furthermore, we propose multiscale enhanced SAM (MeSAM), a new SAM fine-tuning method more suitable for RS images to adapt it to semantic segmentation tasks. Our method first introduces an inception mixer into the image encoder to effectively preserve high-frequency features. Second, by designing a mask decoder with RS correction and incorporating multiscale connections, we make up the difference in SAM from natural images to RS images. Experimental results demonstrated that our method significantly improves the segmentation accuracy of SAM for RS images, outperforming some state-of-the-art (SOTA) methods. The code will be available at https://github.com/Magic-lem/MeSAM. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tao, C.
AU  - Wang, C.
AU  - Lin, S.
AU  - Cai, S.
AU  - Li, D.
AU  - Qian, J.
TI  - Feature Reconstruction With Disruption for Unsupervised Video Anomaly Detection
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 10160
EP  - 10173
DO  - 10.1109/TMM.2024.3405716
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194847809&doi=10.1109%2fTMM.2024.3405716&partnerID=40&md5=9c81ffc47fb4bf4eef5755d2ff7eb920
AB  - Unsupervised video anomaly detection (UVAD) has gained significant attention due to its label-free nature. Typically, UVAD methods can be categorized into two branches, i.e. the one-class classification (OCC) methods and fully UVAD ones. However, the former may suffer from data imbalance and high false alarm rates, while the latter relies heavily on feature representation and pseudo-labels. In this paper, a novel feature reconstruction and disruption model (FRD-UVAD) is proposed for effective feature refinement and better pseudo-label generation in fully UVAD, based on cascade cross-attention transformers, a latent anomaly memory bank and an auxiliary scorer. The clip features are reconstructed using the space-time intra-clip information, as well as cross-inter-clip knowledge. Moreover, instead of blindly reconstructing all training features as OCC methods, a new disruption process is proposed to cooperate with the feature reconstruction simultaneously. Using the collected pseudo anomaly samples, it is able to emphasize the feature differences between normal and abnormal events. Additionally, a pre-trained UVAD scorer is utilized as a different criteria for anomaly prediction, which further refines the pseudo-labels. To demonstrate its effectiveness, comprehensive experiments and detailed ablation studies are conducted on three video benchmarks, namely CUHK Avenue, ShanghaiTech and UCF-Crime. Our proposed model (FRD-UVAD) achieves the best AUC performance (91.23%, 80.14%, and 82.12%) on all three datasets, surpassing other state-of-the-art OCC and fully UVAD methods. Furthermore, it obtains the lowest false alarm rate with a lower scene dependency, compared with other OCC methods. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, L.
AU  - Lu, W.
AU  - Yu, H.
AU  - Mao, Y.
AU  - Bi, H.
AU  - Liu, C.
AU  - Sun, X.
AU  - Fu, K.
TI  - TAFormer: A Unified Target-Aware Transformer for Video and Motion Joint Prediction in Aerial Scenes
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4705016
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2024.3398374
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192732525&doi=10.1109%2fTGRS.2024.3398374&partnerID=40&md5=256d82c95c9087504e1f8b165c786a4c
AB  - As drone technology advances, using unmanned aerial vehicles for aerial surveys has become the dominant trend in modern low-altitude remote sensing. The surge in aerial video data necessitates accurate prediction for future scenarios and motion states of the interested target, particularly in applications like traffic management and disaster response. Existing video prediction methods focus solely on predicting future scenes (video frames), suffering from the neglect of explicitly modeling the target's motion states, which is crucial for aerial video interpretation. To address this issue, we introduce a novel task called target-aware aerial video prediction, aiming to simultaneously predict future scenes and motion states of the target. Furthermore, we designed a model specifically for this task, named TAFormer, which provides a unified modeling approach for both video and target motion states. Specifically, we introduce spatiotemporal attention (STA), which decouples the learning of video dynamics into spatial static attention and temporal dynamic attention, effectively modeling the scene's appearance and motion. In addition, we design an information-sharing mechanism (ISM), which elegantly unifies the modeling of video and target motion by facilitating information interaction through two sets of messenger tokens. Moreover, to alleviate the difficulty of distinguishing targets in blurry predictions, we introduce target-sensitive Gaussian loss (TSGL), enhancing the model's sensitivity to both the target's position and content. Extensive experiments on UAV123VP and VisDroneVP (derived from single-object tracking datasets) demonstrate the exceptional performance of TAFormer in target-aware video prediction, showcasing its adaptability to the additional requirements of aerial video interpretation for target awareness.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Du, J.
AU  - Ma, L.
AU  - Li, J.
AU  - Qin, N.
AU  - Zelek, J.
AU  - Guan, H.
AU  - Li, J.
TI  - RdmkNet & Toronto-RDMK: Large-Scale Datasets for Road Marking Classification and Segmentation
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 10
SP  - 13467
EP  - 13482
DO  - 10.1109/TITS.2024.3394481
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192987732&doi=10.1109%2fTITS.2024.3394481&partnerID=40&md5=f6b264f9836e40a0fef5f643ff40a966
AB  - Effective road marking classification and segmentation play a pivotal role in advancing vehicle-to-everything (V2X) applications and refining road inventory databases. However, the irregular data formats and unordered permutation modes of 3D point clouds, along with the limited availability of large-scale datasets with point-level annotations, remain significant obstacles to designing deep learning-based networks with superior performance. To address these challenges, this paper proposes a novel multi-level feature optimization network structure, named MFPNet, and introduces two point cloud benchmarks, RdmkNet and Toronto-Rdmk, for road marking classification and segmentation in intricate urban environments. MFPNet is composed of three integral modules. First, the M-transformer module, consisting of three transformers obtained from different channels, fully captures rich point cloud background information and long-distance dependencies between objects. Then, the feature pooling aggregation module uses parallel structured pooling attention mechanisms to aggregate features captured by the M-transformer module, while the prediction refinement module further enhances the acquisition of semantic features. Comparative studies indicate that MFPNet can be embedded into general deep learning networks without changing their original network structures, significantly improving the accuracy of multiple baseline networks. Furthermore, extensive experiments demonstrate that the two newly-developed point cloud datasets are meaningful for road marking classification and segmentation tasks, contributing to the development of autonomous driving.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Du2024RdmkNet
ER  -

TY  - JOUR
AU  - Jin, J.
AU  - Lu, W.
AU  - Yu, H.
AU  - Rong, X.
AU  - Sun, X.
AU  - Wu, Y.
TI  - Dynamic and Adaptive Self-Training for Semi-Supervised Remote Sensing Image Semantic Segmentation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5639814
DO  - 10.1109/TGRS.2024.3407142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194883811&doi=10.1109%2fTGRS.2024.3407142&partnerID=40&md5=06e58edc74fa105bee90034a6e4297a1
AB  - Remote sensing (RS) technology has made remarkable progress, providing a wealth of data for various applications, such as ecological conservation and urban planning. However, the meticulous annotation of this data is labor-intensive, leading to a shortage of labeled data, particularly in tasks like semantic segmentation. Semi-supervised methods, combining consistency regularization (CR) with self-Training, offer a solution to efficiently utilize labeled and unlabeled data. However, these methods encounter challenges due to imbalanced data ratios. To tackle these challenges, we introduce a self-Training approach named dynamic and adaptive self-Training (DAST), which is combined with dynamic pseudo-label sampling (DPS), distribution matching (DM), and adaptive threshold updating (ATU). DPS is tailored to address the issue of class distribution imbalance by giving priority to classes with fewer samples. Meanwhile, DM and ATU aim to reduce distribution disparities by adjusting model predictions across augmented images within the framework of CR, ensuring they align with the actual data distribution. Experimental results on the Potsdam and iSAID datasets demonstrate that DAST effectively balances class distribution, aligns model predictions with data distribution, and stabilizes pseudo-labels, leading to state-of-The-Art performance on both datasets. These findings highlight the potential of DAST in overcoming the challenges associated with significant disparities in labeled-To-unlabeled data ratios. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mandalis, P.
AU  - Chondrodima, E.
AU  - Kontoulis, Y.
AU  - Pelekis, N.
AU  - Theodoridis, Y.
TI  - A transformer-based method for vessel traffic flow forecasting
PY  - 2024
T2  - GeoInformatica
DO  - 10.1007/s10707-024-00521-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194703925&doi=10.1007%2fs10707-024-00521-z&partnerID=40&md5=a0ed0a0963c0405787468c7bb5898c36
AB  - In recent years, the maritime domain has experienced tremendous growth due to the exploitation of big traffic data. Particular emphasis has been placed on deep learning methodologies for decision-making. Accurate Vessel Traffic Flow Forecasting (VTFF) is essential for optimizing navigation efficiency and proactively managing maritime operations. In this work, we present a distributed Unified Approach for VTFF (dUA-VTFF), which employs Transformer models and leverages the Apache Spark big data distributed processing framework to learn from historical maritime data and predict future traffic flows over a time horizon of up to 30 min. Particularly, dUA-VTFF leverages vessel timestamped locations along with future vessel locations produced by a Vessel Route Forecasting model. These data are arranged into a spatiotemporal grid to formulate the traffic flows. Subsequently, through the Apache Spark, each grid cell is allocated to a computing node, where appropriately designed Transformer-based models forecast traffic flows in a distributed framework. Experimental evaluations conducted on real Automatic Identification System (AIS) datasets demonstrate the improved efficiency of the dUA-VTFF compared to state-of-the-art traffic flow forecasting methods. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, C.
AU  - Zhao, J.
AU  - Bo, C.
AU  - Li, S.
AU  - Wang, D.
AU  - Lu, H.
TI  - LGTrack: Exploiting Local and Global Properties for Robust Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 9
SP  - 8161
EP  - 8171
DO  - 10.1109/TCSVT.2024.3390054
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190750339&doi=10.1109%2fTCSVT.2024.3390054&partnerID=40&md5=7faca81884277d463c2c34bb114f6c48
AB  - Re-detection is a necessary capability for long-term tracking. Target candidate proposals in the whole image can provide a chance of tracking reset when tracking fails due to tracking drift or target invisibility. In this paper, we propose a unified local-global tracker based on the same transformer architecture sharing weights, which can not only search in a continuous local region but also provide target candidates of the global image in every frame. The requirements of both long-term and short-term scenarios can be addressed using a unified model. A simple proposal selection scheme is adopted to properly select the candidate proposals of re-detection, to assist tracking and obtain better performance. The scheme performs re-evaluation of all high-quality proposals based on a transformer-based embedding network, once the predicted state of the local tracking is not sufficient to be accurate. To capture appearance variations brought by online updates in minimum risks, a long-term-friendly dynamic template update scheme is also designed. Extensive experiments are conducted to demonstrate the effectiveness of our proposed tracker, including three short-term tracking benchmarks and six long-term benchmarks. Our tracker can achieve results comparable to that of the state-of-the-art. The proposed tracker can also work well in balancing the performance and speed, achieving an average speed of approximately 25 fps tested on LaSOT testing set.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Li, X.
AU  - Lin, K.
AU  - Luo, C.
AU  - Ye, Y.
AU  - Hu, X.
TI  - Multiscale and Multilevel Feature Fusion Network for Quantitative Precipitation Estimation With Passive Microwave
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4205916
DO  - 10.1109/TGRS.2024.3396379
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192171718&doi=10.1109%2fTGRS.2024.3396379&partnerID=40&md5=e18f73bb389c52b6321c75ca69fd8ac0
AB  - Passive microwave (PMW) radiometers have been widely utilized for quantitative precipitation estimation (QPE) by leveraging the relationship between brightness temperature (Tb) and rain rate. Nevertheless, accurate precipitation estimation remains a challenge due to the intricate relationship between them, which is influenced by a diverse range of complex atmospheric and surface properties. In addition, the inherent skew distribution of rainfall values prevents models from correctly addressing extreme precipitation events, leading to a significant underestimation. This article presents a novel model called the multiscale and multilevel feature fusion network (MSMLNet), consisting of two essential components: a multiscale feature extractor and a multilevel regression predictor. The feature extractor is specifically designed to extract characteristics from multiple scales, enabling the model to incorporate various meteorological conditions, as well as atmospheric and surface information in the surrounding environment. The regression predictor first assesses the probabilities of multiple rainfall levels for each observed pixel and then extracts features of different levels separately. The multilevel features are fused according to the predicted probabilities. This approach allows each submodule only to focus on a specific range of precipitation, avoiding the undesirable effects of skew distributions. To evaluate the performance of MSMLNet, various deep learning methods are adapted for the precipitation retrieval task, and a PWM-based product from the global precipitation measurement (GPM) mission is also used for comparison. Extensive experiments show that MSMLNet surpasses GMI-based products and the most advanced deep learning approaches by 17.9% and 2.5% in root mean square error (RMSE), and 54.2% and 4.0% in CSI-10, respectively. Moreover, we demonstrate that MSMLNet significantly mitigates the propensity for underestimating heavy precipitation events and has a consistent and outstanding performance in estimating precipitation across various levels. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, G.
AU  - Zhao, Y.
AU  - Lu, G.
TI  - Improving Representation With Hierarchical Contrastive Learning for Emotion-Cause Pair Extraction
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 4
SP  - 1997
EP  - 2011
DO  - 10.1109/TAFFC.2024.3391854
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192171397&doi=10.1109%2fTAFFC.2024.3391854&partnerID=40&md5=a03805cc6b41afbe72bc9671a85ccf60
AB  - Emotion-cause pair extraction (ECPE) aims to extract emotions and their corresponding cause from a document. The previous works have made great progress. However, there exist two major issues in existing works. First, most existing works mainly focus on the semantic relation between the emotion clause and cause clause, ignoring their inner statistical relation in representation space. Second, the existing works are sensitive to the relative position between the emotion clause and cause clause, which damages the model's robustness. To address the two issues, we propose a hierarchical contrastive learning framework (HCL-ECPE), which hierarchically performs contrastive learning on representation from two levels. The first level is inter-clause contrastive learning (ICCL), which performs between emotion clause and cause clause through mutual information maximization. The second level is intra-pair contrastive learning (IPCL), which performs between clause representation and pair representation through contrastive predictive coding (CPC). HCL-ECPE integrates ICCL and IPCL modules to explore the statistical relations between the emotion clause, cause clause, and their constructed emotion-cause pair from the perspective of mutual information, thereby improving the model performance and robustness. Experimental results on two public datasets, ECPED and RECCON, demonstrate that HCL-ECPE outperforms the most competitive baselines. Furthermore, ICCL and IPCL are orthogonal to the existing model, and introducing them into the current models updates state-of-the-art performance. © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Li, W.
AU  - Ruan, Y.-P.
AU  - Shu, Y.
AU  - Chen, J.
AU  - Li, Y.
AU  - Yu, C.
AU  - Zhang, Y.
AU  - Guan, J.
AU  - Zhou, S.
TI  - Weakly Correlated Multimodal Sentiment Analysis: New Dataset and Topic-Oriented Model
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 4
SP  - 2070
EP  - 2082
DO  - 10.1109/TAFFC.2024.3396144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192188701&doi=10.1109%2fTAFFC.2024.3396144&partnerID=40&md5=1d80346613cc4c095355bfe734a8b46a
AB  - Existing multimodal sentiment analysis models focus more on fusing highly correlated image-text pairs, and thus achieves unsatisfactory performance on multimodal social media data which usually manifests weak correlations between different modalities. To address this issue, we first build a large multimodal social media sentiment analysis dataset RU-Senti which contains more than 100,000 image-text pairs with sentiment labels. Then, we proposed a topic-oriented model (TOM) which assumes that text is usually related to a certain portion of the image contents and significant variances exist in sentiment distribution across diverse topics. TOM learns the topic information from textual content and designs a topic-oriented feature alignment module to extract textual semantics correlated information from images, thus achieving the alignment between two modalities. Then, TOM utilizes a transformer encoder initialized with the parameters from a pre-trained vision-language model to fuse the multimodal features for sentiment prediction. According to the experiments over the public MVSA-Multiple dataset and our RU-Senti dataset, RU-Senti is of high suitability for studying weakly correlated multimodal sentiment analysis, and the proposed TOM model also largely outperforms the SOTA mulitimodal sentiment analysis methods and pre-trained vision-language models. © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - He, H.
AU  - Zhang, Q.
AU  - Yi, K.
AU  - Shi, K.
AU  - Niu, Z.
AU  - Cao, L.
TI  - Distributional Drift Adaptation With Temporal Conditional Variational Autoencoder for Multivariate Time Series Forecasting
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 15
DO  - 10.1109/TNNLS.2024.3384842
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192216508&doi=10.1109%2fTNNLS.2024.3384842&partnerID=40&md5=7ce63f1cb5bc4379e1d109be50aa58d6
AB  - Due to the nonstationary nature, the distribution of real-world multivariate time series (MTS) changes over time, which is known as <italic>distribution drift</italic>. Most existing MTS forecasting models greatly suffer from distribution drift and degrade the forecasting performance over time. Existing methods address distribution drift via adapting to the latest arrived data or self-correcting per the meta knowledge derived from future data. Despite their great success in MTS forecasting, these methods hardly capture the intrinsic distribution changes, especially from a distributional perspective. Accordingly, we propose a novel framework temporal conditional variational autoencoder (TCVAE) to model the dynamic distributional dependencies over time between historical observations and future data in MTSs and infer the dependencies as a temporal conditional distribution to leverage latent variables. Specifically, a novel temporal Hawkes attention (THA) mechanism represents temporal factors that subsequently fed into feedforward networks to estimate the prior Gaussian distribution of latent variables. The representation of temporal factors further dynamically adjusts the structures of Transformer-based encoder and decoder to distribution changes by leveraging a gated attention mechanism (GAM). Moreover, we introduce conditional continuous normalization flow (CCNF) to transform the prior Gaussian to a complex and form-free distribution to facilitate flexible inference of the temporal conditional distribution. Extensive experiments conducted on six real-world MTS datasets demonstrate the TCVAE&#x2019;s superior robustness and effectiveness over the state-of-the-art MTS forecasting baselines. We further illustrate the TCVAE applicability through multifaceted case studies and visualization in real-world scenarios. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, Q.
AU  - Pang, Y.
AU  - Zhou, X.
AU  - Liu, Y.
TI  - PIGAT: Physics-Informed Graph Attention Transformer for Air Traffic State Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 12561
EP  - 12577
DO  - 10.1109/TITS.2024.3386128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190773704&doi=10.1109%2fTITS.2024.3386128&partnerID=40&md5=8b7a553d5510977517db4ffd795cb500
AB  - Efficient and resilient traffic management relies on accurate prediction of air traffic states. However, the complex spatial-temporal dependencies of air traffic networks make this task challenging. To address this issue, we propose a novel deep learning framework, named Physics-Informed Graph Attention Transformer (PIGAT), which leverages real-world data and knowledge to predict essential air traffic state parameters. Our approach utilizes fine-grained traffic state detection to extract critical features from aviation databases. The model employs GAT-based spatial learning blocks with temporal Transformers to capture the dynamic spatial-temporal dependencies of data. A dynamic graph generator layer is also utilized to update the airport network's topological structure adaptively, strengthening the model prediction's effectiveness. Furthermore, the fluid queuing-theoretic PDEs are incorporated into the loss function, enhancing the model's interpretability and reliability. Our framework is evaluated on real-world air traffic datasets from 36 major airport hubs within the US. Experimental results demonstrate that our proposed framework efficiently makes accurate predictions and outperforms eight baselines. In conclusion, our proposed framework has the potential to be applied in real-time decision-making systems for air traffic management and provides promising directions for future research. The code for our project is available at: https://github.com/ymlasu/para-atm-collection/tree/master/air-traffic-prediction/PIGAT.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2024PIGAT
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, M.
AU  - Liu, Y.
TI  - Target Detection With Spectral Graph Contrast Clustering Assignment and Spectral Graph Transformer in Hyperspectral Imagery
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5516916
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2024.3394616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192171105&doi=10.1109%2fTGRS.2024.3394616&partnerID=40&md5=ea92df87397a9fdd4a03616f5132d8a8
AB  - Hyperspectral target detection (HTD) is a method that recognizes objects of interest in a scene by a priori target spectrum. Local details and global information on the spectra are critical for accurate target identification. Detectors with excellent discrimination of spectral differences can better highlight targets while suppressing background. To this end, this article proposes an HTD method based on spectral graph contrast clustering assignment and the spectral graph transformer (SGT) to solve these problems. Specifically, for local-global feature extraction of spectra, the pixel spectra are first constructed as the spectral graph. Then, the representations of the first- or higher-order neighbors of the nodes in the spectral graph are aggregated using graph convolutional networks to extract the local detail information of the spectra. The self-attention in Transformer is utilized to learn the global information of the spectra. Second, a novel spectral graph contrast clustering assignment method is proposed to equip the model with excellent spectral discrimination ability. It maintains clustering consistency by swapping predictive clustering assignments while maximizing the similarity of semantically similar graph clusters and keeping other semantically different graph clusters away from them to better discriminate differences between spectra. Finally, comparisons with seven state-of-the-art HTD methods on four real hyperspectral datasets and ablation studies verify the effectiveness of the proposed method in HTD. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, W.
AU  - Peng, Z.
AU  - Dong, L.
AU  - Wei, F.
AU  - Ye, Q.
AU  - Jiao, J.
TI  - Generic-to-Specific Distillation of Masked Autoencoders
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 9
SP  - 8779
EP  - 8793
DO  - 10.1109/TCSVT.2024.3393474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191738916&doi=10.1109%2fTCSVT.2024.3393474&partnerID=40&md5=e8d5e60febf6db1f2b6f0cac3f5648f9
AB  - To transfer the representation capacity of large pre-trained models to lightweight models, knowledge distillation has been widely explored. However, conventional single-stage distillation methods are prone to getting stuck in the transfer of task-specific knowledge, making it difficult to retain task-agnostic knowledge which is crucial for model generalization. In this study, we propose generic-to-specific distillation (G2SD), to boost lightweight models under the assistance of large models pre-trained by masked image modeling. In generic distillation, the decoder of a small model is encouraged to align feature predictions with that of a large model, so that task-agnostic knowledge can be transferred. In specific distillation, predictions of the small model are encouraged to be consistent with those of the large model, to guarantee task performance. G2SD is also applicable for heterogeneous settings(i.e., distilling from ViT to CNN). With G2SD, the ViT-Small model respectively achieves 98.9%, 98.4%, 99.3% and 98.9% accuracies when compared with its teachers (ViT-Base) for image classification, object detection, semantic segmentation and video recognition tasks. The lightweight ResNet models are improved to a new height on image classification task. The code is available at github.com/pengzhiliang/G2SD.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, M.
AU  - Zhu, X.
AU  - Kao, Y.
AU  - Chen, Z.
AU  - Lyu, J.
AU  - Lei, Z.
TI  - Multi-Level Pixel-Wise Correspondence Learning for 6DoF Face Pose Estimation
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 9423
EP  - 9435
DO  - 10.1109/TMM.2024.3391888
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191328802&doi=10.1109%2fTMM.2024.3391888&partnerID=40&md5=322fba04b440d8913b9a57a6eefdba29
AB  - In this paper, we focus on estimating six degrees of freedom (6DoF) pose of a face from a single RGB image, which is an important but under-investigated problem in 3D face applications such as face reconstruction, forgery detection and virtual try-on. This problem is different from traditional face pose estimation and 3D face reconstruction since the distance from camera to face should be estimated, which can not be directly regressed due to the non-linearity of the pose space. To solve the problem, we follow Perspective-n-Point (PnP) and predict the correspondences between 3D points in canonical space and 2D facial pixels on the input image to solve the 6DoF pose parameters. In this framework, the central problem of 6DoF estimation is building the correspondence matrix between a set of sampled 2D pixels and 3D points, and we propose a Correspondence Learning Transformer (CLT) to achieve this goal. Specifically, we build the 2D and 3D features with local, global, and semantic information, and employ self-attention to make the 2D and 3D features interact with each other and build the 2D-3D correspondence. Besides, we argue that 6DoF estimation is not only related with face appearance itself but also the facial external context, which contains rich information about the distance to camera. Therefore, we extract global-and-local features from the integration of face and context, where the cropped face image with smaller receptive fields concentrates on the small distortion by perspective projection, and the whole image with large receptive field provides shoulder and environment information. Experiments show that our method achieves a 2.0% improvement of MAEr and ADD on ARKitFace and a 4.0%/0.7% improvement of MAEt on ARKitFace/BIWI.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Han, Z.
AU  - Fu, Z.
AU  - Chen, S.
AU  - Hui, L.
AU  - Li, G.
AU  - Yang, J.
AU  - Chen, C.W.
TI  - ZS-VAT: Learning Unbiased Attribute Knowledge for Zero-Shot Recognition Through Visual Attribute Transformer
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 12
DO  - 10.1109/TNNLS.2024.3386935
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191313899&doi=10.1109%2fTNNLS.2024.3386935&partnerID=40&md5=ab0f9cab0c115bbda57206b284085772
AB  - In zero-shot learning (ZSL), attribute knowledge plays a vital role in transferring knowledge from seen classes to unseen classes. However, most existing ZSL methods learn biased attribute knowledge, which usually results in biased attribute prediction and a decline in zero-shot recognition performance. To solve this problem and learn unbiased attribute knowledge, we propose a visual attribute Transformer for zero-shot recognition (ZS-VAT), which is an effective and interpretable Transformer designed specifically for ZSL. In ZS-VAT, we design an attribute-head self-attention (AHSA) that is capable of learning unbiased attribute knowledge. Specifically, each attribute head in AHSA first transforms the local features into attribute-reinforced features and then accumulates the attribute knowledge from all corresponding reinforced features, reducing the mutual influence between attributes and avoiding information loss. AHSA finally preserves unbiased attribute knowledge through attribute embeddings. We also propose an attribute fusion model (AFM) that learns to recover the correct category knowledge from the attribute knowledge. In particular, AFM takes all features from AHSA as input and generates global embeddings. We carried out experiments to demonstrate that the attribute knowledge from AHSA and the category knowledge from AFM are able to assist each other. During the final semantic prediction, we combine the attribute embedding prediction (AEP) and global embedding prediction (GEP). We evaluated the proposed scheme on three benchmark datasets. ZS-VAT outperformed the state-of-the-art generalized ZSL (GZSL) methods on two datasets and achieved competitive results on the other dataset. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lim, S.
AU  - El-Basyouny, K.
AU  - Yang, Y.H.
TI  - PU-Ray: Domain-Independent Point Cloud Upsampling via Ray Marching on Neural Implicit Surface
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 10
SP  - 14600
EP  - 14610
DO  - 10.1109/TITS.2024.3388276
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191344426&doi=10.1109%2fTITS.2024.3388276&partnerID=40&md5=545190812f640dc3c170202fb7e577db
AB  - While recent advancements in deep-learning point cloud upsampling methods have improved the input to intelligent transportation systems, they still suffer from issues of domain dependency between synthetic and real-scanned point clouds. This paper addresses the above issues by proposing a new ray-based upsampling approach with an arbitrary rate, where a depth prediction is made for each query ray and its corresponding patch. Our novel method simulates the sphere-tracing ray marching algorithm on the neural implicit surface defined with an unsigned distance function (UDF) to achieve more precise and stable ray-depth predictions by training a point-transformer-based network. The rule-based mid-point query sampling method generates more evenly distributed points without requiring an end-to-end model trained using a nearest-neighbor-based reconstruction loss function, which may bias towards the training dataset. Self-supervised learning becomes possible with accurate ground truths within the input point cloud. The results demonstrate the method's versatility across domains and training scenarios with limited computational resources and training data. Comprehensive analyses of synthetic and real-scanned applications provide empirical evidence for the significance of the upsampling task across the computer vision and graphics domains to real-world applications of ITS.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Lim2024PU-Ray
ER  -

TY  - JOUR
AU  - Zhai, Y.
AU  - Li, W.
AU  - Xian, T.
AU  - Jia, X.
AU  - Zhang, H.
AU  - Tan, Z.
AU  - Zhou, J.
AU  - Zeng, J.
AU  - Philip Chen, C.L.
TI  - CAS-Net: Comparison-Based Attention Siamese Network for Change Detection With an Open High-Resolution UAV Image Dataset
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5619617
SP  - 1
EP  - 17
DO  - 10.1109/TGRS.2024.3386918
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190791941&doi=10.1109%2fTGRS.2024.3386918&partnerID=40&md5=d3cf453fdba099864dd28fcc00baac84
AB  - Change detection (CD) is a process of extracting changes on the Earth s surface from bitemporal images. Current CD methods that use high-resolution remote sensing images require extensive computational resources and are vulnerable to the presence of irrelevant noises in the images. In addressing these challenges, a comparison-based attention Siamese network (CAS-Net) is proposed. The network utilizes contrastive attention modules (CAMs) for feature fusion and employs a classifier to determine similarities and differences of bitemporal image patches. It simplifies pixel-level CDs by comparing image patches. As such, the influences of image background noises on change predictions are reduced. Along with the CAS-Net, an unmanned aerial vehicle (UAV) similarity detection (UAV-SD) dataset is built using high-resolution remote sensing images. This dataset, serving as a benchmark for CD, comprises 10 000 pairs of UAV images with a size of 256 × 256. Experiments of the CAS-Net on the UAV-SD dataset demonstrate that the CAS-Net is superior to other baseline CD networks. The CAS-Net detection accuracy is 93.1% on the UAV-SD dataset. The code and the dataset can be found at https://github.com/WenbaLi/CAS-Net  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, S.
AU  - Li, J.
AU  - Yang, J.
TI  - Pedestrian Crossing Intention Prediction Based on Cross-Modal Transformer and Uncertainty-Aware Multi-Task Learning for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 12538
EP  - 12549
DO  - 10.1109/TITS.2024.3386689
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191291992&doi=10.1109%2fTITS.2024.3386689&partnerID=40&md5=6dfda09332c3c4e5f3f31ed8aab97e8e
AB  - Accurate prediction of whether pedestrians will cross the street is prevalently recognized as an indispensable function of autonomous driving systems, especially in urban environments. How to utilize the complementary information present in different types of data (or modalities) is one of the major challenges. This paper makes the first attempt to develop a cross-modal transformer-based crossing intention prediction model merely using bounding boxes and ego-vehicle speed as input features. The cross-modal transformer can leverage self-attention and cross-modal attention to mine the modality-specific and complementary correlation. A bottleneck feature fusion is presented to obtain the compressed feature representation. To facilitate the network training, we further put forward a novel uncertainty-aware multi-task learning method that jointly predicts the future bounding box as well as crossing action such that the commonalities and differences across two tasks can be exploited. To evaluate the proposed method, extensive comparative experiments and ablation studies are performed on two benchmark datasets. The results demonstrate that by only using the bounding box and ego-vehicle speed as input features, our model is on a par with other state-of-the-art approaches that rely on more inputs, and even achieves superior performance in most cases. The source code will be released at https://github.com/xbchen82/PedCMT.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2024Pedestrian
ER  -

TY  - JOUR
AU  - Liu, M.
AU  - Liu, Y.
AU  - Xu, P.
AU  - Cui, H.
AU  - Ke, J.
AU  - Ma, J.
TI  - Exploiting Geometric Features via Hierarchical Graph Pyramid Transformer for Cancer Diagnosis Using Histopathological Images
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 8
SP  - 2888
EP  - 2900
DO  - 10.1109/TMI.2024.3381994
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189362405&doi=10.1109%2fTMI.2024.3381994&partnerID=40&md5=123ac997433e5879931f8011f2e6aee7
AB  - Cancer is widely recognized as the primary cause of mortality worldwide, and pathology analysis plays a pivotal role in achieving accurate cancer diagnosis. The intricate representation of features in histopathological images encompasses abundant information crucial for disease diagnosis, regarding cell appearance, tumor microenvironment, and geometric characteristics. However, recent deep learning methods have not adequately exploited geometric features for pathological image classification due to the absence of effective descriptors that can capture both cell distribution and gathering patterns, which often serve as potent indicators. In this paper, inspired by clinical practice, a Hierarchical Graph Pyramid Transformer (HGPT) is proposed to guide pathological image classification by effectively exploiting a geometric representation of tissue distribution which was ignored by existing state-of-the-art methods. First, a graph representation is constructed according to morphological feature of input pathological image and learn geometric representation through the proposed multi-head graph aggregator. Then, the image and its graph representation are feed into the transformer encoder layer to model long-range dependency. Finally, a locality feature enhancement block is designed to enhance the 2D local representation of feature embedding, which is not well explored in the existing vision transformers. An extensive experimental study is conducted on Kather-5K, MHIST, NCT-CRC-HE, and GasHisSDB for binary or multi-category classification of multiple cancer types. Results demonstrated that our method is capable of consistently reaching superior classification outcomes for histopathological images, which provide an effective diagnostic tool for malignant tumors in clinical practice.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Long, F.
AU  - Qiu, Z.
AU  - Yao, T.
AU  - Zhou, W.
AU  - Luo, J.
AU  - Mei, T.
TI  - Learning 3D Shape Latent for Point Cloud Completion
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 8717
EP  - 8729
DO  - 10.1109/TMM.2024.3381814
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189498206&doi=10.1109%2fTMM.2024.3381814&partnerID=40&md5=41170ad69223a6f7d8a909d232c8e579
AB  - By formulating the data generation as a sequence procedure of denoising autoencoding, diffusion models have achieved superior in-painting performance on image data and beyond. Nevertheless, it is not trivial when capitalizing on diffusion models to generate missing 3D points. The difficulty originates from the intrinsic structure where 3D point cloud is a set of unordered and irregular coordinates. That motivates us to delve into the 3D structural information for designing point cloud encoder-decoder and shape latent generator, to precisely formulate the latent distribution of the complete point cloud and partial observation. In this paper, we propose Point cloud completion with Latent Diffusion Models (PointLDM), a new approach that leverages the conditional denoising diffusion probabilistic modeling (DDPM) in the 3D latent space for shape reconstruction. The architecture of PointLDM consists of a transformer-based variational auto-encoder (VAE) to model the complete shape latent, and a diffusion network for shape latent prediction. The encoder of VAE exploits both of global shape latent and local point features in shape distribution learning. With the learnt shape latent, the decoder first decodes the shape latent into coarse points, and then recovers the fine-grained details around each coarse point by deforming a 2D grid. To reconstruct the shape latent from partial observation, the diffusion network treats the partial observation as the conditional input and generates the shape latent via DDPM. Extensive experiments conducted on MVP, Completion3D, and KITTI quantitatively and qualitatively demonstrate the efficacy of PointLDM over the state-of-the-art shape completion approaches.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, W.
AU  - Hu, Y.
AU  - Fu, H.
AU  - Yang, M.
AU  - Chng, C.-B.
AU  - Kawasaki, R.
AU  - Chui, C.
AU  - Liu, J.
TI  - Instrument-Tissue Interaction Detection Framework for Surgical Video Understanding
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 8
SP  - 2803
EP  - 2813
DO  - 10.1109/TMI.2024.3381209
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189361321&doi=10.1109%2fTMI.2024.3381209&partnerID=40&md5=a195e8a4aa1005853e5db7b7ce757bf2
AB  - Instrument-tissue interaction detection task, which helps understand surgical activities, is vital for constructing computer-assisted surgery systems but with many challenges. Firstly, most models represent instrument-tissue interaction in a coarse-grained way which only focuses on classification and lacks the ability to automatically detect instruments and tissues. Secondly, existing works do not fully consider relations between intra-and inter-frame of instruments and tissues. In the paper, we propose to represent instrument-tissue interaction as {instrument class, instrument bounding box, tissue class, tissue bounding box, action class} quintuple and present an Instrument-Tissue Interaction Detection Network (ITIDNet) to detect the quintuple for surgery videos understanding. Specifically, we propose a Snippet Consecutive Feature (SCF) Layer to enhance features by modeling relationships of proposals in the current frame using global context information in the video snippet. We also propose a Spatial Corresponding Attention (SCA) Layer to incorporate features of proposals between adjacent frames through spatial encoding. To reason relationships between instruments and tissues, a Temporal Graph (TG) Layer is proposed with intra-frame connections to exploit relationships between instruments and tissues in the same frame and inter-frame connections to model the temporal information for the same instance. For evaluation, we build a cataract surgery video (PhacoQ) dataset and a cholecystectomy surgery video (CholecQ) dataset. Experimental results demonstrate the promising performance of our model, which outperforms other state-of-the-art models on both datasets.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Wei, Z.
AU  - He, H.
AU  - Wei, H.
AU  - Li, S.
AU  - Gao, F.
TI  - Ensembled Traffic-Aware Transformer-Based Predictive Energy Management for Electrified Vehicles
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 12333
EP  - 12346
DO  - 10.1109/TITS.2024.3375331
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188932247&doi=10.1109%2fTITS.2024.3375331&partnerID=40&md5=62da0869b0d47990368fd96261d5f06b
AB  - The predictive energy management strategy (PEMS) offers potential advantages in enhancing the driving economy of electrified vehicles using vehicle speed prediction. However, realizing accurate predictions in practical contexts remains a challenge. Departing from conventional PEMS that rely on historical speed or static traffic data, we introduce a real-time traffic-aware PEMS for improved performance. To better understand the interplay between the host vehicle and its surrounding traffic, we use a Transformer network as the predictor that employs the speeds and relative distances of the surrounding six vehicles to forecast future speed sequences for the host vehicle. To augment this data-driven approach, we develop a dual-predictor strategy based on the deep ensemble technique. This strategy measures the Transformer's output uncertainty to gauge prediction reliability and introduce an automated threshold mechanism. Based on this threshold and real-time uncertainties, the strategy chooses between the Transformer and an exponential predictor to achieve improved prediction outcomes. A reinforcement learning method is integrated as the PEMS optimizer. For validation, we generate training data with traffic information based on the next generation simulation (NGSIM) dataset and create a test scenario in the SUMO simulator. The results confirm that speed predictions based on real-time traffic data surpass traditional PEMS, either directly inputting traffic data or excluding it. The Transformer predictor significantly outperforms the state-of-the-art predictor. Importantly, our dual-predictor design amplifies prediction accuracy by 27.2% against the standard single-network predictor under non-training conditions. Overall, our PEMS enhances driving economy by 11.1% relative to traffic-unaware models and 8.0% over non-Transformer schemes.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Wu2024Ensembled
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Chen, Y.
AU  - Xu, L.
AU  - Luo, J.
AU  - Huang, R.
AU  - Wu, F.
AU  - Miao, Y.
TI  - ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
SP  - 1
EP  - 1
DO  - 10.1109/TCSVT.2024.3378000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188504191&doi=10.1109%2fTCSVT.2024.3378000&partnerID=40&md5=9a9955a7712dab07be418647ff61c1d5
AB  - Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Chen, H.
AU  - Zhou, C.
AU  - Chen, K.
AU  - Liu, C.
AU  - Zou, Z.
AU  - Shi, Z.
TI  - BiFA: Remote Sensing Image Change Detection With Bitemporal Feature Alignment
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
SP  - 1
EP  - 17
DO  - 10.1109/TGRS.2024.3376673
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188457828&doi=10.1109%2fTGRS.2024.3376673&partnerID=40&md5=618af2335cf8ed656b2d495dd5c83270
AB  - Despite the success of deep learning-based change detection (CD) methods, their existing insufficiency in temporal (channel and spatial) and multiscale alignment has rendered them insufficient capability in mitigating external factors (illumination changes and perspective differences) arising from different imaging conditions during CD. In this article, a bitemporal feature alignment (BiFA) model is proposed to produce a precise CD map in a lightweight manner by reducing the impact of irrelevant factors. Specifically, for the temporal alignment, the bitemporal interaction (BI) module is proposed to realize the alignment of the bitemporal image channel level. Our intuition is introducing the BI in the feature extraction stage may benefit suppressing the interference, such as illumination changes. Simultaneously, the alignment module based on differential flow field (ADFF) is proposed to explicitly estimate the offset of the bitemporal image and realize their spatial level alignment to mitigate the inadequate registration resulting from different perspectives. Furthermore, for the multiscale alignment, we introduce the implicit neural alignment decoder (IND) to produce more refined prediction maps achieving precise alignment of multiscale features by learning continuous image representations in coordinate space. Our BiFA outperforms other state-of-the-art methods on six datasets (such as the F1-score (F1)/intersection over union (IoU) scores are improved by 2.70%/3.91% and 2.01%/2.94% on Learning, VIsion, and Remote sensing (LEVIR)+-CD and Sun Yat-sen University (SYSU)-CD, respectively) and displays greater robustness in cross-resolution CD. Our code is available at https://github.com/zmoka-zht/BiFA. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Hu, X.
TI  - TFRNet: Semantic Segmentation Network with Token Filtration and Refinement Method
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 8242
EP  - 8254
DO  - 10.1109/TMM.2024.3378465
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188527750&doi=10.1109%2fTMM.2024.3378465&partnerID=40&md5=d4df8729d3321c6a05b624bdd1c0bad4
AB  - —Transformer-based semantic segmentation has been developed rapidly. Vision transformer (ViT) rely on self-attention mechanism which employs all image patches to compute long-range dependencies. ViT considers all tokens equally important for self-attention calculation. Nevertheless, it has been proved that image tokens contribute differently to the final prediction. In this paper, we propose a token filtration method to select informative tokens. These informative tokens are then used to reweight token sequence so that important image tokens can be focused by transformer for more accurate prediction. Meanwhile, due to lack of local information, transformer-based segmentation usually has incomplete object structure and coarse boundaries. To this end, a segmentation refinement method is introduced to refine transformer segmentation results. The refinement method integrates transformer outputs with convolutional features of the input image to generate refined prediction. Finally, we introduce the token filtration and refinement network (TFRNet) which adopts the proposed token filtration method and the refinement method to improve segmentation performance. We evaluate the proposed TFRNet on the ADE20K and Cityscapes datasets. Experimental results show that the proposed method outperforms other state-of-the-art approaches. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Alam, S.
AU  - Cai, Q.
AU  - Delahaye, D.
TI  - Text-Enriched Air Traffic Flow Modeling and Prediction Using Transformers
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7963
EP  - 7976
DO  - 10.1109/TITS.2024.3379210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189817261&doi=10.1109%2fTITS.2024.3379210&partnerID=40&md5=58fdfa28a7bd37fef3ecb8d31c88f2b1
AB  - The air traffic control paradigm is shifting from sector-based operations to flow-centric approaches to overcome sectors' geographical limits. Modeling and predicting intersecting air traffic flows can assist controllers in flow coordination under the flow-centric paradigm. This paper proposes a flow-centric framework- TEMPT: Text-Enriched air traffic flow Modeling and Prediction using Transformers- to identify, represent, and predict intersecting flows in the airspace. Firstly, nominal flow intersections (NFI) are identified through hierarchical clustering of flight trajectory intersections. A flow pattern consistency-based graph analytics approach is proposed to determine the number of NFIs. Secondly, in contrast to the traditional traffic flow feature representation, i.e., numerical time series of flights, this paper proposes a text-enriched flow feature representation to intuitively describe the 'flow of flights' in the airspace. More specifically, air traffic flow features are described by a 'text paragraph' composed of the time and flight sequences transiting through the NFIs. Finally, a transformer neural network model is adopted to learn the text-enriched flow features and predict the future traffic demand at the NFIs during future time windows. An experimental study was carried out in French airspace to validate the efficacy of TEMPT using one-month ADS-B data in December 2019. Prediction results show that TEMPT outperforms the competitive air traffic flow modeling and prediction approaches: time-series-based Transformers, Long Short-term Memory (LSTM), and Graph Convolutional Networks (GCN), as well as aerodynamic trajectory simulation-based prediction and the historical average.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Ma2024Text-Enriched
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - He, X.
AU  - Jiao, Q.
AU  - Zhang, Q.
AU  - Han, J.
TI  - AMNet: Learning to Align Multi-Modality for RGB-T Tracking
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 7386
EP  - 7400
DO  - 10.1109/TCSVT.2024.3377471
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188539954&doi=10.1109%2fTCSVT.2024.3377471&partnerID=40&md5=d198a0c43dc36b98a7bf33a1e76b56c3
AB  - RGB-T tracking has attracted increasing attention recently due to the all-weather and all-day working capability. However, most current RGB-T trackers usually assume that RGB data and thermal infrared (TIR) data are well spatially aligned, which is difficult to be achieved in practice. Such spatial misalignment between RGB data and TIR data may lead to the ineffective cross-modal information propagation during multi-modal feature fusion, thus reducing the tracking performance. In addition, due to the discrepancy in imaging characteristics of RGB images and TIR images, there also exist great differences between the information captured by the two modality data. The differences in characteristics of RGB and TIR modalities in different local areas will cause a single fusion strategy to be unable to fully explore the complementary information within multi-modal data. For that, we propose an RGB-T tracker, referred to as AMNet, to specifically solve such two problems with two dedicated modules, i.e., a Mutual-interacted Spatial Alignment (MSA) module and an Information Matching Fusion (IMF) module. The former spatially aligns the two modality data through three essential parts, including interactions of multi-modal features, prediction of cross-modal offset map, and enhancement of the aligned features. While the latter first discriminates different types of local regions by employing several intra-modal attention modules and then uses a divide-and-conquer fusion strategy to exploit such discriminative information within RGB and TIR features of different cases for tracking. We validate the effectiveness of our AMNet with extensive experiments on three RGB-T benchmarks, which achieves new state-of-the-art performance. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yuan, S.
AU  - Chen, J.
AU  - Jiang, W.
AU  - Zhao, Z.
AU  - Guo, S.
TI  - LHNetV2: A Balanced Low-Cost Hybrid Network for Single Image Dehazing
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 8197
EP  - 8209
DO  - 10.1109/TMM.2024.3377133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188438897&doi=10.1109%2fTMM.2024.3377133&partnerID=40&md5=e8571549913afef6a25779b6fd1c67c0
AB  - Single-image dehazing is a challenging task that requires both local details and global distribution. Existing methods face challenges in color imbalance and inconsistent details when predicting a haze-free image, because of their limitations in generalization from a specific setting (physics-based methods), capturing global information (CNN-based methods) and capturing detailed local information (ViT-based methods). In response to these challenges, we propose a balanced low-cost hybrid network called LHNetV2 based on LHNetV1. The key insight of LHNetV2 is the effective fusion of different features, and a series of novel approaches is proposed to increase the running speed of the original LHNetV1. Firstly, building upon the Feature-aware Information Fusion method, we preserve the original Physical Embedding and Architecture Aggregation components in LHNetV1. Next, to overcome the speed bottleneck of LHNetV1, we enhance the calculation method of attention in the ViT sub-network and streamline the cross-stage interaction strategy in the CNN main-network. Finally, we introduce a dynamic adversarial loss function to bolster both the training stability and performance of LHNetV2. The experiments are extensively conducted on mainstream datasets, and the results demonstrate that LHNetV2 achieves the best balance between the performance and the running speed in single-image dehazing.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Li, C.
AU  - Zhong, L.
AU  - Chen, Z.
AU  - Yang, W.
AU  - Wang, X.
TI  - DoseDiff: Distance-Aware Diffusion Model for Dose Prediction in Radiotherapy
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 10
SP  - 3621
EP  - 3633
DO  - 10.1109/TMI.2024.3383423
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189619770&doi=10.1109%2fTMI.2024.3383423&partnerID=40&md5=44af9d29e8587c8bd215baf9ce33f51a
AB  - Treatment planning, which is a critical component of the radiotherapy workflow, is typically carried out by a medical physicist in a time-consuming trial-and-error manner. Previous studies have proposed knowledge-based or deep-learning-based methods for predicting dose distribution maps to assist medical physicists in improving the efficiency of treatment planning. However, these dose prediction methods usually fail to effectively utilize distance information between surrounding tissues and targets or organs-at-risk (OARs). Moreover, they are poor at maintaining the distribution characteristics of ray paths in the predicted dose distribution maps, resulting in a loss of valuable information. In this paper, we propose a distance-aware diffusion model (DoseDiff) for precise prediction of dose distribution. We define dose prediction as a sequence of denoising steps, wherein the predicted dose distribution map is generated with the conditions of the computed tomography (CT) image and signed distance maps (SDMs). The SDMs are obtained by distance transformation from the masks of targets or OARs, which provide the distance from each pixel in the image to the outline of the targets or OARs. We further propose a multi-encoder and multi-scale fusion network (MMFNet) that incorporates multi-scale and transformer-based fusion modules to enhance information fusion between the CT image and SDMs at the feature level. We evaluate our model on two in-house datasets and a public dataset, respectively. The results demonstrate that our DoseDiff method outperforms state-of-the-art dose prediction methods in terms of both quantitative performance and visual quality. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, L.
AU  - Li, C.
AU  - Jiao, L.
AU  - Li, L.
AU  - Liu, X.
AU  - Liu, F.
AU  - Yang, S.
AU  - Hou, B.
TI  - Lighter and Robust: A Rotation-Invariant Transformer for VHR Image Change Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4405914
SP  - 1
EP  - 14
DO  - 10.1109/TGRS.2024.3381971
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189348348&doi=10.1109%2fTGRS.2024.3381971&partnerID=40&md5=fbbb2a3b7b6c4188268556943bf470fd
AB  - In recent years, change detection (CD) has emerged as an increasingly intricate research domain. However, in natural images, the orientation of objects is often aligned with the image boundaries, whereas in RS images, the imaging angles are random. As a result, existing CD methods encounter limitations when effectively representing vector features. In this article, we propose a rotation-invariant CD architecture named RFormer. It effectively utilizes direction-sensitive position embedding (DSPE) to represent features in RS images. To address the challenge of the quadratic growth in attention mechanism complexity with sequence length, we introduce low-cost cross attention (LC2A) to reduce its complexity to 1/{C{2}}. Furthermore, we employ the implicit timing extraction process (TEP) to represent interframe bitemporal features. TEP plays a crucial role in mitigating prediction biases caused by seasonal changes in land cover and prevents overconfident discrimination by the classifier in CD tasks. Experimental results demonstrate that RFormer achieves competitive performance on WHU, deeply supervised image fusion network (DSIFN)-CD, CDD, and LEVIR-CD datasets. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kong, J.
AU  - Wang, J.
AU  - Yu, L.-C.
AU  - Zhang, X.
TI  - Multimodality Self-distillation for Fast Inference of Vision and Language Pretrained Models
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 8928
EP  - 8940
DO  - 10.1109/TMM.2024.3384060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189630118&doi=10.1109%2fTMM.2024.3384060&partnerID=40&md5=d1219b1423f881bd00cab6bc232d4a1b
AB  - The computational cost of the vision and language pretrained models (VL-PTMs) limits their deployment in resource-constrained devices that require low latency. One existing solution is to apply the early exiting (EE) strategy to accelerate the inference. This technique can force model prediction using only a few former transformer layers. However, these former layers behave differently with the final classifier, inevitably resulting in performance decline. To counter such limitation, self-distillation has been commonly introduced to enhance the representation abilities of the EE classifiers. This results in a semantic gap since EE classifiers are directly trained to mimic the outputs of the final classifier without access to the modality-specific behaviors. This study proposes a multimodality self-distillation method for the fast inference of VL-PTMs. To fill the semantic gap between modalities, we split the multimodalities into separate modalities and added them as extra inputs to encourage the effective distillation of each modality. Furthermore, the mean squared error (MSE) is introduced to minimize the distance of feature maps and further enhance the representation ability of the EE classifiers. Experiments show that the proposed method outperforms the previous EE strategies with the same inference time, and performs competitively even if the model exited very early. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Wang, Z.
AU  - Ning, N.
AU  - Jin, Z.
AU  - Lu, N.
AU  - Shen, X.
TI  - I2T: From Intention Decoupling to Vehicular Trajectory Prediction Based on Prioriformer Networks
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 9411
EP  - 9426
DO  - 10.1109/TITS.2024.3375900
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188951414&doi=10.1109%2fTITS.2024.3375900&partnerID=40&md5=e0bd04232279d6820803d3a2256f8dec
AB  - A reliable driving trajectory prediction of surrounding vehicles is an essential reference for decision-making and safe driving of an autonomous vehicle. Although predicting short-Term trajectories can be well achieved, it is still very challenging for long-Term prediction of trajectories since the prediction space grows exponentially. In this paper, we propose a novel architecture for trajectory prediction from factored intention estimation (I2T), which decouples the trajectory prediction space into a high-level space for intention estimation and a low-level space for motion prediction. The long-Term dependencies between intention cues and future motions during driving are naturally extended to the internal sharing mechanism of I2T, leading to improved performance. Furthermore, we design a Prioriformer model to serve as the backbone network for I2T so that it can accurately capture the long-Term dependency couplings related to the task of intention estimation or motion prediction. Prioriformer model adopts a personalized normalization method, which facilitates learning latent representations of long-Term features and avoids getting stuck on local optimum. A designed multi-scale fusion encoder extracts features from various receptive fields and then learns richer information from the representation subspaces. An efficient non-Autoregressive decoder reduces the pressure in long-Term prediction of trajectories while avoiding cumulative errors. Experiments on three real-world motion datasets show that I2T can significantly outperform the state-of-The-Art.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2024I2T
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Xu, Y.
AU  - Jiao, H.
AU  - Gao, Z.
AU  - Zhang, L.
TI  - S³ANet: Spatial-Spectral Self-Attention Learning Network for Defending Against Adversarial Attacks in Hyperspectral Image Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5512913
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2024.3381824
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189311305&doi=10.1109%2fTGRS.2024.3381824&partnerID=40&md5=069011ae285e2342e80de755fc337ea0
AB  - Deep neural networks have demonstrated impressive capabilities in hyperspectral image (HSI) classification tasks. However, they are highly vulnerable to adversarial attacks, raising significant security concerns, especially in the remote sensing community. Even subtle adversarial perturbations that are imperceptible to human observers can mislead deep learning (DL) models and result in incorrect predictions. Therefore, ensuring the robustness of DL models has become a critical focus in addressing security-related remote sensing tasks. Considerable progress has been made in defending against adversarial attacks in HSI classification. Nevertheless, existing methods primarily concentrate on spatial relationships between pixels while overlooking the valuable spectral information present in HSI. Besides, these methods are usually limited to a specific scale and cannot accommodate the precise classification demands for ground objects with various scales. To address these limitations, we propose a spatial-spectral self-attention learning network (S3ANet) for defending against adversarial attacks in HSI classification. Our S3ANet incorporates a pyramid spatial attention learning module to effectively capture spatial dependency at multiple scales. In addition, it utilizes a global spectral transformer to establish correlations between pixels in the spectral dimension. By employing the defense method of spatial-spectral fusion, our model can effectively address adversarial attacks from a comprehensive perspective, seamlessly integrating both spatial and spectral information. Extensive experiments conducted on four benchmark HSI datasets illustrate that the proposed S3ANet achieves competitive performance compared to state-of-the-art methods when faced with adversarial attacks. The code is available online at https://github.com/YichuXu/S3ANet.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tran, T.M.
AU  - Bui, D.C.
AU  - Nguyen, T.V.
AU  - Nguyen, K.
TI  - Transformer-Based Spatio-Temporal Unsupervised Traffic Anomaly Detection in Aerial Videos
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 9
SP  - 8292
EP  - 8309
DO  - 10.1109/TCSVT.2024.3376399
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188005131&doi=10.1109%2fTCSVT.2024.3376399&partnerID=40&md5=d2a4f9fc85765fd1b0bb4c55b8d4f228
AB  - Anomaly detection is an area of video analysis and plays an increasing role in ensuring safety, preventing risks, and guaranteeing quick response in intelligent surveillance systems. It has become a popular research topic and has piqued the interest of researchers in different communities, such as computer vision, machine learning, remote sensing, and data mining, in recent years. This promotes novel mobile systems where drones are equipped with cameras to help people find better and more efficient solutions to automatically detect anomalies (e.g., car accidents, traffic congestion, street fighting) in traffic surveillance videos. However, anomaly detection methods are still rarely studied and developed in the remote sensing community due to anomalous events rarely occurring in real life, along with the high similarities between the objects of interest with small sizes, multi-scale objects, complex backgrounds of great variations, and high overlap between objects. Therefore, in order to fully exploit the spatio-temporal information for anomaly detection in traffic surveillance circumstances, we propose a future frame prediction network based on transformer architectures to detect abnormal events from drone videography in an unsupervised way. Our model treats consecutive video frames from an input clip and feeds features to a transformer encoder to capture spatial and temporal representations from the sequence. Then, it leverages a decoder to predict the next frame. Furthermore, an event with high reconstruction error is identified as an anomaly in the test phase. Thoroughly empirical studies demonstrate that our method achieves superior performance on the UIT-ADrone dataset and largely outperforms the state-of-the-art anomaly methods on the Drone-Anomaly dataset in aerial surveillance. The source code is available online at https://github.com/Tungufm/ASTT.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yan, X.
AU  - Gan, X.
AU  - Tang, J.
AU  - Zhang, D.
AU  - Wang, R.
TI  - ProSTformer: Progressive Space-Time Self-Attention Model for Short-Term Traffic Flow Forecasting
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 10802
EP  - 10816
DO  - 10.1109/TITS.2024.3367754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188012766&doi=10.1109%2fTITS.2024.3367754&partnerID=40&md5=1d45801dc725abc72fa10071ad67b52c
AB  - Traffic flow forecasting is essential and challenging to intelligent city management and public safety. In this paper, we attempt to use a pure self-attention method in traffic flow forecasting. However, when dealing with input sequences, including large-scale regions' historical records, it is difficult for the self-attention mechanism to focus on the most relevant ones for forecasting. To address this issue, we design a progressive space-time self-attention mechanism named ProSTformer, which can reduce self-attention computation times from thousands to tens. Our design is based on two pieces of prior knowledge in the traffic flow forecasting literature: (i) spatiotemporal dependencies can be factorized into spatial and temporal dependencies; (ii) adjacent regions have more influences than distant regions, and temporal characteristics of closeness, period and trend are more important than crossed relations between them. Our ProSTformer has two characteristics. First, each block in ProSTformer highlights the unique dependencies, ProSTformer progressively focuses on spatial dependencies from local to global regions, on temporal dependencies from closeness, period and trend to crossed relations between them, and on external dependencies such as weather conditions, temperature and day-of-week. Second, we use the Tensor Rearranging technique to force the model to compute self-attention only to adjacent regions and to the unique temporal characteristic. Then, we use the Patch Merging technique to greatly reduce self-attention computation times to distant regions and crossed temporal relations. We evaluate ProSTformer on two traffic datasets and find that it performs better than sixteen baseline models. The code is available at https://github.com/yanxiao1930/ProSTformer_code/tree/main.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Yan2024ProSTformer
ER  -

TY  - JOUR
AU  - Chaccour, C.
AU  - Saad, W.
AU  - Debbah, M.
AU  - Poor, H.V.
TI  - Joint Sensing, Communication, and AI: A Trifecta for Resilient THz User Experiences
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 9
SP  - 11444
EP  - 11460
DO  - 10.1109/TWC.2024.3382192
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190170739&doi=10.1109%2fTWC.2024.3382192&partnerID=40&md5=da12c6f31faacaa08118b26e4570843f
AB  - In this paper a novel joint sensing, communication, and artificial intelligence (AI) framework is proposed so as to optimize extended reality (XR) experiences over terahertz (THz) wireless systems. Within this framework, active reconfigurable intelligent surfaces (RISs) are incorporated as pivotal elements, serving as enhanced base stations in the THz band to enhance Line-of-Sight (LoS) communication. The proposed framework consists of three main components. First, a tensor decomposition framework is proposed to extract unique sensing parameters for XR users and their environment by exploiting the THz channel sparsity. Essentially, the THz band's quasi-opticality is exploited and the sensing parameters are extracted from the uplink communication signal, thereby allowing for the use of the same waveform, spectrum, and hardware for both communication and sensing functionalities. Then, the Cramér-Rao lower bound is derived to assess the accuracy of the estimated sensing parameters. Second, a non-autoregressive multi-resolution generative AI framework integrated with an adversarial transformer is proposed to predict missing and future sensing information. The proposed framework offers robust and comprehensive historical sensing information and anticipatory forecasts of future environmental changes, which are generalizable to fluctuations in both known and unforeseen user behaviors and environmental conditions. Third, a multi-agent deep recurrent hysteretic Q-neural network is developed to control the handover policy of RIS subarrays, leveraging the informative nature of sensing information to minimize handover cost, maximize the individual quality of personal experiences (QoPEs), and improve the robustness and resilience of THz links. Simulation results show a high generalizability of the proposed unsupervised generative artificial intelligence (AI) framework to fluctuations in user behavior and velocity, leading to a 61% improvement in instantaneous reliability compared to schemes with known channel state information. © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, J.
AU  - Di, X.
AU  - Liu, X.
AU  - Li, J.
AU  - Li, Z.
AU  - Zhao, L.
AU  - Hawbani, A.
AU  - Guizani, M.
TI  - Anomaly Detection for In-Vehicle Network Using Self-Supervised Learning With Vehicle-Cloud Collaboration Update
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7454
EP  - 7466
DO  - 10.1109/TITS.2024.3351438
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189500252&doi=10.1109%2fTITS.2024.3351438&partnerID=40&md5=477c087183ee969409c4b9bf7d38a224
AB  - With the increasing communications between the In-Vehicle Networks (IVNs) and external networks, security has become a stringent problem. In addition, the controller area network bus in IVN lacks security mechanisms by design, which is vulnerable to various attacks. Thus, it is important to detect IVN anomalies for complete vehicular security. However, current studies are constrained by either requiring labeled data or failing to accurately detect message-level anomalies without labeled data. In addition, the concept drift of existing methods has become a challenge over time. To address these problems, this paper proposes an IVN anomaly detection method based on Self-supervised Learning (IVNSL), which is capable of detecting message-level anomalies without labels. The essential idea of IVNSL is to make the message prediction model learn the distribution of normal messages in sequences using message sequences with noise. Furthermore, to accurately detect anomalies, a Message Prediction Model based on Hierarchical transformers (MPMHit) is proposed, which captures the spatial features of the message and the dependencies between messages. Meanwhile, to solve the concept drift over time, this paper proposes an online update mechanism for MPMHit based on vehicle-cloud collaboration. We conduct an extensive experimental evaluation on the car hacking dataset, resulting to an F1-score average and average false positive rates of IVNSL being 2.282% higher and 1.595% lower than the best baseline method. The average detection speed of each message is as fast as 0.1075 ms.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Cao2024Anomaly
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Cheng, S.
AU  - Guo, Z.
AU  - Zhang, X.
TI  - Inferring Video Streaming Quality of Real-Time Communication Inside Network
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 7756
EP  - 7770
DO  - 10.1109/TCSVT.2024.3375604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188006604&doi=10.1109%2fTCSVT.2024.3375604&partnerID=40&md5=600518d498f9228a8b6f8f03148138fa
AB  - Real-time video streaming is getting indispensable in people's daily life, and poses heavy loads and stringent performance requirements on the network. For Internet Service Providers (ISPs), ensuring high-quality real-time video communication is a widely concerned issue. However, inferring the quality of real-time video streaming based on passively-collected network traffic is a great challenge due to limited information in the User Datagram Protocol (UDP) header and the encryption of the application-level protocol. In this paper, we propose IReaV-T to Infer Real-time Video streaming quality with a generalized Transformer, which understands the intrinsic state of the network and predicts the future real-time video quality. By applying novel embedding methods, IReaV-T could make full use of observed traffic features and distinguish different real-time video applications. Extensive comparative experiments demonstrate the effectiveness of IReaV-T, showing that IReaV-T could predict future real-time video quality with mean squared Video Multimethod Assessment Fusion (VMAF) score error less than 6. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, M.
AU  - Song, Y.
AU  - Wei, P.
AU  - Xian, X.
AU  - Shi, Y.
AU  - Lin, L.
TI  - IDF-CR: Iterative Diffusion Process for Divide-and-Conquer Cloud Removal in Remote-Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5615014
SP  - 1
EP  - 14
DO  - 10.1109/TGRS.2024.3378720
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188540234&doi=10.1109%2fTGRS.2024.3378720&partnerID=40&md5=dd1e089fd7f83cc1a0c068195051bf91
AB  - Deep learning technologies have demonstrated their effectiveness in removing cloud cover from optical remote-sensing images. Convolutional neural networks (CNNs) exert dominance in the cloud removal tasks. However, constrained by the inherent limitations of convolutional operations, CNNs can address only a modest fraction of cloud occlusion. In recent years, diffusion models have achieved state-of-the-art (SOTA) proficiency in image generation and reconstruction due to their formidable generative capabilities. Inspired by the rapid development of diffusion models, we first present an iterative diffusion process for cloud removal (IDF-CR), which exhibits strong generative capabilities to achieve component divide-and-conquer (CDC) cloud removal. IDF-CR consists of a pixel space cloud removal (Pixel-CR) module and a latent space iterative noise diffusion (IND) network. Specifically, IDF-CR is divided into two-stage models that address pixel space and latent space. The two-stage model facilitates a strategic transition from preliminary cloud reduction to meticulous detail refinement. In the pixel space stage, Pixel-CR initiates the processing of cloudy images, yielding a suboptimal cloud removal prior to providing the diffusion model with prior cloud removal knowledge. In the latent space stage, the diffusion model transforms low-quality cloud removal into high-quality clean output. We refine the stable diffusion by implementing ControlNet. In addition, an unsupervised iterative noise refinement (INR) module is introduced for the diffusion model to optimize the distribution of the predicted noise, thereby enhancing advanced detail recovery. Our model performs best with other SOTA methods, including image reconstruction and optical remote-sensing cloud removal on the optical remote-sensing datasets.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhai, D.
AU  - Yu, S.
AU  - Wang, W.
AU  - Guan, Y.
AU  - Xia, Y.
TI  - TCRNet: Transparent Object Depth Completion With Cascade Refinements
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
SP  - 1
EP  - 20
DO  - 10.1109/TASE.2024.3371583
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188003455&doi=10.1109%2fTASE.2024.3371583&partnerID=40&md5=6e8f2cb6d4ab6d83b8c790a8f7ff3598
AB  - Transparent objects are commonly found in real life and industrial production. Unlike opaque objects, transparent objects are not easily identifiable in RGB images and often require depth information to determine their position in the image. However, due to the influence of other environmental factors such as reflection and refraction, the depth information of transparent objects is often inaccurate. This leads to difficulties for robots in grasping transparent objects, as incorrect depth information can result in the robot being unable to predict or predict incorrectly the grasping pose. Therefore, it is necessary to complete the depth information for transparent objects. Previous methods for depth completion of transparent objects often struggle to balance accuracy and real-time performance simultaneously. To achieve this goal, in this paper, we propose a transparent object depth completion network called TCRNet based on a cascade refinement structure, which balances accuracy and real-time performance simultaneously. First, the network incorporates a cascade refinement structure in the decoding stage to refine features multiple times, improving the accuracy of depth information. Additionally, an attention module is designed to adjust the extracted features, enabling the network to focus on depth information features in transparent object regions. Finally, a transformer-based error module is implemented in the network&#x2019;s final output stage to predict and adjust the error between the depth image and the ground truth. TCRNet is trained and tested on three datasets: ClearGrasp, Omniverse Object, and TransCG. It outperforms previous methods in terms of performance. Furthermore, TCRNet is applied to existing grasp detection methods to conduct grasping experiments on transparent objects using a real Baxter robot. <italic>Note to Practitioners</italic>&#x2014;With the development of RGB-D camera technology, RGB-D cameras are now widely used in various scenarios such as industrial production, autonomous driving, and robot grasping. However, in certain situations where the camera faces transparent or highly reflective objects, the depth information captured by the camera is often not accurate enough, which can lead to subsequent accidents. Therefore, it is necessary to repair and complete the depth images to achieve accurate understanding of the scene&#x2019;s depth information. In recent years, with the advancement of deep learning, deep learning-based depth image processing and restoration techniques have been widely applied. In this paper, we propose a high-accuracy network for repairing depth images of transparent objects, which can accurately restore and estimate the depth information of transparent objects in various scenarios. Moreover, experimental results demonstrate that our proposed method can generalize well to other unknown scenes, achieving excellent results. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Chen, H.
AU  - Wu, Q.
AU  - Xia, C.
AU  - Li, J.
TI  - Joint Spatio-Temporal Similarity and Discrimination Learning for Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 7284
EP  - 7300
DO  - 10.1109/TCSVT.2024.3377379
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188010641&doi=10.1109%2fTCSVT.2024.3377379&partnerID=40&md5=caf83d6536efc9c277d801c551865ab6
AB  - Visual tracking is a task of localizing a target unceasingly in a video with an initial target state at the first frame. The limited target information makes this problem an extremely challenging task. Existing tracking methods either perform matching based similarity learning or optimization based discrimination reasoning. However, these two types of tracking methods suffer from the problem of ineffectiveness for distinguishing target objects from background distractors and the problem of insufficiency in maintaining spatio-temporal consistency among successive frames, respectively. In this paper, we design a joint spatio-temporal similarity and discrimination learning (STSDL) framework for accurate and robust tracking. The designed framework is composed of two complementary branches: a similarity learning branch and a discrimination learning branch. The similarity learning branch uses an effective transformer encoder-decoder to gather rich spatio-temporal context information to generate a similarity map. In parallel, the discrimination learning branch exploits an efficient model predictor to train a target model to produce a discriminative map. Finally, the similarity map and the discriminative map are adaptively fused for accurate and robust target localization. Experimental results on six prevalent datasets demonstrate that the proposed STSDL can obtain satisfactory results, while it retains a real-time tracking speed of 50 FPS on a single GPU. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Wang, Q.
AU  - Wang, Q.
TI  - A Sign Language Recognition Framework Based on Cross-Modal Complementary Information Fusion
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 8131
EP  - 8144
DO  - 10.1109/TMM.2024.3377095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188462892&doi=10.1109%2fTMM.2024.3377095&partnerID=40&md5=204a7450db4bd560ed71ba3824623a94
AB  - —Sign language recognition (SLR) can connect the hearing-impaired and able-bodied communities. The SLR works through multiple modalities of co-action, which has garnered attention. However, these methods are much less effective or even fail in recognition when confronted with missing modalities. Therefore, this article proposes MMSLR, a multimodal SLR framework with cross-modal complementary information. The framework comprises three key components: the cross-modal information complementation (CMIC) module, the fusion and prediction module (FPM), and the sign language recognition module (SLRM). The CMIC module is designed with multi-layer, multi-view spatial-temporal detectors to observe different modality features in both temporal and spatial dimensions. Additionally, it utilizes co-training to achieve complementary information among multi-modalities. The FPM integrates cross-modal attention with Canberra distance to eliminate inter-modal redundant information while fusing multimodal features. The SLRM constructed based on Transformer fuses partially obtained modalities from CMIC through bidirectional cross-channel attention. Teacher-Student pairs are constructed to transfer full-modal features from FPM to the above fused modality features. Moreover, experimental results on the provided MM-Sentence and publicly available OH-Sentence, TH-Sentence and USTC-CSL datasets demonstrate that MMSLR achieves state-of-the-art performance. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Feng, R.
AU  - Li, Z.
AU  - Liu, B.
AU  - Ding, Y.
TI  - A Joint Spatiotemporal Prediction and Image Confirmation Model for Vehicle Trajectory Concatenation With Low Detection Rates
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 9
SP  - 11701
EP  - 11715
DO  - 10.1109/TITS.2024.3373774
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188531914&doi=10.1109%2fTITS.2024.3373774&partnerID=40&md5=1b8a5aa1c990ecce2d1f949bbbeaba2a
AB  - Ensuring the quality of trajectories is of utmost importance in traffic flow analysis. Traditional approaches rely on reconstructing nearly complete trajectories and subsequently denoising them. However, low detection rates often pose challenges and result in failed trajectory construction. To overcome this issue, this paper presents a trajectory concatenation method that combines NS Transformer prediction and Siamese-VGG16 similarity confirmation, specifically designed to address low detection rates. The employed transformer model can withstand missing values, efficiently extracting internal associations among multiple traffic parameters in conditions of sparse data. Furthermore, a lightweight image feature similarity verification step is integrated after trajectory prediction to find the most similar target to the image in the predicted spatiotemporal domain. Additionally, a lightweight image feature similarity verification step is integrated after trajectory prediction to identify the most similar targets within the predicted spatiotemporal domain. Experimental results demonstrate the efficacy of the proposed method, successfully connecting over 80% of fragmented tracks and yielding significant maintenance of MOTA above 0.74 under low detection accuracy.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Feng2024Joint
ER  -

TY  - JOUR
AU  - Zhou, T.
AU  - Liu, X.
AU  - Xiang, Z.
AU  - Zhang, H.
AU  - Ai, B.
AU  - Liu, L.
AU  - Jing, X.
TI  - Transformer Network Based Channel Prediction for CSI Feedback Enhancement in AI-Native Air Interface
PY  - 2024
T2  - IEEE Transactions on Wireless Communications
VL  - 23
IS  - 9
SP  - 11154
EP  - 11167
DO  - 10.1109/TWC.2024.3379123
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189353842&doi=10.1109%2fTWC.2024.3379123&partnerID=40&md5=ebc3d82ef90de9b2b8cfbb29c58f63c6
AB  - With the development of artificial intelligence (AI), wireless channel prediction based on deep learning (DL) has become a hot research issue. Channel prediction plays an important role in channel state information (CSI) feedback enhancement in AI-native air interface. To better predict the CSI, this paper investigates the Transformer network based channel prediction. Firstly, real channel data are obtained in Beijing-Tianjin railway line, and the channel prediction datasets are constructed through preprocessing. After formulating the channel prediction problem, a channel prediction model based on the Transformer network is newly proposed. The unique multi-head attention mechanism and position encoding of the Transformer network enable the proposed model to have more powerful parallel computation capability and better global information capture capability. Then, the hyper-parameters of the model are determined by autocorrelation analysis and cross-validation. Finally, the performance of the proposed model is evaluated in terms of prediction accuracy and space and time computational complexity using several evaluation metrics, and is compared with classical DL models. It is shown that the proposed model possesses higher prediction performance in the appropriate range of computational complexity.  © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, B.
AU  - Wang, Z.
AU  - Wang, S.
AU  - Cheng, Y.
AU  - Ning, J.
TI  - Bidirectional Interaction of CNN and Transformer Feature for Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 7259
EP  - 7271
DO  - 10.1109/TCSVT.2024.3376690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187998752&doi=10.1109%2fTCSVT.2024.3376690&partnerID=40&md5=6c7d93dbcd23baa56fbd47a9961cc63d
AB  - Empowered by the sophisticated long-range dependency modeling ability of Transformer, tracking performance has seen a dynamic increase in recent years. Approaches in this vein leverage the Transformer feature to integrate the information of target and search regions while neglecting the superior local representation extracted by their CNN backbone. To address this, we introduce a BIdirectional inTeraction mechanism between CNN and Transformer features for visual tracking, termed BIT-Tracker, which admits a comprehensive fusion of local and global representations, and thus boosts tracking performance. The first ingredient of BIT-Tracker is an aggregation of multi-level Transformer features to achieve a better global modeling ability. In order to combine the merits of both local and global representations, our second ingredient performs a bi-directional interaction between CNN and Transformer features, where the interaction is achieved via either querying the CNN feature from the Transformer feature or querying the Transformer feature from the CNN feature. Afterwards, the outputs from both directions are fused to predict the temporal locations of targets. Extensive experiments demonstrate the effectiveness of the proposed feature aggregation and bi-directional interaction modules. Impressively, BIT-Tracker achieves leading performance on eight tracking benchmarks and outperforms SOTA results by salient margins. Code will be made available.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, J.
AU  - Wang, P.
AU  - Li, B.
AU  - Wang, T.
AU  - Pang, X.S.
AU  - Wang, D.
TI  - Exploring User Adoption of ChatGPT: A Technology Acceptance Model Perspective
PY  - 2024
T2  - International Journal of Human-Computer Interaction
DO  - 10.1080/10447318.2024.2314358
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186392861&doi=10.1080%2f10447318.2024.2314358&partnerID=40&md5=a34f4b7a81f13b1c5db6ec57f51c1acc
AB  - In the rapidly evolving landscape of technology, the emergence of Chat Generative Pre-trained Transformer (ChatGPT) marks a pivotal milestone in the realm of Artificial Intelligence (AI). However, little research has reported the predictors of people’s intentions to use ChatGPT. This pioneering study empirically examines user adoption through the lens of the Technology Acceptance Model (TAM) using a convenience sampling method. The study surveyed 784 ChatGPT users in China, of whom 58.93% were males. The results have revealed several key findings: (1) perceived usefulness, perceived ease of use, behavioral intention, and use behavior were positively correlated with each other; (2) behavioral intention acted as a mediating factor in the relationship between perceived usefulness and use behavior, as well as the relationship between perceived ease of use and use behavior; (3) perceived usefulness and behavioral intention played a chain-mediated role between perceived ease of use and use behavior; (4) the relationship between behavioral intention and use behavior exhibited greater strength among females compared to males; (5) the association between behavioral intention and use behavior was found to be stronger among urban users in comparison to their rural counterparts; (6) the connections between perceived ease of use and perceived usefulness, perceived ease of use and behavioral intention, and behavioral intention and use behavior were observed to be stronger among individuals with higher educational backgrounds relative to those with lower educational backgrounds. These findings provide crucial nuanced insights to advance the practical application of ChatGPT, emphasizing the need for enhanced usability and ease of use. However, this study exclusively captured usage behaviors within the Chinese user base. Future investigations could encompass diverse demographics across multiple countries, enabling cross-cultural comparisons. © 2024 Taylor & Francis Group, LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zeng, Y.
AU  - Chen, Y.
AU  - Yang, X.
AU  - Li, Q.
AU  - Yan, J.
TI  - ARS-DETR: Aspect Ratio-Sensitive Detection Transformer for Aerial Oriented Object Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5610315
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3364713
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186091340&doi=10.1109%2fTGRS.2024.3364713&partnerID=40&md5=7a1e642ff1e7e21332844a1a01acd2e5
AB  - Existing oriented object detection in aerial images has progressed a lot in recent years and achieved favorable success. However, high-precision oriented object detection in aerial images remains a challenging task. Some recent works have adopted the classification-based method to predict the angle to address boundary problems in angle. However, we have found that these works often neglect the sensitivity of objects with different aspect ratios to angle. At the same time, it is worth exploring a suitable way to improve the emerging transformer-based approaches to adapt them to oriented object detection. In this article, we propose an Aspect Ratio-Sensitive DEtection TRansformer, termed ARS-DETR, for oriented object detection in aerial images. Specifically, a new angle classification method, called aspect ratio-aware circle smooth label (AR-CSL), is proposed to smooth the angle label more reasonably and discard the hyperparameter introduced by previous work [e.g., circular smooth label (CSL)]. Then, a rotated deformable attention (RDA) module is designed to rotate the sampling points with the corresponding angles and eliminate the misalignment between region features and sampling points. Moreover, a dynamic weight coefficient according to the aspect ratio is adopted to calculate the angle loss. Comprehensive experiments on several challenging datasets demonstrate that our method achieves a competitive performance in the high-precision oriented object detection task.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, T.
AU  - Tan, S.
AU  - Zhao, B.
AU  - Yue, G.
TI  - Multitask Deep Neural Network with Knowledge-Guided Attention for Blind Image Quality Assessment
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 7577
EP  - 7588
DO  - 10.1109/TCSVT.2024.3375344
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187975631&doi=10.1109%2fTCSVT.2024.3375344&partnerID=40&md5=f4ca9079d005461048ac34500b5851e9
AB  - Blind image quality assessment (BIQA) targets predict the perceptual quality of an image without any reference information. However, known methods have considerable room for performance improvement due to limited efforts in distortion knowledge usage. This paper proposes a novel multitask learning based BIQA method termed KGANet, which takes image distortion classification as an auxiliary task and uses the knowledge learned from the auxiliary task to assist accurate quality prediction. Different from existing CNN-based methods, KGANet adopts a transformer as the backbone for feature extraction, which can learn more powerful and robust representations. Specifically, it comprises two essential components: a cross-layer information fusion (CIF) module and a knowledge-guided attention (KGA) module. Considering that both global and local distortions appear in an image, CIF fuses the features of the adjacent layers extracted by the backbone to obtain a multiscale feature representation. KGA incorporates the distortion probability estimated by the auxiliary task with the distortion embeddings, which are selected from subword unit embeddings based on a textual template, to form distortion knowledge. This knowledge further serves as guidance to enhance the features of each layer and strengthen the connection between the main and auxiliary task. We demonstrate the effectiveness of the proposed KGANet through extensive experiments on benchmark databases. Experimental results show that KGANet correlates well with subjective perceptual judgments and achieves superior performance over 12 state-of-the-art BIQA methods. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yuan, C.
AU  - Wang, K.
AU  - Luo, W.
AU  - Wang, X.
AU  - Peng, W.
AU  - Yue, Y.
AU  - Lan, X.
AU  - Chen, N.
TI  - 2-D Magnetotelluric Gradient Prediction with the Transformer + Unet Network Based on Transverse Magnetic Polarization
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5908810
SP  - 1
EP  - 10
DO  - 10.1109/TGRS.2024.3372768
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187407290&doi=10.1109%2fTGRS.2024.3372768&partnerID=40&md5=017089d22db424645a3db3cf7cac1404
AB  - The calculation of magnetotelluric (MT) data gradients can be used for data sensitivity analysis, which is of great significance for actual sensitive areas. However, such calculations are highly complex and time consuming and therefore not conducive for the implementation of rapid analysis. To address this issue and improve computational efficiency, we propose a solution based on the transformer + Unet (T-Unet) neural network model to accelerate the calculation of 2-D MT gradients. First, we create a seven-channel dataset corresponding to the gradient label and then obtain the neural network weight model through network training and iteration and predict the gradient value rapidly and accurately on this basis. The experimental results indicate that, compared to traditional gradient computation, the T-Unet network not only significantly reduces computation time but also ensures high gradient prediction accuracy. This research demonstrates the potential of gradient fast prediction in sensitivity analysis and accelerated MT inversion.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lu, M.
AU  - Li, R.
AU  - Feng, F.
AU  - Ma, Z.
AU  - Wang, X.
TI  - LGR-NET: Language Guided Reasoning Network for Referring Expression Comprehension
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 7771
EP  - 7784
DO  - 10.1109/TCSVT.2024.3374786
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187350864&doi=10.1109%2fTCSVT.2024.3374786&partnerID=40&md5=a4518f40634546df44efe36a3056a170
AB  - Referring Expression Comprehension (REC) is a fundamental task in the vision and language domain, which aims to locate an image region according to a natural language expression. REC requires the models to capture key clues in the text and perform accurate cross-modal reasoning. A recent trend employs transformer-based methods to address this problem. However, most of these methods typically treat image and text equally. They usually perform cross-modal reasoning in a crude way, and utilize textual features as a whole without detailed considerations (e.g., spatial information). This insufficient utilization of textual features will lead to sub-optimal results. In this paper, we propose a Language Guided Reasoning Network (LGR-NET) to fully utilize the guidance of the referring expression. To localize the referred object, we set a prediction token to capture cross-modal features. Furthermore, to sufficiently utilize the textual features, we extend them by our Textual Feature Extender (TFE) from three aspects. First, we design a novel coordinate embedding based on textual features. The coordinate embedding is incorporated to the prediction token to promote its capture of language-related visual features. Second, we employ the extracted textual features for Text-guided Cross-modal Alignment (TCA) and Fusion (TCF), alternately. Third, we devise a novel cross-modal loss to enhance cross-modal alignment between the referring expression and the learnable prediction token. We conduct extensive experiments on five benchmark datasets, and the experimental results show that our LGR-NET achieves a new state-of-the-art. Source code is available at https://github.com/lmc8133/LGR-NET. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Zhu, Y.
TI  - RaFPN: Relation-Aware Feature Pyramid Network for Dense Image Prediction
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 7787
EP  - 7800
DO  - 10.1109/TMM.2024.3371787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187345827&doi=10.1109%2fTMM.2024.3371787&partnerID=40&md5=137f9246878af2a329bd26ce8e65ebc8
AB  - Intuitively, relations among objects assist a model in performing inference under constrained environments. However, the top-down information flow in the Feature pyramid network (FPN) dilutes the relation features contained in the non-adjacent layers. Such a defect reduces the accuracy of detectors, especially for small or obscured objects. To adequately exploit the relations among object instances, we propose the relation-aware feature pyramid network (RaFPN), a simple but effective balanced multi-scale feature module for dense image prediction. RaFPN models the relations among objects by computing the similarity between pixels located on cross-scale features. The result is then delivered to FPN to guide the detector in completing accurate inference. Specifically, we first generate a pair of cross-scale aggregated features based on the channel importance of the output features from FPN. After that, the relation among the cross-scale objects is extracted by a bi-directional interaction mechanism. Finally, relation features are injected directly into each layer of the feature pyramid to avoid dilution. In this way, the relation among instances can adequately guide the detector for dense prediction. Our RaFPN pushes the performance bound of Faster RCNN by 2.0 AP (average precision), outperforming the recent state-of-the-art FPN-based improvements. Notably, for dense prediction tasks such as instance, semantic, and panoptic segmentation, our method brings consistent boosts to them as well.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, H.
AU  - Chen, B.
AU  - Zhu, L.
AU  - Chen, P.
AU  - Song, L.
AU  - Wang, S.
TI  - Video Quality Assessment for Spatio-Temporal Resolution Adaptive Coding
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 6403
EP  - 6415
DO  - 10.1109/TCSVT.2024.3367904
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186089456&doi=10.1109%2fTCSVT.2024.3367904&partnerID=40&md5=1cda73230ae0cb0dd1ad3014dbe4e8a1
AB  - Spatio-temporal resolution adaptive (STRA) coding has been repeatedly proven to be a promising way to improve coding efficiency and reduce coding complexity. The wide consensus is that the optimal subsampled resolution and frame rate should be governed by so- called generalized rate-distortion performance based on the ultimately perceived distortion. However, it is non-trivial to accurately predict the quality of reconstructed videos due to the fact that the distortion originates from both subsampling and compression. To address this issue, we propose a novel video quality assessment model that is fully aware of the information available in downsampled videos for compression, such as resolution and frame rate. More specifically, the proposed model relies on quality-aware spatial features that are extracted by an image quality fine-tuned backbone. Subsequently, the spatio-temporal quality is modeled based on the transformer encoder, which is adaptive to the downsampling spatial and temporal resolutions. This enables the transformer encoder to produce discriminative features that capture long-range temporal dependencies related to the current context. The quality score, which is the output of the transformer encoder, thus reflects both the influence of the subsampling and compression. We conduct extensive experiments that demonstrate the superiority of the proposed model over state-of-the-art methods on four subsampling and compression video quality datasets. Furthermore, we apply the proposed model to bitrate ladder optimization, leading to a perceptual-aware spatial and temporal downsampling strategy that yields promising bitrate savings. The source codes of the proposed model will be publicly available at https://github.com/h4nwei/STRA-VQA.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Zhang, X.
AU  - Luo, Y.
AU  - Hao, Q.
AU  - Su, J.
AU  - Cai, G.
TI  - Guard-Net: Lightweight Stereo Matching Network via Global and Uncertainty-Aware Refinement for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10260
EP  - 10273
DO  - 10.1109/TITS.2024.3357841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187288268&doi=10.1109%2fTITS.2024.3357841&partnerID=40&md5=ae5c417da1e8dccb62c604af4fd44006
AB  - Stereo matching is a prominent research area in autonomous driving and computer vision. Despite significant progress made by learning-based methods, accurately predicting disparities in hazardous regions, which is crucial for ensuring safe vehicle operation, remains challenging. The limitations of methods based on Convolutional Neural Networks (CNNs) are most noticeable in textureless regions and repetitive patterns, leading to unreliable predictions. Furthermore, calculating disparities for boundaries and thin structures, where the disparity jump phenomenon is prominent remains difficult. To address these issues, we propose a lightweight stereo matching architecture that focuses on obtaining real-Time and high-precision disparity maps in hazardous areas. We exploit an efficient global enhanced path to provide global representations in ill-posed regions, where CNN-based approaches often struggle. Second, our model integrates local and global features to generate more reliable cost volume. Finally, our innovative uncertainty-Aware module refines disparity, making full use of high-frequency detailed information and uncertainty attention, effectively preserving complex structures. Comprehensive experimental studies on SceneFlow demonstrate our method outperforms state-of-The-Art methods, achieving an End-Point Error (EPE) of 0.47 with only 3.60M parameters. The effectiveness of our method speed-Accuracy trade-off is further confirmed by competitive results obtained from the KITTI 2012 and KITTI 2015 experiments. Code is available at: https://github.com/YJLCV/Guard-Net.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Liu2024Guard-Net
ER  -

TY  - JOUR
AU  - Zhang, D.
AU  - Xiao, X.
AU  - Zheng, Z.
AU  - Jiang, Y.
AU  - Yang, Y.
TI  - Probabilistic Assignment with Decoupled IoU Prediction for Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 5776
EP  - 5789
DO  - 10.1109/TCSVT.2024.3367537
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186104323&doi=10.1109%2fTCSVT.2024.3367537&partnerID=40&md5=dc409c06eedae9443ad79f517e4ee30a
AB  - Modern Siamese trackers mainly rely on classifying and regressing pre-defined anchor boxes or per-pixel points, which are assigned as positive and negative samples based on box intersection-over-union (IoU) or point distance with corresponding ground-truth for training. However, this rigid configuration potentially involves some noisy and ambiguous positive samples, leading to an inconsistency problem between classification and regression, which limits the tracking performance. In this paper, we propose a novel probabilistic assignment approach that dynamically determines positive/negative samples for each instance. To be specific, we first customize the confidence scores of positive candidates by comprehensively exploring the outputs from both classification and regression heads, and fit these scores as a probability distribution. Therefore, it is intuitive to conduct adaptive label assignment according to their probabilities. Then, we also consider dynamic re-weighting factor for each positive sample, jointly optimizing the classification and regression losses in a synchronized manner. Moreover, we introduce a decoupled IoU prediction branch to bridge the gap between the training and inference objectives for accurate tracking. Thanks to well-aligned procedures, our method significantly improves the performance of both CNN-based and Transformer-based trackers. Extensive experiments conducted on several tracking benchmarks including LaSOT and GOT-10k, demonstrate the effectiveness and efficiency of the proposed probabilistic assignment tracker.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, X.
AU  - Liu, Y.
AU  - Jiao, L.
AU  - Li, L.
AU  - Liu, F.
AU  - Yang, S.
AU  - Hou, B.
TI  - MutSimNet: Mutually Reinforcing Similarity Learning for RS Image Change Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4403613
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2024.3365990
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186159914&doi=10.1109%2fTGRS.2024.3365990&partnerID=40&md5=f4c4838457d063b163041e4def1b3a63
AB  - Change detection (CD) involves analysis of discrepancies between two phases. However, when the unchanged elements are known, the changed features to be identified become straightforward. In addition, remote sensing image (RS) is constrained by limited spectral information, which leads to blurred boundaries between different semantics. Based on these two prior knowledge, in this article, we introduce a novel CD framework, named the mutually reinforcing similarity network (MutSimNet). This architecture aims to minimize false alarms along changing boundaries and reduce misjudgment rates among outliers. First, similarity learning is applied to CD. The relationship between the two phases is considered when deriving the change feature maps. Second, we devise a mutually reinforcing (MR) loss function that integrates initial features with final features. Third, a self-attention module is connected in the feature pyramid network (FPN). This design mitigates information loss during the downsampling process. Fourth, an attention feature fusion strategy is proposed for the integration of multilayer features. This strategy takes into account the interaction between layer-by-layer features. Fifth, the experimental results validate MutSimNet's efficiency, particularly its ability to focus on edge contour learning. The MutSimNet also achieves superior performance on two benchmark datasets and predicts positive samples with higher probability. The codebase is accessible at https://github.com/ly-yu/MutSimNet.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gong, Z.
AU  - Xiao, G.
AU  - Shi, Z.
AU  - Chen, R.
AU  - Yu, J.
TI  - MSGA-Net: Progressive Feature Matching via Multi-Layer Sparse Graph Attention
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 5765
EP  - 5775
DO  - 10.1109/TCSVT.2024.3366912
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186111413&doi=10.1109%2fTCSVT.2024.3366912&partnerID=40&md5=69d03af49c4811526cd917b2b1f5de04
AB  - Feature matching is an essential computer vision task that requires the establishment of high-quality correspondences between two images. Constructing sparse dynamic graphs and extracting contextual information by searching for neighbors in feature space is a prevalent strategy in numerous previous works. Nonetheless, these works often neglect the potential connections between dynamic graphs from different layers, leading to underutilization of available information. To tackle this issue, we introduce a Sparse Dynamic Graph Interaction block for feature matching. This innovation facilitates the implicit establishment of dependencies by enabling interaction and aggregation among dynamic graphs across various layers. In addition, we design a novel Multiple Sparse Transformer to enhance the capture of the global context from the sparse graph. This block selectively mines significant global contextual information along spatial and channel dimensions, respectively. Ultimately, we present the Multi-layer Sparse Graph Attention Network (MSGA-Net), a framework designed to predict probabilities of correspondences as inliers and to recover camera poses. Experimental results demonstrate that our proposed MSGA-Net surpasses state-of-the-art methods on challenging indoor and outdoor datasets. Code will be available at https://github.com/gongzhepeng/MSGA-Net.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Yang, J.
AU  - Yan, W.
AU  - Fang, M.
TI  - RDNet-KD: Recursive Encoder, Bimodal Screening Fusion, and Knowledge Distillation Network for Rail Defect Detection
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
SP  - 1
EP  - 10
DO  - 10.1109/TASE.2024.3374387
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187991083&doi=10.1109%2fTASE.2024.3374387&partnerID=40&md5=e600eba8c5d36cc4f0a6d46f1147aa68
AB  - Rail defect detection (RDD) plays a crucial role in ensuring rail transportation safety. Recently, bimodal algorithms have become mainstream; however, the asymmetry in the information of RGB and depth makes it difficult to find a suitable bimodal information fusion algorithm. In addition, it is difficult to deploy most of the existing methods on mobile devices. To solve these problems, we propose a recursive encoder and bimodal information screening fusion with a knowledge distillation network (RDNet-KD) for RDD. First, we propose the recursive encoder-based depth information augmentation (REDA) algorithm. It recursively learns to expand the channel depth information to alleviate the quality problem of depth information. Second, we propose a similarity-driven bimodal information screening fusion (SICF) module. This evaluates the complementarity of information from two modalities by computing the similarity of their hierarchical feature maps to screen useful information for fusion. Third, we introduce the global location and interrelation-based dual contextual knowledge distillation method to enhance the performance of the compact model. Therefore, it is possible to deploy the network on mobile devices. Based on the extensive experiments performed on the RGB-D rail defect dataset NEU RSDDS-AUG, we validate the competitiveness of our RDNet-KD, considering the prediction quality and operational efficiency relative to 12 state-of-the-art methods. The RDNet-KD code and results are available at https://github.com/legendfantasy/RDNet-KD. <italic>Note to Practitioners</italic>&#x2014;This study introduces a recursive encoder and bimodal information screening fusion with a knowledge distillation network (RDNet-KD) for RDD in RGB-D images. Our method enhances depth information quality and effectively selects valuable information from both modalities using the similarity as a coefficient to evaluate the complementary capabilities of the modal information. Furthermore, to compress the model, we introduce knowledge distillation (KD) to balance the number of parameters and detection results and propose a novel KD method that transfers knowledge from the teacher network to the student network. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, R.
AU  - Ying, X.
AU  - Qi, Y.
AU  - Qu, L.
TI  - UniTR: A Unified TRansformer-Based Framework for Co-Object and Multi-Modal Saliency Detection
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 7622
EP  - 7635
DO  - 10.1109/TMM.2024.3369922
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187025703&doi=10.1109%2fTMM.2024.3369922&partnerID=40&md5=976037e40a2b3a5ee3a6bb0960fec2fb
AB  - Recent years have witnessed a growing interest in co-object segmentation and multi-modal salient object detection. Many efforts are devoted to segmenting co-existed objects among a group of images or detecting salient objects from different modalities. Albeit the appreciable performance achieved on respective benchmarks, each of these methods is limited to a specific task and cannot be generalized to other tasks. In this paper, we develop a Unified TRansformer-based framework, namely UniTR, aiming at tackling the above tasks individually with a unified architecture. Specifically, a transformer module (CoFormer) is introduced to learn the consistency of relevant objects or complementarity from different modalities. To generate high-quality segmentation maps, we adopt a dual-stream decoding paradigm that allows the extracted consistent or complementary information to better guide mask prediction. Moreover, a feature fusion module (ZoomFormer) is designed to enhance backbone features and capture multi-granularity and multi-semantic information. Extensive experiments show that our UniTR performs well on 17 benchmarks, and surpasses existing state-of-the-art approaches. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Saad, O.M.
AU  - Helmy, I.
AU  - Mohammed, M.
AU  - Savvaidis, A.
AU  - Chatterjee, A.
AU  - Chen, Y.
TI  - Deep Learning Peak Ground Acceleration Prediction Using Single-Station Waveforms
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5907213
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2024.3367725
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186087673&doi=10.1109%2fTGRS.2024.3367725&partnerID=40&md5=d0b626efe24e7c94801cb7acc86e6c4c
AB  - Predicting the peak ground acceleration (PGA) from the first few seconds after the P-wave arrival time is crucial in estimating the ground motion intensity of the earthquake. The early estimation of PGA supports the earthquake-early warning (EEW) system to generate the warning. Here, we propose to use the vision transformer (ViT) to predict the PGA using 4-s three-channel single-station seismograms, i.e., 1 s prior to the P-wave arrival and 3 s subsequent to the arrival. The ViT can significantly extract remarkable information from the data resulting in superior prediction performance. The core layer of the ViT is the multihead attention (MHA) network which highlights the significant features of the input data. We train and evaluate the proposed algorithm using the Italian earthquake waveform data, where the proposed algorithm shows a promising result. The proposed ViT network utilizes an augmentation strategy to improve the learning ability of the model. Our proposed method is compared to the benchmark deep learning (DL) methods and empirical ground-motion models (GMMs) and outperforms all of them. The proposed algorithm can even predict the PGA accurately using only 2-s data after the P-wave arrival time. The proposed ViT architecture can also be integrated into a PGA classification framework. Finally, the proposed algorithm is tested using real-time data and shows accurate results, indicating its applicability in real-time monitoring.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, F.
AU  - Meng, Q.
AU  - Li, Z.
AU  - Ren, G.
AU  - Wang, L.
AU  - Zhang, J.
AU  - Xin, R.
AU  - Hu, Y.
TI  - Multisource Feature Embedding and Interaction Fusion Network for Coastal Wetland Classification With Hyperspectral and LiDAR Data
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5509516
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2024.3367960
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186096964&doi=10.1109%2fTGRS.2024.3367960&partnerID=40&md5=8f1102e1af6d734d241cc1aee5ee16f6
AB  - With the development of Earth observation technology, hyperspectral image (HSI) and light detection and ranging (LiDAR) data collaborative monitoring has shown great potential in the ecological protection and restoration of coastal wetlands. However, due to the different working principles adopted by the HSI sensor and the LiDAR sensor, the data obtained by them have different distribution characteristics. The distribution difference limits the fusion of HSI and LiDAR data, bringing a great challenge for coastal wetland classification. To tackle this problem, a multisource feature embedding and interaction fusion network (MsFE-IFN) is proposed for coastal wetland classification. First, the HSI and LiDAR data are embedded in the same feature space, where the feature distribution of multisource remote sensing is aligned to alleviate data distribution differences. Second, the aligned HSI and LiDAR features interact information in channels and pixels, which is able to establish the relationship of spectral, elevation, and geospatial. Third, the HSI and LiDAR features are sent into the feature fusion network, in which the low-frequency residual is retained to enrich intraclass features. Finally, the fused feature is applied for final class prediction. Experiments conducted on three coastal wetland HSI-LiDAR datasets created by ourselves demonstrate the superiority of the proposed MsFE-IFN for coastal wetland classification. The codes will be available from the website: https://github.com/bigshot-g/IEEE_TGRS_MsFE-IFN.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Singh, B.
AU  - Singh, D.
AU  - Kaushal, R.
AU  - Halder, A.
AU  - Chattopadhyay, P.
TI  - GSSTU: Generative Spatial Self-Attention Transformer Unit for Enhanced Video Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 14
DO  - 10.1109/TNNLS.2024.3359716
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186997005&doi=10.1109%2fTNNLS.2024.3359716&partnerID=40&md5=f85930a5c9cf4d9ff51585b03d31e048
AB  - Future frame prediction is a challenging task in computer vision with practical applications in areas such as video generation, autonomous driving, and robotics. Traditional recurrent neural networks have limited effectiveness in capturing long-range dependencies between frames, and combining convolutional neural networks (CNNs) with recurrent networks has limitations in modeling complex dependencies. Generative adversarial networks have shown promising results, but they are computationally expensive and suffer from instability during training. In this article, we propose a novel approach for future frame prediction that combines the encoding capabilities of 3-D CNNs with the sequence modeling capabilities of Transformers. We also propose a spatial self-attention mechanism and a novel neighborhood pixel intensity loss to preserve structural information and local intensity, respectively. Our approach outperforms existing methods in terms of structural similarity (SSIM), peak signal-to-noise ratio (PSNR), and learned perceptual image patch similarity (LPIPS) scores on five public datasets. More precisely, our model exhibited an average improvement of 4.64%, 18.5%, and 42% concerning SSIM, PSNR, and LPIPS for the second most proficient method correspondingly, across all datasets. The results demonstrate the effectiveness of our proposed method in generating high-quality predictions of future frames. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Hou, Y.
AU  - Song, X.
AU  - Hou, C.
AU  - Wang, Z.
AU  - Xiong, Z.
AU  - Ma, D.
TI  - WSPTGAN for Global Ocean Surface Wind Speed Generation With High Temporal Resolution and Spatial Coverage
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4102719
DO  - 10.1109/TGRS.2024.3369640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186975176&doi=10.1109%2fTGRS.2024.3369640&partnerID=40&md5=f55881462bc088d83fb00c43575ec3af
AB  - Obtaining global ocean surface wind speed data with high temporal resolution and spatial coverage is a challenging task. Due to the lack of widely applicable direct measurement methods and algorithms, current research and data products can only achieve good performance in a small spatial range or at low temporal resolution. In this article, a generative adversarial network (GAN) with a transformer structure called Wind Speed Prediction transformer-GAN (WSPTGAN) is proposed to generate wind speed data with good spatial coverage and high temporal resolution for areas. The WSPTGAN is trained with the proposed image-like wind speed data combined partial missing dataset (CPMD), which is combined with the fifth generation of the European Center for Medium-Range Weather Forecast (ECMWF) reanalysis data and Advanced Scatterometer (ASCAT) data from Meteorological Operational satellites. Thanks to the defective data learning mechanism (DDLM), sequential-wise multihead self-attention mechanism (SMSM), and sequence feature adaptive verification mechanism (SFAVM) in the proposed algorithm, the obtained model has good wind speed prediction accuracy with root mean square error (RMSE) of 0.8984 m/s and can achieve multistep 10-min wind speed data generation within the global ocean. After comparison with five state-of-the-art prediction models, it is confirmed that the algorithm in this article is able to make better use of the defective data for learning and prediction of wind field trends in global ocean regions. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shao, Z.
AU  - Han, J.
AU  - Debattista, K.
AU  - Pang, Y.
TI  - DCMSTRD: End-to-end Dense Captioning via Multi-Scale Transformer Decoding
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 7581
EP  - 7593
DO  - 10.1109/TMM.2024.3369863
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187026549&doi=10.1109%2fTMM.2024.3369863&partnerID=40&md5=f3e2b76b1d93d998ce12d615a9eb4164
AB  - Dense captioning creates diverse Region of Interests (RoIs) descriptions for complex visual scenes. While promising results have been obtained, several issues persist. In particular: 1) it is hard to find the optimal parameters for artificially designed modules (e.g., non-maximum suppression (NMS)) causing redundancies and fewer interactions to benefit the two sub-tasks of RoI detection and RoI captioning; 2) the absence of a multi-scale decoder in current methods hinders the acquisition of scale-invariant features, thus leading to poor performance. To tackle these limitations, we bypass the artificially designed modules and present an end-to-end dense captioning framework via multi-scale transformer decoding (DCMSTRD). DCMSTRD solves dense captioning by set matching and prediction instead. To further enhance the discriminative quality of the multi-scale representations during caption generation, we introduce a multi-scale module, termed multi-scale language decoder (MSLD). Our proposed method tested on standard datasets achieves a mean Average Precision (mAP) of 16.7% on the challenging VG-COCO dataset, demonstrating its effectiveness against the current methods. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, G.
AU  - Wang, Q.
AU  - Dong, B.
AU  - Ma, R.
AU  - Liu, N.
AU  - Fu, H.
AU  - Xia, Y.
TI  - : Edge-Aware Multimodal Transformer for RGB-D Salient Object Detection
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 14
DO  - 10.1109/TNNLS.2024.3358858
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187260239&doi=10.1109%2fTNNLS.2024.3358858&partnerID=40&md5=7bf88bee6aaf6c2ea9340032557eb28e
AB  - RGB-D salient object detection (SOD) has gained tremendous attention in recent years. In particular, transformer has been employed and shown great potential. However, existing transformer models usually overlook the vital edge information, which is a major issue restricting the further improvement of SOD accuracy. To this end, we propose a novel edge-aware RGB-D SOD transformer, called, which explicitly models the edge information in a dual-band decomposition framework. Specifically, we employ two parallel decoder networks to learn the high-frequency edge and low-frequency body features from the low-and high-level features extracted from a two-steam multimodal backbone network, respectively. Next, we propose a cross-attention complementarity exploration module to enrich the edge/body features by exploiting the multimodal complementarity information. The refined features are then fed into our proposed color-hint guided fusion module for enhancing the depth feature and fusing the multimodal features. Finally, the resulting features are fused using our deeply supervised progressive fusion module, which progressively integrates edge and body features for predicting saliency maps. Our model explicitly considers the edge information for accurate RGB-D SOD, overcoming the limitations of existing methods and effectively improving the performance. Extensive experiments on benchmark datasets demonstrate that is an effective RGB-D SOD framework that outperforms the current state-of-the-art models, both quantitatively and qualitatively. A further extension to RGB-T SOD demonstrates the promising potential of our model in various kinds of multimodal SOD tasks. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kong, J.
AU  - Fan, X.
AU  - Zuo, M.
AU  - Yan, W.
AU  - Jin, X.
TI  - FICformer: A Multi-factor Fuzzy Bayesian Imputation Cross-former for Big Data-driven Agricultural Decision Support Systems
PY  - 2024
T2  - IEEE Transactions on Fuzzy Systems
SP  - 1
EP  - 12
DO  - 10.1109/TFUZZ.2024.3363213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187011443&doi=10.1109%2fTFUZZ.2024.3363213&partnerID=40&md5=aed0d20f813b37f90996b7770eaecb22
AB  - Smart agricultural decision support systems (DSS) leverage big data technology to generate efficient decision recommendations. However, missing values in sensor data can lead to cumulative errors and reduced accuracy in data analysis, compromising the precision of these decision systems. To address this issue, we propose an intelligent multi-factor prediction framework for smart agriculture environments. This framework utilizes fuzzy Bayesian data imputation to minimize filling errors and provide a reliable data foundation for decision systems. The framework includes a fuzzy Bayesian module for imputing missing data, resulting in complete datasets and enhancing interpretability. Additionally, a multi-factor prediction model is established within an encode-decode framework, incorporating dimension-temporal cross-attention layers to capture and extract correlations among multiple factors. Extensive experiments demonstrate that our proposed model outperforms single-factor prediction, achieving a 13.6&#x0025; increase in correlation. These results validate the effectiveness of the imputation module in enhancing forecasting precision and reliability, thereby assisting agricultural DSS in meeting evolving demands. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Tan, Z.
AU  - Zhang, G.
AU  - Zhang, W.
AU  - Li, Z.
TI  - Learn More and Learn Usefully: Truncation Compensation Network for Semantic Segmentation of High-Resolution Remote Sensing Images
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4403814
SP  - 1
EP  - 14
DO  - 10.1109/TGRS.2024.3363742
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186984033&doi=10.1109%2fTGRS.2024.3363742&partnerID=40&md5=b51fc04209ebcc4ff8f79e4a615044f4
AB  - Semantic segmentation of high-resolution remote-sensing images (HR-RSIs) focuses on classifying each pixel of input images. Recent methods have incorporated a downscaled global image as supplementary input to alleviate global context loss from cropping. Nonetheless, these methods encounter two key challenges: diminished detail in features due to downsampling of the global auxiliary image (GAI) and noise from the same image that reduces the network's discriminability of useful and useless information. To overcome these challenges, we propose a truncation compensation network (TCNet) for HR-RSI semantic segmentation. TCNet features three pivotal modules: the guidance feature extraction module (GFM), the related-category semantic enhancement module (RSEM), and the global-local contextual cross-fusion module (CFM). GFM focuses on compensating for truncated features in the local image and minimizing noise to emphasize learning of useful information. RSEM enhances discernment of global semantic information by predicting spatial positions of related categories and establishing spatial mappings for each. CFM facilitates local image semantic segmentation with extensive contextual information by transferring information from global to local feature maps. Extensive testing on the ISPRS, BLU, and GID datasets confirms the superior efficiency of TCNet over other approaches.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Li, J.
AU  - Hu, Y.
AU  - Chen, H.
TI  - A Battery Prognostics and Health Management Technique Based on Knee Critical Interval and Linear Complexity Self-Attention Transformer in Electric Vehicles
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10216
EP  - 10230
DO  - 10.1109/TITS.2024.3355436
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186073730&doi=10.1109%2fTITS.2024.3355436&partnerID=40&md5=b75d9b34de91b6fe8cd8e837502623f0
AB  - Accurately estimating the remaining useful life (RUL) of lithium-ion batteries is crucial for the safe and reliable operation of batteries in electric vehicles. Due to the slow aging process and complex chemical reactions of batteries, it is challenging to obtain the complete battery lifecycle data to predict the RUL. To embrace these challenges, we propose an intelligent Transformer network with the improved self-attention mechanism based on data of the key interval area. Firstly, the knee-point and knee-onset in the capacity decay curve of the battery are identified by the Bacon-Watts model. The feature data that does not meet the minimum aging period between the knee-point and knee-onset in the aging curve is eliminated to ensure the accuracy and quickness of the prediction. Secondly, the denoising autoencoder (DAE) is used to mine the correlation between the aging characteristics in this interval and the low-dimensional hidden feature of battery aging is reconstructed. Finally, the Transformer network with improved multi-head self-attention mechanism is taken to capture the dependencies between features at different positions. A feed-forward neural network is employed to determine the weights of the features at the different sample time, which are then used in conjunction with fully connected layers and a prediction layer to estimate the remaining lifespan of lithium batteries. The proposed method is validated using the CALCE battery dataset. Simulation results show that the method achieves accurate and fast health prognosis with an average error of 0.0091 for the accuracy metric RE when only key feature interval data are used. There is also a significant advantage in computation time compared to other state-of-the-art algorithms, and our method can provide more accurate and faster health prognosis of batteries.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Ma2024Battery
ER  -

TY  - JOUR
AU  - Xu, L.
AU  - Tang, H.
AU  - Li, H.
AU  - Li, X.
AU  - Gulliver, T.A.
AU  - Le, K.N.
TI  - Secrecy Performance Intelligent Prediction for Mobile Vehicular Networks: An DI-CNN Approach
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7363
EP  - 7373
DO  - 10.1109/TITS.2024.3352668
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187271499&doi=10.1109%2fTITS.2024.3352668&partnerID=40&md5=a5b250f22c11fba2ddeba5c5e7189e58
AB  - The rapid expansion of Internet of Vehicles (IoV) networks has facilitated high throughput and reliable vehicular communications. Mobile vehicular networks face the challenges: diversification of network equipment, user mobility, and the broadcast nature of wireless channels, so physical layer security modeling of IoV communication systems has become important. The complexity of wireless communication channels makes real-time prediction of secrecy performance challenging. This paper presents an analysis of secrecy performance for mobile vehicular networks. To ensure data secure transmission, we have employed the decode-and-forward (DF) relaying scheme. The signal-to-noise ratio (SNR) of the effective end-to-end link is employed to obtain the mathematical expression results, which can evaluate the secrecy performance. The theoretical secrecy performance is confirmed via simulation. Then, we design a dense-inception convolution neural network (DI-CNN) model, and propose a DI-CNN-based intelligent prediction algorithm.Transformer, ShuffleNetV2, RegNet and YOLOv5 methods are employed to analyze the performance of DI-CNN algorithm. It is shown that the DI-CNN approach has a prediction accuracy that is 48.8% better than Transformer.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2024Secrecy
ER  -

TY  - JOUR
AU  - Feng, J.
AU  - Wang, Q.
AU  - Zhang, G.
AU  - Jia, X.
AU  - Yin, J.
TI  - CAT: Center Attention Transformer With Stratified Spatial-Spectral Token for Hyperspectral Image Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5615415
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3374954
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187335729&doi=10.1109%2fTGRS.2024.3374954&partnerID=40&md5=f2e36f21c834daf69c539e94aeeb5496
AB  - Most hyperspectral image (HSI) classification methods rely on square patch sampling to incorporate spatial information, thereby facilitating the label prediction of the center pixel. However, square patch sampling introduces numerous heterogeneous pixels, which could distort the label prediction of the center pixel. Moreover, it generates fixed training patch sample for each center pixel, hampering the performance of transformer-based models requiring a large number of training data. To address the above problems, we proposed center attention transformer (CAT) with stratified spatial-spectral token generated by superpixel sampling for HSI classification. First, to mitigate the inference of heterogeneous pixels, we propose sampling from superpixel region (SSR) mechanism to generate purer image cubes than traditional square neighborhood. Second, to expand the training data for transformer, we propose multiple stratified random sampling (MSRS) mechanism, which generates ample training samples without introducing additional labels. Finally, to more effectively extract information from the sampled patch tokens, we propose spatial-spectral token generation mechanism and CAT structure with Gaussian positional embedding (GPE). This framework can extract long-range correlations of spectral information and pay more attention on the center pixel in spatial dimension. Experimental results on three HSI datasets demonstrate the performance of our proposed method CAT outperforms several state-of-the-art methods. The code of this work is available at https://github.com/fengjiaqi927/CAT-Center_Attention_Transformer.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tian, Y.
AU  - Li, J.
AU  - Fu, H.
AU  - Zhu, L.
AU  - Yu, L.
AU  - Wan, L.
TI  - Self-Mining the Confident Prototypes for Source-Free Unsupervised Domain Adaptation in Image Segmentation
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 7709
EP  - 7720
DO  - 10.1109/TMM.2024.3370678
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187021315&doi=10.1109%2fTMM.2024.3370678&partnerID=40&md5=ba6345e44cd7e34788f69af7e2afa4ee
AB  - This paper studies a practical Source-free unsupervised domain adaptation (SFUDA) problem, which transfers knowledge of source-trained models to the target domain, without accessing the source data. It has received increasing attention in recent years, while the prior arts focus on designing adaptation strategies, ignoring that different target samples exhibit different transfer abilities on the source model. Additionally, we observe pixel-wise class prediction is typically accompanied by ambiguity issue, i.e., prediction errors often occur between several confusing classes. In this study, we propose a dual-branch collaborative learning framework that aims to achieve reliable knowledge transfer from important samples to the rest by fully mining confident prototypes in the target data. Concretely, we first partition the target data into confident samples and uncertain samples via a new class-ranking reliability score and then utilize the latent features from the confident branch as guidance to promote the learning of the uncertain branch. For ambiguity issue, we propose a feature relabelling module, which exploits reliable prototypes in the mini-batch as well as in the target data to refine labels of uncertain features. We further deploy the proposed framework to commonly used CNN and state-of-the-art Transformer architectures and reveal the potential to promote the generalization ability of backbone models. Experimental results on both natural and medical benchmark datasets verify that our proposed approach exceeds state-of-the-art SFUDA methods with large margins, and achieves comparable performance to existing UDA methods.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Zhang, B.
AU  - Hu, R.
AU  - Gu, K.
AU  - Zhai, G.
AU  - Dong, J.
TI  - Underwater Image Quality Assessment: Benchmark Database and Objective Method
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 7734
EP  - 7747
DO  - 10.1109/TMM.2024.3371218
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186969398&doi=10.1109%2fTMM.2024.3371218&partnerID=40&md5=a63567e4bec6b5c99d9085685560c5c3
AB  - Underwater image quality assessment (UIQA) plays a crucial role in monitoring and detecting the quality of acquired underwater images in underwater imaging systems. Currently, the investigation of UIQA encounters two major challenges. First, a lack of large-scale UIQA databases for benchmarking UIQA algorithms remains, which greatly restricts the development of UIQA research. The other limitation is that there is a shortage of effective UIQA methods that can faithfully predict underwater image quality. To alleviate these two challenges, in this paper, we first construct a large-scale UIQA database (UIQD). Specifically, UIQD contains a total of 5369 authentic underwater images that span abundant underwater scenes and typical quality degradation conditions. Extensive subjective experiments are executed to annotate the perceived quality of the underwater images in UIQD. Based on an in-depth analysis of underwater image characteristics, we further establish a novel baseline UIQA metric that integrates channel and spatial attention mechanisms and a transformer. Channel- and spatial attention modules are used to capture the image channel and local quality degradations, while the transformer module characterizes the image quality from a global perspective. Multilayer perception is employed to fuse the local and global feature representations and yield the image quality score. Extensive experiments conducted on UIQD demonstrate that the proposed UIQA model achieves superior prediction performance compared with the state-of-the-art UIQA and IQA methods.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, L.
AU  - Lu, W.
AU  - Yu, H.
AU  - Yao, F.
AU  - Sun, X.
AU  - Fu, K.
TI  - SFTformer: A Spatial-Frequency-Temporal Correlation-Decoupling Transformer for Radar Echo Extrapolation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4102415
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3367857
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186087464&doi=10.1109%2fTGRS.2024.3367857&partnerID=40&md5=f1fa8d83bf0bdf9e9ebda5f61fcc2ff5
AB  - Extrapolating future weather radar echoes from past observations is a complex task vital for precipitation nowcasting. The spatial morphology and temporal evolution of radar echoes exhibit a certain degree of correlation, yet they also possess independent characteristics. Existing methods learn unified spatial and temporal representations in a highly coupled feature space, emphasizing the correlation between spatial and temporal features but neglecting the explicit modeling of their independent characteristics, which may result in mutual interference between them. To effectively model the spatiotemporal dynamics of radar echoes, we propose a spatial-frequency-temporal correlation-decoupling transformer (SFTformer). The model leverages stacked multiple SFT-Blocks to not only mine the correlation of the spatiotemporal dynamics of echo cells but also avoid the mutual interference between the temporal modeling and the spatial morphology refinement by decoupling them. Furthermore, inspired by the practice that weather forecast experts effectively review historical echo evolution to make accurate predictions, SFTfomer incorporates a joint training paradigm for historical echo sequence reconstruction and future echo sequence prediction. Experimental results on the HKO-7 dataset and ChinaNorth-2021 dataset demonstrate the superior performance of SFTfomer in short-term (1 h), mid-term (2 h), and long-term (3 h) precipitation nowcasting.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lu, W.
AU  - Nguyen, M.
TI  - A Lightweight Transformer With Multigranularity Tokens and Connected Component Loss for Land Cover Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4403316
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2024.3364381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185549303&doi=10.1109%2fTGRS.2024.3364381&partnerID=40&md5=bbcb2096cf7e2a80c18ddad4a5f01c4f
AB  - Onboard land cover classification provides ever-updating land cover information, supporting various intelligent satellite applications that demand timely autonomous decision-making based on current and continuous land cover data. However, due to space, weight, and power constraints, satellites possess limited computational resources, rendering them unable to execute conventional land cover classification networks. In response to this challenge, we have designed a lightweight network for land cover classification featuring two efficient transformer attention mechanisms enhanced by multigranularity tokens. Diverging from traditional transformer attention mechanisms that solely capture token-to-token correlations at a single granularity, our approach splits the tokens into four segments and uses atrous convolutions across various dilation rates to aggregate token segments from diverse receptive fields, forming token segment combinations that encompass not only point information but also information from patches of varying sizes. These multigranularity tokens are subsequently processed through the windowed squeeze axial transformer attention (WSATA) and multigranularity bilevel routing attention (MGBRA) for feature enhancement. In another aspect, empirical observations reveal that prediction errors are more prone to manifest on land covers of small extent; however, conventional methods treat all pixels uniformly. This realization motivates us to propose a novel network-agnostic loss named connected component loss (CCL), which specifically targets small-scale land covers and their boundaries. Quantitative metrics and visual interpretations from comprehensive experiments confirm that our method attains state-of-the-art accuracy on two land cover classification datasets while exhibiting significantly faster inference speed than other lightweight networks, underscoring the practical potential of our method on embedded systems.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, J.
AU  - Dong, Z.
AU  - Yao, X.
AU  - Xi, X.
TI  - Optimizing collaboration decisions in technological innovation through machine learning: identify trend and partners in collaboration-knowledge interdependent networks
PY  - 2024
T2  - Annals of Operations Research
DO  - 10.1007/s10479-024-05867-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185259238&doi=10.1007%2fs10479-024-05867-z&partnerID=40&md5=51a83173cda7ad256e63bf7c43fc413e
AB  - Technological innovation, which is exemplified by the convergence of diverse knowledge domains and collaborative efforts across industries, has emerged as the primary catalyst for organizations seeking to enhance their business operations and attain competitive advantages. Consequently, optimizing decision-making processes is imperative for organizations to adeptly forecast technological convergence trends and strategically identify suitable collaboration partners. Since a firm is embedded in both a collaboration network and a knowledge network, it is necessary to consider a dual network structure and the interdependence of the two subnetworks in terms of technological convergence. Regrettably, limited attention has been given to this aspect and the evolving nature of knowledge networks in the existing studies. To address these issues, this study proposes an innovative research framework for technological convergence, combining a dynamic link prediction model using a transformer with the theory of interdependent networks, which enhances predictive algorithms regarding the convergence of new technologies and simultaneously identifies potential collaborative partners. Patent data from the medical device field are collected to conduct experiments. The results indicate that the proposed approach yields a 15% improvement in the area under the curve (AUC) metric over that of the recurrent neural network (RNN)-based dynamic model and a gain of more than 25% compared to the machine learning-based static model. Our study has important theoretical and practical implications for improving business operations and innovation strategies. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Zhao2024Optimizing
ER  -

TY  - JOUR
AU  - Feng, Q.
AU  - Wang, S.
AU  - Li, Y.
TI  - Analysis of DAS Seismic Noise Generation and Elimination Process Based on Mean-SDE Diffusion Model
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5905613
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2024.3362853
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184803913&doi=10.1109%2fTGRS.2024.3362853&partnerID=40&md5=b30a372d4635b99654dfebca62dae533
AB  - Suppressing various noises while achieving precise signal reconstruction in distributed acoustic sensing vertical seismic profiling (DAS VSP) remains a challenge. Existing denoising methods are insufficient due to factors such as the unknown noise-disturbing mechanism, low signal-to-noise ratio (SNR), and limited training data. Therefore, this study proposes the Mean-stochastic differential equation (SDE) diffusion model as an advanced solution. Built upon the standard diffusion model, which incorporates forward and backward diffusion processes, our model introduced three modifications to enhance performance: 1) improving the forward diffusion process: transforming the final state into a combination of the noisy DAS VSP and Gaussian noise. This adjustment allows precise representations of multitype noise generation and facilitates backward sampling; 2) enhancing noise prediction between successive steps in the backward process: a nonlinear activation-free network (NAFnet) with a time multilayer perception (MLP) was employed to provide accurate noise predictions at different states; and 3) addressing training instability inherent in standard diffusion: the objective function is modified to seek the optimal trajectory of the best quality of signal reconstruction rather than directly evaluating the noise prediction. The forward diffusion is a dynamic evolution of adding noise to the pure signal, while the backward processing aims to remove the noise step by step. Comprehensive experiments demonstrate the superiority of our method in diverse noise suppression, signal resolution enhancement, and amplitude preservation. Moreover, grounded in physics-based equations, our method exhibits less dependence on training data compared to conventional deep learning methods. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fang, H.
AU  - Zhang, T.
AU  - Zhou, X.
AU  - Zhang, X.
TI  - Learning Better Video Query with SAM for Video Instance Segmentation
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
SP  - 1
EP  - 1
DO  - 10.1109/TCSVT.2024.3361076
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184324922&doi=10.1109%2fTCSVT.2024.3361076&partnerID=40&md5=b4beb4aa5800df66cd602844e33f1845
AB  - Recently, Transformer-based offline video instance segmentation (VIS) solutions have made significant progress by decomposing the whole task into global segmentation map generation and instance discrimination. We argue that the quality of video queries that represent all instances in a video clip is crucial for offline VIS methods. Existing methods typically interact video queries with dense spatio-temporal features, resulting in significant computational complexity and redundant information. Thus, we propose a novel video instance segmentation framework, LBVQ, dedicated to learning better video queries. Specifically, we first obtain the frame queries for each frame independently without any complex inter-frame spatial-temporal association operations. Secondly, we propose an adaptive query initialization module (AQI), which adaptively integrates frame queries to initialize video queries instead of traditional random initialization strategies. This initialization method preserves rich instance clues and accelerates the optimization of the whole model. Finally, to enhance the quality of video queries, we propose a query propagation module (QPM) that captures relevant instance information in frame queries frame by frame, greatly improving the model&#x2019;s understanding of long videos. By learning higher quality video queries, LBVQ achieves the state-of-the-art on VIS benchmarks with a ResNet-50 backbone: 52.2 AP, 44.8 AP on YouTube-VIS 2019 &#x0026; 2021. Moreover, LBVQ achieves 39.7 AP on YouTube-VIS 2022 and 22.2 AP on OVIS, demonstrating superior potential for long videos. To further improve the quality of segmentation masks, a large-scale pretrained SAM is employed to refine the segmentation results. Code is available at https://github.com/fanghaook/LBVQ. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, Y.
AU  - Taylor, N.C.
AU  - Conkey, A.
AU  - Liu, W.
AU  - Hermans, T.
TI  - Latent Space Planning for Multiobject Manipulation With Environment-Aware Relational Classifiers
PY  - 2024
T2  - IEEE Transactions on Robotics
VL  - 40
SP  - 1724
EP  - 1739
DO  - 10.1109/TRO.2024.3360956
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184336986&doi=10.1109%2fTRO.2024.3360956&partnerID=40&md5=737520f57c56900928e136e2bed26ef6
AB  - Objects rarely sit in isolation in everyday human environments. If we want robots to operate and perform tasks in our human environments, they must understand how the objects they manipulate will interact with structural elements of the environment for all but the simplest of tasks. As such, we would like our robots to reason about how multiple objects and environmental elements relate to one another and how those relations may change as the robot interacts with the world. We examine the problem of predicting interobject and object-environment relations between previously unseen objects and novel environments purely from partial-view point clouds. Our approach enables robots to plan and execute sequences to complete multiobject manipulation tasks defined from logical relations. This removes the burden of providing explicit, continuous object states as goals to the robot. We explore several different neural network architectures for this task. We find the best performing model to be a novel transformer-based neural network that both predicts object-environment relations and learns a latent-space dynamics function. We achieve reliable sim-to-real transfer without any fine-tuning. Our experiments show that our model understands how changes in observed environmental geometry relate to semantic relations between objects.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, N.
AU  - Lu, Z.
AU  - Tian, H.
AU  - Kang, R.
AU  - Cao, J.
AU  - Zhang, Y.
AU  - Liu, A.-A.
TI  - Learning to Supervise Knowledge Retrieval Over a Tree Structure for Visual Question Answering
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 6689
EP  - 6700
DO  - 10.1109/TMM.2024.3355638
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182950829&doi=10.1109%2fTMM.2024.3355638&partnerID=40&md5=7d1fac965badbe081628ed3610e55731
AB  - Knowledge-based visual question answering (KBVQA) aims to retrieve the external knowledge out of images to answer questions. However, current methods always introduce various irrelevant knowledge due to two drawbacks: (1) Synonymy issue. Existing methods heavily rely on words from questions or object labels in images to match knowledge from databases, which disregards the same word may hold multiple meanings within different contexts. (2) Knowledge uncertainty issue. Due to the absence of supervisory signals, recent methods can not determine which knowledge is applicable for answer inference, which can mislead to admit useless knowledge. To address these two problems, we propose to supervise the process of knowledge retrieval over a tree structure for KB-VQA task. For the synonymy issue, we construct a hierarchical knowledge tree to capture the subordination information between knowledge facts, mitigating the impact of synonyms on knowledge retrieval. For the knowledge uncertainty issue, we use the retrieval history as the ground truth to supervise the knowledge retrieval, which facilitates the QA model to form an explicit path of knowledge facts for answer understanding. Finally, we integrate the image, question, and retrieved knowledge into a variant of transformer to predict answers. Experimental results validate the effectiveness of the proposed method on KR-VQA, OK-VQA and VQA v2 datasets.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Li, X.
AU  - Sheng, L.
AU  - Zhu, M.
AU  - Lan, X.
AU  - Gu, F.
TI  - Multiomics-integrated deep language model enables in silico genome-wide detection of transcription factor binding site in unexplored biosamples
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 1
C7  - btae013
DO  - 10.1093/bioinformatics/btae013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183925232&doi=10.1093%2fbioinformatics%2fbtae013&partnerID=40&md5=ba698934edd0b2ab37ac0a045e5bb026
AB  - Motivation: Transcription factor binding sites (TFBS) are regulatory elements that have significant impact on transcription regulation and cell fate determination. Canonical motifs, biological experiments, and computational methods have made it possible to discover TFBS. However, most existing in silico TFBS prediction models are solely DNA-based, and are trained and utilized within the same biosample, which fail to infer TFBS in experimentally unexplored biosamples. Results: Here, we propose TFBS prediction by modified TransFormer (TFTF), a multimodal deep language architecture which integrates multiomics information in epigenetic studies. In comparison to existing computational techniques, TFTF has state-of-the-art accuracy, and is also the first approach to accurately perform genome-wide detection for cell-type and species-specific TFBS in experimentally unexplored biosamples. Compared to peak calling methods, TFTF consistently discovers true TFBS in threshold tuning-free way, with higher recalled rates. The underlying mechanism of TFTF reveals greater attention to the targeted TF’s motif region in TFBS, and general attention to the entire peak region in non-TFBS. TFTF can benefit from the integration of broader and more diverse data for improvement and can be applied to multiple epigenetic scenarios. Availability and implementation: We provide a web server (https://tftf.ibreed.cn/) for users to utilize TFTF model. Users can train TFTF model and discover TFBS with their own data. © The Author(s) 2024. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Nareklishvili, M.
AU  - Geitle, M.
TI  - Deep Ensemble Transformers for Dimensionality Reduction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 12
DO  - 10.1109/TNNLS.2024.3357621
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184325644&doi=10.1109%2fTNNLS.2024.3357621&partnerID=40&md5=5b0b10a821a3aebcb77cdb6701a6ca12
AB  - We propose deep ensemble transformers (DETs), a fast, scalable approach for dimensionality reduction problems. This method leverages the power of deep neural networks and employs cascade ensemble techniques as its fundamental feature extraction tool. To handle high-dimensional data, our approach employs a flexible number of intermediate layers sequentially. These layers progressively transform the input data into decision tree predictions. To further enhance prediction performance, the output from the final intermediate layer is fed through a feed-forward neural network architecture for final prediction. We derive an upper bound of the disparity between the generalization error and the empirical error and demonstrate that it converges to zero. This highlights the generalizability of our method to parameter estimation and feature selection problems. In our experimental evaluations, DETs outperform existing models in terms of prediction accuracy, representation learning ability, and computational time. Specifically, the method achieves over 95% accuracy in gene expression data and can be trained on average 50% faster than traditional artificial neural networks (ANNs). IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, H.
AU  - Yan, C.
AU  - Chen, Z.
AU  - Wang, P.
TI  - A K-Shape Clustering Based Transformer-Decoder Model for Predicting Multi-Step Potentials of Urban Mobility Field
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10298
EP  - 10312
DO  - 10.1109/TITS.2024.3355211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184306462&doi=10.1109%2fTITS.2024.3355211&partnerID=40&md5=308b975049d821b9b49eb4089a2a5af0
AB  - Identifying and predicting the travel hotspots in urban areas can provide crucial support for building intelligent transportation systems. In this study, we propose to use the potentials of urban mobility field to identify the travel hotspots and develop a K-shape clustering transformer-decoder (KSC-TD) model to predict multi-step potentials. In the KSC-TD model, the K-shape clustering method is used to cluster the grids with similar potential time series, whereas the transformer-decoder model is trained for each cluster of grids by integrating the multi-head masked attention mechanism and the scheduled sampling strategy. The developed KSC-TD model is validated using the license plate recognition (LPR) data of Changsha (a major southern city of China). Results indicate that the proposed KSC-TD model outperforms nine benchmark models in predicting the multi-step potentials of urban mobility field, offering a new and effective approach for anticipating urban travel hotspots.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2024K-Shape
ER  -

TY  - JOUR
AU  - Chen, B.
AU  - Zheng, Q.
AU  - Sun, W.
AU  - Yang, G.
AU  - Feng, T.
AU  - Wang, Y.
TI  - Geo-STO3Net: A Deep Neural Network Integrating Geographical Spatiotemporal Information for Surface Ozone Estimation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4102214
SP  - 1
EP  - 14
DO  - 10.1109/TGRS.2024.3358397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184012090&doi=10.1109%2fTGRS.2024.3358397&partnerID=40&md5=72269bace3f7a587f03a67fb8a58d6b3
AB  - The escalating surface ozone (O3) pollution in urban areas throughout China has raised significant concerns due to its detrimental impacts on public health, local environment, and agriculture. Despite numerous efforts in surface O3 estimation, intricate geographical spatiotemporal interactions of the potential predictors have been largely overlooked. This limitation has significantly constrained the O3 estimation accuracy. To address this issue, we proposed a novel deep neural network (DNN), named Geo-STO3Net, to effectively integrate adjacent geographical spatiotemporal information from meteorological data and satellite observations into surface O3 estimation. The Geo-STO3Net model used a spatial encoder based on the residual network, a temporal encoder based on the Transformer, and a feature decoder based on the DNN to comprehensively capture the intricate geographical spatiotemporal dependencies among the predictors. Our model achieved a cross-validation (CV) R2 value of 0.95, outperforming popular models. The Geo-STO3Net model demonstrated robust spatial and temporal transferability, as evidenced by R2 values of 0.94 and 0.82 in external spatial and temporal validation on monthly scales, respectively. The Geo-STO3Net model's proficiency in handling geographical spatiotemporal information led to substantial performance improvements compared to models lacking this feature, with improved CV R2 values ranging from 0.01 to 0.18. Our findings also highlighted the severe O3 pollution over the Yangtze River Delta (YRD) region in 2022, with average surface O3 concentrations reaching 103.14μg/m3. These evidences indicate that our proposed Geo-STO3Net model can accurately estimate surface O3 concentrations and provide valuable insights into the development of effective control policies.  © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jiao, Y.
AU  - Miao, M.
AU  - Yin, Z.
AU  - Lei, C.
AU  - Zhu, X.
AU  - Zhao, X.
AU  - Nie, L.
AU  - Tao, B.
TI  - A Hierarchical Hybrid Learning Framework for Multi-Agent Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 8
SP  - 10344
EP  - 10354
DO  - 10.1109/TITS.2024.3357479
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184832024&doi=10.1109%2fTITS.2024.3357479&partnerID=40&md5=dbc6fe17d3607b45ac121efee642d9e4
AB  - Accurate trajectory prediction for neighboring agents is crucial for autonomous vehicles navigating complex scenes. Recent deep learning (DL) methods excel in encoding complex interactions but often generate invalid predictions due to difficulties in modeling transient and contingency interactions. This paper proposes a hierarchical hybrid framework that combines DL and reinforcement learning (RL) for multi-Agent trajectory prediction, capturing multi-scale interactions that shape future motion. In the DL stage, Transformer-style graph neural network (GNN) is employed to encode heterogeneous interactions at intermediate and global scales, predicting multi-modal intentions as key future positions for agents. In the RL stage, we divide the scene into local scenes based on DL predictions. A Transformer-based Proximal Policy Optimization (PPO) model, incorporated with vehicle kinematics, generates future trajectories in the form of motion planning shaped by microscopic interactions and guided by a multi-objective reward for balanced agent-centric accuracy and scene-wise compatibility. Experimental results on the Argoverse benchmark and driver-in-loop simulations demonstrate that our framework enhances trajectory prediction feasibility and plausibility in interactive scenes.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Jiao2024Hierarchical
ER  -

TY  - JOUR
AU  - Zhao, Z.
AU  - Dong, X.
AU  - Wang, Y.
AU  - Hu, C.
TI  - Advancing Realistic Precipitation Nowcasting with a Spatiotemporal Transformer-Based Denoising Diffusion Model
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4102115
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3355755
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182943699&doi=10.1109%2fTGRS.2024.3355755&partnerID=40&md5=9b52b857942d7f9e4f70f87f1a369738
AB  - Recent advances in deep learning (DL) have significantly improved the quality of precipitation nowcasting. Current approaches are either based on deterministic or generative models. Deterministic models perceive nowcasting as a spatiotemporal prediction task, relying on distance functions like L2-norm loss for training. While improving meteorological evaluation metrics, they inevitably produce blurry predictions with no reference value. In contrast, generative models aim to capture realistic precipitation distributions and generate nowcasting products by sampling within these distributions. However, designing a generative model that produces realistic samples satisfying meteorological evaluation indexes in real-time remains challenging, given the triple dilemma of generative learning: achieving high sample quality, mode coverage, and fast sampling simultaneously. Recently, diffusion models exhibit impressive sample quality but suffer from time-consuming sampling, severely hindering their application in nowcasting. Moreover, samples generated by the U-Net denoiser of the current denoising diffusion model are prone to yield poor meteorological evaluation metrics such as CSI. To this end, we propose a spatiotemporal transformer-based conditional diffusion model with a rapid diffusion strategy. Concretely, we incorporate an adversarial mapping-based rapid diffusion strategy to overcome the time-consuming sampling process for standard diffusion models, enabling timely nowcasting. In addition, a meticulously designed spatiotemporal transformer-based denoiser is incorporated into diffusion models, remedying the defects in U-Net denoisers by estimating diffusion scores and improving nowcasting skill scores. Case studies of typical weather events such as thunderstorms, as well as quantitative indicators, demonstrate the effectiveness of the proposed method in generating sharper and more precise precipitation forecasts while maintaining satisfied meteorological evaluation metrics.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, C.
AU  - Wang, C.
AU  - Yang, S.
AU  - Zou, Q.
TI  - CircSI-SSL: CircRNA-binding site identification based on self-supervised learning
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 1
C7  - btae004
DO  - 10.1093/bioinformatics/btae004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182501111&doi=10.1093%2fbioinformatics%2fbtae004&partnerID=40&md5=04afb0b4625aa9ca0e944740c53badfa
AB  - Motivation: In recent years, circular RNAs (circRNAs), the particular form of RNA with a closed-loop structure, have attracted widespread attention due to their physiological significance (they can directly bind proteins), leading to the development of numerous protein site identification algorithms. Unfortunately, these studies are supervised and require the vast majority of labeled samples in training to produce superior performance. But the acquisition of sample labels requires a large number of biological experiments and is difficult to obtain. Results: To resolve this matter that a great deal of tags need to be trained in the circRNA-binding site prediction task, a self-supervised learning binding site identification algorithm named CircSI-SSL is proposed in this article. According to the survey, this is unprecedented in the research field. Specifically, CircSI-SSL initially combines multiple feature coding schemes and employs RNA_Transformer for cross-view sequence prediction (self-supervised task) to learn mutual information from the multi-view data, and then fine-tuning with only a few sample labels. Comprehensive experiments on six widely used circRNA datasets indicate that our CircSI-SSL algorithm achieves excellent performance in comparison to previous algorithms, even in the extreme case where the ratio of training data to test data is 1:9. In addition, the transplantation experiment of six linRNA datasets without network modification and hyperparameter adjustment shows that CircSI-SSL has good scalability. In summary, the prediction algorithm based on self-supervised learning proposed in this article is expected to replace previous supervised algorithms and has more extensive application value. © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yuan, K.
AU  - Huang, Y.
AU  - Yang, S.
AU  - Wu, M.
AU  - Cao, D.
AU  - Chen, Q.
AU  - Chen, H.
TI  - Evolutionary Decision-Making and Planning for Autonomous Driving: A Hybrid Augmented Intelligence Framework
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 7339
EP  - 7351
DO  - 10.1109/TITS.2023.3349198
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182935151&doi=10.1109%2fTITS.2023.3349198&partnerID=40&md5=eb551b617b833772911b4a495fb84f76
AB  - Recently, thanks to the introduction of human feedback, Chat Generative Pre-trained Transformer (ChatGPT) has achieved remarkable success in the language processing field. Analogically, human drivers are expected to have great potential in improving the performance of autonomous driving under real-world traffic. Therefore, this study proposes a novel framework for evolutionary decision-making and planning by developing a hybrid augmented intelligence (HAI) method to introduce human feedback into the learning process. In the framework, a decision-making scheme based on interactive reinforcement learning (Int-RL) is first developed. Specifically, a human driver evaluates the learning level of the ego vehicle in real-time and intervenes to assist the learning of the vehicle with a conditional sampling mechanism, which encourages the vehicle to pursue human preferences and punishes the bad experience of conflicts with the human. Then, the longitudinal and lateral motion planning tasks are performed utilizing model predictive control (MPC), respectively. The multiple constraints from the vehicle's physical limitation and driving task requirements are elaborated. Finally, a safety guarantee mechanism is proposed to ensure the safety of the HAI system. Specifically, a safe driving envelope is established, and a safe exploration/exploitation logic based on the trial-and-error on the desired decision is designed. Simulation with a high-fidelity vehicle model is conducted, and results show the proposed framework can realize an efficient, reliable, and safe evolution to pursue higher traffic efficiency of the ego vehicle in both multi-lane and congested ramp scenarios.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Yuan2024Evolutionary
ER  -

TY  - JOUR
AU  - She, R.
AU  - Kang, Q.
AU  - Wang, S.
AU  - Tay, W.P.
AU  - Zhao, K.
AU  - Song, Y.
AU  - Geng, T.
AU  - Xu, Y.
AU  - Navarro, D.N.
AU  - Hartmannsgruber, A.
TI  - PointDifformer: Robust Point Cloud Registration With Neural Diffusion and Transformer
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5701015
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3351286
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182368327&doi=10.1109%2fTGRS.2024.3351286&partnerID=40&md5=8832b0772efed960fb1609a590df3a73
AB  - Point cloud registration is a fundamental technique in 3-D computer vision with applications in graphics, autonomous driving, and robotics. However, registration tasks under challenging conditions, under which noise or perturbations are prevalent, can be difficult. We propose a robust point cloud registration approach that leverages graph neural partial differential equations (PDEs) and heat kernel signatures. Our method first uses graph neural PDE modules to extract high-dimensional features from point clouds by aggregating information from the 3-D point neighborhood, thereby enhancing the robustness of the feature representations. Then, we incorporate heat kernel signatures into an attention mechanism to efficiently obtain corresponding keypoints. Finally, a singular value decomposition (SVD) module with learnable weights is used to predict the transformation between two point clouds. Empirical experiments on a 3-D point cloud dataset demonstrate that our approach not only achieves state-of-the-art performance for point cloud registration but also exhibits better robustness to additive noise or 3-D shape perturbations.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liang, Y.
AU  - Zhang, Z.
AU  - Xian, C.
AU  - He, S.
TI  - Delving into Multi-illumination Monocular Depth Estimation: A New Dataset and Method
PY  - 2024
T2  - IEEE Transactions on Multimedia
SP  - 1
EP  - 15
DO  - 10.1109/TMM.2024.3353544
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182946346&doi=10.1109%2fTMM.2024.3353544&partnerID=40&md5=f156870d2bfd778e6bbf473a6de54718
AB  - Monocular depth prediction has received significant attention in recent years. However, the impact of illumination variations, which can shift scenes to unseen domains, has often been overlooked. To address this, we introduce the first indoor scene dataset featuring RGB-D images captured under multiple illumination conditions, allowing for a comprehensive exploration of indoor depth prediction. Additionally, we propose a novel method, MI-Transformer, which leverages global illumination understanding through large receptive fields to capture depth-attention contexts. This enables our network to overcome local window limitations and effectively mitigate the influence of changing illumination conditions. To evaluate the performance and robustness, we conduct extensive qualitative and quantitative analyses on both the proposed dataset and existing benchmarks, comparing our method with state-of-the-art approaches. The experimental results demonstrate the superiority of our method across various metrics, making it the first solution to achieve robust monocular depth estimation under diverse illumination conditions. We provide the codes, pre-trained models, and dataset openly accessible at <uri>https://github.com/ViktorLiang/midepth</uri>. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, J.
AU  - Sun, Z.
AU  - Zheng, H.
AU  - Zhao, X.
TI  - Stiefel-Attentive Transformer for Refrigerator Odor Detection
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 21
IS  - 4
SP  - 7647
EP  - 7661
DO  - 10.1109/TASE.2023.3346823
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181559607&doi=10.1109%2fTASE.2023.3346823&partnerID=40&md5=5fb630e0b131173d90e1f8c5b0de7968
AB  - The detection and recognition of different odors in refrigerator food odor detection tasks prove to be complicated due to the strong correlation between odor features. Existing electronic nose technology faces challenges in distinguishing and identifying different odors. In this paper, we propose a mixed odor detection model for refrigerators that utilizes the multi-head attention mechanism of the Transformer and constrains it on the Stiefel manifold. Firstly, this constraint can better maintain the orthogonality and stability of attention weights, thus improving the reliability of attention computation. Secondly, for odor detection tasks, the Stiefel manifold can better capture the structural information in vector space, thus better capturing the correlation between odor features, ultimately improving the detection accuracy of the model. The proposed method exhibits superior performance in the refrigerator odor classification task, with an average accuracy of 90.6% and an average F1-score of 0.938. In addition, it demonstrates satisfactory performance in odor concentration prediction (MSE=0.009 and R2=0.983). These results indicate that our model outperforms conventional methods, such as decision trees (DT), support vector machines (SVM), multilayer perceptrons (MLP), and convolutional neural networks (CNN). Note to Practitioners - The motivation of this study is to address the problem of food spoilage detection in smart refrigerators. This research primarily focuses on identifying volatile organic compounds in mixed food, but it has potential applications in other electronic nose systems. Existing odor detection methods in refrigerators are mainly designed for specific foods, defining freshness levels in no more than three categories: fresh, slightly spoiled, and spoiled. These methods fail to accurately predict odor intensity, thereby hindering the reliable activation of disinfection devices. This paper proposes a novel approach that utilizes orthogonal constraints of the Stiefel manifold to reduce the degrees of freedom in the Transformer attention matrix. This constraint enables the model to better capture long-term odor sequence features. As a result, the proposed method can accurately predict five different freshness levels and continuous odor intensity values. The computational process of the Stiefel-Attentive Transformer is described in this paper, and visual comparisons of Transformer attention with and without the Stiefel manifold constraint are included. Experimental results demonstrate the effectiveness of the proposed method in addressing the issue of odor detection in smart refrigerators. Future research endeavors will concentrate on integrating user feedback into the framework of reinforcement learning, aiming to advance the precision of the electronic nose. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, F.
AU  - Xu, C.
AU  - Yang, G.
AU  - Hang, R.
AU  - Liu, Q.
TI  - Masked Spectral-Spatial Feature Prediction for Hyperspectral Image Classification
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4400913
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2023.3344782
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181846927&doi=10.1109%2fTGRS.2023.3344782&partnerID=40&md5=6b0f226bdc865171194a4b132e8b6704
AB  - Transformer has emerged as a preferred method for hyperspectral (HS) image classification due to its ability to model long-range dependency. Whereas the transformer contains numerous parameters and further available labeled HS data is limited, which makes it difficult to get a well-trained transformer. Accordingly, we propose a novel HS image classification method called masked spectral-spatial feature prediction (MSSFP). It aims at helping the transformer understand the complicated spectral-spatial structures without labeled HS data, further improving the classification performance. Specifically, the input HS cube is first divided into two sequences along spectral and spatial dimensions, respectively. Then, a portion of these two sequences are masked out and we train a transformer-based encoder-decoder network to predict the hand-crafted features of masked regions. After pretraining, the encoder is fine-tuned to derive two classification results from input spectral and spatial sequences. Finally, spectral and spatial results are aggregated adaptively based on uncertainty comparison. In comparison experiments, MSSFP outperforms several state-of-the-art HS image classification methods on three benchmark datasets including Indian Pines (IP), Houston (HU), and Pavia University (PUS).  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, M.
AU  - Liu, Q.
AU  - Wang, Y.
TI  - HiT: Building Mapping with Hierarchical Transformers
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5606316
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2024.3355274
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182923879&doi=10.1109%2fTGRS.2024.3355274&partnerID=40&md5=ac4dea943109d1b5123815f68a0a06d1
AB  - Deep-learning-based methods have been extensively explored for automatic building mapping from high-resolution remote sensing images over recent years. While most building mapping models produce vector polygons of buildings for geographic and mapping systems, dominant methods typically decompose polygonal building extraction in some subproblems, including segmentation, polygonization, and regularization, leading to complex inference procedures, low accuracy, and poor generalization. In this article, we propose a simple and novel building mapping method with hierarchical transformers, called HiT, improving polygonal building mapping quality from high-resolution remote sensing images. HiT builds on a two-stage detection architecture by adding a polygon head parallel to classification and bounding box regression heads. HiT simultaneously outputs building bounding boxes and vector polygons, which is fully end-to-end trainable. The polygon head formulates a building polygon as serialized vertices with the bidirectional characteristic, a simple and elegant polygon representation avoiding the start or end vertex hypothesis. Under this new perspective, the polygon head adopts a transformer encoder-decoder architecture to predict serialized vertices supervised by the designed bidirectional polygon loss. Furthermore, a hierarchical attention mechanism combined with convolution operation is introduced in the encoder of the polygon head, providing more geometric structures of building polygons at vertex and edge levels. Comprehensive experiments on two benchmarks (the CrowdAI and Inria datasets) demonstrate that our method achieves a new state-of-the-art (SOTA) in terms of instance segmentation and polygonal metrics compared with SOTA methods. Moreover, qualitative results verify the superiority and effectiveness of our model under complex scenes.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Dong, Z.
AU  - Gu, Y.
AU  - Liu, T.
TI  - Generative ConvNet Foundation Model with Sparse Modeling and Low-Frequency Reconstruction for Remote Sensing Image Interpretation
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5603816
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2023.3348479
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181569234&doi=10.1109%2fTGRS.2023.3348479&partnerID=40&md5=5e5d92578edc8e0a26d760cf39bd8718
AB  - Foundation models offer a highly versatile and precise solution for intelligent interpretation of remote sensing images, thus greatly facilitating various remote sensing applications. Nevertheless, conventional remote sensing foundational models based on generative transformers neglect the consideration of multiscale features and frequency information, limiting their potential for dense prediction tasks in remote sensing scenarios. In this article, we make the first attempt to propose a generative convolutional neural network (ConvNet) foundation model tailored for remote sensing scenarios, which comprises two key components: First, a large dataset named GeoSense, containing approximately nine million diverse remote sensing images, is constructed to enhance the robustness and generalization of the foundation model during the pretraining phase. Second, a sparse modeling and low-frequency reconstruction (SMLFR) framework is designed for self-supervised representation learning of the ConvNet foundation model. Specifically, a sparse modeling strategy is proposed in masked image modeling (MIM), which allows ConvNet to process variable-length sequences by treating unmasked patches as voxels and sparsifying the encoder. In addition, a low-frequency reconstruction target is designed to guide the model's attention toward essential ground object features in remote sensing images, while mitigating unnecessary detail interference. To evaluate the general performance of our proposed foundation model, comprehensive experiments have been carried out on five datasets across three downstream tasks. Experimental results demonstrate that our method consistently achieves state-of-The-Art performance across all the benchmark datasets and downstream tasks. The code and pretrained models will be available at https://github.com/HIT-SIRS/SMLFR.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lu, Y.
AU  - Sirejiding, S.
AU  - Ding, Y.
AU  - Wang, C.
AU  - Lu, H.
TI  - Prompt Guided Transformer for Multi-Task Dense Prediction
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 6375
EP  - 6385
DO  - 10.1109/TMM.2024.3349865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182361796&doi=10.1109%2fTMM.2024.3349865&partnerID=40&md5=34e5bf39ed566015855ad443ae554fb3
AB  - Task-conditional architecture offers advantage in parameter efficiency but falls short in performance compared to state-of-the-art multi-decoder methods. How to trade off performance and model parameters is an important and difficult problem. In this paper, we introduce a simple and lightweight task-conditional model called Prompt Guided Transformer (PGT) to optimize this challenge. Our approach designs a Prompt-conditioned Transformer block, which incorporates task-specific prompts in the self-attention mechanism to achieve global dependency modeling and parameter-efficient feature adaptation across multiple tasks. This block is integrated into both the shared encoder and decoder, enhancing the capture of intra- and inter-task features. Moreover, we design a lightweight decoder to further reduce parameter usage, which accounts for only 2.7% of the total model parameters. Extensive experiments on two multi-task dense prediction benchmarks, PASCAL-Context and NYUD-v2, demonstrate that our approach achieves state-of-the-art results among task-conditional methods while using fewer parameters, and maintains a significant balance between performance and parameter size.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ren, L.
AU  - Wang, H.
AU  - Mo, T.
AU  - Yang, L.T.
TI  - A Lightweight Group Transformer-Based Time Series Reduction Network for Edge Intelligence and Its Application in Industrial RUL Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 10
DO  - 10.1109/TNNLS.2023.3347227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181827748&doi=10.1109%2fTNNLS.2023.3347227&partnerID=40&md5=97d54307c4b5e3a5110a479fd8317769
AB  - Recently, deep learning-based models such as transformer have achieved significant performance for industrial remaining useful life (RUL) prediction due to their strong representation ability. In many industrial practices, RUL prediction algorithms are deployed on edge devices for real-time response. However, the high computational cost of deep learning models makes it difficult to meet the requirements of edge intelligence. In this article, a lightweight group transformer with multihierarchy time-series reduction (GT-MRNet) is proposed to alleviate this problem. Different from most existing RUL methods computing all time series, GT-MRNet can adaptively select necessary time steps to compute the RUL. First, a lightweight group transformer is constructed to extract features by employing group linear transformation with significantly fewer parameters. Then, a time-series reduction strategy is proposed to adaptively filter out unimportant time steps at each layer. Finally, a multihierarchy learning mechanism is developed to further stabilize the performance of time-series reduction. Extensive experimental results on the real-world condition datasets demonstrate that the proposed method can significantly reduce up to 74.7% parameters and 91.8% computation cost without sacrificing accuracy. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Zhou, L.
AU  - Chen, Y.
AU  - Chen, Z.
AU  - Tang, M.
AU  - Wang, J.
TI  - EFCPose: End-to-End Multi-Person Pose Estimation With Fully Convolutional Heads
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 6039
EP  - 6050
DO  - 10.1109/TCSVT.2023.3344049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182375040&doi=10.1109%2fTCSVT.2023.3344049&partnerID=40&md5=8981a0753e999055f47862b597450727
AB  - Mainstream methods of multi-person pose estimation are not end-to-end. Recently, some methods build an end-to-end framework based on the DETR framework, aiming to eliminate the need for hand-crafted modules like heuristic grouping and NMS post-processing. However, these DETR-based methods suffer from a heavy memory burden of processing the high-resolution backbone feature maps with transformers. In this paper, we propose an end-to-end multi-person pose estimation method with a fully convolutional network, termed EFCPose. Different from DETR-based methods, it directly predicts instance-aware poses in a pixel-wise manner with lightweight convolutional heads, avoiding the heavy memory burden. Overall, our method adopts the center-offset formulation and a one-to-one label assignment strategy to achieve the multi-person pose estimation in an end-to-end manner. The main contribution of our fully convolutional heads includes two aspects. On the one hand, we propose an unaligned center-offset representation to learn more reliable semantic centers to replace the inconsistent geometric centers, improving the performance of instance detection. On the other hand, we propose a novel regression strategy named limb-aware adaptive regression, which leverages separate adaptive points to convert challenging long-range offsets into simplified short-range offsets and incorporates limb constraints to elevate the regression quality of joint offsets. Compared with current DETR-based end-to-end methods, EFCPose avoids high computational complexity and achieves higher accuracy. Extensive experiments on COCO Keypoint and CrowdPose benchmarks show that EFCPose outperforms other state-of-the-art bottom-up and single-stage methods without flipping augmentation.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yao, Z.
AU  - Li, X.
AU  - Lang, B.
AU  - Chuah, M.C.
TI  - Goal-LBP: Goal-Based Local Behavior Guided Trajectory Prediction for Autonomous Driving
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6770
EP  - 6779
DO  - 10.1109/TITS.2023.3342706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181568438&doi=10.1109%2fTITS.2023.3342706&partnerID=40&md5=71f60b210641c17f63d709a43fe751ea
AB  - In recent years, the design of models for performing the trajectory prediction task, one of the critical tasks in autonomous driving, has received great attention from researchers. However, accurately predicting future locations is challenging due to the difficulty of learning accurate intentions and modeling multimodality. Historical paths at a certain location can help predict the future trajectory of an agent currently located in that position and address these limitations. In this work, we propose a goal-based local behavior guided model, Goal-LBP, using such information (referred to as local behavior data) to generate potential goals and guide the prediction of trajectories conditioned on such goals. Goal-LBP uses Transformer encoders to extract homogeneous features and attention mechanism to represent the heterogeneous interactions and subsequently uses an encoder-decoder Gated Recurrent Unit (GRU) model to generate predictions. We evaluate our Goal-LBP using two large-scale real-world autonomous driving datasets, namely nuScenes and Argoverse. Our results show that compared to several SOTA models, Goal-LBP achieves the best ADE/FDE performance and it ranked #2 on the leaderboard of the nuScenes trajectory benchmark in June 2023. In addition, we also demonstrate that our local behavior estimator block can be easily added to two existing SOTA methods, namely AgentFormer and LaPred. Adding this LBE block improves the original AgentFormer and LaPred performance by at least 10%.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Yao2024Goal-LBP
ER  -

TY  - JOUR
AU  - Tang, W.
AU  - Qing, L.
AU  - Li, L.
AU  - Wang, Y.
AU  - Zhu, C.
TI  - Progressive Graph Reasoning-Based Social Relation Recognition
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 6012
EP  - 6024
DO  - 10.1109/TMM.2023.3344359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181562454&doi=10.1109%2fTMM.2023.3344359&partnerID=40&md5=5c35db349aa0ae1e4edd818241cb30b8
AB  - Identifying relationships between people from images is essential for studying social activities and interactions, and this has significant potential to further the understanding of human social behaviors. Existing image-based research mainly explores social relationships at the dyadic level, i.e., recognizing pairwise relationships based on visual features of persons, objects, and scenes and their logical constraints. Notably, social relational structures are hierarchically nested, i.e., individuals and dyads are nested within group structures, as indicated in the social relations model (SRM) of social psychology. However, existing computer vision-based studies fail to consider hierarchical nested structures, thus overlooking some of the most important interactions, which leads to poor relation reasoning. To improve the performance of reasoning neural networks, we propose a novel SRM framework for progressive graph reasoning (PGR) to explore social interactions. Specifically, we construct individual-dyad and dyad-group graphs to progressively explore the impact of individuals and groups on recognition of dyadic relationships. A transformer is utilized to fuse visual features and graph reasoning knowledge into a comprehensive representation of social relationships. We demonstrate the effectiveness of the proposed model based on PGR using several public datasets and perform extensive ablation studies to explore the reasons behind its superior performance. Experimental results demonstrate that our proposed model successfully predicts social relationships with higher accuracy than state-of-the-art methods.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Yuan, G.
AU  - Wan, S.
AU  - Zheng, Z.
AU  - Liu, D.
AU  - Zhang, H.
AU  - Li, J.
AU  - Zhou, Y.
AU  - Wang, X.
TI  - A granularity-level information fusion strategy on hypergraph transformer for predicting synergistic effects of anticancer drugs
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - bbad522
DO  - 10.1093/bib/bbad522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182850062&doi=10.1093%2fbib%2fbbad522&partnerID=40&md5=bd976f2d528c73cbc436bdd5fc27b971
AB  - Combination therapy has exhibited substantial potential compared to monotherapy. However, due to the explosive growth in the number of cancer drugs, the screening of synergistic drug combinations has become both expensive and time-consuming. Synergistic drug combinations refer to the concurrent use of two or more drugs to enhance treatment efficacy. Currently, numerous computational methods have been developed to predict the synergistic effects of anticancer drugs. However, there has been insufficient exploration of how to mine drug and cell line data at different granularity levels for predicting synergistic anticancer drug combinations. Therefore, this study proposes a granularity-level information fusion strategy based on the hypergraph transformer, named HypertranSynergy, to predict synergistic effects of anticancer drugs. HypertranSynergy introduces synergistic connections between cancer cell lines and drug combinations using hypergraph. Then, the Coarse-grained Information Extraction (CIE) module merges the hypergraph with a transformer for node embeddings. In the CIE module, Contranorm is a normalization layer that mitigates over-smoothing, while Gaussian noise addresses local information gaps. Additionally, the Fine-grained Information Extraction (FIE) module assesses fine-grained information's impact on predictions by employing similarity-aware matrices from drug/cell line features. Both CIE and FIE modules are integrated into HypertranSynergy. In addition, HypertranSynergy achieved the AUC of 0.930.01 and the AUPR of 0.690.02 in 5-fold cross-validation of classification task, and the RMSE of 13.770.07 and the PCC of 0.810.02 in 5-fold cross-validation of regression task. These results are better than most of the state-of-the-art models. © 2024 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, B.
AU  - Fan, F.
AU  - Ni, R.
AU  - Wang, H.
AU  - Jafaripournimchahi, A.
AU  - Hu, H.
TI  - A Multi-Task Learning Network With a Collision-Aware Graph Transformer for Traffic-Agents Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6677
EP  - 6690
DO  - 10.1109/TITS.2023.3345296
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181564597&doi=10.1109%2fTITS.2023.3345296&partnerID=40&md5=501be9deca17a129ec60a314ea72145f
AB  - It is critical for autonomous vehicles to accurately forecast the future trajectories of surrounding agents to avoid collisions. However, capturing the complex interactions between agents in complex urban scenes is challenging. As a result, complex interactions may impair trajectory prediction accuracy. A trajectory prediction network with an enhanced Graph Transformer (TP-EGT) is proposed to forecast the future trajectories of traffic-agents. A collision-aware Graph Transformer is introduced to capture the complex social interactions between traffic-agents. Following that, an additional interaction prediction task that could predict the interaction probabilities between agents is proposed to mitigate the over-smoothing issue of the Graph Transformer via a multi-task learning strategy. Afterward, the trajectory prediction performance is improved with additional interaction probabilities, which are beneficial for the decision-making and planning modules of autonomous vehicles. Quantitative and qualitative evaluations of TP-EGT on the ETH/UCY and ApolloScape databases demonstrate that the trajectory prediction accuracy of TP-EGT is comparable to the state-of-the-art baseline methods, and the predicted interaction probabilities can help autonomous vehicles comprehend the complex traffic scenes. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2024Multi-Task
ER  -

TY  - JOUR
AU  - Hu, Y.
AU  - Wang, Z.
AU  - Huang, Z.
AU  - Liu, Y.
TI  - PolyRoad: Polyline Transformer for Topological Road-Boundary Detection
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5602112
SP  - 1
EP  - 12
DO  - 10.1109/TGRS.2023.3344103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181582564&doi=10.1109%2fTGRS.2023.3344103&partnerID=40&md5=64a7eb66b0accee1c01bc22fb6fb6c19
AB  - Topological road-boundary detection using remote sensing imagery plays a critical role in creating high-definition (HD) maps and enabling autonomous driving. Previous approaches follow an iterative graph-growing paradigm for road-boundary extraction, where road boundaries are predicted vertex by vertex and instance by instance to output a graph, resulting in limitations of low inference speed. In this work, we formulate the road boundaries as polylines instead of a graph and propose a novel polyline transformer for topological road-boundary detection, termed PolyRoad. PolyRoad is built on the transformer architecture and is capable of detecting all road boundaries in parallel, which greatly improves the training and inference speed compared with the graph-based methods. To perform bipartite matching between the ground truth and predicted polylines, we develop a polyline matching cost to measure the distance, considering the order of open and closed polylines. In addition, we propose three different losses for supervising polyline learning: the order-oriented L1 loss, direction loss, and mask loss. The order-oriented L1 loss provides the point-level supervision to constrain the absolute position of each point of the road-boundary polylines. The direction loss provides the direction-level supervision to constrain the geometry shape of the predicted polylines by supervising the relative position of adjacent points. The mask loss provides the pixel-level supervision of the predicted polylines by converting the vector-format polylines into raster-format binary masks. Comprehensive experiments are conducted on the Topo-boundary dataset. Quantitative and qualitative results show that PolyRoad achieves superior performance than prior methods in both pixel-level and geometry-level metrics. More notably, PolyRoad achieves 3.37 \times and 22.85 \times faster inference speeds than Enhanced-iCurb and VecRoad, respectively.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, J.-N.
AU  - Liu, X.-Q.
AU  - Luo, X.
AU  - Xu, X.-S.
TI  - VOLTER: Visual Collaboration and Dual-Stream Fusion for Scene Text Recognition
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 6437
EP  - 6448
DO  - 10.1109/TMM.2024.3350916
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182365407&doi=10.1109%2fTMM.2024.3350916&partnerID=40&md5=52946557dd6f6c20a667143deb320ab7
AB  - Recently, the approaches of linguistic modeling for scene text recognition have gradually become mainstream, mainly consisting of a vision model (VM), a language model (LM), and an optional fusion module. These methods typically use LM and fusion modules to refine the results of VM-based predictions iteratively. However, the VM mainly consists of a Transformer on top of ResNet. It means the attention mechanism is only applied to the high layer of the VM, ignoring the internal image dependencies in the dense features at multiple scales. Therefore, the results in the VM become the performance bottleneck. Meanwhile, the visual and language features of these methods reside in their own space. In this way, it ignores the alignment before fusion, leading to a failure to achieve maximum information interaction. To address these issues, we propose Visual cOllaboration and duaL-stream fusion for scene TExt Recognition, VOLTER for short. Firstly, a multi-stage Local-Global Collaboration Vision Model (LGC-VM) is constructed to focus on both local and global features at multiple scales, breaking vision bottlenecks to provide a better vision prediction. Secondly, to explicitly align the feature space of VM and LM, we introduce a Vision-Language Contrastive (VLC) module by encouraging positive vision-language pairs to have similar representations. Moreover, a Dual-Stream Feature Enhancement (DSFE) module is proposed for the unidirectional interaction of visual-language features to alleviate the alignment problem of different modalities and execute fusion further. Extensive experiments on benchmark datasets demonstrate that the proposed framework can achieve state-of-the-art performance.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liu, F.
AU  - Xing, L.
AU  - Yuan, C.
AU  - Wu, D.
TI  - A Deep Learning Framework to Explore Influences of Data Noises on Lane-Changing Intention Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6514
EP  - 6526
DO  - 10.1109/TITS.2023.3344647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181570513&doi=10.1109%2fTITS.2023.3344647&partnerID=40&md5=d24193829067799f826a23e8a1e86a5c
AB  - The accuracy of the data is crucial to the real-time prediction of autonomous driving. Due to factors such as weather and the accuracy of data collection equipment, there frequently exist noises in the data collected in real time. Therefore, it is necessary to perform analysis on acquired kinematic features related to driving behavior prediction. This study proposes a novel deep learning framework to explore influences of data noises on lane-changing intention prediction. Kinematic features including the longitudinal distance difference, velocity and acceleration, lateral velocity and acceleration of the vehicles are first extracted from the HighD. Then, the anti-interference performance of deep learning models such as transformer is tested. By comparing dataset with and without noises, we develop an evaluation method containing several predictive performance metrics and statistical measures. The results show that: (1) the longitudinal acceleration of the vehicle has the lowest sensitivity to noise, and the lateral velocity has the weakest anti-interference and the highest sensitivity. (2) The Bi-LSTM model with multi-head attention mechanism performs well in reducing the sensitivity of longitudinal acceleration and prediction accuracy. This study provides valuable information for data acquisition and model selection of real-time driving intention prediction. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; FMS:B; 
LB  - Li2024Deep
ER  -

TY  - JOUR
AU  - Hu, X.
AU  - Zhang, X.
AU  - Wang, F.
AU  - Sun, J.
AU  - Sun, F.
TI  - Efficient Camouflaged Object Detection Network Based on Global Localization Perception and Local Guidance Refinement
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 5452
EP  - 5465
DO  - 10.1109/TCSVT.2023.3349209
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181568845&doi=10.1109%2fTCSVT.2023.3349209&partnerID=40&md5=0e686ad4045150acec54acafff7d8586
AB  - Camouflaged Object Detection (COD) is a challenging visual task due to its complex contour, diverse scales, and high similarity to the background. Existing COD methods encounter two predicaments: One is that they are prone to falling into local perception, resulting in inaccurate object localization; Another issue is the difficulty in achieving precise object segmentation due to a lack of detailed information. In addition, most COD methods typically require larger parameter amounts and higher computational complexity in pursuit of better performance. To this end, we propose a global localization perception and local guidance refinement network (PRNet), that simultaneously addresses performance and computational costs. Through effective aggregation and use of semantic and details information, the PRNet can achieve accurate localization and refined segmentation of camouflaged objects. Specifically, with the help of a Cascaded Attention Perceptron (CAP) designed, we can effectively integrate and perceive multi-scale information to localize camouflaged objects. We also design a Guided Refinement Decoder (GRD) in a top-down manner to extract context information and aggregate details to further refine camouflaged prediction results. Extensive experimental results demonstrate that our PRNet outperforms 12 state-of-the-art models on 4 challenging datasets. Meanwhile, the PRNet has a smaller number of parameters (12.74M), lower computational complexity (10.24G), and real-time inference speed (105FPS). Source codes are available at https://github.com/hu-xh/PRNet.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Ren, P.
AU  - Yang, H.
AU  - Zheng, J.
AU  - Bai, F.
TI  - TEFDTA: A transformer encoder and fingerprint representation combined prediction method for bonded and non-bonded drug-Target affinities
PY  - 2024
T2  - Bioinformatics
VL  - 40
IS  - 1
C7  - btad778
DO  - 10.1093/bioinformatics/btad778
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182271996&doi=10.1093%2fbioinformatics%2fbtad778&partnerID=40&md5=2749174bb3e3185a5bac124026cfe654
AB  - Motivation: The prediction of binding affinity between drug and target is crucial in drug discovery. However, the accuracy of current methods still needs to be improved. On the other hand, most deep learning methods focus only on the prediction of non-covalent (non-bonded) binding molecular systems, but neglect the cases of covalent binding, which has gained increasing attention in the field of drug development. Results: In this work, a new attention-based model, A Transformer Encoder and Fingerprint combined Prediction method for Drug-Target Affinity (TEFDTA) is proposed to predict the binding affinity for bonded and non-bonded drug-Target interactions. To deal with such complicated problems, we used different representations for protein and drug molecules, respectively. In detail, an initial framework was built by training our model using the datasets of non-bonded protein-ligand interactions. For the widely used dataset Davis, an additional contribution of this study is that we provide a manually corrected Davis database. The model was subsequently fine-Tuned on a smaller dataset of covalent interactions from the CovalentInDB database to optimize performance. The results demonstrate a significant improvement over existing approaches, with an average improvement of 7.6% in predicting non-covalent binding affinity and a remarkable average improvement of 62.9% in predicting covalent binding affinity compared to using BindingDB data alone. At the end, the potential ability of our model to identify activity cliffs was investigated through a case study. The prediction results indicate that our model is sensitive to discriminate the difference of binding affinities arising from small variances in the structures of compounds.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Song, T.
AU  - Zeng, Z.
AU  - Gao, C.
AU  - Chen, H.
AU  - Li, J.
TI  - Joint Classification of Hyperspectral and LiDAR Data Using Height Information Guided Hierarchical Fusion-and-Separation Network
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5505315
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2024.3353775
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182943880&doi=10.1109%2fTGRS.2024.3353775&partnerID=40&md5=9ac7623f1f8b71e27bce52f0b13d1080
AB  - Hyperspectral image (HSI) and light detection and ranging (LiDAR) data are complementary to each other, which can be combined to improve the classification performance. However, existing deep network models do not sufficiently consider their complementarity to design the network structure and loss functions. Moreover, there lacks a hierarchical mutual-assistance learning mechanism that leverages the modality-shared features to enhance the modality-specific ones and vice versa. In view of these, we propose a novel height information guided hierarchical fusion-and-separation network (HFSNet) for joint classification of HSI and LiDAR data. HFSNet consists of three major components, i.e., dual-structure feature encoders (DSFEs), feature fusion-and-separation blocks (F2SBs), and an edge decoder (ED). Specifically, the transformer and convolutional neural network (CNN) are introduced in DSFEs to encode the spectral and spatial information of HSI and LiDAR data, respectively. In F2SBs, the deformable convolution-based height information guided fusion module (HIGFM) and the modality separation refinement module (MSRM) are proposed to sequentially extract modality-shared and modality-specific features. Additionally, the ED is incorporated into our model to predict the LiDAR edge map from the HSI feature to improve the model's generalization ability. As such, the learned features from HSI and LiDAR data are deeply fused and mutually enhanced. Experiments on three benchmark datasets show the superiority of HFSNet to the state-of-the-art methods for jointly classifying HSI and LiDAR data with limited training samples.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Su, H.
AU  - Qiu, J.
AU  - Tang, Z.
AU  - Huang, Z.
AU  - Yan, X.-H.
TI  - Retrieving Global Ocean Subsurface Density by Combining Remote Sensing Observations and Multiscale Mixed Residual Transformer
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 4201513
SP  - 1
EP  - 13
DO  - 10.1109/TGRS.2024.3350346
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182369572&doi=10.1109%2fTGRS.2024.3350346&partnerID=40&md5=faba1b7dcc86526726f3fc6ab4c3c0d1
AB  - Subsurface density (SD) is a crucial dynamic environment parameter reflecting a 3-D ocean process and stratification, with significant implications for the physical, chemical, and biological processes of the ocean environment. Thus, accurate SD retrieval is essential for studying dynamic processes in the ocean interior. However, complete spatiotemporally accurate SD retrieval remains a challenge in terms of the equation of state and physical methods. This study proposes a novel multiscale mixed residual transformer (MMRT) neural network method to compensate for the inadequacy of the existing methods in dealing with spatiotemporal nonlinear processes and dependence. Considering the spatial correlation and temporal dependence of dynamic processes within the ocean, the MMRT addresses temporal dependence by fully using the transformer's processing of time-series data and spatial correlation by compensating for deficiencies in spatial feature information through multiscale mixed residuals. The MMRT model was compared with the existing random forest (RF) and recurrent neural network (RNN) methods. The MMRT model achieves the best accuracy with an average determination coefficient (R2) of 0.988 and an average root mean square error (RMSE) of 0.050 kg/m3 for all layers. The MMRT model not only outperforms the RF and RNN methods regarding reliability and generalization ability when estimating global ocean SD from remote sensing data but also has a more interpretable encoding process. The MMRT model offers a new method for directly estimating SD using multisource satellite observations, providing significant technical support for future remote sensing super-resolution and prediction of subsurface parameters.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kong, X.
AU  - Shen, Z.
AU  - Wang, K.
AU  - Shen, G.
AU  - Fu, Y.
TI  - Exploring Bus Stop Mobility Pattern: A Multi-Pattern Deep Learning Prediction Framework
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6604
EP  - 6616
DO  - 10.1109/TITS.2023.3345872
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182381068&doi=10.1109%2fTITS.2023.3345872&partnerID=40&md5=6994dd19745ba804e7fb0d49d969d863
AB  - The spatio-temporal prediction task in the transportation network is the core of the solutions for various traffic problems. On one hand, the mobility pattern in traffic can be reflected in the travel behavior of the crowd. In most traffic prediction tasks, the importance of the mobility pattern is often overlooked. On the other hand, traffic prediction also has a variety of predicting scenarios, including short-term and long-term prediction, and relevant research cannot solve the problems under the two scenarios at the same time. In view of the problem of existing work, we propose a multi-pattern traffic prediction framework, MPGNNFormer. First, we construct a new bus stop distance network to model the relationships between stops. Then, we use a graph neural network-based deep clustering method to extract the bus stop mobility pattern. Finally, we design a transformer-based spatio-temporal prediction model (STGNNFormer) to predict bus stop flow by taking full advantage of time dependency and space dependency. After that, we conduct a series of experiments to evaluate and test them on the real bus dataset, including analyzing mobility patterns and comparing prediction results. The experimental results prove that MPGNNFormer can improve the calculation efficiency in the prediction scene while ensuring prediction accuracy in the stop-flow prediction of the transportation network. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; FMS:B; 
LB  - Kong2024Exploring
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Huang, H.
AU  - Wang, Z.
AU  - He, R.
TI  - RISTRA: Recursive Image Super-Resolution Transformer With Relativistic Assessment
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 6475
EP  - 6487
DO  - 10.1109/TMM.2024.3352400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182378575&doi=10.1109%2fTMM.2024.3352400&partnerID=40&md5=a413799faaafd9c5a5bcebb1ef3ab21b
AB  - Many recent image restoration methods use Transformer as the backbone network and redesign the Transformer blocks. Differently, we explore the parameter-sharing mechanism over Transformer blocks and propose a dynamic recursive process to address the image super-resolution task efficiently. We firstly present a Recursive Image Super-resolution Transformer (RIST). By sharing the weights across different blocks, a plain forward process through the whole Transformer network can be folded into recursive iterations through a Transformer block. Such a parameter-sharing based recursive process can not only reduce the model size greatly, but also enable restoring images progressively. Features in the recursive process are modeled as a sequence and propagated with a temporal attention network. Besides, by analyzing the prediction variation across different iterations in RIST, we design a dynamic recursive process that can allocate adaptive computation costs to different samples. Specifically, a quality assessment network estimates the restoration quality and terminates the recursive process dynamically. We propose a relativistic learning strategy to simplify the objective from absolute image quality assessment to relativistic quality comparison. The proposed Recursive Image Super-resolution Transformer with Relativistic Assessment (RISTRA) reduces the model size greatly with the parameter-sharing mechanism, and achieves an instance-wise dynamic restoration process as well. Extensive experiments on several image super-resolution benchmarks show the superiority of our approach over state-of-the-art counterparts.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fang, L.
AU  - Jiang, Y.
AU  - Yu, H.
AU  - Zhang, Y.
AU  - Yue, J.
TI  - Point Label Meets Remote Sensing Change Detection: A Consistency-Aligned Regional Growth Network
PY  - 2024
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 62
C7  - 5603911
SP  - 1
EP  - 11
DO  - 10.1109/TGRS.2023.3348459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181563044&doi=10.1109%2fTGRS.2023.3348459&partnerID=40&md5=ee9a4d58047e34229825dac6b57aeb43
AB  - The acquisition of a substantial volume of precisely dense pixel-Annotated samples plays a crucial role in the effective training of deep learning-based change detection models. Nevertheless, in real-world scenarios, pairwise labeling of massive bitemporal remote sensing images is often laborious and time-consuming, resulting in the lack of labeled samples. In this article, we propose a novel point-based weakly supervised learning approach, called as the consistency-Aligned regional growth network (CARGNet), for remote sensing change detection. Unlike pixel-level labels, point labels are easy to label and usually sparse, which leads to a lack of boundary information, making it difficult for the model to accurately capture the details of the changed objects. Therefore, learning directly from them may mislead the training of the network. To address these problems, we introduce a point-based changed regional growth (PCRG) module and consistency alignment (CA) constraint into CARGNet, which breaks the limitation of point labels in losing important target details. Specifically, our CARGNet contains two branches: A base decoder branch and an expanded decoder branch. First, we utilize the PCRG module to generate the expanded annotations from the point annotations. Then, the base decoder is supervised by the original point annotations, while the expanded decoder is supervised by the expanded annotations. Finally, the CA constraint is thereby achieved by minimizing the discrepancy between the predictions from both the base and the expanded decoders, which greatly improves the performance of the model. Experimental results on LEVIR-CD-Point and DSIFN-CD-Point datasets demonstrate that our proposed CARGNet can achieve highly competitive results compared with state-of-The-Art fully-supervised methods. Code and datasets are available at https://github.com/Wanderlust717/CARGNet.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Liu, C.
AU  - Liu, M.
AU  - Liu, T.
AU  - Lin, H.
AU  - Huang, C.-B.
AU  - Ning, L.
TI  - Attention is all you need: utilizing attention in AI-enabled drug discovery
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - 25
DO  - 10.1093/bib/bbad467
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182017288&doi=10.1093%2fbib%2fbbad467&partnerID=40&md5=04de85a1ae976b6740f0816008785c2e
AB  - Recently, attention mechanism and derived models have gained significant traction in drug development due to their outstanding performance and interpretability in handling complex data structures. This review offers an in-depth exploration of the principles underlying attention-based models and their advantages in drug discovery. We further elaborate on their applications in various aspects of drug development, from molecular screening and target binding to property prediction and molecule generation. Finally, we discuss the current challenges faced in the application of attention mechanisms and Artificial Intelligence technologies, including data quality, model interpretability and computational resource constraints, along with future directions for research. Given the accelerating pace of technological advancement, we believe that attention-based models will have an increasingly prominent role in future drug discovery. We anticipate that these models will usher in revolutionary breakthroughs in the pharmaceutical domain, significantly accelerating the pace of drug development. © 2024 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jiao, Y.
AU  - Zhai, X.
AU  - Peng, L.
AU  - Liu, J.
AU  - Liang, Y.
AU  - Yin, Z.
TI  - A digital twin-based motion forecasting framework for preemptive risk monitoring
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 59
C7  - 102250
DO  - 10.1016/j.aei.2023.102250
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177239163&doi=10.1016%2fj.aei.2023.102250&partnerID=40&md5=ed86cbfb69ea6bdd40439434423f365a
AB  - Risk monitoring is a critical task in numerous industrial fields, including construction engineering. Existing approaches primarily focus on identifying the immediate incidents of unsafe events, often neglecting the latent risks arising from the high uncertainty of agents’ motions. To bridge this gap and lay the basis for preemptive risk monitoring, this paper proposes a novel and effective digital twin-based motion forecasting framework that leverages cloud-edge collaboration to predict the future trajectories of workers on construction sites, while ensuring data privacy and reducing computational burden. The edge-end acquires multi-view images about the physical scene and extracts multi-scale features with a deep learning-based backbone. In the cloud-end, where the digital world is hosted, a Transformer-based trajectory tracking model is developed to construct a behavioral digital replica comprising of multiple workers’ historical trajectories from the bird's-eye view perspective. Subsequently, a LSTM-based model, combined with the social pooling mechanism, is deployed to obtain spatiotemporal interactive features from the historical trajectories and predict workers’ future motions. Experiments are conducted on a dataset (WHUT-MF) collected from real-world constructions sites. Our framework achieves 0.528 m in ADE and 0.84 m in FDE on entire WHUT-MF, which demonstrate that the proposed digital twin-based motion forecasting model accurately predicts the future trajectories of workers in various scenarios with potential risks. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Zhu, Y.
AU  - Li, S.
AU  - Wu, B.
TI  - HG-PerCon: Cross-view contrastive learning for personality prediction
PY  - 2024
T2  - Neural Networks
VL  - 169
SP  - 542
EP  - 554
DO  - 10.1016/j.neunet.2023.10.042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176247880&doi=10.1016%2fj.neunet.2023.10.042&partnerID=40&md5=0c2157233e498f56d89a3b14d552dece
AB  - Personality prediction task not only helps us to better understand personal needs and preferences but also is essential for many fields such as psychology and behavioral economics. Current personality prediction primarily focuses on discovering personality traits through user posts. Additionally, there are also methods that utilize psychological information to uncover certain underlying personality traits. Although significant progress has been made in personality prediction, we believe that current solutions still overlook the long-term sustainability of personality and are constrained by the challenge of capturing consistent personality-related clues across different views in a simple and efficient manner. To this end, we propose HG-PerCon, which utilizes user representations based on historical semantic information and psychological knowledge for cross-view contrastive learning. Specifically, we design a transformer-based module to obtain user representations with long-lasting personality-related information from their historical posts. We leverage a psychological knowledge graph which incorporates language styles to generate user representations guided by psychological knowledge. Additionally, we employ contrastive learning to capture the consistency of user personality-related clues across views. To evaluate the effectiveness of our model, and our approach achieved a reduction of 2%, 4%, and 6% in RMSE compared to the second-best baseline method. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Zhu, S.
AU  - Ge, Y.
AU  - Zeng, B.
AU  - Imran, M.A.
AU  - Abbasi, Q.H.
AU  - Cooper, J.
TI  - Depth-Guided Deep Video Inpainting
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 5860
EP  - 5871
DO  - 10.1109/TMM.2023.3340089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179788888&doi=10.1109%2fTMM.2023.3340089&partnerID=40&md5=00a8fb2405cb50798b778ec3a1388e43
AB  - Video inpainting aims to fill in missing regions of a video after any undesired contents are removed from it. This technique can be applied to repair the broken video or edit the video content. In this paper, we propose a depth-guided deep video inpainting network (DGDVI) and demonstrate its effectiveness in processing challenging broken areas crossing multiple depth layers. To achieve our goal, we divide the inpainting into depth completion, content reconstruction, and content enhancement. Three corresponding modules are designed to implement a process-flow. Firstly, we develop a depth completion module based upon the spatio-temporal Transformer which is used to obtain the completed depth information for each video frame. Secondly, we design a content reconstruction module to generate initially inpainted video. With this module, the contents of the missing regions are composed via the depth-guided feature propagation. Thirdly, we construct a content enhancement module to enhance the temporal coherence and texture quality for the inpainted video. All of proposed modules are jointly optimized to guarantee the high inpainting efficiency. The experimental results demonstrate that our proposed method provides better inpainting results, both qualitatively and quantitatively, compared with the previous state-of-the-art.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, C.
AU  - Zhang, Y.
AU  - Ying, Z.
AU  - Li, L.
AU  - Wang, J.
AU  - Yu, H.
AU  - Zhang, M.
AU  - Feng, X.
AU  - Wei, X.
AU  - Xu, X.
TI  - A transformer-based genomic prediction method fused with knowledge-guided module
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - bbad438
DO  - 10.1093/bib/bbad438
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179022346&doi=10.1093%2fbib%2fbbad438&partnerID=40&md5=702bb5adf8e675f37982e222a0fa70d2
AB  - Genomic prediction (GP) uses single nucleotide polymorphisms (SNPs) to establish associations between markers and phenotypes. Selection of early individuals by genomic estimated breeding value shortens the generation interval and speeds up the breeding process. Recently, methods based on deep learning (DL) have gained great attention in the field of GP. In this study, we explore the application of Transformer-based structures to GP and develop a novel deep-learning model named GPformer. GPformer obtains a global view by gleaning beneficial information from all relevant SNPs regardless of the physical distance between SNPs. Comprehensive experimental results on five different crop datasets show that GPformer outperforms ridge regression-based linear unbiased prediction (RR-BLUP), support vector regression (SVR), light gradient boosting machine (LightGBM) and deep neural network genomic prediction (DNNGP) in terms of mean absolute error, Pearson's correlation coefficient and the proposed metric consistent index. Furthermore, we introduce a knowledge-guided module (KGM) to extract genome-wide association studies-based information, which is fused into GPformer as prior knowledge. KGM is very flexible and can be plugged into any DL network. Ablation studies of KGM on three datasets illustrate the efficiency of KGM adequately. Moreover, GPformer is robust and stable to hyperparameters and can generalize to each phenotype of every dataset, which is suitable for practical application scenarios.  © 2024 The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Feng, Z.
AU  - Li, Y.
AU  - Li, B.
AU  - Wang, Y.
AU  - Sha, C.
AU  - He, M.
AU  - Li, X.
TI  - BatmanNet: bi-branch masked graph transformer autoencoder for molecular representation
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - bbad400
DO  - 10.1093/bib/bbad400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178517418&doi=10.1093%2fbib%2fbbad400&partnerID=40&md5=3c8b59132464103e743fc0d484381d2c
AB  - Although substantial efforts have been made using graph neural networks (GNNs) for artificial intelligence (AI)-driven drug discovery, effective molecular representation learning remains an open challenge, especially in the case of insufficient labeled molecules. Recent studies suggest that big GNN models pre-trained by self-supervised learning on unlabeled datasets enable better transfer performance in downstream molecular property prediction tasks. However, the approaches in these studies require multiple complex self-supervised tasks and large-scale datasets, which are time-consuming, computationally expensive and difficult to pre-train end-to-end. Here, we design a simple yet effective self-supervised strategy to simultaneously learn local and global information about molecules, and further propose a novel bi-branch masked graph transformer autoencoder (BatmanNet) to learn molecular representations. BatmanNet features two tailored complementary and asymmetric graph autoencoders to reconstruct the missing nodes and edges, respectively, from a masked molecular graph. With this design, BatmanNet can effectively capture the underlying structure and semantic information of molecules, thus improving the performance of molecular representation. BatmanNet achieves state-of-the-art results for multiple drug discovery tasks, including molecular properties prediction, drug–drug interaction and drug–target interaction, on 13 benchmark datasets, demonstrating its great potential and superiority in molecular representation learning. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Zhang, L.
AU  - Zhang, K.
AU  - Hu, B.
AU  - Xie, H.
AU  - Mao, Z.
TI  - Cascade Semantic Prompt Alignment Network for Image Captioning
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 5266
EP  - 5281
DO  - 10.1109/TCSVT.2023.3343520
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180346597&doi=10.1109%2fTCSVT.2023.3343520&partnerID=40&md5=caa1f5758b595adccc95ec83d5e6634c
AB  - Image captioning (IC) takes an image as input and generates open-form descriptions in the domain of natural language. IC requires the detection of objects, modeling of relations between them, an assessment of the semantics of the scene and representing the extracted knowledge in a language space. Previous detector-based models suffer from limited semantic perception capability due to predefined object detection classes and semantic inconsistency between visual region features and numeric labels of the detector. Inspired by the fact that text prompts in pre-trained multi-modal models contain specific linguistic knowledge rather than discrete labels, and excel at an open-form semantic understanding of visual inputs and their representation in the domain of natural language. We aim to distill and leverage the transferable language knowledge from the pre-trained RegionCLIP model to remedy the detector for generating rich image captioning. In this paper, we propose a novel Cascade Semantic Prompt Alignment Network (CSA-Net) to produce an aligned fine-grained regional semantic-visual space where rich and consistent textual semantic details are automatically incorporated to region features. Specifically, we first align the object semantic prompt and region features to produce semantic grounded object features. Then, we employ these object features and relation semantic prompt to predict the relations between objects. Finally, these enhanced object and relation features are fed into the language decoder, generating rich descriptions. Extensive experiments conducted on the MSCOCO dataset show that our method achieves a new state-of-the-art performance with 145.2% (single model) and 147.0% (ensemble of 4 models) CIDEr scores on the 'Karpathy' split, 141.6% (c5) and 144.1% (c40) CIDEr scores on the official online test server. Significantly, CSA-Net outperforms in generating captions with higher quality and diversity, achieving a RefCLIP-S score of 83.2. Moreover, we expand the testbeds to other challenging captioning benchmarks, i.e., nocaps datasets, CSA-Net demonstrates superior zero-shot capability.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wilkho, R.S.
AU  - Chang, S.
AU  - Gharaibeh, N.G.
TI  - FF-BERT: A BERT-based ensemble for automated classification of web-based text on flash flood events
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 59
C7  - 102293
DO  - 10.1016/j.aei.2023.102293
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178656911&doi=10.1016%2fj.aei.2023.102293&partnerID=40&md5=b8703d8466c2f86cd08ad10ba45a45ab
AB  - The web is a rich information repository that can be mined to uncover additional data about past flash flood (FF) events, currently missing from existing structured databases. However, this information originates from multiple sources (news articles, government records, and weather records among others) and may cover several topics. Furthermore, these topics may be disproportionately covered on the web. The large size and heterogenous nature of web information render manual review difficult. To address this challenge, we have developed a multi-label text classification model, FF-BERT. FF-BERT is designed to classify FF-related web paragraphs into one or more of seven categories: (1) Damage and Economic Impact (DI), (2) Fatalities, Injuries, and Rescue (FIR), (3) Hydrometeorology (HM), (4) Warning and Emergency (WE), (5) Response and Recovery (RR), (6) Public Health (PH), and (7) Mitigation (MG). To develop FF-BERT, we labeled 21,180 paragraphs from FF-related webpages and performed experiments with multiple model architectures based on the widely used language model Bidirectional Encoder Representation from Transformers (BERT). Our final model outperforms the baseline by 11.83%, as measured by the micro-F1 score. In addition, FF-BERT significantly improves the prediction of minority labels (RR-32.1%, PH-260.4%, and MG-138.6%). We demonstrate using real world examples that FF-BERT can be used to uncover new information about flash flood events. This information can be used to enhance existing databases, such as NOAA's Storm Events Database. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Ye, W.
AU  - Jiang, T.
AU  - Huang, T.
TI  - GIN: Generative INvariant Shape Prior for Amodal Instance Segmentation
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 3924
EP  - 3936
DO  - 10.1109/TMM.2023.3318075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181477035&doi=10.1109%2fTMM.2023.3318075&partnerID=40&md5=11f8dbab28c2609772aa485ca77cd9bc
AB  - Amodal instance segmentation (AIS) predicts the complete shape of the occluded object, including both visible and occluded regions. Because visual clues are lacking, the occluded region is difficult to segment accurately. In human amodal perception, shape-prior knowledge is helpful for AIS. The previous method uses a 2D shape prior by rote memorizing, establishing a shape dictionary and retrieving the closest mask to the segmentation result. However, this approach cannot obtain the shape prior, which is not prestored in the shape dictionary. In this article, to improve generalization ability, we propose a generative invariant shape-prior network (GIN), simulating the human perception process that learns the basic shape, which is invariant to transformations, including translation, rotation, and scaling. We design a novel framework that decouples the learning of shape priors from transformation. GIN is end-to-end trainable and needs no dictionary establishment, making the whole pipeline efficient. GIN outperforms state-of-the-art methods on three public datasets (D2SA, COCOA-cls, and KINS) with large margins.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Malik, M.S.I.
AU  - Nawaz, A.
TI  - SEHP: stacking-based ensemble learning on novel features for review helpfulness prediction
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 1
SP  - 653
EP  - 679
DO  - 10.1007/s10115-023-02020-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178104855&doi=10.1007%2fs10115-023-02020-3&partnerID=40&md5=d4ed03cfd6ba472676e693d1eea613c5
AB  - The review’s helpfulness and its impact on purchase decisions are well established. This study presents a robust helpfulness prediction model for customer reviews. To this end, significant review textual features and newly defined reviewer characteristics are explored with a stacking-based ensemble model. More specifically, stylistic, time complexity, summary language, psychological, and linguistics features are introduced. According to our knowledge, these features are not explored earlier with the stacking-based ensemble model for review helpfulness prediction. The proposed predictive model is evaluated on three benchmark Amazon review datasets, consisting of 200,979 reviews in total. Two algorithms are proposed to help readers for understanding the methodology and researchers to regenerate the results. We compared several machine-learning, stacking-based ensemble, and 1-dimenional convolutional neural network (1D CNN) models. The stacking-based ensemble model shows benchmark performance by obtaining 0.009 mean square error with a hybrid combination of the proposed (reviewer and textual) features. Moreover, the proposed model outperformed five baselines including the fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model by reducing mean square error by 40%. The results show that review textual features are better predictors than reviewer features as a standalone model. The findings of this article have significant implications for the researchers and the business owners. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, X.
AU  - Gao, M.
AU  - Zou, G.
AU  - Bruno, A.
AU  - Chehri, A.
AU  - Jeon, G.
TI  - Object Counting via Group and Graph Attention Network
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 9
SP  - 11884
EP  - 11895
DO  - 10.1109/TNNLS.2023.3336894
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179834452&doi=10.1109%2fTNNLS.2023.3336894&partnerID=40&md5=62f5aef23c1afff43f635d17c4cfb036
AB  - Object counting, defined as the task of accurately predicting the number of objects in static images or videos, has recently attracted considerable interest. However, the unavoidable presence of background noise prevents counting performance from advancing further. To address this issue, we created a group and graph attention network (GGANet) for dense object counting. GGANet is an encoder-decoder architecture incorporating a group channel attention (GCA) module and a learnable graph attention (LGA) module. The GCA module groups the feature map into several subfeatures, each of which is assigned an attention factor through the identical channel attention. The LGA module views the feature map as a graph structure in which the different channels represent diverse feature vertices, and the responses between channels represent edges. The GCA and LGA modules jointly avoid the interference of irrelevant pixels and suppress the background noise. Experiments are conducted on four crowd-counting datasets, two vehicle-counting datasets, one remote-sensing counting dataset, and one few-shot object-counting dataset. Comparative results prove that the proposed GGANet achieves superior counting performance. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jia, Y.
AU  - Liu, J.
AU  - Chen, L.
AU  - Zhao, T.
AU  - Wang, Y.
TI  - THItoGene: a deep learning method for predicting spatial transcriptomics from histological images
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - bbad464
DO  - 10.1093/bib/bbad464
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181176152&doi=10.1093%2fbib%2fbbad464&partnerID=40&md5=f6699a222b8913afd79ca791632a8a9f
AB  - Spatial transcriptomics unveils the complex dynamics of cell regulation and transcriptomes, but it is typically cost-prohibitive. Predicting spatial gene expression from histological images via artificial intelligence offers a more affordable option, yet existing methods fall short in extracting deep-level information from pathological images. In this paper, we present THItoGene, a hybrid neural network that utilizes dynamic convolutional and capsule networks to adaptively sense potential molecular signals in histological images for exploring the relationship between high-resolution pathology image phenotypes and regulation of gene expression. A comprehensive benchmark evaluation using datasets from human breast cancer and cutaneous squamous cell carcinoma has demonstrated the superior performance of THItoGene in spatial gene expression prediction. Moreover, THItoGene has demonstrated its capacity to decipher both the spatial context and enrichment signals within specific tissue regions. THItoGene can be freely accessed at https://github.com/yrjia1015/THItoGene. © 2024 The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wen, S.
AU  - Yang, L.
AU  - Xu, M.
AU  - Qiao, M.
AU  - Xu, T.
AU  - Bai, L.
TI  - Saliency Prediction on Mobile Videos: A Fixation Mapping-Based Dataset and A Transformer Approach
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 7
SP  - 5935
EP  - 5950
DO  - 10.1109/TCSVT.2023.3342903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180332023&doi=10.1109%2fTCSVT.2023.3342903&partnerID=40&md5=83b8d173a02fd0c798460bc9e750d456
AB  - With the booming development of smart devices, mobile videos have drawn broad interest when humans surf social media. Different from traditional long-form videos, mobile videos are featured with uncertain human attention behavior so far owing to the specific displaying mode, thus promoting the research on saliency prediction for mobile videos. Unfortunately, the current eye-tracking experiments are not applicable for mobile videos, since the stationary eye-tracker and eye fixation acquisition are dedicated to the videos presented on computers. To tackle this issue, we propose performing the wearable eye-tracker to record viewers' egocentric fixations and then devising a fixation mapping technique to project the eye fixations from egocentric videos onto mobile videos. Resorting to this technique, the large-scale mobile video saliency (MVS) dataset is established, including 1,007 mobile videos and 5,935,927 fixations. Given this dataset, we exhaustively analyze the characteristics of subjects' fixations and obtain two findings. Based on the MVS dataset and these findings, we propose a saliency prediction approach on mobile videos upon Video Swin Transformer (MVFormer), wherein long-range spatio-temporal dependency is captured to derive the human attention mechanism on mobile videos. In MVFormer, we develop the selective feature fusion module to balance multi-scale features, and the progressive saliency prediction module to generate saliency maps via progressive aggregation of multi-scale features. Extensive experiments show that our MVFormer approach significantly outperforms other state-of-the-art saliency prediction approaches. Finally, we demonstrate the potential application of our MVFormer approach in the H.265 video coding standard by embedding it into the rate control scheme, such that the perceptual quality of compressed mobile videos can be significantly improved. The dataset and code are available at https://github.com/wenshijie110/MVFormer. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huan, R.
AU  - Zhong, G.
AU  - Chen, P.
AU  - Liang, R.
TI  - UniMF: A Unified Multimodal Framework for Multimodal Sentiment Analysis in Missing Modalities and Unaligned Multimodal Sequences
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 5753
EP  - 5768
DO  - 10.1109/TMM.2023.3338769
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179834581&doi=10.1109%2fTMM.2023.3338769&partnerID=40&md5=026ff3dbea7c5b97e6f7d70dd8110713
AB  - In current multimodal sentiment analysis, aligned and complete multimodal sequences are often crucial. Obtaining complete multimodal data in the real world presents various challenges, and aligning multimodal sequences often requires a significant amount of effort. Unfortunately, most multimodal sentiment analysis methods fail when dealing with missing modalities or unaligned multimodal sequences. To tackle these two challenges simultaneously in a simple and lightweight manner, we present the Unified Multimodal Framework (UniMF). The primary components of UniMF comprise two distinct modules. The first module, Translation Module, translates missing modalities using information from existing modalities. The second module, Prediction Module, uses the attention mechanism to fuse the multimodal information and generate predictions. To enhance the translation performance of the Translation Module, we introduce the Multimodal Generation Mask (MGM) and utilize it to construct the Multimodal Generation Transformer (MGT). The MGT can generate the missing modality while focusing on information from existing modalities. Furthermore, we introduce the Multimodal Understanding Transformer (MUT) in the Prediction Module, which includes the Multimodal Understanding Mask (MUM) and a unique sequence, MultiModalSequence (MMSeq), representing a unified multimodality. To assess the performance of UniMF, we perform experiments on four multimodal sentiment datasets, and UniMF attains competitive or state-of-the-art outcomes with fewer learnable parameters. Furthermore, the experimental outcomes signify that UniMF, supported by MGT and MUT - two transformers utilizing special attention mechanisms, can efficiently manage both generating task of missing modalities and understanding task of unaligned multimodal sequences.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Ruan, S.
AU  - Yue, Y.
AU  - Sun, B.
TI  - PETNet: Plaintext-aware encrypted traffic detection network for identifying Cobalt Strike HTTPS traffics
PY  - 2024
T2  - Computer Networks
VL  - 238
C7  - 110120
DO  - 10.1016/j.comnet.2023.110120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178129870&doi=10.1016%2fj.comnet.2023.110120&partnerID=40&md5=776d4bb8f19752fe4bd7528c9bc31133
AB  - Cobalt Strike is the most prevalent attack tool abused by cyber-criminals to achieve command and control on victim hosts over HTTPS traffics. It appears in many ransomware attacks and espionage attacks, threatening public privacy and national security. Therefore, it is of significant value to detect Cobalt Strike HTTPS traffics effectively. However, existing methods could be easily deceived by variable infrastructures or disguised certificates used by attackers, or do not adequately capture the multi-aspect information and their interrelations in encrypted traffics. To overcome these limitations, in this paper, we propose a Plaintext-aware Encrypted Traffic Detection Network (PETNet) to identify Cobalt Strike HTTPS traffics, which contains three main modules: (1) Meta Information Modeling, which parses handshake payloads into semantically explicit identity-agnostic meta features, avoiding being disturbed by infrastructures or certificates; (2) Sequential Information Modeling, which models the interaction between attackers and victims via a Transformer encoder, and captures the interrelations among multi-aspects of traffics by a meta-information-guided attention mechanism, realizing configuration-aware encoding of encrypted contents; (3) Fusion & Prediction, which fuses the interrelated meta information and sequential information to make the final prediction. We conduct extensive experiments on a close-world and four open-world datasets. PETNet outperforms the best baseline by 53.42% in F1-score on average, and remains robust to the concept drift issue during the test period of 14 months, proving its effectiveness and generalization ability. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wei, Y.
AU  - Wu, D.
TI  - Conditional variational transformer for bearing remaining useful life prediction
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 59
C7  - 102247
DO  - 10.1016/j.aei.2023.102247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177833352&doi=10.1016%2fj.aei.2023.102247&partnerID=40&md5=60b9335d5be884c059894316930539d8
AB  - Transformer, built on the self-attention mechanism, has been demonstrated to be effective in numerous applications. However, in the context of prognostics and health management, the self-attention mechanism in the Transformer is not effective in selecting the most important features that are highly correlated with the remaining useful life (RUL) of a component. To address this issue, we developed a novel conditional variational transformer architecture consisting of four networks: two generative networks and two predictive networks. The first generative network uses the transformer encoder–decoder as well as both condition monitoring data and RUL as input to extract the most important features in one feature space from condition monitoring data. The second generative network uses the transformer encoder and condition monitoring data to extract features in another feature space. The two predictive networks use the extracted features in two different feature spaces to make predictions. A KL-divergence is used to minimize the distance between the two feature spaces learned by the first and second generative networks so that the feature space extracted from the second generative network can approximate the feature space extracted from the first generative network. We demonstrated that the proposed method is effective in predicting the RUL of bearings using two datasets. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Buscaldi, D.
AU  - Dessí, D.
AU  - Motta, E.
AU  - Murgia, M.
AU  - Osborne, F.
AU  - Reforgiato Recupero, D.
TI  - Citation prediction by leveraging transformers and natural language processing heuristics
PY  - 2024
T2  - Information Processing and Management
VL  - 61
IS  - 1
C7  - 103583
DO  - 10.1016/j.ipm.2023.103583
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177784800&doi=10.1016%2fj.ipm.2023.103583&partnerID=40&md5=4b5c8ae0feb2be0597ef5ef3a7b81f72
AB  - In scientific papers, it is common practice to cite other articles to substantiate claims, provide evidence for factual assertions, reference limitations, and research gaps, and fulfill various other purposes. When authors include a citation in a given sentence, there are two considerations they need to take into account: (i) where in the sentence to place the citation and (ii) which citation to choose to support the underlying claim. In this paper, we focus on the first task as it allows multiple potential approaches that rely on the researcher's individual style and the specific norms and conventions of the relevant scientific community. We propose two automatic methodologies that leverage transformers architecture for either solving a Mask-Filling problem or a Named Entity Recognition problem. On top of the results of the proposed methodologies, we apply ad-hoc Natural Language Processing heuristics to further improve their outcome. We also introduce s2orc-9K, an open dataset for fine-tuning models on this task. A formal evaluation demonstrates that the generative approach significantly outperforms five alternative methods when fine-tuned on the novel dataset. Furthermore, this model's results show no statistically significant deviation from the outputs of three senior researchers. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Zhu, J.
AU  - Li, Z.
AU  - Tong, H.
AU  - Lu, Z.
AU  - Zhang, N.
AU  - Wei, T.
AU  - Chen, H.-F.
TI  - Phanto-IDP: compact model for precise intrinsically disordered protein backbone generation and enhanced sampling
PY  - 2024
T2  - Briefings in Bioinformatics
VL  - 25
IS  - 1
C7  - bbad429
DO  - 10.1093/bib/bbad429
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178496639&doi=10.1093%2fbib%2fbbad429&partnerID=40&md5=5ae8214a42c40ed953a13056ffe16e7f
AB  - The biological function of proteins is determined not only by their static structures but also by the dynamic properties of their conformational ensembles. Numerous high-accuracy static structure prediction tools have been recently developed based on deep learning; however, there remains a lack of efficient and accurate methods for exploring protein dynamic conformations. Traditionally, studies concerning protein dynamics have relied on molecular dynamics (MD) simulations, which incur significant computational costs for all-atom precision and struggle to adequately sample conformational spaces with high energy barriers. To overcome these limitations, various enhanced sampling techniques have been developed to accelerate sampling in MD. Traditional enhanced sampling approaches like replica exchange molecular dynamics (REMD) and frontier expansion sampling (FEXS) often follow the MD simulation approach and still cost a lot of computational resources and time. Variational autoencoders (VAEs), as a classic deep generative model, are not restricted by potential energy landscapes and can explore conformational spaces more efficiently than traditional methods. However, VAEs often face challenges in generating reasonable conformations for complex proteins, especially intrinsically disordered proteins (IDPs), which limits their application as an enhanced sampling method. In this study, we presented a novel deep learning model (named Phanto-IDP) that utilizes a graph-based encoder to extract protein features and a transformer-based decoder combined with variational sampling to generate highly accurate protein backbones. Ten IDPs and four structured proteins were used to evaluate the sampling ability of Phanto-IDP. The results demonstrate that Phanto-IDP has high fidelity and diversity in the generated conformation ensembles, making it a suitable tool for enhancing the efficiency of MD simulation, generating broader protein conformational space and a continuous protein transition path.  © 2024 The Author(s) 2023. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, H.
AU  - Liu, J.
AU  - Jiang, T.
AU  - Zou, Q.
AU  - Qi, S.
AU  - Cui, Z.
AU  - Tiwari, P.
AU  - Ding, Y.
TI  - AttentionMGT-DTA: A multi-modal drug-target affinity prediction using graph transformer and attention mechanism
PY  - 2024
T2  - Neural Networks
VL  - 169
SP  - 623
EP  - 636
DO  - 10.1016/j.neunet.2023.11.018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181262524&doi=10.1016%2fj.neunet.2023.11.018&partnerID=40&md5=c66b879a2c3137cedef9b77735b248cc
AB  - The accurate prediction of drug-target affinity (DTA) is a crucial step in drug discovery and design. Traditional experiments are very expensive and time-consuming. Recently, deep learning methods have achieved notable performance improvements in DTA prediction. However, one challenge for deep learning-based models is appropriate and accurate representations of drugs and targets, especially the lack of effective exploration of target representations. Another challenge is how to comprehensively capture the interaction information between different instances, which is also important for predicting DTA. In this study, we propose AttentionMGT-DTA, a multi-modal attention-based model for DTA prediction. AttentionMGT-DTA represents drugs and targets by a molecular graph and binding pocket graph, respectively. Two attention mechanisms are adopted to integrate and interact information between different protein modalities and drug-target pairs. The experimental results showed that our proposed model outperformed state-of-the-art baselines on two benchmark datasets. In addition, AttentionMGT-DTA also had high interpretability by modeling the interaction strength between drug atoms and protein residues. Our code is available at https://github.com/JK-Liu7/AttentionMGT-DTA. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 30
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Zhao, G.
AU  - Li, M.
AU  - Zhang, Z.
AU  - Qian, X.
TI  - Reason Generation for Point of Interest Recommendation Via a Hierarchical Attention-Based Transformer Model
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 5511
EP  - 5522
DO  - 10.1109/TMM.2023.3335886
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179075159&doi=10.1109%2fTMM.2023.3335886&partnerID=40&md5=cd31b9e6e8e35795f60c68291c0b7001
AB  - Existing point-of-interest (POI) recommendation methods only show the direct recommendation results and lack the proper reasons for recommendation. In recent years, explainable recommendation has become an increasingly important subfield in recommendation systems. The aim of explainable recommendation is to provide a reason why an item is recommended to a user. In this way, it helps to improve the transparency, persuasiveness and user satisfaction of recommendation systems. The explainable recommendation should indicate users’ preferences for POIs, such as the category and the price. In addition, to increase the diversity of the results, we take emotional intensity into account in our model to generate more vivid reasons. To this end, we propose a hierarchical attention-based transformer model to generate reasons with specific topics and different emotions. With a hierarchical attention mechanism, we can capture the word-level and attribute-level preferences of users. In addition, we also learn the latent representation of the emotion score to generate diverse recommendation reasons. We evaluate the proposed model on a new real-world dataset collected from three travel service websites. The experimental results demonstrate that our method outperforms the related approaches for reason generation. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yun, D.
AU  - Yang, H.-L.
AU  - Kwon, S.
AU  - Lee, S.-R.
AU  - Kim, K.
AU  - Kim, K.
AU  - Lee, H.-C.
AU  - Jung, C.-W.
AU  - Kim, Y.S.
AU  - Han, S.S.
TI  - Automatic segmentation of atrial fibrillation and flutter in single-lead electrocardiograms by self-supervised learning and Transformer architecture
PY  - 2024
T2  - Journal of the American Medical Informatics Association
VL  - 31
IS  - 1
SP  - 79
EP  - 88
DO  - 10.1093/jamia/ocad219
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181176146&doi=10.1093%2fjamia%2focad219&partnerID=40&md5=e77a0449dfe5ac89ab4bce51b91257ca
AB  - Objectives: Automatic detection of atrial fibrillation and flutter (AF/AFL) is a significant concern in preventing stroke and mitigating hemodynamic instability. Herein, we developed a Transformer-based deep learning model for AF/AFL segmentation in single-lead electrocardiograms (ECGs) by self-supervised learning with masked signal modeling (MSM). Materials and Methods: We retrieved data from 11 open-source databases on PhysioNet; 7 of these databases included labeled ECGs, while the other 4 were without labels. Each database contained ECG recordings with durations of ≥30 s. A total of 24 intradialytic ECGs with paroxysmal AF/AFL during 4 h of hemodialysis sessions at Seoul National University Hospital were used for external validation. The model was pretrained by predicting masked areas of ECG signals and fine-tuned by predicting AF/AFL areas. Cross-database validation was used for evaluation, and the intersection over union (IOU) was used as a main performance metric in external database validation. Results: In the 7 labeled databases, the areas marked as AF/AFL constituted 41.1% of the total ECG signals, ranging from 0.19% to 51.31%. In the evaluation per ECG segment, the model achieved IOU values of 0.9254 and 0.9477 for AF/AFL segmentation and other segmentation tasks, respectively. When applied to intradialytic ECGs with paroxysmal AF/AFL, the IOUs for the segmentation of AF/AFL and non-AF/AFL were 0.9896 and 0.9650, respectively. Model performance by different training procedure indicated that pretraining with MSM and the application of an appropriate masking ratio both contributed to the model performance. It also showed higher IOUs of AF/AFL labels than in previous studies when training and test databases were matched. Conclusion: The present model with self-supervised learning by MSM performs robustly in segmenting AF/AFL. © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Bicer, B.
AU  - Dibeklioglu, H.
TI  - Automatic Deceit Detection Through Multimodal Analysis of High-Stake Court-Trials
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 1
SP  - 342
EP  - 356
DO  - 10.1109/TAFFC.2023.3322331
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174839487&doi=10.1109%2fTAFFC.2023.3322331&partnerID=40&md5=5f5fe8a4d586a3c0e7913632d7aebae0
AB  - In this article we propose the use of convolutional self-attention for attention-based representation learning, while replacing traditional vectorization methods with a transformer as the backbone of our speech model for transfer learning within our automatic deceit detection framework. This design performs a multimodal data analysis and applies fusion to merge visual, vocal, and speech(textual) channels; reporting deceit predictions. Our experimental results show that the proposed architecture improves the state-of-the-art on the popular Real-Life Trial (RLT) dataset in terms of correct classification rate. To further assess the generalizability of our design, we experiment on the low-stakes Box of Lies (BoL) dataset and achieve state-of-the-art performance as well as providing cross-corpus comparisons. Following our analysis, we report that (1) convolutional self-attention learns meaningful representations while performing joint attention computation for deception, (2) apparent deceptive intent is a continuous function of time and subjects can display varying levels of apparent deceptive intent throughout recordings, and (3), in support of criminal psychology findings, studying abnormal behavior out of context can be an unreliable way to predict deceptive intent.  © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fang, S.
AU  - Lin, Z.
AU  - Yan, K.
AU  - Li, J.
AU  - Lin, X.
AU  - Ji, R.
TI  - HODN: Disentangling Human-Object Feature for HOI Detection
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 3125
EP  - 3136
DO  - 10.1109/TMM.2023.3307896
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168728274&doi=10.1109%2fTMM.2023.3307896&partnerID=40&md5=300ff7cbb646f7bae8abb6ef231b35c6
AB  - The task of Human-Object Interaction (HOI) detection is to detect humans and their interactions with surrounding objects, where transformer-based methods show dominant advances currently. However, these methods ignore the relationship among humans, objects, and interactions: 1) human features are more contributive than object ones to interaction prediction; 2) interactive information disturbs the detection of objects but helps human detection. In this article, we propose a Human and Object Disentangling Network (HODN) to model the HOI relationships explicitly, where humans and objects are first detected by two disentangling decoders independently and then processed by an interaction decoder. Considering that human features are more contributive to interaction, we propose a Human-Guide Linking method to make sure the interaction decoder focuses on the human-centric regions with human features as the positional embeddings. To handle the opposite influences of interactions on humans and objects, we propose a Stop-Gradient Mechanism to stop interaction gradients from optimizing the object detection but to allow them to optimize the human detection. Our proposed method achieves competitive performance on both the V-COCO and the HICO-Det datasets. It can be combined with existing methods easily for state-of-the-art results.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liang, R.
AU  - Li, Y.
AU  - Zhou, J.
AU  - Li, X.
TI  - STGlow: A Flow-Based Generative Framework With Dual-Graphormer for Pedestrian Trajectory Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 16504
EP  - 16517
DO  - 10.1109/TNNLS.2023.3294998
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165909257&doi=10.1109%2fTNNLS.2023.3294998&partnerID=40&md5=29dc5732d11f8238c205fb03835aaf2c
AB  - The pedestrian trajectory prediction task is an essential component of intelligent systems. Its applications include but are not limited to autonomous driving, robot navigation, and anomaly detection of monitoring systems. Due to the diversity of motion behaviors and the complex social interactions among pedestrians, accurately forecasting their future trajectory is challenging. Existing approaches commonly adopt generative adversarial networks (GANs) or conditional variational autoencoders (CVAEs) to generate diverse trajectories. However, GAN-based methods do not directly model data in a latent space, which may make them fail to have full support over the underlying data distribution. CVAE-based methods optimize a lower bound on the log-likelihood of observations, which may cause the learned distribution to deviate from the underlying distribution. The above limitations make existing approaches often generate highly biased or inaccurate trajectories. In this article, we propose a novel generative flow-based framework with a dual-graphormer for pedestrian trajectory prediction (STGlow). Different from previous approaches, our method can more precisely model the underlying data distribution by optimizing the exact log-likelihood of motion behaviors. Besides, our method has clear physical meanings for simulating the evolution of human motion behaviors. The forward process of the flow gradually degrades complex motion behavior into simple behavior, while its reverse process represents the evolution of simple behavior into complex motion behavior. Furthermore, we introduce a dual-graphormer combined with the graph structure to more adequately model the temporal dependencies and the mutual spatial interactions. Experimental results on several benchmarks demonstrate that our method achieves much better performance compared to previous state-of-the-art approaches. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gu, F.
AU  - Lu, J.
AU  - Cai, C.
AU  - Zhu, Q.
AU  - Ju, Z.
TI  - EANTrack: An Efficient Attention Network for Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 21
IS  - 4
SP  - 5911
EP  - 5928
DO  - 10.1109/TASE.2023.3319676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174843976&doi=10.1109%2fTASE.2023.3319676&partnerID=40&md5=17c5cd4b3801c2f5780e769f989a59cd
AB  - Recently, Siamese trackers have gained widespread attention in visual tracking due to their exceptional performance. However, many trackers still suffer from limitations in challenging scenarios, such as fast motion and scale variation, which hinder the full exploitation of target features. Consequently, the accuracy and efficiency of the trackers are limited. Therefore, this paper proposes an efficient attention network, called EAN, to improve tracking performance. The EAN comprises three primary components, namely a Transformer-s subnetwork, a Transformer-t subnetwork, and a Feature-Fused Attention Module (FFAM). The designed Transformer-s and Transformer-t subnetworks adopt complementary structures and functions to fully integrate and emphasize the relevant feature information, including channel and spatial features. The FFAM is responsible for fusing the multi-level features from both subnetworks, which establishes the global dependencies between the templates and search regions and enhances the discriminative power of the model. To further improve the tracking accuracy, a novel Feature-Aware Attention Module (FAAM) is introduced into the tracking prediction head to enhance the feature representation capability of the model. Finally, we propose an efficient EANTrack tracker based on EAN for robust tracking in complex scenarios, which exhibits significant advantages in challenging attributes. Experimental results on multiple benchmarks indicate that our approach achieves remarkable tracking performance with a real-time running speed of 55.6fps. Note to Practitioners - Siamese trackers have garnered considerable attention in the field of visual tracking due to their impressive performance. However, these trackers often face limitations in challenging scenarios, which impede the complete exploitation of target features. As a result, the accuracy and efficiency of many trackers are compromised. To address these issues, we propose an efficient tracker called EANTrack to enable robust tracking in complex scenarios. Our EANTrack exhibits significant advantages in handling challenging attributes. Please refer to our complete paper for detailed information on the EANTrack tracker and experimental results. Practitioners in the field can benefit from our research by leveraging our findings and methodologies in their work. We encourage further exploration and experimentation to enhance the performance and applicability of visual tracking systems.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, B.
AU  - Zhu, G.
AU  - Li, L.
AU  - Gan, J.
AU  - Li, W.
AU  - Gao, X.
TI  - Blind Image Quality Index With Cross-Domain Interaction and Cross-Scale Integration
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 2729
EP  - 2739
DO  - 10.1109/TMM.2023.3303725
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167815276&doi=10.1109%2fTMM.2023.3303725&partnerID=40&md5=0cf98d8ae74277cd9be8128eb2de5798
AB  - With the assistance of Convolutional Neural Networks (CNNs), Image Quality Assessment (IQA) models have made great progress in evaluating both simulated distortion and authentic distortion. However, most of the existing IQA models only learn the features of distorted images, and thus do not make full use of the available feature representation of other domains. Furthermore, the common multi-scale fusion strategies are relatively simple, such as downsampling and concatenating, which further limits the prediction performance. To this end, we propose a novel blind image quality index with cross-domain interaction and cross-scale integration, which is designed based on the combination of CNN and Transformer. First, the hierarchical spatial-domain and gradient-domain representations are obtained through a typical CNN architecture. Then, based on the proposed gradient-query cross-attention, these two types of features are fully interacted in the Cross-Domain Interaction (CDI) module. To represent the distortion information more comprehensively, the Cross-Scale Integration (CSI) module is proposed to combine the information between different scales progressively. Finally, the quality score is obtained through a simple regression module. The experimental results on five public IQA databases of both simulated and authentic scenes show that the proposed model outperforms the compared state-of-the-art metrics. In addition, cross-database experiments show that the proposed model has strong generalization performance.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xian, K.
AU  - Peng, J.
AU  - Cao, Z.
AU  - Zhang, J.
AU  - Lin, G.
TI  - ViTA: Video Transformer Adaptor for Robust Video Depth Estimation
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 3302
EP  - 3316
DO  - 10.1109/TMM.2023.3309559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169681750&doi=10.1109%2fTMM.2023.3309559&partnerID=40&md5=b214783f67740a4d75b3c7bad728d323
AB  - Depth information plays a pivotal role in numerous computer vision applications, including autonomous driving, 3D reconstruction, and 3D content generation. When deploying depth estimation models in practical applications, it is essential to ensure that the models have strong generalization capabilities. However, existing depth estimation methods primarily concentrate on robust single-image depth estimation, leading to the occurrence of flickering artifacts when applied to video inputs. On the other hand, video depth estimation methods either consume excessive computational resources or lack robustness. To address the above issues, we propose ViTA, a video transformer adaptor, to estimate temporally consistent video depth in the wild. In particular, we leverage a pre-trained image transformer (i.e., DPT) and introduce additional temporal embeddings in the transformer blocks. Such designs enable our ViTA to output reliable results given an unconstrained video. Besides, we present a spatio-temporal consistency loss for supervision. The spatial loss computes the per-pixel discrepancy between the prediction and the ground truth in space, while the temporal loss regularizes the inconsistent outputs of the same point in consecutive frames. To find the correspondences between consecutive frames, we design a bi-directional warping strategy based on the forward and backward optical flow. During inference, our ViTA no longer requires optical flow estimation, which enables it to estimate spatially accurate and temporally consistent video depth maps with fine-grained details in real time. We conduct a detailed ablation study to verify the effectiveness of the proposed components. Extensive experiments on the zero-shot cross-dataset evaluation demonstrate that the proposed method is superior to previous methods.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Wang, X.
AU  - Wang, N.
AU  - Gao, X.
TI  - Address the Unseen Relationships: Attribute Correlations in Text Attribute Person Search
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 16916
EP  - 16926
DO  - 10.1109/TNNLS.2023.3300582
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167779910&doi=10.1109%2fTNNLS.2023.3300582&partnerID=40&md5=db9100021614ecf02295d4a61a2fc148
AB  - Text attribute person search aims to identify the particular pedestrian by textual attribute information. Compared to person re-identification tasks which requires imagery samples as its query, text attribute person search is more useful under the circumstance where only witness is available. Most existing text attribute person search methods focus on improving the matching correlation and alignments by learning better representations of person–attribute instance pairs, with few consideration of the latent correlations between attributes. In this work, we propose a graph convolutional network (GCN) and pseudo-label-based text attribute person search method. Concretely, the model directly constructs the attribute correlations by label co-occurrence probability, in which the nodes are represented by attribute embedding and edges are by the filtered correlation matrix of attribute labels. In order to obtain better representations, we combine the cross-attention module (CAM) and the GCN. Furthermore, to address the unseen attribute relationships, we update the edge information through the instances through testing set with high predicted probability thus to better adapt the attribute distribution. Extensive experiments illustrate that our model outperforms the existing state-of-the-art methods on publicly available person search benchmarks: Market-1501 and PETA. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ren, L.
AU  - Mo, T.
AU  - Cheng, X.
AU  - Li, X.
TI  - Temporal-Frequency Attention Focusing for Time Series Extrinsic Regression via Auxiliary Task
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 15494
EP  - 15506
DO  - 10.1109/TNNLS.2023.3287318
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163417342&doi=10.1109%2fTNNLS.2023.3287318&partnerID=40&md5=76e170c0989ea3981143799b70b72279
AB  - Time series extrinsic regression (TSER) aims at predicting numeric values based on the knowledge of the entire time series. The key to solving the TSER problem is to extract and use the most representative and contributed information from raw time series. To build a regression model that focuses on those information suitable for the extrinsic regression characteristic, there are two major issues to be addressed. That is, how to quantify the contributions of those information extracted from raw time series and then how to focus the attention of the regression model on those critical information to improve the model's regression performance. In this article, a multitask learning framework called temporal-frequency auxiliary task (TFAT) is designed to solve the mentioned problems. To explore the integral information from the time and frequency domains, we decompose the raw time series into multiscale subseries in various frequencies via a deep wavelet decomposition network. To address the first problem, the transformer encoder with the multihead self-attention mechanism is integrated in our TFAT framework to quantify the contribution of temporal-frequency information. To address the second problem, an auxiliary task in a manner of self-supervised learning is proposed to reconstruct the critical temporal-frequency features so as to focusing the regression model's attention on those essential information for facilitating TSER performance. We estimated three kinds of attention distribution on those temporal-frequency features to perform auxiliary task. To evaluate the performances of our method under various application scenarios, the experiments are carried out on the 12 datasets of the TSER problem. Also, ablation studies are used to examine the effectiveness of our method. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qian, X.
AU  - Xue, W.
AU  - Zhang, Q.
AU  - Tao, R.
AU  - Li, H.
TI  - Deep Cross-Modal Retrieval Between Spatial Image and Acoustic Speech
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 4480
EP  - 4489
DO  - 10.1109/TMM.2023.3323876
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174806790&doi=10.1109%2fTMM.2023.3323876&partnerID=40&md5=0cdd31d4a8f2cd2910231b4eab1b7756
AB  - Cross-modal Retrieval (CMR) is formulated for the scenarios where the queries and retrieval results are of different modalities. Existing Cross-modal Retrieval (CMR) studies mainly focus on the common contextualized information between text transcripts and images, and the synchronized event information in audio-visual recordings. Unlike all previous works, in this article, we investigate the geometric correspondence between images and speech recordings captured in the same space and formulate a novel CMR task, called Spatial Image-Acoustic Retrieval (SIAR). To this end, we first design a novel speech encoder that consists of convolution neural networks and transformer layers, to learn space-aware speech representations. Then, to eliminate the cross-modal inherent discrepancy, we propose the Contrastive Speech Image Retrieval (CSIR) method which uses supervised contrastive learning to attract the same-space cross-modal features while repelling the ones from different spaces. Finally, image and speech features are directly compared and we predict the SIAR result with the maximum similarity. Extensive experiments demonstrate that our proposed speech encoder can recognize space from human speeches with superior performance over the other prevailing networks. It also sets our penultimate goal of speech-to-speech retrieval. Furthermore, our CSIR proposal can successfully perform bi-directional SIAR between spatial images and reverberant speeches with promising results. Code and data will be available.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ding, H.
AU  - Wang, B.
AU  - Kang, G.
AU  - Li, W.
AU  - He, C.
AU  - Zhao, Y.
AU  - Wei, Y.
TI  - DropQueries: A Simple Way to Discover Comprehensive Segment Representations
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 3481
EP  - 3490
DO  - 10.1109/TMM.2023.3311909
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171524596&doi=10.1109%2fTMM.2023.3311909&partnerID=40&md5=9f69acc71605d6751d45ea74aa63c60a
AB  - Inspired by the recent progress in object detection (i.e., DETR), the set prediction mechanism significantly advances the research of semantic segmentation and achieves state-of-the-art performance on popular segmentation benchmarks. The generic pipeline of such a mechanism often firstly takes learnable query features to predict classes and segment masks separately and then blends these class-aware segment masks into the final segmentation mask. One key factor behind the successful training of this pipeline is to apply the bipartite matching strategy between the set of predictions and ground-truth segments. However, we find that the bipartite matching-based assignment often tends to segment one target class with only a few learnable queries, making many other pre-defined queries useless. In this article, we propose a simple way, named DropQueries (DQ), to facilitate the set prediction based segmentation architectures. At each iteration of training, our DQ randomly and independently drops each learnable query with a certain probability before bipartite matching. In this way, more queries are encouraged to participate in the segmentation process to discover comprehensive segment representations. We conduct extensive experiments using MaskFormer and Mask2Former as two basic yet powerful segmentation architectures. Without bells and whistles, our DQ strategy can bring consistent improvements over strong baselines on popular semantic segmentation benchmarks, including ADE 20 K, Cityscapes, COCO Stuff 10 K and VSPW. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mashrur, A.
AU  - Luo, W.
AU  - Zaidi, N.A.
AU  - Robles-Kelly, A.
TI  - Robust visual question answering via semantic cross modal augmentation
PY  - 2024
T2  - Computer Vision and Image Understanding
VL  - 238
C7  - 103862
DO  - 10.1016/j.cviu.2023.103862
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174688927&doi=10.1016%2fj.cviu.2023.103862&partnerID=40&md5=7500b6ced4c59ccc53dc14b8d5b1f59a
AB  - Recent advances in vision-language models have resulted in improved accuracy in visual question answering (VQA) tasks. However, their robustness remains limited when faced with out-of-distribution data containing unanswerable questions. In this study, we first construct a simple randomised VQA dataset, incorporating unanswerable questions from the VQA v2 dataset, to evaluate the robustness of a state-of-the-art VQA model. Our findings reveal that the model struggles to predict the “unknown” answer or provides inaccurate responses with high confidence scores for irrelevant questions. To address this issue without retraining the large backbone models, we propose Cross Modal Augmentation (CMA), a model-agnostic, test-time-only, multi-modal semantic augmentation technique. CMA generates multiple semantically-consistent but heterogeneous instances from the visual and textual inputs, which are then fed to the model, and the predictions are combined to achieve a more robust output. We demonstrate that implementing CMA enables the VQA model to provide more reliable answers in scenarios involving unanswerable questions, and show that the approach is generalisable across different categories of pre-trained vision language models. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liao, J.
AU  - Hao, Y.
AU  - Zhou, Z.
AU  - Pan, J.
AU  - Liang, Y.
TI  - Sequence-level affective level estimation based on pyramidal facial expression features
PY  - 2024
T2  - Pattern Recognition
VL  - 145
C7  - 109958
DO  - 10.1016/j.patcog.2023.109958
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171621162&doi=10.1016%2fj.patcog.2023.109958&partnerID=40&md5=ce5411819938e67f591eb45dd852b210
AB  - People tend to focus on changes in a certain complex human affect in the majority of practical applications of affective computing. Facial expression classification models are unable to represent all human affects through a limited number of expression categories. In this backdrop, this paper studies the Sequence-level affective level estimation (S-ALE), which is more relevant to real scenarios and can depict individual affective level in continuous manner. A spatio-temporal framework applied to S-ALE is proposed, which consists of a Facial Expression Features Pyramid Network (FEFPN) and a Temporal Transformer Encoder (TTE). FEFPN is capable of extracting pyramidal facial expression features, while TTE can effectively capture coarse-grained and fine-grained temporal variations of facial sequences. The proposed model is evaluated on six public datasets across three typical S-ALE tasks (engagement prediction, fatigue detection, and pain assessment), and experimental results show that our method is comparable to or outperforms the state-of-the-art algorithms. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, F.
AU  - Ren, P.
AU  - Yin, B.
AU  - Wang, F.
AU  - Li, H.
TI  - CATNet: A Cascaded and Aggregated Transformer Network for RGB-D Salient Object Detection
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 2249
EP  - 2262
DO  - 10.1109/TMM.2023.3294003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164690945&doi=10.1109%2fTMM.2023.3294003&partnerID=40&md5=9666a74ebaa58f87f7f2ad2f04f95f3f
AB  - Salient object detection (SOD) is an important preprocessing operation for various computer vision tasks. Most of existing RGB-D SOD models employ additive or connected strategies to directly aggregate and decode multi-scale features to predict salient maps. However, due to the large differences between the features of different scales, these aggregation strategies adopted may lead to information loss or redundancy, and few methods explicitly consider how to establish connections between features at different scales in the decoding process, which consequently deteriorates the detection performance of the models. To this end, we propose a cascaded and aggregated Transformer Network (CATNet) which consists of three key modules, i.e., attention feature enhancement module (AFEM), cross-modal fusion module (CMFM) and cascaded correction decoder (CCD). Specifically, the AFEM is designed on the basis of atrous spatial pyramid pooling to obtain multi-scale semantic information and global context information in high-level features through dilated convolution and multi-head self-attention mechanism, enhancing high-level features. The role of the CMFM is to enhance and thereafter fuse the RGB features and depth features, alleviating the problem of poor-quality depth maps. The CCD is composed of two subdecoders in a cascading fashion. It is designed to suppress noise in low-level features and mitigate the differences between features at different scales. Moreover, the CCD uses a feedback mechanism to correct and repair the output of the subdecoder by exploiting supervised features, so that the problem of information loss caused by the upsampling operation during the multi-scale features aggregation process can be mitigated. Extensive experimental results demonstrate that the proposed CATNet achieves superior performance over 14 state-of-the-art RGB-D methods on 7 challenging benchmarks.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shi, J.
AU  - Gao, P.
AU  - Smolic, A.
TI  - Blind Image Quality Assessment via Transformer Predicted Error Map and Perceptual Quality Token
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 4641
EP  - 4651
DO  - 10.1109/TMM.2023.3325719
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174847487&doi=10.1109%2fTMM.2023.3325719&partnerID=40&md5=82314e6c603e919f2b18912001b8ed14
AB  - Image quality assessment is a fundamental problem in the field of image processing, and due to the lack of reference images in most practical scenarios, no-reference image quality assessment (NR-IQA), has gained increasing attention recently. With the development of deep learning technology, many deep neural network-based NR-IQA methods have been developed, which try to learn the image quality based on the understanding of database information. Currently, Transformer has achieved remarkable progress in various vision tasks. Since the characteristics of the attention mechanism in Transformer fit the global perceptual impact of artifacts perceived by a human, Transformer is thus well suited for image quality assessment tasks. In this paper, we propose a Transformer based NR-IQA model using a predicted objective error map and perceptual quality token. Specifically, we firstly generate the predicted error map by pre-training one model consisting of a Transformer encoder and decoder, in which the objective difference between the distorted and the reference images is used as supervision. Then, we freeze the parameters of the pre-trained model and design another branch using the vision Transformer to extract the perceptual quality token for feature fusion with the predicted error map. Finally, the fused features are regressed to the final image quality score. Extensive experiments have shown that our proposed method outperforms the state-of-the-art methods in both authentic and synthetic image datasets. Moreover, the attentional map extracted by the perceptual quality token also does conform to the characteristics of the human visual system.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shi, J.
AU  - Wang, Y.
AU  - Yu, Z.
AU  - Li, G.
AU  - Hong, X.
AU  - Wang, F.
AU  - Gong, Y.
TI  - Exploiting Multi-Scale Parallel Self-Attention and Local Variation via Dual-Branch Transformer-CNN Structure for Face Super-Resolution
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 2608
EP  - 2620
DO  - 10.1109/TMM.2023.3301225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166746272&doi=10.1109%2fTMM.2023.3301225&partnerID=40&md5=cbff05407e326eb821d17bcdaaae20a1
AB  - Recently, deep learning technique has been widely employed to deal with face super-resolution (FSR) problem. It aims to predict the nonlinear relationship between the low-resolution (LR) face images and corresponding high-resolution (HR) ones, which could recover the high-frequency details from the LR degraded textures. However, either CNN-based or Transformer-based approaches mostly enhance the details by exploiting the relationship of local pixels or patches on LR features, the nonlocal features are not fully taken into account for producing high-frequency textures. To improve the above problem, we design a novel dual-branch module which consists of Transformer and CNN respectively. The Transformer branch extracts multiple scale feature embeddings and explores local and nonlocal self-attention simultaneously. Thus, the parallel self-attention mechanism has superior capabilities to capture the local and nonlocal dependencies on face image in the face reconstruction. Furthermore, the traditional CNNs usually extract features by combining pixels in a local convolutional kernel, it may be not effective to recover lost high-frequency details since the variations of local pixels are not well measured, which is important in recovering vivid edges and contours. To this end, we propose the local variation based attention block on the CNN branch, which could enhance the capabilities by directly extracting features from the variation of neighboring pixels. Finally, the Transformer-branch and CNN-branch are combined together by the modulation block to fuse both nonlocal and local advantages from two branches. Experimental results demonstrate the effectiveness of the proposed method when compared with state-of-the-art approaches.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zou, L.
AU  - Huang, Z.
AU  - Gu, N.
AU  - Wang, G.
TI  - Learning geometric consistency and discrepancy for category-level 6D object pose estimation from point clouds
PY  - 2024
T2  - Pattern Recognition
VL  - 145
C7  - 109896
DO  - 10.1016/j.patcog.2023.109896
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168798218&doi=10.1016%2fj.patcog.2023.109896&partnerID=40&md5=42fba3ba7d1b7c3e687782653bc67696
AB  - Category-level 6D object pose estimation aims to predict the position and orientation of unseen object instances, which is a fundamental problem in robotic applications. Previous works mainly focused on exploiting visual cues from RGB images, while depth images received less attention. However, depth images contain rich geometric attributes about the object's shape, which are crucial for inferring the object's pose. This work achieves category-level 6D object pose estimation by performing sufficient geometric learning from depth images represented by point clouds. Specifically, we present a novel geometric consistency and geometric discrepancy learning framework called CD-Pose to resolve the intra-category variation, inter-category similarity, and objects with complex structures. Our network consists of a Pose-Consistent Module and a Pose-Discrepant Module. First, a simple MLP-based Pose-Consistent Module is utilized to extract geometrically consistent pose features of objects from the pre-computed object shape priors for each category. Then, the Pose-Discrepant Module, designed as a multi-scale region-guided transformer network, is dedicated to exploring each instance's geometrically discrepant features. Next, the NOCS model of the object is reconstructed according to the integration of consistent and discrepant geometric representations. Finally, 6D object poses are obtained by solving the similarity transformation between the reconstruction and the observed point cloud. Experiments on the benchmark datasets show that our CD-Pose produces superior results to state-of-the-art competitors. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Xi, R.
AU  - Zeng, L.
AU  - Towey, D.
AU  - Bai, R.
AU  - Higashita, R.
AU  - Liu, J.
TI  - Structural Priors Guided Network for the Corneal Endothelial Cell Segmentation
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 1
SP  - 309
EP  - 320
DO  - 10.1109/TMI.2023.3300656
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166768066&doi=10.1109%2fTMI.2023.3300656&partnerID=40&md5=2394cbf874ce983aa7366b7fd84fb2af
AB  - The segmentation of blurred cell boundaries in cornea endothelium microscope images is challenging, which affects the clinical parameter estimation accuracy. Existing deep learning methods only consider pixel-wise classification accuracy and lack of utilization of cell structure knowledge. Therefore, the segmentation of the blurred cell boundary is discontinuous. This paper proposes a structural prior guided network (SPG-Net) for corneal endothelium cell segmentation. We first employ a hybrid transformer convolution backbone to capture more global context. Then, we use Feature Enhancement (FE) module to improve the representation ability of features and Local Affinity-based Feature Fusion (LAFF) module to propagate structural information among hierarchical features. Finally, we introduce the joint loss based on cross entropy and structure similarity index measure (SSIM) to supervise the training process under pixel and structure levels. We compare the SPG-Net with various state-of-the-art methods on four corneal endothelial datasets. The experiment results suggest that the SPG-Net can alleviate the problem of discontinuous cell boundary segmentation and balance the pixel-wise accuracy and structure preservation. We also evaluate the agreement of parameter estimation between ground truth and the prediction of SPG-Net. The statistical analysis results show a good agreement and correlation.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, L.
AU  - Gao, X.
AU  - Hu, Z.
AU  - Zhang, S.
TI  - Pattern-Aware Transformer: Hierarchical Pattern Propagation in Sequential Medical Images
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 1
SP  - 405
EP  - 415
DO  - 10.1109/TMI.2023.3306468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168736774&doi=10.1109%2fTMI.2023.3306468&partnerID=40&md5=e8e3bde94bac8e57f99c8712daea1b83
AB  - This paper investigates how to effectively mine contextual information among sequential images and jointly model them in medical imaging tasks. Different from state-of-the-art methods that model sequential correlations via point-wise token encoding, this paper develops a novel hierarchical pattern-aware tokenization strategy. It handles distinct visual patterns independently and hierarchically, which not only ensures the full flexibility of attention aggregation under different pattern representations but also preserves both local and global information simultaneously. Based on this strategy, we propose a Pattern-Aware Transformer (PATrans) featuring a global-local dual-path pattern-aware cross-attention mechanism to achieve hierarchical pattern matching and propagation among sequential images. Furthermore, PATrans is plug-and-play and can be seamlessly integrated into various backbone networks for diverse downstream sequence modeling tasks. We demonstrate its general application paradigm across four domains and five benchmarks in video object detection and 3D volumetric semantic segmentation tasks, respectively. Impressively, PATrans sets new state-of-the-art across all these benchmarks, i.e., CVC-Video (92.3% detection F1), ASU-Mayo (99.1% localization F1), Lung Tumor (78.59% DSC), Nasopharynx Tumor (75.50% DSC), and Kidney Tumor (87.53% DSC). Codes and models are available at https://github.com/GGaoxiang/PATrans. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Zhao, L.
AU  - Chen, Y.
AU  - Guo, L.
AU  - Zhang, T.
AU  - Hu, X.
AU  - Shen, D.
AU  - Jiang, X.
AU  - Liu, T.
TI  - Rectify ViT Shortcut Learning by Visual Saliency
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 12
SP  - 18013
EP  - 18025
DO  - 10.1109/TNNLS.2023.3310531
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171803934&doi=10.1109%2fTNNLS.2023.3310531&partnerID=40&md5=be85bd5b51de992dd756fa1347935cf8
AB  - Shortcut learning in deep learning models occurs when unintended features are prioritized, resulting in degenerated feature representations and reduced generalizability and interpretability. However, shortcut learning in the widely used vision transformer (ViT) framework is largely unknown. Meanwhile, introducing domain-specific knowledge is a major approach to rectifying the shortcuts that are predominated by background-related factors. For example, eye-gaze data from radiologists are effective human visual prior knowledge that has the great potential to guide the deep learning models to focus on meaningful foreground regions. However, obtaining eye-gaze data can still sometimes be time-consuming, labor-intensive, and even impractical. In this work, we propose a novel and effective saliency-guided ViT (SGT) model to rectify shortcut learning in ViT with the absence of eye-gaze data. Specifically, a computational visual saliency model (either pretrained or fine-tuned) is adopted to predict saliency maps for input image samples. Then, the saliency maps are used to filter the most informative image patches. Considering that this filter operation may lead to global information loss, we further introduce a residual connection that calculates the self-attention across all the image patches. The experiment results on natural and medical image datasets show that our SGT framework can effectively learn and leverage human prior knowledge without eye-gaze data and achieves much better performance than baselines. Meanwhile, it successfully rectifies the harmful shortcut learning and significantly improves the interpretability of the ViT model, demonstrating the promise of transferring human prior knowledge derived visual saliency in rectifying shortcut learning.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gerges, F.
AU  - Boufadel, M.C.
AU  - Bou-Zeid, E.
AU  - Nassif, H.
AU  - Wang, J.T.L.
TI  - Long-term prediction of daily solar irradiance using Bayesian deep learning and climate simulation data
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 1
SP  - 613
EP  - 633
DO  - 10.1007/s10115-023-01955-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170077025&doi=10.1007%2fs10115-023-01955-x&partnerID=40&md5=aa25ef4f942deb5c28f39937b9930c63
AB  - Solar Irradiance depicts the light energy produced by the Sun that hits the Earth. This energy is important for renewable energy generation and is intrinsically fluctuating. Forecasting solar irradiance is crucial for efficient solar energy generation and management. Work in the literature focused on the short-term prediction of solar irradiance, using meteorological data to forecast the irradiance for the next hours, days, or weeks. Facing climate change and the continuous increase in greenhouse gas emissions, particularly from the use of fossil fuels, the reliance on renewable energy sources, such as solar energy, is expanding. Consequently, governments and practitioners are calling for efficient long-term energy generation plans, which could enable 100% renewable-based electricity systems to match energy demand. In this paper, we aim to perform the long-term prediction of daily solar irradiance, by leveraging the downscaled climate simulations of Global Circulation Models (GCMs). We propose a novel Bayesian deep learning framework, named DeepSI (denoting Deep Solar Irradiance), that employs bidirectional long short-term memory autoencoders, prefixed to a transformer, with an uncertainty quantification component based on the Monte Carlo dropout sampling technique. We use DeepSI to predict daily solar irradiance for three different locations within the United States. These locations include the Solar Star power station in California, Medford in New Jersey, and Farmers Branch in Texas. Experimental results showcase the suitability of DeepSI for predicting daily solar irradiance from the simulated climate data, its superiority over related machine learning methods, and its ability to reproduce the daily variability. We further use DeepSI with future climate simulations to produce long-term projections of daily solar irradiance, up to year 2099. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Slade, S.
AU  - Zhang, L.
AU  - Huang, H.
AU  - Asadi, H.
AU  - Lim, C.P.
AU  - Yu, Y.
AU  - Zhao, D.
AU  - Lin, H.
AU  - Gao, R.
TI  - Neural Inference Search for Multiloss Segmentation Models
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 15113
EP  - 15127
DO  - 10.1109/TNNLS.2023.3282799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162714908&doi=10.1109%2fTNNLS.2023.3282799&partnerID=40&md5=ea3fb498a4d58fe5ce508e2547780b03
AB  - Semantic segmentation is vital for many emerging surveillance applications, but current models cannot be relied upon to meet the required tolerance, particularly in complex tasks that involve multiple classes and varied environments. To improve performance, we propose a novel algorithm, neural inference search (NIS), for hyperparameter optimization pertaining to established deep learning segmentation models in conjunction with a new multiloss function. It incorporates three novel search behaviors, i.e., Maximized Standard Deviation Velocity Prediction, Local Best Velocity Prediction, and n-dimensional Whirlpool Search. The first two behaviors are exploratory, leveraging long short-term memory (LSTM)-convolutional neural network (CNN)-based velocity predictions, while the third employs n-dimensional matrix rotation for local exploitation. A scheduling mechanism is also introduced in NIS to manage the contributions of these three novel search behaviors in stages. NIS optimizes learning and multiloss parameters simultaneously. Compared with state-of-the-art segmentation methods and those optimized with other well-known search algorithms, NIS-optimized models show significant improvements across multiple performance metrics on five segmentation datasets. NIS also reliably yields better solutions as compared with a variety of search methods for solving numerical benchmark functions. © 2024 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yun, Y.K.
AU  - Lin, W.
TI  - Towards a Complete and Detail-Preserved Salient Object Detection
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 4667
EP  - 4680
DO  - 10.1109/TMM.2023.3325731
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174804506&doi=10.1109%2fTMM.2023.3325731&partnerID=40&md5=e0a46470be31db9a3b0b78374cd347c9
AB  - Salient Object Detection (SOD) is dominated by Encoder-Decoder networks which involve multi-scale feature fusion and multi-resolution dense supervision. It is prevalent yet problematic to interpolate feature maps or pool ground truth (GT) to fit the size of decoder stages in SOD. Structural properties are unavoidably damaged since pixels are discarded or changed during scaling, resulting in restoration difficulties and poor predictions. Second, it is intuitive and suboptimal to posit the last layer of an encoder as global context, even though it has been widely accepted that high-level encoder features contain global information that contributes to the overall shape of a SOD. To this end, this paper aims to enhance the abovementioned techniques for richer details and a more complete shape. First, we developed a Global Context Branch (GCB) which is a patch-wise supervised SOD on top of the encoder for better global context modeling. Second, we developed a Context Refinement Module (CRM) to improve high/low-level feature fusion and enhance detail reconstruction. Lastly, we adopt Pixel Shuffle (PS) when scaling features and GT maps to preserve structural information. Experiments demonstrated that our proposed framework achieved state-of-the-art performance among all five benchmark datasets against six related existing evaluation metrics. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, H.-X.
AU  - Hu, Q.
AU  - Tan, G.
AU  - Zhang, Y.
AU  - Lin, Z.-Z.
TI  - A Multi-Layer Model Based on Transformer and Deep Learning for Traffic Flow Prediction
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 1
SP  - 443
EP  - 451
DO  - 10.1109/TITS.2023.3311397
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173022416&doi=10.1109%2fTITS.2023.3311397&partnerID=40&md5=2193eef445c09e882e9c6aa16133ae31
AB  - Using traffic data to accurately predict the traffic flow at a certain time in the future can alleviate problems such as traffic congestion, which plays an important role in the healthy transportation and economic development of cities. However, current traffic flow prediction models rely on human experience and only consider the advantages of single machine learning model. Therefore, in this work, we propose a multi-layer model based on transformer and deep learning for traffic flow prediction (MTDLTFP). The MTDLTFP model first draws on the idea of transformer model, which uses multiple encoders and decoders to perform feature extraction on the initial traffic data without human experience. In addition, in the prediction stage, the MTDLTFP model using deep learning technology, which input the hidden features into the convolutional neural network (CNN) and multi-layer feedforward neural network (MFNN) to obtain the prediction score respectively. The CNN model can captures the correlation information between the hidden features, and the MFNN can captures the nonlinear relationship between the features. Finally, we use a linear model to combine the two prediction scores, which can make the final prediction value take into account the common advantages of both models. Multiple experimental results on two real datasets demonstrate the effectiveness of the MTDLTFP model. The experimental results on the WorkDay dataset are as follows, with the RMSE value of 0.191, MAE value of 0.165. The experimental results on the HoliDay dataset are as follows, with RMSE value of 0.227, MAE value of 0.192.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Hu2024Multi-Layer
ER  -

TY  - JOUR
AU  - Jun, E.
AU  - Jeong, S.
AU  - Heo, D.-W.
AU  - Suk, H.-I.
TI  - Medical Transformer: Universal Encoder for 3-D Brain MRI Analysis
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 12
SP  - 17779
EP  - 17789
DO  - 10.1109/TNNLS.2023.3308712
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173031667&doi=10.1109%2fTNNLS.2023.3308712&partnerID=40&md5=14ebc5f27f08c3513cda968f0e3dc1fd
AB  - Transfer learning has attracted considerable attention in medical image analysis because of the limited number of annotated 3-D medical datasets available for training data-driven deep learning models in the real world. We propose Medical Transformer, a novel transfer learning framework that effectively models 3-D volumetric images as a sequence of 2-D image slices. To improve the high-level representation in 3-D-form empowering spatial relations, we use a multiview approach that leverages information from three planes of the 3-D volume, while providing parameter-efficient training. For building a source model generally applicable to various tasks, we pretrain the model using self-supervised learning (SSL) for masked encoding vector prediction as a proxy task, using a large-scale normal, healthy brain magnetic resonance imaging (MRI) dataset. Our pretrained model is evaluated on three downstream tasks: 1) brain disease diagnosis; 2) brain age prediction; and 3) brain tumor segmentation, which are widely studied in brain MRI research. Experimental results demonstrate that our Medical Transformer outperforms the state-of-the-art (SOTA) transfer learning methods, efficiently reducing the number of parameters by up to approximately 92% for classification and regression tasks and 97% for segmentation task, and it also achieves good performance in scenarios where only partial training samples are used. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Yu, X.
AU  - Chen, J.
AU  - He, B.-G.
AU  - Wang, W.
AU  - Rawat, D.B.
AU  - Lyu, Z.
TI  - PGA-Net: Polynomial Global Attention Network With Mean Curvature Loss for Lane Detection
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 1
SP  - 417
EP  - 429
DO  - 10.1109/TITS.2023.3309948
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171751626&doi=10.1109%2fTITS.2023.3309948&partnerID=40&md5=dbe0ceabe447ea1d651c62720fa8ef89
AB  - Lane detection is an important task in the field of automatic driving. Since lane lines usually have complex topologies and exist in various complex scenes (e.g., damaged lanes, severe occlusion, etc.), lane detection remains challenging. In this work, we propose a Polynomial Global Attention Network (PGA-Net) for lane detection, which is an end-to-end model for mining global road information and predicting lanes shape parameter formulas simultaneously. We model lane shape with cubic polynomial function and use the transformer-based DETR model to introduce the context information of lanes and roads to better regress the lane parameters. For polynomial curve modeling, we propose Mean Curvature Loss (MCL) to constrain the curvature of the predicted lanes, thereby enhancing the quality of curve lanes prediction. In addition, we design an improved supervision strategy to eliminate information bias between our parametric prediction methods and the labeling methods of lane datasets. Our method achieves state-of-the-art performance on two popular benchmarks (TuSimple and LLAMAS) and a most challenging benchmark (CULane), while exhibiting accelerated speed (>140fps on 3090 GPU, 28.9% improvement in average) and lightweight model size (<3M, an averaged 83.7% reduction). Our code is available at https://github.com/qklee-lz/PGA-Net.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Li2024PGA-Net
ER  -

TY  - JOUR
AU  - Lan, Y.
AU  - Xu, X.
AU  - Fang, Q.
AU  - Hao, J.
TI  - Sample Efficient Deep Reinforcement Learning With Online State Abstraction and Causal Transformer Model Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 16574
EP  - 16588
DO  - 10.1109/TNNLS.2023.3296642
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168294481&doi=10.1109%2fTNNLS.2023.3296642&partnerID=40&md5=2d7d72757fef0c58e483f29418762911
AB  - Deep reinforcement learning (RL) typically requires a tremendous number of training samples, which are not practical in many applications. State abstraction and world models are two promising approaches for improving sample efficiency in deep RL. However, both state abstraction and world models may degrade the learning performance. In this article, we propose an abstracted model-based policy learning (AMPL) algorithm, which improves the sample efficiency of deep RL. In AMPL, a novel state abstraction method via multistep bisimulation is first developed to learn task-related latent state spaces. Hence, the original Markov decision processes (MDPs) are compressed into abstracted MDPs. Then, a causal transformer model predictor (CTMP) is designed to approximate the abstracted MDPs and generate long-horizon simulated trajectories with a smaller multistep prediction error. Policies are efficiently learned through these trajectories within the abstracted MDPs via a modified multistep soft actor-critic algorithm with a λ -target. Moreover, theoretical analysis shows that the AMPL algorithm can improve sample efficiency during the training process. On Atari games and the DeepMind Control (DMControl) suite, AMPL surpasses current state-of-the-art deep RL algorithms in terms of sample efficiency. Furthermore, DMControl tasks with moving noises are conducted, and the results demonstrate that AMPL is robust to task-irrelevant observational distractors and significantly outperforms the existing approaches.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Nguyen, H.H.
AU  - Blaschko, M.B.
AU  - Saarakkala, S.
AU  - Tiulpin, A.
TI  - Clinically-Inspired Multi-Agent Transformers for Disease Trajectory Forecasting From Multimodal Data
PY  - 2024
T2  - IEEE Transactions on Medical Imaging
VL  - 43
IS  - 1
SP  - 529
EP  - 541
DO  - 10.1109/TMI.2023.3312524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171522654&doi=10.1109%2fTMI.2023.3312524&partnerID=40&md5=e6f3c1877294878302b6eaa0e55102cb
AB  - Deep neural networks are often applied to medical images to automate the problem of medical diagnosis. However, a more clinically relevant question that practitioners usually face is how to predict the future trajectory of a disease. Current methods for prognosis or disease trajectory forecasting often require domain knowledge and are complicated to apply. In this paper, we formulate the prognosis prediction problem as a one-to-many prediction problem. Inspired by a clinical decision-making process with two agents-a radiologist and a general practitioner - we predict prognosis with two transformer-based components that share information with each other. The first transformer in this framework aims to analyze the imaging data, and the second one leverages its internal states as inputs, also fusing them with auxiliary clinical data. The temporal nature of the problem is modeled within the transformer states, allowing us to treat the forecasting problem as a multi-task classification, for which we propose a novel loss. We show the effectiveness of our approach in predicting the development of structural knee osteoarthritis changes and forecasting Alzheimer's disease clinical status directly from raw multi-modal data. The proposed method outperforms multiple state-of-the-art baselines with respect to performance and calibration, both of which are needed for real-world applications. An open-source implementation of our method is made publicly available at https://github.com/Oulu-IMEDS/CLIMATv2. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, S.-X.
AU  - Yang, C.
AU  - Zhu, X.
AU  - Yin, X.-C.
TI  - Arbitrary Shape Text Detection via Boundary Transformer
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 1747
EP  - 1760
DO  - 10.1109/TMM.2023.3286657
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162703566&doi=10.1109%2fTMM.2023.3286657&partnerID=40&md5=fa209eb27c0a942e9ab5018f5b83daea
AB  - In arbitrary shape text detection, locating accurate text boundaries is challenging and non-trivial. Existing methods often suffer from indirect text boundary modeling or complex post-processing. In this article, we systematically present a unified coarse-to-fine framework via boundary learning for arbitrary shape text detection, which can accurately and efficiently locate text boundaries without post-processing. In our method, we explicitly model the text boundary via an innovative iterative boundary transformer in a coarse-to-fine manner. In this way, our method can directly gain accurate text boundaries and abandon complex post-processing to improve efficiency. Specifically, our method mainly consists of a feature extraction backbone, a boundary proposal module, and an iteratively optimized boundary transformer module. The boundary proposal module consisting of multi-layer dilated convolutions will predict important prior information (including classification map, distance field, and direction field) for generating coarse boundary proposals while guiding the boundary transformer's optimization. The boundary transformer module adopts an encoder-decoder structure, in which the encoder is constructed by multi-layer transformer blocks with residual connection while the decoder is a simple multi-layer perceptron network (MLP). Under the guidance of prior information, the boundary transformer module will gradually refine the coarse boundary proposals via iterative boundary deformation. Furthermore, we propose a novel boundary energy loss (BEL) that introduces an energy minimization constraint and an energy monotonically decreasing constraint to further optimize and stabilize the learning of boundary refinement. Extensive experiments on publicly available and challenging datasets demonstrate the state-of-the-art performance and promising efficiency of our method.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tolan, J.
AU  - Yang, H.-I.
AU  - Nosarzewski, B.
AU  - Couairon, G.
AU  - Vo, H.V.
AU  - Brandt, J.
AU  - Spore, J.
AU  - Majumdar, S.
AU  - Haziza, D.
AU  - Vamaraju, J.
AU  - Moutakanni, T.
AU  - Bojanowski, P.
AU  - Johns, T.
AU  - White, B.
AU  - Tiecke, T.
AU  - Couprie, C.
TI  - Very high resolution canopy height maps from RGB imagery using self-supervised vision transformer and convolutional decoder trained on aerial lidar
PY  - 2024
T2  - Remote Sensing of Environment
VL  - 300
C7  - 113888
DO  - 10.1016/j.rse.2023.113888
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175847704&doi=10.1016%2fj.rse.2023.113888&partnerID=40&md5=c128d09416dae543f829c37c690a939d
AB  - Vegetation structure mapping is critical for understanding the global carbon cycle and monitoring nature-based approaches to climate adaptation and mitigation. Repeated measurements of these data allow for the observation of deforestation or degradation of existing forests, natural forest regeneration, and the implementation of sustainable agricultural practices like agroforestry. Assessments of tree canopy height and crown projected area at a high spatial resolution are also important for monitoring carbon fluxes and assessing tree-based land uses, since forest structures can be highly spatially heterogeneous, especially in agroforestry systems. Very high resolution satellite imagery (less than one meter (1 m) Ground Sample Distance) makes it possible to extract information at the tree level while allowing monitoring at a very large scale. This paper presents the first high-resolution canopy height map concurrently produced for multiple sub-national jurisdictions. Specifically, we produce very high resolution canopy height maps for the states of California and São Paulo, a significant improvement in resolution over the ten meter (10 m) resolution of previous Sentinel / GEDI based worldwide maps of canopy height. The maps are generated by the extraction of features from a self-supervised model trained on Maxar imagery from 2017 to 2020, and the training of a dense prediction decoder against aerial lidar maps. We also introduce a post-processing step using a convolutional network trained on GEDI observations. We evaluate the proposed maps with set-aside validation lidar data as well as by comparing with other remotely sensed maps and field-collected data, and find our model produces an average Mean Absolute Error (MAE) of 2.8 m and Mean Error (ME) of 0.6 m. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Zong, D.
AU  - Sun, S.
TI  - Zero-Shot Human-Object Interaction Detection via Similarity Propagation
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 12
SP  - 17805
EP  - 17816
DO  - 10.1109/TNNLS.2023.3309104
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171581510&doi=10.1109%2fTNNLS.2023.3309104&partnerID=40&md5=321249769876bde798546b3710240b8d
AB  - Human-object interaction (HOI) detection involves identifying interactions represented as (human, action, object), requiring the localization of human-object pairs and interaction classification within an image. This work focuses on the challenge of detecting HOIs with unseen objects using the prevalent Transformer architecture. Our empirical analysis reveals that the performance degradation of novel HOI instances primarily arises from misclassifying unseen objects as confusable seen objects. To address this issue, we propose a similarity propagation (SP) scheme that leverages cosine similarity distance to regulate the prediction margin between seen and unseen objects. In addition, we introduce pseudo-supervision for unseen objects based on class semantic similarities during training. Furthermore, we incorporate semantic-aware instance-level and interaction-level contrastive losses with Transformer to enhance intraclass compactness and interclass separability, resulting in improved visual representations. Extensive experiments on two challenging benchmarks, V-COCO and HICO-DET, demonstrate the effectiveness of our model, outperforming current state-of-the-art methods under various zero-shot settings.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Foumani, N.M.
AU  - Tan, C.W.
AU  - Webb, G.I.
AU  - Salehi, M.
TI  - Improving position encoding of transformers for multivariate time series classification
PY  - 2024
T2  - Data Mining and Knowledge Discovery
VL  - 38
IS  - 1
SP  - 22
EP  - 48
DO  - 10.1007/s10618-023-00948-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169842160&doi=10.1007%2fs10618-023-00948-2&partnerID=40&md5=d30f6eb687d822d42dc56e1d9739259d
AB  - Transformers have demonstrated outstanding performance in many applications of deep learning. When applied to time series data, transformers require effective position encoding to capture the ordering of the time series data. The efficacy of position encoding in time series analysis is not well-studied and remains controversial, e.g., whether it is better to inject absolute position encoding or relative position encoding, or a combination of them. In order to clarify this, we first review existing absolute and relative position encoding methods when applied in time series classification. We then proposed a new absolute position encoding method dedicated to time series data called time Absolute Position Encoding (tAPE). Our new method incorporates the series length and input embedding dimension in absolute position encoding. Additionally, we propose computationally Efficient implementation of Relative Position Encoding (eRPE) to improve generalisability for time series. We then propose a novel multivariate time series classification model combining tAPE/eRPE and convolution-based input encoding named ConvTran to improve the position and data embedding of time series data. The proposed absolute and relative position encoding methods are simple and efficient. They can be easily integrated into transformer blocks and used for downstream tasks such as forecasting, extrinsic regression, and anomaly detection. Extensive experiments on 32 multivariate time-series datasets show that our model is significantly more accurate than state-of-the-art convolution and transformer-based models. Code and models are open-sourced at https://github.com/Navidfoumani/ConvTran . © 2023, Crown.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Zhang, K.
AU  - Su, Y.
AU  - Wang, J.
AU  - Wang, Q.
TI  - Learning Cross-Attention Discriminators via Alternating Time-Space Transformers for Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 11
SP  - 15156
EP  - 15169
DO  - 10.1109/TNNLS.2023.3282905
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162883105&doi=10.1109%2fTNNLS.2023.3282905&partnerID=40&md5=f4fb9c9ef4d702a4d45e052919df6622
AB  - In the past few years, visual tracking methods with convolution neural networks (CNNs) have gained great popularity and success. However, the convolution operation of CNNs struggles to relate spatially distant information, which limits the discriminative power of trackers. Very recently, several Transformer-assisted tracking approaches have emerged to alleviate the above issue by combining CNNs with Transformers to enhance the feature representation. In contrast to the methods mentioned above, this article explores a pure Transformer-based model with a novel semi-Siamese architecture. Both the time-space self-attention module used to construct the feature extraction backbone and the cross-attention discriminator used to estimate the response map solely leverage attention without convolution. Inspired by the recent vision transformers (ViTs), we propose the multistage alternating time-space Transformers (ATSTs) to learn robust feature representation. Specifically, temporal and spatial tokens at each stage are alternately extracted and encoded by separate Transformers. Subsequently, a cross-attention discriminator is proposed to directly generate response maps of the search region without additional prediction heads or correlation filters. Experimental results show that our ATST-based model attains favorable results against state-of-the-art convolutional trackers. Moreover, it shows comparable performance with recent 'CNN + Transformer' trackers on various benchmarks while our ATST requires significantly less training data. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Liu, J.
AU  - Mei, T.
AU  - Luo, J.
TI  - CoSeg: Cognitively Inspired Unsupervised Generic Event Segmentation
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 9
SP  - 12507
EP  - 12517
DO  - 10.1109/TNNLS.2023.3263387
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159817352&doi=10.1109%2fTNNLS.2023.3263387&partnerID=40&md5=fb61100eed4097e44fc232eec84c7fb8
AB  - Some cognitive research has discovered that humans accomplish event segmentation as a side effect of event anticipation. Inspired by this discovery, we propose a simple yet effective end-to-end self-supervised learning framework for event segmentation/boundary detection. Unlike the mainstream clustering-based methods, our framework exploits a transformer-based feature reconstruction scheme to detect event boundaries by reconstruction errors. This is consistent with the fact that humans spot new events by leveraging the deviation between their prediction and what is perceived. Thanks to their heterogeneity in semantics, the frames at boundaries are difficult to be reconstructed (generally with large reconstruction errors), which is favorable for event boundary detection. In addition, since the reconstruction occurs on the semantic feature level instead of the pixel level, we develop a temporal contrastive feature embedding (TCFE) module to learn the semantic visual representation for frame feature reconstruction (FFR). This procedure is like humans building up experiences with 'long-term memory.' The goal of our work is to segment generic events rather than localize some specific ones. We focus on achieving accurate event boundaries. As a result, we adopt the F1 score (Precision/Recall) as our primary evaluation metric for a fair comparison with previous approaches. Meanwhile, we also calculate the conventional frame-based mean over frames (MoF) and intersection over union (IoU) metric. We thoroughly benchmark our work on four publicly available datasets and demonstrate much better results. The source code is available at https://github.com/wang3702/CoSeg.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Kong, L.
AU  - Han, Y.
AU  - Qin, J.
AU  - Sun, Z.
TI  - Contextualized Relation Predictive Model for Self-Supervised Group Activity Representation Learning
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 353
EP  - 366
DO  - 10.1109/TMM.2023.3265280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153343972&doi=10.1109%2fTMM.2023.3265280&partnerID=40&md5=43ded071e39a838d7d9cef42ef1b70fd
AB  - Group activity analysis has attracted remarkable attention recently due to the widespread applications in security, entertainment and military. This article targets at learning group activity representations with self-supervision, which differs from the majorities relying heavily on manually annotated labels. Moreover, existing Self-Supervised Learning (SSL) methods for videos are sub-optimal to generate such representations because of the complex context dynamics in group activities. In this article, an end-to-end framework termed Contextualized Relation Predictive Model (Con-RPM) is proposed for self-supervised group activity representation learning with predictive coding. It involves the Serial-Parallel Transformer Encoder (SPTrans-Encoder) to model the context of spatial interactions and temporal variations, and the Hybrid Context Transformer Decoder (HConTrans-Decoder) to predict the future spatio-temporal relations guided by holistic scene context. Additionally, to improve the discriminability and consistency of prediction, we introduce a united loss integrating group-wise and person-wise contrastive losses in frame-level as well as the adversarial loss in global sequence-level. Consequently, our Con-RPM learns robust group representations via describing temporal evolutions of individual relationships and scene semantics explicitly. Extensive experimental results on downstream tasks indicate the effectiveness and generalization of our model in self-supervised learning, and present state-of-the-art performance on the Volleyball, Collective Activity, VolleyTactic, and Choi's New datasets.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zeng, M.
AU  - Wu, Y.
AU  - Li, Y.
AU  - Yin, R.
AU  - Lu, C.
AU  - Duan, J.
AU  - Li, M.
TI  - LncLocFormer: a Transformer-based deep learning model for multi-label lncRNA subcellular localization prediction by using localization-specific attention mechanism
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 12
C7  - btad752
DO  - 10.1093/bioinformatics/btad752
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181178491&doi=10.1093%2fbioinformatics%2fbtad752&partnerID=40&md5=e4f10628dd866e12d1cb2163a6b956d0
AB  - Motivation: There is mounting evidence that the subcellular localization of lncRNAs can provide valuable insights into their biological functions. In the real world of transcriptomes, lncRNAs are usually localized in multiple subcellular localizations. Furthermore, lncRNAs have specific localization patterns for different subcellular localizations. Although several computational methods have been developed to predict the subcellular localization of lncRNAs, few of them are designed for lncRNAs that have multiple subcellular localizations, and none of them take motif specificity into consideration. Results: In this study, we proposed a novel deep learning model, called LncLocFormer, which uses only lncRNA sequences to predict multi-label lncRNA subcellular localization. LncLocFormer utilizes eight Transformer blocks to model long-range dependencies within the lncRNA sequence and shares information across the lncRNA sequence. To exploit the relationship between different subcellular localizations and find distinct localization patterns for different subcellular localizations, LncLocFormer employs a localization-specific attention mechanism. The results demonstrate that LncLocFormer outperforms existing state-of-the-art predictors on the hold-out test set. Furthermore, we conducted a motif analysis and found LncLocFormer can capture known motifs. Ablation studies confirmed the contribution of the localization-specific attention mechanism in improving the prediction performance.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Li, G.
AU  - Sun, Z.
AU  - Hu, W.
AU  - Cheng, G.
AU  - Qu, Y.
TI  - Position-Aware Relational Transformer for Knowledge Graph Embedding
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 8
SP  - 11580
EP  - 11594
DO  - 10.1109/TNNLS.2023.3262937
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153332293&doi=10.1109%2fTNNLS.2023.3262937&partnerID=40&md5=76f9ad952fbb9cf6e2ee02090dbba51d
AB  - Although Transformer has achieved success in language and vision tasks, its capacity for knowledge graph (KG) embedding has not been fully exploited. Using the self-Attention (SA) mechanism in Transformer to model the subject-relation-object triples in KGs suffers from training inconsistency as SA is invariant to the order of input tokens. As a result, it is unable to distinguish a (real) relation triple from its shuffled (fake) variants (e.g., object-relation-subject) and, thus, fails to capture the correct semantics. To cope with this issue, we propose a novel Transformer architecture, namely, Knowformer, for KG embedding. It incorporates relational compositions in entity representations to explicitly inject semantics and capture the role of an entity based on its position (subject or object) in a relation triple. The relational composition for a subject (or object) entity of a relation triple refers to an operator on the relation and the object (or subject). We borrow ideas from the typical translational and semantic-matching embedding techniques to design relational compositions. We carefully design a residual block to integrate relational compositions into SA and efficiently propagate the composed relational semantics layer by layer. We formally prove that the SA with relational compositions is able to distinguish the entity roles in different positions and correctly capture relational semantics. Extensive experiments and analyses on six benchmark datasets show that Knowformer achieves state-of-The-Art performance on both link prediction and entity alignment. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Zheng, Z.
AU  - Su, T.
AU  - Hu, H.
TI  - DATran: Dual Attention Transformer for Multi-Label Image Classification
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 1
SP  - 342
EP  - 356
DO  - 10.1109/TCSVT.2023.3284812
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162663703&doi=10.1109%2fTCSVT.2023.3284812&partnerID=40&md5=afd44d2ba7b26cf1605298501071529c
AB  - Multi-label image classification is a fundamental yet challenging task, which aims to predict the labels associated with a given image. Most of previous methods directly exploit the high-level features from the last layer of convolutional neural network for classification. However, these methods cannot obtain global features due to the limited size of convolutional kernels, and they fail to extract multi-scale features to effectively recognize small-scale objects in the images. Recent studies exploit the graph convolution network to model the label correlations for boosting the classification performance. Despite substantial progress, these methods rely on manually pre-defined graph structures. Besides, they ignore the associations between semantic labels and image regions, and do not fully explore the spatial context of images. To address above issues, we propose a novel Dual Attention Transformer (DATran) model, which adopts a dual-stream architecture that simultaneously learns spatial and channel correlations from multi-label images. Firstly, in order to solve the problem that current methods are difficult to recognize small-size objects, we develop a new multi-scale feature fusion (MSFF) module to generate multi-scale feature representation by jointly integrating both high-level semantics and low-level details. Secondly, we design a prior-enhanced spatial attention (PSA) module to learn the long-range correlation between objects from different spatial positions in images to enhance the model performance. Thirdly, we devise a prior-enhanced channel attention (PCA) module to capture the inter-dependencies between different channel maps, thus effectively improving the correlation between semantic categories. It is worth noting that PSA module and PCA module complement and promote each other to further augment the feature representations. Finally, the outputs of these two attention modules are fused to obtain the final features for classification. Performance evaluation experiments are conducted on MS-COCO 2014, PASCAL VOC 2007 and VG-500 datasets, demonstrating that DATran model achieves better performance than current state-of-the-art models.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Zhang, Z.
AU  - Xu, W.
AU  - Chen, L.
AU  - Wang, G.
AU  - Yan, L.
AU  - Zhong, S.
AU  - Zou, X.
TI  - Learning Oriented Object Detection via Naive Geometric Computing
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 8
SP  - 10513
EP  - 10525
DO  - 10.1109/TNNLS.2023.3242323
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149397979&doi=10.1109%2fTNNLS.2023.3242323&partnerID=40&md5=65efef631ac0d625c0cf9f901c9f927e
AB  - Detecting oriented objects along with estimating their rotation information is one crucial step for image analysis, especially for remote sensing images. Despite that many methods proposed recently have achieved remarkable performance, most of them directly learn to predict object directions under the supervision of only one (e.g., the rotation angle) or a few (e.g., several coordinates) groundtruth (GT) values individually. Oriented object detection would be more accurate and robust if extra constraints, with respect to proposal and rotation information regression, are adopted for joint supervision during training. To this end, we propose a mechanism that simultaneously learns the regression of horizontal proposals, oriented proposals, and rotation angles of objects in a consistent manner, via naive geometric computing, as one additional steady constraint. An oriented center prior guided label assignment strategy is proposed for further enhancing the quality of proposals, yielding better performance. Extensive experiments on six datasets demonstrate the model equipped with our idea significantly outperforms the baseline by a large margin and several new state-of-the-art results are achieved without any extra computational burden during inference. Our proposed idea is simple and intuitive that can be readily implemented. Source codes are publicly available at: https://github.com/wangWilson/CGCDet.git. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kosugi, S.
AU  - Yamasaki, T.
TI  - Personalized Image Enhancement Featuring Masked Style Modeling
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 1
SP  - 140
EP  - 152
DO  - 10.1109/TCSVT.2023.3285765
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162630341&doi=10.1109%2fTCSVT.2023.3285765&partnerID=40&md5=38eaf1611a3a221205fcfd84f39662a2
AB  - We address personalized image enhancement in this study, where we enhance input images for each user based on the user's preferred images. Previous methods apply the same preferred style to all input images (i.e., only one style for each user); in contrast to these methods, we aim to achieve content-aware personalization by applying different styles to each image considering the contents. For content-aware personalization, we make two contributions. First, we propose a method named masked style modeling, which can predict a style for an input image considering the contents by using the framework of masked language modeling. Second, to allow this model to consider the contents of images, we propose a novel training scheme where we download images from Flickr and create pseudo input and retouched image pairs using a degrading model. We conduct quantitative evaluations and a user study, and our method trained using our training scheme successfully achieves content-aware personalization; moreover, our method outperforms other previous methods in this field. Our source code is available at https://github.com/satoshi-kosugi/masked-style-modeling.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Park, J.
AU  - Lee, K.
AU  - Kim, H.Y.
TI  - Integrated Recognition Assistant Framework Based on Deep Learning for Autonomous Driving: Human-Like Restoring Damaged Road Sign Information
PY  - 2024
T2  - International Journal of Human-Computer Interaction
VL  - 40
IS  - 15
SP  - 3982
EP  - 4002
DO  - 10.1080/10447318.2023.2204274
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158140403&doi=10.1080%2f10447318.2023.2204274&partnerID=40&md5=6b0d923178116b84935b74bb20ff2885
AB  - Unpredictable situations frequently occur in real driving environments, and it is often difficult to recognize road signs. In this case, autonomous vehicles (AVs) have a limited ability to predict areas that cannot be detected, making it difficult to judge objects accurately when some information is lost. Therefore, we propose a framework that helps AVs infer proper information under limited conditions. The entire process consists of three steps. First, the missing part of the road sign is restored using the image generative pre-trained transformer model. Next, the sample image with the highest classification accuracy and restored quality is selected among several sample images. Finally, the selected image is provided to users through the designed user interface. The proposed framework improved recognition accuracy compared with unrestored accuracy, indicating the possibility of application as a driving assistance system, and is meaningful in that it is a system that mimics human reasoning ability. © 2023 Taylor & Francis Group, LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Li, L.
AU  - Zeng, D.
TI  - Integrating Relational Knowledge With Text Sequences for Script Event Prediction
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 7
SP  - 9443
EP  - 9454
DO  - 10.1109/TNNLS.2022.3233371
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147309976&doi=10.1109%2fTNNLS.2022.3233371&partnerID=40&md5=684bac2c6da1f1c66be62162bd6579d6
AB  - Script event prediction aims to infer subsequent events given an incomplete script. It requires a deep understanding of events, and can provide support for a variety of tasks. Existing models rarely consider the relational knowledge between events, they regard scripts as sequences or graphs, which cannot capture the relational information between events and the semantic information of script sequences jointly. To address this issue, we propose a new script form, relational event chain, that combines event chains and relational graphs. We also introduce a new model, relational-transformer, to learn embeddings based on this new script form. In particular, we first extract the relationship between events from an event knowledge graph to formalize scripts as relational event chains, then use the relational-transformer to calculate the likelihood of different candidate events, where the model learns event embeddings that encode both semantic and relational knowledge by combining transformers and graph neural networks (GNNs). Experimental results on both one-step inference and multistep inference tasks show that our model can outperform existing baselines, indicating the validity of encoding relational knowledge into event embeddings. The influence of using different model structures and different types of relational knowledge is analyzed as well. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Beyer Díaz, S.
AU  - Coussement, K.
AU  - De Caigny, A.
AU  - Pérez, L.F.
AU  - Creemers, S.
TI  - Do the US president's tweets better predict oil prices? An empirical examination using long short-term memory networks
PY  - 2024
T2  - International Journal of Production Research
VL  - 62
IS  - 6
SP  - 2158
EP  - 2175
DO  - 10.1080/00207543.2023.2217286
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161382629&doi=10.1080%2f00207543.2023.2217286&partnerID=40&md5=7898c98102b8161138dacb570d959f4b
AB  - The price of oil is highly complex to predict as it is impacted by global demand and supply, geopolitical events, and market sentiment. The accuracy of such predictions, however, has far-reaching implications for supply chain performance, portfolio management, and expected stock market returns. This paper contributes to the oil price prediction literature by evaluating the predictive impact of the US President's communication on Twitter, while benchmarking various Natural Language Processing (NLP) techniques, including Term Frequency-Inverse Document Frequency (TF-IDF), Word2Vec, Doc2Vec, Global Vectors for Word Representation (GloVe), and Bidirectional Encoder Representations from Transformers (BERT). These techniques are combined with a deep neural network Long Short-Term Memory (LSTM) architecture using a five-day lag for both the oil price and the textual Twitter data. The data was collected during the term of US President Donald Trump, resulting in 1449 days of crude oil price prediction and a total of 16,457 tweets. The study is validated for Brent and West Texas Intermediate blends, using the daily price of a barrel of crude oil as the target variable. The results confirm that including the US President's tweets significantly increases the predictive power of oil price prediction models, and that an LSTM architecture with BERT as NLP technique has the best performance. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Beyer Díaz2024Do
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Guo, Y.
AU  - Wang, K.
AU  - Liu, F.
AU  - Nie, L.
AU  - Kankanhalli, M.
TI  - Learning to Agree on Vision Attention for Visual Commonsense Reasoning
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 1065
EP  - 1075
DO  - 10.1109/TMM.2023.3275874
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159844224&doi=10.1109%2fTMM.2023.3275874&partnerID=40&md5=796e5af65a88ec61025027c78c783e7a
AB  - Visual Commonsense Reasoning (VCR) remains a significant yet challenging research problem in the realm of visual reasoning. A VCR model generally aims at answering a textual question regarding an image, followed by the rationale prediction for the preceding answering process. Though these two processes are sequential and intertwined, existing methods always consider them as two independent matching-based instances. They, therefore, ignore the pivotal relationship between the two processes, leading to sub-optimal model performance. This paper presents a novel visual attention alignment method to efficaciously handle these two processes in a unified framework. To achieve this, we first design a re-attention module for aggregating the vision attention map produced in each process. Thereafter, the resultant two sets of attention maps are carefully aligned to guide the two processes to make decisions based on the same image regions. We apply this method to both conventional attention and the recent Transformer models and carry out extensive experiments on the VCR benchmark dataset. The results demonstrate that with the attention alignment module, our method achieves a considerable improvement over the baseline methods, evidently revealing the feasibility of the coupling of the two processes as well as the effectiveness of the proposed method.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fan, X.
AU  - Zhang, Y.
AU  - Lu, Y.
AU  - Wang, H.
TI  - PARFormer: Transformer-Based Multi-Task Network for Pedestrian Attribute Recognition
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 1
SP  - 411
EP  - 423
DO  - 10.1109/TCSVT.2023.3285411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162623426&doi=10.1109%2fTCSVT.2023.3285411&partnerID=40&md5=d953aa2a32692a56db2a9eb6bebf4650
AB  - Pedestrian attribute recognition (PAR) has received increasing attention because of its wide application in video surveillance and pedestrian analysis. Extracting robust feature representation is one of the key challenges in this task. The existing methods primarily rely on convolutional neural networks (CNNs) as the backbone network for feature extraction. However, these methods mainly focus on small discriminative regions while ignoring the global perspective. To overcome these limitations, we propose PARFormer, a pure transformer-based multi-task PAR network consisting of four modules. In the feature extraction module, we build a transformer-based strong baseline for feature extraction, which achieves competitive results on several PAR benchmarks compared with the existing CNN-based baseline methods. Since the PAR task is vulnerable to environmental factors, we enhance feature robustness in the feature processing module and propose an effective data augmentation strategy named batch random mask (BRM) block to reinforce the attentive feature learning of random patches. Furthermore, we propose a multi-attribute center loss (MACL) to augment the inter-attribute discriminability of feature representations. As viewpoints can affect some specific attributes, in the viewpoint perception module, we propose a multi-view contrastive loss (MVCL) that enables the network to exploit the viewpoint information. In the attribute recognition module, we alleviate the negative-positive imbalance problem to generate the attribute predictions. These modules interact and jointly learn a highly discriminative feature space and supervise the generation of the final features. Extensive experimental results show that the proposed PARFormer network performs well compared to the state-of-the-art methods on several public datasets, including PETA, RAP, and PA100K. Code will be released at https://github.com/xwf199/PARFormer.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, S.
AU  - Zhai, D.-H.
AU  - Xia, Y.
TI  - A Novel Robotic Pushing and Grasping Method Based on Vision Transformer and Convolution
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 8
SP  - 10832
EP  - 10845
DO  - 10.1109/TNNLS.2023.3244186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149892329&doi=10.1109%2fTNNLS.2023.3244186&partnerID=40&md5=6574e921fcd0d8f09d4a564d282acc0b
AB  - Robotic grasping techniques have been widely studied in recent years. However, it is always a challenging problem for robots to grasp in cluttered scenes. In this issue, objects are placed close to each other, and there is no space around for the robot to place the gripper, making it difficult to find a suitable grasping position. To solve this problem, this article proposes to use the combination of pushing and grasping (PG) actions to help grasp pose detection and robot grasping. We propose a pushing-grasping combined grasping network (GN), PG method based on transformer and convolution (PGTC). For the pushing action, we propose a vision transformer (ViT)-based object position prediction network pushing transformer network (PTNet), which can well capture the global and temporal features and can better predict the position of objects after pushing. To perform the grasping detection, we propose a cross dense fusion network (CDFNet), which can make full use of the RGB image and depth image, and fuse and refine them several times. Compared with previous networks, CDFNet is able to detect the optimal grasping position more accurately. Finally, we use the network for both simulation and actual UR3 robot grasping experiments and achieve SOTA performance. Video and dataset are available at https://youtu.be/Q58YE-Cc250. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Yang, C.
AU  - Chang, J.
AU  - Zhao, F.
AU  - Zha, Z.-J.
AU  - Wu, F.
TI  - DDOD: Dive Deeper into the Disentanglement of Object Detector
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 284
EP  - 298
DO  - 10.1109/TMM.2023.3264008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153356932&doi=10.1109%2fTMM.2023.3264008&partnerID=40&md5=24a66f872943142f2efded862919eff7
AB  - Compared to many other dense prediction tasks, object detection plays a fundamental role in visual perception and scene understanding. Dense object detection, aiming at localizing objects directly from the feature map, has drawn great attention due to its low cost and high efficiency. Though it has been developed for a long time, the training pipeline of dense object detectors is still compromised to lots of conjunctions. In this paper, we demonstrate the existence of three conjunctions lying in the current paradigm of one-stage detectors: 1) only samples assigned as positive in classification head are used to train the regression head; 2) classification and regression share the same input feature and computational fields defined by the parallel head architecture; and 3) samples distributed in different feature pyramid layers are treated equally when computing the loss. Based on this, we propose Disentangled Dense Object Detector (DDOD), a simple, direct, and efficient framework for 2D detection with strong performance. We derive two DDOD variants (i.e., DR-CNN, and DDETR) following the basic one-stage/two-stage and recently developed transformer-based pipelines. Specifically, we develop three effective disentanglement mechanisms and integrate them into the current state-of-the-art object detectors. Extensive experiments on MS COCO benchmark show that our approach obtains significant enhancements with negligible extra overhead on various detectors. Notably, our best model reaches 55.4 mAP on the COCO test-dev set, achieving new state-of-the-art performance on this competitive benchmark. Additionally, we validate our model on several challenging tasks including small object detection and crowded object detection. The experimental results further prove the superiority of disentanglement on these conjunctions. Code is available at https://github.com/zehuichen123/DDOD.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Wang, L.
AU  - Liu, J.
AU  - Tang, J.
TI  - ViST: A Ubiquitous Model with Multimodal Fusion for Crop Growth Prediction
PY  - 2023
T2  - ACM Transactions on Sensor Networks
VL  - 20
IS  - 1
C7  - 23
DO  - 10.1145/3627707
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181539431&doi=10.1145%2f3627707&partnerID=40&md5=efe356d5b2b506e75581eedae5c13c2f
AB  - Crop growth prediction can help agricultural workers to make accurate and reasonable decisions on farming activities. Existing crop growth prediction models focus on one crop and train a single model for each crop. In this article, we develop a ubiquitous growth prediction model for multiple crops, aiming at training a single model for multiple crops. A ubiquitous vision and sensor transformer (ViST) model for crop growth prediction with image and sensor data is developed to achieve the goals. In the proposed model, a cross-attention mechanism is proposed to facilitate the fusion of multimodal feature maps to reduce computational costs and balance the interactive effects among features. To train the model, we combine the data from multiple crops to create a single (ViST) model. A sensor network system is established for data collection on the farm where rice, soybean, and maize are cultivated. Experimental results show that the proposed ViST model has an excellent ubiquitous ability for crop growth prediction with multiple crops. © 2023 Association for Computing Machinery. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fan, B.
AU  - Zhang, K.
AU  - Tian, J.
TI  - HCPVF: Hierarchical Cascaded Point-Voxel Fusion for 3D Object Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 10
SP  - 8997
EP  - 9009
DO  - 10.1109/TCSVT.2023.3268849
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159725172&doi=10.1109%2fTCSVT.2023.3268849&partnerID=40&md5=f2f03db3a66322281622e3ad19a7a6ef
AB  - With the astonishing development of 3D sensors, point cloud based 3D object detection is attracting increasing attention from both industry and academia, and widely applied in various fields, such as robotics and autonomous driving. However, how to balance the 3D object detecting accuracy and speed is still a challenging problem. In this paper, we study this issue and propose a novel and effective 3D point cloudy object detection network based on hierarchical cascaded point-voxel fusion, called HCPVF. Firstly, a novel bird's-eye-view(BEV) attention mechanism with linear complexity is developed to improve point cloud feature backbone network, which can be implemented easily to mine the point-to-point similarity in BEV's view, by two cascaded linear layers and two normalization layers. This operation captures long-range dependencies and reduces the uneven sampling of sparse BEV features, making the extracted point cloudy features more discriminative. Secondly, the proposed HCPVF module is equipped with dual-level hierarchical cascaded detection head, including voxel level and the following point level. The voxel level is composed of coarse Region of interest(RoI) pooling and fine RoI pooling, which are cooperated to aggregate voxel features from different grid divisions and predict relatively coarse detection boxes. In the following, the point level is based on Key Points Transformer. It firstly encodes the spatial context information between the original point and the voxel level box. And then, a novel dual-weighted decoder is developed to enhance the context interaction by weighting the channel and spatial dimensions to obtain more accurate detection results. This design utilizes the voxel based method with high computational efficiency and the point based method with more complete spatial information, fusing low-level voxel features and high-level point features through hierarchical cascaded strategy. Extensive experiments demonstate that the proposed HCPVF achieves state-of-the-art 3D detection performance while maintaining computational efficiency on both the Waymo Open Dataset and the highly-competitive KITTI benchmark.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fang, F.
AU  - Liang, W.
AU  - Cheng, Y.
AU  - Xu, Q.
AU  - Lim, J.-H.
TI  - Enhancing Representation Learning With Spatial Transformation and Early Convolution for Reinforcement Learning-Based Small Object Detection
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 1
SP  - 315
EP  - 328
DO  - 10.1109/TCSVT.2023.3284453
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162649858&doi=10.1109%2fTCSVT.2023.3284453&partnerID=40&md5=913a9e5e33f971a8a1fd32c59d4aef38
AB  - Although object detection has achieved significant progress in the past decade, detecting small objects is still far from satisfactory due to the high variability of object scales and complex backgrounds. The common way to enhance small object detection is to use high-resolution (HR) images. However, this method incurs huge computational resources which grow squarely with the resolution of images. To achieve both accuracy and efficiency, we propose a novel reinforcement learning framework that employs an efficient policy network consisting of a Spatial Transformation Network to enhance the state representation learning and a Transformer model with early convolution to improve feature extraction. Our method has two main steps: (1) coarse location query (CLQ), where an RL agent is trained to predict the locations of small objects on low-resolution (LR) (down-sampled version of HR) images; (2) context-sensitive object detection where HR image patches are used to detect objects on the selected coarse locations and LR image patches on background areas (containing no small objects). In this way, we can obtain high detection performance on small objects while avoiding unnecessary computation on background areas. The proposed method has been tested and benchmarked on various datasets. On the Caltech Pedestrians Detection and Web Pedestrians datasets, the proposed method improves the detection accuracy by 2%, while reducing the number of processed pixels. On the Vision meets Drone object detection dataset and the Oil and Gas Storage Tank dataset, the proposed method outperforms the state-of-the-art (SotA) methods. On MS COCO mini-val set, our method outperforms SotA methods on small object detection, while also achieving comparable performance on medium and large objects.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cong, R.
AU  - Sheng, H.
AU  - Yang, D.
AU  - Cui, Z.
AU  - Chen, R.
TI  - Exploiting Spatial and Angular Correlations with Deep Efficient Transformers for Light Field Image Super-Resolution
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 1421
EP  - 1435
DO  - 10.1109/TMM.2023.3282465
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161587115&doi=10.1109%2fTMM.2023.3282465&partnerID=40&md5=00fd275078b4bbb0f66c14714b7a3d4d
AB  - Global context information is particularly important for comprehensive scene understanding. It helps clarify local confusions and smooth predictions to achieve fine-grained and coherent results. However, most existing light field processing methods leverage convolution layers to model spatial and angular information. The limited receptive field restricts them to learn long-range dependency in LF structure. In this article, we propose a novel network based on deep efficient transformers (i.e., LF-DET) for LF spatial super-resolution. It develops a spatial-angular separable transformer encoder with two modeling strategies termed as sub-sampling spatial modeling and multi-scale angular modeling for global context interaction. Specifically, the former utilizes a sub-sampling convolution layer to alleviate the problem of huge computational cost when capturing spatial information within each sub-aperture image. In this way, our model can cascade more transformers to continuously enhance feature representation with limited resources. The latter processes multi-scale macro-pixel regions to extract and aggregate angular features focusing on different disparity ranges to well adapt to disparity variations. Besides, we capture strong similarities among surrounding pixels by dynamic positional encodings to fill the gap of transformers that lack of local information interaction. The experimental results on both real-world and synthetic LF datasets confirm our LF-DET achieves a significant performance improvement compared with state-of-the-art methods. Furthermore, our LF-DET shows high robustness to disparity variations through the proposed multi-scale angular modeling.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 45
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, R.
AU  - Cheng, Y.
AU  - Huang, S.
AU  - Li, C.
AU  - Cheng, X.
TI  - Transformer-Based High-Fidelity Facial Displacement Completion for Detailed 3D Face Reconstruction
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 799
EP  - 810
DO  - 10.1109/TMM.2023.3271816
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159797847&doi=10.1109%2fTMM.2023.3271816&partnerID=40&md5=a7389113cbc0980145d43dd3619eedc9
AB  - In this paper, we tackle a special face completion task, facial displacement completion, which can offer a key component for many single image 3D face reconstruction systems. To produce a detailed 3D face with ear-to-ear complete displacement UV map, we propose a novel Displacement Completion method based on Transformer (DCT). Current transformer based image inpainting methods usually follow a two-stage scheme, which firstly recovers the masked pixels in low resolution with transformer, and then replenishes the inpainting result in high resolution with GAN. Although these methods have achieved great success, they suffer from information loss from two aspects when applied in face completion: 1) The downsampling operation makes transformer only produce a coarse appearance prior for GAN, incurring middle and low level information loss. 2) Some meaningful facial semantics can be well captured by transformer and further benefit the completion, but it's has not yet been explored. Motivated by the above considerations, we come up with three key designs in the proposed DCT: PCA tokenization, BERT-style learning, and style modulation. Firstly, we use PCA tokenization to replace the downsampling in transformer to preserve more meaningful structures. Secondly, we make transformer simulate the two tasks in BERT, Masked Language Model (MLM) and Next Sentence Prediction (NSP), for both masked pixels and facial attributes recovery. Thirdly, we encode the outcome of transformer as the latent code to guide an image translation network in the StyleGAN2 modulation way. Experments on both FaceScape dataset and in-the-wild data demonstrate DCT's better performance compared with other transformer based or GAN based completion methods.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Yin, P.
AU  - Wang, Y.
AU  - Yang, W.
TI  - CMAT: Integrating Convolution Mixer and Self-Attention for Visual Tracking
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 326
EP  - 338
DO  - 10.1109/TMM.2023.3264851
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153366304&doi=10.1109%2fTMM.2023.3264851&partnerID=40&md5=7121c591b485fd6a13412635df4b78b0
AB  - Convolutional Neural Networks (CNNs) and Transformer are two powerful representation learning techniques for visual tracking. Although CNNs can effectively reduce local redundancy via small-neighborhood convolution operations, their limited receptive fields make it difficult to capture global dependency. Self-attention in Transformer uses patches as the input representation, which can effectively capture long-range dependency. However, blind similarity comparisons between all patches can lead to high redundancy. Is there then a technique that combines well the advantages of both paradigms for visual tracking? In this work, we design a novel backbone network for feature extraction. First, we choose Depthwise Convolution and Pointwise Convolution to build a Convolution Mixer, which effectively separates spatial mixing from channel-wise mixing of information. The Convolution Mixer reduces redundancy in spatial and channel features while increasing receptive field. Then, to exploit the global modeling ability of self-attention, we construct a module by aggregating Convolution Mixer and self-attention. The module shares dominant computational complexity (the square of the channel size) in the first stage. In the second stage, the shift and summation operations are lightweight. Finally, to alleviate the overfitting of the backbone network during training, a dropout layer is added at the end of the module to improve the generalization ability of the network model. Stronger image features are provided for subsequent feature fusion and prediction. The proposed tracker (named CMAT) achieves satisfying tracking performance on ten challenging datasets. In particular, CMAT achieves a 64.1% AUC on LaSOT and a 68.9% AUC on UAV123 while running at 23 FPS.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, G.
AU  - Fu, H.
AU  - Zhou, T.
AU  - Xiao, G.
AU  - Fu, K.
AU  - Xia, Y.
AU  - Zhang, Y.
TI  - Fusion-Embedding Siamese Network for Light Field Salient Object Detection
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 984
EP  - 994
DO  - 10.1109/TMM.2023.3274933
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159839633&doi=10.1109%2fTMM.2023.3274933&partnerID=40&md5=43961cda3d830be51b2fe425af7513e2
AB  - Light field salient object detection (SOD) has shown remarkable success and gained considerable attention from the computer vision community. Existing methods usually employ a single-/two-stream network to detect saliency. However, these methods can only handle up to two different modalities at a time, preventing them from being able to fully explore the rich information in multi-modal light field derived data. To address this, we propose the first joint multi-modal learning framework, called FES-Net, for light field SOD, which can take rich inputs not limited to two modalities. Specifically, we propose an attention-aware adaptation module to first transform the multi-modal inputs for use in our joint learning framework. The transformed inputs are then fed to a Siamese network along with multiple embedded feature fusion modules to extract informative multi-modal features. Finally, we predict saliency maps from the high-level extracted features using a saliency decoder module. Our joint multi-modal learning framework effectively resolves the limitations of existing methods, providing efficient and effective multi-modal learning that can fully explore the valuable information in light field data for accurate saliency detection. Furthermore, we improve the performance by introducing the Transformer as our backbone network. To the best of our knowledge, the improved version of our model, called FES-Trans, is the first attempt to address the challenging light field SOD with the powerful Transformer technique. Extensive experiments on benchmark datasets demonstrate that our models are superior light field SOD approaches and outperform cutting-edge models remarkably.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Cao, L.
AU  - Wang, H.
AU  - Xu, L.
TI  - End-to-End Instance-Level Human Parsing by Segmenting Persons
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 41
EP  - 50
DO  - 10.1109/TMM.2023.3260631
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151538634&doi=10.1109%2fTMM.2023.3260631&partnerID=40&md5=9d8f8ec63cef499c8b89399171a7dc69
AB  - Instance-level human parsing is aimed at separately partitioning the human body into different semantic parts for each individual, which remains a challenging task due to human appearance/pose variation, occlusion and complex backgrounds. Most state-of-the-art methods follow the 'parsing-by-detection' paradigm, which relies on a trained detector to localize persons and then sequentially performs single-person parsing for each person. However, this paradigm is closely related to the detector, and the runtime is proportional to the number of persons in an image. In this paper, we present a novel detection-free framework for instance-level human parsing in an end-to-end manner. We decompose instance-level human parsing into two subtasks via a unified network: 1) semantic segmentation for pixel-level classification as a human part and 2) instance segmentation for mask-level classification as a person. The framework can directly predict the human-part semantic mask for all persons and binary masks for instance-level persons in parallel. The parsing result of each person can be acquired via a Hadamard product between the human-part semantic mask and the corresponding person's binary mask. Extensive experiments demonstrate that our proposed method performs favorably against state-of-the-art methods on the CIHP and MHP v2 datasets.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bai, J.
AU  - Ding, T.
AU  - Jia, W.
AU  - Zhu, S.
AU  - Bai, L.
AU  - Li, F.
TI  - Online Rectangle Packing Algorithm for Swapped Battery Charging Dispatch Model Considering Continuous Charging Power
PY  - 2024
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 21
IS  - 1
SP  - 320
EP  - 331
DO  - 10.1109/TASE.2022.3220280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141583847&doi=10.1109%2fTASE.2022.3220280&partnerID=40&md5=5f9f43c24dc48b90f7c851fd893ef1b7
AB  - The vigorous development of electric vehicles (EVs) is an important means of reducing carbon emissions and mitigating environmental problems such as the greenhouse effect. Battery swapping stations (BSSs) can both provide battery swapping services for large-scale EVs and charge batteries centrally. As the supply of fully charged batteries in the BSS shrinks, it becomes necessary to schedule the charging of the depleted batteries rapidly that users have swapped for fully-charged ones. The charging schedule for depleted batteries must be made without knowledge of future battery arrivals. In this context, this paper develops a mathematical model for online charging scheduling of BSSs, formulates the charging strategy as a two-dimensional rectangle packing problem, and quickly calculates the scheduling arrangement of batteries by partitioning the remaining available capacity of a BSS. Since there are limited battery types within the BSS which can provide battery replacement services, this paper supplements the proposed model with known battery types, which improves the utilization of the available capacity of BSSs. Finally, numerical results verify the effectiveness of the proposed model. Note to Practitioners - Electric vehicles (EVs) are becoming an alternative way to reduce carbon emissions in transportation systems. Herein, the optimal battery charging problem is the core problem when it comes to dispatching a huge number of EVs. Up to now, battery-swapping is widely used for EVs due to its simple, convenient way. Furthermore, a business model for the battery swapping stations (BSSs) is brought up, where EV users send their depleted batteries to the BSS and the BSS provides the users with a fully charged replacement battery from its warehouse, which only takes a few minutes. Since the maximum charging power of the BSS is limited by the capacity of the transformer connecting the BSS to the power grid, the BSS will adopt an optimal charging schedule that maximizes the charging benefit for large quantities of depleted batteries in the warehouse. However, the challenge is that the charging schedule for depleted batteries must be made without knowledge of future battery arrivals because the EV behaviors are difficult to predict. To address this problem, this paper developed an online charging scheduling algorithm, which formulates the charging strategy as a two-dimensional rectangle packing problem. The proposed method can provide battery replacement services in real-time and solve quickly without any information about incoming depleted EV batteries. The proposed model and method have been tested on the system with different numbers of batteries to show the effectiveness. Besides, the online two-dimensional rectangle packing problem can provide an online decision for BSSs.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Nan, Z.
AU  - Xiang, T.
TI  - Third-Person View Attention Prediction in Natural Scenarios With Weak Information Dependency and Human-Scene Interaction Mechanism
PY  - 2024
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 34
IS  - 8
SP  - 6762
EP  - 6773
DO  - 10.1109/TCSVT.2023.3286442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162668471&doi=10.1109%2fTCSVT.2023.3286442&partnerID=40&md5=7da43a7e5e1eef886e56140197a50070
AB  - First-person view attention has been widely studied in computer science domain since 1990s while third-person view attention in natural scenarios begins to gain the intensive interest until 2015. This paper focuses on the problem of third-person view attention prediction in natural scenarios where a human freely performs daily activities without constraints. To handle the two insuffiencies of existing methods: 1) assuming some extra information (except for input images) are given in advance; and 2) ignoring the importance of human-scene interaction, this paper proposes a model with weak information dependency, which helps to alleviate annotation costs. In addition, a transformer-based human-scene interaction mechanism is proposed to explore the global and long-dependency contexts between the human and scene. The pipeline of the proposed model is firstly extracting human and scene features, then inferring human attention probability map by fusing human and scene features via a transformer-based network, and finally predicting human attention object based on human attention probability map and object detection. The experiments on two public datasets validate the effectiveness of our model.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, Q.
AU  - Zhou, L.
AU  - Zhang, Z.
AU  - Liu, S.
AU  - Jiao, B.
AU  - Zhang, J.
AU  - Dai, L.
AU  - Jiang, D.
AU  - Li, J.
AU  - Wei, F.
TI  - VatLM: Visual-Audio-Text Pre-Training With Unified Masked Prediction for Speech Representation Learning
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 1055
EP  - 1064
DO  - 10.1109/TMM.2023.3275873
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159799804&doi=10.1109%2fTMM.2023.3275873&partnerID=40&md5=697560dac95cc6c7405b93249bd8ad12
AB  - Although speech is a simple and effective way for humans to communicate with the outside world, a more realistic speech interaction contains multimodal information, e.g., vision, text. How to design a unified framework to integrate different modal information and leverage different resources (e.g., visual-audio pairs, audio-text pairs, unlabeled speech, and unlabeled text) to facilitate speech representation learning was not well explored. In this article, we propose a unified cross-modal representation learning framework VatLM (Visual-Audio-Text Language Model). The proposed VatLM employs a unified backbone network to model the modality-independent information and utilizes three simple modality-dependent modules to preprocess visual, speech, and text inputs. In order to integrate these three modalities into one shared semantic space, VatLM is optimized with a masked prediction task of unified tokens, given by our proposed unified tokenizer. We evaluate the pre-trained VatLM on audio-visual related downstream tasks, including audio-visual speech recognition (AVSR), and visual speech recognition (VSR) tasks. Results show that the proposed VatLM outperforms previous state-of-the-art models, such as the audio-visual pre-trained AV-HuBERT model, and analysis also demonstrates that VatLM is capable of aligning different modalities into the same space.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, T.
AU  - Chen, H.
AU  - Hu, G.
AU  - He, L.
AU  - Zhao, C.
TI  - Explainability of Speech Recognition Transformers via Gradient-Based Attention Visualization
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 1395
EP  - 1406
DO  - 10.1109/TMM.2023.3282488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161613293&doi=10.1109%2fTMM.2023.3282488&partnerID=40&md5=91e22deaa45c819c642affe4df6b395a
AB  - In vision Transformers, attention visualization methods are used to generate heatmaps highlighting the class-corresponding areas in input images, which offers explanations on how the models make predictions. However, it is not so applicable for explaining automatic speech recognition (ASR) Transformers. An ASR Transformer makes a particular prediction for every input token to form a sentence, but a vision Transformer only makes an overall classification for the input data. Therefore, traditional attention visualization methods may fail in ASR Transformers. In this work, we propose a novel attention visualization method in ASR Transformers and try to explain which frames of the audio result in the output text. Inspired by the model explainability, we also explore ways of improving the effectiveness of the ASR model. Comparing with other Transformer attention visualization methods, our method is more efficient and intuitively understandable, which unravels the attention calculation from information flow of Transformer attention modules. In addition, we demonstrate the utilization of visualization result in three ways: (1) We visualize attention with respect to connectionist temporal classification (CTC) loss to train an ASR model with adversarial attention erasing regularization, which effectively decreases the word error rate (WER) of the model and improves its generalization capability. (2) We visualize the attention on some specific words, interpreting the model by effectively demonstrating the semantic and grammar relationships between these words. (3) Similarly, we analyze how the model manage to distinguish homophones, using contrastive explanation with respect to homophones.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mo, S.
AU  - Xin, M.
TI  - BSTG-Trans: A Bayesian Spatial-Temporal Graph Transformer for Long-Term Pose Forecasting
PY  - 2024
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 673
EP  - 686
DO  - 10.1109/TMM.2023.3269219
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153796888&doi=10.1109%2fTMM.2023.3269219&partnerID=40&md5=8e8e1dd1941dc31dde55a24c5a2a6c32
AB  - Human pose forecasting that aims to predict the body poses happening in the future is an important task in computer vision. However, long-term pose forecasting is particularly challenging because modeling long-range dependencies across the spatial-temporal level is hard for joint-based representation. Another challenge is uncertainty prediction since the future prediction is not a deterministic process. In this article, we present a novel Bayesian Spatial-Temporal Graph Transformer (BSTG-Trans) for predicting accurate, diverse, and uncertain future poses. First, we apply a spatial-temporal graph transformer as an encoder and a temporal-spatial graph transformer as a decoder for modeling the long-range spatial-temporal dependencies across pose joints to generate the long-term future body poses. Furthermore, we propose a Bayesian sampling module for uncertainty quantization of diverse future poses. Finally, a novel uncertainty estimation metric, namely Uncertainty Absolute Error is introduced for measuring both the accuracy and uncertainty of each predicted future pose. We achieve state-of-the-art performance against other baselines on Human3.6 M and HumanEva-I in terms of accuracy, diversity, and uncertainty for long-term pose forecasting. Moreover, our comprehensive ablation studies demonstrate the effectiveness and generalization of each module proposed in our BSTG-Trans.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Tang, Y.
AU  - Xiao, Y.
AU  - Zhou, J.T.
AU  - Fang, Z.
AU  - Yang, F.
TI  - GREnet: Gradually REcurrent Network With Curriculum Learning for 2-D Medical Image Segmentation
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 7
SP  - 10018
EP  - 10032
DO  - 10.1109/TNNLS.2023.3238381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148420817&doi=10.1109%2fTNNLS.2023.3238381&partnerID=40&md5=8665492551e9c35dd05f1c85ef76ce5e
AB  - Medical image segmentation is a vital stage in medical image analysis. Numerous deep-learning methods are booming to improve the performance of 2-D medical image segmentation, owing to the fast growth of the convolutional neural network. Generally, the manually defined ground truth is utilized directly to supervise models in the training phase. However, direct supervision of the ground truth often results in ambiguity and distractors as complex challenges appear simultaneously. To alleviate this issue, we propose a gradually recurrent network with curriculum learning, which is supervised by gradual information of the ground truth. The whole model is composed of two independent networks. One is the segmentation network denoted as GREnet, which formulates 2-D medical image segmentation as a temporal task supervised by pixel-level gradual curricula in the training phase. The other is a curriculum-mining network. To a certain degree, the curriculum-mining network provides curricula with an increasing difficulty in the ground truth of the training set by progressively uncovering hard-to-segmentation pixels via a data-driven manner. Given that segmentation is a pixel-level dense-prediction challenge, to the best of our knowledge, this is the first work to function 2-D medical image segmentation as a temporal task with pixel-level curriculum learning. In GREnet, the naive UNet is adopted as the backbone, while ConvLSTM is used to establish the temporal link between gradual curricula. In the curriculum-mining network, UNet++ supplemented by transformer is designed to deliver curricula through the outputs of the modified UNet++ at different layers. Experimental results have demonstrated the effectiveness of GREnet on seven datasets, i.e., three lesion segmentation datasets in dermoscopic images, an optic disc and cup segmentation dataset and a blood vessel segmentation dataset in retinal images, a breast lesion segmentation dataset in ultrasound images, and a lung segmentation dataset in computed tomography (CT).  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sui, D.
AU  - Zeng, X.
AU  - Chen, Y.
AU  - Liu, K.
AU  - Zhao, J.
TI  - Joint Entity and Relation Extraction With Set Prediction Networks
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 9
SP  - 12784
EP  - 12795
DO  - 10.1109/TNNLS.2023.3264735
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153534232&doi=10.1109%2fTNNLS.2023.3264735&partnerID=40&md5=ee9ed986b97202f94490f646a0bf40c2
AB  - Joint entity and relation extraction is an important task in natural language processing, which aims to extract all relational triples mentioned in a given sentence. In essence, the relational triples mentioned in a sentence are in the form of a set, which has no intrinsic order between elements and exhibits the permutation invariant feature. However, previous seq2seq-based models require sorting the set of relational triples into a sequence beforehand with some heuristic global rules, which destroys the natural set structure. In order to break this bottleneck, we treat joint entity and relation extraction as a direct set prediction problem, so that the extraction model is not burdened with predicting the order of multiple triples. To solve this set prediction problem, we propose networks featured by transformers with non-autoregressive parallel decoding. In contrast to autoregressive approaches that generate triples one by one in a specific order, the proposed networks are able to directly output the final set of relational triples in one shot. Furthermore, we also design a set-based loss that forces unique predictions through bipartite matching. Compared with cross-entropy loss that highly penalizes small shifts in triple order, the proposed bipartite matching loss is invariant to any permutation of predictions; thus, it can provide the proposed networks with a more accurate training signal by ignoring triple order and focusing on relation types and entities. Various experiments on two benchmark datasets demonstrate that our proposed model significantly outperforms the current state-of-the-art (SoTA) models. Training code and trained models are now publicly available at https://github.com/DianboWork/SPN4RE. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 62
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, S.
AU  - Li, F.
AU  - Li, J.
AU  - Li, H.
AU  - Zhang, B.
AU  - Tao, D.
AU  - Gao, X.
TI  - Logical Relation Inference and Multiview Information Interaction for Domain Adaptation Person Re-Identification
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 10
SP  - 14770
EP  - 14782
DO  - 10.1109/TNNLS.2023.3281504
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162673409&doi=10.1109%2fTNNLS.2023.3281504&partnerID=40&md5=f088101290330176bc33e013c9645b2b
AB  - Domain adaptation person re-identification (Re-ID) is a challenging task, which aims to transfer the knowledge learned from the labeled source domain to the unlabeled target domain. Recently, some clustering-based domain adaptation Re-ID methods have achieved great success. However, these methods ignore the inferior influence on pseudo-label prediction due to the different camera styles. The reliability of the pseudo-label plays a key role in domain adaptation Re-ID, while the different camera styles bring great challenges for pseudo-label prediction. To this end, a novel method is proposed, which bridges the gap of different cameras and extracts more discriminative features from an image. Specifically, an intra-to-intermechanism is introduced, in which samples from their own cameras are first grouped and then aligned at the class level across different cameras followed by our logical relation inference (LRI). Thanks to these strategies, the logical relationship between simple classes and hard classes is justified, preventing sample loss caused by discarding the hard samples. Furthermore, we also present a multiview information interaction (MvII) module that takes features of different images from the same pedestrian as patch tokens, obtaining the global consistency of a pedestrian that contributes to the discriminative feature extraction. Unlike the existing clustering-based methods, our method employs a two-stage framework that generates reliable pseudo-labels from the views of the intracamera and intercamera, respectively, to differentiate the camera styles, subsequently increasing its robustness. Extensive experiments on several benchmark datasets show that the proposed method outperforms a wide range of state-of-the-art methods. The source code has been released at https://github.com/lhf12278/LRIMV.  © 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Djeddi, W.E.
AU  - Hermi, K.
AU  - Ben Yahia, S.
AU  - Diallo, G.
TI  - Advancing drug–target interaction prediction: a comprehensive graph-based approach integrating knowledge graph embedding and ProtBert pretraining
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 488
DO  - 10.1186/s12859-023-05593-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180134225&doi=10.1186%2fs12859-023-05593-6&partnerID=40&md5=b7977fde8c2b245bd08ba788e4b3619c
AB  - Background: The pharmaceutical field faces a significant challenge in validating drug target interactions (DTIs) due to the time and cost involved, leading to only a fraction being experimentally verified. To expedite drug discovery, accurate computational methods are essential for predicting potential interactions. Recently, machine learning techniques, particularly graph-based methods, have gained prominence. These methods utilize networks of drugs and targets, employing knowledge graph embedding (KGE) to represent structured information from knowledge graphs in a continuous vector space. This phenomenon highlights the growing inclination to utilize graph topologies as a means to improve the precision of predicting DTIs, hence addressing the pressing requirement for effective computational methodologies in the field of drug discovery. Results: The present study presents a novel approach called DTIOG for the prediction of DTIs. The methodology employed in this study involves the utilization of a KGE strategy, together with the incorporation of contextual information obtained from protein sequences. More specifically, the study makes use of Protein Bidirectional Encoder Representations from Transformers (ProtBERT) for this purpose. DTIOG utilizes a two-step process to compute embedding vectors using KGE techniques. Additionally, it employs ProtBERT to determine target–target similarity. Different similarity measures, such as Cosine similarity or Euclidean distance, are utilized in the prediction procedure. In addition to the contextual embedding, the proposed unique approach incorporates local representations obtained from the Simplified Molecular Input Line Entry Specification (SMILES) of drugs and the amino acid sequences of protein targets. Conclusions: The effectiveness of the proposed approach was assessed through extensive experimentation on datasets pertaining to Enzymes, Ion Channels, and G-protein-coupled Receptors. The remarkable efficacy of DTIOG was showcased through the utilization of diverse similarity measures in order to calculate the similarities between drugs and targets. The combination of these factors, along with the incorporation of various classifiers, enabled the model to outperform existing algorithms in its ability to predict DTIs. The consistent observation of this advantage across all datasets underlines the robustness and accuracy of DTIOG in the domain of DTIs. Additionally, our case study suggests that the DTIOG can serve as a valuable tool for discovering new DTIs. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Djeddi2023Advancing
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Mitra, A.
AU  - Liu, W.
AU  - Berlowitz, D.
AU  - Yu, H.
TI  - TransformEHR: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 7857
DO  - 10.1038/s41467-023-43715-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178204154&doi=10.1038%2fs41467-023-43715-z&partnerID=40&md5=16a8050438ffcdf3eec019f12e54028e
AB  - Deep learning transformer-based models using longitudinal electronic health records (EHRs) have shown a great success in prediction of clinical diseases or outcomes. Pretraining on a large dataset can help such models map the input space better and boost their performance on relevant tasks through finetuning with limited data. In this study, we present TransformEHR, a generative encoder-decoder model with transformer that is pretrained using a new pretraining objective—predicting all diseases and outcomes of a patient at a future visit from previous visits. TransformEHR’s encoder-decoder framework, paired with the novel pretraining objective, helps it achieve the new state-of-the-art performance on multiple clinical prediction tasks. Comparing with the previous model, TransformEHR improves area under the precision–recall curve by 2% (p < 0.001) for pancreatic cancer onset and by 24% (p = 0.007) for intentional self-harm in patients with post-traumatic stress disorder. The high performance in predicting intentional self-harm shows the potential of TransformEHR in building effective clinical intervention systems. TransformEHR is also generalizable and can be easily finetuned for clinical prediction tasks with limited data. © 2023, This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shin, I.
AU  - Kang, K.
AU  - Kim, J.
AU  - Sel, S.
AU  - Choi, J.
AU  - Lee, J.-W.
AU  - Kang, H.Y.
AU  - Song, G.
TI  - AptaTrans: a deep neural network for predicting aptamer-protein interaction using pretrained encoders
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 447
DO  - 10.1186/s12859-023-05577-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177891829&doi=10.1186%2fs12859-023-05577-6&partnerID=40&md5=b5b9b6f162d52cd59ccd6722cad8f2fc
AB  - Background: Aptamers, which are biomaterials comprised of single-stranded DNA/RNA that form tertiary structures, have significant potential as next-generation materials, particularly for drug discovery. The systematic evolution of ligands by exponential enrichment (SELEX) method is a critical in vitro technique employed to identify aptamers that bind specifically to target proteins. While advanced SELEX-based methods such as Cell- and HT-SELEX are available, they often encounter issues such as extended time consumption and suboptimal accuracy. Several In silico aptamer discovery methods have been proposed to address these challenges. These methods are specifically designed to predict aptamer-protein interaction (API) using benchmark datasets. However, these methods often fail to consider the physicochemical interactions between aptamers and proteins within tertiary structures. Results: In this study, we propose AptaTrans, a pipeline for predicting API using deep learning techniques. AptaTrans uses transformer-based encoders to handle aptamer and protein sequences at the monomer level. Furthermore, pretrained encoders are utilized for the structural representation. After validation with a benchmark dataset, AptaTrans has been integrated into a comprehensive toolset. This pipeline synergistically combines with Apta-MCTS, a generative algorithm for recommending aptamer candidates. Conclusion: The results show that AptaTrans outperforms existing models for predicting API, and the efficacy of the AptaTrans pipeline has been confirmed through various experimental tools. We expect AptaTrans will enhance the cost-effectiveness and efficiency of SELEX in drug discovery. The source code and benchmark dataset for AptaTrans are available at https://github.com/pnumlb/AptaTrans . © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Shin2023AptaTrans
ER  -

TY  - JOUR
AU  - Kumar, A.
AU  - Grüning, B.
AU  - Backofen, R.
TI  - Transformer-based tool recommendation system in Galaxy
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 446
DO  - 10.1186/s12859-023-05573-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178469524&doi=10.1186%2fs12859-023-05573-w&partnerID=40&md5=d97fa9b430fdce61e59916f5b0edd6d1
AB  - Background: Galaxy is a web-based open-source platform for scientific analyses. Researchers use thousands of high-quality tools and workflows for their respective analyses in Galaxy. Tool recommender system predicts a collection of tools that can be used to extend an analysis. In this work, a tool recommender system is developed by training a transformer on workflows available on Galaxy Europe and its performance is compared to other neural networks such as recurrent, convolutional and dense neural networks. Results: The transformer neural network achieves two times faster convergence, has significantly lower model usage (model reconstruction and prediction) time and shows a better generalisation that goes beyond training workflows than the older tool recommender system created using RNN in Galaxy. In addition, the transformer also outperforms CNN and DNN on several key indicators. It achieves a faster convergence time, lower model usage time, and higher quality tool recommendations than CNN. Compared to DNN, it converges faster to a higher precision@k metric (approximately 0.98 by transformer compared to approximately 0.9 by DNN) and shows higher quality tool recommendations. Conclusion: Our work shows a novel usage of transformers to recommend tools for extending scientific workflows. A more robust tool recommendation model, created using a transformer, having significantly lower usage time than RNN and CNN, higher precision@k than DNN, and higher quality tool recommendations than all three neural networks, will benefit researchers in creating scientifically significant workflows and exploratory data analysis in Galaxy. Additionally, the ability to train faster than all three neural networks imparts more scalability for training on larger datasets consisting of millions of tool sequences. Open-source scripts to create the recommendation model are available under MIT licence at https://github.com/anuprulez/galaxy_tool_recommendation_transformers. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Kumar2023Transformer-based
ER  -

TY  - JOUR
AU  - Ming, Z.
AU  - Chen, X.
AU  - Wang, S.
AU  - Liu, H.
AU  - Yuan, Z.
AU  - Wu, M.
AU  - Xia, H.
TI  - HostNet: improved sequence representation in deep neural networks for virus-host prediction
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 455
DO  - 10.1186/s12859-023-05582-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178236489&doi=10.1186%2fs12859-023-05582-9&partnerID=40&md5=9c1bffb2f34773c6f036eef5119e1576
AB  - Background: The escalation of viruses over the past decade has highlighted the need to determine their respective hosts, particularly for emerging ones that pose a potential menace to the welfare of both human and animal life. Yet, the traditional means of ascertaining the host range of viruses, which involves field surveillance and laboratory experiments, is a laborious and demanding undertaking. A computational tool with the capability to reliably predict host ranges for novel viruses can provide timely responses in the prevention and control of emerging infectious diseases. The intricate nature of viral-host prediction involves issues such as data imbalance and deficiency. Therefore, developing highly accurate computational tools capable of predicting virus-host associations is a challenging and pressing demand. Results: To overcome the challenges of virus-host prediction, we present HostNet, a deep learning framework that utilizes a Transformer-CNN-BiGRU architecture and two enhanced sequence representation modules. The first module, k-mer to vector, pre-trains a background vector representation of k-mers from a broad range of virus sequences to address the issue of data deficiency. The second module, an adaptive sliding window, truncates virus sequences of various lengths to create a uniform number of informative and distinct samples for each sequence to address the issue of data imbalance. We assess HostNet's performance on a benchmark dataset of “Rabies lyssavirus” and an in-house dataset of “Flavivirus”. Our results show that HostNet surpasses the state-of-the-art deep learning-based method in host-prediction accuracies and F1 score. The enhanced sequence representation modules, significantly improve HostNet's training generalization, performance in challenging classes, and stability. Conclusion: HostNet is a promising framework for predicting virus hosts from genomic sequences, addressing challenges posed by sparse and varying-length virus sequence data. Our results demonstrate its potential as a valuable tool for virus-host prediction in various biological contexts. Virus-host prediction based on genomic sequences using deep neural networks is a promising approach to identifying their potential hosts accurately and efficiently, with significant impacts on public health, disease prevention, and vaccine development. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Ming2023HostNet
ER  -

TY  - JOUR
AU  - Kim, G.B.
AU  - Kim, J.Y.
AU  - Lee, J.A.
AU  - Norsigian, C.J.
AU  - Palsson, B.O.
AU  - Lee, S.Y.
TI  - Functional annotation of enzyme-encoding genes using deep learning with transformer layers
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 7370
DO  - 10.1038/s41467-023-43216-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176391236&doi=10.1038%2fs41467-023-43216-z&partnerID=40&md5=b5f1fd1dc508d403f493bc300163817b
AB  - Functional annotation of open reading frames in microbial genomes remains substantially incomplete. Enzymes constitute the most prevalent functional gene class in microbial genomes and can be described by their specific catalytic functions using the Enzyme Commission (EC) number. Consequently, the ability to predict EC numbers could substantially reduce the number of un-annotated genes. Here we present a deep learning model, DeepECtransformer, which utilizes transformer layers as a neural network architecture to predict EC numbers. Using the extensively studied Escherichia coli K-12 MG1655 genome, DeepECtransformer predicted EC numbers for 464 un-annotated genes. We experimentally validated the enzymatic activities predicted for three proteins (YgfF, YciO, and YjdM). Further examination of the neural network’s reasoning process revealed that the trained neural network relies on functional motifs of enzymes to predict EC numbers. Thus, DeepECtransformer is a method that facilitates the functional annotation of uncharacterized genes. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Fang, Y.
AU  - Jiang, Y.
AU  - Wei, L.
AU  - Ma, Q.
AU  - Ren, Z.
AU  - Yuan, Q.
AU  - Wei, D.-Q.
TI  - DeepProSite: structure-aware protein binding site prediction using ESMFold and pretrained language model
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 12
C7  - btad718
DO  - 10.1093/bioinformatics/btad718
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180003008&doi=10.1093%2fbioinformatics%2fbtad718&partnerID=40&md5=21113b06e6497b46bdef0f367648a433
AB  - Motivation: Identifying the functional sites of a protein, such as the binding sites of proteins, peptides, or other biological components, is crucial for understanding related biological processes and drug design. However, existing sequence-based methods have limited predictive accuracy, as they only consider sequence-adjacent contextual features and lack structural information. Results: In this study, DeepProSite is presented as a new framework for identifying protein binding site that utilizes protein structure and sequence information. DeepProSite first generates protein structures from ESMFold and sequence representations from pretrained language models. It then uses Graph Transformer and formulates binding site predictions as graph node classifications. In predicting protein-protein/peptide binding sites, DeepProSite outperforms state-of-the-art sequence- and structure-based methods on most metrics. Moreover, DeepProSite maintains its performance when predicting unbound structures, in contrast to competing structure-based prediction methods. DeepProSite is also extended to the prediction of binding sites for nucleic acids and other ligands, verifying its generalization capability. Finally, an online server for predicting multiple types of residue is established as the implementation of the proposed DeepProSite. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Xu, Z.
AU  - Li, Q.
AU  - Marchionni, L.
AU  - Wang, K.
TI  - PhenoSV: interpretable phenotype-aware model for the prioritization of genes affected by structural variants
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 7805
DO  - 10.1038/s41467-023-43651-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178059229&doi=10.1038%2fs41467-023-43651-y&partnerID=40&md5=59cda437744269742de71049ba222427
AB  - Structural variants (SVs) represent a major source of genetic variation associated with phenotypic diversity and disease susceptibility. While long-read sequencing can discover over 20,000 SVs per human genome, interpreting their functional consequences remains challenging. Existing methods for identifying disease-related SVs focus on deletion/duplication only and cannot prioritize individual genes affected by SVs, especially for noncoding SVs. Here, we introduce PhenoSV, a phenotype-aware machine-learning model that interprets all major types of SVs and genes affected. PhenoSV segments and annotates SVs with diverse genomic features and employs a transformer-based architecture to predict their impacts under a multiple-instance learning framework. With phenotype information, PhenoSV further utilizes gene-phenotype associations to prioritize phenotype-related SVs. Evaluation on extensive human SV datasets covering all SV types demonstrates PhenoSV’s superior performance over competing methods. Applications in diseases suggest that PhenoSV can determine disease-related genes from SVs. A web server and a command-line tool for PhenoSV are available at https://phenosv.wglab.org . © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Suvarna, M.
AU  - Vaucher, A.C.
AU  - Mitchell, S.
AU  - Laino, T.
AU  - Pérez-Ramírez, J.
TI  - Language models and protocol standardization guidelines for accelerating synthesis planning in heterogeneous catalysis
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 7964
DO  - 10.1038/s41467-023-43836-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178371290&doi=10.1038%2fs41467-023-43836-5&partnerID=40&md5=3c66581ab96e7c04d9982c60207cc177
AB  - Synthesis protocol exploration is paramount in catalyst discovery, yet keeping pace with rapid literature advances is increasingly time intensive. Automated synthesis protocol analysis is attractive for swiftly identifying opportunities and informing predictive models, however such applications in heterogeneous catalysis remain limited. In this proof-of-concept, we introduce a transformer model for this task, exemplified using single-atom heterogeneous catalysts (SACs), a rapidly expanding catalyst family. Our model adeptly converts SAC protocols into action sequences, and we use this output to facilitate statistical inference of their synthesis trends and applications, potentially expediting literature review and analysis. We demonstrate the model’s adaptability across distinct heterogeneous catalyst families, underscoring its versatility. Finally, our study highlights a critical issue: the lack of standardization in reporting protocols hampers machine-reading capabilities. Embracing digital advances in catalysis demands a shift in data reporting norms, and to this end, we offer guidelines for writing protocols, significantly improving machine-readability. We release our model as an open-source web application, inviting a fresh approach to accelerate heterogeneous catalysis synthesis planning. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Feng, C.
AU  - Han, R.
AU  - Wang, Z.
AU  - Ye, L.
AU  - Du, Z.
AU  - Wei, H.
AU  - Zhang, F.
AU  - Peng, Z.
AU  - Yang, J.
TI  - trRosettaRNA: automated prediction of RNA 3D structure with transformer network
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 7266
DO  - 10.1038/s41467-023-42528-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176043592&doi=10.1038%2fs41467-023-42528-4&partnerID=40&md5=ea9f249e345f30e045518c8ec74e59bd
AB  - RNA 3D structure prediction is a long-standing challenge. Inspired by the recent breakthrough in protein structure prediction, we developed trRosettaRNA, an automated deep learning-based approach to RNA 3D structure prediction. The trRosettaRNA pipeline comprises two major steps: 1D and 2D geometries prediction by a transformer network; and 3D structure folding by energy minimization. Benchmark tests suggest that trRosettaRNA outperforms traditional automated methods. In the blind tests of the 15th Critical Assessment of Structure Prediction (CASP15) and the RNA-Puzzles experiments, the automated trRosettaRNA predictions for the natural RNAs are competitive with the top human predictions. trRosettaRNA also outperforms other deep learning-based methods in CASP15 when measured by the Z-score of the Root-Mean-Square Deviation. Nevertheless, it remains challenging to predict accurate structures for synthetic RNAs with an automated approach. We hope this work could be a good start toward solving the hard problem of RNA structure prediction with deep learning. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 48
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Li, P.
TI  - GPDRP: a multimodal framework for drug response prediction with graph transformer
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 484
DO  - 10.1186/s12859-023-05618-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179964308&doi=10.1186%2fs12859-023-05618-0&partnerID=40&md5=ac3759e71fad05ab7f26d88a8033aa95
AB  - Background: In the field of computational personalized medicine, drug response prediction (DRP) is a critical issue. However, existing studies often characterize drugs as strings, a representation that does not align with the natural description of molecules. Additionally, they ignore gene pathway-specific combinatorial implication. Results: In this study, we propose drug Graph and gene Pathway based Drug response prediction method (GPDRP), a new multimodal deep learning model for predicting drug responses based on drug molecular graphs and gene pathway activity. In GPDRP, drugs are represented by molecular graphs, while cell lines are described by gene pathway activity scores. The model separately learns these two types of data using Graph Neural Networks (GNN) with Graph Transformers and deep neural networks. Predictions are subsequently made through fully connected layers. Conclusions: Our results indicate that Graph Transformer-based model delivers superior performance. We apply GPDRP on hundreds of cancer cell lines’ bulk RNA-sequencing data, and it outperforms some recently published models. Furthermore, the generalizability and applicability of GPDRP are demonstrated through its predictions on unknown drug-cell line pairs and xenografts. This underscores the interpretability achieved by incorporating gene pathways. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Yang2023GPDRP
ER  -

TY  - JOUR
AU  - Hartman, V.C.
AU  - Bapat, S.S.
AU  - Weiner, M.G.
AU  - Navi, B.B.
AU  - Sholle, E.T.
AU  - Campion, T.R.
TI  - A method to automate the discharge summary hospital course for neurology patients
PY  - 2023
T2  - Journal of the American Medical Informatics Association
VL  - 30
IS  - 12
SP  - 1995
EP  - 2003
DO  - 10.1093/jamia/ocad177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177102851&doi=10.1093%2fjamia%2focad177&partnerID=40&md5=8a25634f1518f101ee9e10763ff96be9
AB  - Objective: Generation of automated clinical notes has been posited as a strategy to mitigate physician burnout. In particular, an automated narrative summary of a patient’s hospital stay could supplement the hospital course section of the discharge summary that inpatient physicians document in electronic health record (EHR) systems. In the current study, we developed and evaluated an automated method for summarizing the hospital course section using encoder-decoder sequence-to-sequence transformer models. Materials and Methods: We fine-tuned BERT and BART models and optimized for factuality through constraining beam search, which we trained and tested using EHR data from patients admitted to the neurology unit of an academic medical center. Results: The approach demonstrated good ROUGE scores with an R-2 of 13.76. In a blind evaluation, 2 board-certified physicians rated 62% of the automated summaries as meeting the standard of care, which suggests the method may be useful clinically. Discussion and conclusion: To our knowledge, this study is among the first to demonstrate an automated method for generating a discharge summary hospital course that approaches a quality level of what a physician would write. © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Zhang, R.
AU  - Min, Y.
AU  - Ma, D.
AU  - Zhao, D.
AU  - Zeng, J.
TI  - A knowledge-guided pre-training framework for improving molecular representation learning
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 7568
DO  - 10.1038/s41467-023-43214-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177445546&doi=10.1038%2fs41467-023-43214-1&partnerID=40&md5=fde77a37b4ce661dd605c82664ff986a
AB  - Learning effective molecular feature representation to facilitate molecular property prediction is of great significance for drug discovery. Recently, there has been a surge of interest in pre-training graph neural networks (GNNs) via self-supervised learning techniques to overcome the challenge of data scarcity in molecular property prediction. However, current self-supervised learning-based methods suffer from two main obstacles: the lack of a well-defined self-supervised learning strategy and the limited capacity of GNNs. Here, we propose Knowledge-guided Pre-training of Graph Transformer (KPGT), a self-supervised learning framework to alleviate the aforementioned issues and provide generalizable and robust molecular representations. The KPGT framework integrates a graph transformer specifically designed for molecular graphs and a knowledge-guided pre-training strategy, to fully capture both structural and semantic knowledge of molecules. Through extensive computational tests on 63 datasets, KPGT exhibits superior performance in predicting molecular properties across various domains. Moreover, the practical applicability of KPGT in drug discovery has been validated by identifying potential inhibitors of two antitumor targets: hematopoietic progenitor kinase 1 (HPK1) and fibroblast growth factor receptor 1 (FGFR1). Overall, KPGT can provide a powerful and useful tool for advancing the artificial intelligence (AI)-aided drug discovery process. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Pang, C.
AU  - Wang, Y.
AU  - Jin, J.
AU  - Zhang, J.
AU  - Zeng, X.
AU  - Su, R.
AU  - Zou, Q.
AU  - Wei, L.
TI  - Retrosynthesis prediction with an interpretable deep-learning framework based on molecular assembly tasks
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 6155
DO  - 10.1038/s41467-023-41698-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173059901&doi=10.1038%2fs41467-023-41698-5&partnerID=40&md5=c91ae3328d75db0b6ab2c2ec0d72f495
AB  - Automating retrosynthesis with artificial intelligence expedites organic chemistry research in digital laboratories. However, most existing deep-learning approaches are hard to explain, like a “black box” with few insights. Here, we propose RetroExplainer, formulizing the retrosynthesis task into a molecular assembly process, containing several retrosynthetic actions guided by deep learning. To guarantee a robust performance of our model, we propose three units: a multi-sense and multi-scale Graph Transformer, structure-aware contrastive learning, and dynamic adaptive multi-task learning. The results on 12 large-scale benchmark datasets demonstrate the effectiveness of RetroExplainer, which outperforms the state-of-the-art single-step retrosynthesis approaches. In addition, the molecular assembly process renders our model with good interpretability, allowing for transparent decision-making and quantitative attribution. When extended to multi-step retrosynthesis planning, RetroExplainer has identified 101 pathways, in which 86.9% of the single reactions correspond to those already reported in the literature. As a result, RetroExplainer is expected to offer valuable insights for reliable, high-throughput, and high-quality organic synthesis in drug development. © 2023, Springer Nature Limited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Nadler, E.O.
AU  - Darragh-Ford, E.
AU  - Desikan, B.S.
AU  - Conaway, C.
AU  - Chu, M.
AU  - Hull, T.
AU  - Guilbeault, D.
TI  - Divergences in color perception between deep neural networks and humans
PY  - 2023
T2  - Cognition
VL  - 241
C7  - 105621
DO  - 10.1016/j.cognition.2023.105621
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171358370&doi=10.1016%2fj.cognition.2023.105621&partnerID=40&md5=d347de6d59bee31c5bcc677ad893aeab
AB  - Deep neural networks (DNNs) are increasingly proposed as models of human vision, bolstered by their impressive performance on image classification and object recognition tasks. Yet, the extent to which DNNs capture fundamental aspects of human vision such as color perception remains unclear. Here, we develop novel experiments for evaluating the perceptual coherence of color embeddings in DNNs, and we assess how well these algorithms predict human color similarity judgments collected via an online survey. We find that state-of-the-art DNN architectures — including convolutional neural networks and vision transformers — provide color similarity judgments that strikingly diverge from human color judgments of (i) images with controlled color properties, (ii) images generated from online searches, and (iii) real-world images from the canonical CIFAR-10 dataset. We compare DNN performance against an interpretable and cognitively plausible model of color perception based on wavelet decomposition, inspired by foundational theories in computational neuroscience. While one deep learning model — a convolutional DNN trained on a style transfer task — captures some aspects of human color perception, our wavelet algorithm provides more coherent color embeddings that better predict human color judgments compared to all DNNs we examine. These results hold when altering the high-level visual task used to train similar DNN architectures (e.g., image classification versus image segmentation), as well as when examining the color embeddings of different layers in a given DNN architecture. These findings break new ground in the effort to analyze the perceptual representations of machine learning algorithms and to improve their ability to serve as cognitively plausible models of human vision. Implications for machine learning, human perception, and embodied cognition are discussed. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - AJG:4; zdy:4; 
LB  - Nadler2023Divergences
ER  -

TY  - JOUR
AU  - Liang, C.
AU  - Rouzhahong, Y.
AU  - Ye, C.
AU  - Li, C.
AU  - Wang, B.
AU  - Li, H.
TI  - Material symmetry recognition and property prediction accomplished by crystal capsule representation
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 5198
DO  - 10.1038/s41467-023-40756-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168753335&doi=10.1038%2fs41467-023-40756-2&partnerID=40&md5=250a17b66624d86c6751b1042135fe6d
AB  - Learning the global crystal symmetry and interpreting the equivariant information is crucial for accurately predicting material properties, yet remains to be fully accomplished by existing algorithms based on convolution networks. To overcome this challenge, here we develop a machine learning (ML) model, named symmetry-enhanced equivariance network (SEN), to build material representation with joint structure-chemical patterns, to encode important clusters embedded in the crystal structure, and to learn pattern equivariance in different scales via capsule transformers. Quantitative analyses of the intermediate matrices demonstrate that the intrinsic crystal symmetries and interactions between clusters have been exactly perceived by the SEN model and critically affect the prediction performances by reducing effective feature space. The mean absolute errors (MAEs) of 0.181 eV and 0.0161 eV/atom are obtained for predicting bandgap and formation energy in the MatBench dataset. The general and interpretable SEN model reveals the potential to design ML models by implicitly encoding feature relationship based on physical mechanisms. © 2023, Springer Nature Limited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Lin, W.
AU  - Ma, C.
AU  - Li, M.
AU  - Sun, Z.
AU  - Sun, L.
AU  - Huo, Q.
TI  - Robust table structure recognition with dynamic queries enhanced detection transformer
PY  - 2023
T2  - Pattern Recognition
VL  - 144
C7  - 109817
DO  - 10.1016/j.patcog.2023.109817
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165451556&doi=10.1016%2fj.patcog.2023.109817&partnerID=40&md5=a57221aa8e92644e6aa24bb2bd32f107
AB  - We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognize the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage dynamic queries enhanced DETR based separation line regression approach, named DQ-DETR, to predict separation lines from table images directly. Compared to Vallina DETR, we propose three improvements in DQ-DETR to make the two-stage DETR framework work efficiently and effectively for the separation line prediction task: 1) A new query design, named Dynamic Query, to decouple single line query into separable point queries which could intuitively improve the localization accuracy for regression tasks; 2) A dynamic queries based progressive line regression approach to progressively regressing points on the line which further enhances localization accuracy for distorted tables; 3) A prior-enhanced matching strategy to solve the slow convergence issue of DETR. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet, WTW, FinTabNet, and cTDaR TrackB2-Modern. Furthermore, we have validated the robustness and high localization accuracy of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lüders, C.M.
AU  - Pietz, T.
AU  - Maalej, W.
TI  - On understanding and predicting issue links
PY  - 2023
T2  - Requirements Engineering
VL  - 28
IS  - 4
SP  - 541
EP  - 565
DO  - 10.1007/s00766-023-00406-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171731358&doi=10.1007%2fs00766-023-00406-x&partnerID=40&md5=0675aa33fbe1aed9509de36aa9d90faa
AB  - Stakeholders in software projects use issue trackers like JIRA or Bugzilla to capture and manage issues, including requirements, feature requests, and bugs. To ease issue navigation and structure project knowledge, stakeholders manually connect issues via links of certain types that reflect different dependencies, such as Epic-, Block-, Duplicate-, or Relate- links. Based on a large dataset of 16 JIRA repositories, we study the commonalities and differences in linking practices and link types across the repositories. We then investigate how state-of-the-art machine learning models can predict common link types. We observed significant differences across the repositories and link types, depending on how they are used and by whom. Additionally, we observed several inconsistencies, e.g., in how Duplicate links are used. We found that a transformer model trained on titles and descriptions of linked issues significantly outperforms other optimized models, achieving an encouraging average macro F1-score of 0.64 for predicting nine popular link types across all repositories (weighted F1-score of 0.73). For the specific Subtask- and Epic- links, the model achieves top F1-scores of 0.89 and 0.97, respectively. If we restrict the task to predict the mere existence of links, the average macro F1-score goes up to 0.95. In general, the shorter issue text, possibly indicating precise issues, seems to improve the prediction accuracy with a strong negative correlation of - 0.73. We found that Relate-links often get confused with the other links, which suggests that they are likely used as default links in unclear cases. Our findings particularly on the quality and heterogeinity of issue link data have implications for researching and applying issue link prediction in practice. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Tan, G.
AU  - Zhong, R.
AU  - Li, Y.
AU  - Gou, C.
TI  - PIT: Progressive Interaction Transformer for Pedestrian Crossing Intention Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 12
SP  - 14213
EP  - 14225
DO  - 10.1109/TITS.2023.3309309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171738492&doi=10.1109%2fTITS.2023.3309309&partnerID=40&md5=09e675fd943691c4a89ff64a2d26a4bf
AB  - For autonomous driving, one of the major challenges is to predict pedestrian crossing intention in ego-view. Pedestrian intention depends not only on their intrinsic goals but also on the stimulation of surrounding traffic elements. Considering the influence of other traffic elements on pedestrian intention, recent work introduced more traffic element information into the model to successfully improve performance. However, it is still difficult to effectively capture and fully exploit the potential dynamic spatio-temporal interactions among the target pedestrian and its surrounding traffic elements for accurate reasoning. In this work, inspired by neuroscience that human drivers tend to make continuous sensory-motor driving decisions by progressive visual stimulation, we propose a model termed Progressive Interaction Transformer (PIT) for pedestrian crossing intention prediction. Local pedestrian, global environment, and ego-vehicle motion are considered simultaneously in the proposed PIT. In particular, the temporal fusion block and self-attention mechanism are introduced to jointly and progressively model the dynamic spatio-temporal interactions among the three parties, allowing it to capture richer information and make prediction in a similar way to human drivers. Experimental results demonstrate that PIT achieves higher performance compared with other state-of-the-arts and preserves real-time inference. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; FMS:B; 
LB  - Zhou2023PIT
ER  -

TY  - JOUR
AU  - Park, N.H.
AU  - Manica, M.
AU  - Born, J.
AU  - Hedrick, J.L.
AU  - Erdmann, T.
AU  - Zubarev, D.Y.
AU  - Adell-Mill, N.
AU  - Arrechea, P.L.
TI  - Artificial intelligence driven design of catalysts and materials for ring opening polymerization using a domain-specific language
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 3686
DO  - 10.1038/s41467-023-39396-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163091135&doi=10.1038%2fs41467-023-39396-3&partnerID=40&md5=18e7b405bebe94d4553baad030f1bb0e
AB  - Advances in machine learning (ML) and automated experimentation are poised to vastly accelerate research in polymer science. Data representation is a critical aspect for enabling ML integration in research workflows, yet many data models impose significant rigidity making it difficult to accommodate a broad array of experiment and data types found in polymer science. This inflexibility presents a significant barrier for researchers to leverage their historical data in ML development. Here we show that a domain specific language, termed Chemical Markdown Language (CMDL), provides flexible, extensible, and consistent representation of disparate experiment types and polymer structures. CMDL enables seamless use of historical experimental data to fine-tune regression transformer (RT) models for generative molecular design tasks. We demonstrate the utility of this approach through the generation and the experimental validation of catalysts and polymers in the context of ring-opening polymerization—although we provide examples of how CMDL can be more broadly applied to other polymer classes. Critically, we show how the CMDL tuned model preserves key functional groups within the polymer structure, allowing for experimental validation. These results reveal the versatility of CMDL and how it facilitates translation of historical data into meaningful predictive and generative models to produce experimentally actionable output. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Correia, A.
AU  - Guimaraes, D.
AU  - Paredes, H.
AU  - Fonseca, B.
AU  - Paulino, D.
AU  - Trigo, L.
AU  - Brazdil, P.
AU  - Schneider, D.
AU  - Grover, A.
AU  - Jameel, S.
TI  - NLP-Crowdsourcing Hybrid Framework for Inter-Researcher Similarity Detection
PY  - 2023
T2  - IEEE Transactions on Human-Machine Systems
VL  - 53
IS  - 6
SP  - 1017
EP  - 1026
DO  - 10.1109/THMS.2023.3319290
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174806105&doi=10.1109%2fTHMS.2023.3319290&partnerID=40&md5=3bf2cfcd3f4f689c2ca32e8e81d20556
AB  - Visualizing and examining the intellectual landscape and evolution of scientific communities to support collaboration is crucial for multiple research purposes. In some cases, measuring similarities and matching patterns between research publication document sets can help to identify people with similar interests for building research collaboration networks and university-industry linkages. The premise of this work is assessing feasibility for resolving ambiguous cases in similarity detection to determine authorship with natural language processing (NLP) techniques so that crowdsourcing is applied only in instances that require human judgment. Using an NLP-crowdsourcing convergence strategy, we can reduce the costs of microtask crowdsourcing while saving time and maintaining disambiguation accuracy over large datasets. This article contributes a next-gen crowd-artificial intelligence framework that used an ensemble of term frequency-inverse document frequency and bidirectional encoder representation from transformers to obtain similarity rankings for pairs of scientific documents. A sequence of content-based similarity tasks was created using a crowd-powered interface for solving disambiguation problems. Our experimental results suggest that an adaptive NLP-crowdsourcing hybrid framework has advantages for inter-researcher similarity detection tasks where fully automatic algorithms provide unsatisfactory results, with the goal of helping researchers discover potential collaborators using data-driven approaches.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bao, H.
AU  - Zhao, J.
AU  - Zhao, X.
AU  - Zhao, C.
AU  - Lu, X.
AU  - Xu, G.
TI  - Prediction of plant secondary metabolic pathways using deep transfer learning
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 348
DO  - 10.1186/s12859-023-05485-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171625257&doi=10.1186%2fs12859-023-05485-9&partnerID=40&md5=eb6ff83b1821c79adacbbc8eb9d104a2
AB  - Background: Plant secondary metabolites are highly valued for their applications in pharmaceuticals, nutrition, flavors, and aesthetics. It is of great importance to elucidate plant secondary metabolic pathways due to their crucial roles in biological processes during plant growth and development. However, understanding plant biosynthesis and degradation pathways remains a challenge due to the lack of sufficient information in current databases. To address this issue, we proposed a transfer learning approach using a pre-trained hybrid deep learning architecture that combines Graph Transformer and convolutional neural network (GTC) to predict plant metabolic pathways. Results: GTC provides comprehensive molecular representation by extracting both structural features from the molecular graph and textual information from the SMILES string. GTC is pre-trained on the KEGG datasets to acquire general features, followed by fine-tuning on plant-derived datasets. Four metrics were chosen for model performance evaluation. The results show that GTC outperforms six other models, including three previously reported machine learning models, on the KEGG dataset. GTC yields an accuracy of 96.75%, precision of 85.14%, recall of 83.03%, and F1_score of 84.06%. Furthermore, an ablation study confirms the indispensability of all the components of the hybrid GTC model. Transfer learning is then employed to leverage the shared knowledge acquired from the KEGG metabolic pathways. As a result, the transferred GTC exhibits outstanding accuracy in predicting plant secondary metabolic pathways with an average accuracy of 98.30% in fivefold cross-validation and 97.82% on the final test. In addition, GTC is employed to classify natural products. It achieves a perfect accuracy score of 100.00% for alkaloids, while the lowest accuracy score of 98.42% for shikimates and phenylpropanoids. Conclusions: The proposed GTC effectively captures molecular features, and achieves high performance in classifying KEGG metabolic pathways and predicting plant secondary metabolic pathways via transfer learning. Furthermore, GTC demonstrates its generalization ability by accurately classifying natural products. A user-friendly executable program has been developed, which only requires the input of the SMILES string of the query compound in a graphical interface. © 2023, BioMed Central Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Bao2023Prediction
ER  -

TY  - JOUR
AU  - Danzi, M.C.
AU  - Dohrn, M.F.
AU  - Fazal, S.
AU  - Beijer, D.
AU  - Rebelo, A.P.
AU  - Cintra, V.
AU  - Züchner, S.
TI  - Deep structured learning for variant prioritization in Mendelian diseases
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 4167
DO  - 10.1038/s41467-023-39306-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164844470&doi=10.1038%2fs41467-023-39306-7&partnerID=40&md5=785e7c3ea550c4af0dbfca00d9aacf28
AB  - Effective computer-aided or automated variant evaluations for monogenic diseases will expedite clinical diagnostic and research efforts of known and novel disease-causing genes. Here we introduce MAVERICK: a Mendelian Approach to Variant Effect pRedICtion built in Keras. MAVERICK is an ensemble of transformer-based neural networks that can classify a wide range of protein-altering single nucleotide variants (SNVs) and indels and assesses whether a variant would be pathogenic in the context of dominant or recessive inheritance. We demonstrate that MAVERICK outperforms all other major programs that assess pathogenicity in a Mendelian context. In a cohort of 644 previously solved patients with Mendelian diseases, MAVERICK ranks the causative pathogenic variant within the top five variants in over 95% of cases. Seventy-six percent of cases were solved by the top-ranked variant. MAVERICK ranks the causative pathogenic variant in hitherto novel disease genes within the first five candidate variants in 70% of cases. MAVERICK has already facilitated the identification of a novel disease gene causing a degenerative motor neuron disease. These results represent a significant step towards automated identification of causal variants in patients with Mendelian diseases. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Marcus, A.
AU  - Bentley, P.
AU  - Rueckert, D.
TI  - Concurrent Ischemic Lesion Age Estimation and Segmentation of CT Brain Using a Transformer-Based Network
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 12
SP  - 3464
EP  - 3473
DO  - 10.1109/TMI.2023.3287361
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162905533&doi=10.1109%2fTMI.2023.3287361&partnerID=40&md5=1dc6e0f2b4b38c2ec1e19267302d866a
AB  - The cornerstone of stroke care is expedient management that varies depending on the time since stroke onset. Consequently, clinical decision making is centered on accurate knowledge of timing and often requires a radiologist to interpret Computed Tomography (CT) of the brain to confirm the occurrence and age of an event. These tasks are particularly challenging due to the subtle expression of acute ischemic lesions and the dynamic nature of their appearance. Automation efforts have not yet applied deep learning to estimate lesion age and treated these two tasks independently, so, have overlooked their inherent complementary relationship. To leverage this, we propose a novel end-to-end multi-task transformer-based network optimized for concurrent segmentation and age estimation of cerebral ischemic lesions. By utilizing gated positional self-attention and CT-specific data augmentation, the proposed method can capture long-range spatial dependencies while maintaining its ability to be trained from scratch under low-data regimes commonly found in medical imaging. Furthermore, to better combine multiple predictions, we incorporate uncertainty by utilizing quantile loss to facilitate estimating a probability density function of lesion age. The effectiveness of our model is then extensively evaluated on a clinical dataset consisting of 776 CT images from two medical centers. Experimental results demonstrate that our method obtains promising performance, with an area under the curve (AUC) of 0.933 for classifying lesion ages ≤ 4.5 hours compared to 0.858 using a conventional approach, and outperforms task-specific state-of-the-art algorithms.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kroll, A.
AU  - Rousset, Y.
AU  - Hu, X.-P.
AU  - Liebrand, N.A.
AU  - Lercher, M.J.
TI  - Turnover number predictions for kinetically uncharacterized enzymes using machine and deep learning
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 4139
DO  - 10.1038/s41467-023-39840-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164542099&doi=10.1038%2fs41467-023-39840-4&partnerID=40&md5=1526926ad9b7f800b9857bccf040640c
AB  - The turnover number k cat, a measure of enzyme efficiency, is central to understanding cellular physiology and resource allocation. As experimental k cat estimates are unavailable for the vast majority of enzymatic reactions, the development of accurate computational prediction methods is highly desirable. However, existing machine learning models are limited to a single, well-studied organism, or they provide inaccurate predictions except for enzymes that are highly similar to proteins in the training set. Here, we present TurNuP, a general and organism-independent model that successfully predicts turnover numbers for natural reactions of wild-type enzymes. We constructed model inputs by representing complete chemical reactions through differential reaction fingerprints and by representing enzymes through a modified and re-trained Transformer Network model for protein sequences. TurNuP outperforms previous models and generalizes well even to enzymes that are not similar to proteins in the training set. Parameterizing metabolic models with TurNuP-predicted k cat values leads to improved proteome allocation predictions. To provide a powerful and convenient tool for the study of molecular biochemistry and physiology, we implemented a TurNuP web server. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yu, X.
AU  - Bai, C.
AU  - Wang, C.
AU  - Yu, D.
AU  - Chen, C.L.P.
AU  - Wang, Z.
TI  - Self-Supervised Imitation for Offline Reinforcement Learning With Hindsight Relabeling
PY  - 2023
T2  - IEEE Transactions on Systems, Man, and Cybernetics: Systems
VL  - 53
IS  - 12
SP  - 7732
EP  - 7743
DO  - 10.1109/TSMC.2023.3297711
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168736234&doi=10.1109%2fTSMC.2023.3297711&partnerID=40&md5=cc7a6a532626c041e2acf36686e44126
AB  - Reinforcement learning (RL) requires a lot of interactions with the environment, which is usually expensive or dangerous in real-world tasks. To address this problem, offline RL considers learning policies from fixed datasets, which is promising in utilizing large-scale datasets, but still suffers from the unstable estimation for out-of-distribution data. Recent developments in RL via supervised learning methods offer an alternative to learning effective policies from suboptimal datasets while relying on oracle information from the environment. In this article, we present an offline RL algorithm that combines hindsight relabeling and supervised regression to predict actions without oracle information. We use hindsight relabeling on the original dataset and learn a command generator and command-conditional policies in a supervised manner, where the command represents the desired return or goal location according to the corresponding task. Theoretically, we illustrate that our method optimizes the lower bound of the goal-conditional RL objective. Empirically, our method achieves competitive performance in comparison with existing approaches in the sparse reward setting and favorable performance in continuous control tasks.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; AJG:3; zdy:3; 
LB  - Yu2023Self-Supervised
ER  -

TY  - JOUR
AU  - Liang, M.
AU  - Zhu, X.
AU  - Zhou, H.
AU  - Qin, J.
AU  - Yin, X.-C.
TI  - HFENet: Hybrid Feature Enhancement Network for Detecting Texts in Scenes and Traffic Panels
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 12
C7  - 3305686
SP  - 14200
EP  - 14212
DO  - 10.1109/TITS.2023.3305686
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168667093&doi=10.1109%2fTITS.2023.3305686&partnerID=40&md5=ef6bd6f4d981109d0ace7f795c187e70
AB  - Text detection in complex scene images is a challenging task for intelligent transportation. Existing scene text detection methods often adopt multi-scale feature learning strategies to extract informative feature representations for covering objects of various sizes. However, the sampling operation inherent in multi-scale feature generation can easily impair high-frequency details (e.g., textures and boundaries), which are critical for text detection. In this work, we propose an innovative Hybrid Feature Enhancement Network (dubbed HFENet) to explicitly improve the quality of high-frequency information for detecting texts in scenes and traffic panels. To be concrete, we propose a simple yet effective self-guided feature enhancement module (SFEM) for globally lifting feature representations to highly discriminative and high-frequency abundant ones. Notably, our SFEM is pluggable and will be removed after training without introducing extra computational costs. In addition, due to the challenge and importance of accurately predicting boundaries for text detection, we propose a novel boundary enhancement module (BEM) to explicitly strengthen local feature representations in the guidance of boundary annotation for accurate localization. Extensive experiments on multiple publicly available datasets (i.e., MSRA-TD500, CTW1500, Total-Text, Traffic Guide Panel Dataset, Chinese Road Plate Dataset, and ASAYAR_TXT) verify the state-of-the-art performance of our method.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Liang2023HFENet
ER  -

TY  - JOUR
AU  - Oliveira, G.B.
AU  - Pedrini, H.
AU  - Dias, Z.
TI  - TEMPROT: protein function annotation using transformers embeddings and homology search
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 242
DO  - 10.1186/s12859-023-05375-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161277950&doi=10.1186%2fs12859-023-05375-0&partnerID=40&md5=271b54f530e857d46884c6112bda8f44
AB  - Background: Although the development of sequencing technologies has provided a large number of protein sequences, the analysis of functions that each one plays is still difficult due to the efforts of laboratorial methods, making necessary the usage of computational methods to decrease this gap. As the main source of information available about proteins is their sequences, approaches that can use this information, such as classification based on the patterns of the amino acids and the inference based on sequence similarity using alignment tools, are able to predict a large collection of proteins. The methods available in the literature that use this type of feature can achieve good results, however, they present restrictions of protein length as input to their models. In this work, we present a new method, called TEMPROT, based on the fine-tuning and extraction of embeddings from an available architecture pre-trained on protein sequences. We also describe TEMPROT+, an ensemble between TEMPROT and BLASTp, a local alignment tool that analyzes sequence similarity, which improves the results of our former approach. Results: The evaluation of our proposed classifiers with the literature approaches has been conducted on our dataset, which was derived from CAFA3 challenge database. Both TEMPROT and TEMPROT+ achieved competitive results on Fmax , Smin , AuPRC and IAuPRC metrics on Biological Process (BP), Cellular Component (CC) and Molecular Function (MF) ontologies compared to state-of-the-art models, with the main results equal to 0.581, 0.692 and 0.662 of Fmax on BP, CC and MF, respectively. Conclusions: The comparison with the literature showed that our model presented competitive results compared the state-of-the-art approaches considering the amino acid sequence pattern recognition and homology analysis. Our model also presented improvements related to the input size that the model can use to train compared to the literature methods. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Oliveira2023TEMPROT
ER  -

TY  - JOUR
AU  - Gu, B.
AU  - Zhan, J.
AU  - Gong, S.
AU  - Liu, W.
AU  - Su, Z.
AU  - Guizani, M.
TI  - A Spatial-Temporal Transformer Network for City-Level Cellular Traffic Analysis and Prediction
PY  - 2023
T2  - IEEE Transactions on Wireless Communications
VL  - 22
IS  - 12
SP  - 9412
EP  - 9423
DO  - 10.1109/TWC.2023.3270441
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159790507&doi=10.1109%2fTWC.2023.3270441&partnerID=40&md5=2edf096df07c9b1b91a1589d5e624945
AB  - With the accelerated popularization of 5G applications, accurate cellular traffic prediction is becoming increasingly important for efficient network management. Currently, the latest algorithms for cellular traffic prediction generally neglect extraction of the shallow features of cellular traffic and the prediction accuracy is hence limited. Therefore, we propose a global-local spatial-Temporal transformer network (GLSTTN) that can fully excavate diverse spatial-Temporal characteristics of cellular traffic for accurate cellular traffic prediction. Specifically, GLSTTN achieves this goal by constructing two modules: The global spatial-Temporal module and the local spatial-Temporal module. In the global spatial-Temporal module, GLSTTN captures global correlations using stacked spatial-Temporal blocks, where each block is composed of one spatial transformer and one temporal transformer. A skip connection is then used in each block to strengthen feature propagation. In the local spatial-Temporal module, GLSTTN fully extracts the local spatial-Temporal dependencies hidden in globally encoded features using densely connected convolutional neural networks. Extensive experiments demonstrate that GLSTTN achieves more accurate cellular traffic prediction than existing approaches on a real-world cellular traffic dataset. © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, T.
AU  - Chen, J.
AU  - Lü, J.
AU  - Liu, K.
AU  - Zhu, A.
AU  - Snoussi, H.
AU  - Zhang, B.
TI  - Synchronous Spatiotemporal Graph Transformer: A New Framework for Traffic Data Prediction
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 12
SP  - 10589
EP  - 10599
DO  - 10.1109/TNNLS.2022.3169488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132508085&doi=10.1109%2fTNNLS.2022.3169488&partnerID=40&md5=9d726b9c92b87a8dc6b8a1acd118c9b2
AB  - —Modeling the spatiotemporal relationship (STR) of traffic data is important yet challenging for existing graph networks. These methods usually capture features separately in temporal and spatial dimensions or represent the spatiotemporal data by adopting multiple local spatial–temporal graphs. The first kind of method mentioned above is difficult to capture potential temporal–spatial relationships, while the other is limited for long-term feature extraction due to its local receptive field. To handle these issues, the Synchronous Spatio-Temporal grAph Transformer (S2TAT) network is proposed for efficiently modeling the traffic data. The contributions of our method include the following: 1) the nonlocal STR can be synchronously modeled by our integrated attention mechanism and graph convolution in the proposed S2TAT block; 2) the timewise graph convolution and multihead mechanism designed can handle the heterogeneity of data; and 3) we introduce a novel attention-based strategy in the output module, being able to capture more valuable historical information to overcome the shortcoming of conventional average aggregation. Extensive experiments are conducted on PeMS datasets that demonstrate the efficacy of the S2TAT by achieving a top-one accuracy but less computational cost by comparing with the state of the art. © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Yan, M.
AU  - Feng, G.
AU  - Qin, S.
AU  - Wei, F.
TI  - Autonomous On-Demand Deployment for UAV Assisted Wireless Networks
PY  - 2023
T2  - IEEE Transactions on Wireless Communications
VL  - 22
IS  - 12
SP  - 9488
EP  - 9501
DO  - 10.1109/TWC.2023.3271411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159813773&doi=10.1109%2fTWC.2023.3271411&partnerID=40&md5=0bacc32b12253a6087b619147df26d68
AB  - Unmanned aerial vehicle (UAV) assisted wireless network has been recognized as an effective technology to facilitate the formation of a super flexible low-altitude platform for relieving the strain on traditional ground cellular systems. However, the on-demand deployment of the UAV-assisted wireless networks (OWN) becomes an essential yet challenging issue, as the constraints of UAVs' location, resource provisioning, and demand distribution should be jointly considered. In this work, we investigate the OWN problem by proposing an autonomous learning framework (ALF) consisting of three sequential stages: demand prediction, proactive deployment, and resource allocation fine-tuning, which can be capable of autonomous network planning without reliance on manual operations in an extremely dynamic environment. In the demand prediction stage, we first design a dual transformer network (DTN) to capture the temporal and spatial dependencies of wireless traffic. We further reduce the computational complexity of DTN from quadratic time complexity to log-linear time complexity. In the proactive deployment stage, we jointly optimize the UAVs' location and resource provisioning by proposing a modified general benders decomposition algorithm with a Γ-optimal convergence, where a learning-based discerning module is designed to accelerate the algorithm. In the resource allocation fine-tuning stage, we propose a simulated annealing-based algorithm to minimize the transmission rate degradation of users to reduce the bias caused by traffic demand prediction. Extensive numerical results based on an open source dataset demonstrate the effectiveness of the proposed methods in comparison with existing baselines.  © 2002-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mei, X.
AU  - Liu, Z.
AU  - Singh, A.
AU  - Lange, M.
AU  - Boddu, P.
AU  - Gong, J.Q.X.
AU  - Lee, J.
AU  - DeMarco, C.
AU  - Cao, C.
AU  - Platt, S.
AU  - Sivakumar, G.
AU  - Gross, B.
AU  - Huang, M.
AU  - Masseaux, J.
AU  - Dua, S.
AU  - Bernheim, A.
AU  - Chung, M.
AU  - Deyer, T.
AU  - Jacobi, A.
AU  - Padilla, M.
AU  - Fayad, Z.A.
AU  - Yang, Y.
TI  - Interstitial lung disease diagnosis and prognosis using an AI system integrating longitudinal data
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 2272
DO  - 10.1038/s41467-023-37720-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153450017&doi=10.1038%2fs41467-023-37720-5&partnerID=40&md5=22d7c94bc44c1f14cc7d6de57ae8b728
AB  - For accurate diagnosis of interstitial lung disease (ILD), a consensus of radiologic, pathological, and clinical findings is vital. Management of ILD also requires thorough follow-up with computed tomography (CT) studies and lung function tests to assess disease progression, severity, and response to treatment. However, accurate classification of ILD subtypes can be challenging, especially for those not accustomed to reading chest CTs regularly. Dynamic models to predict patient survival rates based on longitudinal data are challenging to create due to disease complexity, variation, and irregular visit intervals. Here, we utilize RadImageNet pretrained models to diagnose five types of ILD with multimodal data and a transformer model to determine a patient’s 3-year survival rate. When clinical history and associated CT scans are available, the proposed deep learning system can help clinicians diagnose and classify ILD patients and, importantly, dynamically predict disease progression and prognosis. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Krapp, L.F.
AU  - Abriata, L.A.
AU  - Cortés Rodriguez, F.
AU  - Dal Peraro, M.
TI  - PeSTo: parameter-free geometric deep learning for accurate prediction of protein binding interfaces
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 2175
DO  - 10.1038/s41467-023-37701-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152863703&doi=10.1038%2fs41467-023-37701-8&partnerID=40&md5=db677c60304640b0c7b7ae5e3a432e4b
AB  - Proteins are essential molecular building blocks of life, responsible for most biological functions as a result of their specific molecular interactions. However, predicting their binding interfaces remains a challenge. In this study, we present a geometric transformer that acts directly on atomic coordinates labeled only with element names. The resulting model—the Protein Structure Transformer, PeSTo—surpasses the current state of the art in predicting protein-protein interfaces and can also predict and differentiate between interfaces involving nucleic acids, lipids, ions, and small molecules with high confidence. Its low computational cost enables processing high volumes of structural data, such as molecular dynamics ensembles allowing for the discovery of interfaces that remain otherwise inconspicuous in static experimentally solved structures. Moreover, the growing foldome provided by de novo structural predictions can be easily analyzed, providing new opportunities to uncover unexplored biology. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Hernandez, I.
AU  - Nie, W.
TI  - The AI-IP: Minimizing the guesswork of personality scale item development through artificial intelligence
PY  - 2023
T2  - Personnel Psychology
VL  - 76
IS  - 4
SP  - 1011
EP  - 1035
DO  - 10.1111/peps.12543
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140015986&doi=10.1111%2fpeps.12543&partnerID=40&md5=534080dc0524434579dc6e975b1fbd26
AB  - We propose a framework for integrating various modern natural language processing (NLP) models to assist researchers with developing valid psychological scales. Transformer-based deep neural networks offer state-of-the-art performance on various natural language tasks. This project adapts the transformer model GPT-2 to learn the structure of personality items, and generate the largest openly available pool of personality items, consisting of one million new items. We then use that artificial intelligence-based item pool (AI-IP) to provide a subset of potential scale items for measuring a desired construct. To better recommend construct-related items, we train a paired neural network-based classification BERT model to predict the observed correlation between personality items using only their text. We also demonstrate how zero-shot models can help balance desired content domains within the scale. In combination with the AI-IP, these models narrow the large item pool to items most correlated with a set of initial items. We demonstrate the ability of this multimodel framework to develop longer cohesive scales from a small set of construct-relevant items. We found reliability, validity, and fit equivalent for AI-assisted scales compared to scales developed and optimized by traditional methods. By leveraging neural networks’ ability to generate text relevant to a given topic and infer semantic similarity, this project demonstrates how to support creative and open-ended elements of the scale development process to increase the likelihood of one's initial scale being valid, and minimize the need to modify and revalidate the scale. © 2022 The Authors. Personnel Psychology published by Wiley Periodicals LLC.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - FMS:A; AJG:5; ZUFE:1A; zdy:5; 
LB  - Hernandez2023AI-IP
ER  -

TY  - JOUR
AU  - Lang, Q.
AU  - Liu, X.
AU  - Jia, W.
TI  - AFS Graph: Multidimensional Axiomatic Fuzzy Set Knowledge Graph for Open-Domain Question Answering
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 12
SP  - 10904
EP  - 10918
DO  - 10.1109/TNNLS.2022.3171677
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132522899&doi=10.1109%2fTNNLS.2022.3171677&partnerID=40&md5=ee0b165c6ae97dfe7fa6a697cc4c5f60
AB  - — Open-domain question answering (QA) tasks require a model to retrieve inference chains associated with the answer from massive documents. The core of a QA model is the information filtering ability and reasoning ability. This article proposes a semantic knowledge reasoning graph model based on the multidimensional axiomatic fuzzy set (AFS), which can generate the knowledge graph (KG) and build reasoning paths for reading comprehension tasks through unsupervised learning. Moreover, taking advantage of the interpretable AFS framework enables the proposed model to have the ability to learn and analyze the semantic relationships between candidate documents. Meanwhile, the utilization of the multidimensional AFS acquires semantic descriptions of candidate documents more concise and flexible. The similarity degree between paragraphs is calculated according to the AFS description to generate the graph. Interpretable chains of reasoning provided by the AFS knowledge graph (AFS Graph) will serve as the basis for the answer prediction. Compared with the previous methods, the AFS Graph model presented in this article improves interpretability and reasoning ability. Experimental results show that the proposed model can achieve the state-of-the-art performance on datasets of HotpotQA, SQuAD, and Natural Questions Open. © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Janson, G.
AU  - Valdes-Garcia, G.
AU  - Heo, L.
AU  - Feig, M.
TI  - Direct generation of protein conformational ensembles via machine learning
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 774
DO  - 10.1038/s41467-023-36443-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147835808&doi=10.1038%2fs41467-023-36443-x&partnerID=40&md5=8b2ffe1f16e4b9a51724bea56b9ddc3a
AB  - Dynamics and conformational sampling are essential for linking protein structure to biological function. While challenging to probe experimentally, computer simulations are widely used to describe protein dynamics, but at significant computational costs that continue to limit the systems that can be studied. Here, we demonstrate that machine learning can be trained with simulation data to directly generate physically realistic conformational ensembles of proteins without the need for any sampling and at negligible computational cost. As a proof-of-principle we train a generative adversarial network based on a transformer architecture with self-attention on coarse-grained simulations of intrinsically disordered peptides. The resulting model, idpGAN, can predict sequence-dependent coarse-grained ensembles for sequences that are not present in the training set demonstrating that transferability can be achieved beyond the limited training data. We also retrain idpGAN on atomistic simulation data to show that the approach can be extended in principle to higher-resolution conformational ensemble generation. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 52
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kroll, A.
AU  - Ranjan, S.
AU  - Engqvist, M.K.M.
AU  - Lercher, M.J.
TI  - A general model to predict small molecule substrates of enzymes based on machine and deep learning
PY  - 2023
T2  - Nature Communications
VL  - 14
IS  - 1
C7  - 2787
DO  - 10.1038/s41467-023-38347-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159436009&doi=10.1038%2fs41467-023-38347-2&partnerID=40&md5=15577bf3ed1951781a3231fdccf93f0e
AB  - For most proteins annotated as enzymes, it is unknown which primary and/or secondary reactions they catalyze. Experimental characterizations of potential substrates are time-consuming and costly. Machine learning predictions could provide an efficient alternative, but are hampered by a lack of information regarding enzyme non-substrates, as available training data comprises mainly positive examples. Here, we present ESP, a general machine-learning model for the prediction of enzyme-substrate pairs with an accuracy of over 91% on independent and diverse test data. ESP can be applied successfully across widely different enzymes and a broad range of metabolites included in the training data, outperforming models designed for individual, well-studied enzyme families. ESP represents enzymes through a modified transformer model, and is trained on data augmented with randomly sampled small molecules assigned as non-substrates. By facilitating easy in silico testing of potential substrates, the ESP web server may support both basic and applied science. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Li, J.
AU  - Gao, G.
AU  - Lu, H.
AU  - Yang, J.
AU  - Yue, D.
TI  - Lightweight Real-Time Semantic Segmentation Network With Efficient Transformer and CNN
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 12
SP  - 15897
EP  - 15906
DO  - 10.1109/TITS.2023.3248089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149404169&doi=10.1109%2fTITS.2023.3248089&partnerID=40&md5=62da41f719c7d50b318de26b9da2e0f7
AB  - In the past decade, convolutional neural networks (CNNs) have shown prominence for semantic segmentation. Although CNN models have very impressive performance, the ability to capture global representation is still insufficient, which results in suboptimal results. Recently, Transformer achieved huge success in NLP tasks, demonstrating its advantages in modeling long-range dependency. Recently, Transformer has also attracted tremendous attention from computer vision researchers who reformulate the image processing tasks as a sequence-to-sequence prediction but resulted in deteriorating local feature details. In this work, we propose a lightweight real-time semantic segmentation network called LETNet. LETNet combines a U-shaped CNN with Transformer effectively in a capsule embedding style to compensate for respective deficiencies. Meanwhile, the elaborately designed Lightweight Dilated Bottleneck (LDB) module and Feature Enhancement (FE) module cultivate a positive impact on training from scratch simultaneously. Extensive experiments performed on challenging datasets demonstrate that LETNet achieves superior performances in accuracy and efficiency balance. Specifically, It only contains 0.95M parameters and 13.6G FLOPs but yields 72.8% mIoU at 120 FPS on the Cityscapes test set and 70.5% mIoU at 250 FPS on the CamVid test dataset using a single RTX 3090 GPU. Source code will be available at https://github.com/IVIPLab/LETNet.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 47
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2023Lightweight
ER  -

TY  - JOUR
AU  - Zhou, X.
AU  - Wu, S.
AU  - Shi, R.
AU  - Zheng, B.
AU  - Wang, S.
AU  - Yin, H.
AU  - Zhang, J.
AU  - Yan, C.
TI  - Transformer-Based Multi-Scale Feature Integration Network for Video Saliency Prediction
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 12
C7  - 3278410
SP  - 7696
EP  - 7707
DO  - 10.1109/TCSVT.2023.3278410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161059489&doi=10.1109%2fTCSVT.2023.3278410&partnerID=40&md5=52b2ce1c8ecb74df0151cbdd2afaa00a
AB  - Most cutting-edge video saliency prediction models rely on spatiotemporal features extracted by 3D convolutions due to its local contextual cues acquirement ability. However, the shortage of 3D convolutions is that it cannot effectively capture long-term spatiotemporal dependencies in videos. To address this limitation, we propose a novel Transformer-based Multi-scale Feature Integration Network (TMFI-Net) for video saliency prediction, where the proposed TMFI-Net consists of a semantic-guided encoder and a hierarchical decoder. Firstly, embarking on the Transformer-based multi-level spatiotemporal features, the semantic-guided encoder enhances the features by inserting the high-level feature into each level feature via a top-down pathway and a longitudinal connection, which endows the multi-level spatiotemporal features with rich contextual information. In this way, the features are steered to give more concerns to saliency regions. Secondly, the hierarchical decoder employs a multi-dimensional attention (MA) module to elevate features along channel, temporal, and spatial dimensions jointly. Successively, the hierarchical decoder deploys a progressive decoding block to conduct an initial saliency prediction, which provides a coarse localization of saliency regions. Lastly, considering the complementarity of different saliency predictions, we integrate all initial saliency prediction results into the final saliency map. Comprehensive experimental results on four video saliency datasets firmly demonstrate that our model achieves superior performance when compared with the state-of-the-art video saliency models. The code is available at https://github.com/wusonghe/TMFI-Net.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kong, L.
AU  - Zhou, W.
AU  - Pei, D.
AU  - He, Z.
AU  - Huang, D.
TI  - Group Activity Representation Learning With Long-Short States Predictive Transformer
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 12
C7  - 3278984
SP  - 7267
EP  - 7281
DO  - 10.1109/TCSVT.2023.3278984
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161034460&doi=10.1109%2fTCSVT.2023.3278984&partnerID=40&md5=fa39785be08e59ff667166f661a05fdb
AB  - The research goal of this paper is to learn the group activity representations in a self-supervised fashion instead of through the use of conventional methods that rely on manually annotated labels. It is essential for this task to better describe the complex group states and their future transitions. To this end, we propose a long-short state predictive Transformer (LSSPT), which mines the meaningful spatiotemporal features of group activities by predicting the future group states with long- and short-term historical state dynamics. LSSPT consists of an encoder that models diverse spatiotemporal state representations in the observation, together with a decoder that exploits rich dynamic patterns by attending to both the short-term spatial context and long-term history state evolutions to predict future group states. Furthermore, we consider the distinguishability and consistency of the predicted states and introduce a joint learning mechanism to optimize the models, enabling LSSPT to describe more reliable state transitions. Finally, extensive experiments are carried out to evaluate the learned representation on downstream tasks on the Volleyball, Collective Activity and VolleyTactic datasets, which showcases the method's state-of-the-art performance over the existing self-supervised learning approaches.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, M.
AU  - Liu, C.
AU  - Li, S.
AU  - Yan, Q.
AU  - Fang, Q.
AU  - Chen, Q.
TI  - A Geometric Knowledge Oriented Single-Frame 2D-to-3D Human Absolute Pose Estimation Method
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 12
C7  - 3279291
SP  - 7282
EP  - 7295
DO  - 10.1109/TCSVT.2023.3279291
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161000320&doi=10.1109%2fTCSVT.2023.3279291&partnerID=40&md5=21241f3f46fdf9a5390de3428a505435
AB  - As a critical part of the 3D human pose estimation (HPE), establishing the 2D-to-3D lifting mapping is limited by depth ambiguity. Most current works generally lack the quantitative analysis of the relative depth expression and the depth ambiguity error expression in lifting mapping, resulting in low prediction efficiency and poor interpretability. To this end, this paper mines and leverages prior geometric knowledge of these expressions based on the pinhole imaging principle, decoupling the 2D-to-3D lifting mapping and simplifying the model training. Specifically, this paper proposes a prior geometric knowledge oriented pose estimation model with two-branch transformer architectures, explicitly introducing high-dimensional prior geometric features to improve model efficiency and interpretability. It converts the regression of spatial coordinates into the prediction of spatial direction vectors between joints to generate multiple feasible solutions further alleviate the depth ambiguity. Moreover, this paper raises a novel non-learning-based absolute depth estimation algorithm based on prior geometric relationship decoupling from relative depth expression for the first time. It establishes multiple independent depth mapping from non-root nodes to the root node to calculate the absolute depth candidate, which is parameter-free, plug-and-play, and interpretable. Experiments show that the proposed pose estimation model achieves state-of-the-art performance on Human 3.6M and MPI-INF-3DHP benchmarks with lower parameters and faster inference speed, and the proposed absolute depth estimation algorithm achieves similar performance to traditional methods without any network parameters. The source code are available at https://github.com/Humengxian/GKONet.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liang, J.
AU  - Pei, W.
AU  - Lu, F.
TI  - Layout-Bridging Text-to-Image Synthesis
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 12
SP  - 7438
EP  - 7451
DO  - 10.1109/TCSVT.2023.3274228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159825873&doi=10.1109%2fTCSVT.2023.3274228&partnerID=40&md5=68d698d1433cfeecede06fb3c8650a71
AB  - The crux of text-to-image synthesis stems from the difficulty of preserving the cross-modality semantic consistency between the input text and the synthesized image. Typical methods, which seek to model the text-to-image mapping directly, could only capture keywords in the text that indicates common objects or actions but fail to learn their spatial distribution patterns. An effective way to circumvent this limitation is to generate an image layout as guidance, which is attempted by a few methods. Nevertheless, these methods fail to generate practically effective layouts due to the diversity of input text and object location. In this paper we push for effective modeling in both text-to-layout generation and layout-to-image synthesis. Specifically, we formulate the text-to-layout generation as a sequence-to-sequence modeling task, and build our model upon Transformer to learn the spatial relationships between objects by modeling the sequential dependencies between them. In the stage of layout-to-image synthesis, we focus on learning the textual-visual semantic alignment per object in the layout to precisely incorporate the input text into the layout-to-image synthesizing process. To evaluate the quality of generated layout, we design a new metric specifically, dubbed Layout Quality Score, which considers both the absolute distribution errors of bounding boxes in the layout and the mutual spatial relationships between them. Extensive experiments on three datasets demonstrate the superior performance of our method over state-of-the-art methods on both predicting the layout and synthesizing the image from the given text.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Liu, M.
AU  - Wu, J.
AU  - Nie, L.
TI  - Multi-Granularity Interaction and Integration Network for Video Question Answering
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 12
C7  - 3278492
SP  - 7684
EP  - 7695
DO  - 10.1109/TCSVT.2023.3278492
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161013220&doi=10.1109%2fTCSVT.2023.3278492&partnerID=40&md5=8c332763c2b87b8a00c9f0bee4cd2f43
AB  - Video question answering, aiming to answer a natural language question related to the given video, has gained popularity in the last few years. Although significant improvements have been achieved, it is still confronted with two challenges: the sufficient comprehension of video content and the long-tailed answers. To this end, we propose a multi-granularity interaction and integration network for video question answering. It jointly explores multi-level intra-granularity and inter-granularity relations to enhance the comprehension of videos. To be specific, we first build a word-enhanced visual representation module to achieve cross-modal alignment. And then we advance a multi-granularity interaction module to explore the intra-granularity and inter-granularity relationships. Finally, a question-guided interaction module is developed to select question-related visual representations for answer prediction. In addition, we employ the seesaw loss for open-ended tasks to alleviate the long-tailed word distribution effect. Both the quantitative and qualitative results on TGIF-QA, MSRVTT-QA, and MSVD-QA datasets demonstrate the superiority of our model over several state-of-the-art approaches.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kim, Y.
AU  - Kwon, J.
TI  - AttSec: protein secondary structure prediction by capturing local patterns from attention map
PY  - 2023
T2  - BMC Bioinformatics
VL  - 24
IS  - 1
C7  - 183
DO  - 10.1186/s12859-023-05310-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158034168&doi=10.1186%2fs12859-023-05310-3&partnerID=40&md5=43e4996434c93937727f24922a2fdb78
AB  - Background: Protein secondary structures that link simple 1D sequences to complex 3D structures can be used as good features for describing the local properties of protein, but also can serve as key features for predicting the complex 3D structures of protein. Thus, it is very important to accurately predict the secondary structure of the protein, which contains a local structural property assigned by the pattern of hydrogen bonds formed between amino acids. In this study, we accurately predict protein secondary structure by capturing the local patterns of protein. For this objective, we present a novel prediction model, AttSec, based on transformer architecture. In particular, AttSec extracts self-attention maps corresponding to pairwise features between amino acid embeddings and passes them through 2D convolution blocks to capture local patterns. In addition, instead of using additional evolutionary information, it uses protein embedding as an input, which is generated by a language model. Results: For the ProteinNet DSSP8 dataset, our model showed 11.8% better performance on the entire evaluation datasets compared with other no-evolutionary-information-based models. For the NetSurfP-2.0 DSSP8 dataset, it showed 1.2% better performance on average. There was an average performance improvement of 9.0% for the ProteinNet DSSP3 dataset and an average of 0.7% for the NetSurfP-2.0 DSSP3 dataset. Conclusion: We accurately predict protein secondary structure by capturing the local patterns of protein. For this objective, we present a novel prediction model, AttSec, based on transformer architecture. Although there was no dramatic accuracy improvement compared with other models, the improvement on DSSP8 was greater than that on DSSP3. This result implies that using our proposed pairwise feature could have a remarkable effect for several challenging tasks that require finely subdivided classification. Github package URL is https://github.com/youjin-DDAI/AttSec . © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Kim2023AttSec
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Wang, J.
AU  - Luo, Y.
AU  - Zhao, S.
AU  - Li, W.
AU  - Li, S.Z.
TI  - Efficient prediction of peptide self-assembly through sequential and graphical encoding
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad409
DO  - 10.1093/bib/bbad409
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177472553&doi=10.1093%2fbib%2fbbad409&partnerID=40&md5=ff08844f81eef40c0a89db141b19e148
AB  - In recent years, there has been an explosion of research on the application of deep learning to the prediction of various peptide properties, due to the significant development and market potential of peptides. Molecular dynamics has enabled the efficient collection of large peptide datasets, providing reliable training data for deep learning. However, the lack of systematic analysis of the peptide encoding, which is essential for artificial intelligence-assisted peptide-related tasks, makes it an urgent problem to be solved for the improvement of prediction accuracy. To address this issue, we first collect a high-quality, colossal simulation dataset of peptide self-assembly containing over 62 000 samples generated by coarse-grained molecular dynamics. Then, we systematically investigate the effect of peptide encoding of amino acids into sequences and molecular graphs using state-of-the-art sequential (i.e. recurrent neural network, long short-term memory and Transformer) and structural deep learning models (i.e. graph convolutional network, graph attention network and GraphSAGE), on the accuracy of peptide self-assembly prediction, an essential physiochemical process prior to any peptide-related applications. Extensive benchmarking studies have proven Transformer to be the most powerful sequence-encoding-based deep learning model, pushing the limit of peptide self-assembly prediction to decapeptides. In summary, this work provides a comprehensive benchmark analysis of peptide encoding with advanced deep learning models, serving as a guide for a wide range of peptide-related predictions such as isoelectric points, hydration free energy, etc. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guan, J.
AU  - Peng, C.
AU  - Shang, J.
AU  - Tang, X.
AU  - Sun, Y.
TI  - PhaGenus: genus-level classification of bacteriophages using a Transformer model
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad408
DO  - 10.1093/bib/bbad408
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177103598&doi=10.1093%2fbib%2fbbad408&partnerID=40&md5=50f15c7a9555706d503751d8796916ae
AB  - Motivation: Bacteriophages (phages for short), which prey on and replicate within bacterial cells, have a significant role in modulating microbial communities and hold potential applications in treating antibiotic resistance. The advancement of high-throughput sequencing technology contributes to the discovery of phages tremendously. However, the taxonomic classification of assembled phage contigs still faces several challenges, including high genetic diversity, lack of a stable taxonomy system and limited knowledge of phage annotations. Despite extensive efforts, existing tools have not yet achieved an optimal balance between prediction rate and accuracy. Results: In this work, we develop a learning-based model named PhaGenus, which conducts genus-level taxonomic classification for phage contigs. PhaGenus utilizes a powerful Transformer model to learn the association between protein clusters and support the classification of up to 508 genera. We tested PhaGenus on four datasets in different scenarios. The experimental results show that PhaGenus outperforms state-of-the-art methods in predicting low-similarity datasets, achieving an improvement of at least 13.7%. Additionally, PhaGenus is highly effective at identifying previously uncharacterized genera that are not represented in reference databases, with an improvement of 8.52%. The analysis of the infants' gut and GOV2.0 dataset demonstrates that PhaGenus can be used to classify more contigs with higher accuracy. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, B.
AU  - Lin, M.
AU  - Chen, T.
AU  - Wang, L.
TI  - FG-BERT: a generalized and self-supervised functional group-based molecular representation learning framework for properties prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad398
DO  - 10.1093/bib/bbad398
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176500338&doi=10.1093%2fbib%2fbbad398&partnerID=40&md5=1325e061123d2f72cfacaffd66e4eaf3
AB  - Artificial intelligence-based molecular property prediction plays a key role in molecular design such as bioactive molecules and functional materials. In this study, we propose a self-supervised pretraining deep learning (DL) framework, called functional group bidirectional encoder representations from transformers (FG-BERT), pertained based on ∼1.45 million unlabeled drug-like molecules, to learn meaningful representation of molecules from function groups. The pretrained FG-BERT framework can be fine-tuned to predict molecular properties. Compared to state-of-the-art (SOTA) machine learning and DL methods, we demonstrate the high performance of FG-BERT in evaluating molecular properties in tasks involving physical chemistry, biophysics and physiology across 44 benchmark datasets. In addition, FG-BERT utilizes attention mechanisms to focus on FG features that are critical to the target properties, thereby providing excellent interpretability for downstream training tasks. Collectively, FG-BERT does not require any artificially crafted features as input and has excellent interpretability, providing an out-of-the-box framework for developing SOTA models for a variety of molecule (especially for drug) discovery tasks. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Brahma, R.
AU  - Shin, J.-M.
AU  - Cho, K.-H.
TI  - KinScan: AI-based rapid profiling of activity across the kinome
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad396
DO  - 10.1093/bib/bbad396
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177991156&doi=10.1093%2fbib%2fbbad396&partnerID=40&md5=6f6434a2e8aa459ee1d56b66325991c1
AB  - Kinases play a vital role in regulating essential cellular processes, including cell cycle progression, growth, apoptosis, and metabolism, by catalyzing the transfer of phosphate groups from adenosing triphosphate to substrates. Their dysregulation has been closely associated with numerous diseases, including cancer development, making them attractive targets for drug discovery. However, accurately predicting the binding affinity between chemical compounds and kinase targets remains challenging due to the highly conserved structural similarities across the kinome. To address this limitation, we present KinScan, a novel computational approach that leverages large-scale bioactivity data and integrates the Multi-Scale Context Aware Transformer framework to construct a virtual profiling model encompassing 391 protein kinases. The developed model demonstrates exceptional prediction capability, distinguishing between kinases by utilizing structurally aligned kinase binding site features derived from multiple sequence alignment for fast and accurate predictions. Through extensive validation and benchmarking, KinScan demonstrated its robust predictive power and generalizability for large-scale kinome-wide profiling and selectivity, uncovering associations with specific diseases and providing valuable insights into kinase activity profiles of compounds. Furthermore, we deployed a web platform for end-to-end profiling and selectivity analysis, accessible at https://kinscan.drugonix.com/softwares/kinscan. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, T.
AU  - Gao, H.
AU  - Ren, X.
AU  - Xu, G.
AU  - Liu, B.
AU  - Wu, N.
AU  - Luo, H.
AU  - Wang, Y.
AU  - Tu, T.
AU  - Yao, B.
AU  - Guan, F.
AU  - Teng, Y.
AU  - Huang, H.
AU  - Tian, J.
TI  - Protein-protein interaction and site prediction using transfer learning
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad376
DO  - 10.1093/bib/bbad376
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175498465&doi=10.1093%2fbib%2fbbad376&partnerID=40&md5=458376d406fc773dfd920957df713c6b
AB  - The advanced language models have enabled us to recognize protein-protein interactions (PPIs) and interaction sites using protein sequences or structures. Here, we trained the MindSpore ProteinBERT (MP-BERT) model, a Bidirectional Encoder Representation from Transformers, using protein pairs as inputs, making it suitable for identifying PPIs and their respective interaction sites. The pretrained model (MP-BERT) was fine-tuned as MPB-PPI (MP-BERT on PPI) and demonstrated its superiority over the state-of-the-art models on diverse benchmark datasets for predicting PPIs. Moreover, the model's capability to recognize PPIs among various organisms was evaluated on multiple organisms. An amalgamated organism model was designed, exhibiting a high level of generalization across the majority of organisms and attaining an accuracy of 92.65%. The model was also customized to predict interaction site propensity by fine-tuning it with PPI site data as MPB-PPISP. Our method facilitates the prediction of both PPIs and their interaction sites, thereby illustrating the potency of transfer learning in dealing with the protein pair task. © 2023 The Author(s). Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mukhtar, H.
AU  - Khan, M.U.G.
TI  - STMMOT: Advancing multi-object tracking through spatiotemporal memory networks and multi-scale attention pyramids
PY  - 2023
T2  - Neural Networks
VL  - 168
SP  - 363
EP  - 379
DO  - 10.1016/j.neunet.2023.09.047
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173174648&doi=10.1016%2fj.neunet.2023.09.047&partnerID=40&md5=fea271daf6eaa18fd43865261bcbb27f
AB  - Multi-object Tracking (MOT) is very important in human surveillance, sports analytics, autonomous driving, and cooperative robots. Current MOT methods do not perform well in non-uniform movements, occlusion and appearance–reappearance scenarios. We introduce a comprehensive MOT method that seamlessly merges object detection and identity linkage within an end-to-end trainable framework, designed with the capability to maintain object links over a long period of time. Our proposed model, named STMMOT, is architectured around 4 key modules: (1) Candidate proposal creation network, generates object proposals via vision-Transformer encoder–decoder architecture; (2) Scale variant pyramid, progressive pyramid structure to learn the self-scale and cross-scale similarities in multi-scale feature maps; (3) Spatio-temporal memory encoder, extracting the essential information from the memory associated with each object under tracking; and (4) Spatio-temporal memory decoder, simultaneously resolving the tasks of object detection and identity association for MOT. Our system leverages a robust spatio-temporal memory module that retains extensive historical object state observations and effectively encodes them using an attention-based aggregator. The uniqueness of STMMOT resides in representing objects as dynamic query embeddings that are updated continuously, which enables the prediction of object states with an attention mechanism and eradicates the need for post-processing. Experimental results show that STMMOT archives scores of 79.8 and 78.4 for IDF1, 79.3 and 74.1 for MOTA, 73.2 and 69.0 for HOTA, 61.2 and 61.5 for AssA, and maintained an ID switch count of 1529 and 1264 on MOT17 and MOT20, respectively. When evaluated on MOT20, it scored 78.4 in IDF1, 74.1 in MOTA, 69.0 in HOTA, and 61.5 in AssA, and kept the ID switch count to 1264. Compared with the previous best TransMOT, STMMOT achieves around a 4.58% and 4.25% increase in IDF1, and ID switching reduction to 5.79% and 21.05% on MOT17 and MOT20, respectively. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Umerenkov, D.
AU  - Nikolaev, F.
AU  - Shashkova, T.I.
AU  - Strashnov, P.V.
AU  - Sindeeva, M.
AU  - Shevtsov, A.
AU  - Ivanisenko, N.V.
AU  - Kardymon, O.L.
TI  - PROSTATA: a framework for protein stability assessment using transformers
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 11
C7  - btad671
DO  - 10.1093/bioinformatics/btad671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177102636&doi=10.1093%2fbioinformatics%2fbtad671&partnerID=40&md5=a3e110ad5369c681f30d15592e410c23
AB  - Motivation: Accurate prediction of change in protein stability due to point mutations is an attractive goal that remains unachieved. Despite the high interest in this area, little consideration has been given to the transformer architecture, which is dominant in many fields of machine learning. Results: In this work, we introduce PROSTATA, a predictive model built in a knowledge-transfer fashion on a new curated dataset. PROSTATA demonstrates advantage over existing solutions based on neural networks. We show that the large improvement margin is due to both the architecture of the model and the quality of the new training dataset. This work opens up opportunities to develop new lightweight and accurate models for protein stability assessment. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Tan, T.
AU  - Lim, J.M.-Y.
AU  - Foo, J.J.
AU  - Muniandy, R.
TI  - 3D detection transformer: Set prediction of objects using point clouds
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 236
C7  - 103808
DO  - 10.1016/j.cviu.2023.103808
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172364089&doi=10.1016%2fj.cviu.2023.103808&partnerID=40&md5=7b4b149f555978ff4076110c5ed67dcc
AB  - Object detection in 3D scenes rely on two main methods: detection based on proposals (two-stage detectors) or detections based on anchors (single-stage detectors), similar to approaches for object detection in 2D. In this paper, we propose the 3DeTR framework that produces 3D detections without the use of anchors or proposals, allowing training of the entire neural network in an end-to-end manner. Raw point cloud scenes are augmented and input into distance-and-reflectiveness-based feature extractor to produce representative points. Then, a transformer encoder–decoder module learns the local object relations and global context to generate parallel detections, which are then passed to a set-based loss function to map predictions to the set of ground truth labels uniquely. The model's architecture produces 3D detections by regressing directly with the set of ground truths without the need for anchors or proposals, which are bottlenecks for object detection performances. We tested the framework on the KITTI Vision Benchmark Suite 3D object detection dataset, achieving results on par with the state-of-the-art: 80.37 AP on Cars (Moderate) class and 47.92 AP on Pedestrians (Moderate) class. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Guo, H.
AU  - Zhang, F.
AU  - Wang, X.
AU  - Wu, K.
AU  - Qiu, S.
AU  - Liu, B.
AU  - Wang, Y.
AU  - Hu, Y.
AU  - Li, J.
TI  - HNetGO: protein function prediction via heterogeneous network transformer
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbab556
DO  - 10.1093/bib/bbab556
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174865619&doi=10.1093%2fbib%2fbbab556&partnerID=40&md5=7f6a41552ef09a12031df984c9cd3987
AB  - Protein function annotation is one of the most important research topics for revealing the essence of life at molecular level in the post-genome era. Current research shows that integrating multisource data can effectively improve the performance of protein function prediction models. However, the heavy reliance on complex feature engineering and model integration methods limits the development of existing methods. Besides, models based on deep learning only use labeled data in a certain dataset to extract sequence features, thus ignoring a large amount of existing unlabeled sequence data. Here, we propose an end-to-end protein function annotation model named HNetGO, which innovatively uses heterogeneous network to integrate protein sequence similarity and protein-protein interaction network information and combines the pretraining model to extract the semantic features of the protein sequence. In addition, we design an attention-based graph neural network model, which can effectively extract node-level features from heterogeneous networks and predict protein function by measuring the similarity between protein nodes and gene ontology term nodes. Comparative experiments on the human dataset show that HNetGO achieves state-of-the-art performance on cellular component and molecular function branches. © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kersting, J.
AU  - Maoro, F.
AU  - Geierhos, M.
TI  - Towards comparable ratings: Exploring bias in German physician reviews
PY  - 2023
T2  - Data and Knowledge Engineering
VL  - 148
C7  - 102235
DO  - 10.1016/j.datak.2023.102235
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174574820&doi=10.1016%2fj.datak.2023.102235&partnerID=40&md5=334f5e6ce18d32c745cca32a3f1a94fb
AB  - In this study, we evaluate the impact of gender-biased data from German-language physician reviews on the fairness of fine-tuned language models. For two different downstream tasks, we use data reported to be gender biased and aggregate it with annotations. First, we propose a new approach to aspect-based sentiment analysis that allows identifying, extracting, and classifying implicit and explicit aspect phrases and their polarity within a single model. The second task we present is grade prediction, where we predict the overall grade of a review on the basis of the review text. For both tasks, we train numerous transformer models and evaluate their performance. The aggregation of sensitive attributes, such as a physician's gender and migration background, with individual text reviews allows us to measure the performance of the models with respect to these sensitive groups. These group-wise performance measures act as extrinsic bias measures for our downstream tasks. In addition, we translate several gender-specific templates of the intrinsic bias metrics into the German language and evaluate our fine-tuned models. Based on this set of tasks, fine-tuned models, and intrinsic and extrinsic bias measures, we perform correlation analyses between intrinsic and extrinsic bias measures. In terms of sensitive groups and effect sizes, our bias measure results show different directions. Furthermore, correlations between measures of intrinsic and extrinsic bias can be observed in different directions. This leads us to conclude that gender-biased data does not inherently lead to biased models. Other variables, such as template dependency for intrinsic measures and label distribution in the data, must be taken into account as they strongly influence the metric results. Therefore, we suggest that metrics and templates should be chosen according to the given task and the biases to be assessed. © 2023 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pereira, T.O.
AU  - Abbasi, M.
AU  - Arrais, J.P.
TI  - Enhancing reinforcement learning for de novo molecular design applying self-attention mechanisms
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad368
DO  - 10.1093/bib/bbad368
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175660507&doi=10.1093%2fbib%2fbbad368&partnerID=40&md5=2ce0704b9d8ed35848c8f442e2d77d66
AB  - The drug discovery process can be significantly improved by applying deep reinforcement learning (RL) methods that learn to generate compounds with desired pharmacological properties. Nevertheless, RL-based methods typically condense the evaluation of sampled compounds into a single scalar value, making it difficult for the generative agent to learn the optimal policy. This work combines self-attention mechanisms and RL to generate promising molecules. The idea is to evaluate the relative significance of each atom and functional group in their interaction with the target, and to utilize this information for optimizing the Generator. Therefore, the framework for de novo drug design is composed of a Generator that samples new compounds combined with a Transformer-encoder and a biological affinity Predictor that evaluate the generated structures. Moreover, it takes the advantage of the knowledge encapsulated in the Transformer’s attention weights to evaluate each token individually. We compared the performance of two output prediction strategies for the Transformer: standard and masked language model (MLM). The results show that the MLM Transformer is more effective in optimizing the Generator compared with the state-of-the-art works. Additionally, the evaluation models identified the most important regions of each molecule for the biological interaction with the target. As a case study, we generated synthesizable hit compounds that can be putative inhibitors of the enzyme ubiquitin-specific protein 7 (USP7). © 2023 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xiao, L.
AU  - Wu, X.
AU  - Yang, S.
AU  - Xu, J.
AU  - Zhou, J.
AU  - He, L.
TI  - Cross-modal fine-grained alignment and fusion network for multimodal aspect-based sentiment analysis
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 6
C7  - 103508
DO  - 10.1016/j.ipm.2023.103508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172028496&doi=10.1016%2fj.ipm.2023.103508&partnerID=40&md5=ed77ecd67f92b6fb25d426378e30e4b4
AB  - Multi-modal Aspect-based Sentiment Analysis (MABSA) aims to forecast the polarity of sentiment concerning aspects within a given sentence based on the correlation between the sentence and its accompanying image. Comprehending multi-modal sentiment expression requires strong cross-modal alignment and fusion ability. Previous state-of-the-art (SOTA) models fail to explicitly align valuable visual clues with aspect and sentiment information in textual representations and overlook the utilization of syntactic dependency information in the accompanying text modality. We present CoolNet (Cross-modal Fine-grained Alignment and Fusion Network) to boost the performance of visual-language models in seamlessly integrating vision and language information. Specifically, CoolNet starts by transforming an image into a textual caption and a graph structure, then dynamically aligns the semantic and syntactic information from both the input sentence and the generated caption, as well as models the object-level visual features. Finally, a cross-modal transformer is employed to fuse and model the inter-modality dynamics.This network boasts advanced cross-modal fine-grained alignment and fusion capabilities. On standard benchmarks such as Twitter-2015 and Twitter-2017, CoolNet consistently outperforms state-of-the-art algorithm FITE with notable improvements in accuracy and Macro-F1 values. Specifically, we observe an improvement in accuracy and Macro-F1 values by 1.43% and 1.38% for Twitter-2015, and 0.74% and 0.88% for Twitter-2017, respectively, demonstrating the superiority of our CoolNet architecture. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Khan, A.R.
AU  - Reinders, M.J.T.
AU  - Khatri, I.
TI  - Determining epitope specificity of T-cell receptors with transformers
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 11
C7  - btad632
DO  - 10.1093/bioinformatics/btad632
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176508373&doi=10.1093%2fbioinformatics%2fbtad632&partnerID=40&md5=b42f737b69cab08254cca4dd04c76f31
AB  - Summary: T-cell receptors (TCRs) on T cells recognize and bind to epitopes presented by the major histocompatibility complex in case of an infection or cancer. However, the high diversity of TCRs, as well as their unique and complex binding mechanisms underlying epitope recognition, make it difficult to predict the binding between TCRs and epitopes. Here, we present the utility of transformers, a deep learning strategy that incorporates an attention mechanism that learns the informative features, and show that these models pre-trained on a large set of protein sequences outperform current strategies. We compared three pre-trained auto-encoder transformer models (ProtBERT, ProtAlbert, and ProtElectra) and one pre-trained auto-regressive transformer model (ProtXLNet) to predict the binding specificity of TCRs to 25 epitopes from the VDJdb database (human and murine). Two additional modifications were performed to incorporate gene usage of the TCRs in the four transformer models. Of all 12 transformer implementations (four models with three different modifications), a modified version of the ProtXLNet model could predict TCR-epitope pairs with the highest accuracy (weighted F1 score 0.55 simultaneously considering all 25 epitopes). The modification included additional features representing the gene names for the TCRs. We also showed that the basic implementation of transformers outperformed the previously available methods, i.e. TCRGP, TCRdist, and DeepTCR, developed for the same biological problem, especially for the hard-to-classify labels. We show that the proficiency of transformers in attention learning can be made operational in a complex biological setting like TCR binding prediction. Further ingenuity in utilizing the full potential of transformers, either through attention head visualization or introducing additional features, can extend T-cell research avenues.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Wolfinger, R.
TI  - A prediction model for blood-brain barrier penetrating peptides based on masked peptide transformers with dynamic routing
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 6
C7  - bbad399
DO  - 10.1093/bib/bbad399
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177990847&doi=10.1093%2fbib%2fbbad399&partnerID=40&md5=2f327b816e458a23b35c5948d60e7b13
AB  - Blood-brain barrier penetrating peptides (BBBPs) are short peptide sequences that possess the ability to traverse the selective blood-brain interface, making them valuable drug candidates or carriers for various payloads. However, the in vivo or in vitro validation of BBBPs is resource-intensive and time-consuming, driving the need for accurate in silico prediction methods. Unfortunately, the scarcity of experimentally validated BBBPs hinders the efficacy of current machine-learning approaches in generating reliable predictions. In this paper, we present DeepB3P3, a novel framework for BBBPs prediction. Our contribution encompasses four key aspects. Firstly, we propose a novel deep learning model consisting of a transformer encoder layer, a convolutional network backbone, and a capsule network classification head. This integrated architecture effectively learns representative features from peptide sequences. Secondly, we introduce masked peptides as a powerful data augmentation technique to compensate for small training set sizes in BBBP prediction. Thirdly, we develop a novel threshold-tuning method to handle imbalanced data by approximating the optimal decision threshold using the training set. Lastly, DeepB3P3 provides an accurate estimation of the uncertainty level associated with each prediction. Through extensive experiments, we demonstrate that DeepB3P3 achieves state-of-the-art accuracy of up to 98.31% on a benchmarking dataset, solidifying its potential as a promising computational tool for the prediction and discovery of BBBPs. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Deihim, A.
AU  - Alonso, E.
AU  - Apostolopoulou, D.
TI  - STTRE: A Spatio-Temporal Transformer with Relative Embeddings for multivariate time series forecasting
PY  - 2023
T2  - Neural Networks
VL  - 168
SP  - 549
EP  - 559
DO  - 10.1016/j.neunet.2023.09.039
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174048628&doi=10.1016%2fj.neunet.2023.09.039&partnerID=40&md5=3108fef89dea8eab32440dc7cb9d4b5f
AB  - The prevalence of multivariate time series data across several disciplines fosters a demand and, subsequently, significant growth in the research and advancement of multivariate time series analysis. Drawing inspiration from a popular natural language processing model, the Transformer, we propose the Spatio-Temporal Transformer with Relative Embeddings (STTRE) to address multivariate time series forecasting. This work primarily focuses on developing a Transformer-based framework that can fully exploit the spatio-temporal nature of a multivariate time series by incorporating several of the Transformer's key components, but with augmentations that allow them to excel in multivariate time series forecasting. Current Transformer-based models for multivariate time series often neglect the data's spatial component(s) and utilize absolute position embeddings as their only means to detect the data's temporal component(s), which we show is flawed for time series applications. The lack of emphasis on fully exploiting the spatio-temporality of the data can incur subpar results in terms of accuracy. We redesign relative position representations, which we rename to relative embeddings, to unveil a new method for detecting latent spatial, temporal, and spatio-temporal dependencies more effectively than previous Transformer-based models. We couple these relative embeddings with a restructuring of the Transformer's primary sequence learning mechanism, multi-head attention, in a way that allows for full utilization of relative embeddings, thus achieving up to a 24% improvement in accuracy over other state-of-the-art multivariate time series models on a comprehensive selection of publicly available multivariate time series forecasting datasets. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, J.
AU  - Wu, Z.
AU  - Wang, S.
AU  - Demonceaux, C.
AU  - Jiang, Q.
TI  - Bidirectional Collaborative Mentoring Network for Marine Organism Detection and Beyond
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 11
SP  - 6595
EP  - 6608
DO  - 10.1109/TCSVT.2023.3264442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153397237&doi=10.1109%2fTCSVT.2023.3264442&partnerID=40&md5=b841f71f183504e2dace7d9ef94fc1c8
AB  - Organism detection plays a vital role in marine resource exploitation and marine economy. How to accurately locate the target organism object within the camouflaged and dark light oceanic scene has recently drawn great attention in the research community. Existing learning-based works usually leverage local texture details within a neighboring area, with few methods explicitly exploring the usage of contextualized awareness for accurate object detection. From a novel perspective, we in this work present a Bidirectional Collaborative Mentoring Network (BCMNet) which fully explores both texture and context clues during the encoding and decoding stages, making the cross-paradigm interaction bidirectional and improving the scene understanding at all stages. Specifically, we first extract texture and context features through a dual-branch encoder and attentively fuse them through our adjacent feature fusion (AFF) block. Then, we propose a structure-aware module (SAM) and a detail-enhanced module (DEM) to form our two-stage decoding pipeline. On the one hand, our SAM leverages both local and global clues to preserve morphological integrity and generate an initial prediction of the target object. On the other hand, the DEM explicitly explores long-range dependencies to refine the initially predicted object mask further. The combination of SAM and DEM enables better extracting, preserving, and enhancing the object morphology, making it easier to segment the target object from the camouflaged background with sharp contour. Extensive experiments on three benchmark datasets show that our proposed BCMNet performs favorably over state-of-the-art models. The code will be made available at https://github.com/chasecjg/BCMNet.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, B.
AU  - Shi, T.
AU  - Zhong, L.
AU  - Zhang, Y.
AU  - Ye, Y.
TI  - Graph-coupled time interval network for sequential recommendation
PY  - 2023
T2  - Information Sciences
VL  - 648
C7  - 119510
DO  - 10.1016/j.ins.2023.119510
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168761802&doi=10.1016%2fj.ins.2023.119510&partnerID=40&md5=90f5df62f4e31fb246f0aec349044acd
AB  - Modeling the dynamics of sequential patterns (i.e., sequential recommendation) has obtained great attention, where the key problem is how to infer the next interesting item according to users' historical actions. Owing to high efficiency and accuracy, several Transformer-like frameworks have successfully achieved this task without adopting complicated recurrent or convolutional operations. Nevertheless, they focus only on the user-item bipartite graph and forgo other auxiliary information, which is non-trivial to attain satisfactory performance especially under long-tail distribution scenarios. In modeling short-term user interests, they fail to capture the time intervals between the recent actions and the target timestamp, which may result in the suboptimal performance. To settle such two problems, we propose a novel architecture for the task of sequential recommendation, namely graph-coupled time interval network (GCTN). Specifically, by means of item category information, we devise a category-aware graph propagation module to better learn user and item embeddings. Furthermore, we design a time-aware self-attention mechanism, which explicitly captures the effect of the time interval between two actions for next item prediction. To integrate these two parts into an organic whole, we introduce a personalized gating strategy to differentiate the importance of each part under the special context. Extensive experiments demonstrate the effectiveness and efficiency of GCTN over recent state-of-the-art methods on four real-world datasets, seamlessly combining the advantages of graph neural networks and Transformers. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:B; 
LB  - Wu2023Graph-coupled
ER  -

TY  - JOUR
AU  - Trisedya, B.D.
AU  - Salim, F.D.
AU  - Chan, J.
AU  - Spina, D.
AU  - Scholer, F.
AU  - Sanderson, M.
TI  - i-Align: an interpretable knowledge graph alignment model
PY  - 2023
T2  - Data Mining and Knowledge Discovery
VL  - 37
IS  - 6
SP  - 2494
EP  - 2516
DO  - 10.1007/s10618-023-00963-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167328200&doi=10.1007%2fs10618-023-00963-3&partnerID=40&md5=1eaaa4769f7ed549465cb9381eb5cfb8
AB  - Knowledge graphs (KGs) are becoming essential resources for many downstream applications. However, their incompleteness may limit their potential. Thus, continuous curation is needed to mitigate this problem. One of the strategies to address this problem is KG alignment, i.e., forming a more complete KG by merging two or more KGs. This paper proposes i-Align, an interpretable KG alignment model. Unlike the existing KG alignment models, i-Align provides an explanation for each alignment prediction while maintaining high alignment performance. Experts can use the explanation to check the correctness of the alignment prediction. Thus, the high quality of a KG can be maintained during the curation process (e.g., the merging process of two KGs). To this end, a novel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component of i-Align for aggregating information from entities’ neighbors (structures). Trans-GE uses Edge-gated Attention that combines the adjacency matrix and the self-attention matrix to learn a gating mechanism to control the information aggregation from the neighboring entities. It also uses historical embeddings, allowing Trans-GE to be trained over mini-batches, or smaller sub-graphs, to address the scalability issue when encoding a large KG. Another component of i-Align is a Transformer encoder for aggregating entities’ attributes. This way, i-Align can generate explanations in the form of a set of the most influential attributes/neighbors based on attention weights. Extensive experiments are conducted to show the power of i-Align. The experiments include several aspects, such as the model’s effectiveness for aligning KGs, the quality of the generated explanations, and its practicality for aligning large KGs. The results show the effectiveness of i-Align in these aspects. © 2023, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jadhav, Y.
AU  - Berthel, J.
AU  - Hu, C.
AU  - Panat, R.
AU  - Beuth, J.
AU  - Barati Farimani, A.
TI  - StressD: 2D Stress estimation using denoising diffusion model
PY  - 2023
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 416
C7  - 116343
DO  - 10.1016/j.cma.2023.116343
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168751388&doi=10.1016%2fj.cma.2023.116343&partnerID=40&md5=35f5a621481114bdd998440ab7a75a37
AB  - Finite element analysis (FEA), a common approach for simulating stress distribution for a given geometry, is generally associated with high computational cost, especially when high mesh resolution is required. Furthermore, the non-adaptive nature of FEA requires the entire model to be solved even for minor geometric variations creating a bottleneck during iterative design optimization. This necessitates a framework that can efficiently predict stress distribution in geometries based on given boundary and loading conditions. In this paper, we present StressD, a framework for predicting von Mises stress fields based on the denoising diffusion model. The StressD framework involves two models, a U-net-based denoising diffusion model and an auxiliary network to generate and predict stress distribution in structures. The denoising diffusion model generates a normalized stress map based on the given geometry, boundary conditions and loading condition, while the auxiliary network is used to determine the scaling information needed to un-normalize the generated stress map. We evaluate the StressD framework on cantilever structures and show that it is able to accurately predict von Mises stress fields while significantly reducing computational cost compared to traditional FEA. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Sun, X.
AU  - Zhou, J.
AU  - Liu, L.
AU  - Wu, Z.
TI  - CasTformer: A novel cascade transformer towards predicting information diffusion
PY  - 2023
T2  - Information Sciences
VL  - 648
C7  - 119531
DO  - 10.1016/j.ins.2023.119531
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168768594&doi=10.1016%2fj.ins.2023.119531&partnerID=40&md5=2ec403404e1ee73cb22391e5259e1827
AB  - Predicting information diffusion cascade is an essential task in social networks. We mainly focus on predicting the size of the information cascade. The relationships inside a cascade are diverse, including global and relative spatio-temporal relationships, as well as interpersonal influence relationships. These complex relationships between nodes play a crucial role in cascade prediction, but they have not been thoroughly investigated. The Transformer's global receptive field can assist in capturing the relationships between two arbitrary nodes. However, using Transformer directly for a cascade is insufficient without considering its temporal and structural characteristics. In this paper, we propose a novel cascade Transformer for the first time, called CasTformer, specifically designed for cascade size prediction. CasTformer utilizes a global spatio-temporal positional encoding and relative relationship bias matrices on the self-attention mechanism to capture diverse cascade relationships. Moreover, self-knowledge distillation is employed for obtaining a better cascade representation to enhance prediction performance. We use four datasets with nearly millions of cascade samples to validate our model and it achieves training in 3 hours. Experimental results show that it outperforms state-of-the-art methods by an average of 11.9%, 6.1%, and 9.6% on MSLE, MAPE, and R2, respectively. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Sun2023CasTformer
ER  -

TY  - JOUR
AU  - Wu, W.
AU  - Yang, W.
AU  - Ma, W.
AU  - Chen, X.-D.
TI  - How Many Annotations Do We Need for Generalizing New-Coming Shadow Images?
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 11
SP  - 6213
EP  - 6224
DO  - 10.1109/TCSVT.2023.3263903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153342017&doi=10.1109%2fTCSVT.2023.3263903&partnerID=40&md5=9f7616c263dbae209da1da13acd82b00
AB  - Unlabeled data is often used to improve the generalization ability of one segmentation model. However, it tends to neglect the inherent difficulty of unlabeled samples, and then produces inaccurate pseudo masks in some unseen scenes, resulting in severe confirmation bias and potential performance degradation. These motivate two unexplored questions for new-coming data: (1) How many images do we need to annotate; and (2) how to annotate them? In this paper, two kinds of shadow detectors (i.e., SDTR and SDTR+) based on the Transformer and self-training scheme are successively proposed. The main difference between them is whether weak annotations are required for partial unlabeled data. Specifically, in SDTR, we first introduce an image-level sample selection scheme to separate the unlabeled data into reliable and unreliable samples from the holistic prediction-level stability. Then, we perform selective retraining to exploit the unlabeled images progressively in a curriculum learning manner. While in SDTR+, we further provide various weak labels (i.e., point, box and scribble) for the rest unreliable samples and design corresponding loss functions. By doing this, it can achieve a better trade-off between performance improvement and annotation cost. Experimental results on public benchmarks (i.e., SBU, UCF and ISTD) show that both SDTR and SDTR+ can be favorable against state-of-the-art methods.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Belainine, B.
AU  - Sadat, F.
AU  - Boukadoum, M.
TI  - End-to-End Dialogue Generation Using a Single Encoder and a Decoder Cascade With a Multidimension Attention Mechanism
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 11
SP  - 8482
EP  - 8492
DO  - 10.1109/TNNLS.2022.3151347
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125713255&doi=10.1109%2fTNNLS.2022.3151347&partnerID=40&md5=4dca9b548a5374630d2ab3522acb5eb9
AB  - Human dialogues often show underlying dependencies between turns, with each interlocutor influencing the queries/responses of the other. This article follows this by proposing a neural architecture for conversation modeling that looks at the dialogue history of both sides. It consists of a generative model where one encoder feeds three decoders to process three successive turns of dialogue for predicting the next utterance, with a multidimension attention mechanism aggregating the past and current contexts for a cascade effect on each decoder. As a result, a more comprehensive account of the dialogue evolution is obtained than by focusing on a single turn or the last encoder context, or on the user side alone. The response generation performance of the model is evaluated on three corpora of different sizes and topics, and a comparison is made with six recent generative neural architectures, using both automatic metrics and human judgments. Our results show that the proposed architecture equals or improves the state-of-the-art for adequacy and fluency, particularly when large open-domain corpora are used in the training. Moreover, it allows better tracking of the dialogue state evolution for response explainability. © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Chrysostomou, D.
AU  - Yang, H.
TI  - A speech-enabled virtual assistant for efficient human–robot interaction in industrial environments
PY  - 2023
T2  - Journal of Systems and Software
VL  - 205
C7  - 111818
DO  - 10.1016/j.jss.2023.111818
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168410918&doi=10.1016%2fj.jss.2023.111818&partnerID=40&md5=530c8dfded5074c74b94fcbf6f71e4fd
AB  - This paper presents a natural language-enabled virtual assistant (VA), named Max, developed to support flexible and scalable human–robot interactions (HRI) with industrial robots. Regardless of the numerous natural language interfaces already proposed for intuitive HRI on the industrial shop floor, most of those interfaces remain tightly bound with a specific robotic system. Besides, the lack of a natural and efficient human–robot communication protocol hinders the user experience. Therefore three key elements characterize the proposed framework. First, a Client–Server style architecture is introduced so Max can provide a centralized solution for managing and controlling various types of robots deployed on the shop floor. Second, inspired by human–human communication, two conversation strategies, lexical-semantic and general diversion strategies, are used to guide Max's response generation. These conversation strategies were embedded to improve the operator's engagement with the manufacturing tasks. Third, we fine-tuned the state-of-the-art (SOTA) pre-trained model, Bidirectional Encoder Representations from Transformers (BERT), to support a highly accurate prediction of requested intents from the operator and robot services. Multiple experiments were conducted using the latest iteration of our autonomous industrial mobile manipulator, “Little Helper (LH)”, to validate Max's performance in a real manufacturing environment. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Dai, J.
AU  - Li, H.
AU  - Zeng, R.
AU  - Bai, J.
AU  - Zhou, F.
AU  - Pan, J.
TI  - KD-Former: Kinematic and dynamic coupled transformer network for 3D human motion prediction
PY  - 2023
T2  - Pattern Recognition
VL  - 143
C7  - 109806
DO  - 10.1016/j.patcog.2023.109806
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164226850&doi=10.1016%2fj.patcog.2023.109806&partnerID=40&md5=17d6e91b0fe7283274a76a46b949377c
AB  - Recent studies have made remarkable progress on 3D human motion prediction by describing motion with kinematic knowledge. However, kinematics only considers the 3D positions or rotations of human skeletons, failing to reveal the physical characteristics of human motion. Motion dynamics reflects the forces between joints, explicitly encoding the skeleton topology, whereas rarely exploited in motion prediction. In this paper, we propose the Kinematic and Dynamic coupled transFormer (KD-Former), which incorporates dynamics with kinematics, to learn powerful features for high-fidelity motion prediction. Specifically, We first formulate a reduced-order dynamic model of human body to calculate the forces of all joints. Then we construct a non-autoregressive encoder-decoder framework based on the transformer structure. The encoder involves a kinematic encoder and a dynamic encoder, which are respectively responsible for extracting the kinematic and dynamic features for given history sequences via a spatial transformer and a temporal transformer. Future query sequences are decoded in parallel in the decoder by leveraging the encoded kinematic and dynamic information of history sequences. Experiments on Human3.6M and CMU MoCap benchmarks verify the effectiveness and superiority of our method. Code will be available at: https://github.com/wslh852/KD-Former.git. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, J.
AU  - Jiao, L.
AU  - Shang, R.
AU  - Liu, X.
AU  - Li, R.
AU  - Xu, L.
TI  - EPT-Net: Edge Perception Transformer for 3D Medical Image Segmentation
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 11
SP  - 3229
EP  - 3243
DO  - 10.1109/TMI.2023.3278461
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161003792&doi=10.1109%2fTMI.2023.3278461&partnerID=40&md5=d634bba4630ab12b4271fb9ffb7861fe
AB  - The convolutional neural network has achieved remarkable results in most medical image seg- mentation applications. However, the intrinsic locality of convolution operation has limitations in modeling the long-range dependency. Although the Transformer designed for sequence-to-sequence global prediction was born to solve this problem, it may lead to limited positioning capability due to insufficient low-level detail features. Moreover, low-level features have rich fine-grained information, which greatly impacts edge segmentation decisions of different organs. However, a simple CNN module is difficult to capture the edge information in fine-grained features, and the computational power and memory consumed in processing high-resolution 3D features are costly. This paper proposes an encoder-decoder network that effectively combines edge perception and Transformer structure to segment medical images accurately, called EPT-Net. Under this framework, this paper proposes a Dual Position Transformer to enhance the 3D spatial positioning ability effectively. In addition, as low-level features contain detailed information, we conduct an Edge Weight Guidance module to extract edge information by minimizing the edge information function without adding network parameters. Furthermore, we verified the effectiveness of the proposed method on three datasets, including SegTHOR 2019, Multi-Atlas Labeling Beyond the Cranial Vault and the re-labeled KiTS19 dataset called KiTS19-M by us. The experimental results show that EPT-Net has significantly improved compared with the state-of-the-art medical image segmentation method.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Lin, F.
AU  - Wu, S.
AU  - Tian, S.
AU  - Yu, L.
TI  - PRSeg: A Lightweight Patch Rotate MLP Decoder for Semantic Segmentation
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 11
SP  - 6860
EP  - 6871
DO  - 10.1109/TCSVT.2023.3271523
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159683543&doi=10.1109%2fTCSVT.2023.3271523&partnerID=40&md5=7e4ddaf3baed00c128fca737051e0393
AB  - The lightweight MLP-based decoder has become increasingly promising for semantic segmentation. However, the channel-wise MLP cannot expand the receptive fields, lacking the context modeling capacity, which is critical to semantic segmentation. In this paper, we propose a parametric-free patch rotate operation to reorganize the pixels spatially. It first divides the feature map into multiple groups and then rotates the patches within each group. Based on the proposed patch rotate operation, we design a novel segmentation network, named PRSeg, which includes an off-the-shelf backbone and a lightweight Patch Rotate MLP decoder containing multiple Dynamic Patch Rotate Blocks (DPR-Blocks). In each DPR-Block, the fully connected layer is performed following a Patch Rotate Module (PRM) to exchange spatial information between pixels. Specifically, in PRM, the feature map is first split into the reserved part and rotated part along the channel dimension according to the predicted probability of the Dynamic Channel Selection Module (DCSM), and our proposed patch rotate operation is only performed on the rotated part. Extensive experiments on ADE20K, Cityscapes and COCO-Stuff 10K datasets prove the effectiveness of our approach. We expect that our PRSeg can promote the development of MLP-based decoder in semantic segmentation.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Guo, F.
TI  - Online object tracking based interactive attention
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 236
C7  - 103809
DO  - 10.1016/j.cviu.2023.103809
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170429749&doi=10.1016%2fj.cviu.2023.103809&partnerID=40&md5=0fdd9f6c5c42cd1796f56a7c8f47df9f
AB  - By embedding Transformer into the Siamese tracking framework, some Transformer-based Siamese tracking network are proposed, such as TransT and SwinTrack. Nevertheless, the existing Transformer-based Siamese tracking networks do not fully utilize the object information of template branch, and their position encoding methods cannot accurately perceive the object position. Aiming at these problems, a novel Transformer-based Siamese tracking network, which includes feature extraction, feature fusion and prediction head, is proposed in this work. Firstly, an interactive attention calculation module for template branch and search branch is designed to enhance the feature extraction capability of the network for the object region and suppress the background interference. In addition, to address the problem that the existing Transformer-based feature fusion network is not sensitive enough to the object location region, a position encoding method that characterizes the relative distance is proposed to enhance the perception ability of the object location and reduce network parameters. Then, the contrastive loss is introduced to enhance the discriminative ability of the classification layer between foreground and background, and to effectively deal with the interference of similar objects in the background. Extensive experiments with state-of-the-art trackers are carried out on four challenging visual object tracking benchmarks: GOT-10k, LaSOText, TLP, and TrackingNet. Experimental results demonstrate the proposed method is more robust on multiple challenges and can achieve considerable performances with AO of 70.1% on GOT-10k, SUC score of 45.5% on LaSOT ext, 56.9% on TLP, and 79.7% on TrackingNet datasets. It runs faster (7.1G MACs) and occupies less memory (21M), making it more suitable for practical applications. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tong, J.
AU  - Xie, L.
AU  - Yang, W.
AU  - Zhang, K.
AU  - Zhao, J.
TI  - Enhancing time series forecasting: A hierarchical transformer with probabilistic decomposition representation
PY  - 2023
T2  - Information Sciences
VL  - 647
C7  - 119410
DO  - 10.1016/j.ins.2023.119410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169560816&doi=10.1016%2fj.ins.2023.119410&partnerID=40&md5=bfcc66d7c4128b9c879a55f60538ed00
AB  - Time series forecasting is crucial for several fields, such as disaster warning, weather prediction, and energy consumption. Transformer-based models are considered to have revolutionized the field of time series forecasting. However, the autoregressive form of the Transformer gives rise to cumulative errors in the inference stage. Furthermore, the complex temporal pattern of the time series leads to increased difficulty for the models in mining reliable temporal dependencies. In this paper, we propose a hierarchical Transformer with probabilistic decomposition representation, which provides a flexible framework for hierarchical and decomposable forecasts for time series. The hierarchical mechanism utilizes the forecasting results of the Transformer as conditional information for the generative model, performing sequence-level forecasts to approximate the ground truth, which can mitigate the cumulative error of the autoregressive Transformer. In addition, the conditional generative model encodes historical and predictive information into the latent space and reconstructs typical patterns from the latent space, including seasonality and trend terms. The process provides a flexible framework for the separation of complex patterns through the interaction of information in the latent space. Extensive experiments on several datasets demonstrate the effectiveness and robustness of the model, indicating that it compares favorably with the state of the art. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; FMS:B; 
LB  - Tong2023Enhancing
ER  -

TY  - JOUR
AU  - Sun, S.
AU  - Huang, D.
AU  - Tao, X.
AU  - Pan, C.
AU  - Liu, G.
AU  - Chen, C.
TI  - Boosting Scene Graph Generation with Contextual Information
PY  - 2023
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 2
C7  - 3615868
DO  - 10.1145/3615868
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176759372&doi=10.1145%2f3615868&partnerID=40&md5=621cac1626167c1eb621b539a2ce1cb2
AB  - Scene graph generation (SGG) has been developed to detect objects and their relationships from the visual data and has attracted increasing attention in recent years. Existing works have focused on extracting object context for SGG. However, very few works have attempted to exploit implicit contextual correlations among relationships of the objects. Furthermore, most existing SGG schemes rely on high-level features to predict the predicates while overlooking the potential inherent association of low-level features with the object relationships. We present in this article a novel scheme to capture enhanced contextual information for both objects and relationships. We design a Dual-branch Context Analysis Transformer (DCAT) architecture to extract both object context and relationship context from the visual data with dual transformer branches and then effectively fuse both high-level and low-level features by an adaptive approach to facilitate relationship prediction. Specifically, we first conduct feature representation learning to enrich relation representations by the visual, spatial, and linguistic feature extractors. Next, two transformer branches are designed to leverage the modeling of global associative interaction and mine the hidden association among objects and relationships. Then, we devise a novel feature disentangling method to decouple contextualized high-level features with guidance from the visual semantics. Finally, we develop a refined attention module to perform low-level feature recalibration for the refinement of the final predicate prediction. Experiments on Visual Genome and Action Genome datasets demonstrate the effectiveness of DCAT for both image and video SGG settings. Moreover, we also test the quality of the generated image scene graphs to verify the generalizability on downstream tasks like sentence-to-graph retrieval and image retrieval.  © 2023 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, J.
AU  - Ma, T.
AU  - Chen, H.
AU  - Lai, M.
AU  - Ju, Z.
AU  - Xu, Y.
TI  - Marrying Global-Local Spatial Context for Image Patches in Computer-Aided Assessment
PY  - 2023
T2  - IEEE Transactions on Systems, Man, and Cybernetics: Systems
VL  - 53
IS  - 11
SP  - 7099
EP  - 7111
DO  - 10.1109/TSMC.2023.3290205
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165309391&doi=10.1109%2fTSMC.2023.3290205&partnerID=40&md5=8e47b2f706f5df3b035fff3f376d5b58
AB  - Computer-aided assessment using whole slide images (WSIs) is one of the critical steps in clinical procedures. How do doctors recognize cancer in a WSI? A quick answer is that they consider the spatial structure of a WSI rather than only considering single patches. We argue that two clues are essential for computer-aided deep learning: 1) global spatial context and 2) local semantic information. This is because local, semi-local, and global tissue observing are the principal assessment means of pathologists, perfectly corresponding with both clues. However, most existing methods only consider local spatial information learning within each patch rather than developing an effective local-to-global reaction, leading to an incapable of capturing robust and enriched representation. Toward a new area for computer-aided assessment, we propose novel neural networks to learn the global-local spatial context in WSIs, called GLSCL. The GLSCL is among the first trials that understand both clues for WSI understanding. Furthermore, the proposed novel operators enable the GLSCL to learn spatial semantic representation sufficiently. We evaluate the GLSCL using renal cell carcinoma (RCC) samples with synthetic ambiguity collected from the public benchmark and clinical procedures. Enhanced by global and local spatial information, the GLSCL achieves state-of-the-art performance, including classification accuracy, survival prediction index, and cancer tissue attention rate.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; AJG:3; zdy:3; 
LB  - Yu2023Marrying
ER  -

TY  - JOUR
AU  - Tian, R.
AU  - Wang, C.
AU  - Hu, J.
AU  - Ma, Z.
TI  - Multi-scale spatial-temporal aware transformer for traffic prediction
PY  - 2023
T2  - Information Sciences
VL  - 648
C7  - 119557
DO  - 10.1016/j.ins.2023.119557
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169003980&doi=10.1016%2fj.ins.2023.119557&partnerID=40&md5=2e119029da31b9cc765d44e837ce7924
AB  - Traffic prediction is an important part of smart city management. Accurate traffic prediction can be deployed in urban applications such as congestion alerting and route planning, thus providing sustainable services to the public or relevant departments. Although some improvements have been made in existing traffic prediction methods, there are challenges due to the following: (1) Time series has multi-scale nature, that is, from different scale time ranges, traffic flow changes show different trends; (2) Spatial heterogeneity, meaning that traffic conditions in similar functional areas are usually similar. This task remains difficult. To address the above challenges, we propose a new spatial-temporal prediction method, namely Multi-Scale Spatial-Temporal Aware Transformer (MSSTAT), which is a Transformer architecture with multi-scale characteristics. Specifically, compared to the input of encoder, the input of different decoder layers has different scale information, MSSTAT synchronizes model the connection between time steps and scale information by a kind of Parallel Cross Multi-Head Attention, which gives each time step several times the perceived field while also being able to weaken the impact brought by anomaly point. In addition, to add connections between regions with similar functions, we map the traffic data of each node as a probability distribution and then measure the similarity between the nodes by the Wasserstein Distance, which leads to our proposed spatial-temporal aware adjacency matrix. Experimental results on four traffic flow datasets show that MSSTAT outperforms the state-of-the-art baseline. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; FMS:B; 
LB  - Tian2023Multi-scale
ER  -

TY  - JOUR
AU  - Rao, Y.
AU  - Ju, Y.
AU  - Li, C.
AU  - Rigall, E.
AU  - Yang, J.
AU  - Fan, H.
AU  - Dong, J.
TI  - Learning General Descriptors for Image Matching With Regression Feedback
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 11
SP  - 6693
EP  - 6707
DO  - 10.1109/TCSVT.2023.3267279
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153491806&doi=10.1109%2fTCSVT.2023.3267279&partnerID=40&md5=5e3b4188f8089b00c72fccfac03f14c1
AB  - Recent advances on feature descriptors for image matching put more emphasis on encoding invariances (e.g. illumination invariance) to promote the descriptors' discriminative power. However, according to the information entropy, more invariance implies greater certainty and less informativeness in a descriptor. Consequently, descriptors encoding too many invariances usually show poor generalization to unknown image changes, lacking enough informativeness to cover the large uncertainty in unseen scenes. This limits the application scenarios of learned descriptors. In this paper, we propose to alleviate this issue from the perspective of informativeness and we thus design hierarchical consistent constraint by introducing regression feedback in a self-supervised manner. Combined with the hardest-within-batch matching constraint, we form a novel dual supervision framework, to encourage the descriptor to learn an informative representation while maintaining a good discriminative power. Moreover, to fully mine the context information hidden in image and boost the informativeness in turn, we present AANet, a descriptor network that efficiently predicts dense description by the powerful Attentional Aggregation of multi-level features. Experiments across challenging feature matching on HPatches, RDNIM datasets, and visual localization tasks on Aachen Day-night dataset show that our method outperforms recent state-of-the-art descriptors while keeping encouraging efficiency. The application of visual 3D reconstruction on various scenarios also demonstrates the high generalization ability of our method.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tao, R.
AU  - Zou, X.
AU  - Zheng, G.
TI  - LAST: LAtent Space-Constrained Transformers for Automatic Surgical Phase Recognition and Tool Presence Detection
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 11
SP  - 3256
EP  - 3268
DO  - 10.1109/TMI.2023.3279838
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161042896&doi=10.1109%2fTMI.2023.3279838&partnerID=40&md5=feb9f7bbceb16d5633a6f2db78561085
AB  - When developing context-aware systems, automatic surgical phase recognition and tool presence detection are two essential tasks. There exist previous attempts to develop methods for both tasks but majority of the existing methods utilize a frame-level loss function (e.g., cross-entropy) which does not fully leverage the underlying semantic structure of a surgery, leading to sub-optimal results. In this paper, we propose multi-task learning-based, LAtent Space-constrained Transformers, referred as LAST, for automatic surgical phase recognition and tool presence detection. Our design features a two-branch transformer architecture with a novel and generic way to leverage video-level semantic information during network training. This is done by learning a non-linear compact presentation of the underlying semantic structure information of surgical videos through a transformer variational autoencoder (VAE) and by encouraging models to follow the learned statistical distributions. In other words, LAST is of structure-aware and favors predictions that lie on the extracted low dimensional data manifold. Validated on two public datasets of the cholecystectomy surgery, i.e., the Cholec80 dataset and the M2cai16 dataset, our method achieves better results than other state-of-the-art methods. Specifically, on the Cholec80 dataset, our method achieves an average accuracy of 93.12±4.71%, an average precision of 89.25±5.49%, an average recall of 90.10±5.45% and an average Jaccard of 81.11 ±7.62% for phase recognition, and an average mAP of 95.15±3.87% for tool presence detection. Similar superior performance is also observed when LAST is applied to the M2cai16 dataset.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, M.
AU  - Zhu, X.
AU  - Wang, H.
AU  - Cao, S.
AU  - Liu, C.
AU  - Song, Q.
TI  - STDFormer: Spatial-Temporal Motion Transformer for Multiple Object Tracking
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 11
SP  - 6571
EP  - 6594
DO  - 10.1109/TCSVT.2023.3263884
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153344755&doi=10.1109%2fTCSVT.2023.3263884&partnerID=40&md5=332344c8d5d4af782d2ab19d36e1492f
AB  - Mainstream multi-object tracking methods exploit appearance information and/or motion information to achieve interframe association. However, dealing with similar appearance and occlusion is a challenge for appearance information, while motion information is limited by linear assumptions and is prone to failure in nonlinear motion patterns. In this work, we disregard appearance clues and propose a pure motion tracker to address the above issues. It dexterously utilizes Transformer to estimate complex motion and achieves high-performance tracking with low computing resources. Furthermore, contrastive learning is introduced to optimize feature representation for robust association. Specifically, we first exploit the long-range modeling capability of Transformer to mine intention information in temporal motion and decision information in spatial interaction and introduce prior detection to constrain the range of motion estimation. Then, we introduce contrastive learning as an auxiliary task to extract reliable motion features to compute affinity and introduce bidirectional matching to improve the affinity computation distribution. In addition, given that both tasks are dedicated to narrowing the embedding distance between the motion features of the tracked object and the detection features, we design a joint-motion-and-association framework to unify the above two tasks in one framework for optimization. The experimental results achieved with three benchmark datasets, MOT17, MOT20 and DanceTrack, verify the effectiveness of our proposed method. Compared with state-of-the-art methods, the proposed STDFormer sets a new state-of-the-art on DanceTrack and achieves competitive performance on MOT17 and MOT20. This demonstrates the advantage of our method in handling associations under similar appearance, occlusion or nonlinear motion. At the same time, the significant advantages of the proposed method over Transformer-based and contrastive learning-based methods suggest a new direction for the application of Transformer and contrastive learning in MOT. In addition, to verify the generalization of STDFormer in unmanned aerial vehicle (UAV) videos, we also evaluate STDFormer on VisDrone2019. The results show that STDFormer achieves state-of-the-art performance on VisDrone2019, which proves that it can handle small-scale object associations in UAV videos well. The code is available at https://github.com/Xiaotong-Zhu/STDFormer.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Yu, L.
AU  - Ding, X.
AU  - Liao, X.
AU  - Wang, L.
TI  - Shared-Specific Feature Learning With Bottleneck Fusion Transformer for Multi-Modal Whole Slide Image Analysis
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 11
SP  - 3374
EP  - 3383
DO  - 10.1109/TMI.2023.3287256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162901224&doi=10.1109%2fTMI.2023.3287256&partnerID=40&md5=27f746701dc380e79bc9d68206cd6648
AB  - The fusion of multi-modal medical data is essential to assist medical experts to make treatment decisions for precision medicine. For example, combining the whole slide histopathological images (WSIs) and tabular clinical data can more accurately predict the lymph node metastasis (LNM) of papillary thyroid carcinoma before surgery to avoid unnecessary lymph node resection. However, the huge-sized WSI provides much more high-dimensional information than low-dimensional tabular clinical data, making the information alignment challenging in the multi-modal WSI analysis tasks. This paper presents a novel transformer-guided multi-modal multi-instance learning framework to predict lymph node metastasis from both WSIs and tabular clinical data. We first propose an effective multi-instance grouping scheme, named siamese attention-based feature grouping (SAG), to group high-dimensional WSIs into representative low-dimensional feature embeddings for fusion. We then design a novel bottleneck shared-specific feature transfer module (BSFT) to explore the shared and specific features between different modalities, where a few learnable bottleneck tokens are utilized for knowledge transfer between modalities. Moreover, a modal adaptation and orthogonal projection scheme were incorporated to further encourage BSFT to learn shared and specific features from multi-modal data. Finally, the shared and specific features are dynamically aggregated via an attention mechanism for slide-level prediction. Experimental results on our collected lymph node metastasis dataset demonstrate the efficiency of our proposed components and our framework achieves the best performance with AUC (area under the curve) of 97.34%, outperforming the state-of-the-art methods by over 1.27%. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Geng, M.
AU  - Cai, Z.
AU  - Zhu, Y.
AU  - Chen, X.
AU  - Lee, D.-H.
TI  - Multimodal Vehicular Trajectory Prediction With Inverse Reinforcement Learning and Risk Aversion at Urban Unsignalized Intersections
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 11
SP  - 12227
EP  - 12240
DO  - 10.1109/TITS.2023.3285891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163502848&doi=10.1109%2fTITS.2023.3285891&partnerID=40&md5=50c4be9c2fcea48823d72ff98b2f4172
AB  - Understanding human drivers' intentions and predicting their future motions are significant to connected and autonomous vehicles and traffic safety and surveillance systems. Predicting multimodal vehicular trajectories at urban unsignalized intersections remains challenging due to dynamic traffic flow and uncertainty of human drivers' maneuvers. In this paper, we propose a comprehensive trajectory prediction framework that combines a multimodal trajectory generation network with inverse reinforcement learning (IRL) and risk aversion (RA) modules. Specifically, we first construct a multimodal spatial-temporal Transformer network (mmSTTN) to generate multiple trajectory candidates, using trajectory coordinates as inputs. Accounting for spatio-temporal features, we formulate the IRL reward function for evaluating all candidate trajectories. The optimal trajectory is then selected based on the computed rewards, a process that mimics human drivers' decision-making. We further develop the RA module based on the driving risk field for optimal risk-averse trajectory prediction. We conduct experiments and ablation studies using the inD dataset at an urban unsignalized intersection, demonstrating impressive human trajectory alignment, prediction accuracy, and the ability to generate risk-averse trajectories. Our proposed framework reduces prediction errors and driving risks by 25% and 30% compared to baseline methods. Results validate vehicles' human-like risk-averse diverging-and-concentrating behavior as they traverse the intersection. The proposed framework presents a novel approach for forecasting multimodal vehicular trajectories by imitating human drivers and incorporating physics-based risk information derived from the driving field. This research offers a promising direction for enhancing the safety and efficiency of connected and autonomous vehicles navigating urban environments. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; FMS:B; 
LB  - Geng2023Multimodal
ER  -

TY  - JOUR
AU  - Zhang, Y.-Z.
AU  - Bai, Z.
AU  - Imoto, S.
TI  - Investigation of the BERT model on nucleotide sequences with non-standard pre-training and evaluation of different k-mer embeddings
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 10
C7  - btad617
DO  - 10.1093/bioinformatics/btad617
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175357489&doi=10.1093%2fbioinformatics%2fbtad617&partnerID=40&md5=b8c46719ceaeb06dd924edc67cd1948c
AB  - Motivation: In recent years, pre-training with the transformer architecture has gained significant attention. While this approach has led to notable performance improvements across a variety of downstream tasks, the underlying mechanisms by which pre-training models influence these tasks, particularly in the context of biological data, are not yet fully elucidated. Results: In this study, focusing on the pre-training on nucleotide sequences, we decompose a pre-training model of Bidirectional Encoder Representations from Transformers (BERT) into its embedding and encoding modules to analyze what a pre-trained model learns from nucleotide sequences. Through a comparative study of non-standard pre-training at both the data and model levels, we find that a typical BERT model learns to capture overlapping-consistent k-mer embeddings for its token representation within its embedding module. Interestingly, using the k-mer embeddings pre-trained on random data can yield similar performance in downstream tasks, when compared with those using the k-mer embeddings pre-trained on real biological sequences. We further compare the learned k-mer embeddings with other established k-mer representations in downstream tasks of sequence-based functional prediction. Our experimental results demonstrate that the dense representation of k-mers learned from pre-training can be used as a viable alternative to one-hot encoding for representing nucleotide sequences. Furthermore, integrating the pre-trained k-mer embeddings with simpler models can achieve competitive performance in two typical downstream tasks.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Buton, N.
AU  - Coste, F.
AU  - Le Cunff, Y.
TI  - Predicting enzymatic function of protein sequences with attention
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 10
C7  - btad620
DO  - 10.1093/bioinformatics/btad620
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175356563&doi=10.1093%2fbioinformatics%2fbtad620&partnerID=40&md5=bed823e58fe5d08ed42d15c2286094a1
AB  - Motivation: There is a growing number of available protein sequences, but only a limited amount has been manually annotated. For example, only 0.25% of all entries of UniProtKB are reviewed by human annotators. Further developing automatic tools to infer protein function from sequence alone can alleviate part of this gap. In this article, we investigate the potential of Transformer deep neural networks on a specific case of functional sequence annotation: the prediction of enzymatic classes. Results: We show that our EnzBert transformer models, trained to predict Enzyme Commission (EC) numbers by specialization of a protein language model, outperforms state-of-the-art tools for monofunctional enzyme class prediction based on sequences only. Accuracy is improved from 84% to 95% on the prediction of EC numbers at level two on the EC40 benchmark. To evaluate the prediction quality at level four, the most detailed level of EC numbers, we built two new time-based benchmarks for comparison with state-of-the-art methods ECPred and DeepEC: the macro-F1 score is respectively improved from 41% to 54% and from 20% to 26%. Finally, we also show that using a simple combination of attention maps is on par with, or better than, other classical interpretability methods on the EC prediction task. More specifically, important residues identified by attention maps tend to correspond to known catalytic sites. Quantitatively, we report a max F-Gain score of 96.05%, while classical interpretability methods reach 91.44% at best.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Chae, S.
AU  - Davoudi, A.
AU  - Song, J.
AU  - Evans, L.
AU  - Hobensack, M.
AU  - Bowles, K.H.
AU  - McDonald, M.V.
AU  - Barrón, Y.
AU  - Rossetti, S.C.
AU  - Cato, K.
AU  - Sridharan, S.
AU  - Topaz, M.
TI  - Predicting emergency department visits and hospitalizations for patients with heart failure in home healthcare using a time series risk model
PY  - 2023
T2  - Journal of the American Medical Informatics Association
VL  - 30
IS  - 10
SP  - 1622
EP  - 1633
DO  - 10.1093/jamia/ocad129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174080253&doi=10.1093%2fjamia%2focad129&partnerID=40&md5=1f463c265510ec0baf0a7c8e77827d69
AB  - Objectives: Little is known about proactive risk assessment concerning emergency department (ED) visits and hospitalizations in patients with heart failure (HF) who receive home healthcare (HHC) services. This study developed a time series risk model for predicting ED visits and hospitalizations in patients with HF using longitudinal electronic health record data. We also explored which data sources yield the best-performing models over various time windows. Materials and Methods: We used data collected from 9362 patients from a large HHC agency. We iteratively developed risk models using both structured (eg, standard assessment tools, vital signs, visit characteristics) and unstructured data (eg, clinical notes). Seven specific sets of variables included: (1) the Outcome and Assessment Information Set, (2) vital signs, (3) visit characteristics, (4) rule-based natural language processing-derived variables, (5) term frequency-inverse document frequency variables, (6) Bio-Clinical Bidirectional Encoder Representations from Transformers variables, and (7) topic modeling. Risk models were developed for 18 time windows (1–15, 30, 45, and 60 days) before an ED visit or hospitalization. Risk prediction performances were compared using recall, precision, accuracy, F1, and area under the receiver operating curve (AUC). Results: The best-performing model was built using a combination of all 7 sets of variables and the time window of 4 days before an ED visit or hospitalization (AUC = 0.89 and F1 = 0.69). Discussion and Conclusion: This prediction model suggests that HHC clinicians can identify patients with HF at risk for visiting the ED or hospitalization within 4 days before the event, allowing for earlier targeted interventions. VC The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Valencia, J.D.
AU  - Hendrix, D.A.
TI  - Improving deep models of protein-coding potential with a Fourier-transform architecture and machine translation task
PY  - 2023
T2  - PLoS Computational Biology
VL  - 19
IS  - 10 October
C7  - e1011526
DO  - 10.1371/journal.pcbi.1011526
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174544045&doi=10.1371%2fjournal.pcbi.1011526&partnerID=40&md5=14d595c7ef56cb1436150af8606986ec
AB  - Ribosomes are information-processing macromolecular machines that integrate complex sequence patterns in messenger RNA (mRNA) transcripts to synthesize proteins. Studies of the sequence features that distinguish mRNAs from long noncoding RNAs (lncRNAs) may yield insight into the information that directs and regulates translation. Computational methods for calculating protein-coding potential are important for distinguishing mRNAs from lncRNAs during genome annotation, but most machine learning methods for this task rely on previously known rules to define features. Sequence-to-sequence (seq2seq) models, particularly ones using transformer networks, have proven capable of learning complex grammatical relationships between words to perform natural language translation. Seeking to leverage these advancements in the biological domain, we present a seq2seq formulation for predicting protein-coding potential with deep neural networks and demonstrate that simultaneously learning translation from RNA to protein improves classification performance relative to a classification-only training objective. Inspired by classical signal processing methods for gene discovery and Fourier-based image-processing neural networks, we introduce LocalFilterNet (LFNet). LFNet is a network architecture with an inductive bias for modeling the three-nucleotide periodicity apparent in coding sequences. We incorporate LFNet within an encoder-decoder framework to test whether the translation task improves the classification of transcripts and the interpretation of their sequence features. We use the resulting model to compute nucleotide-resolution importance scores, revealing sequence patterns that could assist the cellular machinery in distinguishing mRNAs and lncRNAs. Finally, we develop a novel approach for estimating mutation effects from Integrated Gradients, a backpropagation-based feature attribution, and characterize the difficulty of efficient approximations in this setting. Copyright: © 2023 Valencia, Hendrix. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Zhang, L.
AU  - Fan, H.
AU  - Luo, T.
TI  - Collaborative three-stream transformers for video captioning
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 235
C7  - 103799
DO  - 10.1016/j.cviu.2023.103799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168002959&doi=10.1016%2fj.cviu.2023.103799&partnerID=40&md5=0b0c5766b88140bd26e06fb9d68c8915
AB  - As the most critical components in a sentence, subject, predicate and object require special attention in the video captioning task. To implement this idea, we design a novel framework, named COllaborative three-Stream Transformers (COST), to model the three parts separately and complement each other for better representation. Specifically, COST is formed by three branches of transformers to exploit the visual-linguistic interactions of different granularities in spatial–temporal domain between videos and text, detected objects and text, and actions and text. Meanwhile, we propose a cross-granularity attention module to align the interactions modeled by the three branches of transformers, then the three branches of transformers can support each other to exploit the most discriminative semantic information of different granularities for accurate predictions of captions. The whole model is trained in an end-to-end fashion. Extensive experiments conducted on three large-scale challenging datasets, i.e., YouCookII, ActivityNet Captions and MSVD, demonstrate that the proposed method performs favorably against the state-of-the-art methods. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Ai, J.
AU  - Lu, M.
AU  - Wang, J.
AU  - Shi, H.
TI  - Semantic feature learning for software defect prediction from source code and external knowledge
PY  - 2023
T2  - Journal of Systems and Software
VL  - 204
C7  - 111753
DO  - 10.1016/j.jss.2023.111753
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162135348&doi=10.1016%2fj.jss.2023.111753&partnerID=40&md5=a9932d7b4fea55da8f7e67f4bdbab497
AB  - Software defects not only reduce operational reliability but also significantly increase overall maintenance costs. Consequently, it is necessary to predict software defects at an early stage. Existing software defect prediction studies work with artificially designed metrics or features extracted from source code by machine learning-based approaches to perform classification. However, these methods fail to make full use of the defect-related information other than code, such as comments in codes and commit messages. Therefore, in this paper, additional information extracted from natural language text is combined with the programming language codes to enrich the semantic features. A novel model based on Transformer architecture and multi-channel CNN, PM2-CNN, is proposed for software defect prediction. Pretrained language model and CNN-based classifier are utilized in the model to obtain context-sensitive representations and capture the local correlation of sequences. A large and widely used dataset is utilized to verify the effectiveness of the proposed method. The results show that the proposed method has improvements in generic evaluation metrics compared with the optimal baseline method. Accordingly, external information can have a positive impact on software defect prediction, and our model effectively incorporates such information to improve detection performance. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Yu, L.
AU  - Xiang, W.
AU  - Fang, J.
AU  - Chen, Y.-P.P.
AU  - Chi, L.
TI  - eX-ViT: A Novel explainable vision transformer for weakly supervised semantic segmentation
PY  - 2023
T2  - Pattern Recognition
VL  - 142
C7  - 109666
DO  - 10.1016/j.patcog.2023.109666
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160713461&doi=10.1016%2fj.patcog.2023.109666&partnerID=40&md5=aa91dc32f6f14801054498f2ec61894a
AB  - Recently vision transformer models have become prominent models for a multitude of vision tasks. These models, however, are usually opaque with weak feature interpretability, making their predictions inaccessible to the users. While there has been a surge of interest in the development of post-hoc solutions that explain model decisions, these methods can not be broadly applied to different transformer architectures, as rules for interpretability have to change accordingly based on the heterogeneity of data and model structures. Moreover, there is no method currently built for an intrinsically interpretable transformer, which is able to explain its reasoning process and provide a faithful explanation. To close these crucial gaps, we propose a novel vision transformer dubbed the eXplainable Vision Transformer (eX-ViT), an intrinsically interpretable transformer model that is able to jointly discover robust interpretable features and perform the prediction. Specifically, eX-ViT is composed of the Explainable Multi-Head Attention (E-MHA) module, the Attribute-guided Explainer (AttE) module with the self-supervised attribute-guided loss. The E-MHA tailors explainable attention weights that are able to learn semantically interpretable representations from tokens in terms of model decisions with noise robustness. Meanwhile, AttE is proposed to encode discriminative attribute features for the target object through diverse attribute discovery, which constitutes faithful evidence for the model predictions. Additionally, we have developed a self-supervised attribute-guided loss for our eX-ViT architecture, which utilizes both the attribute discriminability mechanism and the attribute diversity mechanism to enhance the quality of learned representations. As a result, the proposed eX-ViT model can produce faithful and robust interpretations with a variety of learned attributes. To verify and evaluate our method, we apply the eX-ViT to several weakly supervised semantic segmentation (WSSS) tasks, since these tasks typically rely on accurate visual explanations to extract object localization maps. Particularly, the explanation results obtained via eX-ViT are regarded as pseudo segmentation labels to train WSSS models. Comprehensive simulation results illustrate that our proposed eX-ViT model achieves comparable performance to supervised baselines, while surpassing the accuracy and interpretability of state-of-the-art black-box methods using only image-level labels. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Papa, L.
AU  - Russo, P.
AU  - Amerini, I.
TI  - METER: A Mobile Vision Transformer Architecture for Monocular Depth Estimation
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 10
SP  - 5882
EP  - 5893
DO  - 10.1109/TCSVT.2023.3260310
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151567085&doi=10.1109%2fTCSVT.2023.3260310&partnerID=40&md5=525cc7805441c48980acc3763e1127d8
AB  - Depth estimation is a fundamental knowledge for autonomous systems that need to assess their own state and perceive the surrounding environment. Deep learning algorithms for depth estimation have gained significant interest in recent years, owing to the potential benefits of this methodology in overcoming the limitations of active depth sensing systems. Moreover, due to the low cost and size of monocular cameras, researchers have focused their attention on monocular depth estimation (MDE), which consists in estimating a dense depth map from a single RGB video frame. State of the art MDE models typically rely on vision transformers (ViT) architectures that are highly deep and complex, making them unsuitable for fast inference on devices with hardware constraints. Purposely, in this paper, we address the problem of exploiting ViT in MDE on embedded devices. Those systems are usually characterized by limited memory capabilities and low-power CPU/GPU. We propose METER, a novel lightweight vision transformer architecture capable of achieving state of the art estimations and low latency inference performances on the considered embedded hardwares: NVIDIA Jetson TX1 and NVIDIA Jetson Nano. We provide a solution consisting of three alternative configurations of METER, a novel loss function to balance pixel estimation and reconstruction of image details, and a new data augmentation strategy to improve the overall final predictions. The proposed method outperforms previous lightweight works over the two benchmark datasets: the indoor NYU Depth v2 and the outdoor KITTI.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, B.
AU  - Fu, X.
AU  - Luo, C.
AU  - Ye, Y.
AU  - Li, X.
AU  - Jing, L.
TI  - Cross-Domain Aspect-Based Sentiment Classification by Exploiting Domain- Invariant Semantic-Primary Feature
PY  - 2023
T2  - IEEE Transactions on Affective Computing
VL  - 14
IS  - 4
SP  - 3106
EP  - 3119
DO  - 10.1109/TAFFC.2023.3239540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147289868&doi=10.1109%2fTAFFC.2023.3239540&partnerID=40&md5=3d2388edba3e88da382f43a3240d973b
AB  - Aspect-based sentiment analysis is an important task in fine-grained sentiment analysis, which aims to infer the sentiment towards a given aspect. Previous studies have shown notable success when sufficient labeled training data is available. However, annotating adequate data is labor-intensive, which sets substantial barriers for generalizing the sentiment predictor to the new domain. Two main challenges exist in cross-domain aspect-based sentiment analysis. One challenge is acquiring the domain-invariant knowledge; the other challenge is mining the syntactic-related words towards the aspect-term. In this article, we propose a transformer-based semantic-primary knowledge transferring network (TSPKT) for cross-domain aspect-term sentiment analysis, which utilizes semantic-primary knowledge as a bridge to enable knowledge transfer across domains. Specifically, we first build an S-Graph from external semantic lexicons, and extract the semantic-primary knowledge from the S-Graph. Second, AoaGraphormer is proposed to learn the syntactically relevant words towards the aspect-term. Third, we extend the standard biLSTM classifier to fully integrate the semantic-primary knowledge by adding a novel knowledge-aware memory unit (KAMU) to the biLSTM cell. Extensive experiments on six cross-domain setups demonstrate the superiority of TSPKT against the state-of-the-art baseline methods. © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Wu, D.
AU  - Boulet, B.
TI  - MetaProbformer for Charging Load Probabilistic Forecasting of Electric Vehicle Charging Stations
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 10
SP  - 10445
EP  - 10455
DO  - 10.1109/TITS.2023.3276947
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161066186&doi=10.1109%2fTITS.2023.3276947&partnerID=40&md5=ba14cb69d5a8b5a9c6a52ceb08286c02
AB  - The penetration of electric vehicles (EV) has been increasing rapidly in recent years. Electric vehicle charging load poses a huge demand on the power grids. The forecasting for electric vehicle charging load, especially for the charging load of EV charging stations, is of significant importance for the safe operation of power grids. However, most of the existing forecasting methods fail to capture the long-term dependencies efficiently and assume the availability of a large amount of training data. Hence, they cannot address newly built charging stations with scarce historical charging load data. Meanwhile, most of the methods focus on point forecasting, which lacks risk consideration. In this work, we aim to leverage the benefits of Transformer-based models for EV charging forecasting. Specifically, we propos Probformer, a Transformer-based forecasting model for charging load forecasting. To enable Probformer to adapt fast to unseen environments, we further extend it to MetaProbformer, a meta-learning-based forecasting framework. Extensive experiments have been done on real-world datasets for both point forecasting and probabilistic forecasting. Experimental results show that our methods can consistently outperform baseline methods by a large margin.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2023MetaProbformer
ER  -

TY  - JOUR
AU  - Yan, C.
AU  - Li, X.
AU  - Zhang, Y.
AU  - Wang, Z.
AU  - Wan, Y.
TI  - MIN: multi-dimensional interest network for click-through rate prediction
PY  - 2023
T2  - Knowledge and Information Systems
VL  - 65
IS  - 10
SP  - 3945
EP  - 3965
DO  - 10.1007/s10115-023-01885-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159378461&doi=10.1007%2fs10115-023-01885-8&partnerID=40&md5=a1ee3d8af012bb9b4e6c979cce3bfc98
AB  - Click-through rate (CTR) prediction is a critical task in recommender systems and online advertising systems. The extensive collection of behavior data has become popular for building prediction models by capturing user interests from behavior sequences. There are two types of entities involved in behavior sequences, users and items, which form three kinds of relationships: user-to-user, user-to-item, and item-to-item. Most related work focuses on only one or two of these relationships, often ignoring the association between users, which also helps discover potential user interests. In this paper, we consider all three relationships useful and propose a Multi-dimensional Interest Network (MIN) to focus on their impact on CTR prediction simultaneously. It consists of three sub-networks that capture users’ preferences regarding group interests and individual interests. Specifically, the u-u sub-network models the relationship between the target user and those who have clicked on the target item. It takes user representations learned from behavior sequences via transformer as input. Two other sub-networks capture the individual interest of the target user. The u-i sub-network models the relationship between the target user and the target item. The i-i sub-network models the relationship between the target item and the items the target user has interacted with in the past time. Extensive evaluations on the real datasets show that our MIN model outperforms the state-of-the-art solutions in prediction accuracy (+ 5.0% in AUC and − 17.2% in Logloss, averagely). The ablation experiments also validate that each sub-network in MIN helps with improving the CTR prediction performance by using the u-u sub-network playing a more critical role. The source code is available at https://github.com/cocolixiao/MIN . © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, H.
AU  - Fan, X.
AU  - Hou, Y.
AU  - Pei, W.
AU  - Ge, H.
AU  - Yang, X.
AU  - Zhou, D.
AU  - Zhang, Q.
AU  - Zhang, M.
TI  - Toward Realistic 3D Human Motion Prediction With a Spatio-Temporal Cross- Transformer Approach
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 10
SP  - 5707
EP  - 5720
DO  - 10.1109/TCSVT.2023.3255186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149880610&doi=10.1109%2fTCSVT.2023.3255186&partnerID=40&md5=cf2cadf220604b950a9451a6f7296b7a
AB  - Human motion prediction intends to predict how humans move given a historical sequence of 3D human motions. Recent transformer-based methods have attracted increasing attentions and demonstrated their promising performance in 3D human motion prediction. However, existing methods generally decompose the input of human motion information into spatial and temporal branches in a separate way and seldom consider their inherent coherence between the two branches, hence often failing to register the dynamic spatio-temporal information during the training process. Motivated by these issues, we propose a spatio-temporal cross-transformer network (STCT) for 3D human motion predictions. Specifically, we investigate various types of interaction methods (i.e., Concatenation Interaction, Msg token interaction, and Cross-transformer) to capture the coherence of the spatial and temporal branches. According to the obtained results, the proposed cross-transformer interaction method shows its superiority over other methods. Meanwhile, considering that most existing works treat the human body as a set of 3D human joint positions, the predicted human joints are proportionally less appropriate to the realistic human body due to unreasonable bone length and non-plausible poses as time progresses. We further resort to the bone constraints of human mesh to produce more realistic human motions. By fitting a parametric body model (i.e., SMPL-X model) to the predicted human joints, a reconstruction loss function is proposed to remedy the unreasonable bone length and pose errors. Comprehensive experiments on AMASS and Human3.6M datasets have demonstrated that our method achieves superior performance over compared methods.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qayyum, A.
AU  - Razzak, I.
AU  - Tanveer, M.
AU  - Mazher, M.
TI  - Spontaneous Facial Behavior Analysis Using Deep Transformer-based Framework for Child-computer Interaction
PY  - 2023
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 20
IS  - 2
C7  - 43
DO  - 10.1145/3539577
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176753141&doi=10.1145%2f3539577&partnerID=40&md5=b6278286bce9446c435a504405f92d53
AB  - A fascinating challenge in robotics-human interaction is imitating the emotion recognition capability of humans to robots with the aim to make human-robotics interaction natural, genuine and intuitive. To achieve the natural interaction in affective robots, human-machine interfaces, and autonomous vehicles, understanding our attitudes and opinions is very important, and it provides a practical and feasible path to realize the connection between machine and human. Multimodal interface that includes voice along with facial expression can manifest a large range of nuanced emotions compared to purely textual interfaces and provide a great value to improve the intelligence level of effective communication. Interfaces that fail to manifest or ignore user emotions may significantly impact the performance and risk being perceived as cold, socially inept, untrustworthy, and incompetent. To equip a child well for life, we need to help our children identify their feelings, manage them well, and express their needs in healthy, respectful, and direct ways. Early identification of emotional deficits can help to prevent low social functioning in children. In this work, we analyzed the child's spontaneous behavior using multimodal facial expression and voice signal presenting multimodal transformer-based last feature fusion for facial behavior analysis in children to extract contextualized representations from RGB video sequence and Hematoxylin and eosin video sequence and then using these representations followed by pairwise concatenations of contextualized representations using cross-feature fusion technique to predict users emotions. To validate the performance of the proposed framework, we have performed experiments with the different pairwise concatenations of contextualized representations that showed significantly better performance than state-of-the-art method. Besides, we perform t-distributed stochastic neighbor embedding visualization to visualize the discriminative feature in lower dimension space and probability density estimation to visualize the prediction capability of our proposed model. © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, C.
AU  - Liu, Y.
AU  - Chen, L.
AU  - Zhang, C.
TI  - Bidirectional Spatial-Temporal Adaptive Transformer for Urban Traffic Flow Forecasting
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 10
SP  - 6913
EP  - 6925
DO  - 10.1109/TNNLS.2022.3183903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133775660&doi=10.1109%2fTNNLS.2022.3183903&partnerID=40&md5=72fd1fda6a1ea4622bbe4a566f674bd9
AB  - Urban traffic forecasting is the cornerstone of the intelligent transportation system (ITS). Existing methods focus on spatial-temporal dependency modeling, while two intrinsic properties of the traffic forecasting problem are overlooked. First, the complexity of diverse forecasting tasks is nonuniformly distributed across various spaces (e.g., suburb versus downtown) and times (e.g., rush hour versus off-peak). Second, the recollection of past traffic conditions is beneficial to the prediction of future traffic conditions. Based on these properties, we propose a bidirectional spatial-temporal adaptive transformer (Bi-STAT) for accurate traffic forecasting. Bi-STAT adopts an encoder-decoder architecture, where both the encoder and the decoder maintain a spatial-adaptive transformer and a temporal-adaptive transformer structure. Inspired by the first property, each transformer is designed to dynamically process the traffic streams according to their task complexities. Specifically, we realize this by the recurrent mechanism with a novel dynamic halting module (DHM). Each transformer performs iterative computation with shared parameters until DHM emits a stopping signal. Motivated by the second property, Bi-STAT utilizes one decoder to perform the present → past recollection task and the other decoder to perform the present → future prediction task. The recollection task supplies complementary information to assist and regularize the prediction task for a better generalization. Through extensive experiments, we show the effectiveness of each module in Bi-STAT and demonstrate the superiority of Bi-STAT over the state-of-the-art baselines on four benchmark datasets. The code is available at https://github.com/chenchl19941118/Bi-STAT.git.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 49
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zou, G.
AU  - Lai, Z.
AU  - Ma, C.
AU  - Tu, M.
AU  - Fan, J.
AU  - Li, Y.
TI  - When Will We Arrive? A Novel Multi-Task Spatio-Temporal Attention Network Based on Individual Preference for Estimating Travel Time
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 10
SP  - 11438
EP  - 11452
DO  - 10.1109/TITS.2023.3276916
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161042931&doi=10.1109%2fTITS.2023.3276916&partnerID=40&md5=13272680512ccadefa90a7d5fc2c368d
AB  - Predicting how long a trip will take may allow travelers plan ahead, save money, and avoid traffic congestion. The journey time estimation model should take into account three crucial factors: (1) individual travel preference, (2) dynamic spatio-temporal correlations, and (3) the association between long-term speed forecast and travel time estimate. In order to overcome these challenges, this study proposes a unique parallel architecture called the multi-task spatio-temporal attention network (MT-STAN) to estimate journey times. To extract the dynamic spatio-temporal correlations of the road network, we first develop a traffic speed prediction model based on spatio-temporal block and bridge transformer networks, combining the road, timestamp, and traffic speed information into hidden states. Second, we offer a personalized model for estimating journey times that makes use of cross-network, holistic attention, and semantic transformer. In this approach, travel preferences extraction through cross-network, holistic attention permits correlations between the dynamic road network's hidden states and individual journey characteristics, which are subsequently transformed into global semantics by the semantic transformer; preferences and semantics are integrated during the estimate phase. Finally, a multi-task learning component is included, which combines both traffic speed prediction and individual journey time estimate, via the sharing of underlying network parameters and the improvement of the contextual semantic knowledge of the latter job. Evaluation experiments are carried out using a highway dataset collected in Yinchuan City, Ningxia Province, China. The proposed prediction model outperforms state-of-the-art baseline approaches in experiments.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; FMS:B; 
LB  - Zou2023When
ER  -

TY  - JOUR
AU  - Xia, C.
AU  - Wang, J.
AU  - Qin, Y.
AU  - Wen, J.
AU  - Liu, Z.
AU  - Song, N.
AU  - Wu, L.
AU  - Chen, B.
AU  - Gu, Y.
AU  - Yang, J.
TI  - KaryoNet: Chromosome Recognition With End-to-End Combinatorial Optimization Network
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 10
SP  - 2899
EP  - 2911
DO  - 10.1109/TMI.2023.3268889
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153802272&doi=10.1109%2fTMI.2023.3268889&partnerID=40&md5=17ea4b01b28288e158cd2c53bab88ee5
AB  - Chromosome recognition is a critical way to diagnose various hematological malignancies and genetic diseases, which is however a repetitive and time-consuming process in karyotyping. To explore the relative relation between chromosomes, in this work, we start from a global perspective and learn the contextual interactions and class distribution features between chromosomes within a karyotype. We propose an end-to-end differentiable combinatorial optimization method, KaryoNet, which captures long-range interactions between chromosomes with the proposed Masked Feature Interaction Module (MFIM) and conducts label assignment in a flexible and differentiable way with Deep Assignment Module (DAM). Specially, a Feature Matching Sub-Network is built to predict the mask array for attention computation in MFIM. Lastly, Type and Polarity Prediction Head can predict chromosome type and polarity simultaneously. Extensive experiments on R-band and G-band two clinical datasets demonstrate the merits of the proposed method. For normal karyotypes, the proposed KaryoNet achieves the accuracy of 98.41% on R-band chromosome and 99.58% on G-band chromosome. Owing to the extracted internal relation and class distribution features, KaryoNet can also achieve state-of-the-art performances on karyotypes of patients with different types of numerical abnormalities. The proposed method has been applied to assist clinical karyotype diagnosis. Our code is available at: https://github.com/xiabc612/KaryoNet.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yue, W.
AU  - Liao, H.
AU  - Xia, Y.
AU  - Lam, V.
AU  - Luo, J.
AU  - Wang, Z.
TI  - Cascade Multi-Level Transformer Network for Surgical Workflow Analysis
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 10
SP  - 2817
EP  - 2831
DO  - 10.1109/TMI.2023.3265354
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153365674&doi=10.1109%2fTMI.2023.3265354&partnerID=40&md5=c9df7397f3204f88d900adb9db8a1b3e
AB  - Surgical workflow analysis aims to recognise surgical phases from untrimmed surgical videos. It is an integral component for enabling context-aware computer-aided surgical operating systems. Many deep learning-based methods have been developed for this task. However, most existing works aggregate homogeneous temporal context for all frames at a single level and neglect the fact that each frame has its specific need for information at multiple levels for accurate phase prediction. To fill this gap, in this paper we propose Cascade Multi-Level Transformer Network (CMTNet) composed of cascaded Adaptive Multi-Level Context Aggregation (AMCA) modules. Each AMCA module first extracts temporal context at the frame level and the phase level and then fuses frame-specific spatial feature, frame-level temporal context, and phase-level temporal context for each frame adaptively. By cascading multiple AMCA modules, CMTNet is able to gradually enrich the representation of each frame with the multi-level semantics that it specifically requires, achieving better phase prediction in a frame-adaptive manner. In addition, we propose a novel refinement loss for CMTNet, which explicitly guides each AMCA module to focus on extracting the key context for refining the prediction of the previous stage in terms of both prediction confidence and smoothness. This further enhances the quality of the extracted context effectively. Extensive experiments on the Cholec80 and the M2CAI datasets demonstrate that CMTNet achieves state-of-the-art performance.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Geng, M.
AU  - Li, J.
AU  - Li, C.
AU  - Xie, N.
AU  - Chen, X.
AU  - Lee, D.-H.
TI  - Adaptive and Simultaneous Trajectory Prediction for Heterogeneous Agents via Transferable Hierarchical Transformer Network
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 10
SP  - 11479
EP  - 11492
DO  - 10.1109/TITS.2023.3276946
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162731101&doi=10.1109%2fTITS.2023.3276946&partnerID=40&md5=b37544a19e59c5aaeae5b7465313d513
AB  - Simultaneously and accurately predicting trajectories of multiple heterogeneous agents is crucial for intelligent transportation systems (ITS) applications, e.g., connected and autonomous vehicles. Existing model-based and data-driven methods can achieve good prediction accuracy, but most of them neglect the domain shift issue and prevalent imperfect data problems, i.e., few-shot learning and zero-shot learning issues. To address these issues, we propose a multi-source transfer learning (TL) framework, transferable hierarchical Siamese Transformer network (T-HSTN), for trajectory prediction of multiple heterogeneous agents, e.g., vehicles, bicycles, and pedestrians, at urban unsignalized intersections under small data conditions. Specifically, by extending the self-attention mechanism and exploring feature representations of traffic scenes, a Transformer-based network that hierarchically extracts temporal/spatial features and map features is introduced as the basic prediction model. Moreover, a TL framework with adaptive learning and feature alignment modules is built to explore the feature representations of unfixed traffic scenes and align both statistical and deep features to learn domain-invariant knowledge. More challenging trajectory prediction experiments are designed, corresponding to newly-built or badly-instrumented intersections under real-world scenarios. Experimental results verify the proposed method's high accuracy, transferability, and generability. Our work fills the gap in solutions and benchmarks for TL tasks in trajectory prediction for heterogeneous agents. The conducted TL experiments provide a more practical setting of considering imperfect data problems in trajectory prediction. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Geng2023Adaptive
ER  -

TY  - JOUR
AU  - Mukhtar, H.
AU  - Afzal, A.
AU  - Alahmari, S.
AU  - Yonbawi, S.
TI  - CCGN: Centralized collaborative graphical transformer multi-agent reinforcement learning for multi-intersection signal free-corridor
PY  - 2023
T2  - Neural Networks
VL  - 166
SP  - 396
EP  - 409
DO  - 10.1016/j.neunet.2023.07.027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169905129&doi=10.1016%2fj.neunet.2023.07.027&partnerID=40&md5=70c2bbd1ad0b966a11aea73c86449423
AB  - Tackling traffic signal control through multi-agent reinforcement learning is a widely-employed approach. However, current state-of-the-art models have drawbacks: intersections optimize their own local rewards and cause traffic to waste time and fuel with a start-stop mode at each intersection. They also lack information sharing among intersections and their specialized policy hinders the ability to adapt to new traffic scenarios. To overcome these limitations, This work presents a centralized collaborative graph network (CCGN) with the core objective of a signal-free corridor once the traffic flows have waited at the entry intersection of the traffic intersection network on either side, the subsequent intersection gives the open signal as the traffic flows arrive. CCGN combines local policy networks (LPN) and global policy networks, where LPN employed at each intersection predicts actions based on Transformer and Graph Convolutional Network (GCN). In contrast, GPN is based on GCN and Q-network that receives the LPN states, traffic flow and road information to manage intersections to provide a signal-free corridor. We developed the Deep Graph Convolution Q-Network (DGCQ) by combining Deep Q-Network (DQN) and GCN to achieve a signal-free corridor. DGCQ leverages GCN's intersection collaboration and DQN's information aggregation for traffic control decisions Proposed CCGN model is trained on the robust synthetic traffic network and evaluated on the real-world traffic networks that outperform the other state-of-the-art models. © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Han, S.
AU  - Fu, H.
AU  - Wu, Y.
AU  - Zhao, G.
AU  - Song, Z.
AU  - Huang, F.
AU  - Zhang, Z.
AU  - Liu, S.
AU  - Zhang, W.
TI  - HimGNN: a novel hierarchical molecular graph representation learning framework for property prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 5
C7  - bbad305
DO  - 10.1093/bib/bbad305
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172424356&doi=10.1093%2fbib%2fbbad305&partnerID=40&md5=7efcd20e951b23849f4ea5b384551471
AB  - Accurate prediction of molecular properties is an important topic in drug discovery. Recent works have developed various representation schemes for molecular structures to capture different chemical information in molecules. The atom and motif can be viewed as hierarchical molecular structures that are widely used for learning molecular representations to predict chemical properties. Previous works have attempted to exploit both atom and motif to address the problem of information loss in single representation learning for various tasks. To further fuse such hierarchical information, the correspondence between learned chemical features from different molecular structures should be considered. Herein, we propose a novel framework for molecular property prediction, called hierarchical molecular graph neural networks (HimGNN). HimGNN learns hierarchical topology representations by applying graph neural networks on atom- and motif-based graphs. In order to boost the representational power of the motif feature, we design a Transformer-based local augmentation module to enrich motif features by introducing heterogeneous atom information in motif representation learning. Besides, we focus on the molecular hierarchical relationship and propose a simple yet effective rescaling module, called contextual self-rescaling, that adaptively recalibrates molecular representations by explicitly modelling interdependencies between atom and motif features. Extensive computational experiments demonstrate that HimGNN can achieve promising performances over state-of-the-art baselines on both classification and regression tasks in molecular property prediction.  © 2023 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gao, J.
AU  - Shen, Z.
AU  - Xie, Y.
AU  - Lu, J.
AU  - Lu, Y.
AU  - Chen, S.
AU  - Bian, Q.
AU  - Guo, Y.
AU  - Shen, L.
AU  - Wu, J.
AU  - Zhou, B.
AU  - Hou, T.
AU  - He, Q.
AU  - Che, J.
AU  - Dong, X.
TI  - TransFoxMol: predicting molecular property with focused attention
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 5
C7  - bbad306
DO  - 10.1093/bib/bbad306
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172424659&doi=10.1093%2fbib%2fbbad306&partnerID=40&md5=9ba53ef4e2665ccb3040fb4a99a4231d
AB  - Predicting the biological properties of molecules is crucial in computer-aided drug development, yet it's often impeded by data scarcity and imbalance in many practical applications. Existing approaches are based on self-supervised learning or 3D data and using an increasing number of parameters to improve performance. These approaches may not take full advantage of established chemical knowledge and could inadvertently introduce noise into the respective model. In this study, we introduce a more elegant transformer-based framework with focused attention for molecular representation (TransFoxMol) to improve the understanding of artificial intelligence (AI) of molecular structure property relationships. TransFoxMol incorporates a multi-scale 2D molecular environment into a graph neural network + Transformer module and uses prior chemical maps to obtain a more focused attention landscape compared to that obtained using existing approaches. Experimental results show that TransFoxMol achieves state-of-the-art performance on MoleculeNet benchmarks and surpasses the performance of baselines that use self-supervised learning or geometry-enhanced strategies on small-scale datasets. Subsequent analyses indicate that TransFoxMol's predictions are highly interpretable and the clever use of chemical knowledge enables AI to perceive molecules in a simple but rational way, enhancing performance.  © 2023 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Ning, Z.
AU  - Ding, Y.
AU  - Wang, Y.
AU  - Peng, Q.
AU  - Fu, L.
TI  - KGETCDA: an efficient representation learning framework based on knowledge graph encoder from transformer for predicting circRNA-disease associations
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 5
C7  - bbad292
DO  - 10.1093/bib/bbad292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172424020&doi=10.1093%2fbib%2fbbad292&partnerID=40&md5=10f9ead44b3a7f6b06bd7afd3296e242
AB  - Recent studies have demonstrated the significant role that circRNA plays in the progression of human diseases. Identifying circRNA-disease associations (CDA) in an efficient manner can offer crucial insights into disease diagnosis. While traditional biological experiments can be time-consuming and labor-intensive, computational methods have emerged as a viable alternative in recent years. However, these methods are often limited by data sparsity and their inability to explore high-order information. In this paper, we introduce a novel method named Knowledge Graph Encoder from Transformer for predicting CDA (KGETCDA). Specifically, KGETCDA first integrates more than 10 databases to construct a large heterogeneous non-coding RNA dataset, which contains multiple relationships between circRNA, miRNA, lncRNA and disease. Then, a biological knowledge graph is created based on this dataset and Transformer-based knowledge representation learning and attentive propagation layers are applied to obtain high-quality embeddings with accurately captured high-order interaction information. Finally, multilayer perceptron is utilized to predict the matching scores of CDA based on their embeddings. Our empirical results demonstrate that KGETCDA significantly outperforms other state-of-the-art models. To enhance user experience, we have developed an interactive web-based platform named HNRBase that allows users to visualize, download data and make predictions using KGETCDA with ease. The code and datasets are publicly available at https://github.com/jinyangwu/KGETCDA.  © 2023 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zheng, Y.
AU  - Zhang, Y.
AU  - Xiao, B.
TI  - Target-Aware Transformer Tracking
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 9
SP  - 4542
EP  - 4551
DO  - 10.1109/TCSVT.2023.3276061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160251992&doi=10.1109%2fTCSVT.2023.3276061&partnerID=40&md5=77fad112e3c4eee01d7f36da186fed90
AB  - Object tracking is aimed at locating a specific object in the image sequence, such as pedestrians, vehicles, and so on. The existing algorithms based on siamese neural network predict the target through similarity matching. Although these algorithms have achieved satisfactory performance, in the process of similarity calculation between template image and search image, only local information is often concerned, which makes the algorithms difficult to obtain the optimal solution. To deal with the abovementioned problems, we propose a model based on Transformer, named TaTrack. Specifically, we first use the encoders to enhance the features. Then, the dependency between template features and search features is established through the target-aware module. Finally, we utilize the classification regression network to locate the target, and use the classification score to adapt to update the template image. Experiments show that our model can achieve great performance on GOT-10k, LaSOT, and TrackingNet datasets.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sattler, F.
AU  - Korjakow, T.
AU  - Rischke, R.
AU  - Samek, W.
TI  - FedAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 9
SP  - 5531
EP  - 5543
DO  - 10.1109/TNNLS.2021.3129371
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108294421&doi=10.1109%2fTNNLS.2021.3129371&partnerID=40&md5=7e9c2ead045cbca2e05edb83943502cc
AB  - Federated distillation (FD) is a popular novel algorithmic paradigm for Federated learning (FL), which achieves training performance competitive to prior parameter averaging-based methods, while additionally allowing the clients to train different model architectures, by distilling the client predictions on an unlabeled auxiliary set of data into a student model. In this work, we propose FedAUX, an extension to FD, which, under the same set of assumptions, drastically improves the performance by deriving maximum utility from the unlabeled auxiliary data. FedAUX modifies the FD training procedure in two ways: First, unsupervised pre-training on the auxiliary data is performed to find a suitable model initialization for the distributed training. Second, (ϵ, δ -differentially private certainty scoring is used to weight the ensemble predictions on the auxiliary data according to the certainty of each client model. Experiments on large-scale convolutional neural networks (CNNs) and transformer models demonstrate that our proposed method achieves remarkable performance improvements over state-of-the-art FL methods, without adding appreciable computation, communication, or privacy cost. For instance, when training ResNet8 on non-independent identically distributed (i.i.d.) subsets of CIFAR10, FedAUX raises the maximum achieved validation accuracy from 30.4% to 78.1%, further closing the gap to centralized training performance. Code is available at https://github.com/fedl-repo/fedaux.  © 2021 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 49
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guan, W.
AU  - Song, X.
AU  - Wang, K.
AU  - Wen, H.
AU  - Ni, H.
AU  - Wang, Y.
AU  - Chang, X.
TI  - Egocentric Early Action Prediction via Multimodal Transformer-Based Dual Action Prediction
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 9
SP  - 4472
EP  - 4483
DO  - 10.1109/TCSVT.2023.3248271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149418673&doi=10.1109%2fTCSVT.2023.3248271&partnerID=40&md5=0e93bd110a028ffa3be02710edfb47c8
AB  - Egocentric early action prediction, which aims to recognize the on-going action in the video captured in the first-person view as early as possible before the action is fully executed, is a new yet challenging task due to the limited partial video input. Pioneer studies focused on solving this task with LSTMs as the backbone and simply compiling the observed video segment and unobserved video segment into a single vector, which hence suffer from two key limitations: lack the non-sequential relation modeling with the video snippet sequence and the correlation modeling between the observed and unobserved video segment. To address these two limitations, in this paper, we propose a novel multimodal TransfoRmer-based duAl aCtion prEdiction (mTRACE) model for the task of egocentric early action prediction, which consists of two key modules: the early (observed) segment action prediction module and the future (unobserved) segment action prediction module. Both modules take Transformer encoders as the backbone for encoding all the potential relations among the input video snippets, and involve several single-modal and multi-modal classifiers for comprehensive supervision. Different from previous work, each of the two modules outputs two multi-modal feature vectors: one for encoding the current input video segment, and the other one for predicting the missing video segment. For optimization, we design a two-stage training scheme, including the mutual enhancement stage and end-to-end aggregation stage. The former stage alternatively optimizes the two action prediction modules, where the correlation between the observed and unobserved video segment is modeled with a consistency regularizer, while the latter seamlessly aggregates the two modules to fully utilize the capacity of the two modules. Extensive experiments have demonstrated the superiority of our proposed model. We have released the codes and the corresponding parameters to benefit other researchers at https://trace729.wixsite.com/trace. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wen, Y.
AU  - Li, Z.
AU  - Wang, X.
AU  - Xu, W.
TI  - Traffic demand prediction based on spatial-temporal guided multi graph Sandwich-Transformer
PY  - 2023
T2  - Information Sciences
VL  - 643
C7  - 119269
DO  - 10.1016/j.ins.2023.119269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161063770&doi=10.1016%2fj.ins.2023.119269&partnerID=40&md5=4d92f86652d54757fa543ee3a27aeaa5
AB  - The ability of spatial-temporal traffic demand prediction is crucial for urban computing, traffic management and future autonomous driving. In this paper, a novel Spatial-Temporal Guided Multi-graph Sandwich-Transformer (STGMT) is suggested to address the ubiquitous spatial-temporal heterogeneity in traffic demand forecasting. Compared to the original Transformer, we employ Time to Vector (Time2Vec) and Node to Vector (Node2Vec) in the embedding layer to obtain universal representations for temporal nodes and spatial nodes, respectively, which are then combined to form Spatial-Temporal Embedding (STE) blocks. The STE guides the attention mechanism, maintaining a unique parameter space for spatial-temporal nodes and enabling the learning of node-specific patterns. In STGMT, we develop Multi-head Temporal Attention (MTA) and Multi-head Temporal Interactive Attention (MTIA) for extracting temporal features, while Multi-head Spatial Attention (MSA) is employed for extracting spatial features. Furthermore, MSA incorporates both the accessibility graph determined by road topology and the similarity graph determined by specific traffic events to characterize the pairwise relationships among spatial nodes. Various attentions and feed-forward layers are rearranged and combined to form the Sandwich-Transformer. Extensive experiments are conducted on public datasets of node-level tasks of two different types (highway and urban) and indicate that the STGMT outperforms state-of-the-art models. The proposed STGMT effectively addresses the ubiquitous spatial-temporal heterogeneity challenge in traffic demand forecasting, thereby enhancing the accuracy of traffic demand prediction and offering valuable guidance for traffic planning and operations. Our code and data are open source at https://github.com/YanJieWen/STGMT-Tensorflow-implementation. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Wen2023Traffic
ER  -

TY  - JOUR
AU  - Zou, S.
AU  - Xu, Y.
AU  - Li, C.
AU  - Ma, L.
AU  - Cheng, L.
AU  - Vo, M.
TI  - Snipper: A Spatiotemporal Transformer for Simultaneous Multi-Person 3D Pose Estimation Tracking and Forecasting on a Video Snippet
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 9
SP  - 4921
EP  - 4933
DO  - 10.1109/TCSVT.2023.3244152
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149406798&doi=10.1109%2fTCSVT.2023.3244152&partnerID=40&md5=78201c172248228c9f508f9b2e314946
AB  - Multi-person pose understanding from RGB videos involves three complex tasks: pose estimation, tracking and motion forecasting. Intuitively, accurate multi-person pose estimation facilitates robust tracking, and robust tracking builds crucial history for correct motion forecasting. Most existing works either focus on a single task or employ multi-stage approaches to solving multiple tasks separately, which tends to make sub-optimal decision at each stage and also fail to exploit correlations among the three tasks. In this paper, we propose Snipper, a unified framework to perform multi-person 3D pose estimation, tracking, and motion forecasting simultaneously in a single stage. We propose an efficient yet powerful deformable attention mechanism to aggregate spatiotemporal information from the video snippet. Building upon this deformable attention, a video transformer is learned to encode the spatiotemporal features from the multi-frame snippet and to decode informative pose features for multi-person pose queries. Finally, these pose queries are regressed to predict multi-person pose trajectories and future motions in a single shot. In the experiments, we show the effectiveness of Snipper on three challenging public datasets where our generic model rivals specialized state-of-art baselines for pose estimation, tracking, and forecasting. Code is available at https://github.com/JimmyZou/Snipper.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhong, X.
AU  - Yan, X.
AU  - Yang, Z.
AU  - Huang, W.
AU  - Jiang, K.
AU  - Liu, R.W.
AU  - Wang, Z.
TI  - Visual Exposes You: Pedestrian Trajectory Prediction Meets Visual Intention
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 9
SP  - 9390
EP  - 9400
DO  - 10.1109/TITS.2023.3266762
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153503280&doi=10.1109%2fTITS.2023.3266762&partnerID=40&md5=45c3ecc3e9831fe2cc293c09ee919a70
AB  - Pedestrian trajectory prediction in multiple scenarios is of immense importance in autonomous driving and disentanglement of human behavior but is limited in catching human intention and initiative. Most previous works tend to predict the trajectory using only 2D coordinates, which generally cause two common problems: a) Overlooking the subjective initiative, including sudden swerve and erratic movement; b) A potential challenge called abnormal collision caused by unlabeled pedestrians on dataset is not being identified and resolved, which would ruin the model prediction. To break those limitations, we introduce visual localization and orientation as Visual Intention Knowledge to help the trajectory prediction, which is learned directly from visual scenarios. It benefits to comprehend human intention and formulates decision-making processes. Moreover, by learning from the visual information and decision-making policy, we construct the Visual Intention Knowledge associated spatio-temporal Transformer (VIKT) to predict human trajectory by combining the intention knowledge with the novel Transformer. Extensive experimental results demonstrate that our VIKT model could achieve competitive performance by the Visual Intention Knowledge through optimizing the model prediction compared with state-of-the-art methods in terms of prediction accuracy on ETH/UCY and SDD benchmarks.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Zhong2023Visual
ER  -

TY  - JOUR
AU  - Fei, H.
AU  - Ren, Y.
AU  - Zhang, Y.
AU  - Ji, D.
TI  - Nonautoregressive Encoder-Decoder Neural Framework for End-to-End Aspect-Based Sentiment Triplet Extraction
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 9
SP  - 5544
EP  - 5556
DO  - 10.1109/TNNLS.2021.3129483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120868082&doi=10.1109%2fTNNLS.2021.3129483&partnerID=40&md5=54727bf4e1a9beec9d9d5a51af40b4c3
AB  - Aspect-based sentiment triplet extraction (ASTE) aims at recognizing the joint triplets from texts, i.e., aspect terms, opinion expressions, and correlated sentiment polarities. As a newly proposed task, ASTE depicts the complete sentiment picture from different perspectives to better facilitate real-world applications. Unfortunately, several major challenges, such as the overlapping issue and long-distance dependency, have not been addressed effectively by the existing ASTE methods, which limits the performance of the task. In this article, we present an innovative encoder-decoder framework for end-to-end ASTE. Specifically, the ASTE task is first modeled as an unordered triplet set prediction problem, which is satisfied with a nonautoregressive decoding paradigm with a pointer network. Second, a novel high-order aggregation mechanism is proposed for fully integrating the underlying interactions between the overlapping structure of aspect and opinion terms. Third, a bipartite matching loss is introduced for facilitating the training of our nonautoregressive system. Experimental results on benchmark datasets show that our proposed framework significantly outperforms the state-of-the-art methods. Further analysis demonstrates the advantages of the proposed framework in handling the overlapping issue, relieving long-distance dependency and decoding efficiency.  © 2021 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 40
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Zhao, Z.
AU  - Li, B.
AU  - Han, J.
TI  - LCPFormer: Towards Effective 3D Point Cloud Analysis via Local Context Propagation in Transformers
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 9
SP  - 4985
EP  - 4996
DO  - 10.1109/TCSVT.2023.3247506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149397555&doi=10.1109%2fTCSVT.2023.3247506&partnerID=40&md5=8a11b0400096891e2055e4dbb5b31eb5
AB  - Transformer with its underlying attention mechanism and the ability to capture long-range dependencies makes it become a natural choice for unordered point cloud data. However, local regions separated from the general sampling architecture corrupt the structural information of the instances, and the inherent relationships between adjacent local regions lack exploration. In other words, the transformer only focuses on the long-range dependence, while local structural information is still crucial in a transformer-based 3D point cloud model. To enable transformers to incorporate local structural information, we proposed a straightforward solution based on the natural structure of the point clouds to exploit the message passing between neighboring local regions, thus making their representations more comprehensive and discriminative. Concretely, the proposed module, named Local Context Propagation (LCP), is inserted between two transformer layers. It takes advantage of the overlapping points of adjacent local regions (statistically shown to be prevalent) as intermediaries, then re-weighs the features of these shared points from different local regions before passing them to the next layers. Finally, we design a flexible LCPFormer architecture equipped with the LCP module, which is applicable to several different tasks. Experimental results demonstrate that our proposed LCPFormer outperforms various transformer-based methods in benchmarks including 3D shape classification and dense prediction tasks such as 3D object detection and semantic segmentation. Code will be released for reproduction.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wong, C.
AU  - Xia, B.
AU  - Peng, Q.
AU  - Yuan, W.
AU  - You, X.
TI  - MSN: Multi-Style Network for Trajectory Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 9
SP  - 9751
EP  - 9766
DO  - 10.1109/TITS.2023.3274777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161609901&doi=10.1109%2fTITS.2023.3274777&partnerID=40&md5=220e0827f0fb24f0e26a2208719fc31d
AB  - Trajectory prediction aims to forecast agents' possible future locations considering their observations along with the video context. It is strongly needed by many autonomous platforms like tracking, detection, robot navigation, and self-driving cars. Whether it is agents' internal personality factors, interactive behaviors with the neighborhood, or the influence of surroundings, they all impact agents' future planning. However, many previous methods model and predict agents' behaviors with the same strategy or feature distribution, making them challenging to make predictions with sufficient style differences. This paper proposes the Multi-Style Network (MSN), which utilizes style proposal and stylized prediction using two sub-networks, to provide multi-style predictions in a novel categorical way adaptively. The proposed network contains a series of style channels, and each channel is bound to a unique and specific behavior style. We use agents' end-point plannings and their interaction context as the basis for the behavior classification, so as to adaptively learn multiple diverse behavior styles through these channels. Then, we assume that the target agents may plan their future behaviors according to each of these categorized styles, thus utilizing different style channels to make predictions with significant style differences in parallel. Experiments show that the proposed MSN outperforms current state-of-the-art methods up to 10% quantitatively on two widely used datasets, and presents better multi-style characteristics qualitatively.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; FMS:B; 
LB  - Wong2023MSN
ER  -

TY  - JOUR
AU  - Hu, H.
AU  - Wang, Q.
AU  - Zhang, Z.
AU  - Li, Z.
AU  - Gao, Z.
TI  - Holistic transformer: A joint neural network for trajectory prediction and decision-making of autonomous vehicles
PY  - 2023
T2  - Pattern Recognition
VL  - 141
C7  - 109592
DO  - 10.1016/j.patcog.2023.109592
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152624678&doi=10.1016%2fj.patcog.2023.109592&partnerID=40&md5=9f004af5db56ee34ab8a61effaaa1891
AB  - Trajectory prediction and behavioral decision-making are two important tasks for autonomous vehicles that require a good understanding of the environmental context. Notably, behavioral decisions are better made by referring to the outputs of trajectory predictions. However, most current solutions perform these tasks separately. Therefore, this paper proposes a new joint holistic transformer network that combines multiple cues to predict trajectories and make behavioral decisions simultaneously. To better explore the intrinsic relationships among cues, the network uses existing knowledge and adopts three kinds of attention mechanisms: the sparse multi-head type for reducing noise impact, feature selection sparse type for optimally using partial prior knowledge, and multi-head with sigmoid activation type for optimally using posteriori knowledge. Compared with other trajectory prediction models, the proposed model has a better comprehensive performance and good interpretability. Perceptual noise robustness experiments demonstrate that the proposed model has good noise robustness. Thus, simultaneous trajectory prediction and behavioral decision-making combining multiple cues are accomplished, which reduces computational costs and enhances semantic relationships between scenes and agents. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Zhang, J.
AU  - Yang, L.
AU  - Yang, Y.
AU  - Li, X.
AU  - Gao, Z.
TI  - Short-term passenger flow prediction for multi-traffic modes: A Transformer and residual network based multi-task learning method
PY  - 2023
T2  - Information Sciences
VL  - 642
C7  - 119144
DO  - 10.1016/j.ins.2023.119144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160005776&doi=10.1016%2fj.ins.2023.119144&partnerID=40&md5=34bfa51bb722ea24119fac423e7a22cb
AB  - Managing multiple traffic modes cooperatively is becoming increasingly important owing to the diversity of passenger demands. Short-term passenger flow predictions for multi-traffic modes can be applied to the management of the multi-traffic modes system. However, this is challenging because the spatiotemporal features of multi-traffic modes are complex. Moreover, the passenger flows of the multi-traffic modes differentiated and fluctuated significantly. To address these issues, this study proposes a multitask learning-based model, called Res-Transformer, for short-term inflow prediction of multi-traffic modes. The Res-Transformer consists of two parts: (1) modified Transformer layers comprising the Conv-Transformer layer and the multi-head attention mechanism, which helps extract the spatiotemporal features of multi-traffic modes, and (2) the structure of the residual network, which is utilized to obtain correlations among multi-traffic modes and prevent gradient vanishing and explosion. The proposed model was evaluated using two large-scale real-world datasets from Beijing, China. One was a traffic hub, and the other was a residential area. The results not only demonstrate the effectiveness and robustness of the Res-Transformer but also prove the benefits of considering multi-traffic modes jointly. This study provides critical insights into short-term inflow prediction of the multi-traffic modes system. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2023Short-term
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Jiang, Y.
AU  - Lu, M.
AU  - Li, R.
AU  - Xia, Y.
TI  - Survival Prediction via Hierarchical Multimodal Co-Attention Transformer: A Computational Histology-Radiology Solution
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 9
SP  - 2678
EP  - 2689
DO  - 10.1109/TMI.2023.3263010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151517905&doi=10.1109%2fTMI.2023.3263010&partnerID=40&md5=4d6d0d6c9854262dd979826d486af28e
AB  - The rapid advances in deep learning-based computational pathology and radiology have demonstrated the promise of using whole slide images (WSIs) and radiology images for survival prediction in cancer patients. However, most image-based survival prediction methods are limited to using either histology or radiology alone, leaving integrated approaches across histology and radiology relatively underdeveloped. There are two main challenges in integrating WSIs and radiology images: (1) the gigapixel nature of WSIs and (2) the vast difference in spatial scales between WSIs and radiology images. To address these challenges, in this work, we propose an interpretable, weakly-supervised, multimodal learning framework, called Hierarchical Multimodal Co-Attention Transformer (HMCAT), to integrate WSIs and radiology images for survival prediction. Our approach first uses hierarchical feature extractors to capture various information including cellular features, cellular organization, and tissue phenotypes in WSIs. Then the hierarchical radiology-guided co-attention (HRCA) in HMCAT characterizes the multimodal interactions between hierarchical histology-based visual concepts and radiology features and learns hierarchical co-attention mappings for two modalities. Finally, HMCAT combines their complementary information into a multimodal risk score and discovers prognostic features from two modalities by multimodal interpretability. We apply our approach to two cancer datasets (365 WSIs with matched magnetic resonance [MR] images and 213 WSIs with matched computed tomography [CT] images). Our results demonstrate that the proposed HMCAT consistently achieves superior performance over the unimodal approaches trained on either histology or radiology data alone, as well as other state-of-the-art methods.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Lian, Z.
TI  - FontTransformer: Few-shot high-resolution Chinese glyph image synthesis via stacked transformers
PY  - 2023
T2  - Pattern Recognition
VL  - 141
C7  - 109593
DO  - 10.1016/j.patcog.2023.109593
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153075217&doi=10.1016%2fj.patcog.2023.109593&partnerID=40&md5=7c1db22c3f6fb686efbccfb045d68110
AB  - Automatic generation of high-quality Chinese fonts from a few online training samples is a challenging task, especially when the amount of samples is very small. Existing few-shot font generation methods can only synthesize low-resolution glyph images that often possess incorrect topological structures or/and incomplete strokes. To address the problem, this paper proposes FontTransformer, a novel few-shot learning model, for high-resolution Chinese glyph image synthesis by using stacked Transformers. The key idea is to apply the parallel Transformer to avoid the accumulation of prediction errors and utilize the serial Transformer to enhance the quality of synthesized strokes. Meanwhile, we also design a novel encoding scheme to feed more glyph information and prior knowledge to our model, which further enables the generation of high-resolution and visually-pleasing glyph images. Both qualitative and quantitative experimental results demonstrate the superiority of our method compared to other existing approaches in few-shot Chinese font synthesis task. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gai, D.
AU  - Feng, R.
AU  - Min, W.
AU  - Yang, X.
AU  - Su, P.
AU  - Wang, Q.
AU  - Han, Q.
TI  - Spatiotemporal Learning Transformer for Video-Based Human Pose Estimation
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 9
SP  - 4564
EP  - 4576
DO  - 10.1109/TCSVT.2023.3269666
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159670507&doi=10.1109%2fTCSVT.2023.3269666&partnerID=40&md5=6422c3743a5d88fdc96894cbee05c12a
AB  - Multi-frame human pose estimation has long been an appealing and fundamental issue in visual perception. Owing to the frequent rapid motion and pose occlusion in videos, this task is extremely challenging. Current state-of-the-art methods seek to model spatiotemporal features by equally fusing each frame in the local sequence, which weakens the target frame information. In addition, existing approaches usually emphasize more on deep features while ignoring the detailed information implied in the shallow feature maps, resulting in the dropping of crucial features. To address the above problems, we propose an effective framework, namely spatiotemporal learning transformer for video-based human pose estimation (SLT-Pose), which consists of a Personalized Feature Extraction Module (PFEM), Self-feature Refinement Module (SRM), Cross-frame Temporal Learning Module (CTLM) and Disentangled Keypoint Detector (DKD). To be specific, we propose PFEM which extracts and modulates the individual frame features to adapt to the varying human shape, and integrates single-frame features to obtain the spatiotemporal features. We further present SRM to establish global correlation spatial cues on the target frame to attain the refinement feature. Then, a CTLM is designed to search for the information most closely related to the target frame from the spatiotemporal features to intensify the interaction between the target frame and the local sequence, using both the shallow detailed and the deep semantic representations. Finally, we employ DKD to extract the disentangled characteristics of each joint and encode the articulated joint pairs in the human body, promoting the model to reasonably and accurately predict the keypoint heatmaps. Extensive experiments on three huamn motion benchmarks, including PoseTrack2017, PoseTrack2018, and Sub-JHMDB dataset, demonstrate that SLT-Pose plays favorably against state-of-the-art approaches in terms of both objective evaluation and subjective visual performance.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, F.
AU  - Ke, P.
AU  - Huang, M.
TI  - Directed Acyclic Transformer Pre-training for High-quality Non-autoregressive Text Generation
PY  - 2023
T2  - Transactions of the Association for Computational Linguistics
VL  - 11
SP  - 941
EP  - 959
DO  - 10.1162/tacl_a_00582
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177432344&doi=10.1162%2ftacl_a_00582&partnerID=40&md5=42bb0a6ff59c8bd0d5fbcd3256cff71a
AB  - Non-AutoRegressive (NAR) text generation models have drawn much attention because of their significantly faster decoding speed and good generation quality in machine transla-tion. However, in a wider range of text generation tasks, existing NAR models lack proper pre-training, making them still far behind the pre-trained autoregressive models. In this paper, we propose Pre-trained Directed Acy-clic Transformer (PreDAT) and a novel pre-training task to promote prediction consistency in NAR generation. Experiments on five text generation tasks show that our PreDAT re-markably outperforms existing pre-trained NAR models (+4.2 score on average) and even achieves better results than pre-trained autore-gressive baselines in n-gram-based metrics, along with 17 times speedup in throughput. Further analysis shows that PreDAT benefits from the unbiased prediction order that alle-viates the error accumulation problem in au-toregressive generation, which provides new insights into the advantages of NAR generation. © 2023 Association for Computational Linguistics.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kong, L.
AU  - Ojha, V.
AU  - Gao, R.
AU  - Suganthan, P.N.
AU  - Snášel, V.
TI  - Low-rank and global-representation-key-based attention for graph transformer
PY  - 2023
T2  - Information Sciences
VL  - 642
C7  - 119108
DO  - 10.1016/j.ins.2023.119108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159566842&doi=10.1016%2fj.ins.2023.119108&partnerID=40&md5=f8b8a585a314d02d0724a1ec5ec7fa02
AB  - Transformer architectures have been applied to graph-specific data such as protein structure and shopper lists, and they perform accurately on graph/node classification and prediction tasks. Researchers have proved that the attention matrix in Transformers has low-rank properties, and the self-attention plays a scoring role in the aggregation function of the Transformers. However, it can not solve the issues such as heterophily and over-smoothing. The low-rank properties and the limitations of Transformers inspire this work to propose a Global Representation (GR) based attention mechanism to alleviate the two heterophily and over-smoothing issues. First, this GR-based model integrates geometric information of the nodes of interest that conveys the structural properties of the graph. Unlike a typical Transformer where a node feature forms a Key, we propose to use GR to construct the Key, which discovers the relation between the nodes and the structural representation of the graph. Next, we present various compositions of GR emanating from nodes of interest and α-hop neighbors. Then, we explore this attention property with an extensive experimental test to assess the performance and the possible direction of improvements for future works. Additionally, we provide mathematical proof showing the efficient feature update in our proposed method. Finally, we verify and validate the performance of the model on eight benchmark datasets that show the effectiveness of the proposed method. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; FMS:B; 
LB  - Kong2023Low-rank
ER  -

TY  - JOUR
AU  - Myronov, A.
AU  - Mazzocco, G.
AU  - Król, P.
AU  - Plewczynski, D.
TI  - BERTrand-peptide:TCR binding prediction using Bidirectional Encoder Representations from Transformers augmented with random TCR pairing
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 8
C7  - btad468
DO  - 10.1093/bioinformatics/btad468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168777174&doi=10.1093%2fbioinformatics%2fbtad468&partnerID=40&md5=d6b1500eabb6a525f0d434eeeaf65cd8
AB  - Motivation: The advent of T-cell receptor (TCR) sequencing experiments allowed for a significant increase in the amount of peptide:TCR binding data available and a number of machine-learning models appeared in recent years. High-quality prediction models for a fixed epitope sequence are feasible, provided enough known binding TCR sequences are available. However, their performance drops significantly for previously unseen peptides. Results: We prepare the dataset of known peptide:TCR binders and augment it with negative decoys created using healthy donors' T-cell repertoires. We employ deep learning methods commonly applied in Natural Language Processing to train part a peptide:TCR binding model with a degree of cross-peptide generalization (0.69 AUROC). We demonstrate that BERTrand outperforms the published methods when evaluated on peptide sequences not used during model training.  © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Hartout, P.
AU  - Počuča, B.
AU  - Méndez-García, C.
AU  - Schleberger, C.
TI  - Investigating the human and nonobese diabetic mouse MHC class II immunopeptidome using protein language modeling
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 8
C7  - btad469
DO  - 10.1093/bioinformatics/btad469
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167847433&doi=10.1093%2fbioinformatics%2fbtad469&partnerID=40&md5=d580d17b78b0741a779d1cc7b352e88d
AB  - Motivation: Identifying peptides associated with the major histocompability complex class II (MHCII) is a central task in the evaluation of the immunoregulatory function of therapeutics and drug prototypes. MHCII-peptide presentation prediction has multiple biopharmaceutical applications, including the safety assessment of biologics and engineered derivatives in silico, or the fast progression of antigen-specific immunomodulatory drug discovery programs in immune disease and cancer. This has resulted in the collection of large-scale datasets on adaptive immune receptor antigenic responses and MHC-associated peptide proteomics. In parallel, recent deep learning algorithmic advances in protein language modeling have shown potential in leveraging large collections of sequence data and improve MHC presentation prediction. Results: Here, we train a compact transformer model (AEGIS) on human and mouse MHCII immunopeptidome data, including a preclinical murine model, and evaluate its performance on the peptide presentation prediction task. We show that the transformer performs on par with existing deep learning algorithms and that combining datasets from multiple organisms increases model performance. We trained variants of the model with and without MHCII information. In both alternatives, the inclusion of peptides presented by the I-Ag7 MHC class II molecule expressed by nonobese diabetic mice enabled for the first time the accurate in silico prediction of presented peptides in a preclinical type 1 diabetes model organism, which has promising therapeutic applications. © 2023 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shen, L.
AU  - Wei, Y.
AU  - Wang, Y.
TI  - GBT: Two-stage transformer framework for non-stationary time series forecasting
PY  - 2023
T2  - Neural Networks
VL  - 165
SP  - 953
EP  - 970
DO  - 10.1016/j.neunet.2023.06.044
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165232889&doi=10.1016%2fj.neunet.2023.06.044&partnerID=40&md5=446d28027f945c1c73b40322ae525950
AB  - This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, especially when handling non-stationary time series. Based on this observation, we propose GBT, a novel two-stage Transformer framework with Good Beginning. It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences. Prediction results of Auto-Regression stage serve as a ‘Good Beginning’, i.e., a better initialization for inputs of Self-Regression stage. We also propose the Error Score Modification module to further enhance the forecasting capability of the Self-Regression stage in GBT. Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity. It is also general enough to couple with these models to strengthen their forecasting capability. The source code is available at: https://github.com/OrigamiSL/GBT © 2023 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Gao, L.
AU  - Yang, J.
AU  - Xu, S.
AU  - Ye, J.
AU  - Zhang, X.
AU  - Lai, Y.-K.
TI  - Deep Deformation Detail Synthesis for Thin Shell Models
PY  - 2023
T2  - Computer Graphics Forum
VL  - 42
IS  - 5
C7  - e14903
DO  - 10.1111/cgf.14903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167718579&doi=10.1111%2fcgf.14903&partnerID=40&md5=d699f66b5a888c67f43110916b4f83ba
AB  - In physics-based cloth animation, rich folds and detailed wrinkles are achieved at the cost of expensive computational resources and huge labor tuning. Data-driven techniques make efforts to reduce the computation significantly by utilizing a preprocessed database. One type of methods relies on human poses to synthesize fitted garments, but these methods cannot be applied to general cloth animations. Another type of methods adds details to the coarse meshes obtained through simulation, which does not have such restrictions. However, existing works usually utilize coordinate-based representations which cannot cope with large-scale deformation, and requires dense vertex correspondences between coarse and fine meshes. Moreover, as such methods only add details, they require coarse meshes to be sufficiently close to fine meshes, which can be either impossible, or require unrealistic constraints to be applied when generating fine meshes. To address these challenges, we develop a temporally and spatially as-consistent-as-possible deformation representation (named TS-ACAP) and design a DeformTransformer network to learn the mapping from low-resolution meshes to ones with fine details. This TS-ACAP representation is designed to ensure both spatial and temporal consistency for sequential large-scale deformations from cloth animations. With this TS-ACAP representation, our DeformTransformer network first utilizes two mesh-based encoders to extract the coarse and fine features using shared convolutional kernels, respectively. To transduct the coarse features to the fine ones, we leverage the spatial and temporal Transformer network that consists of vertex-level and frame-level attention mechanisms to ensure detail enhancement and temporal coherence of the prediction. Experimental results show that our method is able to produce reliable and realistic animations in various datasets at high frame rates with superior detail synthesis abilities compared to existing methods. © 2023 Eurographics - The European Association for Computer Graphics and John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Mazuz, E.
AU  - Shtar, G.
AU  - Kutsky, N.
AU  - Rokach, L.
AU  - Shapira, B.
TI  - Pretrained transformer models for predicting the withdrawal of drugs from the market
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 8
C7  - btad519
DO  - 10.1093/bioinformatics/btad519
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169296331&doi=10.1093%2fbioinformatics%2fbtad519&partnerID=40&md5=ab2412ac1dbc2f1f04e1023466217532
AB  - Motivation: The process of drug discovery is notoriously complex, costing an average of 2.6 billion dollars and taking ∼13 years to bring a new drug to the market. The success rate for new drugs is alarmingly low (around 0.0001%), and severe adverse drug reactions (ADRs) frequently occur, some of which may even result in death. Early identification of potential ADRs is critical to improve the efficiency and safety of the drug development process. Results: In this study, we employed pretrained large language models (LLMs) to predict the likelihood of a drug being withdrawn from the market due to safety concerns. Our method achieved an area under the curve (AUC) of over 0.75 through cross-database validation, outperforming classical machine learning models and graph-based models. Notably, our pretrained LLMs successfully identified over 50% drugs that were subsequently withdrawn, when predictions were made on a subset of drugs with inconsistent labeling between the training and test sets.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Tang, C.
AU  - Hu, Q.
AU  - Zhou, G.
AU  - Yao, J.
AU  - Zhang, J.
AU  - Huang, Y.
AU  - Ye, Q.
TI  - Transformer Sub-Patch Matching for High-Performance Visual Object Tracking
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 8
SP  - 8121
EP  - 8135
DO  - 10.1109/TITS.2023.3264664
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153373340&doi=10.1109%2fTITS.2023.3264664&partnerID=40&md5=ba9e8c6583023e3122a2051079af6f26
AB  - Visual tracking is a core component of intelligent transportation systems, especially for unmanned driving and road surveillance. Numerous convolutional neural network (CNN) trackers have achieved unprecedented performance. However, CNN features with regular spatial context relationships experience difficulty matching the rigid target templates when dramatic deformation and occlusion occur. In this paper, we propose a novel full Transformer Sub-patch Matching network for tracking (TSMtrack), which decomposes the tracked object into sub-patches, and interlaced matches the extracted sub-patches by leveraging the attention mechanism born with the Transformer. Roots in Transformer architecture, TSMtrack consists of image patch decomposition, sub-patch matching, and position prediction. Specifically, TSMtrack converts the whole frame into sub-patches and extracts the sub-patch features independently. By sub-patch matching and FFN-like prediction, TSMtrack enables independent similarity measurement between sub-patch features in an interlaced and iterative fashion. With a full Transformer pipeline implemented, we achieve a high-quality trade-off between tracking speed performance. Experiments on nine benchmarks demonstrate the effectiveness of our Transformer sub-patch matching framework. In particular, it realizes an AO of 75.6 on GOT-10K and SR of 57.9 on WebUAV-3M with 48 FPS on GPU RTX-2060s.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; FMS:B; 
LB  - Tang2023Transformer
ER  -

TY  - JOUR
AU  - Rafiei, F.
AU  - Zeraati, H.
AU  - Abbasi, K.
AU  - Ghasemi, J.B.
AU  - Parsaeian, M.
AU  - Masoudi-Nejad, A.
TI  - DeepTraSynergy: drug combinations using multimodal deep learning with transformers
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 8
C7  - btad438
DO  - 10.1093/bioinformatics/btad438
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166442606&doi=10.1093%2fbioinformatics%2fbtad438&partnerID=40&md5=e4127e1ed84f87845ae40d398d5832eb
AB  - Motivation: Screening bioactive compounds in cancer cell lines receive more attention. Multidisciplinary drugs or drug combinations have a more effective role in treatments and selectively inhibit the growth of cancer cells. Results: Hence, we propose a new deep learning-based approach for drug combination synergy prediction called DeepTraSynergy. Our proposed approach utilizes multimodal input including drug–target interaction, protein–protein interaction, and cell–target interaction to predict drug combination synergy. To learn the feature representation of drugs, we have utilized transformers. It is worth noting that our approach is a multitask approach that predicts three outputs including the drug–target interaction, its toxic effect, and drug combination synergy. In our approach, drug combination synergy is the main task and the two other ones are the auxiliary tasks that help the approach to learn a better model. In the proposed approach three loss functions are defined: synergy loss, toxic loss, and drug–protein interaction loss. The last two loss functions are designed as auxiliary losses to help learn a better solution. DeepTraSynergy outperforms the classic and state-of-the-art models in predicting synergistic drug combinations on the two latest drug combination datasets. The DeepTraSynergy algorithm achieves accuracy values of 0.7715 and 0.8052 (an improvement over other approaches) on the DrugCombDB and OncologyScreen datasets, respectively. Also, we evaluate the contribution of each component of DeepTraSynergy to show its effectiveness in the proposed method. The introduction of the relation between proteins (PPI networks) and drug–protein interaction significantly improves the prediction of synergistic drug combinations. © 2023 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Sortino, R.
AU  - Palazzo, S.
AU  - Rundo, F.
AU  - Spampinato, C.
TI  - Transformer-based image generation from scene graphs
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 233
C7  - 103721
DO  - 10.1016/j.cviu.2023.103721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160002264&doi=10.1016%2fj.cviu.2023.103721&partnerID=40&md5=1d07d597cffea4f402be18e1ffe1139f
AB  - Graph-structured scene descriptions can be efficiently used in generative models to control the composition of the generated image. Previous approaches are based on the combination of graph convolutional networks and adversarial methods for layout prediction and image generation, respectively. In this work, we show how employing multi-head attention to encode the graph information, as well as using a transformer-based model in the latent space for image generation can improve the quality of the sampled data, without the need to employ adversarial models with the subsequent advantage in terms of training stability. The proposed approach, specifically, is entirely based on transformer architectures both for encoding scene graphs into intermediate object layouts and for decoding these layouts into images, passing through a lower dimensional space learned by a vector-quantized variational autoencoder. Our approach shows an improved image quality with respect to state-of-the-art methods as well as a higher degree of diversity among multiple generations from the same scene graph. We evaluate our approach on three public datasets: Visual Genome, COCO, and CLEVR. We achieve an Inception Score of 13.7 and 12.8, and an FID of 52.3 and 60.3, on COCO and Visual Genome, respectively. We perform ablation studies on our contributions to assess the impact of each component. Code is available at https://github.com/perceivelab/trf-sg2im. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chien, C.-H.
AU  - Trappey, A.J.C.
AU  - Wang, C.-C.
TI  - ARIMA-AdaBoost hybrid approach for product quality prediction in advanced transformer manufacturing
PY  - 2023
T2  - Advanced Engineering Informatics
VL  - 57
C7  - 102055
DO  - 10.1016/j.aei.2023.102055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163027314&doi=10.1016%2fj.aei.2023.102055&partnerID=40&md5=f601472e7fded48b1ae77a361cf39d87
AB  - End product quality prediction is one of the key issues in smart manufacturing. Reliable evaluation and parameter optimization is needed to ensure their high-quality production outputs. This study develops a novel approach that integrates adaptive machine learning and nonlinear regression to accurately predict highly customized end product quality based on small sets of supply-chain data through digital transformation, especially for complex industrial machinery manufacturing. This study was conducted in collaboration with a major power transformer manufacturer and its supply chain partners. Using the supply chain's key component real dataset, the qualities of end products are predicted using the adaptive model trained and validated with reliable accuracy. The power transformer key component parameter, i.e., core (or iron) loss, is incorporated as an input dataset for prediction model training and testing. The novel model integrates autoregressive integrated moving average (ARIMA) and adaptive boosting (AdaBoost) machine learning, called ARIMA-AdaBoost. Compared with the previous research, the experiment results have shown that the ARIMA-AdaBoost outperforms the simple AdaBoost and Long Short-Term Memory (LSTM)-AdaBoost for transformer quality predictions. The ARIMA-AdaBoost model outperforms the existing methodologies in terms of mean absolute percentage error (MAE) and root mean square error (RMSE) in real-data verification. The proposed approach benefits the manufacturers in overall production costs for predicting complex, expensive, and highly customized industrial product qualities and is adaptable to various industrial sectors. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xie, L.
AU  - Xie, L.
TI  - Elucidation of genome-wide understudied proteins targeted by PROTAC-induced degradation using interpretable machine learning
PY  - 2023
T2  - PLoS Computational Biology
VL  - 19
IS  - 8 August
C7  - e1010974
DO  - 10.1371/journal.pcbi.1010974
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168798359&doi=10.1371%2fjournal.pcbi.1010974&partnerID=40&md5=d1224e3ba3e32c7bd1a23e01398d037c
AB  - Proteolysis-targeting chimeras (PROTACs) are hetero-bifunctional molecules that induce the degradation of target proteins by recruiting an E3 ligase. PROTACs have the potential to inactivate disease-related genes that are considered undruggable by small molecules, making them a promising therapy for the treatment of incurable diseases. However, only a few hundred proteins have been experimentally tested for their amenability to PROTACs, and it remains unclear which other proteins in the entire human genome can be targeted by PROTACs. In this study, we have developed PrePROTAC, an interpretable machine learning model based on a transformer-based protein sequence descriptor and random forest classification. PrePROTAC predicts genome-wide targets that can be degraded by CRBN, one of the E3 ligases. In the benchmark studies, PrePROTAC achieved a ROC-AUC of 0.81, an average precision of 0.84, and over 40% sensitivity at a false positive rate of 0.05. When evaluated by an external test set which comprised proteins from different structural folds than those in the training set, the performance of PrePROTAC did not drop significantly, indicating its generalizability. Furthermore, we developed an embedding SHapley Additive exPlanations (eSHAP) method, which extends conventional SHAP analysis for original features to an embedding space through in silico mutagenesis. This method allowed us to identify key residues in the protein structure that play critical roles in PROTAC activity. The identified key residues were consistent with existing knowledge. Using PrePROTAC, we identified over 600 novel understudied proteins that are potentially degradable by CRBN and proposed PROTAC compounds for three novel drug targets associated with Alzheimer’s disease. © 2023 Xie, Xie. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gomes, L.
AU  - da Silva Torres, R.
AU  - Côrtes, M.L.
TI  - BERT- and TF-IDF-based feature extraction for long-lived bug prediction in FLOSS: A comparative study
PY  - 2023
T2  - Information and Software Technology
VL  - 160
C7  - 107217
DO  - 10.1016/j.infsof.2023.107217
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152939913&doi=10.1016%2fj.infsof.2023.107217&partnerID=40&md5=938e8ab6fdc27e7fe4fe0274662aa1a2
AB  - Context: The correct prediction of long-lived bugs could help maintenance teams to build their plan and to fix more bugs that often adversely affect software quality and disturb the user experience across versions in Free/Libre Open-Source Software (FLOSS). Machine Learning and Text Mining methods have been applied to solve many real-world prediction problems, including bug report handling. Objective: Our research aims to compare the accuracy of ML classifiers on long-lived bug prediction in FLOSS using Bidirectional Encoder Representations from Transformers (BERT)- and Term Frequency - Inverse Document Frequency (TF-IDF)-based feature extraction. Besides that, we aim to investigate BERT variants on the same task. Method: We collected bug reports from six popular FLOSS and used the Machine Learning classifiers to predict long-lived bugs. Furthermore, we compare different feature extractors, based on BERT and TF-IDF methods, in long-lived bug prediction. Results: We found that long-lived bug prediction using BERT-based feature extraction systematically outperformed the TF-IDF. The SVM and Random Forest outperformed other classifiers in almost all datasets using BERT. Furthermore, smaller BERT architectures show themselves as competitive. Conclusion: Our results demonstrated a promising avenue to predict long-lived bugs based on BERT contextual embedding features and fine-tuning procedures. © 2023 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:B期刊; FMS:B; 
LB  - Gomes2023BERT
ER  -

TY  - JOUR
AU  - Ni, Z.
AU  - Valls Mascaró, E.
AU  - Ahn, H.
AU  - Lee, D.
TI  - Human–object interaction prediction in videos through gaze following
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 233
C7  - 103741
DO  - 10.1016/j.cviu.2023.103741
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161302203&doi=10.1016%2fj.cviu.2023.103741&partnerID=40&md5=07cf8c073c8f9201b1afbb4f22a13782
AB  - Understanding the human–object interactions (HOIs) from a video is essential to fully comprehend a visual scene. This line of research has been addressed by detecting HOIs from images and lately from videos. However, the video-based HOI anticipation task in the third-person view remains understudied. In this paper, we design a framework to detect current HOIs and anticipate future HOIs in videos. We propose to leverage human gaze information since people often fixate on an object before interacting with it. These gaze features together with the scene contexts and the visual appearances of human–object pairs are fused through a spatio-temporal transformer. To evaluate the model in the HOI anticipation task in a multi-person scenario, we propose a set of person-wise multi-label metrics. Our model is trained and validated on the VidHOI dataset, which contains videos capturing daily life and is currently the largest video HOI dataset. Experimental results in the HOI detection task show that our approach improves the baseline by a great margin of 36.3% relatively. Moreover, we conduct an extensive ablation study to demonstrate the effectiveness of our modifications and extensions to the spatio-temporal transformer. Our code is publicly available on. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hao, C.
AU  - Mao, X.
AU  - Ma, T.
AU  - He, S.
AU  - Li, B.
AU  - Liu, H.
AU  - Peng, F.
AU  - Zhang, L.
TI  - A novel deep learning method with partly explainable: Intelligent milling tool wear prediction model based on transformer informed physics
PY  - 2023
T2  - Advanced Engineering Informatics
VL  - 57
C7  - 102106
DO  - 10.1016/j.aei.2023.102106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166488219&doi=10.1016%2fj.aei.2023.102106&partnerID=40&md5=e568919abcc247e20047c9f0e47f09de
AB  - With the trend of lightweight in the field of intelligent electric vehicles and 3C, the demand for high precision machining of aluminum alloy parts is growing. And tool condition monitoring (TCM) is very important for quality control of parts, so intelligent high-accuracy wear prediction of aluminum alloy high precision machining tools has great industrial application value at present and in the future. This paper presents a novel TCM model (Conv-PhyFormer) of Transformer with physics informed. The model has excellent ability to capture short-term and long-term dependencies from nonlinear cutting time series data when there are few training samples. The embedded hard physical constraint and soft physical constraint in the model make the model partially interpretable. Soft physical constraint in the form of one-dimensional causal convolution can help the proposed model better learn the local context. Hard physical constraint in the form of the mathematical equation representing cutting physical knowledge are embedded, thus the model does not need to learn this knowledge from time series data from scratch. A large number of analysis results of aluminum alloy machining experimental data show that the proposed Conv-PhyFormer has significantly superior prediction accuracy and robustness compared with the current three popular deep learning models for TCM. Embedded soft and hard physical constraints can significantly reduce the training epochs of Transformer prediction model. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, E.
AU  - Fu, H.
AU  - Zhou, L.
AU  - Xu, D.
TI  - Bridging Synthetic and Real Images: A Transferable and Multiple Consistency Aided Fundus Image Enhancement Framework
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 8
SP  - 2189
EP  - 2199
DO  - 10.1109/TMI.2023.3247783
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149382538&doi=10.1109%2fTMI.2023.3247783&partnerID=40&md5=a7b566225e96a24c047087cdcc71987a
AB  - Deep learning based image enhancement models have largely improved the readability of fundus images in order to decrease the uncertainty of clinical observations and the risk of misdiagnosis. However, due to the difficulty of acquiring paired real fundus images at different qualities, most existing methods have to adopt synthetic image pairs as training data. The domain shift between the synthetic and the real images inevitably hinders the generalization of such models on clinical data. In this work, we propose an end-to-end optimized teacher-student framework to simultaneously conduct image enhancement and domain adaptation. The student network uses synthetic pairs for supervised enhancement, and regularizes the enhancement model to reduce domain-shift by enforcing teacher-student prediction consistency on the real fundus images without relying on enhanced ground-truth. Moreover, we also propose a novel multi-stage multi-attention guided enhancement network (MAGE-Net) as the backbones of our teacher and student network. Our MAGE-Net utilizes multi-stage enhancement module and retinal structure preservation module to progressively integrate the multi-scale features and simultaneously preserve the retinal structures for better fundus image quality enhancement. Comprehensive experiments on both real and synthetic datasets demonstrate that our framework outperforms the baseline approaches. Moreover, our method also benefits the downstream clinical tasks.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tao, C.
AU  - Cao, J.
AU  - Wang, C.
AU  - Zhang, Z.
AU  - Gao, Z.
TI  - Pseudo-Mono for Monocular 3D Object Detection in Autonomous Driving
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 8
SP  - 3962
EP  - 3975
DO  - 10.1109/TCSVT.2023.3237579
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147294317&doi=10.1109%2fTCSVT.2023.3237579&partnerID=40&md5=06fbbf42ddd81eada414af2af52d3cb9
AB  - Current monocular 3D object detection algorithms generally suffer from inaccurate depth estimation, which leads to reduction of detection accuracy. The depth error from image-to-image generation for the stereo view is insignificant compared with the gap in single-image generation. Therefore, a novel pseudo-monocular 3D object detection framework is proposed, which is called Pseudo-Mono. Particularly, stereo images are brought into monocular 3D detection. Firstly, stereo images are taken as input, then a lightweight depth predictor is used to generate the depth map of input images. Secondly, the left input images obtained from stereo camera are used as subjects, which generate enhanced visual feature and multi-scale depth feature by depth indexing and feature matching probabilities, respectively. Finally, sparse anchors set by the foreground probability maps and the multi-scale feature maps are used as reference points to find the suitable initialization approach of object query. The encoded visual feature is adopted to enhance object query for enabling deep interaction between visual feature and depth feature. Compared with popular monocular 3D object detection methods, Pseudo-Mono is able to achieve richer fine-grained information without additional data input. Extensive experimental results on the datasets of KITTI, NuScenes, and MS-COCO demonstrate the generalizability and portability of the proposed method. The effectiveness and efficiency of Pseudo-Mono have been demonstrated by extensive ablation experiments. Experiments on a real vehicle platform have shown that the proposed method maintains high performance in complex real-world environments.  © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Darmawan, J.T.
AU  - Leu, J.-S.
AU  - Avian, C.
AU  - Ratnasari, N.R.P.
TI  - MITNet: a fusion transformer and convolutional neural network architecture approach for T-cell epitope prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 4
C7  - bbad202
DO  - 10.1093/bib/bbad202
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165521695&doi=10.1093%2fbib%2fbbad202&partnerID=40&md5=4d42d2f2b283e2a9300e0d558f575987
AB  - Classifying epitopes is essential since they can be applied in various fields, including therapeutics, diagnostics and peptide-based vaccines. To determine the epitope or peptide against an antibody, epitope mapping with peptides is the most extensively used method. However, this method is more time-consuming and inefficient than using present methods. The ability to retrieve data on protein sequences through laboratory procedures has led to the development of computational models that predict epitope binding based on machine learning and deep learning (DL). It has also evolved to become a crucial part of developing effective cancer immunotherapies. This paper proposes an architecture to generalize this case since various research strives to solve a low-performance classification problem. A proposed DL model is the fusion architecture, which combines two architectures: Transformer architecture and convolutional neural network (CNN), called MITNet and MITNet-Fusion. Combining these two architectures enriches feature space to correlate epitope labels with the binary classification method. The selected epitope–T-cell receptor (TCR) interactions are GILG, GLCT and NLVP, acquired from three databases: IEDB, VDJdb and McPAS-TCR. The previous input data was extracted using amino acid composition, dipeptide composition, spectrum descriptor and the combination of all those features called AADIP composition to encode the input data to DL architecture. For ensuring consistency, fivefold cross-validations were performed using the area under curve metric. Results showed that GILG, GLCT and NLVP received scores of 0.85, 0.87 and 0.86, respectively. Those results were compared to prior architecture and outperformed other similar deep learning models. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Jia, X.
AU  - Zhang, L.
AU  - Li, Y.
AU  - Elder, J.H.
AU  - Lu, H.
TI  - A uniform transformer-based structure for feature fusion and enhancement for RGB-D saliency detection
PY  - 2023
T2  - Pattern Recognition
VL  - 140
C7  - 109516
DO  - 10.1016/j.patcog.2023.109516
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151541432&doi=10.1016%2fj.patcog.2023.109516&partnerID=40&md5=75cad48039d210b1dccb4009c9685349
AB  - RGB-D saliency detection integrates information from both RGB images and depth maps to improve the prediction of salient regions under challenging conditions. The key to RGB-D saliency detection is to fully mine and fuse information at multiple scales across the two modalities. Previous approaches tend to apply the multi-scale and multi-modal fusion separately via local operations, which fails to capture long-range dependencies. Here we propose a transformer-based structure to address this issue. The proposed architecture is composed of two modules: an Intra-modality Feature Enhancement Module (IFEM) and an Inter-modality Feature Fusion Module (IFFM). IFFM conducts a sufficient feature fusion by integrating features from multiple scales and two modalities over all positions simultaneously. IFEM enhances feature on each scale by selecting and integrating complementary information from other scales within the same modality before IFFM. We show that transformer is a uniform operation which presents great efficacy in both feature fusion and feature enhancement, and simplifies the model design. Extensive experimental results on five benchmark datasets demonstrate that our proposed network performs favorably against most state-of-the-art RGB-D saliency detection methods. Furthermore, our model is efficient for having relatively smaller FLOPs and model size compared with other methods. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, H.
AU  - Liu, T.
AU  - Wang, Z.
TI  - scHiMe: predicting single-cell DNA methylation levels based on single-cell Hi-C data
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 4
C7  - bbad223
DO  - 10.1093/bib/bbad223
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165521730&doi=10.1093%2fbib%2fbbad223&partnerID=40&md5=206d5dcf96920dd82c56a659480887cd
AB  - Recently a biochemistry experiment named methyl-3C was developed to simultaneously capture the chromosomal conformations and DNA methylation levels on individual single cells. However, the number of data sets generated from this experiment is still small in the scientific community compared with the greater amount of single-cell Hi-C data generated from separate single cells. Therefore, a computational tool to predict single-cell methylation levels based on single-cell Hi-C data on the same individual cells is needed. We developed a graph transformer named scHiMe to accurately predict the base-pair-specific (bp-specific) methylation levels based on both single-cell Hi-C data and DNA nucleotide sequences. We benchmarked scHiMe for predicting the bp-specific methylation levels on all of the promoters of the human genome, all of the promoter regions together with the corresponding first exon and intron regions, and random regions on the whole genome. Our evaluation showed a high consistency between the predicted and methyl-3C-detected methylation levels. Moreover, the predicted DNA methylation levels resulted in accurate classifications of cells into different cell types, which indicated that our algorithm successfully captured the cell-to-cell variability in the single-cell Hi-C data. scHiMe is freely available at http://dna.cs.miami.edu/scHiMe/. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Deng, J.
AU  - Zhou, X.
AU  - Zhang, P.
AU  - Cheng, W.
AU  - Liu, M.
AU  - Tian, J.
TI  - IEPAPI: a method for immune epitope prediction by incorporating antigen presentation and immunogenicity
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 4
C7  - bad171
DO  - 10.1093/bib/bbad171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167681706&doi=10.1093%2fbib%2fbbad171&partnerID=40&md5=9c325a9c94b5aa90b205b6f1084eb522
AB  - CD8+ T cells can recognize peptides presented by class I human leukocyte antigen (HLA-I) of nucleated cells. Exploring this immune mechanism is essential for identifying T-cell vaccine targets in cancer immunotherapy. Over the past decade, the wealth of data generated by experiments has spawned many computational approaches for predicting HLA-I binding, antigen presentation and T-cell immune responses. Nevertheless, existing HLA-I binding and antigen presentation prediction approaches suffer from low precision due to the absence of T-cell receptor (TCR) recognition. Direct modeling of T-cell immune responses is less effective as TCR recognition's mechanism still remains underexplored. Therefore, directly applying these existing methods to screen cancer neoantigens is still challenging. Here, we propose a novel immune epitope prediction method termed IEPAPI by effectively incorporating antigen presentation and immunogenicity. First, IEPAPI employs a transformer-based feature extraction block to acquire representations of peptides and HLA-I proteins. Second, IEPAPI integrates the prediction of antigen presentation prediction into the input of immunogenicity prediction branch to simulate the connection between the biological processes in the T-cell immune response. Quantitative comparison results on an independent antigen presentation test dataset exhibit that IEPAPI outperformed the current state-of-the-art approaches NetMHCpan4.1 and mhcf lurry2.0 on 100 (25/25) and 76% (19/25) of the HLA subtypes, respectively. Furthermore, IEPAPI demonstrates the best precision on two independent neoantigen datasets when compared with existing approaches, suggesting that IEPAPI provides a vital tool for T-cell vaccine design. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ding, P.
AU  - Wang, Y.
AU  - Zhang, X.
AU  - Gao, X.
AU  - Liu, G.
AU  - Yu, B.
TI  - DeepSTF: predicting transcription factor binding sites by interpretable deep neural networks combining sequence and shape
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 4
C7  - bbad231
DO  - 10.1093/bib/bbad231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167350099&doi=10.1093%2fbib%2fbbad231&partnerID=40&md5=8fe545d6879e9776d75d0e028a8d299b
AB  - Precise targeting of transcription factor binding sites (TFBSs) is essential to comprehending transcriptional regulatory processes and investigating cellular function. Although several deep learning algorithms have been created to predict TFBSs, the models’ intrinsic mechanisms and prediction results are difficult to explain. There is still room for improvement in prediction performance. We present DeepSTF, a unique deep-learning architecture for predicting TFBSs by integrating DNA sequence and shape profiles. We use the improved transformer encoder structure for the first time in the TFBSs prediction approach. DeepSTF extracts DNA higher-order sequence features using stacked convolutional neural networks (CNNs), whereas rich DNA shape profiles are extracted by combining improved transformer encoder structure and bidirectional long short-term memory (Bi-LSTM), and, finally, the derived higher-order sequence features and representative shape profiles are integrated into the channel dimension to achieve accurate TFBSs prediction. Experiments on 165 ENCODE chromatin immunoprecipitation sequencing (ChIP-seq) datasets show that DeepSTF considerably outperforms several state-of-the-art algorithms in predicting TFBSs, and we explain the usefulness of the transformer encoder structure and the combined strategy using sequence features and shape profiles in capturing multiple dependencies and learning essential features. In addition, this paper examines the significance of DNA shape features predicting TFBSs. The source code of DeepSTF is available at https://github.com/YuBinLab-QUST/DeepSTF/. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhan, Y.
AU  - Guo, J.
AU  - Philip Chen, C.L.
AU  - Meng, X.-B.
TI  - iBT-Net: an incremental broad transformer network for cancer drug response prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 4
C7  - bbad256
DO  - 10.1093/bib/bbad256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165521639&doi=10.1093%2fbib%2fbbad256&partnerID=40&md5=e9b9b89f449d80ad4022ba22f42ff3e7
AB  - In modern precision medicine, it is an important research topic to predict cancer drug response. Due to incomplete chemical structures and complex gene features, however, it is an ongoing work to design efficient data-driven methods for predicting drug response. Moreover, since the clinical data cannot be easily obtained all at once, the data-driven methods may require relearning when new data are available, resulting in increased time consumption and cost. To address these issues, an incremental broad Transformer network (iBT-Net) is proposed for cancer drug response prediction. Different from the gene expression features learning from cancer cell lines, structural features are further extracted from drugs by Transformer. Broad learning system is then designed to integrate the learned gene features and structural features of drugs to predict the response. With the capability of incremental learning, the proposed method can further use new data to improve its prediction performance without retraining totally. Experiments and comparison studies demonstrate the effectiveness and superiority of iBT-Net under different experimental configurations and continuous data learning. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Zhao, X.
AU  - Zhang, X.
AU  - Paliwal, M.
TI  - Real-Time Forecasting of Dockless Scooter-Sharing Demand: A Spatio-Temporal Multi-Graph Transformer Approach
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 8
SP  - 8507
EP  - 8518
DO  - 10.1109/TITS.2023.3239309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148438643&doi=10.1109%2fTITS.2023.3239309&partnerID=40&md5=d71ae67d54e2e88adf57ede9b55ab40b
AB  - Accurately forecasting the real-time travel demand for dockless scooter-sharing is crucial for the planning and operations of transportation systems. Deep learning models provide researchers with powerful tools to achieve this task, but research in this area is still lacking. This paper thus proposes a novel deep learning architecture named Spatio-Temporal Multi-Graph Transformer (STMGT) to forecast the real-time spatiotemporal dockless scooter-sharing demand. The proposed model uses a graph convolutional network (GCN) based on adjacency graph, functional similarity graph, demographic similarity graph, and transportation supply similarity graph to attach spatial dependency to temporal input (i.e., historical demand). The output of GCN is subsequently processed with weather condition information by the Transformer to capture temporal dependency. Then, a convolutional layer is used to generate the final prediction. The proposed model is evaluated for two real-world case studies in Washington, D.C. and Austin, TX, respectively, and the results show that for both case studies, STMGT significantly outperforms all the selected benchmark models, and the most important model component is the weather information. The proposed model can help micromobility operators develop optimal vehicle rebalancing schemes and guide cities to better manage dockless scooter-sharing operations.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; FMS:B; 
LB  - Xu2023Real-Time
ER  -

TY  - JOUR
AU  - Zhu, Y.
AU  - Zhao, W.
AU  - Hua, R.
AU  - Wu, X.
TI  - Topic-aware video summarization using multimodal transformer
PY  - 2023
T2  - Pattern Recognition
VL  - 140
C7  - 109578
DO  - 10.1016/j.patcog.2023.109578
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151555885&doi=10.1016%2fj.patcog.2023.109578&partnerID=40&md5=a5968bb886c03de54fbdcc6d8cf018d9
AB  - Video summarization aims to generate a short and compact summary to represent the original video. Existing methods mainly focus on how to extract a general objective synopsis that precisely summaries the video content. However, in real scenarios, a video usually contains rich content with multiple topics and people may cast diverse interests on the visual contents even for the same video. In this paper, we propose a novel topic-aware video summarization task that generates multiple video summaries with different topics. To support the study of this new task, we first build a video benchmark dataset by collecting videos from various types of movies and annotate them with topic labels and frame-level importance scores. Then we propose a multimodal Transformer model for the topic-aware video summarization, which simultaneously predicts topic labels and generates topic-related summaries by adaptively fusing multimodal features extracted from the video. Experimental results show the effectiveness of our method. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tang, Z.
AU  - Chen, Z.
AU  - Li, Z.
AU  - Zhong, B.
AU  - Zhang, X.
AU  - Zhang, X.
TI  - Unifying Dual-Attention and Siamese Transformer Network for Full-Reference Image Quality Assessment
PY  - 2023
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 19
IS  - 6
C7  - 205
DO  - 10.1145/3597434
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168308786&doi=10.1145%2f3597434&partnerID=40&md5=a1213bfee036782565db267afd02a07c
AB  - Image Quality Assessment (IQA) is a critical task of computer vision. Most Full-Reference (FR) IQA methods have limitation in the accurate prediction of perceptual qualities of the traditional distorted images and the Generative Adversarial Networks (GANs) based distorted images. To address this issue, we propose a novel method by Unifying Dual-Attention and Siamese Transformer Network (UniDASTN) for FR-IQA. An important contribution is the spatial attention module composed of a Siamese Transformer Network and a feature fusion block. It can focus on significant regions and effectively maps the perceptual differences between the reference and distorted images to a latent distance for distortion evaluation. Another contribution is the dual-attention strategy that exploits channel attention and spatial attention to aggregate features for enhancing distortion sensitivity. In addition, a novel loss function is designed by jointly exploiting Mean Square Error (MSE), bidirectional Kullback-Leibler divergence, and rank order of quality scores. The designed loss function can offer stable training and thus enables the proposed UniDASTN to effectively learn visual perceptual image quality. Extensive experiments on standard IQA databases are conducted to validate the effectiveness of the proposed UniDASTN. The IQA results demonstrate that the proposed UniDASTN outperforms some state-of-the-art FR-IQA methods on the LIVE, CSIQ, TID2013, and PIPAL databases.  © 2023 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xia, X.
AU  - Zhu, C.
AU  - Zhong, F.
AU  - Liu, L.
TI  - MDTips: a multimodal-data-based drug-target interaction prediction system fusing knowledge, gene expression profile, and structural data
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 7
C7  - btad411
DO  - 10.1093/bioinformatics/btad411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164271444&doi=10.1093%2fbioinformatics%2fbtad411&partnerID=40&md5=698c35b4484e7bccd66d6c3e7c73c6b0
AB  - Motivation: Screening new drug-target interactions (DTIs) by traditional experimental methods is costly and time-consuming. Recent advances in knowledge graphs, chemical linear notations, and genomic data enable researchers to develop computational-based-DTI models, which play a pivotal role in drug repurposing and discovery. However, there still needs to develop a multimodal fusion DTI model that integrates available heterogeneous data into a unified framework. Results: We developed MDTips, a multimodal-data-based DTI prediction system, by fusing the knowledge graphs, gene expression profiles, and structural information of drugs/targets. MDTips yielded accurate and robust performance on DTI predictions. We found that multimodal fusion learning can fully consider the importance of each modality and incorporate information from multiple aspects, thus improving model performance. Extensive experimental results demonstrate that deep learning-based encoders (i.e. Attentive FP and Transformer) outperform traditional chemical descriptors/fingerprints, and MDTips outperforms other state-of-the-art prediction models. MDTips is designed to predict the input drugs' candidate targets, side effects, and indications with all available modalities. Via MDTips, we reverse-screened candidate targets of 6766 drugs, which can be used for drug repurposing and discovery.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Korangi, K.
AU  - Mues, C.
AU  - Bravo, C.
TI  - A transformer-based model for default prediction in mid-cap corporate markets
PY  - 2023
T2  - European Journal of Operational Research
VL  - 308
IS  - 1
SP  - 306
EP  - 320
DO  - 10.1016/j.ejor.2022.10.032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143550150&doi=10.1016%2fj.ejor.2022.10.032&partnerID=40&md5=bf3c81e595f7896a3367391bc7df9610
AB  - In this paper, we study mid-cap companies, i.e. publicly traded companies with less than US$10 billion in market capitalisation. Using a large dataset of US mid-cap companies observed over 30 years, we look to predict the default probability term structure over the short to medium term and understand which data sources (i.e. fundamental, market or pricing data) contribute most to the default risk. Whereas existing methods typically require that data from different time periods are first aggregated and turned into cross-sectional features, we frame the problem as a multi-label panel data classification problem. To tackle it, we then employ transformer models, a state-of-the-art deep learning model emanating from the natural language processing domain. To make this approach suitable to the given credit risk setting, we use a loss function for multi-label classification, to deal with the term structure, and propose a multi-channel architecture with differential training that allows the model to use all input data efficiently. Our results show that the proposed deep learning architecture produces superior performance, resulting in a sizeable improvement in AUC (Area Under the receiver operating characteristic Curve) over traditional models. In order to interpret the model, we also demonstrate how to produce an importance ranking for the different data sources and their temporal relationships, using a Shapley approach for feature groups. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Korangi2023transformer-based
ER  -

TY  - JOUR
AU  - Jiang, Y.
AU  - Meng, R.
AU  - Huang, Y.
AU  - Lu, W.
AU  - Liu, J.
TI  - Generating keyphrases for readers: A controllable keyphrase generation framework
PY  - 2023
T2  - Journal of the Association for Information Science and Technology
VL  - 74
IS  - 7
SP  - 759
EP  - 774
DO  - 10.1002/asi.24749
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152078043&doi=10.1002%2fasi.24749&partnerID=40&md5=01cd8026a771549625906f2186732770
AB  - With the wide application of keyphrases in many Information Retrieval (IR) and Natural Language Processing (NLP) tasks, automatic keyphrase prediction has been emerging. However, these statistically important phrases are contributing increasingly less to the related tasks because the end-to-end learning mechanism enables models to learn the important semantic information of the text directly. Similarly, keyphrases are of little help for readers to quickly grasp the paper's main idea because the relationship between the keyphrase and the paper is not explicit to readers. Therefore, we propose to generate keyphrases with specific functions for readers to bridge the semantic gap between them and the information producers, and verify the effectiveness of the keyphrase function for assisting users’ comprehension with a user experiment. A controllable keyphrase generation framework (the CKPG) that uses the keyphrase function as a control code to generate categorized keyphrases is proposed and implemented based on Transformer, BART, and T5, respectively. For the Computer Science domain, the Macro-avgs of (Formula presented.), (Formula presented.), and (Formula presented.) on the Paper with Code dataset are up to 0.680, 0.535, and 0.558, respectively. Our experimental results indicate the effectiveness of the CKPG models. © 2023 Association for Information Science and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - FMS:A; 
LB  - Jiang2023Generating
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - He, Z.
AU  - Dang, R.
AU  - Chen, H.
AU  - Liu, C.
AU  - Chen, Q.
TI  - RES-StS: Referring Expression Speaker via Self-Training With Scorer for Goal-Oriented Vision-Language Navigation
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 7
SP  - 3441
EP  - 3454
DO  - 10.1109/TCSVT.2022.3233554
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147214696&doi=10.1109%2fTCSVT.2022.3233554&partnerID=40&md5=5f50ee9d5e674658256bbce9c9fabe25
AB  - It is a rather practical but difficult task to find a specified target object via autonomous exploration based on natural language descriptions in an unstructured environment. Since the human-annotated data is expensive to gather for the goal-oriented vision-language navigation (GVLN) task, the size of the standard dataset is inadequate, which has significantly limited the accuracy of previous techniques. In this work, we aim to improve the robustness and generalization of the navigator by dynamically providing high-quality pseudo-instructions using a proposed RES-StS paradigm. Specifically, we establish a referring expression speaker (RES) to predict descriptive instructions for the given path to the goal object. Based on an environment-and-object fusion (EOF) module, RES derives spatial representations from the input trajectories, which are subsequently encoded by a number of transformer layers. Additionally, given that the quality of the pseudo labels is important for data augmentation while the limited dataset may also hinder RES learning, we propose to equip RES with a more effective generation ability by using the self-training approach. A trajectory-instruction matching scorer (TIMS) network based on contrastive learning is proposed to selectively use rehearsal of prior knowledge. Finally, all network modules in the system are integrated by suggesting a multi-stage training strategy, allowing them to assist one another and thus enhance performance on the GVLN task. Experimental results demonstrate the effectiveness of our approach. Compared with the SOTA methods, our method improves SR, SPL, and RGS by 4.72%, 2.55%, and 3.45% respectively, on the REVERIE dataset, and 4.58%, 3.75% and 3.14% respectively, on the SOON dataset.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Gu, Z.
AU  - Luo, X.
AU  - Chen, J.
AU  - Deng, M.
AU  - Lai, L.
TI  - Hierarchical graph transformer with contrastive learning for protein function prediction
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 7
C7  - btad410
DO  - 10.1093/bioinformatics/btad410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164626192&doi=10.1093%2fbioinformatics%2fbtad410&partnerID=40&md5=20994ec2d42a072ac37e42bd58d789f9
AB  - Motivation: In recent years, high-throughput sequencing technologies have made large-scale protein sequences accessible. However, their functional annotations usually rely on low-throughput and pricey experimental studies. Computational prediction models offer a promising alternative to accelerate this process. Graph neural networks have shown significant progress in protein research, but capturing long-distance structural correlations and identifying key residues in protein graphs remains challenging. Results: In the present study, we propose a novel deep learning model named Hierarchical graph transformEr with contrAstive Learning (HEAL) for protein function prediction. The core feature of HEAL is its ability to capture structural semantics using a hierarchical graph Transformer, which introduces a range of super-nodes mimicking functional motifs to interact with nodes in the protein graph. These semantic-aware super-node embeddings are then aggregated with varying emphasis to produce a graph representation. To optimize the network, we utilized graph contrastive learning as a regularization technique to maximize the similarity between different views of the graph representation. Evaluation of the PDBch test set shows that HEAL-PDB, trained on fewer data, achieves comparable performance to the recent state-of-the-art methods, such as DeepFRI. Moreover, HEAL, with the added benefit of unresolved protein structures predicted by AlphaFold2, outperforms DeepFRI by a significant margin on Fmax, AUPR, and Smin metrics on PDBch test set. Additionally, when there are no experimentally resolved structures available for the proteins of interest, HEAL can still achieve better performance on AFch test set than DeepFRI and DeepGOPlus by taking advantage of AlphaFold2 predicted structures. Finally, HEAL is capable of finding functional sites through class activation mapping. © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Rao, Z.
AU  - Wang, H.
AU  - Chen, L.
AU  - Lian, Y.
AU  - Zhong, Y.
AU  - Liu, Z.
AU  - Cai, Y.
TI  - Monocular Road Scene Bird's Eye View Prediction via Big Kernel-Size Encoder and Spatial-Channel Transform Module
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 7
SP  - 7138
EP  - 7148
DO  - 10.1109/TITS.2023.3253554
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151547733&doi=10.1109%2fTITS.2023.3253554&partnerID=40&md5=21bfeb21344c9ba7692b071db485ee9d
AB  - A detailed representation of the surrounding road scene is crucial for an autonomous driving system. sethlcolor yellow The camera-based Bird's Eye View map has been a popular solution to present the surrounding information, due to its low cost and rich spatial context information. Most of the existing methods predict the BEV map based on the depth-estimation or the trivial homography method, which may cause the error propagation and the absence of content. To overcome these drawbacks, we propose a novel end-to-end framework that employs the front monocular image to predict the road layout and vehicle occupancy. In particular, to capture the long-range feature, we redesign a CNN encoder with a large kernel size to extract the image features. For reducing the big difference between the front image features and the top-down features, we propose a novel Spatial-Channel projection module to convert the front map into the top-down space. Additionally, concerning the correlation between front view and top-down view, we propose the Dual Cross-view Transformer module to refine the top-down view feature maps and strengthen the transformation. Extensive evaluations on the KITTI and Argoverse datasets present that the proposed model achieves the state-of-the-art results for both datasets. Furthermore, the proposed model runs in 37 FPS on a single GPU, demonstrating the generation of a real-time BEV map. The code will be published at https://github.com/raozhongyu/BEV-LKA.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Rao2023Monocular
ER  -

TY  - JOUR
AU  - Liu, H.-Y.
AU  - Guo, J.-W.
AU  - Jiang, H.-Y.
AU  - Liu, Y.-C.
AU  - Zhang, X.-P.
AU  - Yan, D.-M.
TI  - PuzzleNet: Boundary-Aware Feature Matching for Non-Overlapping 3D Point Clouds Assembly
PY  - 2023
T2  - Journal of Computer Science and Technology
VL  - 38
IS  - 3
SP  - 492
EP  - 509
DO  - 10.1007/s11390-023-3127-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167523211&doi=10.1007%2fs11390-023-3127-8&partnerID=40&md5=e1c7aa942523f077192ccfe01dfcb4c7
AB  - We address the 3D shape assembly of multiple geometric pieces without overlaps, a scenario often encountered in 3D shape design, field archeology, and robotics. Existing methods depend on strong assumptions on the number of shape pieces and coherent geometry or semantics of shape pieces. Despite raising attention to 3D registration with complex or low overlapping patterns, few methods consider shape assembly with rare overlaps. To address this problem, we present a novel framework inspired by solving puzzles, named PuzzleNet, which conducts multi-task learning by leveraging both 3D alignment and boundary information. Specifically, we design an end-to-end neural network based on a point cloud transformer with two-way branches for estimating rigid transformation and predicting boundaries simultaneously. The framework is then naturally extended to reassemble multiple pieces into a full shape by using an iterative greedy approach based on the distance between each pair of candidate-matched pieces. To train and evaluate PuzzleNet, we construct two datasets, named DublinPuzzle and ModelPuzzle, based on a real-world urban scan dataset (DublinCity) and a synthetic CAD dataset (ModelNet40) respectively. Experiments demonstrate our effectiveness in solving 3D shape assembly for multiple pieces with arbitrary geometry and inconsistent semantics. Our method surpasses state-of-the-art algorithms by more than 10 times in rotation metrics and four times in translation metrics. © 2023, Institute of Computing Technology, Chinese Academy of Sciences.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zheng, X.
AU  - Sun, K.
AU  - Liu, W.
AU  - Zhang, Y.
TI  - Self-supervised vision transformer-based few-shot learning for facial expression recognition
PY  - 2023
T2  - Information Sciences
VL  - 634
SP  - 206
EP  - 226
DO  - 10.1016/j.ins.2023.03.105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150792082&doi=10.1016%2fj.ins.2023.03.105&partnerID=40&md5=dfe0f6b2a1670261a57bd9211daefc6e
AB  - Facial expression recognition (FER) is embedded in many real-world human-computer interaction tasks, such as online learning, depression recognition and remote diagnosis. However, FER is often hindered by privacy concerns and low recognition accuracy due to inadequate data transfer restrictions on public clouds, insufficient quantities of effective labeled samples and class imbalance. To address the above challenges, we have developed an automatic privacy-preserving learning state recognition system for supervising the quality of online teaching with the cooperation of edge servers and cloud servers to reduce the risk of privacy exposure. In particular, we propose few-shot facial expression recognition with a self-supervised vision transformer (SSF-ViT) by integrating self-supervised learning (SSL) and few-shot learning (FSL) to train a deep learning model with fewer labeled samples. Specifically, a vision transformer (ViT) is jointly pretrained with four self-supervised pretext tasks, including image denoising and reconstruction, image rotation prediction, jigsaw puzzle and masked patch prediction, to obtain a pretrained ViT encoder. Then, the pretrained ViT encoder is used on a lab-controlled labeled FER dataset to extract the spatiotemporal features and implement the FER task to fine-tune the parameters. Finally, we construct prototypes to verify the few-shot classification method for specific expression recognition. Support and query sets are divided in the wild FER dataset, and few-shot classification episodes are constructed. The fine-tuned ViT encoder is used as the feature extractor to build the prototype for each support set category, and the expression classification results are obtained by computing the Euclidean distance between the query samples and the prototypes. The extensive experimental results show that SSF-ViT can achieve recognition accuracies of 74.95%, 66.04%, 63.69% and 90.98% on the FER2013, AffectNet, SFEW 2.0 and RAF-DB datasets, respectively. In addition, SSF-ViT can improve the recognition performance of specific expression categories on these datasets. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2023Self-supervised
ER  -

TY  - JOUR
AU  - Chen, C.
AU  - Wang, H.-F.
AU  - Zhu, Q.-Q.
AU  - Liu, J.-F.
TI  - Graph Enhanced Transformer for Aspect Category Detection
PY  - 2023
T2  - Journal of Computer Science and Technology
VL  - 38
IS  - 3
SP  - 612
EP  - 625
DO  - 10.1007/s11390-021-1000-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167520292&doi=10.1007%2fs11390-021-1000-1&partnerID=40&md5=7820dbe43bc43b687394e84178d8c44e
AB  - Aspect category detection is one challenging subtask of aspect based sentiment analysis, which categorizes a review sentence into a set of predefined aspect categories. Most existing methods regard the aspect category detection as a flat classification problem. However, aspect categories are inter-related, and they are usually organized with a hierarchical tree structure. To leverage the structure information, this paper proposes a hierarchical multi-label classification model to detect aspect categories and uses a graph enhanced transformer network to integrate label dependency information into prediction features. Experiments have been conducted on four widely-used benchmark datasets, showing that the proposed model outperforms all strong baselines. © 2023, Institute of Computing Technology, Chinese Academy of Sciences.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Morehead, A.
AU  - Liu, J.
AU  - Cheng, J.
TI  - A gated graph transformer for protein complex structure quality assessment and its performance in CASP15
PY  - 2023
T2  - Bioinformatics
VL  - 39
SP  - I308
EP  - I317
DO  - 10.1093/bioinformatics/btad203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164234672&doi=10.1093%2fbioinformatics%2fbtad203&partnerID=40&md5=750a3c3e43d9555ddaa70e554df85b2e
AB  - Motivation: Proteins interact to form complexes to carry out essential biological functions. Computational methods such as AlphaFold-multimer have been developed to predict the quaternary structures of protein complexes. An important yet largely unsolved challenge in protein complex structure prediction is to accurately estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. Results: In this work, we introduce a new gated neighborhood-modulating graph transformer to predict the quality of 3D protein complex structures. It incorporates node and edge gates within a graph transformer framework to control information flow during graph message passing. We trained, evaluated and tested the method (called DProQA) on newly-curated protein complex datasets before the 15th Critical Assessment of Techniques for Protein Structure Prediction (CASP15) and then blindly tested it in the 2022 CASP15 experiment. The method was ranked 3rd among the single-model quality assessment methods in CASP15 in terms of the ranking loss of TM-score on 36 complex targets. The rigorous internal and external experiments demonstrate that DProQA is effective in ranking protein complex structures.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Dumitrescu, A.
AU  - Jokinen, E.
AU  - Paatero, A.
AU  - Kellosalo, J.
AU  - Paavilainen, V.O.
AU  - Lähdesmäki, H.
TI  - TSignal: a transformer model for signal peptide prediction
PY  - 2023
T2  - Bioinformatics
VL  - 39
SP  - I347
EP  - I356
DO  - 10.1093/bioinformatics/btad228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163693976&doi=10.1093%2fbioinformatics%2fbtad228&partnerID=40&md5=3a6a28e4cc720027987fe287d134dcc7
AB  - Motivation: Signal peptides (SPs) are short amino acid segments present at the N-terminus of newly synthesized proteins that facilitate protein translocation into the lumen of the endoplasmic reticulum, after which they are cleaved off. Specific regions of SPs influence the efficiency of protein translocation, and small changes in their primary structure can abolish protein secretion altogether. The lack of conserved motifs across SPs, sensitivity to mutations, and variability in the length of the peptides make SP prediction a challenging task that has been extensively pursued over the years. Results: We introduce TSignal, a deep transformer-based neural network architecture that utilizes BERT language models and dot-product attention techniques. TSignal predicts the presence of SPs and the cleavage site between the SP and the translocated mature protein. We use common benchmark datasets and show competitive accuracy in terms of SP presence prediction and state-of-the-art accuracy in terms of cleavage site prediction for most of the SP types and organism groups. We further illustrate that our fully data-driven trained model identifies useful biological information on heterogeneous test sequences.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Burkhardt, H.A.
AU  - Ding, X.
AU  - Kerbrat, A.
AU  - Comtois, K.A.
AU  - Cohen, T.
TI  - From benchmark to bedside: transfer learning from social media to patient-provider text messages for suicide risk prediction
PY  - 2023
T2  - Journal of the American Medical Informatics Association
VL  - 30
IS  - 6
SP  - 1068
EP  - 1078
DO  - 10.1093/jamia/ocad062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165722216&doi=10.1093%2fjamia%2focad062&partnerID=40&md5=03b8f3044aaa9cfd2fea70d5149c4669
AB  - Objective: Compared to natural language processing research investigating suicide risk prediction with social media (SM) data, research utilizing data from clinical settings are scarce. However, the utility of models trained on SM data in text from clinical settings remains unclear. In addition, commonly used performance metrics do not directly translate to operational value in a real-world deployment. The objectives of this study were to evaluate the utility of SM-derived training data for suicide risk prediction in a clinical setting and to develop a metric of the clinical utility of automated triage of patient messages for suicide risk. Materials and Methods: Using clinical data, we developed a Bidirectional Encoder Representations from Transformers-based suicide risk detection model to identify messages indicating potential suicide risk. We used both annotated and unlabeled suicide-related SM posts for multi-stage transfer learning, leveraging customized contemporary learning rate schedules. We also developed a novel metric estimating predictive models' potential to reduce follow-up delays with patients in distress and used it to assess model utility. Results: Multi-stage transfer learning from SM data outperformed baseline approaches by traditional classification performance metrics, improving performance from 0.734 to a best F1 score of 0.797. Using this approach for automated triage could reduce response times by 15 minutes per urgent message. Discussion: Despite differences in data characteristics and distribution, publicly available SM data benefit clinical suicide risk prediction when used in conjunction with contemporary transfer learning techniques. Estimates of time saved due to automated triage indicate the potential for the practical impact of such models when deployed as part of established suicide prevention interventions. Conclusions: This work demonstrates a pathway for leveraging publicly available SM data toward improving risk assessment, paving the way for better clinical care and improved clinical outcomes.  © 2023 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Yang, M.
AU  - Ma, J.
TI  - UNADON: transformer-based model to predict genome-wide chromosome spatial position
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 1 S
SP  - I553
EP  - I562
DO  - 10.1093/bioinformatics/btad246
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164230693&doi=10.1093%2fbioinformatics%2fbtad246&partnerID=40&md5=ed3e668f7751c6bcb77a0c7e03aa526d
AB  - Motivation: The spatial positioning of chromosomes relative to functional nuclear bodies is intertwined with genome functions such as transcription. However, the sequence patterns and epigenomic features that collectively influence chromatin spatial positioning in a genome-wide manner are not well understood. Results: Here, we develop a new transformer-based deep learning model called UNADON, which predicts the genome-wide cytological distance to a specific type of nuclear body, as measured by TSA-seq, using both sequence features and epigenomic signals. Evaluations of UNADON in four cell lines (K562, H1, HFFc6, HCT116) show high accuracy in predicting chromatin spatial positioning to nuclear bodies when trained on a single cell line. UNADON also performed well in an unseen cell type. Importantly, we reveal potential sequence and epigenomic factors that affect large-scale chromatin compartmentalization in nuclear bodies. Together, UNADON provides new insights into the principles between sequence features and large-scale chromatin spatial localization, which has important implications for understanding nuclear structure and function.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Gao, K.
AU  - Li, X.
AU  - Chen, B.
AU  - Hu, L.
AU  - Liu, J.
AU  - Du, R.
AU  - Li, Y.
TI  - Dual Transformer Based Prediction for Lane Change Intentions and Trajectories in Mixed Traffic Environment
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 6
SP  - 6203
EP  - 6216
DO  - 10.1109/TITS.2023.3248842
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149836203&doi=10.1109%2fTITS.2023.3248842&partnerID=40&md5=396e9d843bf4169358237730e2244516
AB  - In a mixed traffic environment of human and autonomous driving, it is crucial for an autonomous vehicle to predict the lane change intentions and trajectories of vehicles that pose a risk to it. However, due to the uncertainty of human intentions, accurately predicting lane change intentions and trajectories is a great challenge. Therefore, this paper aims to establish the connection between intentions and trajectories and propose a dual Transformer model for the target vehicle. The dual Transformer model contains a lane change intention prediction model and a trajectory prediction model. The lane change intention prediction model is able to extract social correlations in terms of vehicle states and outputs an intention probability vector. The trajectory prediction model fuses the intention probability vector, which enables it to obtain prior knowledge. For the intention prediction model, the accuracy can be improved by designing the multi-head attention. For the trajectory prediction model, the performance can be optimized by incorporating intention probability vectors and adding the LSTM. Verified on NGSIM and highD datasets, the experimental results show that this model has encouraging accuracy. Compared with the model without intention probability vectors, the impact of the model on NGSIM dataset and highD dataset in RMSE is improved by 57.27% and 58.70% respectively. Compared with two existed models, evaluation metrics of the intention prediction can be improved by 7.40-10.09% on NGSIM dataset and 2.17-2.69% on highD dataset within advanced prediction time 1s. This method provides the insights for designing advanced perceptual systems for autonomous vehicles.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 56
C2  - CCF:B期刊; FMS:B; 
LB  - Gao2023Dual
ER  -

TY  - JOUR
AU  - Sun, B.
AU  - Li, H.
AU  - He, J.
AU  - Zhang, Y.
TI  - Supervised Contrastive Learned Deep Model for Question Continuation Evaluation
PY  - 2023
T2  - IEEE Transactions on Human-Machine Systems
VL  - 53
IS  - 3
SP  - 560
EP  - 568
DO  - 10.1109/THMS.2023.3271625
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160255605&doi=10.1109%2fTHMS.2023.3271625&partnerID=40&md5=61bdd320eb59036b8e4e693e6e599c8e
AB  - Question continuation evaluation (QCE) is a branch task of dialogue act prediction (DAP) in the natural language processing area, which is aimed at predicting whether each question in a dialogue is worthy of being followed-up under a specific context. QCE is important for communication, education, and even entertainment. Regrettably, QCE has always been disregarded as an auxiliary task for conversational machine reading comprehension. QCE involves more information and relationships than the original DAP task, making it more complex. Moreover, the classification of QCE inherently renders the samples confusing. In this article, a transformer long short-term memory (LSTM)-based supervised contrastive learned model for QCE is proposed to automatically distribute QCE labels. This model is mainly constructed with transformer encoder blocks and LSTM modules, and supervised contrastive learning (SCL) is innovatively introduced to the training process. This model is good at extracting both information about corpora and the relationships among corpora, and SCL alleviates any confusion. With the only applicable dataset, i.e., Question Answering in Context (QuAC), experiments are conducted. This model is proven to perform well and is robust to missing data. The performance is 2.3% (accuracy) and 12.2% (macro-F1 score) higher than baselines from QuAC and only decreases by approximately 2.3% when 10% data remain.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, X.
AU  - Zhang, L.-X.
AU  - Gao, L.
AU  - Dai, W.
AU  - Han, X.
AU  - Lai, Y.-K.
AU  - Chen, Y.
TI  - GLIM-Net: Chronic Glaucoma Forecast Transformer for Irregularly Sampled Sequential Fundus Images
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 6
SP  - 1875
EP  - 1884
DO  - 10.1109/TMI.2023.3243692
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149383383&doi=10.1109%2fTMI.2023.3243692&partnerID=40&md5=3f07359ba94ecad3df822001723ee0c7
AB  - Chronic Glaucoma is an eye disease with progressive optic nerve damage. It is the second leading cause of blindness after cataract and the first leading cause of irreversible blindness. Glaucoma forecast can predict future eye state of a patient by analyzing the historical fundus images, which is helpful for early detection and intervention of potential patients and avoiding the outcome of blindness. In this paper, we propose a GLaucoma forecast transformer based on Irregularly saMpled fundus images named GLIM-Net to predict the probability of developing glaucoma in the future. The main challenge is that the existing fundus images are often sampled at irregular times, making it difficult to accurately capture the subtle progression of glaucoma over time. We therefore introduce two novel modules, namely time positional encoding and time-sensitive MSA (multi-head self-attention) modules, to address this challenge. Unlike many existing works that focus on prediction for an unspecified future time, we also propose an extended model which is further capable of prediction conditioned on a specific future time. The experimental results on the benchmark dataset SIGF show that the accuracy of our method outperforms the state-of-the-art models. In addition, the ablation experiments also confirm the effectiveness of the two modules we propose, which can provide a good reference for the optimization of Transformer models.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Boadu, F.
AU  - Cao, H.
AU  - Cheng, J.
TI  - Combining protein sequences and structures with transformers and equivariant graph neural networks to predict protein function
PY  - 2023
T2  - Bioinformatics
VL  - 39
SP  - I318
EP  - I325
DO  - 10.1093/bioinformatics/btad208
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164234344&doi=10.1093%2fbioinformatics%2fbtad208&partnerID=40&md5=0a701b2fdc64f1f8555d0760ec5fd034
AB  - Motivation: Millions of protein sequences have been generated by numerous genome and transcriptome sequencing projects. However, experimentally determining the function of the proteins is still a time consuming, low-throughput, and expensive process, leading to a large protein sequence-function gap. Therefore, it is important to develop computational methods to accurately predict protein function to fill the gap. Even though many methods have been developed to use protein sequences as input to predict function, much fewer methods leverage protein structures in protein function prediction because there was lack of accurate protein structures for most proteins until recently. Results: We developed TransFun - a method using a transformer-based protein language model and 3D-equivariant graph neural networks to distill information from both protein sequences and structures to predict protein function. It extracts feature embeddings from protein sequences using a pre-trained protein language model (ESM) via transfer learning and combines them with 3D structures of proteins predicted by AlphaFold2 through equivariant graph neural networks. Benchmarked on the CAFA3 test dataset and a new test dataset, TransFun outperforms several state-of-the-art methods, indicating that the language model and 3D-equivariant graph neural networks are effective methods to leverage protein sequences and structures to improve protein function prediction. Combining TransFun predictions and sequence similarity-based predictions can further increase prediction accuracy.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shang, J.
AU  - Peng, C.
AU  - Tang, X.
AU  - Sun, Y.
TI  - PhaVIP: Phage VIrion Protein classification based on chaos game representation and Vision Transformer
PY  - 2023
T2  - Bioinformatics
VL  - 39
SP  - I30
EP  - I39
DO  - 10.1093/bioinformatics/btad229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164234640&doi=10.1093%2fbioinformatics%2fbtad229&partnerID=40&md5=dce1e5d67b104f07040254d2ab467cbe
AB  - Motivation: As viruses that mainly infect bacteria, phages are key players across a wide range of ecosystems. Analyzing phage proteins is indispensable for understanding phages' functions and roles in microbiomes. High-throughput sequencing enables us to obtain phages in different microbiomes with low cost. However, compared to the fast accumulation of newly identified phages, phage protein classification remains difficult. In particular, a fundamental need is to annotate virion proteins, the structural proteins, such as major tail, baseplate, etc. Although there are experimental methods for virion protein identification, they are too expensive or time-consuming, leaving a large number of proteins unclassified. Thus, there is a great demand to develop a computational method for fast and accurate phage virion protein (PVP) classification. Results: In this work, we adapted the state-of-the-art image classification model, Vision Transformer, to conduct virion protein classification. By encoding protein sequences into unique images using chaos game representation, we can leverage Vision Transformer to learn both local and global features from sequence "images". Our method, PhaVIP, has two main functions: classifying PVP and non-PVP sequences and annotating the types of PVP, such as capsid and tail. We tested PhaVIP on several datasets with increasing difficulty and benchmarked it against alternative tools. The experimental results show that PhaVIP has superior performance. After validating the performance of PhaVIP, we investigated two applications that can use the output of PhaVIP: phage taxonomy classification and phage host prediction. The results showed the benefit of using classified proteins over all proteins.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Huang, Z.
AU  - Zhang, P.
AU  - Deng, L.
TI  - DeepCoVDR: deep transfer learning with graph transformer and cross-attention for predicting COVID-19 drug response
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 1 S
SP  - I475
EP  - I483
DO  - 10.1093/bioinformatics/btad244
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164233830&doi=10.1093%2fbioinformatics%2fbtad244&partnerID=40&md5=b281213815f2c47829749f9e234badf0
AB  - Motivation: The coronavirus disease 2019 (COVID-19) remains a global public health emergency. Although people, especially those with underlying health conditions, could benefit from several approved COVID-19 therapeutics, the development of effective antiviral COVID-19 drugs is still a very urgent problem. Accurate and robust drug response prediction to a new chemical compound is critical for discovering safe and effective COVID-19 therapeutics. Results: In this study, we propose DeepCoVDR, a novel COVID-19 drug response prediction method based on deep transfer learning with graph transformer and cross-attention. First, we adopt a graph transformer and feed-forward neural network to mine the drug and cell line information. Then, we use a cross-attention module that calculates the interaction between the drug and cell line. After that, DeepCoVDR combines drug and cell line representation and their interaction features to predict drug response. To solve the problem of SARS-CoV-2 data scarcity, we apply transfer learning and use the SARS-CoV-2 dataset to fine-tune the model pretrained on the cancer dataset. The experiments of regression and classification show that DeepCoVDR outperforms baseline methods. We also evaluate DeepCoVDR on the cancer dataset, and the results indicate that our approach has high performance compared with other state-of-the-art methods. Moreover, we use DeepCoVDR to predict COVID-19 drugs from FDA-approved drugs and demonstrate the effectiveness of DeepCoVDR in identifying novel COVID-19 drugs.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Moulouel, K.
AU  - Chibani, A.
AU  - Amirat, Y.
TI  - Ontology-based hybrid commonsense reasoning framework for handling context abnormalities in uncertain and partially observable environments
PY  - 2023
T2  - Information Sciences
VL  - 631
SP  - 468
EP  - 486
DO  - 10.1016/j.ins.2023.02.078
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150367886&doi=10.1016%2fj.ins.2023.02.078&partnerID=40&md5=b983e69d4c2b5db89e9f77a12288602e
AB  - Ambient intelligence (AmI) systems aim to provide users with context-aware assistance services intended to improve the quality of their lives in terms of autonomy, safety, and well-being. Taking the uncertainty and partial observability of these environments into account is of major importance for context recognition and, more specifically, to detect and solve context abnormalities such as those related to the user's behavior or those related to context attribute prediction. In this paper, an ontology-based framework integrating machine learning and probabilistic planning within commonsense reasoning is proposed to recognize the user's context and abnormalities associated with it. The reasoning is performed using event calculus in answer set programming (ECASP); ECASP allows for abductive and temporal reasoning, which results in an eXplainable AI (XAI) approach. A context ontology is proposed to axiomatize the reasoning and introduce the notion of probabilistic fluents into the EC formalism in order to perform probabilistic reasoning. The reasoning incorporates probabilistic planning based on a partially observable Markov decision process (POMDP) to solve knowledge incompleteness. To evaluate the proposed framework, real-life scenarios, based on the Orange4Home and SIMADL public datasets are implemented and discussed. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Moulouel2023Ontology-based
ER  -

TY  - JOUR
AU  - Gao, Z.
AU  - Cui, X.
AU  - Zhuo, T.
AU  - Cheng, Z.
AU  - Liu, A.-A.
AU  - Wang, M.
AU  - Chen, S.
TI  - A Multitemporal Scale and Spatial-Temporal Transformer Network for Temporal Action Localization
PY  - 2023
T2  - IEEE Transactions on Human-Machine Systems
VL  - 53
IS  - 3
SP  - 569
EP  - 580
DO  - 10.1109/THMS.2023.3266037
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159802303&doi=10.1109%2fTHMS.2023.3266037&partnerID=40&md5=dd6b56b99fd7afbd2efb5013ce8fa0a5
AB  - Temporal action localization plays an important role in video analysis, which aims to localize and classify actions in untrimmed videos. Previous methods often predict actions on a feature space of a single temporal scale. However, the temporal features of a low-level scale lack sufficient semantics for action classification, while a high-level scale cannot provide the rich details of the action boundaries. In addition, the long-range dependencies of video frames are often ignored. To address these issues, a novel multitemporal-scale spatial-temporal transformer (MSST) network is proposed for temporal action localization, which predicts actions on a feature space of multiple temporal scales. Specifically, we first use refined feature pyramids of different scales to pass semantics from high-level scales to low-level scales. Second, to establish the long temporal scale of the entire video, we use a spatial-temporal transformer encoder to capture the long-range dependencies of video frames. Then, the refined features with long-range dependencies are fed into a classifier for coarse action prediction. Finally, to further improve the prediction accuracy, we propose a frame-level self-attention module to refine the classification and boundaries of each action instance. Most importantly, these three modules are jointly explored in a unified framework, and MSST has an anchor-free and end-to-end architecture. Extensive experiments show that the proposed method can outperform state-of-the-art approaches on the THUMOS14 dataset and achieve comparable performance on the ActivityNet1.3 dataset. Compared with A2Net (TIP20, Avg{0.3:0.7}), Sub-Action (CSVT2022, Avg{0.1:0.5}), and AFSD (CVPR21, Avg{0.3:0.7}) on the THUMOS14 dataset, the proposed method can achieve improvements of 12.6%, 17.4%, and 2.2%, respectively.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, T.
AU  - Guo, Z.
AU  - Cheng, J.
TI  - Atomic protein structure refinement using all-atom graph representations and SE(3)-equivariant graph transformer
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 5
C7  - btad298
DO  - 10.1093/bioinformatics/btad298
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160700879&doi=10.1093%2fbioinformatics%2fbtad298&partnerID=40&md5=47ffb6fb2e3a650cb9e702494bb803d9
AB  - Motivation: The state-of-art protein structure prediction methods such as AlphaFold are being widely used to predict structures of uncharacterized proteins in biomedical research. There is a significant need to further improve the quality and nativeness of the predicted structures to enhance their usability. In this work, we develop ATOMRefine, a deep learning-based, end-to-end, all-atom protein structural model refinement method. It uses a SE(3)-equivariant graph transformer network to directly refine protein atomic coordinates in a predicted tertiary structure represented as a molecular graph. Results: The method is first trained and tested on the structural models in AlphaFoldDB whose experimental structures are known, and then blindly tested on 69 CASP14 regular targets and 7 CASP14 refinement targets. ATOMRefine improves the quality of both backbone atoms and all-atom conformation of the initial structural models generated by AlphaFold. It also performs better than two state-of-the-art refinement methods in multiple evaluation metrics including an all-atom model quality score—the MolProbity score based on the analysis of all-atom contacts, bond length, atom clashes, torsion angles, and side-chain rotamers. As ATOMRefine can refine a protein structure quickly, it provides a viable, fast solution for improving protein geometry and fixing structural errors of predicted structures through direct coordinate refinement. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Tian, C.
AU  - Shao, F.
AU  - Chai, X.
AU  - Jiang, Q.
AU  - Xu, L.
AU  - Ho, Y.-S.
TI  - Viewport-Sphere-Branch Network for Blind Quality Assessment of Stitched 360° Omnidirectional Images
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 6
SP  - 2546
EP  - 2560
DO  - 10.1109/TCSVT.2022.3225172
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144010848&doi=10.1109%2fTCSVT.2022.3225172&partnerID=40&md5=b62611218ecc4cca54631501b847ab8f
AB  - Compared with conventional images/videos, omnidirectional data records rich information with higher resolution and wider Field-of-View. Moreover, the stitching distortions introduced in the panoramic content generation process make the quality assessment task more challenging. Targeting at designing an accurate and fast stitched 360° omnidirectional image quality evaluator, we propose a Viewport- Sphere-Branch Network (VSBNet) via dual-branch quality estimation. Specifically, for the viewport quality estimation, we extract distorted viewports around the stitching seams and conduct distortion rectification through a progressively complementary network to obtain pseudo-reference viewports. The qualitative and quantitative experiments validate that pseudo-reference viewports are reliable. Then, the differences between distorted and pseudo-reference viewports are quantified through transformer architecture to obtain quality scores of viewports. The introduction of pseudo-reference viewports can effectively improve the performance of the viewport quality prediction branch. To establish general scenario awareness and accurately evaluate the immersive experience, we extract feature representation through deformable convolutions to eliminate 2D-to-Sphere intrinsic sampling distortions and use multilayer perceptron to predict score of the whole sphere. The final prediction score is obtained by aggregating the quality scores from viewport and sphere branches. We evaluate the proposed VSBNet on two benchmark databases and results demonstrate that the combination of two branches can obtain more accurate results. Overall, our method is superior to existing full reference and no reference models designed for conventional images and 360° omnidirectional images.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ge, Y.
AU  - Zhang, Q.
AU  - Xiang, T.-Z.
AU  - Zhang, C.
AU  - Bi, H.
TI  - TCNet: Co-Salient Object Detection via Parallel Interaction of Transformers and CNNs
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 6
SP  - 2600
EP  - 2615
DO  - 10.1109/TCSVT.2022.3225865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144081406&doi=10.1109%2fTCSVT.2022.3225865&partnerID=40&md5=d7246ab5194e79c3b999c0044bfcdfe9
AB  - The purpose of co-salient object detection (CoSOD) is to detect the salient objects that co-occur in a group of relevant images. CoSOD has been significantly prospered by recent advances in convolutional neural networks (CNNs). However, it shows general limitations in modeling long-range feature dependencies, which is crucial for CoSOD. In the vision transformer, the self-attention mechanism is utilized to capture global dependencies but unfortunately destroy local spatial details, which are also essential for CoSOD. To address the above issues, we propose a dual network structure, called TCNet, which can efficiently excavate both local information and global representations for co-saliency learning via the parallel interaction of Transformers and CNNs. Specifically, it contains three critical components, i.e., the mutual consensus module (MCM), the consensus complementary module (CCM), and the group consistent progressive decoder (GCPD). MCM aims to capture the global consensus from high-level features of these two branches as a guide for the following integration of consensus cues of both branches at each level. Next, CCM is designed to effectively fuse the consensus of local information and global contexts from different levels of the two branches. Finally, GCPD is developed to maintain group feature consistency and predict accurate co-saliency maps. The proposed TCNet is evaluated on five challenging CoSOD benchmark datasets using six widely used metrics, showing that our proposed method is superior to other existing cutting-edge methods for co-salient object detection.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chang, K.-L.
AU  - Chen, J.-H.
AU  - Lin, T.-C.
AU  - Leu, J.-Y.
AU  - Kao, C.-F.
AU  - Wong, J.Y.
AU  - Tsai, H.-K.
TI  - Short human eccDNAs are predictable from sequences
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
C7  - bbad147
DO  - 10.1093/bib/bbad147
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159759649&doi=10.1093%2fbib%2fbbad147&partnerID=40&md5=8640481b4ecfd3cd8805c2cbad0b74b6
AB  - Background: Ubiquitous presence of short extrachromosomal circular DNAs (eccDNAs) in eukaryotic cells has perplexed generations of biologists. Their widespread origins in the genome lacking apparent specificity led some studies to conclude their formation as random or near-random. Despite this, the search for specific formation of short eccDNA continues with a recent surge of interest in biomarker development. Results: To shed new light on the conf licting views on short eccDNAs' randomness, here we present DeepCircle, a bioinformatics framework incorporating convolution- and attention-based neural networks to assess their predictability. Short human eccDNAs from different datasets indeed have low similarity in genomic locations, but DeepCircle successfully learned shared DNA sequence features to make accurate cross-datasets predictions (accuracy: convolution-based models: 79.65 ± 4.7%, attention-based models: 83.31 ± 4.18%). Conclusions: The excellent performance of our models shows that the intrinsic predictability of eccDNAs is encoded in the sequences across tissue origins. Our work demonstrates how the perceived lack of specificity in genomics data can be re-assessed by deep learning models to uncover unexpected similarity. © The Author(s) 2023. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, Z.
AU  - Xu, D.
AU  - Hu, P.J.-H.
AU  - Huang, T.-S.
TI  - A hierarchical multilabel graph attention network method to predict the deterioration paths of chronic hepatitis B patients
PY  - 2023
T2  - Journal of the American Medical Informatics Association
VL  - 30
IS  - 5
SP  - 846
EP  - 858
DO  - 10.1093/jamia/ocad008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152976916&doi=10.1093%2fjamia%2focad008&partnerID=40&md5=60d307a66c7469a789b091c687cf4c69
AB  - Objective: Estimating the deterioration paths of chronic hepatitis B (CHB) patients is critical for physicians' decisions and patient management. A novel, hierarchical multilabel graph attention-based method aims to predict patient deterioration paths more effectively. Applied to a CHB patient data set, it offers strong predictive utilities and clinical value. Materials and Methods: The proposed method incorporates patients' responses to medications, diagnosis event sequences, and outcome dependencies to estimate deterioration paths. From the electronic health records maintained by a major healthcare organization in Taiwan, we collect clinical data about 177 959 patients diagnosed with hepatitis B virus infection. We use this sample to evaluate the proposed method's predictive efficacy relative to 9 existing methods, as measured by precision, recall, F-measure, and area under the curve (AUC). Results: We use 20% of the sample as holdouts to test each method's prediction performance. The results indicate that our method consistently and significantly outperforms all benchmark methods. It attains the highest AUC, with a 4.8% improvement over the best-performing benchmark, as well as 20.9% and 11.4% improvements in precision and F-measures, respectively. The comparative results demonstrate that our method is more effective for predicting CHB patients' deterioration paths than existing predictive methods. Discussion and Conclusion: The proposed method underscores the value of patient-medication interactions, temporal sequential patterns of distinct diagnosis, and patient outcome dependencies for capturing dynamics that underpin patient deterioration over time. Its efficacious estimates grant physicians a more holistic view of patient progressions and can enhance their clinical decision-making and patient management. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Li, K.
AU  - Li, J.
AU  - Guo, D.
AU  - Yang, X.
AU  - Wang, M.
TI  - Transformer-Based Visual Grounding with Cross-Modality Interaction
PY  - 2023
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 19
IS  - 6
C7  - 183
DO  - 10.1145/3587251
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167562650&doi=10.1145%2f3587251&partnerID=40&md5=fdc847961c264ba9bcc43c96a424e664
AB  - This article tackles the challenging yet important task of Visual Grounding (VG), which aims to localize a visual region in the given image referred by a natural language query. Existing efforts on the VG task are twofold: (1) two-stage methods first extract region proposals and then rank them according to their similarities with the referring expression, which usually leads to suboptimal results due to the quality of region proposals; (2) one-stage methods usually predict all the possible coordinates of the target region online by leveraging modern object detection architectures, which pay little attention to cross-modality correlations and have limited generalization ability. To better address the task, we present an effective transformer-based end-to-end visual grounding approach, which focuses on capturing the cross-modality correlations between the referring expression and visual regions for accurately reasoning the location of the target region. Specifically, our model consists of a feature encoder, a cross-modality interactor, and a modality-agnostic decoder. The feature encoder is employed to capture the intra-modality correlation, which models the linguistic context in query and the spatial dependency in image respectively. The cross-modality interactor endows the model with the capability of highlighting the localization-relevant visual and textual cues by mutual verification of vision and language, which plays a key role in our model. The decoder learns a consolidated token representation enriched by multi-modal contexts and further directly predicts the box coordinates. Extensive experiments on five public benchmark datasets with quantitative and qualitative analysis clearly demonstrate the effectiveness and rationale of our proposed method. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Guo, Z.
AU  - Wang, K.
AU  - Gao, X.
AU  - Wang, G.
TI  - End-to-end interpretable disease-gene association prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
C7  - bbad118
DO  - 10.1093/bib/bbad118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159758021&doi=10.1093%2fbib%2fbbad118&partnerID=40&md5=0f6c27d5f76c90fbbfc98647b25a3220
AB  - Identifying disease-gene associations is a fundamental and critical biomedical task towards understanding molecular mechanisms, the diagnosis and treatment of diseases. It is time-consuming and expensive to experimentally verify causal links between diseases and genes. Recently, deep learning methods have achieved tremendous success in identifying candidate genes for genetic diseases. The gene prediction problem can be modeled as a link prediction problem based on the features of nodes and edges of the gene-disease graph. However, most existing researches either build homogeneous networks based on one single data source or heterogeneous networks based on multi-source data, and artificially define meta-paths, so as to learn the network representation of diseases and genes. The former cannot make use of abundant multi-source heterogeneous information, while the latter needs domain knowledge and experience when defining meta-paths, and the accuracy of the model largely depends on the definition of meta-paths. To address the aforementioned challenges above bottlenecks, we propose an end-to-end disease-gene association prediction model with parallel graph transformer network (DGP-PGTN), which deeply integrates the heterogeneous information of diseases, genes, ontologies and phenotypes. DGP-PGTN can automatically and comprehensively capture the multiple latent interactions between diseases and genes, discover the causal relationship between them and is fully interpretable at the same time. We conduct comprehensive experiments and show that DGP-PGTN outperforms the state-of-the-art methods significantly on the task of disease-gene association prediction. Furthermore, DGP-PGTN can automatically learn the implicit relationship between diseases and genes without manually defining meta paths. © Crown copyright 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Song, Y.
AU  - Wang, Y.
AU  - Wang, X.
AU  - Huang, D.
AU  - Nguyen, A.
AU  - Meng, J.
TI  - Multi-task adaptive pooling enabled synergetic learning of RNA modification across tissue, type and species from low-resolution epitranscriptomes
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
C7  - bbad105
DO  - 10.1093/bib/bbad105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159766157&doi=10.1093%2fbib%2fbbad105&partnerID=40&md5=a2d7045f141fe9c268d7b33f82799675
AB  - Post- and co-transcriptional RNA modifications are found to play various roles in regulating essential biological processes at all stages of RNA life. Precise identification of RNA modification sites is thus crucial for understanding the related molecular functions and specific regulatory circuitry. To date, a number of computational approaches have been developed for in silico identification of RNA modification sites; however, most of them require learning from base-resolution epitranscriptome datasets, which are generally scarce and available only for a limited number of experimental conditions, and predict only a single modification, even though there are multiple inter-related RNA modification types available. In this study, we proposed AdaptRM, a multi-task computational method for synergetic learning of multi-tissue, type and species RNA modifications from both high- and low-resolution epitranscriptome datasets. By taking advantage of adaptive pooling and multi-task learning, the newly proposed AdaptRM approach outperformed the state-of-the-art computational models (WeakRM and TS-m6A-DL) and two other deep-learning architectures based on Transformer and ConvMixer in three different case studies for both high-resolution and low-resolution prediction tasks, demonstrating its effectiveness and generalization ability. In addition, by interpreting the learned models, we unveiled for the first time the potential association between different tissues in terms of epitranscriptome sequence patterns. AdaptRM is available as a user-friendly web server from http://www.rnamd.org/AdaptRM together with all the codes and data used in this project. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lei, Y.
AU  - Li, Y.
TI  - A novel scheme of domain transfer in document-level cross-domain sentiment classification
PY  - 2023
T2  - Journal of Information Science
VL  - 49
IS  - 3
SP  - 567
EP  - 581
DO  - 10.1177/01655515211012329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105788933&doi=10.1177%2f01655515211012329&partnerID=40&md5=25f77d32ba735227de9b2c10dc2c6277
AB  - The sentiment classification aims to learn sentiment features from the annotated corpus and automatically predict the sentiment polarity of new sentiment text. However, people have different ways of expressing feelings in different domains. Thus, there are important differences in the characteristics of sentimental distribution across different domains. At the same time, in certain specific domains, due to the high cost of corpus collection, there is no annotated corpus available for the classification of sentiment. Therefore, it is necessary to leverage or reuse existing annotated corpus for training. In this article, we proposed a new algorithm for extracting central sentiment sentences in product reviews, and improved the pre-trained language model Bidirectional Encoder Representations from Transformers (BERT) to achieve the domain transfer for cross-domain sentiment classification. We used various pre-training language models to prove the effectiveness of the newly proposed joint algorithm for text-ranking and emotional words extraction, and utilised Amazon product reviews data set to demonstrate the effectiveness of our proposed domain-transfer framework. The experimental results of 12 different cross-domain pairs showed that the new cross-domain classification method was significantly better than several popular cross-domain sentiment classification methods. © The Author(s) 2021.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Lei2023novel
ER  -

TY  - JOUR
AU  - Chen, W.
AU  - Yang, Z.
AU  - Xue, L.
AU  - Duan, J.
AU  - Sun, H.
AU  - Zheng, N.
TI  - Multimodal Pedestrian Trajectory Prediction Using Probabilistic Proposal Network
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 6
SP  - 2877
EP  - 2891
DO  - 10.1109/TCSVT.2022.3229694
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146248940&doi=10.1109%2fTCSVT.2022.3229694&partnerID=40&md5=1ef52a4286f7f1136ea67c41aa677919
AB  - Forecasting multiple pedestrian trajectories is a challenging task for real-world applications, as the motion patterns of pedestrian are essentially stochastic and uncertain. Previous works have demonstrated that predicting diverse goals in advance can effectively improve the performance of pedestrian trajectory prediction. However, these methods are either unable to perform probabilistic and high-efficiency trajectory prediction, or mainly rely on the predefined template trajectories which are not high-performance and insufficient to represent the possible pedestrian behaviors. In this paper, we propose a new Probabilistic Proposal Network (PPNet) to concentrate on the generation of goals and the utilization of goal guidance. PPNet firstly generates multiple weighted goals based on the diverse latent intentions automatically obtained by unsupervised learning, and then designs the goal-conditioned Transformer networks to predict probabilistic proposals as the final trajectories. Extensive experimental results on ETH/UCY datasets and Stanford Drone Dataset indicate that PPNet achieves both state-of-the-art performance and high efficiency on pedestrian trajectory prediction. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Vazquez Romaguera, L.
AU  - Alley, S.
AU  - Carrier, J.-F.
AU  - Kadoury, S.
TI  - Conditional-Based Transformer Network With Learnable Queries for 4D Deformation Forecasting and Tracking
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 6
SP  - 1603
EP  - 1618
DO  - 10.1109/TMI.2023.3234046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147232039&doi=10.1109%2fTMI.2023.3234046&partnerID=40&md5=25ed7099099939582dc8a3b47f52afa7
AB  - Real-time motion management for image-guided radiation therapy interventions plays an important role for accurate dose delivery. Forecasting future 4D deformations from in-plane image acquisitions is fundamental for accurate dose delivery and tumor targeting. However, anticipating visual representations is challenging and is not exempt from hurdles such as the prediction from limited dynamics, and the high-dimensionality inherent to complex deformations. Also, existing 3D tracking approaches typically need both template and search volumes as inputs, which are not available during real-time treatments. In this work, we propose an attention-based temporal prediction network where features extracted from input images are treated as tokens for the predictive task. Moreover, we employ a set of learnable queries, conditioned on prior knowledge, to predict future latent representation of deformations. Specifically, the conditioning scheme is based on estimated time-wise prior distributions computed from future images available during the training stage. Finally, we propose a new framework to address the problem of temporal 3D local tracking using cine 2D images as inputs, by employing latent vectors as gating variables to refine the motion fields over the tracked region. The tracker module is anchored on a 4D motion model, which provides both the latent vectors and the volumetric motion estimates to be refined. Our approach avoids auto-regression and leverages spatial transformations to generate the forecasted images. The tracking module reduces the error by 63% compared to a conditional-based transformer 4D motion model, yielding a mean error of 1.5± 1.1 mm. Furthermore, for the studied cohort of abdominal 4D MRI images, the proposed method is able to predict future deformations with a mean geometrical error of 1.2± 0.7 mm.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Dong, W.
AU  - Yang, Q.
AU  - Wang, J.
AU  - Xu, L.
AU  - Li, X.
AU  - Luo, G.
AU  - Gao, X.
TI  - Multi-modality attribute learning-based method for drug-protein interaction prediction based on deep neural network
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
C7  - bbad161
DO  - 10.1093/bib/bbad161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159761316&doi=10.1093%2fbib%2fbbad161&partnerID=40&md5=01e9f2916a76c22b4b8ffd4397b64db8
AB  - Identification of active candidate compounds for target proteins, also called drug-protein interaction (DPI) prediction, is an essential but time-consuming and expensive step, which leads to fostering the development of drug discovery. In recent years, deep network-based learning methods were frequently proposed in DPIs due to their powerful capability of feature representation. However, the performance of existing DPI methods is still limited by insufficiently labeled pharmacological data and neglected intermolecular information. Therefore, overcoming these difficulties to perfect the performance of DPIs is an urgent challenge for researchers. In this article, we designed an innovative'multi-modality attributes' learning-based framework for DPIs with molecular transformer and graph convolutional networks, termed, multi-modality attributes (MMA)-DPI. Specifically, intermolecular sub-structural information and chemical semantic representations were extracted through an augmented transformer module from biomedical data. A tri-layer graph convolutional neural network module was applied to associate the neighbor topology information and learn the condensed dimensional features by aggregating a heterogeneous network that contains multiple biological representations of drugs, proteins, diseases and side effects. Then, the learned representations were taken as the input of a fully connected neural network module to further integrate them in molecular and topological space. Finally, the attribute representations were fused with adaptive learning weights to calculate the interaction score for the DPIs tasks. MMA-DPI was evaluated in different experimental conditions and the results demonstrate that the proposed method achieved higher performance than existing state-of-the-art frameworks. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guan, Z.
AU  - Jiang, Z.
TI  - Transformer-based anti-noise models for CRISPR-Cas9 off-target activities prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
C7  - bbad127
DO  - 10.1093/bib/bbad127
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159759328&doi=10.1093%2fbib%2fbbad127&partnerID=40&md5=0c9430a69dbb92dfb63a5e8d4b12bf58
AB  - The off-target effect occurring in the CRISPR-Cas9 system has been a challenging problem for the practical application of this gene editing technology. In recent years, various prediction models have been proposed to predict potential off-target activities. However, most of the existing prediction methods do not fully exploit guide RNA (gRNA) and DNA sequence pair information effectively. In addition, available prediction methods usually ignore the noise effect in original off-target datasets. To address these issues, we design a novel coding scheme, which considers the key features of mismatch type, mismatch location and the gRNA-DNA sequence pair information. Furthermore, a transformer-based anti-noise model called CrisprDNT is developed to solve the noise problem that exists in the off-target data. Experimental results of eight existing datasets demonstrate that the method with the inclusion of the anti-noise loss functions is superior to available state-of-the-art prediction methods. CrisprDNT is available at https://github.com/gzrgzx/CrisprDNT. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Wei, Y.
AU  - Xu, S.
AU  - Tan, Q.
AU  - Zong, L.
AU  - Wang, J.
AU  - Wang, Y.
AU  - Chen, J.
AU  - Hong, L.
AU  - Li, Y.
TI  - AcrNET: predicting anti-CRISPR with deep learning
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 5
C7  - btad259
DO  - 10.1093/bioinformatics/btad259
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159739339&doi=10.1093%2fbioinformatics%2fbtad259&partnerID=40&md5=91ed909ea5aa2fc70800564f02db874c
AB  - Motivation: As an important group of proteins discovered in phages, anti-CRISPR inhibits the activity of the immune system of bacteria (i.e. CRISPR-Cas), offering promise for gene editing and phage therapy. However, the prediction and discovery of anti-CRISPR are challenging due to their high variability and fast evolution. Existing biological studies rely on known CRISPR and anti-CRISPR pairs, which may not be practical considering the huge number. Computational methods struggle with prediction performance. To address these issues, we propose a novel deep neural network for anti-CRISPR analysis (AcrNET), which achieves significant performance. Results: On both the cross-fold and cross-dataset validation, our method outperforms the state-of-the-art methods. Notably, AcrNET improves the prediction performance by at least 15% regarding the F1 score for the cross-dataset test problem comparing with state-of-art Deep Learning method. Moreover, AcrNET is the first computational method to predict the detailed anti-CRISPR classes, which may help illustrate the anti-CRISPR mechanism. Taking advantage of a Transformer protein language model ESM-1b, which was pre-trained on 250 million protein sequences, AcrNET overcomes the data scarcity problem. Extensive experiments and analysis suggest that the Transformer model feature, evolutionary feature, and local structure feature complement each other, which indicates the critical properties of anti-CRISPR proteins. AlphaFold prediction, further motif analysis, and docking experiments further demonstrate that AcrNET can capture the evolutionarily conserved pattern and the interaction between anti-CRISPR and the target implicitly. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Wang, W.
AU  - Feng, C.
AU  - Zhang, H.
AU  - Chen, Z.
AU  - Zhan, Y.
TI  - Expression snippet transformer for robust video-based facial expression recognition
PY  - 2023
T2  - Pattern Recognition
VL  - 138
C7  - 109368
DO  - 10.1016/j.patcog.2023.109368
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147547261&doi=10.1016%2fj.patcog.2023.109368&partnerID=40&md5=7d4124c03b89916fa48829fed132ac17
AB  - Although Transformer can be powerful for modeling visual relations and describing complicated patterns, it could still perform unsatisfactorily for video-based facial expression recognition, since the expression movements in a video can be too small to reflect meaningful spatial-temporal relations. To this end, we propose to decompose the modeling of expression movements of a video into the modeling of a series of expression snippets, each of which contains a few frames, and then boost the Transformer's ability for intra-snippet and inter-snippet visual modeling, respectively, obtaining the Expression snippet Transformer (EST). For intra-snippet modeling, we devise an attention-augmented snippet feature extractor to enhance the encoding of subtle facial movements of each snippet. For inter-snippet modeling, we introduce a shuffled snippet order prediction head and a corresponding loss to improve the modeling of subtle motion changes across subsequent snippets. The EST obtains state-of-the-art performance, demonstrating its superiority to other CNN-based methods. Our code and the trained model are available at https://github.com/DreamMr/EST © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 49
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Franco, L.
AU  - Placidi, L.
AU  - Giuliari, F.
AU  - Hasan, I.
AU  - Cristani, M.
AU  - Galasso, F.
TI  - Under the hood of transformer networks for trajectory forecasting
PY  - 2023
T2  - Pattern Recognition
VL  - 138
C7  - 109372
DO  - 10.1016/j.patcog.2023.109372
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148333409&doi=10.1016%2fj.patcog.2023.109372&partnerID=40&md5=695bd588f1fd6dc604ebfe552be09705
AB  - Transformer Networks have established themselves as the de-facto state-of-the-art for trajectory forecasting but there is currently no systematic study on their capability to model the motion patterns of people, without interactions with other individuals nor the social context. There is abundant literature on LSTMs, CNNs and GANs on this subject. However methods adopting Transformer techniques achieve great performances by complex models and a clear analysis of their adoption as plain sequence models is missing. This paper proposes the first in-depth study of Transformer Networks (TF) and the Bidirectional Transformers (BERT) for the forecasting of the individual motion of people, without bells and whistles. We conduct an exhaustive evaluation of the input/output representations, problem formulations and sequence modelling, including a novel analysis of their capability to predict multi-modal futures. Out of comparative evaluation on the ETH+UCY benchmark, both TF and BERT are top performers in predicting individual motions and remain within a narrow margin wrt more complex techniques, including both social interactions and scene contexts. Source code will be released for all conducted experiments. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Guan, J.
AU  - Zhou, S.
TI  - Molecular property prediction by contrastive learning with attention-guided positive sample selection
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 5
C7  - btad258
DO  - 10.1093/bioinformatics/btad258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159741068&doi=10.1093%2fbioinformatics%2fbtad258&partnerID=40&md5=99d40ada4d5306c3a36034a445d688c2
AB  - Motivation: Predicting molecular properties is one of the fundamental problems in drug design and discovery. In recent years, self-supervised learning (SSL) has shown its promising performance in image recognition, natural language processing, and single-cell data analysis. Contrastive learning (CL) is a typical SSL method used to learn the features of data so that the trained model can more effectively distinguish the data. One important issue of CL is how to select positive samples for each training example, which will significantly impact the performance of CL. Results: In this article, we propose a new method for molecular property prediction (MPP) by Contrastive Learning with Attention-guided Positive-sample Selection (CLAPS). First, we generate positive samples for each training example based on an attention-guided selection scheme. Second, we employ a Transformer encoder to extract latent feature vectors and compute the contrastive loss aiming to distinguish positive and negative sample pairs. Finally, we use the trained encoder for predicting molecular properties. Experiments on various benchmark datasets show that our approach outperforms the state-of-the-art (SOTA) methods in most cases. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lu, Q.
AU  - Zhang, R.
AU  - Zhou, H.
AU  - Ni, D.
AU  - Xiao, W.
AU  - Li, J.
TI  - MetaHMEI: meta-learning for prediction of few-shot histone modifying enzyme inhibitors
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
C7  - bbad115
DO  - 10.1093/bib/bbad115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159760123&doi=10.1093%2fbib%2fbbad115&partnerID=40&md5=6abc78b43b611b6fd4e614ee488b2b9d
AB  - Motivation: Histones are the chief protein components of chromatin, and the chemical modifications on histones crucially inf luence the transcriptional state of related genes. Histone modifying enzyme (HME), responsible for adding or removing the chemical labels, has emerged as a very important class of drug target, with a few HME inhibitors launched as anti-cancerous drugs and tens of molecules under clinical trials. To accelerate the drug discovery process of HME inhibitors, machine learning-based predictive models have been developed to enrich the active molecules from vast chemical space. However, the number of compounds with known activity distributed largely unbalanced among different HMEs, particularly with many targets of less than a hundred active samples. In this case, it is difficult to build effective virtual screening models directly based on machine learning. Results: To this end, we propose a new Meta-learning-based Histone Modifying Enzymes Inhibitor prediction method (MetaHMEI). Our proposed MetaHMEI first uses a self-supervised pretraining approach to obtain high-quality molecular substructure embeddings from a large unlabeled chemical dataset. Then, MetaHMEI exploits a Transformer-based encoder and meta-learning framework to build a prediction model. MetaHMEI allows the effective transfer of the prior knowledge learned from HMEs with sufficient samples to HMEs with a small number of samples, so the proposed model can produce accurate predictions for HMEs with limited data. Extensive experimental results on our collected and curated HMEs datasets show that MetaHMEI is better than other methods in the case of few-shot learning. Furthermore, we applied MetaHMEI in the virtual screening process of histone JMJD3 inhibitors and successfully obtained three small molecule inhibitors, further supporting the validity of our model. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ye, Z.
AU  - Li, S.
AU  - Mi, X.
AU  - Shao, B.
AU  - Dai, Z.
AU  - Ding, B.
AU  - Feng, S.
AU  - Sun, B.
AU  - Shen, Y.
AU  - Xiao, Z.
TI  - STMHCpan, an accurate Star-Transformer-based extensible framework for predicting MHC i allele binding peptides
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 3
DO  - 10.1093/bib/bbad164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159756042&doi=10.1093%2fbib%2fbbad164&partnerID=40&md5=2ea7d013e478b04181b803fe71f86395
AB  - Peptide-major histocompatibility complex I (MHC I) binding affinity prediction is crucial for vaccine development, but existing methods face limitations such as small datasets, model overfitting due to excessive parameters and suboptimal performance. Here, we present STMHCPan (STAR-MHCPan), an open-source package based on the Star-Transformer model, for MHC I binding peptide prediction. Our approach introduces an attention mechanism to improve the deep learning network architecture and performance in antigen prediction. Compared with classical deep learning algorithms, STMHCPan exhibits improved performance with fewer parameters in receptor affinity training. Furthermore, STMHCPan outperforms existing ligand benchmark datasets identified by mass spectrometry. It can also handle peptides of arbitrary length and is highly scalable for predicting T-cell responses. Our software is freely available for use, training and extension through Github (ttps://github.com/Luckysoutheast/STMHCPan.git). © 2023 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ji, Y.
AU  - Shang, J.
AU  - Tang, X.
AU  - Sun, Y.
TI  - HOTSPOT: hierarchical host prediction for assembled plasmid contigs with transformer
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 5
C7  - btad283
DO  - 10.1093/bioinformatics/btad283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159552726&doi=10.1093%2fbioinformatics%2fbtad283&partnerID=40&md5=b09beba7676df603876bf9f6c333a991
AB  - Motivation: As prevalent extrachromosomal replicons in many bacteria, plasmids play an essential role in their hosts’ evolution and adaptation. The host range of a plasmid refers to the taxonomic range of bacteria in which it can replicate and thrive. Understanding host ranges of plasmids sheds light on studying the roles of plasmids in bacterial evolution and adaptation. Metagenomic sequencing has become a major means to obtain new plasmids and derive their hosts. However, host prediction for assembled plasmid contigs still needs to tackle several challenges: different sequence compositions and copy numbers between plasmids and the hosts, high diversity in plasmids, and limited plasmid annotations. Existing tools have not yet achieved an ideal tradeoff between sensitivity and precision on metagenomic assembled contigs. Results: In this work, we construct a hierarchical classification tool named HOTSPOT, whose backbone is a phylogenetic tree of the bacterial hosts from phylum to species. By incorporating the state-of-the-art language model, Transformer, in each node’s taxon classifier, the top-down tree search achieves an accurate host taxonomy prediction for the input plasmid contigs. We rigorously tested HOTSPOT on multiple datasets, including RefSeq complete plasmids, artificial contigs, simulated metagenomic data, mock metagenomic data, the Hi-C dataset, and the CAMI2 marine dataset. All experiments show that HOTSPOT outperforms other popular methods. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Gao, P.
AU  - Yang, X.
AU  - Zhang, R.
AU  - Goulermas, J.Y.
AU  - Geng, Y.
AU  - Yan, Y.
AU  - Huang, K.
TI  - Generalized image outpainting with U-transformer
PY  - 2023
T2  - Neural Networks
VL  - 162
SP  - 1
EP  - 10
DO  - 10.1016/j.neunet.2023.02.021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149296011&doi=10.1016%2fj.neunet.2023.02.021&partnerID=40&md5=cb7c9abb71920a02f7cbd299d9c6c6db
AB  - In this paper, we develop a novel transformer-based generative adversarial neural network called U-Transformer for generalized image outpainting problems. Different from most present image outpainting methods conducting horizontal extrapolation, our generalized image outpainting could extrapolate visual context all-side around a given image with plausible structure and details even for complicated scenery, building, and art images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular Swin Transformer blocks. As such, our novel neural network can better cope with image long-range dependencies which are crucially important for generalized image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor (TSP) module to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. By adjusting the predicting step in the TSP module in the testing stage, we can generate arbitrary outpainting size given the input sub-image. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ni, S.
AU  - Zhou, W.
AU  - Wen, J.
AU  - Hu, L.
AU  - Qiao, S.
TI  - Enhancing sequential recommendation with contrastive Generative Adversarial Network
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 3
C7  - 103331
DO  - 10.1016/j.ipm.2023.103331
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149176358&doi=10.1016%2fj.ipm.2023.103331&partnerID=40&md5=70da474707cce01e938a8f3edd15393b
AB  - Sequential recommendation models a user's historical sequence to predict future items. Existing studies utilize deep learning methods and contrastive learning for data augmentation to alleviate data sparsity. However, these existing methods cannot learn accurate high-quality item representations while augmenting data. In addition, they usually ignore data noise and user cold-start issues. To solve the above issues, we investigate the possibility of Generative Adversarial Network (GAN) with contrastive learning for sequential recommendation to balance data sparsity and noise. Specifically, we propose a new framework, Enhanced Contrastive Learning with Generative Adversarial Network for Sequential Recommendation (ECGAN-Rec), which models the training process as a GAN and recommendation task as the main task of the discriminator. We design a sequence augmentation module and a contrastive GAN module to implement both data-level and model-level augmentations. In addition, the contrastive GAN learns more accurate high-quality item representations to alleviate data noise after data augmentation. Furthermore, we propose an enhanced Transformer recommender based on GAN to optimize the performance of the model. Experimental results on three open datasets validate the efficiency and effectiveness of the proposed model and the ability of the model to balance data noise and data sparsity. Specifically, the improvement of ECGAN-Rec in two evaluation metrics (HR@N and NDCG@N) compared to the state-of-the-art model performance on the Beauty, Sports and Yelp datasets are 34.95%, 36.68%, and 13.66%, respectively. Our implemented model is available via https://github.com/nishawn/ECGANRec-master. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Wang, S.
AU  - Lin, M.
AU  - Xu, Z.
AU  - Guo, W.
TI  - Learning speaker-independent multimodal representation for sentiment analysis
PY  - 2023
T2  - Information Sciences
VL  - 628
SP  - 208
EP  - 225
DO  - 10.1016/j.ins.2023.01.116
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147197890&doi=10.1016%2fj.ins.2023.01.116&partnerID=40&md5=bfdbc53d355943644d9db6a719c5d904
AB  - Multimodal sentiment analysis is an actively growing research area that utilizes language, acoustic and visual signals to predict sentiment inclination. Compared to language, acoustic and visual features carry a more evident personal style which may degrade the model generalization capability. The issue will be exacerbated in a speaker-independent setting, where the model will encounter samples from unseen speakers during the testing stage. To mitigate personal style's impact, we propose a framework named SIMR for learning speaker-independent multimodal representation. This framework separates the nonverbal inputs into style encoding and content representation with the aid of informative cross-modal correlations. Besides, in terms of integrating cross-modal complementary information, the classical transformer-based approaches are inherently inclined to discover compatible cross-modal interactions but ignore incompatible ones. In contrast, we suggest simultaneously locating both through an enhanced cross-modal transformer module. Experimental results show that the proposed model achieves state-of-the-art performance on several datasets. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2023Learning
ER  -

TY  - JOUR
AU  - Roy, A.M.
AU  - Bhaduri, J.
TI  - DenseSPH-YOLOv5: An automated damage detection model based on DenseNet and Swin-Transformer prediction head-enabled YOLOv5 with attention mechanism
PY  - 2023
T2  - Advanced Engineering Informatics
VL  - 56
C7  - 102007
DO  - 10.1016/j.aei.2023.102007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159555749&doi=10.1016%2fj.aei.2023.102007&partnerID=40&md5=bcb9a42df7efcea709581643ae1906f2
AB  - Objective.: Computer vision-based up-to-date accurate damage classification and localization are of decisive importance for infrastructure monitoring, safety, and the serviceability of civil infrastructure. Current state-of-the-art deep learning (DL)-based damage detection models, however, often lack superior feature extraction capability in complex and noisy environments, limiting the development of accurate and reliable object distinction. Method.: To this end, we present DenseSPH-YOLOv5, a real-time DL-based high-performance damage detection model where DenseNet blocks have been integrated with the backbone to improve in preserving and reusing critical feature information. Additionally, convolutional block attention modules (CBAM) have been implemented to improve attention performance mechanisms for strong and discriminating deep spatial feature extraction that results in superior detection under various challenging environments. Moreover, an additional feature fusion layers and a Swin-Transformer Prediction Head (SPH) have been added leveraging advanced self-attention mechanism for more efficient detection of multiscale object sizes and simultaneously reducing the computational complexity. Results.: Evaluating the model performance in large-scale Road Damage Dataset (RDD-2018), at a detection rate of 62.4 FPS, DenseSPH-YOLOv5 obtains a mean average precision (mAP) value of 85.25%, F1-score of 81.18%, and precision (P) value of 89.51% outperforming current state-of-the-art models. Significance.: The present research provides an effective and efficient damage localization model addressing the shortcoming of existing DL-based damage detection models by providing highly accurate localized bounding box prediction. Current work constitutes a step towards an accurate and robust automated damage detection system in real-time in-field applications. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 127
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhao, Q.
AU  - Gao, T.
AU  - Guo, N.
TI  - TSVFN: Two-Stage Visual Fusion Network for multimodal relation extraction
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 3
C7  - 103264
DO  - 10.1016/j.ipm.2023.103264
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145966897&doi=10.1016%2fj.ipm.2023.103264&partnerID=40&md5=23efc2339223f1939be2941f3c4775c6
AB  - Multimodal relation extraction is a critical task in information extraction, aiming to predict the class of relations between head and tail entities from linguistic sequences and related images. However, the current works are vulnerable to less relevant visual objects detected from images and are not able to sufficiently fuse visual information into text pre-trained models. To overcome these problems, we propose a Two-Stage Visual Fusion Network (TSVFN) that employs the multimodal fusion approach in vision-enhanced entity relation extraction. In the first stage, we design multimodal graphs, whose novelty lies mainly in transforming the sequence learning into the graph learning. In the second stage, we merge the transformer-based visual representation into the text pre-trained model by a multi-scale cross-model projector. Specifically, two multimodal fusion operations are implemented inside the pre-trained model respectively. We finally accomplish deep interaction of multimodal multi-structured data in two fusion stages. Extensive experiments are conducted on a dataset (MNRE), our model outperforms the current state-of-the-art method by 1.76%, 1.52%, 1.29%, and 1.17% in terms of accuracy, precision, recall, and F1 score, respectively. Moreover, our model also achieves excellent results under the condition of fewer samples. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Zhao, M.
AU  - Tang, H.
AU  - Xie, P.
AU  - Dai, S.
AU  - Sebe, N.
AU  - Wang, W.
TI  - Bidirectional Transformer GAN for Long-Term Human Motion Prediction
PY  - 2023
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 19
IS  - 5
C7  - 163
DO  - 10.1145/3579359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148734726&doi=10.1145%2f3579359&partnerID=40&md5=fa1cade1df0ea740bac3e96d1a58d22d
AB  - The mainstream motion prediction methods usually focus on short-Term prediction, and their predicted long-Term motions often fall into an average pose, i.e., the freezing forecasting problem [27]. To mitigate this problem, we propose a novel Bidirectional Transformer-based Generative Adversarial Network (BiTGAN) for long-Term human motion prediction. The bidirectional setup leads to consistent and smooth generation in both forward and backward directions. Besides, to make full use of the history motions, we split them into two parts. The first part is fed to the Transformer encoder in our BiTGAN while the second part is used as the decoder input. This strategy can alleviate the exposure problem [37]. Additionally, to better maintain both the local (i.e., frame-level pose) and global (i.e., video-level semantic) similarities between the predicted motion sequence and the real one, the soft dynamic time warping (Soft-DTW) loss is introduced into the generator. Finally, we utilize a dual-discriminator to distinguish the predicted sequence at both frame and sequence levels. Extensive experiments on the public Human3.6M dataset demonstrate that our proposed BiTGAN achieves state-of-The-Art performance on long-Term (4s) human motion prediction, and reduces the average error of all actions by 4%.  © 2023 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Çelik, E.
AU  - Dalyan, T.
TI  - Unified benchmark for zero-shot Turkish text classification
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 3
C7  - 103298
DO  - 10.1016/j.ipm.2023.103298
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147606807&doi=10.1016%2fj.ipm.2023.103298&partnerID=40&md5=b0b3cbc4ac4321ffddeaae6967a0a9f1
AB  - Effective learning schemes such as fine-tuning, zero-shot, and few-shot learning, have been widely used to obtain considerable performance with only a handful of annotated training data. In this paper, we presented a unified benchmark to facilitate the problem of zero-shot text classification in Turkish. For this purpose, we evaluated three methods, namely, Natural Language Inference, Next Sentence Prediction and our proposed model that is based on Masked Language Modeling and pre-trained word embeddings on nine Turkish datasets for three main categories: topic, sentiment, and emotion. We used pre-trained Turkish monolingual and multilingual transformer models which can be listed as BERT, ConvBERT, DistilBERT and mBERT. The results showed that ConvBERT with the NLI method yields the best results with 79% and outperforms previously used multilingual XLM-RoBERTa model by 19.6%. The study contributes to the literature using different and unattempted transformer models for Turkish and showing improvement of zero-shot text classification performance for monolingual models over multilingual models. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Dai, L.
AU  - Liu, H.
AU  - Tang, H.
AU  - Wu, Z.
AU  - Song, P.
TI  - AO2-DETR: Arbitrary-Oriented Object Detection Transformer
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 5
SP  - 2342
EP  - 2356
DO  - 10.1109/TCSVT.2022.3222906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142856037&doi=10.1109%2fTCSVT.2022.3222906&partnerID=40&md5=b46a458907b9bcb7ce4b6e82d2d2d6fd
AB  - Arbitrary-oriented object detection (AOOD) is a challenging task to detect objects in the wild with arbitrary orientations and cluttered arrangements. Existing approaches are mainly based on anchor-based boxes or dense points, which rely on complicated hand-designed processing steps and inductive bias, such as anchor generation, transformation, and non-maximum suppression reasoning. Recently, the emerging transformer-based approaches view object detection as a direct set prediction problem that effectively removes the need for hand-designed components and inductive biases. In this paper, we propose an Arbitrary-Oriented Object DEtection TRansformer framework, termed AO2-DETR, which comprises three dedicated components. More precisely, an oriented proposal generation mechanism is proposed to explicitly generate oriented proposals, which provides better positional priors for pooling features to modulate the cross-attention in the transformer decoder. An adaptive oriented proposal refinement module is introduced to extract rotation-invariant region features and eliminate the misalignment between region features and objects. And a rotation-aware set matching loss is used to ensure the one-to-one matching process for direct set prediction without duplicate predictions. Our method considerably simplifies the overall pipeline and presents a new AOOD paradigm. Comprehensive experiments on several challenging datasets show that our method achieves superior performance on the AOOD task.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 79
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, D.
AU  - Lei, F.
TI  - Temporal group-aware graph diffusion networks for dynamic link prediction
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 3
C7  - 103292
DO  - 10.1016/j.ipm.2023.103292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147993359&doi=10.1016%2fj.ipm.2023.103292&partnerID=40&md5=55d27ddc871d41a29741af7d03f4495a
AB  - Dynamic link prediction is a critical task in network research that seeks to predict future network links based on the relative behavior of prior network changes. However, most existing methods overlook mutual interactions between neighbors and long-distance interactions and lack the interpretability of the model's predictions. To tackle the above issues, in this paper, we propose a temporal group-aware graph diffusion network(TGGDN). First, we construct a group affinity matrix to describe mutual interactions between neighbors, i.e., group interactions. Then, we merge the group affinity matrix into the graph diffusion to form a group-aware graph diffusion, which simultaneously captures group interactions and long-distance interactions in dynamic networks. Additionally, we present a transformer block that models the temporal information of dynamic networks using self-attention, allowing the TGGDN to pay greater attention to task-related snapshots while also providing interpretability to better understand the network evolutionary patterns. We compare the proposed TGGDN with state-of-the-art methods on five different sizes of real-world datasets ranging from 1k to 20k nodes. Experimental results show that TGGDN achieves an average improvement of 8.3% and 3.8% in terms of ACC and AUC on all datasets, respectively, demonstrating the superiority of TGGDN in the dynamic link prediction task. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Cheng, D.
AU  - Wang, G.
AU  - Wang, B.
AU  - Zhang, Q.
AU  - Han, J.
AU  - Zhang, D.
TI  - Hybrid routing transformer for zero-shot learning
PY  - 2023
T2  - Pattern Recognition
VL  - 137
C7  - 109270
DO  - 10.1016/j.patcog.2022.109270
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145252929&doi=10.1016%2fj.patcog.2022.109270&partnerID=40&md5=f7eb7d7b14493a1ba12c87f296bdc8cf
AB  - Zero-shot learning (ZSL) aims to learn models that can recognize unseen image semantics based on the training of data with seen semantics. Recent studies either leverage the global image features or mine discriminative local patch features to associate the extracted visual features to the semantic attributes. However, due to the lack of the necessary top-down guidance and semantic alignment for ensuring the model attend to the real attribute-correlation regions, these methods still encounter a significant semantic gap between the visual modality and the attribute modality, which makes their prediction on unseen semantics unreliable. To solve this problem, this paper establishes a novel transformer encoder-decoder model, called hybrid routing transformer (HRT). In HRT encoder, we embed an active attention, which is constructed by both the bottom-up and the top-down dynamic routing pathways to generate the attribute-aligned visual feature. While in HRT decoder, we use static routing to calculate the correlation among the attribute-aligned visual features, the corresponding attribute semantics, and the class attribute vectors to generate the final class label predictions. This design makes the presented transformer model a hybrid of 1) top-down and bottom-up attention pathways and 2) dynamic and static routing pathways. Comprehensive experiments on three widely-used benchmark datasets, namely CUB, SUN, and AWA2, are conducted. The obtained experimental results demonstrate the effectiveness of the proposed method. Our code is released in https://github.com/KORIYN/HRT. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 61
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xi, D.
AU  - Tang, L.
AU  - Chen, R.
AU  - Xu, W.
TI  - A multimodal time-series method for gifting prediction in live streaming platforms
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 3
C7  - 103254
DO  - 10.1016/j.ipm.2022.103254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145260789&doi=10.1016%2fj.ipm.2022.103254&partnerID=40&md5=dde34ab64ce7f6f56d24d91045132940
AB  - Viewer gifting is an important business mode in live streaming industry, which closely relates to the income of the platforms and streamers. Previous studies on gifting prediction are often limited to cross-section data and consider the problem from the macro perspective of the whole live streaming. However, the multimodal information and the time accumulation effect of live streaming content on viewer gifting behavior are ignored. In this paper, we put forward a multimodal time-series method (MTM) for predicting real-time gifting. The core module of the method is the multimodal time-series analysis (MTA), which targets at effectively fusing multimodal information. Specifically, the proposed orthogonal projection (OP) model can promote cross-modal information interaction without introducing additional parameters. To achieve the interaction of multi-modal information at the same level, we also design a stackable joint representation layer, which makes each target modality's representation (visual, acoustic and textual modality) can benefit from all the other modalities. The residual connections are introduced as well to ensure the integration of low-level and high-level information. On our dataset, our model shows improved performance compared to other advanced models by at least 8% on F1. Meanwhile, the MTA is able to meet the real-time requirements of the live streaming setting, and has demonstrated its robustness and transferability in other tasks. Our research may offer some insights about how to efficiently fuse multimodal information, and contribute to the research on viewer gifting behavior prediction in the live streaming context. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Li, M.
AU  - Zhang, Y.
AU  - Li, X.
AU  - Zhang, Y.
AU  - Yin, B.
TI  - Hypergraph Transformer Neural Networks
PY  - 2023
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 17
IS  - 5
C7  - 63
DO  - 10.1145/3565028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153856470&doi=10.1145%2f3565028&partnerID=40&md5=f55f2a30b340243f4d1697253e15938e
AB  - Graph neural networks (GNNs) have been widely used for graph structure learning and achieved excellent performance in tasks such as node classification and link prediction. Real-world graph networks imply complex and various semantic information and are often referred to as heterogeneous information networks (HINs). Previous GNNs have laboriously modeled heterogeneous graph networks with pairwise relations, in which the semantic information representation for learning is incomplete and severely hinders node embedded learning. Therefore, the conventional graph structure cannot satisfy the demand for information discovery in HINs. In this article, we propose an end-to-end hypergraph transformer neural network (HGTN) that exploits the communication abilities between different types of nodes and hyperedges to learn higher-order relations and discover semantic information. Specifically, attention mechanisms weigh the importance of semantic information hidden in original HINs to generate useful meta-paths. Meanwhile, our method develops a multi-scale attention module to aggregate node embeddings in higher-order neighborhoods. We evaluate the proposed model with node classification tasks on six datasets: DBLP, ACM, IBDM, Reuters, STUD-BJUT, and Citeseer. Experiments on a large number of benchmarks show the advantages of HGTN.  © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; FMS:B; 
LB  - Li2023Hypergraph
ER  -

TY  - JOUR
AU  - Pang, J.
AU  - Jiang, C.
AU  - Chen, Y.
AU  - Chang, J.
AU  - Feng, M.
AU  - Wang, R.
AU  - Yao, J.
TI  - 3D Shuffle-Mixer: An Efficient Context-Aware Vision Learner of Transformer-MLP Paradigm for Dense Prediction in Medical Volume
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 5
SP  - 1241
EP  - 1253
DO  - 10.1109/TMI.2022.3191974
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135231498&doi=10.1109%2fTMI.2022.3191974&partnerID=40&md5=eeeaefb31b70e87175ba68af251e07c2
AB  - Dense prediction in medical volume provides enriched guidance for clinical analysis. CNN backbones have met bottleneck due to lack of long-range dependencies and global context modeling power. Recent works proposed to combine vision transformer with CNN, due to its strong global capture ability and learning capability. However, most works are limited to simply applying pure transformer with several fatal flaws (i.e., lack of inductive bias, heavy computation and little consideration for 3D data). Therefore, designing an elegant and efficient vision transformer learner for dense prediction in medical volume is promising and challenging. In this paper, we propose a novel 3D Shuffle-Mixer network of a new Local Vision Transformer-MLP paradigm for medical dense prediction. In our network, a local vision transformer block is utilized to shuffle and learn spatial context from full-view slices of rearranged volume, a residual axial-MLP is designed to mix and capture remaining volume context in a slice-aware manner, and a MLP view aggregator is employed to project the learned full-view rich context to the volume feature in a view-aware manner. Moreover, an Adaptive Scaled Enhanced Shortcut is proposed for local vision transformer to enhance feature along spatial and channel dimensions adaptively, and a CrossMerge is proposed to skip-connect the multi-scale feature appropriately in the pyramid architecture. Extensive experiments demonstrate the proposed model outperforms other state-of-the-art medical dense prediction methods. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Borchert, P.
AU  - Coussement, K.
AU  - De Caigny, A.
AU  - De Weerdt, J.
TI  - Extending business failure prediction models with textual website content using deep learning
PY  - 2023
T2  - European Journal of Operational Research
VL  - 306
IS  - 1
SP  - 348
EP  - 357
DO  - 10.1016/j.ejor.2022.06.060
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134723297&doi=10.1016%2fj.ejor.2022.06.060&partnerID=40&md5=250b32572ff3788bb3de6b809ddc99e8
AB  - Business failure prediction (BFP) is an important instrument in assessing the risk of corporate failure. While a large body of research has focused on BFP, recent research in operations research and analytics acknowledges the beneficial effect of incorporating textual data for predictive modelling. However, extant BFP research that incorporates textual company information is very scarce. Based on a dataset containing 13,571 European companies provided by the largest European data aggregator, this study investigates the added value of extending traditional BFP models with textual website content. We further benchmark various feature extraction techniques in natural language processing (i.e. the vector-space approach, neural networks-based approaches and transformers) and assess the best way of representing and integrating textual website features for BFP modelling. The results confirm that including textual website data improves BFP predictive performance, and that textual features extracted by transformers add the most value to the BFP models in this benchmark setting. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Borchert2023Extending
ER  -

TY  - JOUR
AU  - Xiong, J.
AU  - Yu, L.
AU  - Niu, X.
AU  - Leng, Y.
TI  - XRR: Extreme multi-label text classification with candidate retrieving and deep ranking
PY  - 2023
T2  - Information Sciences
VL  - 622
SP  - 115
EP  - 132
DO  - 10.1016/j.ins.2022.11.158
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145556608&doi=10.1016%2fj.ins.2022.11.158&partnerID=40&md5=8b0396990d98095b3739121c47d76747
AB  - Extreme Multi-label Text Classification (XMTC) is a key task of finding the most relevant labels from a large label set for a document. Although some deep learning-based methods have shown great success in XMTC, they still suffer from the following drawbacks. First, although several methods have improved the precision by clustering labels and combining several sub-models to train and predict for one dataset, they were not ideal in terms of computational efficiency. Second, most of those methods need a low dimensional bottleneck layer before the output layer to compress the feature representations to fit the GPU memory, which results in information loss of original features. In this paper, we proposed a novel two-stage XMTC framework with candidate Retrieving and deep Ranking (XRR) to address those drawbacks. In the retrieving stage, we designed two retrieval strategies, including an aligning Point Mutual Information (aPMI) method, and a Unified Label-Semantic Embedding (ULSE) method, to extract hundreds of candidates from massive labels. In the ranking stage, we presented a deep ranking model using a pre-trained transformer to distinguish the true labels from candidates. Extensive experiments show that XRR outperforms the state-of-the-art methods on five widely used multi-label datasets. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; FMS:B; 
LB  - Xiong2023XRR
ER  -

TY  - JOUR
AU  - Huo, G.
AU  - Zhang, Y.
AU  - Wang, B.
AU  - Gao, J.
AU  - Hu, Y.
AU  - Yin, B.
TI  - Hierarchical Spatio-Temporal Graph Convolutional Networks and Transformer Network for Traffic Flow Forecasting
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 3855
EP  - 3867
DO  - 10.1109/TITS.2023.3234512
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147217824&doi=10.1109%2fTITS.2023.3234512&partnerID=40&md5=e85eb12ef4f4506bd1e2e3088c2643b8
AB  - Graph convolutional networks (GCN) have been applied in the traffic flow forecasting tasks with the graph capability in describing the irregular topology structures of road networks. However, GCN based traffic flow forecasting methods often fail to simultaneously capture the short-term and long-term temporal relations carried by the traffic flow data, and also suffer the over-smoothing problem. To overcome the problems, we propose a hierarchical traffic flow forecasting network by merging newly designed the long-term temporal Transformer network (LTT) and the spatio-temporal graph convolutional networks (STGC). Specifically, LTT aims to learn the long-term temporal relations among the traffic flow data, while the STGC module aims to capture the short-term temporal relations and spatial relations among the traffic flow data, respectively, via cascading between the one-dimensional convolution and the graph convolution. In addition, an attention fusion mechanism is proposed to combine the long-term with the short-term temporal relations as the input of the graph convolution layer in STGC, in order to mitigate the over-smoothing problem of GCN. Experimental results on three public traffic flow datasets prove the effectiveness and robustness of the proposed method.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - CCF:B期刊; FMS:B; 
LB  - Huo2023Hierarchical
ER  -

TY  - JOUR
AU  - Wang, D.
AU  - Guo, X.
AU  - Tian, Y.
AU  - Liu, J.
AU  - He, L.
AU  - Luo, X.
TI  - TETFN: A text enhanced transformer fusion network for multimodal sentiment analysis
PY  - 2023
T2  - Pattern Recognition
VL  - 136
C7  - 109259
DO  - 10.1016/j.patcog.2022.109259
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144584121&doi=10.1016%2fj.patcog.2022.109259&partnerID=40&md5=1e00f26a11c183e33d0286463b60c43e
AB  - Multimodal sentiment analysis (MSA), which aims to recognize sentiment expressed by speakers in videos utilizing textual, visual and acoustic cues, has attracted extensive research attention in recent years. However, textual, visual and acoustic modalities often contribute differently to sentiment analysis. In general, text contains more intuitive sentiment-related information and outperforms nonlinguistic modalities in MSA. Seeking a strategy to take advantage of this property to obtain a fusion representation containing more sentiment-related information and simultaneously preserving inter- and intra-modality relationships becomes a significant challenge. To this end, we propose a novel method named Text Enhanced Transformer Fusion Network (TETFN), which learns text-oriented pairwise cross-modal mappings for obtaining effective unified multimodal representations. In particular, it incorporates textual information in learning sentiment-related nonlinguistic representations through text-based multi-head attention. In addition to preserving consistency information by cross-modal mappings, it also retains the differentiated information among modalities through unimodal label prediction. Furthermore, the vision pre-trained model Vision-Transformer is utilized to extract visual features from the original videos to preserve both global and local information of a human face. Extensive experiments on benchmark datasets CMU-MOSI and CMU-MOSEI demonstrate the superior performance of the proposed TETFN over state-of-the-art methods. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 82
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Guo, S.
AU  - Li, M.
AU  - Ge, X.
AU  - Li, H.
AU  - Chen, R.
AU  - Li, T.
TI  - Constructing meaningful code changes via graph transformer
PY  - 2023
T2  - IET Software
VL  - 17
IS  - 2
SP  - 154
EP  - 167
DO  - 10.1049/sfw2.12097
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147002613&doi=10.1049%2fsfw2.12097&partnerID=40&md5=b62776ef8ca8c70fb4f774146aba6b43
AB  - The rapid development of Open-Source Software (OSS) has resulted in a significant demand for code changes to maintain OSS. Symptoms of poor design and implementation choices in code changes often occur, thus heavily hindering code reviewers to verify correctness and soundness of code changes. Researchers have investigated how to learn meaningful code changes to assist developers in anticipating changes that code reviewers may suggest for the submitted code. However, there are two main limitations to be addressed, including the limitation of long-range dependencies of the source code and the missing syntactic structural information of the source code. To solve these limitations, a novel method is proposed, named Graph Transformer for learning meaningful Code Transformations (GTCT), to provide developers with preliminary and quick feedback when developers submit code changes, which can improve the quality of code changes and improve the efficiency of code review. GTCT comprises two components: code graph embedding and code transformation learning. To address the missing syntactic structural information of the source code limitation, the code graph embedding component captures the types and patterns of code changes by encoding the source code into a code graph structure from the lexical and syntactic representations of the source code. Subsequently, the code transformation learning component uses the multi-head attention mechanism and positional encoding mechanism to address the long-range dependencies limitation. Extensive experiments are conducted to evaluate the performance of GTCT by both quantitative and qualitative analyses. For the quantitative analysis, GTCT relatively outperforms the baseline on six datasets by 210%, 342.86%, 135%, 29.41%, 109.09%, and 91.67% in terms of perfect prediction. Meanwhile, the qualitative analysis shows that each type of code change by GTCT outperforms that of the baseline method in terms of bug fixed, refactoring code and others' taxonomy of code changes. © 2023 The Authors. IET Software published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, J.
AU  - Zhang, A.
AU  - Liu, F.
AU  - Zhang, X.
TI  - STGRNS: an interpretable transformer-based method for inferring gene regulatory networks from single-cell transcriptomic data
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 4
C7  - btad165
DO  - 10.1093/bioinformatics/btad165
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152171582&doi=10.1093%2fbioinformatics%2fbtad165&partnerID=40&md5=4285793fe2ea5efb34327c3ff874c570
AB  - Motivation: Single-cell RNA-sequencing (scRNA-seq) technologies provide an opportunity to infer cell-specific gene regulatory networks (GRNs), which is an important challenge in systems biology. Although numerous methods have been developed for inferring GRNs from scRNA-seq data, it is still a challenge to deal with cellular heterogeneity. Results: To address this challenge, we developed an interpretable transformer-based method namely STGRNS for inferring GRNs from scRNA-seq data. In this algorithm, gene expression motif technique was proposed to convert gene pairs into contiguous sub-vectors, which can be used as input for the transformer encoder. By avoiding missing phase-specific regulations in a network, gene expression motif can improve the accuracy of GRN inference for different types of scRNA-seq data. To assess the performance of STGRNS, we implemented the comparative experiments with some popular methods on extensive benchmark datasets including 21 static and 27 time-series scRNA-seq dataset. All the results show that STGRNS is superior to other comparative methods. In addition, STGRNS was also proved to be more interpretable than “black box” deep learning methods, which are well-known for the difficulty to explain the predictions clearly. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Ramana, K.
AU  - Srivastava, G.
AU  - Kumar, M.R.
AU  - Gadekallu, T.R.
AU  - Lin, J.C.-W.
AU  - Alazab, M.
AU  - Iwendi, C.
TI  - A Vision Transformer Approach for Traffic Congestion Prediction in Urban Areas
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 3922
EP  - 3934
DO  - 10.1109/TITS.2022.3233801
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147207357&doi=10.1109%2fTITS.2022.3233801&partnerID=40&md5=94be37b2d56c9d28d4b3a8cee1695e22
AB  - Traffic problems continue to deteriorate because of increasing population in urban areas that rely on many modes of transportation, the transportation infrastructure has achieved considerable strides in the last several decades. This has led to an increase in congestion control difficulties, which directly affect citizens through air pollution, fuel consumption, traffic law breaches, noise pollution, accidents, and loss of time. Traffic prediction is an essential aspect of an intelligent transportation system in smart cities because it helps reduce overall traffic congestion. This article aims to design and enforce a traffic prediction scheme that is efficient and accurate in forecasting traffic flow. Available traffic flow prediction methods are still unsuitable for real-world applications. This fact motivated us to work on a traffic flow forecasting issue using Vision Transformers (VTs). In this work, VTs were used in conjunction with Convolutional neural networks (CNN) to predict traffic congestion in urban spaces on a city-wide scale. In our proposed architecture, a traffic image is fed to a CNN, which generates feature maps. These feature maps are then fed to the VT, which employs the dual techniques of tokenization and projection. Tokenization is used to convert features into tokens containing Vision information, which are then sent to projection, where they are transformed into feature maps and ultimately delivered to LSTM. The experimental results demonstrate that the vision transformer prediction method based on Spatio-temporal characteristics is an excellent way of predicting traffic flow, particularly during anomalous traffic situations. The proposed technology surpasses traditional methods in terms of precision, accuracy and recall and aids in energy conservation. Through rerouting, the proposed work will benefit travellers and reduce fuel use.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 54
C2  - CCF:B期刊; FMS:B; 
LB  - Ramana2023Vision
ER  -

TY  - JOUR
AU  - Wang, Y.
AU  - Wang, J.
AU  - Cao, Y.
AU  - Li, S.
AU  - Kwan, O.
TI  - Integrated Inspection on PCB Manufacturing in Cyber-Physical-Social Systems
PY  - 2023
T2  - IEEE Transactions on Systems, Man, and Cybernetics: Systems
VL  - 53
IS  - 4
SP  - 2098
EP  - 2106
DO  - 10.1109/TSMC.2022.3229096
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146234481&doi=10.1109%2fTSMC.2022.3229096&partnerID=40&md5=19c7fd43bb6eb7627dbc03479877265c
AB  - The printed circuit boards (PCBs) industry is one of the fastest-growing industries in recent decades. The PCB manufacturing process is highly complicated and severely affected by social factors, which makes it very important to conduct integrated inspection, assuring and improving the production quality. In this article, we propose an artificial systems, computational experiments, and parallel execution-based integrated inspection method in cyber-physical-social systems (CPSS) to realize smart manufacturing. In this inspection system, rather than simply performing modeling, analysis, and control, we perform descriptive intelligence to construct production processes with limited multimodal information, perform predictive intelligence to conduct defect detection and defect prediction, and perform prescriptive intelligence to achieve defect diagnosis and defect management. In this way, our inspection system could offer a learning and training platform for workers to master professional inspection skills, provide an experimentation and evaluation platform for product defect monitoring and early warnings, and supply guidance about defect management and control to improve manufacturing processes. For technical implementation, we leverage a Transformer-based foundation model to achieve knowledge reasoning and human-computer interaction. As a result, we provide an innovative solution to cope with the challenges of quality inspection in current smart manufacturing, and expect its further applications in the PCB industry.  © 2013 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; AJG:3; zdy:3; 
LB  - Wang2023Integrated
ER  -

TY  - JOUR
AU  - Yang, C.
AU  - Pei, Z.
TI  - Long-Short Term Spatio-Temporal Aggregation for Trajectory Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 4114
EP  - 4126
DO  - 10.1109/TITS.2023.3234962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147298679&doi=10.1109%2fTITS.2023.3234962&partnerID=40&md5=59ee2340b46a1ad25d6a5e09e7f8ac22
AB  - Pedestrian trajectory prediction in crowd scenes plays a significant role in intelligent transportation systems. The main challenges are manifested in learning motion patterns and addressing future uncertainty. Typically, trajectory prediction is considered in two dimensions, including temporal dynamics modeling and social interactions capturing. For temporal dependencies, although existing models based on recurrent neural networks (RNNs) or convolutional neural networks (CNNs) achieve high performance on short-term prediction, they still suffer from limited scalability for long sequences. For social interactions, previous graph-based methods only consider fixed features but ignore dynamic interactions between pedestrians. Considering that the transformer network has a strong capability of capturing spatial and long-term temporal dynamics, we propose Long-Short Term Spatio-Temporal Aggregation (LSSTA) network for human trajectory prediction. First, a modern variant of graph neural networks, named spatial encoder, is presented to characterize spatial interactions between pedestrians. Second, LSSTA utilizes a transformer network to handle long-term temporal dependencies and aggregates the spatial and temporal features with a temporal convolution network (TCN). Thus, TCN is combined with the transformer to form a long-short term temporal dependency encoder. Additionally, multi-modal prediction is an efficient way to address future uncertainty. Existing auto-encoder modules are extended with static scene information and future ground truth for multi-modal trajectory prediction. Experimental results on complex scenes demonstrate the superior performance of our method in comparison to existing approaches.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:B期刊; FMS:B; 
LB  - Yang2023Long-Short
ER  -

TY  - JOUR
AU  - Kothari, P.
AU  - Alahi, A.
TI  - Safety-Compliant Generative Adversarial Networks for Human Trajectory Forecasting
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 4251
EP  - 4261
DO  - 10.1109/TITS.2022.3233906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147260526&doi=10.1109%2fTITS.2022.3233906&partnerID=40&md5=a7dc9d6f3e73cedf432b05bd4d0bd63c
AB  - Human trajectory forecasting in crowds presents the challenges of modelling social interactions and outputting collision-free multimodal distribution. Following the success of Social Generative Adversarial Networks (SGAN), recent works propose various GAN-based designs to better model human motion in crowds. Despite superior performance in reducing distance-based metrics, current networks fail to output socially acceptable trajectories, as evidenced by high collisions in model predictions. To counter this, we introduce SGANv2: an improved safety-compliant SGAN architecture equipped with spatio-temporal interaction modelling and a transformer-based discriminator. The spatio-temporal modelling ability helps to learn the human social interactions better while the transformer-based discriminator design improves temporal sequence modelling. Additionally, SGANv2 utilizes the learned discriminator even at test-time via a collaborative sampling strategy that not only refines the colliding trajectories but also prevents mode collapse, a common phenomenon in GAN training. Through extensive experimentation on multiple real-world and synthetic datasets, we demonstrate the efficacy of SGANv2 to provide socially-compliant multimodal trajectories.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; FMS:B; 
LB  - Kothari2023Safety-Compliant
ER  -

TY  - JOUR
AU  - Han, C.
AU  - Ma, T.
AU  - Gu, L.
AU  - Cao, J.
AU  - Shi, X.
AU  - Huang, W.
AU  - Tong, Z.
TI  - Asphalt Pavement Health Prediction Based on Improved Transformer Network
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 4
SP  - 4482
EP  - 4493
DO  - 10.1109/TITS.2022.3229326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147208715&doi=10.1109%2fTITS.2022.3229326&partnerID=40&md5=bced7dc4381d53610d58cd7a5a82f320
AB  - Neural network-based models have been implemented to predict various health indicators of asphalt pavement using pavement historical detection data. Unfortunately, their accuracy and reliability are not acceptable owing to their shallow architecture. To solve the issue, this study proposed an improved Transformer network to predict asphalt pavement health, called the Transformer with forward and reversed time series (Transformer FRTS). In terms of the input data, Transformer FRTS uses a new data form, so-called the random difference time series, to reduce the time dependency of the network prediction. In terms of the network architecture, the proposed network uses its encoder and decoder to obtain the data association from the forward and reverse time series. In addition, Transformer FRTS uses a post-processing decision criterion to improve the accuracy and reliability of prediction. The numerical experiment using the detection data from RIOHTrack full-scale track demonstrates that the proposed network has state-of-the-practice performance in asphalt pavement health prediction.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:B期刊; FMS:B; 
LB  - Han2023Asphalt
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Bai, L.
TI  - Few-shot link prediction for temporal knowledge graphs based on time-aware translation and attention mechanism
PY  - 2023
T2  - Neural Networks
VL  - 161
SP  - 371
EP  - 381
DO  - 10.1016/j.neunet.2023.01.043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147842949&doi=10.1016%2fj.neunet.2023.01.043&partnerID=40&md5=9415934c7d37aa61e6057bc99a1e2209
AB  - Few-shot knowledge graph completion (KGC) is an important and common task in real applications, which aims to predict unseen facts when only few samples are available for each relation in the knowledge graph (KG). Previous methods on few-shot KGC mainly focus on static KG, however, many KG in real-world applications are dynamic and develop over time. In this work, we consider few-shot KGC in temporal knowledge graphs (TKGs), where the fact may only hold for a specific timestamp. We propose a Few-Shot Completion model in TKG (TFSC), which compare the input query to the given few-shot references to make predictions. Specifically, in order to enhance the representation of entities in the case of few samples, we use the attention mechanism to model the neighbor entities of the task entity with timestamp information, and generate expressive time-aware entity pair representations through the Transformer encoder. A comprehensive set of experiments is finally carried out to demonstrate the effectiveness a of our proposed model TFSC. © 2023 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Zhu, Z.
AU  - Su, H.
AU  - Zhu, J.
AU  - Zheng, S.
AU  - He, Y.
AU  - Xue, H.
TI  - To make yourself invisible with Adversarial Semantic Contours
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 230
C7  - 103659
DO  - 10.1016/j.cviu.2023.103659
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149422933&doi=10.1016%2fj.cviu.2023.103659&partnerID=40&md5=55732755324160d38a8e5eda77f5e982
AB  - Modern object detectors are vulnerable to adversarial examples, which may bring risks to real-world applications. The sparse attack is an important task which, compared with the popular adversarial perturbation on the whole image, needs to select the potential pixels that is generally regularized by an ℓ0-norm constraint, and simultaneously optimize the corresponding texture. The non-differentiability of ℓ0 norm brings challenges and many works on attacking object detection adopted manually-designed patterns to address them, which are meaningless and independent of objects, and therefore lead to relatively poor attack performance. In this paper, we propose Adversarial Semantic Contour (ASC), an MAP estimate of a Bayesian formulation of sparse attack with a deceived prior of object contour. The object contour prior effectively reduces the search space of pixel selection and improves the attack by introducing more semantic bias. Extensive experiments demonstrate that ASC can corrupt the prediction of 9 modern detectors with different architectures (e.g., one-stage, two-stage and Transformer) by modifying fewer than 5% of the pixels of the object area in COCO in white-box scenario and around 10% of those in black-box scenario. We further extend the attack to datasets for autonomous driving systems to verify the effectiveness. We conclude with cautions about contour being the common weakness of object detectors with various architecture and the care needed in applying them in safety-sensitive scenarios. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Long, X.
AU  - Gong, X.
AU  - Zhang, B.
AU  - Zhou, H.
TI  - Deep learning based data prefetching in CPU-GPU unified virtual memory
PY  - 2023
T2  - Journal of Parallel and Distributed Computing
VL  - 174
SP  - 19
EP  - 31
DO  - 10.1016/j.jpdc.2022.12.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144449438&doi=10.1016%2fj.jpdc.2022.12.004&partnerID=40&md5=52d4630dee9bd2745c1ae2f0805e8ded
AB  - Unified Virtual Memory (UVM) relieves the developers from the onus of maintaining complex data structures and explicit data migration by enabling on-demand data movement between CPU memory and GPU memory. However, on-demand paging soon becomes a performance bottleneck of UVM due to the high latency caused by page table walks and data migration over interconnect. Prefetching is considered a promising solution to this problem given its ability to leverage the locality of program memory access patterns. However, existing locality-based prefetching schemes can not handle all the situations. An ideal prefetcher should not only look at narrow regions of the requested address space but also capture global context to deliver a good prediction of the memory access pattern. This paper proposes a novel framework for page prefetching for UVM through deep learning. We first show that a powerful Transformer learning model can provide high accuracy for UVM page prefetching. We then perform analysis to interpret this Transformer model and derive several insights that allow us to design a simpler model to match the unconstrained model's accuracy with orders of magnitude lower cost. We use a pattern-based method to make the UVM page preditor general to different GPU workloads. We evaluate this framework on a set of 11 memory-intensive benchmarks from popular benchmark suites. Our solution outperforms the state-of-the-art (SOTA) UVM framework, improving the performance by 10.89%, improving the device memory page hit rate by 16.98% (89.02% vs. 76.10% for prior art), and reducing the CPU-GPU interconnect traffic by 11.05%. According to our proposed unified metric, which combines the accuracy, coverage, and page hit rate, our solution is approaching the ideal prefetching scheme more than the SOTA design (0.90 vs. 0.85, with the perfect prefetcher of 1.0). © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zou, W.
AU  - Qi, X.
AU  - Zhou, W.
AU  - Sun, M.
AU  - Sun, Z.
AU  - Shan, C.
TI  - Graph Flow: Cross-Layer Graph Flow Distillation for Dual Efficient Medical Image Segmentation
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 4
SP  - 1159
EP  - 1171
DO  - 10.1109/TMI.2022.3224459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144027697&doi=10.1109%2fTMI.2022.3224459&partnerID=40&md5=8e57c6bfbfc09c8732c7978c7ea898aa
AB  - With the development of deep convolutional neural networks, medical image segmentation has achieved a series of breakthroughs in recent years. However, high-performance convolutional neural networks always mean numerous parameters and high computation costs, which will hinder the applications in resource-limited medical scenarios. Meanwhile, the scarceness of large-scale annotated medical image datasets further impedes the application of high-performance networks. To tackle these problems, we propose Graph Flow, a comprehensive knowledge distillation framework, for both network-efficiency and annotation-efficiency medical image segmentation. Specifically, the Graph Flow Distillation transfers the essence of cross-layer variations from a well-trained cumbersome teacher network to a non-trained compact student network. In addition, an unsupervised Paraphraser Module is integrated to purify the knowledge of the teacher, which is also beneficial for the training stabilization. Furthermore, we build a unified distillation framework by integrating the adversarial distillation and the vanilla logits distillation, which can further refine the final predictions of the compact network. With different teacher networks (traditional convolutional architecture or prevalent transformer architecture) and student networks, we conduct extensive experiments on four medical image datasets with different modalities (Gastric Cancer, Synapse, BUSI, and CVC-ClinicDB). We demonstrate the prominent ability of our method on these datasets, which achieves competitive performances. Moreover, we demonstrate the effectiveness of our Graph Flow through a novel semi-supervised paradigm for dual efficient medical image segmentation. Our code will be available at Graph Flow.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jiang, L.
AU  - Zhang, T.
AU  - Lei, W.
AU  - Zhuang, K.
AU  - Li, Y.
TI  - A new convolutional dual-channel Transformer network with time window concatenation for remaining useful life prediction of rolling bearings
PY  - 2023
T2  - Advanced Engineering Informatics
VL  - 56
C7  - 101966
DO  - 10.1016/j.aei.2023.101966
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151359510&doi=10.1016%2fj.aei.2023.101966&partnerID=40&md5=736a2789b2c138d752ea082c87966d4c
AB  - Deep learning has achieved numerous breakthroughs in bearing predicting remaining useful life (RUL). However, the current mainstream deep learning framework inevitably has flaws, including the disadvantage of the small receptive field, the difficulty of learning long-term dependencies and the singularity of feature extraction domains, etc. Given the challenges mentioned above, we propose a new convolutional dual-channel Transformer network (CDCT) for remaining useful life prediction of rolling bearings. In the CDCT, the causal convolution operation is applied to extract local features from the time and frequency domains and add positional encoding to the input signal, while the transformer block is utilized for extracting bidirectional features and fusing them. The CDCT not only has a global receptive field but also can learn long-term dependencies regardless of sequence length. Besides, the time window concatenation is adopted to ameliorate the problem of large amounts of trainable parameters of the Transformer-based models. In the experiments, we conduct a detailed analysis of each crucial element and hyperparameter of the CDCT and compare it to multiple basic and advanced methods. The experimental results highlight the superiority of the CDCT in bearing RUL prediction and demonstrate the effectiveness of crucial elements in the CDCT. © 2023
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, B.
AU  - Fan, T.
AU  - Wang, K.
AU  - Zhang, H.
AU  - Yu, C.
AU  - Nie, S.
AU  - Qi, Y.
AU  - Zheng, W.-M.
AU  - Han, J.
AU  - Fan, Z.
AU  - Sun, S.
AU  - Ye, S.
AU  - Yang, H.
AU  - Bu, D.
TI  - Accurate and efficient protein sequence design through learning concise local environment of residues
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 3
C7  - btad122
DO  - 10.1093/bioinformatics/btad122
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150752102&doi=10.1093%2fbioinformatics%2fbtad122&partnerID=40&md5=27b30435367ad7dc36653969f043cb7c
AB  - Motivation: Computational protein sequence design has been widely applied in rational protein engineering and increasing the design accuracy and efficiency is highly desired. Results: Here, we present ProDESIGN-LE, an accurate and efficient approach to protein sequence design. ProDESIGN-LE adopts a concise but informative representation of the residue's local environment and trains a transformer to learn the correlation between local environment of residues and their amino acid types. For a target backbone structure, ProDESIGN-LE uses the transformer to assign an appropriate residue type for each position based on its local environment within this structure, eventually acquiring a designed sequence with all residues fitting well with their local environments. We applied ProDESIGN-LE to design sequences for 68 naturally occurring and 129 hallucinated proteins within 20 s per protein on average. The designed proteins have their predicted structures perfectly resembling the target structures with a state-of-the-art average TM-score exceeding 0.80. We further experimentally validated ProDESIGN-LE by designing five sequences for an enzyme, chloramphenicol O-acetyltransferase type III (CAT III), and recombinantly expressing the proteins in Escherichia coli. Of these proteins, three exhibited excellent solubility, and one yielded monomeric species with circular dichroism spectra consistent with the natural CAT III protein.  © 2023 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Häffner, S.
AU  - Hofer, M.
AU  - Nagl, M.
AU  - Walterskirchen, J.
TI  - Introducing an Interpretable Deep Learning Approach to Domain-Specific Dictionary Creation: A Use Case for Conflict Prediction
PY  - 2023
T2  - Political Analysis
VL  - 24
IS  - 1
DO  - 10.1017/pan.2023.7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151496504&doi=10.1017%2fpan.2023.7&partnerID=40&md5=9779a88597fa77ee93e63a430871e50b
AB  - Recent advancements in natural language processing (NLP) methods have significantly improved their performance. However, more complex NLP models are more difficult to interpret and computationally expensive. Therefore, we propose an approach to dictionary creation that carefully balances the trade-off between complexity and interpretability. This approach combines a deep neural network architecture with techniques to improve model explainability to automatically build a domain-specific dictionary. As an illustrative use case of our approach, we create an objective dictionary that can infer conflict intensity from text data. We train the neural networks on a corpus of conflict reports and match them with conflict event data. This corpus consists of over 14,000 expert-written International Crisis Group (ICG) CrisisWatch reports between 2003 and 2021. Sensitivity analysis is used to extract the weighted words from the neural network to build the dictionary. In order to evaluate our approach, we compare our results to state-of-the-art deep learning language models, text-scaling methods, as well as standard, nonspecialized, and conflict event dictionary approaches. We are able to show that our approach outperforms other approaches while retaining interpretability.  © The Author(s), 2023. Published by Cambridge University Press on behalf of the Society for Political Methodology.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Barbalau, A.
AU  - Ionescu, R.T.
AU  - Georgescu, M.-I.
AU  - Dueholm, J.
AU  - Ramachandra, B.
AU  - Nasrollahi, K.
AU  - Khan, F.S.
AU  - Moeslund, T.B.
AU  - Shah, M.
TI  - SSMTL++: Revisiting self-supervised multi-task learning for video anomaly detection
PY  - 2023
T2  - Computer Vision and Image Understanding
VL  - 229
C7  - 103656
DO  - 10.1016/j.cviu.2023.103656
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148330842&doi=10.1016%2fj.cviu.2023.103656&partnerID=40&md5=d4983d46090e4b329e14108869d66011
AB  - A self-supervised multi-task learning (SSMTL) framework for video anomaly detection was recently introduced in literature. Due to its highly accurate results, the method attracted the attention of many researchers. In this work, we revisit the self-supervised multi-task learning framework, proposing several updates to the original method. First, we study various detection methods, e.g. based on detecting high-motion regions using optical flow or background subtraction, since we believe the currently used pre-trained YOLOv3 is suboptimal, e.g. objects in motion or objects from unknown classes are never detected. Second, we modernize the 3D convolutional backbone by introducing multi-head self-attention modules, inspired by the recent success of vision transformers. As such, we alternatively introduce both 2D and 3D convolutional vision transformer (CvT) blocks. Third, in our attempt to further improve the model, we study additional self-supervised learning tasks, such as predicting segmentation maps through knowledge distillation, solving jigsaw puzzles, estimating body pose through knowledge distillation, predicting masked regions (inpainting), and adversarial learning with pseudo-anomalies. We conduct experiments to assess the performance impact of the introduced changes. Upon finding more promising configurations of the framework, dubbed SSMTL++v1 and SSMTL++v2, we extend our preliminary experiments to more data sets, demonstrating that our performance gains are consistent across all data sets. In most cases, our results on Avenue, ShanghaiTech and UBnormal raise the state-of-the-art performance bar to a new level. © 2023 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 48
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, R.
AU  - Wang, Z.
AU  - Wang, X.
AU  - Meng, Z.
AU  - Cui, W.
TI  - MHTAN-DTI: Metapath-based hierarchical transformer and attention network for drug–target interaction prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 2
C7  - bbad079
DO  - 10.1093/bib/bbad079
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150665991&doi=10.1093%2fbib%2fbbad079&partnerID=40&md5=0473fb126d6f5365b7adaac723d97be6
AB  - Drug–target interaction (DTI) prediction can identify novel ligands for specific protein targets, and facilitate the rapid screening of effective new drug candidates to speed up the drug discovery process. However, the current methods are not sensitive enough to complex topological structures, and complicated relations between multiple node types are not fully captured yet. To address the above challenges, we construct a metapath-based heterogeneous bioinformatics network, and then propose a DTI prediction method with metapath-based hierarchical transformer and attention network for drug–target interaction prediction (MHTAN-DTI), applying metapath instance-level transformer, single-semantic attention and multi-semantic attention to generate low-dimensional vector representations of drugs and proteins. Metapath instance-level transformer performs internal aggregation on the metapath instances, and models global context information to capture long-range dependencies. Single-semantic attention learns the semantics of a certain metapath type, introduces the central node weight and assigns different weights to different metapath instances to obtain the semantic-specific node embedding. Multi-semantic attention captures the importance of different metapath types and performs weighted fusion to attain the final node embedding. The hierarchical transformer and attention network weakens the inf luence of noise data on the DTI prediction results, and enhances the robustness and generalization ability of MHTAN-DTI. Compared with the state-of-the-art DTI prediction methods, MHTAN-DTI achieves significant performance improvements. In addition, we also conduct sufficient ablation studies and visualize the experimental results. All the results demonstrate that MHTAN-DTI can offer a powerful and interpretable tool for integrating heterogeneous information to predict DTIs and provide new insights into drug discovery. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ang, G.
AU  - Lim, E.-P.
TI  - Investment and Risk Management with Online News and Heterogeneous Networks
PY  - 2023
T2  - ACM Transactions on the Web
VL  - 17
IS  - 2
C7  - 8
DO  - 10.1145/3532858
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154609289&doi=10.1145%2f3532858&partnerID=40&md5=bb3e7f441ffeff826e0e044f8fe368df
AB  - Stock price movements in financial markets are influenced by large volumes of news from diverse sources on the web, e.g., online news outlets, blogs, social media. Extracting useful information from online news for financial tasks, e.g., forecasting stock returns or risks, is, however, challenging due to the low signal-to-noise ratios of such online information. Assessing the relevance of each news article to the price movements of individual stocks is also difficult, even for human experts. In this article, we propose the Guided Global-Local Attention-based Multimodal Heterogeneous Network (GLAM) model, which comprises novel attention-based mechanisms for multimodal sequential and graph encoding, a guided learning strategy, and a multitask training objective. GLAM uses multimodal information, heterogeneous relationships between companies and leverages significant local responses of individual stock prices to online news to extract useful information from diverse global online news relevant to individual stocks for multiple forecasting tasks. Our extensive experiments with multiple datasets show that GLAM outperforms other state-of-the-art models on multiple forecasting tasks and investment and risk management application case-studies.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cao, Q.
AU  - Ge, C.
AU  - Wang, X.
AU  - Harvey, P.J.
AU  - Zhang, Z.
AU  - Ma, Y.
AU  - Wang, X.
AU  - Jia, X.
AU  - Mobli, M.
AU  - Craik, D.J.
AU  - Jiang, T.
AU  - Yang, J.
AU  - Wei, Z.
AU  - Wang, Y.
AU  - Chang, S.
AU  - Yu, R.
TI  - Designing antimicrobial peptides using deep learning and molecular dynamic simulations
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 2
C7  - bbad058
DO  - 10.1093/bib/bbad058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150665646&doi=10.1093%2fbib%2fbbad058&partnerID=40&md5=d18ac51c20e56a12724b80544bcd0427
AB  - With the emergence of multidrug-resistant bacteria, antimicrobial peptides (AMPs) offer promising options for replacing traditional antibiotics to treat bacterial infections, but discovering and designing AMPs using traditional methods is a time-consuming and costly process. Deep learning has been applied to the de novo design of AMPs and address AMP classification with high efficiency. In this study, several natural language processing models were combined to design and identify AMPs, i.e. sequence generative adversarial nets, bidirectional encoder representations from transformers and multilayer perceptron. Then, six candidate AMPs were screened by AlphaFold2 structure prediction and molecular dynamic simulations. These peptides show low homology with known AMPs and belong to a novel class of AMPs. After initial bioactivity testing, one of the peptides, A-222, showed inhibition against gram-positive and gram-negative bacteria. The structural analysis of this novel peptide A-222 obtained by nuclear magnetic resonance confirmed the presence of an alpha-helix, which was consistent with the results predicted by AlphaFold2. We then performed a structure–activity relationship study to design a new series of peptide analogs and found that the activities of these analogs could be increased by 4–8-fold against Stenotrophomonas maltophilia WH 006 and Pseudomonas aeruginosa PAO1. Overall, deep learning shows great potential in accelerating the discovery of novel AMPs and holds promise as an important tool for developing novel AMPs. © The Author(s) 2023. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Gao, Z.
AU  - Zhang, D.
AU  - Hau, W.K.
AU  - Zhang, H.
TI  - Progressive Perception Learning for Main Coronary Segmentation in X-Ray Angiography
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 3
SP  - 864
EP  - 879
DO  - 10.1109/TMI.2022.3219126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141636143&doi=10.1109%2fTMI.2022.3219126&partnerID=40&md5=85de1aafbe3ab3f37e182e70ee86f401
AB  - Main coronary segmentation from the X-ray angiography images is important for the computer-aided diagnosis and treatment of coronary disease. However, it confronts the challenge at three different image granularities (the semantic, surrounding, and local levels). The challenge includes the semantic confusion between the main and collateral vessels, low contrast between the foreground vessel and background surroundings, and local ambiguity near the vessel boundaries. The traditional hand-crafted feature-based methods may be insufficient because they may lack the semantic relationship information and may not distinguish the main and collateral vessels. The existing deep learning-based methods seem to have issues due to the deficiency in the long-distance semantic relationship capture, the foreground and background interference adaptability, and the boundary detail information preservation. To solve the main coronary segmentation challenge, we propose the progressive perception learning (PPL) framework to inspect these three different image granularities. Specifically, the PPL contains the context, interference, and boundary perception modules. The context perception is designed to focus on the main coronary vessel based on the semantic dependence capture among different coronary segments. The interference perception is designed to purify the feature maps based on the foreground vessel enhancement and background artifact suppression. The boundary perception is designed to highlight the boundary details based on boundary feature extraction through the intersection between the foreground and background predictions. Extensive experiments on 1085 subjects show that the PPL is effective (e.g., the overall Dice is greater than 95%), and superior to thirteen state-of-the-art coronary segmentation methods.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ghosh, S.
AU  - Ekbal, A.
AU  - Bhattacharyya, P.
TI  - VAD-assisted multitask transformer framework for emotion recognition and intensity prediction on suicide notes
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 2
C7  - 103234
DO  - 10.1016/j.ipm.2022.103234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144423009&doi=10.1016%2fj.ipm.2022.103234&partnerID=40&md5=2a580bffaa875be66036df36629d7655
AB  - Detecting suicidal tendencies and preventing suicides is an important social goal. The rise and continuance of emotion, the emotion category, and the intensity of the emotion are important clues about suicidal tendencies. The three determinants of emotion, viz. Valence, Arousal, and Dominance (VAD) can help determine a person's exact emotion(s) and its intensity. This paper introduces an end-to-end VAD-assisted transformer-based multi-task network for detecting emotion (primary task) and its intensity (auxiliary task) in suicide notes. As part of this research, we expand the utility of the emotion-annotated benchmark dataset of suicide notes, CEASE-v2.0, by annotating all its sentences with emotion intensity labels. Empirical results show that our multi-task method performs better than the corresponding single-task systems, with the best attained overall Mean Recall (MR) of 65.25% on the emotion task. On a similar task, we improved MR by 8.78% over the existing state-of-the-art system. We evaluated our approach on three benchmark datasets for three different tasks. We observed that the introduced method consistently outperformed existing state-of-the-art approaches on the studied datasets, demonstrating its capacity to generalize to other downstream correlated tasks. We qualitatively examined our model's output by comparing it to the labeling of a psychiatrist. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Chen, M.
AU  - Zhang, L.
AU  - Feng, R.
AU  - Xue, X.
AU  - Feng, J.
TI  - Rethinking Local and Global Feature Representation for Dense Prediction
PY  - 2023
T2  - Pattern Recognition
VL  - 135
C7  - 109168
DO  - 10.1016/j.patcog.2022.109168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141925030&doi=10.1016%2fj.patcog.2022.109168&partnerID=40&md5=9aebbac7d8a114f0e0bc4f61ea3f8dbd
AB  - Although fully convolution networks (FCNs) have dominated dense prediction tasks (e.g., semantic segmentation, depth estimation and object detection) for decades, they are inherently limited in capturing long-range structured relationship with the layers of local kernels. While recent Transformer-based models have proven extremely successful in computer vision tasks by capturing global representation, they would deteriorate dense prediction results by over-smoothing the regions containing fine details (e.g., boundaries and small objects). To this end, we aim to provide an alternative perspective by rethinking local and global feature representation for the dense prediction task. Specifically, we deploy a Dual-Stream Convolution-Transformer architecture, called DSCT, by taking advantage of both the convolution and Transformer to learn a rich feature representation, combining with a task decoder to provide a powerful dense prediction model. DSCT extracts high resolution local feature representation from convolution layers and global feature representation from Transformer layers. With the local and global context modeled explicitly in every layer, the two streams can be combined with a decoder to perform task of semantic segmentation, monocular depth estimation or object detection. Extensive experiments show that DSCT can achieve superior performance on the three tasks above. For semantic segmentation, DSCT builds a new state of the art on Cityscapes validation set (83.31% mIoU) with only 80,000 training iterations and appealing performance (49.27% mIoU) on ADE20K validation set, outperforming most of the alternatives. For monocular depth estimation, our model achieves 2.423 RMSE on KITTI Eigen split, superior to most of the convolution or Transformer counterparts. For object detection, without using FPN, we can achieve 44.5% APb on COCO dataset when using Faster R-CNN, which is higher than Conformer. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, X.
AU  - Wang, J.
AU  - Zhao, Y.
AU  - Gao, Y.
TI  - Mix-ViT: Mixing attentive vision transformer for ultra-fine-grained visual categorization
PY  - 2023
T2  - Pattern Recognition
VL  - 135
C7  - 109131
DO  - 10.1016/j.patcog.2022.109131
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141303699&doi=10.1016%2fj.patcog.2022.109131&partnerID=40&md5=ac67cf1ee4ceb6f7f63da180b842c0f0
AB  - Ultra-fine-grained visual categorization (ultra-FGVC) moves down the taxonomy level to classify sub-granularity categories of fine-grained objects. This inevitably poses a challenge, i.e., classifying highly similar objects with limited samples, which impedes the performance of recent advanced vision transformer methods. To that end, this paper introduces Mix-ViT, a novel mixing attentive vision transformer to address the above challenge towards improved ultra-FGVC. The core design is a self-supervised module that mixes the high-level sample tokens and learns to predict whether a token has been substituted after attentively substituting tokens. This drives the model to understand the contextual discriminative details among inter-class samples. Via incorporating such a self-supervised module, the network gains more knowledge from the intrinsic structure of input data and thus improves generalization capability with limited training sample. The proposed Mix-ViT achieves competitive performance on seven publicly available datasets, demonstrating the potential of vision transformer compared to CNN for the first time in addressing the challenging ultra-FGVC tasks. The code is available at https://github.com/Markin-Wang/MixViT © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 45
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, W.
AU  - Xia, Z.
AU  - Dou, P.
AU  - Su, T.
AU  - Hu, H.
TI  - Aligning Image Semantics and Label Concepts for Image Multi-Label Classification
PY  - 2023
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
VL  - 19
IS  - 2
C7  - 75
DO  - 10.1145/3550278
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142726107&doi=10.1145%2f3550278&partnerID=40&md5=15d98c385ab948cede3d18f9e1f74154
AB  - Image multi-label classification task is mainly to correctly predict multiple object categories in the images. To capture the correlation between labels, graph convolution network based methods have to manually count the label co-occurrence probability from training data to construct a pre-defined graph as the input of graph network, which is inflexible and may degrade model generalizability. Moreover, most of the current methods cannot effectively align the learned salient object features with the label concepts, so that the predicted results of model may not be consistent with the image content. Therefore, how to learn the salient semantic features of images and capture the correlation between labels, and then effectively align them is one of the key to improve the performance of image multi-label classification task. To this end, we propose a novel image multi-label classification framework which aims to align Image Semantics with Label Concepts (ISLC). Specifically, we propose a residual encoder to learn salient object features in the images, and exploit the self-attention layer in aligned decoder to automatically capture the correlation between labels. Then, we leverage the cross-attention layers in aligned decoder to align image semantic features with label concepts, so as to make the labels predicted by model more consistent with image content. Finally, the output features of the last layer of residual encoder and aligned decoder are fused to obtain the final output feature for classification. The proposed ISLC model achieves good performance on various prevalent multi-label image datasets such as MS-COCO 2014, PASCAL VOC 2007, VG-500, and NUS-WIDE with 87.2%, 96.9%, 39.4%, and 64.2%, respectively.  © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ikhwantri, F.
AU  - Putra, J.W.G.
AU  - Yamada, H.
AU  - Tokunaga, T.
TI  - Looking deep in the eyes: Investigating interpretation methods for neural models on reading tasks using human eye-movement behaviour
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 2
C7  - 103195
DO  - 10.1016/j.ipm.2022.103195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143811456&doi=10.1016%2fj.ipm.2022.103195&partnerID=40&md5=5f46266e5d7ecce7c4c61f91416a14e4
AB  - This paper provides the first broad overview of the relation between different interpretation methods and human eye-movement behaviour across different tasks and architectures. The interpretation methods of neural networks provide the information the machine considers important, while the human eye-gaze has been believed to be a proxy of the human cognitive process. Thus, comparing them explains machine behaviour in terms of human behaviour, leading to improvement in machine performance through minimising their difference. We consider three types of natural language processing (NLP) tasks: sentiment analysis, relation classification and question answering, and four interpretation methods based on: simple gradient, integrated gradient, input-perturbation and attention, and three architectures: LSTM, CNN and Transformer. We leverage two corpora annotated with eye-gaze information: the Zuco dataset and the MQA-RC dataset. This research sets up two research questions. First, we investigate whether the saliency (importance) of input-words conform with those from human eye-gaze features. To this end, we compute a saliency distance (SD) between input words (by an interpretation method) and an eye-gaze feature. SD is defined as the KL-divergence between the saliency distribution over input words and an eye-gaze feature. We found that the SD scores vary depending on the combinations of tasks, interpretation methods and architectures. Second, we investigate whether the models with good saliency conformity to human eye-gaze behaviour have better prediction performances. To this end, we propose a novel evaluation device called “SD-performance curve” (SDPC) which represents the cumulative model performance against the SD scores. SDPC enables us to analyse the underlying phenomena that were overlooked using only the macroscopic metrics, such as average SD scores and rank correlations, that are typically used in the past studies. We observe that the impact of good saliency conformity between humans and machines on task performance varies among the combinations of tasks, interpretation methods and architectures. Our findings should be considered when introducing eye-gaze information for model training to improve the model performance. © 2022 The Authors
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Pal, A.
AU  - Pradhan, M.
TI  - Survey of fake news detection using machine intelligence approach
PY  - 2023
T2  - Data and Knowledge Engineering
VL  - 144
C7  - 102118
DO  - 10.1016/j.datak.2022.102118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143768723&doi=10.1016%2fj.datak.2022.102118&partnerID=40&md5=c7bcc4a927943069b6108a674a3a499c
AB  - With the extensive spreading of all information through digital platforms, it is of maximal importance that each people get to differentiate between them. Fake news is a vast problem in our society we cannot predict which news is fake or real without having knowledge or proof of that particular news. This has become a supreme problem, so we decided to create a solution to this problem. Thus, we built a small model which helps in detecting fake news, where we are dealing with some articles which have been collected from the internet. We have labeled each of them as either fake or true. We have trained our dataset using these articles and have used different machine learning algorithms like Passive Aggressive Classifier, Naïve Bayes, Logistic Regression, Decision Tree, Long short term memory (LSTM), and Bidirectional Encoder Representations from Transformers (BERT) to compare the results. Our experimental result has achieved 99.6% accuracy from Decision Tree algorithm and obtained 99.8% recall from LSTM for detection of fake news. Passive Aggressive Classifier performs excellent on a large data set. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jiang, X.
AU  - Yu, Z.
AU  - Hai, C.
AU  - Liu, H.
AU  - Wu, X.
AU  - Ward, T.
TI  - DNformer: Temporal Link Prediction with Transfer Learning in Dynamic Networks
PY  - 2023
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 17
IS  - 3
C7  - 3551892
DO  - 10.1145/3551892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152615977&doi=10.1145%2f3551892&partnerID=40&md5=930627c1f6ef52369dc968fe7811967a
AB  - Temporal link prediction (TLP) is among the most important graph learning tasks, capable of predicting dynamic, time-varying links within networks. The key problem of TLP is how to explore potential link-evolving tendency from the increasing number of links over time. There exist three major challenges toward solving this problem: temporal nonlinear sparsity, weak serial correlation, and discontinuous structural dynamics. In this article, we propose a novel transfer learning model, called DNformer, to predict temporal link sequence in dynamic networks. The structural dynamic evolution is sequenced into consecutive links one by one over time to inhibit temporal nonlinear sparsity. The self-attention of the model is used to capture the serial correlation between the input and output link sequences. Moreover, our structural encoding is designed to obtain changing structures from the consecutive links and to learn the mapping between link sequences. This structural encoding consists of two parts: the node clustering encoding of each link and the link similarity encoding between links. These encodings enable the model to perceive the importance and correlation of links. Furthermore, we introduce a measurement of structural similarity in the loss function for the structural differences of link sequences. The experimental results demonstrate that our model outperforms other state-of-the-art TLP methods such as Transformer, TGAT, and EvolveGCN. It achieves the three highest AUC and four highest precision scores in five different representative dynamic networks problems.  © 2023 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; FMS:B; 
LB  - Jiang2023DNformer
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Lin, Y.
AU  - Li, B.
AU  - Tan, S.
TI  - Learning Features of Intra-Consistency and Inter-Diversity: Keys Toward Generalizable Deepfake Detection
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 3
SP  - 1468
EP  - 1480
DO  - 10.1109/TCSVT.2022.3209336
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139497781&doi=10.1109%2fTCSVT.2022.3209336&partnerID=40&md5=ffaed2e291b7d6c5f7bb6ecf02fbe52b
AB  - Public concerns about deepfake face forgery are continually rising in recent years. Most deepfake detection approaches attempt to learn discriminative features between real and fake faces through end-to-end trained deep neural networks. However, the majorities of them suffer from the problem of poor generalization across different data sources, forgery methods, and/or post-processing operations. In this paper, following the simple but effective principle in discriminative representation learning, i.e., towards learning features of intra-consistency within classes and inter-diversity between classes, we leverage a novel transformer-based self-supervised learning method and an effective data augmentation strategy towards generalizable deepfake detection. Considering the differences between the real and fake images are often subtle and local, the proposed method firstly utilizes Self Prediction Learning (SPL) to learn rich hidden representations by predicting masked patches at a pre-training stage. Intra-class consistency clues in images can be mined without deepfake labels. After pre-training, the discrimination model is then fine-tuned via multi-task learning, including a deepfake classification task and a forgery mask estimation task. It is facilitated by our new data augmentation method called Adjustable Forgery Synthesizer (AFS), which can conveniently simulate the process of synthesizing deepfake images with various levels of visual reality in an explicit manner. AFS greatly prevents overfitting due to insufficient diversity in training data. Comprehensive experiments demonstrate that our method outperforms the state-of-the-art competitors on several popular benchmark datasets in terms of generalization to unseen forgery methods and untrained datasets.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 36
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Yang, J.
AU  - Chen, B.
AU  - Du, S.
TI  - Counting Varying Density Crowds Through Density Guided Adaptive Selection CNN and Transformer Estimation
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 3
SP  - 1055
EP  - 1068
DO  - 10.1109/TCSVT.2022.3208714
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139388904&doi=10.1109%2fTCSVT.2022.3208714&partnerID=40&md5=c07e0ada2aab34001aff383dcf4d3722
AB  - In real-world crowd counting applications, the crowd densities in an image vary greatly. When facing density variation, humans tend to locate and count the targets in low-density regions, and reason the number in high-density regions. We observe that CNN focus on the local information correlation using a fixed-size convolution kernel and the Transformer could effectively extract the semantic crowd information by using the global self-attention mechanism. Thus, CNN could locate and estimate crowds accurately in low-density regions, while it is hard to properly perceive the densities in high-density regions. On the contrary, Transformer has a high reliability in high-density regions, but fails to locate the targets in sparse regions. Neither CNN nor Transformer can well deal with this kind of density variation. To address this problem, we propose a CNN and Transformer Adaptive Selection Network (CTASNet) which can adaptively select the appropriate counting branch for different density regions. Firstly, CTASNet generates the prediction results of CNN and Transformer. Then, considering that CNN/Transformer is appropriate for low/high-density regions, a density guided adaptive selection module is designed to automatically combine the predictions of CNN and Transformer. Moreover, to reduce the influences of annotation noise, we introduce a Correntropy based optimal transport loss. Extensive experiments on four challenging crowd counting datasets have validated the proposed method.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zou, J.
AU  - Sun, A.
AU  - Long, C.
AU  - Aliannejadi, M.
AU  - Kanoulas, E.
TI  - Asking Clarifying Questions: To benefit or to disturb users in Web search?
PY  - 2023
T2  - Information Processing and Management
VL  - 60
IS  - 2
C7  - 103176
DO  - 10.1016/j.ipm.2022.103176
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142759494&doi=10.1016%2fj.ipm.2022.103176&partnerID=40&md5=237711c1baf14affd15b600e079d9b36
AB  - Modern information-seeking systems are becoming more interactive, mainly through asking Clarifying Questions (CQs) to refine users’ information needs. System-generated CQs may be of different qualities. However, the impact of asking multiple CQs of different qualities in a search session remains underexplored. Given the multi-turn nature of conversational information-seeking sessions, it is critical to understand and measure the impact of CQs of different qualities, when they are posed in various orders. In this paper, we conduct a user study on CQ quality trajectories, i.e., asking CQs of different qualities in chronological order. We aim to investigate to what extent the trajectory of CQs of different qualities affects user search behavior and satisfaction, on both query-level and session-level. Our user study is conducted with 89 participants as search engine users. Participants are asked to complete a set of Web search tasks. We find that the trajectory of CQs does affect the way users interact with Search Engine Result Pages (SERPs), e.g., a preceding high-quality CQ prompts the depth users to interact with SERPs, while a preceding low-quality CQ prevents such interaction. Our study also demonstrates that asking follow-up high-quality CQs improves the low search performance and user satisfaction caused by earlier low-quality CQs. In addition, only showing high-quality CQs while hiding other CQs receives better gains with less effort. That is, always showing all CQs may be risky and low-quality CQs do disturb users. Based on observations from our user study, we further propose a transformer-based model to predict which CQs to ask, to avoid disturbing users. In short, our study provides insights into the effects of trajectory of asking CQs, and our results will be helpful in designing more effective and enjoyable search clarification systems. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Guo, D.
AU  - Wu, E.Q.
AU  - Wu, Y.
AU  - Zhang, J.
AU  - Law, R.
AU  - Lin, Y.
TI  - FlightBERT: Binary Encoding Representation for Flight Trajectory Prediction
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 2
SP  - 1828
EP  - 1842
DO  - 10.1109/TITS.2022.3219923
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141552554&doi=10.1109%2fTITS.2022.3219923&partnerID=40&md5=7a60b102d715b0e1853d8ef64fb7949c
AB  - Flight Trajectory Prediction (TP) is an essential task in Air Traffic Control (ATC). Currently, the TP task is usually achieved by regression approaches, which concatenates several scalar attributes of the observation into a low-dimensional vector as the inputs. However, it is difficult to accurately model aircraft motion patterns using low-dimensional features in complex and time-varying ATC environments. To improve the performance of the TP task, in this paper, a novel framework, called FlightBERT, is proposed based on Binary Encoding (BE) representation, which enables us to tackle the TP task as a multi binary classification problem. Specifically, the scalar attributes of the flight trajectory are encoded into binary codes and transformed into a high-dimensional representation by the attribute embedding module. Considering the prior knowledge among flight attributes, an Attribute Correlation Attention (ACoAtt) block is designed to explicitly capture the correlations among the specific attributes. A stacked Transformer block is applied to serve as the backbone network, which is followed by the predictor to generate the outputs. Considering the nature of flight trajectory, a hybrid constrained loss, i.e., combining the mean square error loss with the binary cross-entropy loss, is innovatively designed to optimize the proposed framework. The proposed method is validated on a large-scale dataset, which is collected from the real-world ATC environment. The experimental results demonstrate that the proposed method outperforms other baselines by quantitative and qualitative evaluations. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; FMS:B; 
LB  - Guo2023FlightBERT
ER  -

TY  - JOUR
AU  - Jia, S.
AU  - Pei, X.
AU  - Yao, W.
AU  - Wong, S.C.
TI  - Self-Supervised Depth Estimation Leveraging Global Perception and Geometric Smoothness
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 2
SP  - 1502
EP  - 1517
DO  - 10.1109/TITS.2022.3219604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141633662&doi=10.1109%2fTITS.2022.3219604&partnerID=40&md5=090ae2892d4c4a1d69f8bcd4b3c9cca0
AB  - Self-supervised depth estimation has drawn much attention in recent years as it does not require labeled data but image sequences. Moreover, it can be conveniently used in various applications, such as autonomous driving, robotics, realistic navigation, and smart cities. However, extracting global contextual information from images and predicting a geometrically natural depth map remain challenging. In this paper, we present DLNet for pixel-wise depth estimation, which simultaneously extracts global and local features with the aid of our depth Linformer block. This block consists of the Linformer and innovative soft split multi-layer perceptron blocks. Moreover, a three-dimensional geometry smoothness loss is proposed to predict a geometrically natural depth map by imposing the second-order smoothness constraint on the predicted three-dimensional point clouds, thereby realizing improved performance as a byproduct. Finally, we explore the multi-scale prediction strategy and propose the maximum margin dual-scale prediction strategy for further performance improvement. In experiments on the KITTI and Make3D benchmarks, the proposed DLNet achieves performance competitive to those of the state-of-the-art methods, reducing time and space complexities by more than 62% and 56% at a resolution of 416 × 128 , respectively. Extensive testing on various real-world situations further demonstrates the strong practicality and generalization capability of the proposed model. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; FMS:B; 
LB  - Jia2023Self-Supervised
ER  -

TY  - JOUR
AU  - Xu, L.
AU  - Liu, H.
AU  - Song, J.
AU  - Li, R.
AU  - Hu, Y.
AU  - Zhou, X.
AU  - Patras, P.
TI  - TransMUSE: Transferable Traffic Prediction in MUlti-Service Edge Networks
PY  - 2023
T2  - Computer Networks
VL  - 221
C7  - 109518
DO  - 10.1016/j.comnet.2022.109518
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144053595&doi=10.1016%2fj.comnet.2022.109518&partnerID=40&md5=e80e94bdbf62626c9d1f1f41dc361478
AB  - The Covid-19 pandemic has forced the workforce to switch to working from home, which has put significant burdens on the management of broadband networks and called for intelligent service-by-service resource optimization at the network edge. In this context, network traffic prediction is crucial for operators to provide reliable connectivity across large geographic regions. Although recent advances in neural network design have demonstrated potential to effectively tackle forecasting, in this work we reveal based on real-world measurements that network traffic across different regions differs widely. As a result, models trained on historical traffic data observed in one region can hardly serve in making accurate predictions in other areas. Training bespoke models for different regions is tempting, but that approach bears significant measurement overhead, is computationally expensive, and does not scale. Therefore, in this paper we propose TransMUSE (Transferable Traffic Prediction in MUlti-Service Edge Networks), a novel deep learning framework that clusters similar services, groups edge-nodes into cohorts by traffic feature similarity, and employs a Transformer-based Multi-service Traffic Prediction Network (TMTPN), which can be directly transferred within a cohort without any customization. We demonstrate that TransMUSE exhibits imperceptible performance degradation in terms of mean absolute error (MAE) when forecasting traffic, compared with settings where a model is trained for each individual edge node. Moreover, our proposed TMTPN architecture outperforms the state-of-the-art, achieving up to 43.21% lower MAE in the multi-service traffic prediction task. To the best of our knowledge, this is the first work that jointly employs model transfer and multi-service traffic prediction to reduce measurement overhead, while providing fine-grained accurate demand forecasts for edge services provisioning. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hussain, Y.
AU  - Huang, Z.
AU  - Zhou, Y.
AU  - Wang, S.
TI  - Boosting source code suggestion with self-supervised Transformer Gated Highway
PY  - 2023
T2  - Journal of Systems and Software
VL  - 196
C7  - 111553
DO  - 10.1016/j.jss.2022.111553
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145576596&doi=10.1016%2fj.jss.2022.111553&partnerID=40&md5=d908580c7b4657222b2b768549937c97
AB  - Attention-based transformer language models have shown significant performance gains in various natural language tasks. In this work, we explore the impact of transformer language models on the task of source code suggestion. The core intention of this work is to boost the modeling performance for the source code suggestion task and to explore how the training procedures and model architectures impact modeling performance. Additionally, we propose a transformer-based self-supervised learning technique called Transformer Gated Highway that outperforms recurrent and transformer language models of comparable size. The proposed approach combines the Transformer language model with Gated Highway introducing a notion of recurrence. We compare the performance of the proposed approach with transformer-based BERT (CodeTran), RoBERTa (RoBERTaCode), GPT2 (TravTrans), CodeGen and recurrent neural language-based LSTM (CodeLSTM) models. Moreover, we have experimented with various architectural settings for the transformer models to evaluate their impact on modeling performance. The extensive evaluation of the presented approach exhibits better performance on two programming language datasets; Java and C#. Additionally, we have adopted the presented approach for the syntax error correction task to predict the correct syntax token to render its possible implications for other source code modeling tasks. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Li, R.
AU  - Ji, P.
AU  - Xu, Y.
AU  - Bhanu, B.
TI  - MonoIndoor++: Towards Better Practice of Self-Supervised Monocular Depth Estimation for Indoor Environments
PY  - 2023
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 33
IS  - 2
SP  - 830
EP  - 846
DO  - 10.1109/TCSVT.2022.3207105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139438591&doi=10.1109%2fTCSVT.2022.3207105&partnerID=40&md5=ee5fd039f2bd75a4f7e347d4e4f82178
AB  - Self-supervised monocular depth estimation has seen significant progress in recent years, especially in outdoor environments, i.e., autonomous driving scenes. However, depth prediction results are not satisfying in indoor scenes where most of the existing data are captured with hand-held devices. As compared to outdoor environments, estimating depth of monocular videos for indoor environments, using self-supervised methods, results in two additional challenges: (i) the depth range of indoor video sequences varies a lot across different frames, making it difficult for the depth network to induce consistent depth cues for training, whereas the maximum distance in outdoor scenes mostly stays the same as the camera usually sees the sky; (ii) the indoor sequences recorded with handheld devices often contain much more rotational motions, which cause difficulties for the pose network to predict accurate relative camera poses, while the motions of outdoor sequences are pre-dominantly translational, especially for street-scene driving datasets such as KITTI. In this work, we propose a novel framework-MonoIndoor++ by giving special considerations to those challenges and consolidating a set of good practices for improving the performance of self-supervised monocular depth estimation for indoor environments. First, a depth factorization module with transformer-based scale regression network is proposed to estimate a global depth scale factor explicitly, and the predicted scale factor can indicate the maximum depth values. Second, rather than using a single-stage pose estimation strategy as in previous methods, we propose to utilize a residual pose estimation module to estimate relative camera poses across consecutive frames iteratively. Third, to incorporate extensive coordinates guidance for our residual pose estimation module, we propose to perform coordinate convolutional encoding directly over the inputs to pose networks. The proposed method is validated on a variety of benchmark indoor datasets, i.e., EuRoC MAV, NYUv2, ScanNet and 7-Scenes, demonstrating the state-of-the-art performance. In addition, the effectiveness of each module is shown through a carefully conducted ablation study and the good generalization and universality of our trained model is also demonstrated, specifically on ScanNet and 7-Scenes datasets.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Z.
AU  - Yeung, W.
AU  - Gravel, N.
AU  - Salcedo, M.
AU  - Soleymani, S.
AU  - Li, S.
AU  - Kannan, N.
TI  - Phosformer: an explainable transformer model for protein kinase-specific phosphorylation predictions
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 2
C7  - btad046
DO  - 10.1093/bioinformatics/btad046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147458169&doi=10.1093%2fbioinformatics%2fbtad046&partnerID=40&md5=86869344d618300ae22ed431d9600c8b
AB  - Motivation: The human genome encodes over 500 distinct protein kinases which regulate nearly all cellular processes by the specific phosphorylation of protein substrates. While advances in mass spectrometry and proteomics studies have identified thousands of phosphorylation sites across species, information on the specific kinases that phosphorylate these sites is currently lacking for the vast majority of phosphosites. Recently, there has been a major focus on the development of computational models for predicting kinase–substrate associations. However, most current models only allow predictions on a subset of well-studied kinases. Furthermore, the utilization of hand-curated features and imbalances in training and testing datasets pose unique challenges in the development of accurate predictive models for kinase-specific phosphorylation prediction. Motivated by the recent development of universal protein language models which automatically generate context-aware features from primary sequence information, we sought to develop a unified framework for kinase-specific phosphosite prediction, allowing for greater investigative utility and enabling substrate predictions at the whole kinome level. Results: We present a deep learning model for kinase-specific phosphosite prediction, termed Phosformer, which predicts the probability of phosphorylation given an arbitrary pair of unaligned kinase and substrate peptide sequences. We demonstrate that Phosformer implicitly learns evolutionary and functional features during training, removing the need for feature curation and engineering. Further analyses reveal that Phosformer also learns substrate specificity motifs and is able to distinguish between functionally distinct kinase families. Benchmarks indicate that Phosformer exhibits significant improvements compared to the state-of-the-art models, while also presenting a more generalized, unified, and interpretable predictive framework. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kang, Y.
AU  - Elofsson, A.
AU  - Jiang, Y.
AU  - Huang, W.
AU  - Yu, M.
AU  - Li, Z.
TI  - AFTGAN: prediction of multi-type PPI based on attention free transformer and graph attention network
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 2
C7  - btad052
DO  - 10.1093/bioinformatics/btad052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147457539&doi=10.1093%2fbioinformatics%2fbtad052&partnerID=40&md5=3eda24b08fac35a013cfb414bba8e5f5
AB  - Motivation: Protein–protein interaction (PPI) networks and transcriptional regulatory networks are critical in regulating cells and their signaling. A thorough understanding of PPIs can provide more insights into cellular physiology at normal and disease states. Although numerous methods have been proposed to predict PPIs, it is still challenging for interaction prediction between unknown proteins. In this study, a novel neural network named AFTGAN was constructed to predict multi-type PPIs. Regarding feature input, ESM-1b embedding containing much biological information for proteins was added as a protein sequence feature besides amino acid co-occurrence similarity and one-hot coding. An ensemble network was also constructed based on a transformer encoder containing an AFT module (performing the weight operation on vital protein sequence feature information) and graph attention network (extracting the relational features of protein pairs) for the part of the network framework. Results: The experimental results showed that the Micro-F1 of the AFTGAN based on three partitioning schemes (BFS, DFS and the random mode) on the SHS27K and SHS148K datasets was 0.685, 0.711 and 0.867, as well as 0.745, 0.819 and 0.920, respectively, all higher than that of other popular methods. In addition, the experimental comparisons confirmed the performance superiority of the proposed model for predicting PPIs of unknown proteins on the STRING dataset. © The Author(s) 2023. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Chen, C.
AU  - Zhou, K.
AU  - Wang, Z.
AU  - Xiao, R.
TI  - Generative Consistency for Semi-Supervised Cerebrovascular Segmentation From TOF-MRA
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 2
SP  - 346
EP  - 353
DO  - 10.1109/TMI.2022.3184675
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133638862&doi=10.1109%2fTMI.2022.3184675&partnerID=40&md5=01b603c41ede525ab8356b90ba38a601
AB  - Cerebrovascular segmentation from Time-of-flight magnetic resonance angiography (TOF-MRA) is a critical step in computer-aided diagnosis. In recent years, deep learning models have proved its powerful feature extraction for cerebrovascular segmentation. However, they require many labeled datasets to implement effective driving, which are expensive and professional. In this paper, we propose a generative consistency for semi-supervised (GCS) model. Considering the rich information contained in the feature map, the GCS model utilizes the generation results to constrain the segmentation model. The generated data comes from labeled data, unlabeled data, and unlabeled data after perturbation, respectively. The GCS model also calculates the consistency of the perturbed data to improve the feature mining ability. Subsequently, we propose a new model as the backbone of the GSC model. It transfers TOF-MRA into graph space and establishes correlation using Transformer. We demonstrated the effectiveness of the proposed model on TOF-MRA representations, and tested the GCS model with state-of-the-art semi-supervised methods using the proposed model as backbone. The experiments prove the important role of the GCS model in cerebrovascular segmentation. Code is available at https://github.com/MontaEllis/SSL-For-Medical-Segmentation.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Liang, S.
AU  - Jiang, Y.
TI  - Path reliability-based graph attention networks
PY  - 2023
T2  - Neural Networks
VL  - 159
SP  - 153
EP  - 160
DO  - 10.1016/j.neunet.2022.11.021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146241161&doi=10.1016%2fj.neunet.2022.11.021&partnerID=40&md5=cf033cd4ab961dae9b62b681d45c5ebe
AB  - Self-attention mechanism has been successfully introduced in Graph Neural Networks (GNNs) for graph representation learning and achieved state-of-the-art performances in tasks such as node classification and node attacks. In most existing attention-based GNNs, attention score is only computed between two directly connected nodes with their representation at a single layer. However, this attention score computation method cannot account for its multi-hop neighbors, which supply graph structure information and have influence on many tasks such as link prediction, knowledge graph completion, and adversarial attack as well. In order to address this problem, in this paper, we propose Path Reliability-based Graph Attention Networks (PRGATs), a novel method to incorporate multi-hop neighboring context into attention score computation, enabling to capture longer-range dependencies and large-scale structural information within a single layer. Moreover, path reliability-based attention layer, a core layer of PRGATs, uses a resource-constrain allocation algorithm to compute the reliable path and its attention scores from neighboring nodes to non-neighboring nodes, increasing the receptive field for every message-passing layer. Experimental results on real-world datasets show that, as compared with baselines, our model outperforms existing methods up to 3% on standard node classification and 12% on graph universal adversarial attack. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bai, N.
AU  - Wang, X.
AU  - Han, R.
AU  - Wang, Q.
AU  - Liu, Z.
TI  - PAFormer: Anomaly Detection of Time Series With Parallel-Attention Transformer
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 14
DO  - 10.1109/TNNLS.2023.3337876
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180315391&doi=10.1109%2fTNNLS.2023.3337876&partnerID=40&md5=0d029d0a42a6a6f63588337375082b3b
AB  - Time-series anomaly detection is a critical task with significant impact as it serves a pivotal role in the field of data mining and quality management. Current anomaly detection methods are typically based on reconstruction or forecasting algorithms, as these methods have the capability to learn compressed data representations and model time dependencies. However, most methods rely on learning normal distribution patterns, which can be difficult to achieve in real-world engineering applications. Furthermore, real-world time-series data is highly imbalanced, with a severe lack of representative samples for anomalous data, which can lead to model learning failure. In this article, we propose a novel end-to-end unsupervised framework called the parallel-attention transformer (PAFormer), which discriminates anomalies by modeling both the global characteristics and local patterns of time series. Specifically, we construct parallel-attention (PA), which includes two core modules: the global enhanced representation module (GERM) and the local perception module (LPM). GERM consists of two pattern units and a normalization module, with attention weights that indicate the relationship of each data point to the whole series (global). Due to the rarity of anomalous points, they have strong associations with adjacent data points. LPM is composed of a learnable Laplace kernel function that learns the neighborhood relevancies through the distributional properties of the kernel function (local). We employ the PA to learn the global-local distributional differences for each data point, which enables us to discriminate anomalies. Finally, we propose a two-stage adversarial loss to optimize the model. We conduct experiments on five public benchmark datasets (real-world datasets) and one synthetic dataset. The results show that PAFormer outperforms state-of-the-art baselines. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Lou, J.
AU  - Liu, X.
AU  - Tan, H.
AU  - Whitaker, R.
AU  - Liu, H.
TI  - SSPNet: Predicting Visual Saliency Shifts
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 26
SP  - 4938
EP  - 4949
DO  - 10.1109/TMM.2023.3327886
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181559341&doi=10.1109%2fTMM.2023.3327886&partnerID=40&md5=f800c76fadccbec7ba4fcf3ccb3b8231
AB  - When images undergo quality degradation caused by editing, compression or transmission, their saliency tends to shift away from its original position. Saliency shifts indicate visual behaviour change and therefore contain vital information regarding perception of visual content and its distortions. Given a pristine image and its distorted format, we want to be able to detect saliency shifts induced by distortions. The resulting saliency shift map (SSM) can be used to identify the region and degree of visual distraction caused by distortions, and consequently to perceptually optimise image coding or enhancement algorithms. To this end, we first create a largest-of-its-kind eye-tracking database, comprising 60 pristine images and their associated 540 distorted formats viewed by 96 subjects. We then propose a computational model to predict the saliency shift map (SSM), utilising transformers and convolutional neural networks. Experimental results demonstrate that the proposed model is highly effective in detecting distortion-induced saliency shifts in natural images. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Le, Y.
AU  - Cao, D.
AU  - Lu, S.
AU  - Quan, Z.
AU  - Wang, M.
TI  - Graph Reasoning With Supervised Contrastive Learning for Legal Judgment Prediction
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 15
DO  - 10.1109/TNNLS.2023.3344634
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181560255&doi=10.1109%2fTNNLS.2023.3344634&partnerID=40&md5=870e3107babc8bd7f9b2e034d80c99b7
AB  - Given the fact descriptions of legal cases, the legal judgment prediction (LJP) problem aims to determine three judgment tasks of law articles, charges, and the term of penalty. Most existing studies have considered task dependencies while neglecting the prior dependencies of labels among different tasks. Therefore, how to make better use of the information on the relation dependencies among tasks and labels becomes a crucial issue. To this end, we transform the text classification problem into a node classification framework based on graph reasoning and supervised contrastive learning (SCL) techniques, named GraSCL. Specifically, we first design a graph reasoning network to model the potential dependency structures and facilitate relational learning under various graph topologies. Then, we introduce the SCL method for the LJP task to further leverage the label relation on the graph. To accommodate the node classification settings, we extend the traditional SCL method to novel variants for SCL at the node level, which allows the GraSCL framework to be trained efficiently even with small batches. Furthermore, to recognize the importance of hard negative samples in contrastive learning, we introduce a simple yet effective technique called online hard negative mining (OHNM) to enhance our SCL approach. This technique complements our SCL method and enables us to control the number and complexity of negative samples, leading to further improvements in the model&#x2019;s performance. Finally, extensive experiments are conducted on two well-known benchmarks, demonstrating the effectiveness and rationality of our proposed SCL approach as compared to the state-of-the-art competitors. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, M.
AU  - Xing, J.
AU  - Mei, J.
AU  - Liu, Y.
AU  - Jiang, Y.
TI  - ActionCLIP: Adapting Language-Image Pretrained Models for Video Action Recognition
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 13
DO  - 10.1109/TNNLS.2023.3331841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178063031&doi=10.1109%2fTNNLS.2023.3331841&partnerID=40&md5=29df9b3db5bf1ade9ec19af41963cc86
AB  - The canonical approach to video action recognition dictates a neural network model to do a classic and standard 1-of-N majority vote task. They are trained to predict a fixed set of predefined categories, limiting their transferability on new datasets with unseen concepts. In this article, we provide a new perspective on action recognition by attaching importance to the semantic information of label texts rather than simply mapping them into numbers. Specifically, we model this task as a video-text matching problem within a multimodal learning framework, which strengthens the video representation with more semantic language supervision and enables our model to do zero-shot action recognition without any further labeled data or parameters&#x2019; requirements. Moreover, to handle the deficiency of label texts and make use of tremendous web data, we propose a new paradigm based on this multimodal learning framework for action recognition, which we dub <italic>&#x201C;pre-train, adapt and fine-tune.&#x201D;</italic> This paradigm first learns powerful representations from pre-training on a large amount of web image-text or video-text data. Then, it makes the action recognition task to act more like pre-training problems via adaptation engineering. Finally, it is fine-tuned end-to-end on target datasets to obtain strong performance. We give an instantiation of the new paradigm, <italic>ActionCLIP</italic>, which not only has superior and flexible zero-shot/few-shot transfer ability but also reaches a top performance on general action recognition task, achieving 83.8% top-1 accuracy on Kinetics-400 with a ViT-B/16 as the backbone. Code is available at https://github.com/sallymmx/ActionCLIP.git. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhu, S.
AU  - Zheng, J.
AU  - Ma, Q.
TI  - MR-Transformer: Multiresolution Transformer for Multivariate Time Series Prediction
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 13
DO  - 10.1109/TNNLS.2023.3327416
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177047379&doi=10.1109%2fTNNLS.2023.3327416&partnerID=40&md5=679037ccab82e2d0c3eb2a6c51333145
AB  - Multivariate time series (MTS) prediction has been studied broadly, which is widely applied in real-world applications. Recently, transformer-based methods have shown the potential in this task for their strong sequence modeling ability. Despite progress, these methods pay little attention to extracting short-term information in the context, while short-term patterns play an essential role in reflecting local temporal dynamics. Moreover, we argue that there are both consistent and specific characteristics among multiple variables, which should be fully considered for MTS modeling. To this end, we propose a multiresolution transformer (MR-Transformer) for MTS prediction, modeling MTS from both the temporal and the variable resolution. Specifically, for the temporal resolution, we design a long short-term transformer. We first split the sequence into nonoverlapping segments in an adaptive way and then extract short-term patterns within segments, while long-term patterns are captured by the inherent attention mechanism. Both of them are aggregated together to capture the temporal dependencies. For the variable resolution, besides the variable-consistent features learned by long short-term transformer, we also design a temporal convolution module to capture the specific features of each variable individually. MR-Transformer enhances the MTS modeling ability by combining multiresolution features between both time steps and variables. Extensive experiments conducted on real-world time series datasets show that MR-Transformer significantly outperforms the state-of-the-art MTS prediction models. The visualization analysis also demonstrates the effectiveness of the proposed model. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ding, W.
AU  - Geng, Y.
AU  - Huang, J.
AU  - Ju, H.
AU  - Wang, H.
AU  - Lin, C.
TI  - MGRW-Transformer: Multigranularity Random Walk Transformer Model for Interpretable Learning
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 15
DO  - 10.1109/TNNLS.2023.3326283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177091804&doi=10.1109%2fTNNLS.2023.3326283&partnerID=40&md5=d7cae72b44626f2c2cacad3cf2c1efaf
AB  - Deep-learning models have been widely used in image recognition tasks due to their strong feature-learning ability. However, most of the current deep-learning models are &#x201C;black box&#x201D; systems that lack a semantic explanation of how they reached their conclusions. This makes it difficult to apply these methods to complex medical image recognition tasks. The vision transformer (ViT) model is the most commonly used deep-learning model with a self-attention mechanism that shows the region of influence as compared to traditional convolutional networks. Thus, ViT offers greater interpretability. However, medical images often contain lesions of variable size in different locations, which makes it difficult for a deep-learning model with a self-attention module to reach correct and explainable conclusions. We propose a multigranularity random walk transformer (MGRW-Transformer) model guided by an attention mechanism to find the regions that influence the recognition task. Our method divides the image into multiple subimage blocks and transfers them to the ViT module for classification. Simultaneously, the attention matrix output from the multiattention layer is fused with the multigranularity random walk module. Within the multigranularity random walk module, the segmented image blocks are used as nodes to construct an undirected graph using the attention node as a starting node and guiding the coarse-grained random walk. We appropriately divide the coarse blocks into finer ones to manage the computational cost and combine the results based on the importance of the discovered features. The result is that the model offers a semantic interpretation of the input image, a visualization of the interpretation, and insight into how the decision was reached. Experimental results show that our method improves classification performance with medical images while presenting an understandable interpretation for use by medical professionals. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ren, L.
AU  - Wang, H.
AU  - Huang, G.
TI  - DLformer: A Dynamic Length Transformer-Based Network for Efficient Feature Representation in Remaining Useful Life Prediction
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
IS  - 99
DO  - 10.1109/TNNLS.2023.3257038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190427527&doi=10.1109%2fTNNLS.2023.3257038&partnerID=40&md5=c56c34a087c993059b7ab40751afffc6
AB  - Representation learning-based remaining useful life (RUL) prediction plays a crucial role in improving the security and reducing the maintenance cost of complex systems. Despite the superior performance, the high computational cost of deep networks hinders deploying the models on low-compute platforms. A significant reason for the high cost is the computation of representing long sequences. In contrast to most RUL prediction methods that learn features of the same sequence length, we consider that each time series has its characteristics and the sequence length should be adjusted adaptively. Our motivation is that an "easy" sample with representative characteristics can be correctly predicted even when short feature representation is provided, while "hard" samples need complete feature representation. Therefore, we focus on sequence length and propose a dynamic length transformer (DLformer) that can adaptively learn sequence representation of different lengths. Then, a feature reuse mechanism is developed to utilize previously learned features to reduce redundant computation. Finally, in order to achieve dynamic feature representation, a particular confidence strategy is designed to calculate the confidence level for the prediction results. Regarding interpretability, the dynamic architecture can help human understand which part of the model is activated. Experiments on multiple datasets show that DLformer can increase up to 90% inference speed, with less than 5% degradation in model accuracy. © 2023 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qiang, X.
AU  - He, W.
AU  - Chen, S.
AU  - Lv, Q.
AU  - Huang, F.
TI  - Hierarchical Point Cloud Transformer: A Unified Vegetation Semantic Segmentation Model for Multisource Point Clouds Based on Deep Learning
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 4411816
SP  - 1
EP  - 16
DO  - 10.1109/TGRS.2023.3336651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178037630&doi=10.1109%2fTGRS.2023.3336651&partnerID=40&md5=5cda1c5d4ad5e4b06a8d8bc8338ec6f8
AB  - The semantic segmentation of vegetation point clouds has very important application value in the field of geosciences. It can distinguish vegetation regions from other regions, further classify and analyze the vegetation, and help us better understand the distribution and characteristics of vegetation to protect and manage natural resources. The PointNet and PointNet++ models use maximum pooling as the aggregation function, allowing the deep neural networks to classify unordered point clouds directly with high classification accuracy. However, their ability to extract spatial correlations and local features from point clouds is insufficient, which restricts the improvement of point cloud semantic segmentation accuracy and results in the poor processing of vegetation point clouds. To resolve this problem, this research designs the novel hierarchical point cloud transformer (HPCT) model, suitable for the semantic segmentation of multisource vegetation point clouds. Combined with deep learning techniques, different levels of features are processed hierarchically based on a hierarchical structure, and a transformer module is combined in the feature extraction part, so as to obtain a larger receptive field and stronger semantic feature extraction capability. At the same time, we also propose a unified spatial scale sampling method for heterogeneous point cloud data input, which can be used not only for training and predicting the independent HPCT models with a single source of data, but also for training and predicting a unified HPCT model with multisource data. Semantic segmentation experiments are carried out on self-collected three-source datasets. The results show that the semantic segmentation performance of evaluation indicators (such as Recall, Pre, IoU, and OA) of the proposed HPCT model under the independent training and unified training on the three-source data exceed those of the PointNet, PointNet++, and PCT models, and even exceed some newly emerging models, such as PontCNN and DGCNN. The unified HPCT model has better segmentation performance than the independent HPCT model, with average Recall, Pre, IoU, and OA indicators increasing by 1.07%, 1.73%, 4.33%, and 1.03%, respectively. We attribute this superior accuracy to the unified training with the three-source data. The average Recall, Pre, IoU, and OA indicators of the unified HPCT model for the entire three-source dataset exceed 96%, 98%, 95%, and 98%, respectively.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wilson, M.
AU  - Petty, J.
AU  - Frank, R.
TI  - How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure
PY  - 2023
T2  - Transactions of the Association for Computational Linguistics
VL  - 11
SP  - 1377
EP  - 1395
DO  - 10.1162/tacl_a_00608
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180688611&doi=10.1162%2ftacl_a_00608&partnerID=40&md5=0518804d9e10009f3e37d1c94b7c5373
AB  - Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive. © 2023, MIT Press Journals. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Deng, K.
AU  - Zhang, D.
AU  - Liu, Y.
AU  - Leng, H.
AU  - Yin, F.
AU  - Ren, K.
AU  - Song, J.
TI  - LPT-QPN: A Lightweight Physics-Informed Transformer for Quantitative Precipitation Nowcasting
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 4107119
SP  - 1
EP  - 19
DO  - 10.1109/TGRS.2023.3328945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177056338&doi=10.1109%2fTGRS.2023.3328945&partnerID=40&md5=e41b510116511d16c46ab395b7bc6c4a
AB  - Quantitative precipitation nowcasting (QPN) is a highly challenging task in weather forecasting. The ability to provide precise, immediate, and detailed QPN products is necessary for a variety of situations, including storm warnings, air travel, and large gatherings. To address this challenge, this article proposes a new transformer lightweight physics-informed transformer (LPT)-QPN for QPN tasks, utilizing vertical cumulative liquid water content (VIL) products. This model adopts novel transformer modules to model the long-term evolution of precipitation and incorporates multihead squared attention (MHSA) to model its highly nonlinear relationships while reducing computational complexity. The results of experimental evaluations demonstrate the superiority of LPT-QPN when compared to existing state-of-the-art QPN models. In particular, the LPT-QPN model demonstrates greater accuracy for long lead time and in high-intensity areas, confirmed in both quantitative and qualitative evaluations. In addition, through three customized fine-tuning schemes, we are able to further improve the predictability of the LPT-QPN model for specific precipitation events. By incorporating the physical constraints of the convection-diffusion equation, our approach offers novel perspectives for future explorations that combine physical prior knowledge and deep-learning (DL) techniques. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, S.
AU  - Zhai, D.
AU  - Guan, Y.
AU  - Xia, Y.
TI  - Category-Level 6-D Object Pose Estimation With Shape Deformation for Robotic Grasp Detection
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
SP  - 1
EP  - 15
DO  - 10.1109/TNNLS.2023.3330011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177080921&doi=10.1109%2fTNNLS.2023.3330011&partnerID=40&md5=ba35d788d9024b844b37dc973bcb49b5
AB  - Category-level 6-D object pose estimation plays a crucial role in achieving reliable robotic grasp detection. However, the disparity between synthetic and real datasets hinders the direct transfer of models trained on synthetic data to real-world scenarios, leading to ineffective results. Additionally, creating large-scale real datasets is a time-consuming and labor-intensive task. To overcome these challenges, we propose CatDeform, a novel category-level object pose estimation network trained on synthetic data but capable of delivering good performance on real datasets. In our approach, we introduce a transformer-based fusion module that enables the network to leverage multiple sources of information and enhance prediction accuracy through feature fusion. To ensure proper deformation of the prior point cloud to align with scene objects, we propose a transformer-based attention module that deforms the prior point cloud from both geometric and feature perspectives. Building upon CatDeform, we design a two-branch network for supervised learning, bridging the gap between synthetic and real datasets and achieving high-precision pose estimation in real-world scenes using predominantly synthetic data supplemented with a small amount of real data. To minimize reliance on large-scale real datasets, we train the network in a self-supervised manner by estimating object poses in real scenes based on the synthetic dataset without manual annotation. We conduct training and testing on CAMERA25 and REAL275 datasets, and our experimental results demonstrate that the proposed method outperforms state-of-the-art (SOTA) techniques in both self-supervised and supervised training paradigms. Finally, we apply CatDeform to object pose estimation and robotic grasp experiments in real-world scenarios, showcasing a higher grasp success rate. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Chen, H.
AU  - Wu, J.
AU  - Li, J.
AU  - Jing, N.
TI  - SegMind: Semisupervised Remote Sensing Image Semantic Segmentation With Masked Image Modeling and Contrastive Learning Method
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 4408917
DO  - 10.1109/TGRS.2023.3321041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174846984&doi=10.1109%2fTGRS.2023.3321041&partnerID=40&md5=ae5571fbd33318f3bf60dfd9fa42d500
AB  - Remote sensing (RS) image semantic segmentation has attracted much attention due to its wide applications. However, deep learning-based RS image semantic segmentation methods usually require substantial manual pixelwise annotations, which are expensive and hard to obtain in practice. Although the existing semisupervised RS semantic segmentation methods effectively reduce dependence on labeled data, they generally focus on information consistency between labeled and unlabeled images, but ignore the potential context information between different areas of the RS image. In fact, the objects contained in an RS image usually have some long-range dependence between each other, since trees are usually on both sides of a road, and the middle of two rows of houses is commonly a road. Therefore, we believe that the potential dependencies between different areas of the RS image should be beneficial to reduce the label dependence of RS semantic segmentation. Based on this point, we propose a novel semisupervised RS image semantic segmentation network named SegMind, which is based on mean-teacher (MT) architecture and adopts masked image modeling (MIM) to enhance information interactions of different areas. Moreover, contrastive learning (CL) and entropy loss are introduced to SegMind framework to further improve the linear separability and prediction confidence of the proposed model. Experiments on three datasets have demonstrated the superiority of the proposed method over the state-of-the-art methods. The code is available at https://github.com/lzh-ggs-ddu/SegMind.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jiang, B.
AU  - Wang, Z.
AU  - Wang, X.
AU  - Zhang, Z.
AU  - Chen, L.
AU  - Wang, X.
AU  - Luo, B.
TI  - VcT: Visual Change Transformer for Remote Sensing Image Change Detection
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 2005214
DO  - 10.1109/TGRS.2023.3327139
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176327383&doi=10.1109%2fTGRS.2023.3327139&partnerID=40&md5=7167a712f905f79b309c9fd4d40fcd88
AB  - Given two remote sensing images, the goal of visual change detection task is to detect significantly changed areas between them. Existing visual change detectors usually adopt convolutional neural networks (CNNs) or transformers for feature representation learning and focus on learning effective representation for the changed regions between images. Although good performance can be obtained by enhancing the features of the change regions, however, these works are still limited mainly due to the ignorance of mining the unchanged background context information. It is known that one main challenge for change detection is how to obtain the consistent representations for two images involving different variations, such as spatial variation and sunlight intensity. In this work, we demonstrate that carefully mining the common background information provides an important cue to learn the consistent representations for the two images which thus obviously facilitates the visual change detection problem. Based on this observation, we propose a novel visual change transformer (VcT) model for visual change detection problem. To be specific, a shared backbone network is first used to extract the feature maps for the given image pair. Then, each pixel of feature map is regarded as a graph node and the graph neural network (GNN) is proposed to model the structured information for coarse change map prediction. Top- K reliable tokens can be mined from the map and refined by using the clustering algorithm. Then, these reliable tokens are enhanced by first utilizing self/cross-attention (CA) schemes and then interacting with original features via an anchor-primary attention (APA) learning module. Finally, the prediction head is proposed to get a more accurate change map. Extensive experiments on multiple benchmark datasets validated the effectiveness of our proposed VcT model. The source code and pre-trained models are available at https://github.com/Event-AHU/VcT-Remote-Sensing-Change-Detection.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Qin, H.
AU  - Xie, W.
TI  - HTDFormer: Hyperspectral Target Detection Based on Transformer With Distributed Learning
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5524715
DO  - 10.1109/TGRS.2023.3317033
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174504943&doi=10.1109%2fTGRS.2023.3317033&partnerID=40&md5=7cffd6f9f4eb07e9bc8f150f7944099e
AB  - In recent years, many hyperspectral target detection (HTD) methods based on advanced techniques have been proposed and achieved good results. However, the large amount of data produced by satellites and airborne remote sensing instruments has posed new challenges for efficient target detection of massive hyperspectral images (HSIs). In this article, we propose a new weakly supervised HTD framework based on a transformer with distributed learning (HTDFormer), which capitalizes on the parallel processing capabilities of multiple workers to efficiently handle large-scale HSIs. Specifically, the HTDFormer framework effectively integrates both spectral and spatial features within a unified optimization procedure via the transformer mechanism. A flexible sample augmentation approach is proposed to overcome the limitations of inadequate well-labeled training instances and meet the requirements of the transformer. To facilitate model training, we introduce the concept of distributed deep learning (DDL) into HTDFormer by leveraging a ring all-reduce (RAR) decentralized architecture, which embeds distributed learning into an HTD framework for the first time. Furthermore, the large-batch training strategy and the gradient compression strategy are used to enable large-scale distributed processing and reduce communication costs, respectively. Finally, an exponentially constrained nonlinear function is adopted to acquire pixel-level prediction via spectral-spatial fusion. Experimental results demonstrate that the proposed framework achieves promising performance with regard to the increasing scale of real HSIs.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Xia, J.
AU  - Liu, Z.
AU  - Lei, G.
AU  - Lee, K.
AU  - Ning, F.
TI  - Missing Sonic Logs Generation for Gas Hydrate-Bearing Sediments via Hybrid Networks Combining Deep Learning With Rock Physics Modeling
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5921915
SP  - 1
EP  - 15
DO  - 10.1109/TGRS.2023.3330869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177036260&doi=10.1109%2fTGRS.2023.3330869&partnerID=40&md5=cf096e78a20dc4aa6430421f379bdf5d
AB  - Logging-while-drilling (LWD) sonic data are critical for marine gas hydrate reservoir evaluation and production prediction. However, acquiring complete acoustic logs, particularly shear wave, poses significant challenges and incurs high costs. To tackle this issue, we develop a two-branch hybrid framework for predicting LWD sonic logs of hydrate-bearing sediments from existing logging data. One branch based on a rock physics model is utilized to generate background (no-hydrate/no-gas) elastic wave velocity profiles, while the other deep learning branch (DLB) compensates for the residuals between actual observations and the outputs of the first branch. The state-of-the-art Transformer encoder block is employed in the DLB to extract potentially intricate patterns within logging sequences. Such a scientific knowledge-guided network architecture with additional physics-based feature construction provides an explainable process that improves the physical consistency of predictions. Our method is tested with two publicly available datasets from the Cascadia continental margin. The hybrid model greatly enhances the predictive accuracy of the physical process model (with a minimum mean absolute percentage error of 0.73% and 4.33% for P- and S-wave velocities, respectively) and demonstrates outstanding generalization performance compared to pure data-driven approaches. The well-trained model offers impressive extrapolation beyond observed conditions for unmeasured high hydrate saturation (>40%) intervals in the region.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Zhang, H.
AU  - Chen, K.
AU  - Zhou, C.
AU  - Chen, S.
AU  - Zou, Z.
AU  - Shi, Z.
TI  - Continuous Cross-Resolution Remote Sensing Image Change Detection
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5623320
DO  - 10.1109/TGRS.2023.3325829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174855534&doi=10.1109%2fTGRS.2023.3325829&partnerID=40&md5=ce3391c3c7758e5cc8dfd98458fbacdc
AB  - Most contemporary supervised remote sensing (RS) image change detection (CD) approaches are customized for equal-resolution bitemporal images. Real-world applications raise the need for cross-resolution CD, a.k.a., CD based on bitemporal images with different spatial resolutions. Given training samples of a fixed bitemporal resolution difference (ratio) between the high-resolution (HR) image and the low-resolution (LR) one, current cross-resolution methods may fit a certain ratio but lack adaptation to other resolution differences. Toward continuous cross-resolution CD, we propose scale-invariant learning to enforce the model consistently predicting HR results given synthesized samples of varying resolution differences. Concretely, we synthesize blurred versions of the HR image by random downsampled reconstructions to reduce the gap between HR and LR images. We introduce coordinate-based representations to decode per-pixel predictions by feeding the coordinate query and corresponding multilevel embedding features into an MLP that implicitly learns the shape of land cover changes, therefore benefiting recognizing blurred objects in the LR image. Moreover, considering that spatial resolution mainly affects the local textures, we apply local-window self-attention to align bitemporal features during the early stages of the encoder. Extensive experiments on two synthesized and one real-world different-resolution CD datasets verify the effectiveness of the proposed method. Our method significantly outperforms several vanilla CD methods and two cross-resolution CD methods on the three datasets both in in-distribution and out-of-distribution settings. The empirical results suggest that our method could yield relatively consistent HR change predictions regardless of varying bitemporal resolution ratios. Our code will be public.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yao, H.
AU  - Chen, R.
AU  - Chen, W.
AU  - Sun, H.
AU  - Xie, W.
AU  - Lu, X.
TI  - Pseudolabel-Based Unreliable Sample Learning for Semi-Supervised Hyperspectral Image Classification
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5527116
DO  - 10.1109/TGRS.2023.3322558
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174822287&doi=10.1109%2fTGRS.2023.3322558&partnerID=40&md5=71e9efe63f6d870e24749bfc857afa6a
AB  - Recently, pseudolabel-based deep learning methods have shown excellent performance in semi-supervised hyperspectral image (HSI) classification. These methods usually select high-confidence unlabeled samples to help optimize backbone classification networks. However, a large number of remaining low-confidence unlabeled samples, which contain rich land-covers information, are underused. In this article, we propose a pseudolabel-based unreliable sample learning (PUSL) method to fully exploit low-confidence unlabeled samples for semi-supervised HSI classification. First, to avoid overfitting the spatial distribution of labeled samples, we build a position-free transformer (PFT) as the backbone classification network. Second, PFT is initially trained with labeled samples in a supervised learning manner to obtain an initial classifier, which is then used to split unlabeled samples into reliable and unreliable unlabeled samples based on the predicted confidence. Third, reliable unlabeled samples participate in training along with labeled samples. Finally, unreliable unlabeled samples are treated as negative samples for the corresponding categories to improve the discrimination of PFT in a contrastive learning paradigm. Extensive experiments on three HSI datasets demonstrate that PUSL outperforms the compared methods.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Alkhalifah, T.
AU  - Huang, J.
AU  - Li, Z.
TI  - Self-Supervised Pretraining Vision Transformer With Masked Autoencoders for Building Subsurface Model
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 4506610
DO  - 10.1109/TGRS.2023.3308999
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169669060&doi=10.1109%2fTGRS.2023.3308999&partnerID=40&md5=e6d8a2882b6e6ba56156d5a2f15f0600
AB  - Building subsurface models is a very important but challenging task in hydrocarbon exploration and development. The subsurface elastic properties are usually sourced from seismic data and well logs. Thus, we design a deep learning (DL) framework using vision transformer (ViT) as the backbone architecture to build the subsurface model using well log information as we apply full waveform inversion (FWI) on the seismic data. However, training a ViT network from scratch with limited well log data can be difficult to achieve good generalization. To overcome this, we implement an efficient self-supervised pretraining process using a masked autoencoder (MAE) architecture to learn important feature representations in seismic volumes. The seismic volumes required by the pretraining are randomly extracted from a seismic inversion, such as an FWI result. We can also incorporate reverse time migration (RTM) image into the seismic volumes to provide additional structure information. The pretraining task of MAE is to reconstruct the original image from the masked image with a masking ratio of 75%. This pretraining task enables the network to learn the high-level latent representations. After the pretraining process, we then fine-tune the ViT network to build the optimal mapping relationship between 2-D seismic volumes and 1-D well segments. Once the fine-tuning process is finished, we apply the trained ViT network to the whole seismic inversion domain to predict the subsurface model. At last, we use one synthetic dataset and two field datasets to test the performance of the proposed method. The test results demonstrate that the proposed method effectively integrates seismic and well information to improve the resolution and accuracy of the velocity model.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, N.
AU  - Li, Z.
AU  - Liu, R.
AU  - Zhang, H.
AU  - Gao, J.
AU  - Wei, T.
AU  - Si, J.
AU  - Wu, H.
TI  - ASHFormer: Axial and Sliding Window-Based Attention with High-Resolution Transformer for Automatic Stratigraphic Correlation
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5913910
DO  - 10.1109/TGRS.2023.3296934
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165254240&doi=10.1109%2fTGRS.2023.3296934&partnerID=40&md5=331facf977b8fb92ee13543115c3921d
AB  - The stratigraphic correlation of well logs is crucial for characterizing subsurface reservoirs. However, due to the complexity of well logs and the huge amount of well data, manual correlation is time- and resource-intensive. Hence, various computerized stratigraphic correlation methods have been developed, especially regarding convolutional neural networks (CNNs). Recently, transformer, a self-attention system that evolved from the natural language processing (NLP), has attained state-of-the-art (SOTA) performance over CNNs in a variety of domains because of its ability to perceive global features. We propose the axial and sliding window-based attention with high-resolution transformer (ASHFormer), combining the high-resolution network (HRNet) with an axial and sliding window self-attention block (ASBlock) intended for stratigraphic correlation of well logs. ASBlock includes three different forms of multihead self-attentions (MHSAs), including sliding-window attention, horizontal-axis attention, and vertical-axis attention, therefore, it is possible to retrieve well logs' long-range and local information. The experiments show that ASHFormer predicts more accurate stratigraphic correlation results than HRNet and CNNs meet transformer (CMT) (a transformer combining CNN and self-attention). The usefulness of the transformer for well log feature extraction and automatic stratigraphic correlation is demonstrated by ASHFormer's 9.74% improvement in correlation accuracy over HRNet with the same architecture. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qi, C.
AU  - Yin, J.
AU  - Niu, Y.
AU  - Xu, J.
TI  - Neighborhood Spatial Aggregation MC Dropout for Efficient Uncertainty-Aware Semantic Segmentation in Point Clouds
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5704016
DO  - 10.1109/TGRS.2023.3314130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171525657&doi=10.1109%2fTGRS.2023.3314130&partnerID=40&md5=2f49047045bccaa47219213d950ed3a5
AB  - Uncertainty-aware semantic segmentation of the point clouds includes predictive uncertainty estimation and uncertainty-guided model optimization. One key challenge in the task is the efficiency of pointwise predictive distribution establishment. The widely used Monte Carlo (MC) dropout establishes the distribution by computing the standard deviation of samples using multiple stochastic forward propagations, which is time-consuming for tasks based on point clouds containing massive points. Hence, a framework embedded with neighborhood spatial aggregation (NSA)-MC dropout, a variant of MC dropout, is proposed to establish distributions in just one forward pass. Specifically, our method uses the one-time stochastic inference of a point with neighbors to approximate the point's repeated stochastic inferences, outputting pointwise distribution via the prediction variance of neighbors. Based on this, uncertainties acquire from the predictive distribution. The aleatoric uncertainty is integrated into the loss function to suppress noise, preventing the model from overfitting. Besides, the predictive uncertainty quantifies the prediction confidence. Experiments show that our plug-and-play NSA-MC dropout significantly improves the segmentation performance of backbones, ranging from multilayer perceptron (MLP)-, convolution-, and attention-based to transformer-based networks, without introducing additional parameters. Besides, it is several times faster than MC dropout to quantify the results' credibility, and the inference time does not establish a coupling relation with the sampling times.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hu, Z.
AU  - Gao, K.
AU  - Zhang, X.
AU  - Wang, J.
AU  - Wang, H.
AU  - Yang, Z.
AU  - Li, C.
AU  - Li, W.
TI  - EMO2-DETR: Efficient-Matching Oriented Object Detection With Transformers
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5616814
DO  - 10.1109/TGRS.2023.3300154
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166761099&doi=10.1109%2fTGRS.2023.3300154&partnerID=40&md5=04cd857c6e8d928d4f3ba0f117555b24
AB  - Object detection in remote sensing is a challenging task due to the arbitrary orientations of objects and the vast variation in the number of objects within a single image. For instance, one image may contain hundreds of small vehicles, while another may only have a single football field. Recently, DEtection TRansformer (DETR) and its variants have achieved great success in object detection by setting a fixed number of object queries and using bipartite graph matching for one-to-one label assignment. However, we have observed that bipartite graph matching can result in relative redundancy of object queries when the number of objects changes dramatically in an image. This relative redundancy can cause two problems: slower convergence during training and redundant bounding boxes during inference. To analyze the aforementioned problems, we proposed a metric, redundancy of object query (ROQ), to quantitatively analyze the redundancy. Through experiments, we discovered that the reason for the two issues is the difficulty in distinguishing between high-quality negative samples and positive samples. In this article, we proposed efficient-matching oriented object detection with transformers (EMO2-DETR) consisting of three dedicated components to address the aforementioned issues. Specifically, reassign bipartite graph matching (RBGM) is proposed to extract high-quality negative samples from the negative samples. And ignored sample predicted head (ISPH) is proposed to predict high-quality negative samples. Then, reassigned Hungarian loss is used to better involve high-quality negative samples in the update of model parameters. Extensive experiments on DOTAv1 and DOTAv1.5 datasets demonstrated that our proposed method achieves the competitive results. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Wang, H.
AU  - Xi, Z.
AU  - Zhang, R.
TI  - Smooth Deep Learning Magnetotelluric Inversion Based on Physics-Informed Swin Transformer and Multiwindow Savitzky-Golay Filter
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 4505214
DO  - 10.1109/TGRS.2023.3304313
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167806172&doi=10.1109%2fTGRS.2023.3304313&partnerID=40&md5=2b44e7df4044090e206bdefa88ae5339
AB  - Despite exhibiting excellent inversion results for synthetic data in magnetotelluric (MT) inversion, applying deep learning (DL) to directly inverting MT field data remains challenging. In this study, different from most previous works that mainly focus on generating massive representative resistivity models to cover the solutions of the field data or constructing a strong network by employing advanced DL techniques, we provide a new perspective in that a multiwindow Savitzky-Golay (MWSG) filter is proposed to first smooth the apparent resistivity and phase derived from the MT field measurements before network prediction. This smoothing operation aims to promote the actual apparent resistivity and phase to be close in morphology and smoothness to the training input data, i.e., to adapt the field data to the training sample data. Then, the smoothed apparent resistivity and phase, instead of the original ones, are fed into the well-trained network for instantaneous inversion. Because we create a set of layered resistivity models with gradual-changing resistivity to act as desired output during network training, it together with the proposed MWSG filter enables this work to achieve smooth inversion. Besides, we introduce Swin Transformer (SwinT) to improve the efficiency of MT DL inversion, based on which a physics-informed SwinT (PISwinT) is implemented to enhance the generalization capability. We demonstrate the proposed PISwinT-MWSG smooth inversion method in both synthetic and field MT cases, and it is expected to improve the adaptability and practicability of the DL method to directly solve the inverse problems in MT surveys. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, Y.
AU  - Zhang, W.
AU  - Wang, H.
AU  - Wang, X.
TI  - Causal Meta-Transfer Learning for Cross-Domain Few-Shot Hyperspectral Image Classification
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5521014
DO  - 10.1109/TGRS.2023.3309055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169691441&doi=10.1109%2fTGRS.2023.3309055&partnerID=40&md5=f5fd5520ee37326bdd7d37baabc218ac
AB  - Few-shot hyperspectral image (HSI) classification poses challenges due to sample selection bias in few-shot scenarios, potentially leading to incorrect statistical associations between noncausal factors and category semantics. To address these challenges, an original HSI is treated as a mixture comprising causal and noncausal factors. By integrating the causal learning, meta-learning, and transfer learning, a cross-domain few-shot HSI classification method based on causal meta-transfer learning (CMTL) is developed. First, a mask Transformer is implemented to identify noncausal factors unrelated to categories. Second, an independent causal constraint is applied to separate the causal and noncausal factors and enhance the inclusion of pure and independent causal factors in the features. Finally, the meta-transfer learning is leveraged to enable the classification model to extract causal factors highly correlated with category semantics from data, facilitating the cross-domain knowledge transfer. Meanwhile, a causal association module (CAM) is employed to maximize the mutual information between causal factors and category predictions, thereby ensuring a strong causal association between causal factors and classification tasks. Experimental results show that the CMTL achieves competitive performance in cross-domain few-shot HSI classification tasks. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shen, L.
AU  - Su, H.
AU  - Li, Z.
AU  - Jia, C.
AU  - Yang, R.
TI  - Self-Attention-Based Transformer for Nonlinear Maneuvering Target Tracking
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5109013
DO  - 10.1109/TGRS.2023.3312314
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171566395&doi=10.1109%2fTGRS.2023.3312314&partnerID=40&md5=0ca1f628fedcb2a6fae9d56d0f954b78
AB  - In the field of radar, nonlinearity has always been significant challenge in target tracking algorithms. It is evident in the complexity of the target motion model, observation model, and maneuverability of the target. Traditional model-based algorithms often rely on numerical approximations or simulations to obtain suboptimal solutions, which may lead to conversion errors and increase algorithm complexity. Model-free methods based on deep neural networks (DNNs) have been continuously employed in nonlinear target tracking (NTT) to improve target state estimation performance. This article introduces two nonlinear trackers based on the Transformer that are used for smoothing, filtering, and predicting target states in the NTT task. First, a classical Transformer-based method is proposed for smoothing and prediction, improving both inference efficiency and accuracy through parallel operation. After that, to handle the recursive operation required for filtering, we introduce a novel recursive Transformer for recursive filtering and predicting of the target state. This significantly reduces computational load compared to the classical Transformer method. Simulation results indicate that the proposed algorithm outperforms traditional and recurrent neural network (RNN)-based methods.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tang, X.
AU  - Zhang, T.
AU  - Ma, J.
AU  - Zhang, X.
AU  - Liu, F.
AU  - Jiao, L.
TI  - WNet: W-Shaped Hierarchical Network for Remote-Sensing Image Change Detection
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5615814
DO  - 10.1109/TGRS.2023.3296383
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165280725&doi=10.1109%2fTGRS.2023.3296383&partnerID=40&md5=a241196e4be9980b908961de75e85855
AB  - Change detection (CD) is a hot research topic in the remote-sensing (RS) community. With the increasing availability of high-resolution (HR) RS images, there is a growing demand for CD models with high detection accuracy and generalization ability. In other words, the CD models are expected to work well for various HRRS images. Convolutional neural networks (CNNs) have been dominated in HRRS image CD due to their excellent information extraction and nonlinear fitting capabilities. However, they are not skilled in modeling long-range contexts hidden in HRRS images, which limits their performance in CD tasks more or less. Recently, the Transformer, which is good at extracting global context dependencies, has become popular in the RS community. Nevertheless, detailed local knowledge receives insufficient emphasis in common Transformers. Considering the above discussion, we combine CNNs and Transformers and propose a new W-shaped dual-Siamese branch hierarchical network for HRRS image CD named W-shaped hierarchical network (WNet). WNet first incorporates a Siamese CNN and a Siamese Transformer into a dual-branch encoder to extract multilevel local fine-grained features and global long-range contextual dependencies. Also, we introduce deformable ideas into the Siamese CNN and Transformer to make WNet understand the critical and irregular areas within HRRS images. Second, the difference enhancement module (DEM) is developed and embedded into the encoder to produce the difference feature maps at different levels. Using simple pixel-wise subtraction and channel-wise concatenation, the changes of interest and irrelevant changes can be highlighted and suppressed in a learnable manner. Next, the multilevel difference feature maps are fused stage by stage by CNN-Transformer fusion modules (CTFMs), which are the basic units of the decoder in WNet. In CTFMs, the local, global, and cross-scale clues are taken into account to ensure the integrity of information. Finally, a simple classifier is constructed and added at the top of the decoder to predict the change maps. Positive experimental results counted on four public datasets demonstrate that the proposed WNet is helpful in HRRS image CD tasks. Our source codes are available at https://github.com/TangXu-Group/Remote-Sensing-Image-Change-Detection/tree/main/WNet. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 47
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, S.
AU  - Shu, T.
AU  - Zhao, H.
AU  - Zhong, G.
AU  - Chen, X.
TI  - TempEE: Temporal-Spatial Parallel Transformer for Radar Echo Extrapolation Beyond Autoregression
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5108914
DO  - 10.1109/TGRS.2023.3311510
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171592925&doi=10.1109%2fTGRS.2023.3311510&partnerID=40&md5=6a61040816a50121bca3916bfa490f5f
AB  - Meteorological radar reflectivity data (i.e., radar echo) significantly influences precipitation prediction. It can facilitate accurate and expeditious forecasting of short-term heavy rainfall bypassing the need for complex numerical weather prediction (NWP) models. In comparison to conventional models, deep-learning (DL)-based radar echo extrapolation algorithms exhibit higher effectiveness and efficiency. Nevertheless, the development of a reliable and generalized echo extrapolation algorithm is impeded by three primary challenges: cumulative error spreading, imprecise representation of sparsely distributed echoes, and inaccurate description of nonstationary motion processes. To tackle these challenges, this article proposes a novel radar echo extrapolation algorithm called temporal-spatial parallel transformer, referred to as TempEE. TempEE avoids using autoregression and instead employs a one-step forward strategy to prevent the cumulative error from spreading during the extrapolation process. Additionally, we propose the incorporation of a multilevel temporal-spatial attention mechanism to improve the algorithm's capability of capturing both global and local information while emphasizing task-related regions, including sparse echo representations, in an efficient manner. Furthermore, the algorithm extracts spatio-temporal representations from continuous echo images using a parallel encoder to model the nonstationary motion process for echo extrapolation. The superiority of our TempEE has been demonstrated in the context of the classic radar echo extrapolation task, utilizing a real-world dataset. Extensive experiments have further validated the efficacy and indispensability of various components within TempEE. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fang, S.
AU  - Li, K.
AU  - Li, Z.
TI  - Changer: Feature Interaction is What You Need for Change Detection
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5610111
DO  - 10.1109/TGRS.2023.3277496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160262418&doi=10.1109%2fTGRS.2023.3277496&partnerID=40&md5=6202132598d9ee886b3c3fab4d275c00
AB  - Change detection is an important tool for long-term Earth observation missions. It takes bi-temporal images as input and predicts 'where' the change has occurred. Different from other dense prediction tasks, a meaningful consideration for change detection is the interaction between bi-temporal features. With this motivation, in this article we propose a novel general change detection architecture, MetaChanger, which includes a series of alternative interaction layers in the feature extractor. To verify the effectiveness of MetaChanger, we propose two derived models, ChangerAD and ChangerEx with simple interaction strategies: aggregation-distribution (AD) and feature 'exchange.' AD is abstracted from some complex interaction methods, and feature 'exchange' is a completely parameter and computation-free operation by exchanging bi-temporal features. In addition, for better alignment of bi-temporal features, we propose a flow-based dual-alignment fusion (FDAF) module which allows interactive alignment and feature fusion. Crucially, we observe Changer series models achieve competitive performance on different scale change detection datasets. Further, our proposed ChangerAD and ChangerEx could serve as a starting baseline for future MetaChanger design. Code and weights are made available at https://github.com/likyoo/open-cd.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 105
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Zhao, Y.
AU  - Dong, Y.
AU  - Du, B.
TI  - Self-Supervised Pretraining via Multimodality Images With Transformer for Change Detection
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5402711
DO  - 10.1109/TGRS.2023.3271024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159685385&doi=10.1109%2fTGRS.2023.3271024&partnerID=40&md5=777c23e35356dde25a206213a155c015
AB  - Self-supervised learning (SSL) has shown remarkable success in image representation learning. Among these methods, masked image modeling and contrastive learning are the most recent and dominant methods. However, these two approaches will behave differently after being transferred into various downstream tasks. In this article, we propose a red, green, and blue (RGB)-elevation contrastive and image mask prediction pretraining framework. The elevation is normalized digital surface model. Then, we evaluate the learned representation by transferring the pretrained model into change detection (CD) task. To this end, we leverage the recently proposed vision transformer's capability of attending to objects and combine it with the pretext task which consists of masked image modeling and instance discriminant for fine-tuning the spatial tokens. In addition, the CD task also requires us to do information interaction between the two temporal remote sensing images. To counter this problem, we propose a plug-in temporal fusion module based on masked cross attention, and then, we evaluate its effectiveness in three open CD datasets in terms of initializing the supervised training weights. Our method achieves improvements in comparison to supervised learning methods and two mainstream SSL methods momentum contrast (MoCo) and DINO on CD task. The results of our experiment also achieve the state-of-the-art in four CD datasets. The code will be available at URL.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Salazar, J.J.
AU  - Maldonado-Cruz, E.
AU  - Ochoa, J.
AU  - Pyrcz, M.J.
TI  - Self-Supervised Learning for Seismic Data: Enhancing Model Interpretability With Seismic Attributes
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5911918
DO  - 10.1109/TGRS.2023.3285820
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162632645&doi=10.1109%2fTGRS.2023.3285820&partnerID=40&md5=0d3833091bf59b7563bca4881597df1e
AB  - Deep learning (DL) has shown great potential in geosciences, such as seismic data processing and interpretation, improving decision-making and reducing analysis time. However, DL faces two main challenges. First, many DL models rely on labeled data, which can be time-consuming to obtain. Second, the predictions from these models often lack interpretability, making it difficult to use them for high-value decisions. To address these limitations, we propose a novel workflow that eliminates the need for labeled data and enables interpretation of the results, highlighting key geological features. The proposed workflow trains a vision transformer (ViT) to produce six attention maps, focusing on diverse and relevant regions, by assigning higher attention values. We first train the ViT using a modified distillation with no labels (DINO) method specifically designed for the seismic domain and monitor for overfitting. Then, to evaluate the focus of each attention head (AH), we use nine seismic attributes as predictor features for the assigned attention using a gradient boosting model. Finally, the method samples the seismic attributes in stationary regions of the attention maps and calculates Shapley additive explanations (SHAP) values to determine the most impactful attributes on the attention prediction. Each AH can concentrate on unique geological features of the input seismic image, as indicated by different relationships between SHAP values and seismic attributes. Additionally, regardless of location, each AH can detect the same geologically significant pattern based on the attributes used. The proposed workflow enables the interpretability of the model's importance, guided by expert knowledge through seismic attributes.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tuli, S.
AU  - Dedhia, B.
AU  - Tuli, S.
AU  - Jha, N.K.
TI  - FlexiBERT: Are Current Transformer Architectures too Homogeneous and Rigid?
PY  - 2023
T2  - Journal of Artificial Intelligence Research
IS  - 77
SP  - 39
EP  - 70
DO  - 10.1613/JAIR.1.13942
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161980367&doi=10.1613%2fJAIR.1.13942&partnerID=40&md5=544b8b6c43767e924e0d50906371e8d4
AB  - The existence of a plethora of language models makes the problem of selecting the best one for a custom task challenging. Most state-of-the-art methods leverage transformer-based models (e.g., BERT) or their variants. However, training such models and exploring their hyperparameter space is computationally expensive. Prior work proposes several neural architecture search (NAS) methods that employ performance predictors (e.g., surrogate models) to address this issue; however, such works limit analysis to homogeneous models that use fixed dimensionality throughout the network. This leads to sub-optimal architectures. To address this limitation, we propose a suite of heterogeneous and flexible models, namely FlexiBERT, that have varied encoder layers with a diverse set of possible operations and different hidden dimensions. For better-posed surrogate modeling in this expanded design space, we propose a new graph-similarity-based embedding scheme. We also propose a novel NAS policy, called BOSHNAS, that leverages this new scheme, Bayesian modeling, and second-order optimization, to quickly train and use a neural surrogate model to converge to the optimal architecture. A comprehensive set of experiments shows that the proposed policy, when applied to the FlexiBERT design space, pushes the performance frontier upwards compared to traditional models. FlexiBERT-Mini, one of our proposed models, has 3% fewer parameters than BERT-Mini and achieves 8.9% higher GLUE score. A FlexiBERT model with equivalent performance as the best homogeneous model has 2.6× smaller size. FlexiBERT-Large, another proposed model, attains state-of-the-art results, outperforming the baseline models by at least 5.7% on the GLUE benchmark. © 2023 The Authors.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Wei, L.
AU  - Ye, X.
AU  - Zhang, K.
AU  - Teng, S.
AU  - Li, Z.
AU  - Jin, J.
AU  - Kim, M.J.
AU  - Sakurai, T.
AU  - Cui, L.
AU  - Manavalan, B.
AU  - Wei, L.
TI  - SiameseCPP: a sequence-based Siamese network to predict cell-penetrating peptides by contrastive learning
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 1
C7  - bbac545
DO  - 10.1093/bib/bbac545
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161278707&doi=10.1093%2fbib%2fbbac545&partnerID=40&md5=9ec52e6afb679b8f17f86cc40e084ec5
AB  - Background: Cell-penetrating peptides (CPPs) have received considerable attention as a means of transporting pharmacologically active molecules into living cells without damaging the cell membrane, and thus hold great promise as future therapeutics. Recently, several machine learning-based algorithms have been proposed for predicting CPPs. However, most existing predictive methods do not consider the agreement (disagreement) between similar (dissimilar) CPPs and depend heavily on expert knowledge-based handcrafted features. Results: In this study, we present SiameseCPP, a novel deep learning framework for automated CPPs prediction. SiameseCPP learns discriminative representations of CPPs based on a well-pretrained model and a Siamese neural network consisting of a transformer and gated recurrent units. Contrastive learning is used for the first time to build a CPP predictive model. Comprehensive experiments demonstrate that our proposed SiameseCPP is superior to existing baseline models for predicting CPPs. Moreover, SiameseCPP also achieves good performance on other functional peptide datasets, exhibiting satisfactory generalization ability.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Rao, C.
AU  - Wang, J.
AU  - Cheng, G.
AU  - Xie, X.
AU  - Han, J.
TI  - Learning Orientation-Aware Distances for Oriented Object Detection
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5610911
DO  - 10.1109/TGRS.2023.3278933
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161084452&doi=10.1109%2fTGRS.2023.3278933&partnerID=40&md5=44601699dc7c8e2016704aae9f4c1d16
AB  - Oriented object detectors have suffered severely from the discontinuous boundary problem for a long time. In this work, we ingeniously avoid this problem by relating regression outputs to regression target orientations. The core idea of our method is to build a contour function which imports orientations and outputs the corresponding distance predictions. Inspired by Fourier transformations, we assume this function can be represented as a linear combination of trigonometric functions and Fourier series. We replace the final 4-D layer in the regression branch of fully convolutional one-stage object detector (FCOS) with a Fourier series transformation (FST) module and term this new network FCOSF. By this unique design, the regression outputs in FCOSF can adaptively vary according to the regression target orientations. Thus, the discontinuous boundary has no impact on our FCOSF. More importantly, FCOSF avoids building complicated oriented box representations, which usually cause extra computations and ambiguities. With only flipping augmentation and single-scale training and testing, FCOSF with ResNet-50 achieves 73.64% mean average precision (mAP) on the DOTA-v1.0 dataset with up to 23.6-frames/s speed, surpassing all one-stage oriented object detectors. On the more challenging DOTA-v2.0 dataset, FCOSF also achieves the highest results of 51.75% mAP among one-stage detectors. More experiments on DIOR-R and HRSC2016 are also conducted to verify the robustness of FCOSF. Code and models will be available at https://github.com/DDGRCF/FCOSF.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Xie, Y.
AU  - Li, B.
AU  - Xie, C.
AU  - Zhang, Y.
AU  - Wang, A.
AU  - Zhu, L.
TI  - Spatial-Spectral 1DSwin Transformer with Groupwise Feature Tokenization for Hyperspectral Image Classification
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5516616
DO  - 10.1109/TGRS.2023.3294424
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164737008&doi=10.1109%2fTGRS.2023.3294424&partnerID=40&md5=828459d8b59a3188e9242fee68db4e05
AB  - The hyperspectral image (HSI) classification aims to assign each pixel to a land-cover category. It is receiving increasing attention from both industry and academia. The main challenge lies in capturing reliable and informative spatial and spectral dependencies concealed in the HSI for each class. To address the challenge, we propose a spatial-spectral 1DSwin (SS1DSwin) Transformer with groupwise feature tokenization for HSI classification. Specifically, we reveal local and hierarchical spatial-spectral relationships from two different perspectives. It mainly consists of a groupwise feature tokenization module (GFTM) and a 1DSwin Transformer with cross-block normalized connection module (TCNCM). For GFTM, we reorganize an image patch into overlapping cubes and further generate groupwise token embeddings with multihead self-attention (MSA) to learn the local spatial-spectral relationship along the spatial dimension. For TCNCM, we adopt the shifted windowing strategy when acquiring the hierarchical spatial-spectral relationship along the spectral dimension with 1-D window-based MSA (1DW-MSA) and 1-D shifted window-based MSA (1DSW-MSA) and leverage cross-block normalized connection (CNC) to adaptively fuse the feature maps from different blocks. In SS1DSwin, we apply these two modules in order and predict the class label for each pixel. To test the effectiveness of the proposed method, extensive experiments are conducted on four HSI datasets, and the results indicate that SS1DSwin outperforms several current state-of-the-art methods. The source code of the proposed method is available at https://github.com/Minato252/SS1DSwin. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xue, Z.
AU  - Zhiqiang, Z.
AU  - Zhengyin, H.
TI  - Exploring interdisciplinarity of science projects based on the text mining
PY  - 2023
T2  - Journal of Information Science
DO  - 10.1177/01655515231182075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164513536&doi=10.1177%2f01655515231182075&partnerID=40&md5=11c537b2e384104cb9ed874df4cb23a9
AB  - Interdisciplinary research has gradually become one of the main driving forces to promote original innovation of scientific research, and how to measure the interdisciplinarity of science project is becoming an important topic in the science foundation managements. Existing researches mainly using methods, such as academic degree or institutional discipline or discipline category mapping of journals, to measure the interdisciplinarity. This study proposes an approach to mine and capture the different or complementary characteristics of interdisciplinarity of projects by combining text mining and machine learning methods. First, we construct the classification system and extract a raw paper and its discipline matrix according to the discipline category of journals where the references were published in. Second, we cut the matrix to summarise the distribution of key disciplines in each paper and extract the text features in the abstract and title to form a training set. Finally, we compare and analyse the classification effects of Naive Bayesian Model, Support Vector Machine and Bidirectional Encoder Representations from Transformers (BERT) model. Then, the model evaluation indicators show that the best classification effect was achieved by the BERT model. Therefore, the deep pre-trained linguistic model BERT is chosen to predict the discipline distribution of each project. In addition, the different aspects of interdisciplinarity are measured using network coherence and discipline diversity indicators. Besides, experts are invited to evaluate and interpret the results. This proposed approach could be applied to deeply understand the discipline integration from a new perspective. © The Author(s) 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Xue2023Exploring
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Guo, W.
AU  - Wu, C.
AU  - Li, W.
AU  - Tao, R.
TI  - FANet: An Arbitrary Direction Remote Sensing Object Detection Network Based on Feature Fusion and Angle Classification
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5608811
DO  - 10.1109/TGRS.2023.3273354
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159821997&doi=10.1109%2fTGRS.2023.3273354&partnerID=40&md5=34099365f0e08d655eb450faee3a26d4
AB  - High-precision remote sensing image object detection has broad application prospects in military defense, disaster emergency, urban planning, and other fields. The arbitrary orientation, dense arrangement, and small size of objects in remote sensing images, however, lead to poor detection accuracy of existing methods. To achieve accurate detection, this article proposes an arbitrary directional remote sensing object detection method, called 'FANet,' based on feature fusion and angle classification. Initially, the angle prediction branch is introduced, and the circular smooth label (CSL) method is used to transform the angle regression problem into a classification problem, which solves the difficult problem of abrupt changes in the boundaries of the rotating frame while realizing the object frame rotation. Subsequently, to extract robust remote sensing objects, innovatively introduced a pure convolutional model as a backbone network, while Conv is replaced by GSConv to reduce the number of parameters in the model along with ensuring detection accuracy. Finally, the strengthen connection feature pyramid network (SC-FPN) is proposed to redesign the lateral connection part for deep and shallow layer feature fusion and add jump connections between the input and output of the same level feature map to enrich the feature semantic information. In addition, add a variable parameter to the original localization loss function to satisfy the bounding box regression accuracy under different intersection over union (IoU) thresholds, and thus obtain more accurate object detection. The comprehensive experimental results on two public datasets for rotated object detection, a large-scale dataset for object detection in aerial images (DOTA) and HRSC2016, demonstrate the effectiveness of our method.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Pan, S.
AU  - Chen, Y.
AU  - Chen, J.
AU  - Yi, S.
AU  - Zhang, D.
AU  - Song, G.
TI  - An Unsupervised Inversion Method for Seismic Brittleness Parameters Driven by the Physical Equation
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5909013
DO  - 10.1109/TGRS.2023.3273302
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159802040&doi=10.1109%2fTGRS.2023.3273302&partnerID=40&md5=ebfe2be5c08481dc3764d0cc31e54c9d
AB  - Brittleness is an important parameter characterizing the fracturing properties of shale reservoir, which can be predicted by the prestack seismic inversion. In order to overcome the low efficiency and ill-posed problems of the traditional prestack brittleness inversion, we propose a new unsupervised deep learning (DL) inversion method for seismic brittleness parameters based on the physical equation. This method integrates DL framework and the physical equation and provides a DL inversion strategy without actual labels. We first input the original seismic data into the Fastformer network and use the low-frequency model as the physical constraint to predict the brittle parameters. Then, the prediction results of brittleness parameters are sent to the forward modeling module (a linear approximation equation) to calculate the synthetic seismic data. Next, the error between the calculated seismic data and original seismic data is used to update the network prediction results. The network parameters are iteratively optimized to minimize the error, and the brittle prediction parameters are finally output. In the whole training process, it is not necessary to use the real brittle parameters as the labels. Through this method, the effect of approximate unsupervised learning is obtained. Finally, we apply the proposed method to the synthetic data and field data and compared with the results inverted by the traditional L1 method. The experimental results show that the proposed method has higher inversion accuracy and efficiency than the traditional L1 method, which has a great potential in the practical application. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Oh, B.-D.
AU  - Schuler, W.
TI  - Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?
PY  - 2023
T2  - Transactions of the Association for Computational Linguistics
VL  - 11
SP  - 336
EP  - 350
DO  - 10.1162/tacl_a_00548
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153493316&doi=10.1162%2ftacl_a_00548&partnerID=40&md5=53ae8bcf55be4f8011b34a596a334e3c
AB  - This work presents a linguistic analysis into why larger Transformer-based pre-trained language models with more parameters and lower perplexity nonetheless yield surprisal estimates that are less predictive of human reading times. First, regression analyses show a strictly monotonic, positive log-linear relationship between perplexity and fit to reading times for the more recently released five GPT-Neo variants and eight OPT variants on two separate datasets, replicating earlier results limited to just GPT-2 (Oh et al., 2022). Subsequently, analysis of residual errors reveals a systematic deviation of the larger variants, such as underpredicting reading times of named entities and making compensatory overpredictions for reading times of function words such as modals and conjunctions. These results suggest that the propensity of larger Transformer-based models to ‘memorize’ sequences during training makes their surprisal estimates diverge from humanlike expectations, which warrants caution in using pre-trained language models to study human language processing. © 2023 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 47
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chopin, B.
AU  - Tang, H.
AU  - Otberdout, N.
AU  - Daoudi, M.
AU  - Sebe, N.
TI  - Interaction Transformer for Human Reaction Generation
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 8842
EP  - 8854
DO  - 10.1109/TMM.2023.3242152
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148435155&doi=10.1109%2fTMM.2023.3242152&partnerID=40&md5=246b38d6c54b2fe60388936085dbb0e4
AB  - We address the challenging task of human reaction generation, which aims to generate a corresponding reaction based on an input action. Most of the existing works do not focus on generating and predicting the reaction and cannot generate the motion when only the action is given as input. To address this limitation, we propose a novel interaction Transformer (InterFormer) consisting of a Transformer network with both temporal and spatial attention. Specifically, temporal attention captures the temporal dependencies of the motion of both characters and of their interaction, while spatial attention learns the dependencies between the different body parts of each character and those which are part of the interaction. Moreover, we propose using graphs to increase the performance of spatial attention via an interaction distance module that helps focus on nearby joints from both characters. Extensive experiments on the SBU interaction, K3HI, and DuetDance datasets demonstrate the effectiveness of InterFormer. Our method is general and can be used to generate more complex and long-term interactions.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, C.
AU  - Jiang, M.
AU  - Kong, J.
TI  - BGTracker: Cross-Task Bidirectional Guidance Strategy for Multiple Object Tracking
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
C7  - 3256761
SP  - 8132
EP  - 8144
DO  - 10.1109/TMM.2023.3256761
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151368935&doi=10.1109%2fTMM.2023.3256761&partnerID=40&md5=6eb68d61686c821816994819f75b8bc5
AB  - Recent works have shown that the joint-detection-and-embedding (JDE) paradigm has significantly enhanced the performance of multiple object tracking by simultaneously learning detection and re-identification features. These methods always utilize a weight-shared backbone network and two non-interactive branches for different tasks. This non-interactive multi-task learning strategy cannot make full use of geometric and semantic information between detection and re-identification tasks. And in the JDE paradigm, there exists a feature misalignment between detection and re-identification due to their different optimization directions. In this article, BGTracker is proposed as a novel online tracking framework with a cross-task bidirectional guidance strategy between detection and re-identification. Firstly, we propose a Channel-based Decoupling module and Cross-direction Transformer to alleviate feature misalignment, which can obtain task-aligned embeddings and discriminative representations at the feature level. Then, we propose the bidirectional guidance strategy to link the two tasks by the prediction map's statistical information. In this strategy, two designed feature transformations are employed to utilize the advantages of each task for complementing each other at the task level. Finally, extensive experiments demonstrate that the proposed BGTracker outperforms various existing methods on the MOTChallenge benchmarks.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, Q.
AU  - Wang, J.
AU  - Jiang, B.
AU  - Luo, B.
TI  - Fine-Grained Visual Classification via Internal Ensemble Learning Transformer
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
C7  - 3244340
SP  - 9015
EP  - 9028
DO  - 10.1109/TMM.2023.3244340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149368858&doi=10.1109%2fTMM.2023.3244340&partnerID=40&md5=a7f476ae07af7a652e326f99c9a6a788
AB  - Recently, vision transformers (ViTs) have been investigated in fine-grained visual recognition (FGVC) and are now considered state of the art. However, most ViT-based works ignore the different learning performances of the heads in the multi-head self-attention (MHSA) mechanism and its layers. To address these issues, in this paper, we propose a novel internal ensemble learning transformer (IELT) for FGVC. The proposed IELT involves three main modules: multi-head voting (MHV) module, cross-layer refinement (CLR) module, and dynamic selection (DS) module. To solve the problem of the inconsistent performances of multiple heads, we propose the MHV module, which considers all of the heads in each layer as weak learners and votes for tokens of discriminative regions as cross-layer feature based on the attention maps and spatial relationships. To effectively mine the cross-layer feature and suppress the noise, the CLR module is proposed, where the refined feature is extracted and the assist logits operation is developed for the final prediction. In addition, a newly designed DS module adjusts the token selection number at each layer by weighting their contributions of the refined feature. In this way, the idea of ensemble learning is combined with the ViT to improve fine-grained feature representation. The experiments demonstrate that our method achieves competitive results compared with the state of the art on five popular FGVC datasets.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 55
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Q.
AU  - Yu, C.
TI  - Object Detection Made Simpler by Eliminating Heuristic NMS
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 9254
EP  - 9262
DO  - 10.1109/TMM.2023.3248966
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149365272&doi=10.1109%2fTMM.2023.3248966&partnerID=40&md5=c0da4cede02fea785395e8702bb7f155
AB  - It is valuable and promising to remove post-processing non-maximum suppression (NMS) for object detectors, making detectors simpler and purely end-to-end. Removing NMS is possible if the object detector can identify only one positive sample for prediction for each ground-truth object instance in an image. In this work, we propose a compact and plug-in head, named PSS head, which can be attached to any one-stage detectors to make them NMS-free. Specifically, the PSS head works by automatically selecting a positive sample for each instance to be detected, so that the detectors with our PSS head can directly remove NMS. The success of our PSS head lies in three aspects, namely one-to-one label assignment, stop-gradient operation for eliminating optimization conflicts, and the pss loss and ranking loss specifically designed for the PSS head. Experiments on the COCO dataset demonstrate the effectiveness of our method. In particular, when compared with stage-of-the-art NMS-free methods, our VFNETPSS (attaching PSS head to VFNET) achieves 44.0% mAP, which exceeds the 41.5% mAP of DeFCN with a large margin. When taking Res2Net-101-DCN as backbone network, our VFNETPSS achieves 50.3% mAP on the COCO test set, which is a promising performance even among NMS-based methods.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Jiang, Q.
AU  - Zhao, S.
AU  - Feng, W.
AU  - Lin, W.
TI  - Deep Blind Image Quality Assessment Powered by Online Hard Example Mining
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 4774
EP  - 4784
DO  - 10.1109/TMM.2023.3257564
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151390174&doi=10.1109%2fTMM.2023.3257564&partnerID=40&md5=cf7c41750acbac44559c98bcdf289f09
AB  - Recently, blind image quality assessment (BIQA) models based on deep neural networks (DNNs) have achieved impressive performance on existing datasets. However, due to the intrinsic imbalance property of the training set, not all distortions or images are handled equally well. Online hard example mining (OHEM) is a promising way to alleviate this issue. Inspired by the recent finding that network pruning disproportionately hampers the model's memorization of a tractable subset, e.g., atypical, low-quality, long-tailed samples, which are hard-to-memorize during training and easily "forgotten"during pruning, we propose an effective "plug-and-play"OHEM pipeline for generalizable deep BIQA. Specifically, we train two parallel weight-sharing branches simultaneously, where one is full model and other is a "self-competitor"generated from the full model online by network pruning. Then, we leverage the prediction disagreement between the full model and its pruned variant (i.e., the self-competitor) to expose easily "forgettable"samples, which are therefore regarded as the hard ones. We enforce the prediction consistency between the full model and its pruned variant to implicitly put more focus on these hard samples, which benefits the full model to recover forgettable information introduced by pruning. Extensive experiments across multiple datasets and BIQA models demonstrate that the proposed OHEM can improve the model performance and generalizability as measured by correlation numbers and group maximum differentiation (gMAD) competition. © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Q.
AU  - Chen, X.
AU  - Meng, X.
AU  - Chen, H.
AU  - Shao, F.
AU  - Sun, W.
TI  - Dual-Task Interactive Learning for Unsupervised Spatio-Temporal-Spectral Fusion of Remote Sensing Images
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 5402015
DO  - 10.1109/TGRS.2023.3265400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153395070&doi=10.1109%2fTGRS.2023.3265400&partnerID=40&md5=4a95ebdb081460418e00f26b1adbd87c
AB  - Spatio-temporal-spectral fusion aims to produce high spatio-temporal-spectral resolution images by integrating the complementary spatial, temporal, and spectral advantages of multisource remote sensing images. However, on one hand, the existing spatio-temporal-spectral fusion methods are insufficient to exploit the inherent complex nonlinear spatial, temporal, and spectral relationship among multisource and multitemporal observations. On the other hand, since the unavailability of real high spatio-temporal-spectral resolution images, it is difficult to adopt deep learning (DL) methods with supervised training. In this article, we propose an effective unsupervised spatio-temporal-spectral fusion model (USTSFM) with dual-task interactive learning to alleviate these problems. The proposed USTSFM has two branches: the spatio-temporal-spectral mapping (STSM) branch is to describe the temporal relationship, and the spectral super-resolution (SSR) branch is to model the spectral relationship. Moreover, the spatial-spectral interaction compensation block is designed to make the two branches compensate and benefit from each other. This intrinsically related and mutually facilitated strategy allows the USTSFM to sufficiently exploit the inherent spatial, temporal, and spectral relationship. In addition, a shared reconstruction module is meticulously designed for the two tasks, which not only reduces the parameters but also allows the supervised task to guide the convergence of the unsupervised task, boosting the stability of unsupervised training. The qualitative and quantitative results demonstrated that the proposed USTSFM has richer spatial details and more accurate predictions than the other state-of-the-art methods. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, X.
AU  - Liu, F.
AU  - Lin, G.
TI  - Effective End-to-End Vision Language Pretraining With Semantic Visual Loss
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 8408
EP  - 8417
DO  - 10.1109/TMM.2023.3237166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147280160&doi=10.1109%2fTMM.2023.3237166&partnerID=40&md5=e87baca4e912a674e71015c0c2870de3
AB  - Current vision language pretraining models are dominated by methods using region visual features extracted from object detectors. Given their good performance, the extract-then-process pipeline significantly restricts the inference speed and therefore limits their real-world use cases. However, training vision language models from raw image pixels is difficult, as the raw image pixels give much less prior knowledge than region features. In this paper, we systematically study how to leverage auxiliary visual pretraining tasks to help training end-to-end vision language models. We introduce three types of visual losses that enable much faster convergence and better finetuning accuracy. Compared with region feature models, our end-to-end models could achieve similar or better performance on down-stream tasks and run more than 10 times faster during inference. Compared with other end-to-end models, our proposed method could achieve similar or better performance when pretrained for only 10% of the pretraining GPU hours.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, B.
AU  - Wisniewski, G.
AU  - Crabbé, B.
TI  - Assessing the Capacity of Transformer to Abstract Syntactic Representations: A Contrastive Analysis Based on Long-distance Agreement
PY  - 2023
T2  - Transactions of the Association for Computational Linguistics
VL  - 11
SP  - 18
EP  - 33
DO  - 10.1162/tacl_a_00531
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146920768&doi=10.1162%2ftacl_a_00531&partnerID=40&md5=2effb3db1b1adc83bc9673102301e1a9
AB  - Many studies have shown that transformers are able to predict subject-verb agreement, demon-strating their ability to uncover an abstract representation of the sentence in an unsupervised way. Recently, Li et al. (2021) found that transformers were also able to predict the object-past participle agreement in French, the modeling of which in formal grammar is fun-damentally different from that of subject-verb agreement and relies on a movement and an anaphora resolution. To better understand transformers’ internal working, we propose to contrast how they handle these two kinds of agreement. Using probing and counterfactual analysis methods, our experiments on French agreements show that (i) the agreement task suffers from several confounders that partially question the con-clusions drawn so far and (ii) transformers handle subject-verb and object-past participle agreements in a way that is consistent with their modeling in theoretical linguistics. © 2023 Association for Computational Linguistics.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Nambiar, A.
AU  - Liu, S.
AU  - Heflin, M.
AU  - Forsyth, J.M.
AU  - Maslov, S.
AU  - Hopkins, M.
AU  - Ritz, A.
TI  - Transformer Neural Networks for Protein Family and Interaction Prediction Tasks
PY  - 2023
T2  - Journal of Computational Biology
VL  - 30
IS  - 1
SP  - 95
EP  - 111
DO  - 10.1089/cmb.2022.0132
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145955554&doi=10.1089%2fcmb.2022.0132&partnerID=40&md5=a77457b73a2a69e56801291b3e95ee87
AB  - The scientific community is rapidly generating protein sequence information, but only a fraction of these proteins can be experimentally characterized. While promising deep learning approaches for protein prediction tasks have emerged, they have computational limitations or are designed to solve a specific task. We present a Transformer neural network that pre-trains task-agnostic sequence representations. This model is fine-tuned to solve two different protein prediction tasks: protein family classification and protein interaction prediction. Our method is comparable to existing state-of-the-art approaches for protein family classification while being much more general than other architectures. Further, our method outperforms other approaches for protein interaction prediction for two out of three different scenarios that we generated. These results offer a promising framework for fine-tuning the pre-trained sequence representations for other protein prediction tasks.  © 2023, Mary Ann Liebert, Inc., publishers 2023.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Shao, S.
AU  - Li, R.
AU  - Pei, Z.
AU  - Liu, Z.
AU  - Chen, W.
AU  - Zhu, W.
AU  - Wu, X.
AU  - Zhang, B.
TI  - Towards Comprehensive Monocular Depth Estimation: Multiple Heads are Better Than One
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 7660
EP  - 7671
DO  - 10.1109/TMM.2022.3224810
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144018718&doi=10.1109%2fTMM.2022.3224810&partnerID=40&md5=f6ec9cd491bece7eb7a3bda3117c4a08
AB  - Depth estimation attracts widespread attention in the computer vision community. However, it is still quite difficult to recover an accurate depth map using only one RGB image. We observe a phenomenon that existing methods tend to fail in different cases, caused by differences in network architecture, loss function and so on. In this work, we investigate into the phenomenon and propose to integrate the strengths of multiple weak depth predictor to build a comprehensive and accurate depth predictor, which is critical for many real-world applications, e.g., 3D reconstruction. Specifically, we construct multiple base (weak) depth predictors by utilizing different Transformer-based and convolutional neural network (CNN)-based architectures. Transformer establishes long-range correlation while CNN preserves local information ignored by Transformer due to the spatial inductive bias. Therefore, the coupling of Transformer and CNN contributes to the generation of complementary depth estimates, which are essential to achieve a comprehensive depth predictor. Then, we design mixers to learn from multiple weak predictions and adaptively fuse them into a strong depth estimate. The resultant model, which we refer to as Transformer-assisted depth ensembles (TEDepth). On the standard NYU-Depth-v2 and KITTI datasets, we thoroughly explore how the neural ensembles affect the depth estimation and demonstrate that our TEDepth achieves better results than previous state-of-the-art approaches. To validate the generalizability across cameras, we directly apply the models trained on NYU-Depth-v2 to the SUN RGB-D dataset without any fine-tuning, and the superior results emphasize its strong generalizability.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, G.
AU  - Bai, Y.
AU  - Zhang, W.
AU  - Yao, T.
AU  - Shihada, B.
AU  - Mei, T.
TI  - Boosting Generic Visual-Linguistic Representation With Dynamic Contexts
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 8445
EP  - 8457
DO  - 10.1109/TMM.2023.3237164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147305328&doi=10.1109%2fTMM.2023.3237164&partnerID=40&md5=93da0730cae62bb5988c67221b712fea
AB  - Pretraining large models on generous multi-modal corpora has accelerated the development of visual-linguistic (VL) representation and achieved great success on various vision-and-language downstream tasks. Learning these models is usually executed by predicting the randomly masked words of captions or patches in images. Such approaches, nevertheless, seldom explore the supervision of causalities behind the caption descriptions or the procedure of generating events beyond still images. In this work, we endow the pretrained models with high-level cognition by delving into dynamic contexts to model the visual and linguistic causalities uniformly. Specifically, we format the dynamic contexts of an image as the sentences describing the events before, on, and after image. Unlike traditional caption-wise similarity, we propose a novel dynamic contexts-based similarity (DCS) metric, in which the correlation of potential causes and effects besides immediate visual content are considered to measure the relevance among images. DCS can be further simplified by parameterizing event continuity to relax the requirements on dense contextual event annotations. A new pre-task is designed to minimize the feature distances of dynamically contextual relevant images and incorporate the event causality and commonsense knowledge into the VL representation learning. Models based on our dynamic contexts significantly outperform typical VL models on multiple cross-modal downstream tasks, including the conventional visual commonsense reasoning (VCR), visual question answering (VQA), zero-shot image-text retrieval, and extended image / event ordering tasks. © 2023 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fan, X.
AU  - Pan, H.
AU  - Tian, A.
AU  - Chung, W.K.
AU  - Shen, Y.
TI  - SHINE: Protein language model-based pathogenicity prediction for short inframe insertion and deletion variants
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 1
C7  - bbac584
DO  - 10.1093/bib/bbac584
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147044554&doi=10.1093%2fbib%2fbbac584&partnerID=40&md5=40dbd86444a5ca9a29335e60263a56c7
AB  - Accurate variant pathogenicity predictions are important in genetic studies of human diseases. Inframe insertion and deletion variants (indels) alter protein sequence and length, but not as deleterious as frameshift indels. Inframe indel Interpretation is challenging due to limitations in the available number of known pathogenic variants for training. Existing prediction methods largely use manually encoded features including conservation, protein structure and function, and allele frequency to infer variant pathogenicity. Recent advances in deep learning modeling of protein sequences and structures provide an opportunity to improve the representation of salient features based on large numbers of protein sequences. We developed a new pathogenicity predictor for SHort Inframe iNsertion and dEletion (SHINE). SHINE uses pretrained protein language models to construct a latent representation of an indel and its protein context from protein sequences and multiple protein sequence alignments, and feeds the latent representation into supervised machine learning models for pathogenicity prediction. We curated training data from ClinVar and gnomAD, and created two test datasets from different sources. SHINE achieved better prediction performance than existing methods for both deletion and insertion variants in these two test datasets. Our work suggests that unsupervised protein language models can provide valuable information about proteins, and new methods based on these models can improve variant interpretation in genetic analyses.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Yao, M.
AU  - Xiao, X.
AU  - Xiong, Y.
TI  - RockFormer: A U-Shaped Transformer Network for Martian Rock Segmentation
PY  - 2023
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 61
C7  - 4600116
DO  - 10.1109/TGRS.2023.3235525
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147228799&doi=10.1109%2fTGRS.2023.3235525&partnerID=40&md5=f8646e38aa739990a3268ea45af2441e
AB  - Martian rock segmentation aims to separate rock pixels from background, which plays a crucial role in downstream tasks, such as traversing and geologic analysis by Mars rovers. The U-Nets have achieved certain results in rock segmentation. However, due to the inherent locality of convolution operations, U-Nets are inadequate in modeling global context and long-range spatial dependencies. Although emerging Transformers can solve this, they suffer from difficulties in extracting and retaining sufficient low-level local information. These shortcomings limit the performance of the existing networks for Martian rocks that are variable in shape, size, texture, and color. Therefore, we propose RockFormer, the first U-shaped Transformer framework for Mars rock segmentation, consisting of a hierarchical encoder-decoder architecture with a feature refining module (FRM) connected between them. Specifically, the encoder hierarchically generates multiscale features using an improved vision Transformer (improved-ViT), where both abundant local information and long-range contexts are exploited. The FRM removes less representative features and captures global dependencies between multiscale features, improving RockFormer's robustness to Martian rocks with diverse appearances. The decoder is responsible for aggregating these features for pixelwise rock prediction. For evaluation, we establish two Mars rock datasets, including both real and synthesized images. One is MarsData-V2, an extension of our previously published MarsData collected from real Mars rocks. The other is SynMars, a synthetic dataset sequentially photographed from a virtual terrain built referring to the TianWen-1 dataset. Extensive experiments on the two datasets show the superiority of RockFormer for Martian rock segmentation, achieving state-of-the-art performance with decent computational simplicity.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, P.
AU  - Yan, Y.
AU  - Huang, S.-Y.
TI  - DeepHomo2.0: improved protein-protein contact prediction of homodimers by transformer-enhanced deep learning
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 1
C7  - bbac499
DO  - 10.1093/bib/bbac499
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147044958&doi=10.1093%2fbib%2fbbac499&partnerID=40&md5=f8fd05309ebc11b618f13b015be7dd8d
AB  - Protein-protein interactions play an important role in many biological processes. However, although structure prediction for monomer proteins has achieved great progress with the advent of advanced deep learning algorithms like AlphaFold, the structure prediction for protein-protein complexes remains an open question. Taking advantage of the Transformer model of ESM-MSA, we have developed a deep learning-based model, named DeepHomo2.0, to predict protein-protein interactions of homodimeric complexes by leveraging the direct-coupling analysis (DCA) and Transformer features of sequences and the structure features of monomers. DeepHomo2.0 was extensively evaluated on diverse test sets and compared with eight state-of-the-art methods including protein language model-based, DCA-based and machine learning-based methods. It was shown that DeepHomo2.0 achieved a high precision of >70% with experimental monomer structures and >60% with predicted monomer structures for the top 10 predicted contacts on the test sets and outperformed the other eight methods. Moreover, even the version without using structure information, named DeepHomoSeq, still achieved a good precision of >55% for the top 10 predicted contacts. Integrating the predicted contacts into protein docking significantly improved the structure prediction of realistic Critical Assessment of Protein Structure Prediction homodimeric complexes. DeepHomo2.0 and DeepHomoSeq are available at http://huanglab.phys.hust.edu.cn/DeepHomo2/.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yang, K.
AU  - Zhang, H.
AU  - Gao, F.
AU  - Shi, J.
AU  - Zhang, Y.
AU  - Wu, Q.M.J.
TI  - DETA: A Point-Based Tracker With Deformable Transformer and Task-Aligned Learning
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 7545
EP  - 7558
DO  - 10.1109/TMM.2022.3223213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142821505&doi=10.1109%2fTMM.2022.3223213&partnerID=40&md5=c149c7b8f9ccee795108ab06386cce39
AB  - Current point-based trackers are usually implemented by the following two branches: a classification branch for predicting the target candidate locations and a regression branch for regressing the tracking box, which may lead to a spatial misalignment between the two tasks. Meanwhile, they ignore a meaningful exploration on how to define positive and negative samples during training and explicit border information for accurate box prediction. In this research, we investigate the key issues of point-based trackers and unlock their key limitations. First, we design a novel task-aligned component and a new loss function, named task-aligned loss, to learn the alignment of the classification and regression tasks. Second, we introduce a border alignment (BorderAlign) component in both the classification and regression branches to effectively exploit the border features of a tracking target. Third, we develop an adaptive training sample assignment (ATSA) to adaptively divide the positive and negative samples based on the statistical characteristics of the tracking object. Finally, a deformable transformer is developed to enhance the representations of search features and explore rich temporal contexts among video frames. Extensive experimental results demonstrate that the proposed tracker achieves state-of-the-art performance on six tracking benchmark datasets.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Yang, J.
AU  - Dai, T.
AU  - Xiao, Y.
TI  - A predictive model based on user awareness and multi-type rumors forwarding dynamics
PY  - 2023
T2  - Information Sciences
VL  - 619
SP  - 795
EP  - 816
DO  - 10.1016/j.ins.2022.11.072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142876393&doi=10.1016%2fj.ins.2022.11.072&partnerID=40&md5=00111d86b15defd3863166b93b1359c6
AB  - Previous models for predicting rumor-forwarding trends were primarily focused on feature generation and model prediction in two independent directions: message text and user association features. However, the abstraction of user awareness, text contextual feature extraction limitation, and inefficiency of traditional hyperparameter search methods still pose numerous challenges. This study proposes a rumor-forwarding trend prediction model that combines user awareness and multi-type rumor to address such challenges. First, considering the abstraction of user awareness under multi-type rumors, we extract features by cascading user behavior, historical activities, interactions, and activity levels and by fusing features using a two-layer fully connected network to effectively quantify the relevant features of user awareness. Second, considering the limitations of traditional text representation in semantic context understanding, we use the Bidirectional Encoder Representation from Transformers (BERT) pre-training model to characterize the text in the topic, obtain text representation sequence with contextual relationships, and propose an Improved Cuckoo Search (ICS) method that optimizes the hyperparameters of the temporal convolutional network (TCN) model. Finally, an Improved Cuckoo Search-TCN-based rumor-forwarding trend prediction model is constructed based on user awareness features and text representation sequences to predict the rumor-forwarding trend. Certain rumors with a large potential impact range can be monitored at the early dissemination stage. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; FMS:B; 
LB  - Li2023predictive
ER  -

TY  - JOUR
AU  - Fei, B.
AU  - Yang, W.
AU  - Ma, L.
AU  - Chen, W.-M.
TI  - DcTr: Noise-robust point cloud completion by dual-channel transformer with cross-attention
PY  - 2023
T2  - Pattern Recognition
VL  - 133
C7  - 109051
DO  - 10.1016/j.patcog.2022.109051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144097103&doi=10.1016%2fj.patcog.2022.109051&partnerID=40&md5=78d165e3bca20e4d772b52c02d01e313
AB  - Current point cloud completion research mainly utilizes the global shape representation and local features to recover the missing regions of 3D shape for the partial point cloud. However, these methods suffer from inefficient utilization of local features and unstructured points prediction in local patches, hardly resulting in a well-arranged structure for points. To tackle these problems, we propose to employ Dual-channel Transformer and Cross-attention (CA) for point cloud completion (DcTr). The DcTr is apt at using local features and preserving a well-structured generation process. Specifically, the dual-channel transformer leverages point-wise attention and channel-wise attention to summarize the deconvolution patterns used in the previous Dual-channel Transformer Point Deconvolution (DCTPD) stage to produce the deconvolution in the current DCTPD stage. Meanwhile, we employ cross-attention to convey the geometric information from the local regions of incomplete point clouds for the generation of complete ones at different resolutions. In this way, we can generate the locally compact and structured point cloud by capturing the structure characteristic of 3D shape in local patches. Our experimental results indicate that DcTr outperforms the state-of-the-art point cloud completion methods under several benchmarks and is robust to various kinds of noise. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yu, Q.
AU  - Fan, K.
AU  - Zheng, Y.
TI  - Domain Adaptive Transformer Tracking Under Occlusions
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 1452
EP  - 1461
DO  - 10.1109/TMM.2023.3234372
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147222477&doi=10.1109%2fTMM.2023.3234372&partnerID=40&md5=c9dd1e0f880cd34a043b2467d9b944b9
AB  - Due to their excellent performance on aggregating global features, Transformer structures are being widely employed in deep learning-based visual object tracking algorithms, recently. Nevertheless, existing Transformer-based trackers still fail to handle occlusion problems due to drift in feature distributions. To address this issue, we introduce domain adaptation techniques into a novel object tracking framework, DATransT, including feature extraction, domain adaptive Transformer module and prediction head. The domain adaptive Transformer module consists of three weight-sharing branches with self and cross attention mechanisms: the source, the target and the source-target branches. Specifically, the source-target branch employs cross-attention to effectively align the feature distributions of the source and target branches. Meanwhile, we present a pseudo-labeling strategy to generate high-quality training samples. Extensive experiments show that DATransT obtains promising results on several popular datasets, containing LaSOT, TrackingNet, GOT-10k, NfS, OTB2015 and UAV123. Moreover, our method outperforms existing state-of-the-art trackers under full occlusions and partial occlusions. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kang, Y.
AU  - Xu, Y.
AU  - Wang, X.
AU  - Pu, B.
AU  - Yang, X.
AU  - Rao, Y.
AU  - Chen, J.
TI  - HN-PPISP: a hybrid network based on MLP-Mixer for protein-protein interaction site prediction
PY  - 2023
T2  - Briefings in Bioinformatics
VL  - 24
IS  - 1
C7  - bbac480
DO  - 10.1093/bib/bbac480
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147045081&doi=10.1093%2fbib%2fbbac480&partnerID=40&md5=380cd70b2abc094bd598878dd3e6a344
AB  - Motivation: Biological experimental approaches to protein-protein interaction (PPI) site prediction are critical for understanding the mechanisms of biochemical processes but are time-consuming and laborious. With the development of Deep Learning (DL) techniques, the most popular Convolutional Neural Networks (CNN)-based methods have been proposed to address these problems. Although significant progress has been made, these methods still have limitations in encoding the characteristics of each amino acid in protein sequences. Current methods cannot efficiently explore the nature of Position Specific Scoring Matrix (PSSM), secondary structure and raw protein sequences by processing them all together. For PPI site prediction, how to effectively model the PPI context with attention to prediction remains an open problem. In addition, the long-distance dependencies of PPI features are important, which is very challenging for many CNN-based methods because the innate ability of CNN is difficult to outperform auto-regressive models like Transformers. Results: To effectively mine the properties of PPI features, a novel hybrid neural network named HN-PPISP is proposed, which integrates a Multi-layer Perceptron Mixer (MLP-Mixer) module for local feature extraction and a two-stage multi-branch module for global feature capture. The model merits Transformer, TextCNN and Bi-LSTM as a powerful alternative for PPI site prediction. On the one hand, this is the first application of an advanced Transformer (i.e. MLP-Mixer) with a hybrid network for sequence-based PPI prediction. On the other hand, unlike existing methods that treat global features altogether, the proposed two-stage multi-branch hybrid module firstly assigns different attention scores to the input features and then encodes the feature through different branch modules. In the first stage, different improved attention modules are hybridized to extract features from the raw protein sequences, secondary structure and PSSM, respectively. In the second stage, a multi-branch network is designed to aggregate information from both branches in parallel. The two branches encode the features and extract dependencies through several operations such as TextCNN, Bi-LSTM and different activation functions. Experimental results on real-world public datasets show that our model consistently achieves state-of-the-art performance over seven remarkable baselines. Availability: The source code of HN-PPISP model is available at https://github.com/ylxu05/HN-PPISP.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, W.
AU  - Zhong, C.
AU  - Peng, J.
AU  - Wei, Z.
TI  - DxFormer: a decoupled automatic diagnostic system based on decoder–encoder transformer with dense symptom representations
PY  - 2023
T2  - Bioinformatics
VL  - 39
IS  - 1
C7  - btac744
DO  - 10.1093/bioinformatics/btac744
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146182266&doi=10.1093%2fbioinformatics%2fbtac744&partnerID=40&md5=2d44b41ee68eaf2d8b3549f462d82ad3
AB  - Motivation: Symptom-based automatic diagnostic system queries the patient’s potential symptoms through continuous interaction with the patient and makes predictions about possible diseases. A few studies use reinforcement learning (RL) to learn the optimal policy from the joint action space of symptoms and diseases. However, existing RL (or Non-RL) methods focus on disease diagnosis while ignoring the importance of symptom inquiry. Although these systems have achieved considerable diagnostic accuracy, they are still far below its performance upper bound due to few turns of interaction with patients and insufficient performance of symptom inquiry. To address this problem, we propose a new automatic diagnostic framework called DxFormer, which decouples symptom inquiry and disease diagnosis, so that these two modules can be independently optimized. The transition from symptom inquiry to disease diagnosis is parametrically determined by the stopping criteria. In DxFormer, we treat each symptom as a token, and formalize the symptom inquiry and disease diagnosis to a language generation model and a sequence classification model, respectively. We use the inverted version of Transformer, i.e. the decoder–encoder structure, to learn the representation of symptoms by jointly optimizing the reinforce reward and cross-entropy loss. Results: We conduct experiments on three real-world medical dialogue datasets, and the experimental results verify the feasibility of increasing diagnostic accuracy by improving symptom recall. Our model overcomes the shortcomings of previous RL-based methods. By decoupling symptom query from the process of diagnosis, DxFormer greatly improves the symptom recall and achieves the state-of-the-art diagnostic accuracy. © The Author(s) 2022. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Le, K.T.
AU  - Rashidi, G.
AU  - Andrzejak, A.
TI  - A methodology for refined evaluation of neural code completion approaches
PY  - 2023
T2  - Data Mining and Knowledge Discovery
VL  - 37
IS  - 1
SP  - 167
EP  - 204
DO  - 10.1007/s10618-022-00866-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141198125&doi=10.1007%2fs10618-022-00866-9&partnerID=40&md5=e4e8c69ed346985499ee7aaeec5e029c
AB  - Code completion has become an indispensable feature of modern Integrated Development Environments. In recent years, many approaches have been proposed to tackle this task. However, it is hard to compare between the models without explicitly re-evaluating them due to the differences of used benchmarks (e.g. datasets and evaluation metrics). Besides, almost all of these works report the accuracy of the code completion models as aggregated metrics averaged over all types of code tokens. Such evaluations make it difficult to assess the potential improvements for particularly relevant types of tokens (i.e. method or variable names), and blur the differences between the performance of the methods. In this paper, we propose a methodology called Code Token Type Taxonomy (CT3) to address the issue of using aggregated metrics. We identify multiple dimensions relevant for code prediction (e.g. syntax type, context, length), partition the tokens into meaningful types along each dimension, and compute individual accuracies by type. We illustrate the utility of this methodology by comparing the code completion accuracy of a Transformer-based model in two variants: with closed, and with open vocabulary. Our results show that the refined evaluation provides a more detailed view of the differences and indicates where further work is needed. We also survey the state-of-the-art of Machine Learning-based code completion models to illustrate that there is a demand for a set of standardized benchmarks for code completion approaches. Furthermore, we find that the open vocabulary model is significantly more accurate for relevant code token types such as usage of (defined) variables and literals. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kim, G.
AU  - Kim, H.
AU  - Kong, K.
AU  - Song, J.-W.
AU  - Kang, S.-J.
TI  - Human Body-Aware Feature Extractor Using Attachable Feature Corrector for Human Pose Estimation
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 5789
EP  - 5799
DO  - 10.1109/TMM.2022.3199098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136842708&doi=10.1109%2fTMM.2022.3199098&partnerID=40&md5=cc2f22f08b799298b3568dad931ef6da
AB  - Top-down pose estimation generally employs a person detector and estimates the keypoints of the detected person. This method assumes that only a single person exists within the bounding box cropped by detection. However, this assumption leads to some challenges in practice. First, a loose-fitted bounding box may include certain body parts of a non-target person. Second, spatial interference between several people exists owing to occlusion, so more than a single person can exist in the cropped image. In such scenarios, the pose estimation may falsely predict the keypoints of two or more persons as those of a single person. To tackle these issues, this paper proposes the human body-aware feature extractor based on the global- and local-reasoning features. The global-reasoning feature considers the entire body using transformer's non-local computation property and the local-reasoning feature concentrates on the individual body parts using convolutional neural networks. With those two features, we extract corrected features by filtering unnecessary features and supplementing necessary features using our proposed novel architecture. Hence, the proposed method can focus on the target person's keypoints, thereby mitigating the aforementioned concerns. Our method achieves noticeable improvement when applied to state-of-the-art top-down pose estimation networks.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Deng, H.
AU  - Yang, Z.
AU  - Hao, T.
AU  - Li, Q.
AU  - Liu, W.
TI  - Multimodal Affective Computing With Dense Fusion Transformer for Inter- and Intra-Modality Interactions
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 6575
EP  - 6587
DO  - 10.1109/TMM.2022.3211197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139501560&doi=10.1109%2fTMM.2022.3211197&partnerID=40&md5=d3dbeff7d1ec87d7ca11514af22ecd63
AB  - This paper proposes a dense fusion transformer (DFT) framework to integrate textual, acoustic, and visual information for multimodal affective computing. DFT exploits a modality-shared transformer (MT) module to extract the modality-shared features by modelling unimodal, bimodal, and trimodal interactions jointly. MT constructs a series of dense fusion blocks to fuse utterance-level sequential features of the multiple modalities from the perspectives of low-level and high-level semantics. In particular, MT adopts local and global transformers to learn modality-shared representations by modelling inter- and intra-modality interactions. Furthermore, we devise a modality-specific representation (MR) module with a soft orthogonality constraint to penalize the distance between modality-specific and modality-shared representations, which are fused by a transformer to make affective predictions. Extensive experiments conducted on five public benchmark datasets show that DFT outperforms the state-of-the-art baselines.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pang, Y.
AU  - Yao, L.
AU  - Xu, J.
AU  - Wang, Z.
AU  - Lee, T.-Y.
TI  - Integrating transformer and imbalanced multi-label learning to identify antimicrobial peptides and their functional activities
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 24
SP  - 5368
EP  - 5374
DO  - 10.1093/bioinformatics/btac711
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144585853&doi=10.1093%2fbioinformatics%2fbtac711&partnerID=40&md5=3b04561332c151ad34a1b15283160a20
AB  - Motivation: Antimicrobial peptides (AMPs) have the potential to inhibit multiple types of pathogens and to heal infections. Computational strategies can assist in characterizing novel AMPs from proteome or collections of synthetic sequences and discovering their functional abilities toward different microbial targets without intensive labor. Results: Here, we present a deep learning-based method for computer-aided novel AMP discovery that utilizes the transformer neural network architecture with knowledge from natural language processing to extract peptide sequence information. We implemented the method for two AMP-related tasks: the first is to discriminate AMPs from other peptides, and the second task is identifying AMPs functional activities related to seven different targets (gram-negative bacteria, gram-positive bacteria, fungi, viruses, cancer cells, parasites and mammalian cell inhibition), which is a multi-label problem. In addition, asymmetric loss was adopted to resolve the intrinsic imbalance of dataset, particularly for the multi-label scenarios. The evaluation showed that our proposed scheme achieves the best performance for the first task (96.85% balanced accuracy) and has a more unbiased prediction for the second task (79.83% balanced accuracy averaged across all functional activities) when compared with that of strategies without imbalanced learning or deep learning. © 2022 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Zhu, Y.-H.
AU  - Zhang, C.
AU  - Yu, D.-J.
AU  - Zhang, Y.
TI  - Integrating unsupervised language model with triplet neural networks for protein gene ontology prediction
PY  - 2022
T2  - PLoS Computational Biology
VL  - 18
IS  - 12
C7  - e1010793
DO  - 10.1371/journal.pcbi.1010793
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144617184&doi=10.1371%2fjournal.pcbi.1010793&partnerID=40&md5=d0e572a188f4db33aebbd18d37714bfc
AB  - Accurate identification of protein function is critical to elucidate life mechanisms and design new drugs. We proposed a novel deep-learning method, ATGO, to predict Gene Ontology (GO) attributes of proteins through a triplet neural-network architecture embedded with pre-trained language models from protein sequences. The method was systematically tested on 1068 non-redundant benchmarking proteins and 3328 targets from the third Critical Assessment of Protein Function Annotation (CAFA) challenge. Experimental results showed that ATGO achieved a significant increase of the GO prediction accuracy compared to the state-of-the-art approaches in all aspects of molecular function, biological process, and cellular component. Detailed data analyses showed that the major advantage of ATGO lies in the utilization of pre-trained transformer language models which can extract discriminative functional pattern from the feature embeddings. Meanwhile, the proposed triplet network helps enhance the association of functional similarity with feature similarity in the sequence embedding space. In addition, it was found that the combination of the network scores with the complementary homology-based inferences could further improve the accuracy of the predicted models. These results demonstrated a new avenue for high-accuracy deep-learning function prediction that is applicable to large-scale protein function annotations from sequence alone. © 2022 Zhu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pei, J.
AU  - Cheng, T.
AU  - Tang, H.
AU  - Chen, C.
TI  - Transformer-Based Efficient Salient Instance Segmentation Networks With Orientative Query
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 1964
EP  - 1978
DO  - 10.1109/TMM.2022.3141891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123358612&doi=10.1109%2fTMM.2022.3141891&partnerID=40&md5=e0f4dc9f8ba83d4f6a11924b06572d2a
AB  - Salient instance segmentation (SIS) can be considered as the next generation task for the saliency detection community. Most of the existing state-of-the-art methods used for this novel challenging task are built on the mainstream Mask R-CNN architecture. However, this mechanism relies heavily on hand-designed anchors and NMS post-processing. In this paper, we provide a one stage SIS framework with transformers, termed Orientative Query Transformer (OQTR). To leverage the long-range dependencies of transformers, a cross fusion module is designed to efficiently fuse the global features in the encoder and salient query features for salient mask prediction. Furthermore, derived from the center prior in traditional saliency models, we propose an orientative query that is considered as the initial salient object query to accelerate convergence. In addition, to mitigate the issue of the lack of a large-scale dataset with salient instance labels, we collect a new SIS dataset (SIS10 K) containing over 10 K images elaborately annotated with both object- and instance-level labels to promote the community. Without any post-processing, our end-to-end OQTR framework significantly surpasses the top-1 RDPNet by an average of 13.1% AP scores across all three challenging datasets, demonstrating the strong performance of the proposed OQTR.  © 2021 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, F.
AU  - Zheng, K.
AU  - Lu, L.
AU  - Xiao, J.
AU  - Wu, M.
AU  - Kuo, C.-F.
AU  - Miao, S.
TI  - Lumbar Bone Mineral Density Estimation From Chest X-Ray Images: Anatomy-Aware Attentive Multi-ROI Modeling
PY  - 2023
T2  - IEEE Transactions on Medical Imaging
VL  - 42
IS  - 1
SP  - 257
EP  - 267
DO  - 10.1109/TMI.2022.3209648
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139528821&doi=10.1109%2fTMI.2022.3209648&partnerID=40&md5=41b799d68e2b4c73bf2c9c765bc2430c
AB  - Osteoporosis is a common chronic metabolic bone disease often under-diagnosed and under-treated due to the limited access to bone mineral density (BMD) examinations, e.g., via Dual-energy X-ray Absorptiometry (DXA). This paper proposes a method to predict BMD from Chest X-ray (CXR), one of the most commonly accessible and low-cost medical imaging examinations. The proposed method first automatically detects Regions of Interest (ROIs) of local CXR bone structures. Then a multi-ROI deep model with transformer encoder is developed to exploit both local and global information in the chest X-ray image for accurate BMD estimation. The proposed method is evaluated on 13719 CXR patient cases with ground truth BMD measured by the gold standard DXA. The model predicted BMD has a strong correlation with the ground truth (Pearson correlation coefficient 0.894 on lumbar 1). When applied in osteoporosis screening, it achieves a high classification performance (average AUC of 0.968). As the first effort of using CXR scans to predict the BMD, the proposed algorithm holds strong potential to promote early osteoporosis screening and public health.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Liao, L.
AU  - Gao, Y.
AU  - Wang, R.
AU  - Huang, H.
TI  - TopicBERT: A Topic-Enhanced Neural Language Model Fine-Tuned for Sentiment Classification
PY  - 2023
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 34
IS  - 1
SP  - 380
EP  - 393
DO  - 10.1109/TNNLS.2021.3094987
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112172672&doi=10.1109%2fTNNLS.2021.3094987&partnerID=40&md5=6b85d4d63f29078e5a20fab086ec0b56
AB  - Sentiment classification is a form of data analytics where people's feelings and attitudes toward a topic are mined from data. This tantalizing power to 'predict the zeitgeist' means that sentiment classification has long attracted interest, but with mixed results. However, the recent development of the BERT framework and its pretrained neural language models is seeing new-found success for sentiment classification. BERT models are trained to capture word-level information via mask language modeling and sentence-level contexts via next sentence prediction tasks. Out of the box, they are adequate models for some natural language processing tasks. However, most models are further fine-tuned with domain-specific information to increase accuracy and usefulness. Motivated by the idea that a further fine-tuning step would improve the performance for downstream sentiment classification tasks, we developed TopicBERT - a BERT model fine-tuned to recognize topics at the corpus level in addition to the word and sentence levels. TopicBERT comprises two variants: TopicBERT-ATP (aspect topic prediction), which captures topic information via an auxiliary training task, and TopicBERT-TA, where topic representation is directly injected into a topic augmentation layer for sentiment classification. With TopicBERT-ATP, the topics are predetermined by an LDA mechanism and collapsed Gibbs sampling. With TopicBERT-TA, the topics can change dynamically during the training. Experimental results show that both approaches deliver the state-of-the-art performance in two different domains with SemEval 2014 Task 4. However, in a test of methods, direct augmentation outperforms further training. Comprehensive analyses in the form of ablation, parameter, and complexity studies accompany the results.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fu, X.
AU  - Deng, H.
AU  - Yuan, X.
AU  - Hu, J.
TI  - Generating High Coherence Monophonic Music Using Monte-Carlo Tree Search
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 3763
EP  - 3772
DO  - 10.1109/TMM.2022.3165718
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128339609&doi=10.1109%2fTMM.2022.3165718&partnerID=40&md5=5b77030bc51a3749b59f28258efe7b16
AB  - Music generation task is commonly considered as a note-by-note prediction problem. Moreover, prediction models generating one musical note at a time may ignore the overall coherence because the music phrase is incomplete and unable to demonstrate musicality. To address these issues, in this study, we propose a feasible monophonic music generation framework that can simulate subsequent trends for each predicted musical note. The framework generates a musical note mainly in three steps: 1) a sequence prediction model is used to predict the most potential candidates, 2) the subsequent trends for each candidate are modeled and evaluated, and 3) the best candidate is selected as the final result. We use the Monte-Carlo tree search algorithm because of its great capability of discovering near-optimal results. We establish a method of training a value network that can assess musical coherence to evaluate the simulated sequences. Further, we used a smoothed polynomial upper confidence trees algorithm to improve the accuracy and efficiency of the search process. An accurate dataset labeled by us, which contains 36 transcribed samples from real-world pop songs, was used to validate our framework. Compared with the note-by-note sequence prediction model, our framework exhibits a better sense of musicality. Our framework can be applied to generate symbolic monophonic music, particularly the main melody track in pop music.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Guo, Y.
AU  - Song, J.
AU  - Gao, L.
AU  - Shen, H.T.
TI  - AMANet: Adaptive Multi-Path Aggregation for Learning Human 2D-3D Correspondences
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 979
EP  - 992
DO  - 10.1109/TMM.2021.3135145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121763539&doi=10.1109%2fTMM.2021.3135145&partnerID=40&md5=e5d5c22e6807b6666eafd0eeb7174a30
AB  - Learning human 2D-3D correspondences aims to map all human 2D pixels to a 3D human template, namely human densepose estimation, involving surface patch recognition (i.e., Index-to-Patch (I)) and regression of patch-specific UV coordinates. Despite recent progress, it remains challenging especially under the condition of 'in the wild', where RGB images capture real-world scenes with backgrounds, occlusions, scale variations, and postural diversity. In this paper, we address three vital problems in this task: 1) how to perceive multi-scale visual information for instances 'in the wild'; 2) how to design learning objectives to address the precise instance representation harassed by 'multiple instances in one bounding box' phenomenon; and 3) how to boost the performance of index-to-patch prediction faced by limited supervision. To tackle problems above, we propose an end-to-end deep Adaptive Multi-path Aggregation network (AMA-net) for Human DensePose Estimation. First, we introduce an adaptive multi-path aggregation algorithm to extract varying-sized instance-level features, which capture multi-scale information of a bounding-box and are then utilized for parsing different instances. Second, we adopt an instance augmentation learning objective to further distinguish the target instance from other interference instances. Third, taking advantage of 2D human parsers that are trained from sufficient annotations, we introduce a task transformer that bridges the 'gap' between 2D human parsing and densepose estimation, thus benefiting the performance of densepose estimator. Experimental results on the challenging DensePose-COCO dataset demonstrate that our approach sets a new record, and it significantly outperforms the state-of-the-art methods. Codes and models are publicly available.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, Y.
AU  - Ji, J.
AU  - Sun, X.
AU  - Zhou, Y.
AU  - Wu, Y.
AU  - Huang, F.
AU  - Ji, R.
TI  - Knowing What it is: Semantic-Enhanced Dual Attention Transformer
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 3723
EP  - 3736
DO  - 10.1109/TMM.2022.3164787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127740921&doi=10.1109%2fTMM.2022.3164787&partnerID=40&md5=1b3e13f6b64286daaca3515a936da743
AB  - Attention has become an indispensable component of the models of various multimedia tasks like Image Captioning (IC) and Visual Question Answering (VQA). However, most existing attention modules are designed for capturing the spatial dependency, and are still insufficient in semantic understanding, e.g., the categories of objects and their attributes, which is also critical for image captioning. To compensate for this defect, we propose a novel attention module termed Channel-wise Attention Block (CAB) to model channel-wise dependency for both visual modality and linguistic modality, thereby improving semantic learning and multi-modal reasoning simultaneously. Specifically, CAB has two novel designs to tackle with the high overhead of channel-wise attention, which are the reduction-reconstruction block structure and the gating-based attention prediction. Based on CAB, we further propose a novel Semantic-enhanced Dual Attention Transformer (termed SDATR), which combines the merits of spatial and channel-wise attentions. To validate SDATR, we conduct extensive experiments on the MS COCO dataset and yield new state-of-the-art performance of 134.5 CIDEr score on COCO Karpathy test split and 136.0 CIDEr score on the official online testing server. To examine the generalization of SDATR, we also apply it to the task of visual question answering, where superior performance gains are also witnessed. The code and models are publicly available at https://github.com/xmu-xiaoma666/SDATR.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Zhang, S.
AU  - Cui, Z.
AU  - Li, Z.
AU  - Xie, J.
AU  - Yang, J.
TI  - Tube-Embedded Transformer for Pixel Prediction
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 2503
EP  - 2514
DO  - 10.1109/TMM.2022.3147664
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124221672&doi=10.1109%2fTMM.2022.3147664&partnerID=40&md5=58d8a524b12b0b8a40e4e00b1d98e7fc
AB  - Multi-task pixel-level learning, which aims to exploit the inter-task interactions to improve the learning of each task, is an important but challenging issue in visual perception and multimedia applications. Measuring the inter-task correlation and intra-task specificity, we propose a tube-embedded transformer (TET) framework for robust multi-task pixel prediction. To facilitate inter-task interactions, we aggregate and project all tasks into a shared tube pool to generate the latent multi-task representation during the coarse-to-fine decoding stages. The resulting task-tube interactions replace the two-by-two task-task interactions to reduce the model complexity significantly. In addition, we introduce the transformer mechanism to adaptively transfer tube features to the target task. Concretely, on the one hand, multi-task features aggregate in the tube to generate the shared feature representation bases; on the other hand, based on the task-tube association and complementarity, the tube outputs the query entry and the weighting coefficients of the target task. Experimentally, on the joint learning of semantic segmentation, depth estimation, and surface normal estimation, the comparison experiments show the superiority of the TET multi-task learning method over other state-of-the-art approaches, and the ablation experiments verify the effectiveness of the TET mechanism. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Du, W.
AU  - Chen, S.
AU  - Li, H.
AU  - Li, Z.
AU  - Cao, X.
AU  - Lv, Y.
TI  - Airport Capacity Prediction With Multisource Features: A Temporal Deep Learning Approach
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 1
SP  - 615
EP  - 630
DO  - 10.1109/TITS.2022.3213029
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140720706&doi=10.1109%2fTITS.2022.3213029&partnerID=40&md5=be17508f2cca3af3224ec0c7fef28964
AB  - Accurate airport capacity estimation is crucial for the secure and orderly operation of the aviation system. However, such estimation is a non-trivial task as capacity depends on various meteorological and operational features. The complex coupling characteristics among these multi-source features have proved to be challenging for most of the traditional regression models. Recently, enhanced by its excellent ability to mine nonlinear relationships, the machine learning methods trigger widely applications. However, due to the imbalance of features scatter and the neglect of temporal dependences in aviation systems, existing machine learning methods for airport capacity prediction still have room for improvement. In light of these, this paper presents a novel airport capacity prediction method based on the multi-channel fusion Transformer model (MF-Transformer). Besides the commonly used aviation features, we unprecedentedly harness the power of the high-dimensional meteorological feature for accurate prediction. As to the model, we construct a multi-channel feature fusion structure, which includes a three-channel network for multi-source features extraction and an attention-based feature fusion module between channels. In each channel, the Transformer-based model is utilized to capture the temporal dependences of features. We conduct experiments on the capacity prediction tasks of the Beijing Capital International Airport which is the largest airport in China and verify that the proposed MF-Transformer outperforms benchmarks under different prediction horizons.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; FMS:B; 
LB  - Du2023Airport
ER  -

TY  - JOUR
AU  - Deng, X.
AU  - Feng, S.
AU  - Lyu, G.
AU  - Wang, T.
AU  - Lang, C.
TI  - Beyond Word Embeddings: Heterogeneous Prior Knowledge Driven Multi-Label Image Classification
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 4013
EP  - 4025
DO  - 10.1109/TMM.2022.3171095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129383791&doi=10.1109%2fTMM.2022.3171095&partnerID=40&md5=51c9332cd02bce1d0fa821700dcca2b7
AB  - Multi-Label Image Classification (MLIC) is a fundamental yet challenging task which aims to recognize multiple labels from given images. The key to solve MLIC lies in how to accurately model the correlation between labels. Recent studies often adopt Graph Convolutional Network (GCN) to model label dependencies with word embeddings as prior knowledge. However, classical word embeddings typically contain redundant information due to the imperfect distributional hypothesis it relies on, which may degrade model generalizability. To tackle this problem, we propose a novel deep learning framework termed Visual-Semantic based Graph Convolutional Network (VSGCN), which alleviates the negative impact of redundant information by utilizing heterogeneous sources of prior knowledge. Specifically, we construct both visual prototype and semantic prototype for each label as heterogeneous prior label representations, which are further mapped to multi-label classifiers via two Multi-Head GCNs separately. The Multi-Head GCN mechanism proposed in this paper aims to guide the information propagation between prototypes for each label, which constructs multiple correlation graphs to simultaneously model the label correlation in different subspaces. Notably, we alleviate the negative influence of needless information by decreasing the inconsistency of predictions that come from visual space and semantic space. Extensive experiments conducted on various multi-label image datasets demonstrate the superiority of our proposed method.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Wang, Y.
AU  - Chau, L.-P.
TI  - Moving Towards Centers: Re-Ranking With Attention and Memory for Re-Identification
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 3456
EP  - 3468
DO  - 10.1109/TMM.2022.3161189
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127055338&doi=10.1109%2fTMM.2022.3161189&partnerID=40&md5=307d40f18e52f484185fa70ad8a12ad1
AB  - Re-ranking utilizes contextual information to optimize the initial ranking list of person or vehicle re-identification (re-ID), which boosts the retrieval performance at post-processing steps. This paper proposes a re-ranking network to predict the correlations between the probe and top-ranked neighbor samples. Specifically, all the feature embeddings of query and gallery images are expanded and enhanced by a linear combination of their neighbors, with the correlation prediction serving as discriminative combination weights. The combination process is equivalent to moving independent embeddings toward the identity centers, improving cluster compactness. For correlation prediction, we first aggregate the contextual information for probe's k-nearest neighbors via the Transformer encoder. Then, we distill and refine the probe-related features into the Contextual Memory cell via attention mechanism. Like humans that retrieve images by not only considering probe images but also memorizing the retrieved ones, the Contextual Memory produces multi-view descriptions for each instance. Finally, the neighbors are reconstructed with features fetched from the Contextual Memory, and a binary classifier predicts their correlations with the probe. Experiments on six widely-used person and vehicle re-ID benchmarks demonstrate the effectiveness of the proposed method. Especially, our method surpasses the state-of-the-art re-ranking approaches on large-scale datasets by a significant margin, i.e., with an average 4.83% CMC@1 and 14.83% mAP improvements on VERI-Wild, MSMT17, and VehicleID datasets.  © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, M.
AU  - Suo, W.
AU  - Wang, P.
AU  - Zhang, Y.
AU  - Wu, Q.
TI  - A Proposal-Free One-Stage Framework for Referring Expression Comprehension and Generation via Dense Cross-Attention
PY  - 2023
T2  - IEEE Transactions on Multimedia
VL  - 25
SP  - 2446
EP  - 2458
DO  - 10.1109/TMM.2022.3147385
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124223753&doi=10.1109%2fTMM.2022.3147385&partnerID=40&md5=ca59f5e16a1e516615af0d6c1a487903
AB  - Referring Expression Comprehension (REC) and Generation (REG) have become one of the most important tasks in visual reasoning, since it is an essential step for many vision-and-language tasks such as visual question answering or visual dialogue. However, it has not been widely used in many downstream tasks, mainly for the following reasons: 1) mainstream two-stage methods rely on additional annotations or off-the-shelf detectors to generate proposals. It would heavily degrade the generalization ability of models and lead to inevitable error accumulation. 2) Although one-stage strategies for REC have been proposed, these methods have to depend on lots of hyper-parameters (such as anchors) to generate bounding box. In this paper, we present a proposal-free one-stage (PFOS) framework that can directly regress the region-of-interest from the image or generate unambiguous descriptions in an end-to-end manner. Instead of using the dominant two-stage fashion, we take the dense-grid of images as input for a cross-attention transformer that learns multi-modal correspondences. The final bounding box or sentence is directly predicted from the image without the anchor selection or the computation of visual difference. Furthermore, we expand the traditional two-stage listener-speaker framework to jointly train by a one-stage learning paradigm. Our model achieves state-of-the-art performance on both accuracy and speed for comprehension and competitive results for generation.  © 2021 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yi, S.
AU  - Liu, X.
AU  - Li, J.
AU  - Chen, L.
TI  - UAVformer: A Composite Transformer Network for Urban Scene Segmentation of UAV Images
PY  - 2023
T2  - Pattern Recognition
VL  - 133
C7  - 109019
DO  - 10.1016/j.patcog.2022.109019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137696709&doi=10.1016%2fj.patcog.2022.109019&partnerID=40&md5=f274a93034957d3656c74b645bd97311
AB  - Urban scenes segmentation based on UAV (Unmanned aerial vehicle) view is a fundamental task for the applications of smart city such as city planning, land use monitoring, traffic monitoring, and crowd estimation. While urban scenes in UAV image characteristic by large scale variation of objects size and complexity background, which posed challenges to urban scenes segmentation of UAV image. The feature extracting backbone of existing networks cannot extract complex features of UAV image effectively, which limits the performance of urban scenes segmentation. To design segmentation network capable of extracting features of large scale variation urban ground scenes, this study proposed a novel composite transformer network for urban scenes segmentation of UAV image. A composite backbone with aggregation windows multi-head self-attention transformer blocks is proposed to make the extracted features more representatives by adaptive multi-level features fusion, and the full utilisation of contextual information and local information. Position attention modules are inserted in each stage between encoder and decoder to further enhance the spatial attention of extracted feature maps. Finally, a V-shaped decoder which is capable of utilising multi-level features is designed to get accurately dense prediction. The accuracy of urban scenes segmentation could significantly be enhanced in this way and successfully segmented the large scale variation objects from UAV views. Extensive ablation experiments and comparative experiments for the proposed network have been conducted on the public available urban scenes segmentation datasets for UAV imagery. Experimental results have demonstrated the effectiveness of designed network structure and the superiority of proposed network over state-of-the-art methods. Specifically, reached 53.2% mIoU on the UAVid dataset and 77.6% mIoU on the UDD6 dataset, respectively. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Probst, D.
AU  - Manica, M.
AU  - Nana Teukam, Y.G.
AU  - Castrogiovanni, A.
AU  - Paratore, F.
AU  - Laino, T.
TI  - Biocatalysed synthesis planning using data-driven learning
PY  - 2022
T2  - Nature Communications
VL  - 13
IS  - 1
C7  - 964
DO  - 10.1038/s41467-022-28536-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124922491&doi=10.1038%2fs41467-022-28536-w&partnerID=40&md5=3c4b31ad0b38160932ce2cbab808055a
AB  - Enzyme catalysts are an integral part of green chemistry strategies towards a more sustainable and resource-efficient chemical synthesis. However, the use of biocatalysed reactions in retrosynthetic planning clashes with the difficulties in predicting the enzymatic activity on unreported substrates and enzyme-specific stereo- and regioselectivity. As of now, only rule-based systems support retrosynthetic planning using biocatalysis, while initial data-driven approaches are limited to forward predictions. Here, we extend the data-driven forward reaction as well as retrosynthetic pathway prediction models based on the Molecular Transformer architecture to biocatalysis. The enzymatic knowledge is learned from an extensive data set of publicly available biochemical reactions with the aid of a new class token scheme based on the enzyme commission classification number, which captures catalysis patterns among different enzymes belonging to the same hierarchy. The forward reaction prediction model (top-1 accuracy of 49.6%), the retrosynthetic pathway (top-1 single-step round-trip accuracy of 39.6%) and the curated data set are made publicly available to facilitate the adoption of enzymatic catalysis in the design of greener chemistry processes. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Aldahdooh, J.
AU  - Vähä-Koskela, M.
AU  - Tang, J.
AU  - Tanoli, Z.
TI  - Using BERT to identify drug-target interactions from whole PubMed
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 245
DO  - 10.1186/s12859-022-04768-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132303874&doi=10.1186%2fs12859-022-04768-x&partnerID=40&md5=ff690fbee985d16b8fba3e1967bf5d10
AB  - Background: Drug-target interactions (DTIs) are critical for drug repurposing and elucidation of drug mechanisms, and are manually curated by large databases, such as ChEMBL, BindingDB, DrugBank and DrugTargetCommons. However, the number of curated articles likely constitutes only a fraction of all the articles that contain experimentally determined DTIs. Finding such articles and extracting the experimental information is a challenging task, and there is a pressing need for systematic approaches to assist the curation of DTIs. To this end, we applied Bidirectional Encoder Representations from Transformers (BERT) to identify such articles. Because DTI data intimately depends on the type of assays used to generate it, we also aimed to incorporate functions to predict the assay format. Results: Our novel method identified 0.6 million articles (along with drug and protein information) which are not previously included in public DTI databases. Using 10-fold cross-validation, we obtained ~ 99% accuracy for identifying articles containing quantitative drug-target profiles. The F1 micro for the prediction of assay format is 88%, which leaves room for improvement in future studies. Conclusion: The BERT model in this study is robust and the proposed pipeline can be used to identify previously overlooked articles containing quantitative DTIs. Overall, our method provides a significant advancement in machine-assisted DTI extraction and curation. We expect it to be a useful addition to drug mechanism discovery and repurposing. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Aldahdooh2022Using
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Guo, F.
AU  - Du, M.
AU  - Wang, G.
AU  - Cao, C.
TI  - A novel method for drug-target interaction prediction based on graph transformers model
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 459
DO  - 10.1186/s12859-022-04812-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141159323&doi=10.1186%2fs12859-022-04812-w&partnerID=40&md5=a8f56b63b74a764a09a39994f8b55af2
AB  - Background: Drug-target interactions (DTIs) prediction becomes more and more important for accelerating drug research and drug repositioning. Drug-target interaction network is a typical model for DTIs prediction. As many different types of relationships exist between drug and target, drug-target interaction network can be used for modeling drug-target interaction relationship. Recent works on drug-target interaction network are mostly concentrate on drug node or target node and neglecting the relationships between drug-target. Results: We propose a novel prediction method for modeling the relationship between drug and target independently. Firstly, we use different level relationships of drugs and targets to construct feature of drug-target interaction. Then, we use line graph to model drug-target interaction. After that, we introduce graph transformer network to predict drug-target interaction. Conclusions: This method introduces a line graph to model the relationship between drug and target. After transforming drug-target interactions from links to nodes, a graph transformer network is used to accomplish the task of predicting drug-target interactions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Wang2022novel
ER  -

TY  - JOUR
AU  - Duan, B.
AU  - Peng, J.
AU  - Zhang, Y.
TI  - IMSE: interaction information attention and molecular structure based drug drug interaction extraction
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
C7  - 338
DO  - 10.1186/s12859-022-04876-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135952210&doi=10.1186%2fs12859-022-04876-8&partnerID=40&md5=2fbdb145e909c8e899e8c5c7c9530036
AB  - Background: Extraction of drug drug interactions from biomedical literature and other textual data is an important component to monitor drug-safety and this has attracted attention of many researchers in healthcare. Existing works are more pivoted around relation extraction using bidirectional long short-term memory networks (BiLSTM) and BERT model which does not attain the best feature representations. Results: Our proposed DDI (drug drug interaction) prediction model provides multiple advantages: (1) The newly proposed attention vector is added to better deal with the problem of overlapping relations, (2) The molecular structure information of drugs is integrated into the model to better express the functional group structure of drugs, (3) We also added text features that combined the T-distribution and chi-square distribution to make the model more focused on drug entities and (4) it achieves similar or better prediction performance (F-scores up to 85.16%) compared to state-of-the-art DDI models when tested on benchmark datasets. Conclusions: Our model that leverages state of the art transformer architecture in conjunction with multiple features can bolster the performances of drug drug interation tasks in the biomedical domain. In particular, we believe our research would be helpful in identification of potential adverse drug reactions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Duan2022IMSE
ER  -

TY  - JOUR
AU  - Zheng, S.
AU  - Zeng, T.
AU  - Li, C.
AU  - Chen, B.
AU  - Coley, C.W.
AU  - Yang, Y.
AU  - Wu, R.
TI  - Deep learning driven biosynthetic pathways navigation for natural products with BioNavi-NP
PY  - 2022
T2  - Nature Communications
VL  - 13
IS  - 1
C7  - 3342
DO  - 10.1038/s41467-022-30970-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131725290&doi=10.1038%2fs41467-022-30970-9&partnerID=40&md5=15b9f7cb79d4ae3b9fe818d256cd6b84
AB  - The complete biosynthetic pathways are unknown for most natural products (NPs), it is thus valuable to make computer-aided bio-retrosynthesis predictions. Here, a navigable and user-friendly toolkit, BioNavi-NP, is developed to predict the biosynthetic pathways for both NPs and NP-like compounds. First, a single-step bio-retrosynthesis prediction model is trained using both general organic and biosynthetic reactions through end-to-end transformer neural networks. Based on this model, plausible biosynthetic pathways can be efficiently sampled through an AND-OR tree-based planning algorithm from iterative multi-step bio-retrosynthetic routes. Extensive evaluations reveal that BioNavi-NP can identify biosynthetic pathways for 90.2% of 368 test compounds and recover the reported building blocks as in the test set for 72.8%, 1.7 times more accurate than existing conventional rule-based approaches. The model is further shown to identify biologically plausible pathways for complex NPs collected from the recent literature. The toolkit as well as the curated datasets and learned models are freely available to facilitate the elucidation and reconstruction of the biosynthetic pathways for NPs. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 57
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lian, J.
AU  - Yu, F.
AU  - Li, L.
AU  - Zhou, Y.
TI  - Causal Temporal-Spatial Pedestrian Trajectory Prediction With Goal Point Estimation and Contextual Interaction
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 24499
EP  - 24509
DO  - 10.1109/TITS.2022.3204342
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139395100&doi=10.1109%2fTITS.2022.3204342&partnerID=40&md5=6a123ad332d18f5959ba0b0304ea6007
AB  - Forecasting pedestrian trajectories in complex dynamic environments is highly critical for the application of autonomous vehicles and robots. Accordingly, this paper proposes a novel pedestrian trajectory prediction model called CTSGI, which, utilizes self-attention mechanism to construct an interactive graph between pedestrians and their neighbors based on their spatial relationship, to model the crowd's interaction. At the same time, it uses self-attention to extract the temporal dependence for a single pedestrian. In order to effectively model the interaction between the pedestrian and the context, such as where a pedestrian can walk or approach, the semantic segmentation of background image is utilized. CTSGI estimates the goal points of pedestrian and their neighbors to assist in predicting the future trajectory. In addition, the causal structure model is used to analyze the confounding factors existing in the encoding stage, and Do-calculus is introduced for eliminating the confounding impact to improve the prediction performance. Moreover, extensive experiments are conducted for the proposed model on ETH and UCY datasets, and clearly, the experimental results reveal that the model reported herein outperforms the comparative state-of-the-art methods by 27.59% in Average Displacement Error (ADE) and 8.33% in Final Displacement Error (FDE). Furthermore, visualization of attention indicates that our model can capture the interaction between some specific pedestrian and their neighbors better. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Lian2022Causal
ER  -

TY  - JOUR
AU  - Salem, M.
AU  - Keshavarzi Arshadi, A.
AU  - Yuan, J.S.
TI  - AMPDeep: hemolytic activity prediction of antimicrobial peptides using transfer learning
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 389
DO  - 10.1186/s12859-022-04952-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138602005&doi=10.1186%2fs12859-022-04952-z&partnerID=40&md5=2125c41f02770a53515428c6040c8433
AB  - Background: Deep learning’s automatic feature extraction has proven to give superior performance in many sequence classification tasks. However, deep learning models generally require a massive amount of data to train, which in the case of Hemolytic Activity Prediction of Antimicrobial Peptides creates a challenge due to the small amount of available data. Results: Three different datasets for hemolysis activity prediction of therapeutic and antimicrobial peptides are gathered and the AMPDeep pipeline is implemented for each. The result demonstrate that AMPDeep outperforms the previous works on all three datasets, including works that use physicochemical features to represent the peptides or those who solely rely on the sequence and use deep learning to learn representation for the peptides. Moreover, a combined dataset is introduced for hemolytic activity prediction to address the problem of sequence similarity in this domain. AMPDeep fine-tunes a large transformer based model on a small amount of peptides and successfully leverages the patterns learned from other protein and peptide databases to assist hemolysis activity prediction modeling. Conclusions: In this work transfer learning is leveraged to overcome the challenge of small data and a deep learning based model is successfully adopted for hemolysis activity classification of antimicrobial peptides. This model is first initialized as a protein language model which is pre-trained on masked amino acid prediction on many unlabeled protein sequences in a self-supervised manner. Having done so, the model is fine-tuned on an aggregated dataset of labeled peptides in a supervised manner to predict secretion. Through transfer learning, hyper-parameter optimization and selective fine-tuning, AMPDeep is able to achieve state-of-the-art performance on three hemolysis datasets using only the sequence of the peptides. This work assists the adoption of large sequence-based models for peptide classification and modeling tasks in a practical manner. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Salem2022AMPDeep
ER  -

TY  - JOUR
AU  - Hong, Y.
AU  - Lee, J.
AU  - Ko, J.
TI  - A-Prot: protein structure modeling using MSA transformer
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 93
DO  - 10.1186/s12859-022-04628-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126333729&doi=10.1186%2fs12859-022-04628-8&partnerID=40&md5=cd2fbb48c4c6729caf6a447776b6c958
AB  - Background: The accuracy of protein 3D structure prediction has been dramatically improved with the help of advances in deep learning. In the recent CASP14, Deepmind demonstrated that their new version of AlphaFold (AF) produces highly accurate 3D models almost close to experimental structures. The success of AF shows that the multiple sequence alignment of a sequence contains rich evolutionary information, leading to accurate 3D models. Despite the success of AF, only the prediction code is open, and training a similar model requires a vast amount of computational resources. Thus, developing a lighter prediction model is still necessary. Results: In this study, we propose a new protein 3D structure modeling method, A-Prot, using MSA Transformer, one of the state-of-the-art protein language models. An MSA feature tensor and row attention maps are extracted and converted into 2D residue-residue distance and dihedral angle predictions for a given MSA. We demonstrated that A-Prot predicts long-range contacts better than the existing methods. Additionally, we modeled the 3D structures of the free modeling and hard template-based modeling targets of CASP14. The assessment shows that the A-Prot models are more accurate than most top server groups of CASP14. Conclusion: These results imply that A-Prot accurately captures the evolutionary and structural information of proteins with relatively low computational cost. Thus, A-Prot can provide a clue for the development of other protein property prediction methods. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Hong2022A-Prot
ER  -

TY  - JOUR
AU  - Fang, Y.
AU  - Zhao, F.
AU  - Qin, Y.
AU  - Luo, H.
AU  - Wang, C.
TI  - Learning All Dynamics: Traffic Forecasting via Locality-Aware Spatio-Temporal Joint Transformer
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 23433
EP  - 23446
DO  - 10.1109/TITS.2022.3197640
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136843712&doi=10.1109%2fTITS.2022.3197640&partnerID=40&md5=6390ad15b2da537012124db43c4a9fe8
AB  - Forecasting traffic flow and speed in the urban is important for many applications, ranging from the intelligent navigation of map applications to congestion relief of city management systems. Therefore, mining the complex spatio-temporal correlations in the traffic data to accurately predict traffic is essential for the community. However, previous studies that combined the graph convolution network or self-attention mechanism with deep time series models (e.g., the recurrent neural network) can only capture spatial dependencies in each time slot and temporal dependencies in each sensor, ignoring the spatial and temporal correlations across different time slots and sensors. Besides, the state-of-the-art Transformer architecture used in previous methods is insensitive to local spatio-temporal contexts, which is hard to suit with traffic forecasting. To solve the above two issues, we propose a novel deep learning model for traffic forecasting, named Locality-aware spatio-temporal joint Transformer (Lastjormer), which elaborately designs a spatio-temporal joint attention in the Transformer architecture to capture all dynamic dependencies in the traffic data. Specifically, our model utilizes the dot-product self-attention on sensors across many time slots to extract correlations among them and introduces the linear and convolution self-attention mechanism to reduce the computation needs and incorporate local spatio-temporal information. Experiments on three real-world traffic datasets, England, METR-LA, and PEMS-BAY, demonstrate that our Lastjormer achieves state-of-the-art performances on a variety of challenging traffic forecasting benchmarks.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - CCF:B期刊; FMS:B; 
LB  - Fang2022Learning
ER  -

TY  - JOUR
AU  - Zhong, W.
AU  - He, C.
AU  - Xiao, C.
AU  - Liu, Y.
AU  - Qin, X.
AU  - Yu, Z.
TI  - Long-distance dependency combined multi-hop graph neural networks for protein–protein interactions prediction
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 521
DO  - 10.1186/s12859-022-05062-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143320524&doi=10.1186%2fs12859-022-05062-6&partnerID=40&md5=59ed7fe6d2ab8f8a2e8e1316acfb2476
AB  - Background: Protein–protein interactions are widespread in biological systems and play an important role in cell biology. Since traditional laboratory-based methods have some drawbacks, such as time-consuming, money-consuming, etc., a large number of methods based on deep learning have emerged. However, these methods do not take into account the long-distance dependency information between each two amino acids in sequence. In addition, most existing models based on graph neural networks only aggregate the first-order neighbors in protein–protein interaction (PPI) network. Although multi-order neighbor information can be aggregated by increasing the number of layers of neural network, it is easy to cause over-fitting. So, it is necessary to design a network that can capture long distance dependency information between amino acids in the sequence and can directly capture multi-order neighbor information in protein–protein interaction network. Results: In this study, we propose a multi-hop neural network (LDMGNN) model combining long distance dependency information to predict the multi-label protein–protein interactions. In the LDMGNN model, we design the protein amino acid sequence encoding (PAASE) module with the multi-head self-attention Transformer block to extract the features of amino acid sequences by calculating the interdependence between every two amino acids. And expand the receptive field in space by constructing a two-hop protein–protein interaction (THPPI) network. We combine PPI network and THPPI network with amino acid sequence features respectively, then input them into two identical GIN blocks at the same time to obtain two embeddings. Next, the two embeddings are fused and input to the classifier for predict multi-label protein–protein interactions. Compared with other state-of-the-art methods, LDMGNN shows the best performance on both the SHS27K and SHS148k datasets. Ablation experiments show that the PAASE module and the construction of THPPI network are feasible and effective. Conclusions: In general terms, our proposed LDMGNN model has achieved satisfactory results in the prediction of multi-label protein–protein interactions. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zhong2022Long-distance
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Xuan, J.
AU  - Yao, C.
AU  - Gao, Q.
AU  - Wang, L.
AU  - Jin, X.
AU  - Li, S.
TI  - A deep learning approach for orphan gene identification in moso bamboo (Phyllostachys edulis) based on the CNN + Transformer model
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 162
DO  - 10.1186/s12859-022-04702-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129379844&doi=10.1186%2fs12859-022-04702-1&partnerID=40&md5=a09179f8bd09c98807e730ce292cb54e
AB  - Background: Orphan gene play an important role in the environmental stresses of many species and their identification is a critical step to understand biological functions. Moso bamboo has high ecological, economic and cultural value. Studies have shown that the growth of moso bamboo is influenced by various stresses. Several traditional methods are time-consuming and inefficient. Hence, the development of efficient and high-accuracy computational methods for predicting orphan genes is of great significance. Results: In this paper, we propose a novel deep learning model (CNN + Transformer) for identifying orphan genes in moso bamboo. It uses a convolutional neural network in combination with a transformer neural network to capture k-mer amino acids and features between k-mer amino acids in protein sequences. The experimental results show that the average balance accuracy value of CNN + Transformer on moso bamboo dataset can reach 0.875, and the average Matthews Correlation Coefficient (MCC) value can reach 0.471. For the same testing set, the Balance Accuracy (BA), Geometric Mean (GM), Bookmaker Informedness (BM), and MCC values of the recurrent neural network, long short-term memory, gated recurrent unit, and transformer models are all lower than those of CNN + Transformer, which indicated that the model has the extensive ability for OG identification in moso bamboo. Conclusions: CNN + Transformer model is feasible and obtains the credible predictive results. It may also provide valuable references for other related research. As our knowledge, this is the first model to adopt the deep learning techniques for identifying orphan genes in plants. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zhang2022deep
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Zhang, Y.
AU  - Fortino, G.
AU  - Guan, Q.
AU  - Liu, J.
AU  - Song, J.
TI  - Software Escalation Prediction Based on Deep Learning in the Cognitive Internet of Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 25408
EP  - 25418
DO  - 10.1109/TITS.2022.3140903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123778689&doi=10.1109%2fTITS.2022.3140903&partnerID=40&md5=0b664f65aebf23445012c85e34e04696
AB  - In the Cognitive Internet of Vehicles (CIoV), vehicles, road side units (RSU) and other key nodes have been equipped with more and more software to support intelligent transportation system (ITS), vehicle automatic control and intelligent road information services. Additionally, technological innovation forces the software in the CIoV to update and upgrade in time. However, escalation is critical to the safety, stability, and maintenance cost of transportation systems. It can be assumed that when the intelligent services supporting CIoV can realize self-perception and escalation, the cognitive ability and coordination ability of the entire CIoV will be greatly improved. To address this, we first propose a deep learning-based method for Software Escalation Prediction (SEP) in CIoV. Specifically, the pretraining mechanism of transformers in the field of natural language processing is combined with software upgrade-related events to dynamically model software sequence activities. To capture the event association in the software activities, we use graph modeling software's state log and utilize a graph neural network (GNN) to learn the complex life activity rule of software. Finally, the above characteristics are deeply integrated. The proposed method has a 6%-8% improvement over the RoBERTa methods.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; FMS:B; 
LB  - Wang2022Software
ER  -

TY  - JOUR
AU  - Hou, L.
AU  - Li, S.E.
AU  - Yang, B.
AU  - Wang, Z.
AU  - Nakano, K.
TI  - Structural Transformer Improves Speed-Accuracy Trade-Off in Interactive Trajectory Prediction of Multiple Surrounding Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 24778
EP  - 24790
DO  - 10.1109/TITS.2022.3193665
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135762964&doi=10.1109%2fTITS.2022.3193665&partnerID=40&md5=70861e8e99e113c5c20932e975740c58
AB  - Fast and accurate long-term trajectory prediction of surrounding vehicles (SVs) is critical to autonomous driving systems. In high-density traffic flows, strongly correlated vehicle behaviors require considering the interactions among multiple SVs when predicting their future trajectories. However, existing interactive prediction methods, most based on Long Short-Term Memory (LSTM), are suffering from slow prediction because they analyze SVs one by one and analyze trajectory sequence node by node. This paper presents a fast interactive trajectory prediction method called Structural Transformer which learns both spatial and temporal dependencies among multiple SVs in parallel. Specifically, our model first removes the internal states and loops of LSTM and replaces with a weighted self-reference mapping to realize parallel computation. Then, it embeds the relative spatial information of multiple SVs into trajectory states and reorganizes the self-reference mapping with neighbor-only interaction masks to achieve interactive prediction. Results on the NGSIM dataset show satisfyingly speed and accuracy performance on long-term trajectory prediction of multiple SVs. The longitudinal and lateral errors are reduced to 2.67m and 0.25m over 5s time horizon. The computational time of each step is only 12ms on a 2080ti GPU, which is over 4 times faster than the Structural LSTM.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; FMS:B; 
LB  - Hou2022Structural
ER  -

TY  - JOUR
AU  - Ferruz, N.
AU  - Schmidt, S.
AU  - Höcker, B.
TI  - ProtGPT2 is a deep unsupervised language model for protein design
PY  - 2022
T2  - Nature Communications
VL  - 13
IS  - 1
C7  - 4348
DO  - 10.1038/s41467-022-32007-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134893372&doi=10.1038%2fs41467-022-32007-7&partnerID=40&md5=79d8493f900a65644c583cc750c6a664
AB  - Protein design aims to build novel proteins customized for specific purposes, thereby holding the potential to tackle many environmental and biomedical problems. Recent progress in Transformer-based architectures has enabled the implementation of language models capable of generating text with human-like capabilities. Here, motivated by this success, we describe ProtGPT2, a language model trained on the protein space that generates de novo protein sequences following the principles of natural ones. The generated proteins display natural amino acid propensities, while disorder predictions indicate that 88% of ProtGPT2-generated proteins are globular, in line with natural sequences. Sensitive sequence searches in protein databases show that ProtGPT2 sequences are distantly related to natural ones, and similarity networks further demonstrate that ProtGPT2 is sampling unexplored regions of protein space. AlphaFold prediction of ProtGPT2-sequences yields well-folded non-idealized structures with embodiments and large loops and reveals topologies not captured in current structure databases. ProtGPT2 generates sequences in a matter of seconds and is freely available. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 221
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lupo, U.
AU  - Sgarbossa, D.
AU  - Bitbol, A.-F.
TI  - Protein language models trained on multiple sequence alignments learn phylogenetic relationships
PY  - 2022
T2  - Nature Communications
VL  - 13
IS  - 1
C7  - 6298
DO  - 10.1038/s41467-022-34032-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140351057&doi=10.1038%2fs41467-022-34032-y&partnerID=40&md5=ec8bdfa349902aa961b0f6949f41e245
AB  - Self-supervised neural language models with attention have recently been applied to biological sequence data, advancing structure, function and mutational effect prediction. Some protein language models, including MSA Transformer and AlphaFold’s EvoFormer, take multiple sequence alignments (MSAs) of evolutionarily related proteins as inputs. Simple combinations of MSA Transformer’s row attentions have led to state-of-the-art unsupervised structural contact prediction. We demonstrate that similarly simple, and universal, combinations of MSA Transformer’s column attentions strongly correlate with Hamming distances between sequences in MSAs. Therefore, MSA-based language models encode detailed phylogenetic relationships. We further show that these models can separate coevolutionary signals encoding functional and structural constraints from phylogenetic correlations reflecting historical contingency. To assess this, we generate synthetic MSAs, either without or with phylogeny, from Potts models trained on natural MSAs. We find that unsupervised contact prediction is substantially more resilient to phylogenetic noise when using MSA Transformer versus inferred Potts models. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Sutopo, R.
AU  - Lim, J.M.-Y.
AU  - Baskaran, V.M.
TI  - Efficient Long-Term Dependencies Learning for Passenger Flow Prediction with Selective Feedback Mechanism
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 12
SP  - 24020
EP  - 24030
DO  - 10.1109/TITS.2022.3199748
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137895363&doi=10.1109%2fTITS.2022.3199748&partnerID=40&md5=71a65ac8dcc996bf9c839cb4ef743af6
AB  - With the rapid growth of worldwide urbanization, the increasing demand for public transportation is indispensable. To improve the service quality, predicting the flow of passengers is important for the transport operators. Information on density of passengers can be used as early warnings of overcrowding and to determine if additional fleet is required. However, passenger flow forecasting is a challenging task, as it is affected by many complex factors such as spatial dependencies, temporal dependencies, and external influences. Furthermore, the ability to learn the long-term dependency of the data is also crucial, as the distant past flow information contributes to the flow over time. Most of the existing studies struggle to solve this issue, especially to learn the long-term dependency of the data, as they rely heavily on the raw handcrafted features and require high memory bandwidth to compute. To address these issues, we propose a Selective Feedback Transformer (SFT) capable of learning long-term dependency efficiently, where the selective feedback mechanism only computes the important feedback from the dominant query-key pairs in the memory. Experimental results demonstrate that the proposed model outperforms all the benchmarked methods by 27%-37% in terms of RMSE and 36%-50% in terms of MAE. Additionally, when the proposed model is tested with shallowed model (less number of decoding layer), it exhibits a substantial improvement of 14%-57% in the training time and 15%-46% in the inference time, with minimal impact on the accuracies.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 0
C2  - CCF:B期刊; FMS:B; 
LB  - Sutopo2022Efficient
ER  -

TY  - JOUR
AU  - Li, L.
AU  - Song, T.
AU  - Wu, J.
AU  - Dong, W.
AU  - Qian, J.
AU  - Shi, G.
TI  - Blind Image Quality Index for Authentic Distortions with Local and Global Deep Feature Aggregation
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 12
SP  - 8512
EP  - 8523
DO  - 10.1109/TCSVT.2021.3112197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115129688&doi=10.1109%2fTCSVT.2021.3112197&partnerID=40&md5=3304af731868593bdc23d42452971cd9
AB  - Blind image quality assessment (BIQA) for authentic distortions is still a great challenge, even in today's deep learning era. It has been widely acknowledged that local and global features are both indispensable for IQA, which play complementary roles. While combining local and global features is straightforward in traditional handcrafted feature-based IQA metrics, it is not an easy task in the deep learning framework. This is mainly due to the fact that deep neural networks typically require input images with a fixed size. Current metrics either resize the image or use local patches as input, which are problematic in that they cannot integrate local and global aspects as well as their interactions to achieve comprehensive quality evaluation. Motivated by the above facts, this paper presents a new BIQA metric for authentic distortions by aggregating local and global deep features in a Vision-Transformer framework. In the proposed metric, selective local regions and global content are simultaneously input for complementary feature extraction, and the Vision-Transformer is employed to build the relationship between different local patches and image quality. Self-attention mechanism is further adopted to explore the interaction between local and global deep features, producing the final image quality score. Extensive experiments on five authentically distorted IQA databases demonstrate that the proposed metric outperforms the state-of-the-arts in terms of both prediction performance and generalization ability.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fei, Y.
AU  - Zhang, H.
AU  - Wang, Y.
AU  - Liu, Z.
AU  - Liu, Y.
TI  - LTPConstraint: a transfer learning based end-to-end method for RNA secondary structure prediction
PY  - 2022
T2  - BMC Bioinformatics
VL  - 23
IS  - 1
C7  - 354
DO  - 10.1186/s12859-022-04847-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136369520&doi=10.1186%2fs12859-022-04847-z&partnerID=40&md5=db480c132e6e1a3d3a5b1b29b7ebc66f
AB  - Background: RNA secondary structure is very important for deciphering cell’s activity and disease occurrence. The first method which was used by the academics to predict this structure is biological experiment, But this method is too expensive, causing the promotion to be affected. Then, computing methods emerged, which has good efficiency and low cost. However, the accuracy of computing methods are not satisfactory. Many machine learning methods have also been applied to this area, but the accuracy has not improved significantly. Deep learning has matured and achieves great success in many areas such as computer vision and natural language processing. It uses neural network which is a kind of structure that has good functionality and versatility, but its effect is highly correlated with the quantity and quality of the data. At present, there is no model with high accuracy, low data dependence and high convenience in predicting RNA secondary structure. Results: This paper designs a neural network called LTPConstraint to predict RNA secondary structure. The network is based on many network structure such as Bidirectional LSTM, Transformer and generator. It also uses transfer learning to train modelso that the data dependence can be reduced. Conclusions: LTPConstraint has achieved high accuracy in RNA secondary structure prediction. Compared with the previous methods, the accuracy improves obviously both in predicting the structure with pseudoknot and the structure without pseudoknot. At the same time, LTPConstraint is easy to operate and can achieve result very quickly. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Fei2022LTPConstraint
ER  -

TY  - JOUR
AU  - Fang, Y.
AU  - Liu, X.
AU  - Liu, H.
TI  - Attention-aware contrastive learning for predicting T cell receptor–antigen binding specificity
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 6
C7  - bbac378
DO  - 10.1093/bib/bbac378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142403401&doi=10.1093%2fbib%2fbbac378&partnerID=40&md5=09c87517674f1b8ea834d8d748034b38
AB  - Motivation:: It has been proven that only a small fraction of the neoantigens presented by major histocompatibility complex (MHC) class I molecules on the cell surface can elicit T cells. This restriction can be attributed to the binding specificity of T cell receptor (TCR) and peptide-MHC complex (pMHC). Computational prediction of T cells binding to neoantigens is a challenging and unresolved task. Results:: In this paper, we proposed an attention-aware contrastive learning model, ATMTCR, to infer the TCR–pMHC binding specificity. For each TCR sequence, we used a transformer encoder to transform it to latent representation, and then masked a percentage of amino acids guided by attention weights to generate its contrastive view. Compared to fully-supervised baseline model, we verified that contrastive learning-based pretraining on large-scale TCR sequences significantly improved the prediction performance of downstream tasks. Interestingly, masking a percentage of amino acids with low attention weights yielded best performance compared to other masking strategies. Comparison experiments on two independent datasets demonstrated our method achieved better performance than other existing algorithms. Moreover, we identified important amino acids and their positional preference through attention weights, which indicated the potential interpretability of our proposed model. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, L.
AU  - Lin, J.
AU  - Liu, R.
AU  - Zheng, Z.
AU  - Meng, L.
AU  - Chen, X.
AU  - Li, X.
AU  - Wong, K.-C.
TI  - CoaDTI: multi-modal co-attention based framework for drug-target interaction annotation
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 6
C7  - bbac446
DO  - 10.1093/bib/bbac446
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142403487&doi=10.1093%2fbib%2fbbac446&partnerID=40&md5=a531d56afc551b3e7ac5f98c5bd1da90
AB  - Motivation: The identification of drug-target interactions (DTIs) plays a vital role for in silico drug discovery, in which the drug is the chemical molecule, and the target is the protein residues in the binding pocket. Manual DTI annotation approaches remain reliable; however, it is notoriously laborious and time-consuming to test each drug-target pair exhaustively. Recently, the rapid growth of labelled DTI data has catalysed interests in high-throughput DTI prediction. Unfortunately, those methods highly rely on the manual features denoted by human, leading to errors. Results: Here, we developed an end-to-end deep learning framework called CoaDTI to significantly improve the efficiency and interpretability of drug target annotation. CoaDTI incorporates the Co-attention mechanism to model the interaction information from the drug modality and protein modality.In particular, CoaDTI incorporates transformer to learn the protein representations from raw amino acid sequences, and GraphSage to extract the molecule graph features from SMILES. Furthermore, we proposed to employ the transfer learning strategy to encode protein features by pre-trained transformer to address the issue of scarce labelled data. The experimental results demonstrate that CoaDTI achieves competitive performance on three public datasets compared with state-of-the-art models. In addition, the transfer learning strategy further boosts the performance to an unprecedented level. The extended study reveals that CoaDTI can identify novel DTIs such as reactions between candidate drugs and severe acute respiratory syndrome coronavirus 2-associated proteins. The visualization of co-attention scores can illustrate the interpretability of our model for mechanistic insights. Availability: Source code are publicly available at https://github.com/Layne-Huang/CoaDTI.  © The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhou, Y.
AU  - Wang, X.
AU  - Yao, L.
AU  - Zhu, M.
TI  - LDAformer: predicting lncRNA-disease associations based on topological feature extraction and Transformer encoder
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 6
C7  - bbac370
DO  - 10.1093/bib/bbac370
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142403506&doi=10.1093%2fbib%2fbbac370&partnerID=40&md5=82c90e74e7f9ed7327749799d92cdbba
AB  - The identification of long noncoding RNA (lncRNA)-disease associations is of great value for disease diagnosis and treatment, and it is now commonly used to predict potential lncRNA-disease associations with computational methods. However, the existing methods do not sufficiently extract key features during data processing, and the learning model parts are either less powerful or overly complex. Therefore, there is still potential to achieve better predictive performance by improving these two aspects. In this work, we propose a novel lncRNA-disease association prediction method LDAformer based on topological feature extraction and Transformer encoder. We construct the heterogeneous network by integrating the associations between lncRNAs, diseases and micro RNAs (miRNAs). Intra-class similarities and inter-class associations are presented as the lncRNA-disease-miRNA weighted adjacency matrix to unify semantics. Next, we design a topological feature extraction process to further obtain multi-hop topological pathway features latent in the adjacency matrix. Finally, to capture the interdependencies between heterogeneous pathways, a Transformer encoder based on the global self-attention mechanism is employed to predict lncRNA-disease associations. The efficient feature extraction and the intuitive and powerful learning model lead to ideal performance. The results of computational experiments on two datasets show that our method outperforms the state-of-the-art baseline methods. Additionally, case studies further indicate its capability to discover new associations accurately. © The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kujawski, A.
AU  - Sarradj, E.
TI  - Fast grid-free strength mapping of multiple sound sources from microphone array data using a Transformer architecture
PY  - 2022
T2  - Journal of the Acoustical Society of America
VL  - 152
IS  - 5
SP  - 2543
EP  - 2556
DO  - 10.1121/10.0015005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143181965&doi=10.1121%2f10.0015005&partnerID=40&md5=0145a9bb3ebb2874f38157dddfa72879
AB  - Conventional microphone array methods for the characterization of sound sources that require a focus-grid are, depending on the grid resolution, either computationally demanding or limited in reconstruction accuracy. This paper presents a deep learning method for grid-free source characterization using a Transformer architecture that is exclusively trained with simulated data. Unlike previous grid-free model architectures, the presented approach requires a single model to characterize an unknown number of ground-truth sources. The model predicts a set of source components, spatially arranged in clusters. Integration over the predicted cluster components allows for the determination of the strength for each ground-truth source individually. Fast and accurate source mapping performance of up to ten sources at different frequencies is demonstrated and strategies to reduce the training effort at neighboring frequencies are given. A comparison with the established grid-based CLEAN-SC and a probabilistic sparse Bayesian learning method on experimental data emphasizes the validity of the approach.  © 2022 Acoustical Society of America.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Qiu, Y.
AU  - Ding, S.
AU  - Tian, D.
AU  - Zhang, C.
AU  - Zhou, D.
TI  - Predicting the quality of answers with less bias in online health question answering communities
PY  - 2022
T2  - Information Processing and Management
VL  - 59
IS  - 6
C7  - 103112
DO  - 10.1016/j.ipm.2022.103112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141744838&doi=10.1016%2fj.ipm.2022.103112&partnerID=40&md5=b0e16b8fafaa47e505eff0638d65c9de
AB  - Existing approaches in online health question answering (HQA) communities to identify the quality of answers either address it subjectively by human assessment or mainly using textual features. This process may be time-consuming and lose the semantic information of answers. We present an automatic approach for predicting answer quality that combines sentence-level semantics with textual and non-textual features in the context of online healthcare. First, we extend the knowledge adoption model (KAM) theory to obtain the six dimensions of quality measures for textual and non-textual features. Then we apply the Bidirectional Encoder Representations from Transformers (BERT) model for extracting semantic features. Next, the multi-dimensional features are processed for dimensionality reduction using linear discriminant analysis (LDA). Finally, we incorporate the preprocessed features into the proposed BK-XGBoost method to automatically predict the answer quality. The proposed method is validated on a real-world dataset with 48121 question-answer pairs crawled from the most popular online HQA communities in China. The experimental results indicate that our method competes against the baseline models on various evaluation metrics. We found up to 2.9% and 5.7% improvement in AUC value in comparison with BERT and XGBoost models respectively. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Rotman, G.
AU  - Reichart, R.
TI  - Multi-task Active Learning for Pre-trained Transformer-based Models
PY  - 2022
T2  - Transactions of the Association for Computational Linguistics
VL  - 10
SP  - 1209
EP  - 1228
DO  - 10.1162/tacl_a_00515
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141399893&doi=10.1162%2ftacl_a_00515&partnerID=40&md5=1bd8c6096353b984027e734f27de6883
AB  - Multi-task learning, in which several tasks are jointly learned by a single model, allows NLP models to share information from multiple annotations and may facilitate better predictions when the tasks are inter-related. This technique, however, requires annotating the same text with multiple annotation schemes, which may be costly and laborious. Active learning (AL) has been demonstrated to op-timize annotation processes by iteratively se-lecting unlabeled examples whose annotation is most valuable for the NLP model. Yet, multi-task active learning (MT-AL) has not been applied to state-of-the-art pre-trained Transformer-based NLP models. This paper aims to close this gap. We explore various multi-task selection criteria in three realistic multi-task scenarios, reflecting different relations between the participating tasks, and demonstrate the effectiveness of multi-task compared to single-task selection. Our results suggest that MT-AL can be effectively used in order to minimize annotation efforts for multi-task NLP models.1. © 2022 Association for Computational Linguistics.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zheng, Y.
AU  - Gindra, R.H.
AU  - Green, E.J.
AU  - Burks, E.J.
AU  - Betke, M.
AU  - Beane, J.E.
AU  - Kolachalama, V.B.
TI  - A Graph-Transformer for Whole Slide Image Classification
PY  - 2022
T2  - IEEE Transactions on Medical Imaging
VL  - 41
IS  - 11
SP  - 3003
EP  - 3015
DO  - 10.1109/TMI.2022.3176598
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130453930&doi=10.1109%2fTMI.2022.3176598&partnerID=40&md5=a0cec43b8d170bdfcf874c9fce90f7dd
AB  - Deep learning is a powerful tool for whole slide image (WSI) analysis. Typically, when performing supervised deep learning, a WSI is divided into small patches, trained and the outcomes are aggregated to estimate disease grade. However, patch-based methods introduce label noise during training by assuming that each patch is independent with the same label as the WSI and neglect overall WSI-level information that is significant in disease grading. Here we present a Graph-Transformer (GT) that fuses a graph-based representation of an WSI and a vision transformer for processing pathology images, called GTP, to predict disease grade. We selected 4,818 WSIs from the Clinical Proteomic Tumor Analysis Consortium (CPTAC), the National Lung Screening Trial (NLST), and The Cancer Genome Atlas (TCGA), and used GTP to distinguish adenocarcinoma (LUAD) and squamous cell carcinoma (LSCC) from adjacent non-cancerous tissue (normal). First, using NLST data, we developed a contrastive learning framework to generate a feature extractor. This allowed us to compute feature vectors of individual WSI patches, which were used to represent the nodes of the graph followed by construction of the GTP framework. Our model trained on the CPTAC data achieved consistently high performance on three-label classification (normal versus LUAD versus LSCC: mean accuracy = 91.2 ± 2.5%) based on five-fold cross-validation, and mean accuracy = 82.3 ± 1.0% on external test data (TCGA). We also introduced a graph-based saliency mapping technique, called GraphCAM, that can identify regions that are highly associated with the class label. Our findings demonstrate GTP as an interpretable and effective deep learning framework for WSI-level classification.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 80
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Halder, S.
AU  - Lim, K.H.
AU  - Chan, J.
AU  - Zhang, X.
TI  - POI recommendation with queuing time and user interest awareness
PY  - 2022
T2  - Data Mining and Knowledge Discovery
VL  - 36
IS  - 6
SP  - 2379
EP  - 2409
DO  - 10.1007/s10618-022-00865-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139213849&doi=10.1007%2fs10618-022-00865-w&partnerID=40&md5=be95780c46d0900338dd807743956ff5
AB  - Point-of-interest (POI) recommendation is a challenging problem due to different contextual information and a wide variety of human mobility patterns. Prior studies focus on recommendation that considers user travel spatiotemporal and sequential patterns behaviours. These studies do not pay attention to user personal interests, which is a significant factor for POI recommendation. Besides user interests, queuing time also plays a significant role in affecting user mobility behaviour, e.g., having to queue a long time to enter a POI might reduce visitor’s enjoyment. Recently, attention-based recurrent neural networks-based approaches show promising performance in the next POI recommendation task. However, they are limited to single head attention, which can have difficulty in finding the appropriate user mobility behaviours considering complex relationships among POI spatial distances, POI check-in time, user interests and POI queuing times. In this research work, we are the first to consider queuing time and user interest awareness factors for next POI recommendation. We demonstrate how it is non-trivial to recommend a next POI and simultaneously predict its queuing time. To solve this problem, we propose a multi-task, multi-head attention transformer model called TLR-M_UI. The model recommends the next POIs to the target users and predicts queuing time to access the POIs simultaneously by considering user mobility behaviours. The proposed model utilises POIs description-based user personal interest that can also solve the new categorical POI cold start problem. Extensive experiments on six real-world datasets show that the proposed models outperform the state-of-the-art baseline approaches in terms of precision, recall, and F1-score evaluation metrics. The model also predicts and minimizes the queuing time. For the reproducibility of the proposed model, we have publicly shared our implementation code at GitHub (https://github.com/sajalhalder/TLR-M_UI). © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, L.
AU  - Wang, C.-C.
AU  - Chen, X.
TI  - Predicting drug–target binding affinity through molecule representation block based on multi-head attention and skip connection
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 6
C7  - bbac468
DO  - 10.1093/bib/bbac468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142369398&doi=10.1093%2fbib%2fbbac468&partnerID=40&md5=b2a74a20fadd99cff95f5a3bf0111fc8
AB  - Exiting computational models for drug–target binding affinity prediction have much room for improvement in prediction accuracy, robustness and generalization ability. Most deep learning models lack interpretability analysis and few studies provide application examples. Based on these observations, we presented a novel model named Molecule Representation Block-based Drug-Target binding Affinity prediction (MRBDTA). MRBDTA is composed of embedding and positional encoding, molecule representation block and interaction learning module. The advantages of MRBDTA are reflected in three aspects: (i) developing Trans block to extract molecule features through improving the encoder of transformer, (ii) introducing skip connection at encoder level in Trans block and (iii) enhancing the ability to capture interaction sites between proteins and drugs. The test results on two benchmark datasets manifest that MRBDTA achieves the best performance compared with 11 state-of-the-art models. Besides, through replacing Trans block with single Trans encoder and removing skip connection in Trans block, we verified that Trans block and skip connection could effectively improve the prediction accuracy and reliability of MRBDTA. Then, relying on multi-head attention mechanism, we performed interpretability analysis to illustrate that MRBDTA can correctly capture part of interaction sites between proteins and drugs. In case studies, we firstly employed MRBDTA to predict binding affinities between Food and Drug Administration-approved drugs and severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) replication-related proteins. Secondly, we compared true binding affinities between 3C-like proteinase and 185 drugs with those predicted by MRBDTA. The final results of case studies reveal reliable performance of MRBDTA in drug design for SARS-CoV-2. © The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Hu, J.
AU  - Sun, H.
AU  - Xu, M.
AU  - Yu, Y.
AU  - Liu, Y.
AU  - Cheng, L.
TI  - MGPLI: exploring multigranular representations for protein–ligand interaction prediction
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 21
SP  - 4859
EP  - 4867
DO  - 10.1093/bioinformatics/btac597
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141004918&doi=10.1093%2fbioinformatics%2fbtac597&partnerID=40&md5=d14f7f60aac7dbc5e5ccba12a84753a9
AB  - Motivation: The capability to predict the potential drug binding affinity against a protein target has always been a fundamental challenge in silico drug discovery. The traditional experiments in vitro and in vivo are costly and time-consuming which need to search over large compound space. Recent years have witnessed significant success on deep learning-based models for drug-target binding affinity prediction task. Results: Following the recent success of the Transformer model, we propose a multigranularity protein–ligand interaction (MGPLI) model, which adopts the Transformer encoders to represent the character-level features and fragment-level features, modeling the possible interaction between residues and atoms or their segments. In addition, we use the convolutional neural network to extract higher-level features based on transformer encoder outputs and a highway layer to fuse the protein and drug features. We evaluate MGPLI on different protein–ligand interaction datasets and show the improvement of prediction performance compared to state-of-the-art baselines. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Brenon, A.
AU  - Moncla, L.
AU  - McDonough, K.
TI  - Classifying encyclopedia articles: Comparing machine and deep learning methods and exploring their predictions
PY  - 2022
T2  - Data and Knowledge Engineering
VL  - 142
C7  - 102098
DO  - 10.1016/j.datak.2022.102098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141913869&doi=10.1016%2fj.datak.2022.102098&partnerID=40&md5=a71227e38ded3376a9ab25b19be31106
AB  - This article presents a comparative study of supervised classification approaches applied to the automatic classification of encyclopedia articles written in French. Our dataset includes all 70k text articles from Diderot and d'Alembert’s Encyclopédie (1751-72). In a two-task experiment we test combinations of (1) text vectorization methods (bags-of-words and word embeddings) and (2) traditional Machine Learning and newer Deep Learning classification methods (including transformer architectures). In addition to evaluating each approach, we review the results quantitatively and qualitatively. The best model obtains an average F-score of 86% for 38 classes. Using network analysis, we highlight the difficulty of labeling semantically close classes. We also discuss misclassifications in order to understand the relationship between content and different ways of ordering knowledge. We openly release all code and results, and data is available on request.1 © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, G.
AU  - Qi, H.
AU  - Shen, Y.
AU  - Yin, B.
TI  - TCSA-Net: A Temporal-Context-Based Self-Attention Network for Next Location Prediction
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 20735
EP  - 20745
DO  - 10.1109/TITS.2022.3181339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132756661&doi=10.1109%2fTITS.2022.3181339&partnerID=40&md5=57dcf3006b1df39d7f7294c194139b60
AB  - Next location prediction aims to find the location that the user will visit next. It plays a fundamental role for location-based applications. However, the heterogeneity and sparsity of the trajectory data pose great challenges to the task. Recently, RNN-based methods have shown promising performance in learining the spatio-temporal characteristics of the trajectory. While the effectiveness of location prediction has been improved, the computational efficiency and the long-term preferences still leave space for further research. The self-attention mechanism is viewed as a promising solution for parallel computation and exploiting sequential regularities from sparse data. But the huge memory cost and the neglect of temporal information make it infeasible to directly modeling human mobility regularities. In this paper, we propose a temporal-context-based self-attention network named TCSA-Net, which can simultaneously exploit long- and short-term mvoement preferences from sparse and long trajectories. In particular, we design a novel two-stage self-attention architecture that can learn long-term dependency under constrained memory budget. Further, we propose a multi-modal embedding layer to model two complementary temporal contexts and provide more abundant temporal and sequential information. Extensive experiments on two real-life datasets show that the TCSA-Net significantly outperforms the state-of-the-art methods in terms of standard evaluation metrics.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Sun2022TCSA-Net
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Dai, Q.
TI  - Latent adversarial regularized autoencoder for high-dimensional probabilistic time series prediction
PY  - 2022
T2  - Neural Networks
VL  - 155
SP  - 383
EP  - 397
DO  - 10.1016/j.neunet.2022.08.025
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138025849&doi=10.1016%2fj.neunet.2022.08.025&partnerID=40&md5=84977fe5b2a56d045a5e4171b9c5293f
AB  - Many practical applications require probabilistic prediction of time series to model the distribution on future horizons. With ever-increasing dimensions, much effort has been invested into developing methods that often make an assumption about the independence between time series. Consequently, the probabilistic prediction in high-dimensional environments has become an essential topic with significant challenges. In this paper, we propose a novel probabilistic model called latent adversarial regularized autoencoder, abbreviated as TimeLAR, specifically for high-dimensional multivariate Time Series Prediction (TSP). It integrates the flexibility of Generative Adversarial Networks (GANs) and the capability of autoencoders in extracting higher-level non-linear features. Through flexible autoencoder mapping, TimeLAR learns cross-series relationships and encodes this global information into several latent variables. We design a modified Transformer for these latent variables to capture global temporal patterns and infer latent space prediction distributions, where only one step is required to output multi-step predictions. Furthermore, we employ the GAN to further refine the performance of latent space predictions, by using a discriminator to guide the training of the autoencoder and the Transformer in an adversarial process. Finally, complex distributions of multivariate time series data can be modeled by the non-linear decoder of the autoencoder. The effectiveness of TimeLAR is empirically underpinned by extensive experiments conducted on five real-world high-dimensional time series datasets in the fields of transportation, electricity, and web page views. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, K.
AU  - Feng, X.
AU  - Wu, L.
AU  - He, Z.
TI  - Trajectory Prediction for Autonomous Driving Using Spatial-Temporal Graph Attention Transformer
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 22343
EP  - 22353
DO  - 10.1109/TITS.2022.3164450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129406845&doi=10.1109%2fTITS.2022.3164450&partnerID=40&md5=e4e4dfd52591f047bf796065c1461af6
AB  - For autonomous vehicles driving on roads, future trajectories of surrounding traffic agents (e.g., vehicles, bicycles, pedestrians) are essential information. The prediction of future trajectories is challenging as the motion of traffic agents is constantly affected by spatial-temporal interactions from agents and road infrastructure. To take those interactions into account, this study proposes a Graph Attention Transformer (Gatformer) in which a traffic scene is represented by a sparse graph. To maintain the spatial and temporal information of traffic agents in a traffic scene, Convolutional Neural Networks (CNNs) are utilized to extract spatial features and a position encoder is proposed to encode the spatial features and the corresponding temporal features. Based on the encoded features, a Graph Attention Network (GAT) block is employed to model the agent-agent and agent-infrastructure interactions with the help of attention mechanisms. Finally, a Transformer network is introduced to predict trajectories for multiple agents simultaneously. Experiments are conducted over the Lyft dataset and state-of-the-art methods are introduced for comparison. The results show that the proposed Gatformer could make more accurate predictions while requiring less inference time than its counterparts.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 62
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2022Trajectory
ER  -

TY  - JOUR
AU  - Yuan, Q.
AU  - Chen, S.
AU  - Wang, Y.
AU  - Zhao, H.
AU  - Yang, Y.
TI  - Alignment-free metal ion-binding site prediction from protein sequence through pretrained language model and multi-task learning
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 6
C7  - bbac444
DO  - 10.1093/bib/bbac444
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142403495&doi=10.1093%2fbib%2fbbac444&partnerID=40&md5=f4d1feac64724eee8ab2a1373795b5b3
AB  - More than one-third of the proteins contain metal ions in the Protein Data Bank. Correct identification of metal ion-binding residues is important for understanding protein functions and designing novel drugs. Due to the small size and high versatility of metal ions, it remains challenging to computationally predict their binding sites from protein sequence. Existing sequence-based methods are of low accuracy due to the lack of structural information, and time-consuming owing to the usage of multi-sequence alignment. Here, we propose LMetalSite, an alignment-free sequence-based predictor for binding sites of the four most frequently seen metal ions in BioLiP (Zn2+, Ca2+, Mg2+ and Mn2+). LMetalSite leverages the pretrained language model to rapidly generate informative sequence representations and employs transformer to capture long-range dependencies. Multi-task learning is adopted to compensate for the scarcity of training data and capture the intrinsic similarities between different metal ions. LMetalSite was shown to surpass state-of-the-art structure-based methods by more than 19.7, 14.4, 36.8 and 12.6% in area under the precision recall on the four independent tests, respectively. Further analyses indicated that the self-attention modules are effective to learn the structural contexts of residues from protein sequence. We provide the data sets, source codes and trained models of LMetalSite at https://github.com/biomed-AI/LMetalSite. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xie, Y.
AU  - Niu, J.
AU  - Zhang, Y.
AU  - Ren, F.
TI  - Multisize Patched Spatial-Temporal Transformer Network for Short- and Long-Term Crowd Flow Prediction
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 21548
EP  - 21568
DO  - 10.1109/TITS.2022.3186707
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134304842&doi=10.1109%2fTITS.2022.3186707&partnerID=40&md5=d29cb1218f5ec508825de01b6cb60a43
AB  - The prediction of urban crowds is crucial not only to traffic management but also to studies on the city-level social phenomena, such as energy consumption, urban growth, city planning, and epidemic prevention. The challenges of accurately predicting crowd flow come from the non-linear spatial-temporal dependence of crowd flow data, periodic laws, such as daily and weekly periodicity, and external factors, such as weather and holidays. It is even more challenging for most existing short-term prediction models to make an accurate long-term prediction. In this paper, we propose a novel patched Transformer-based sequence-to-sequence model, called MultiSize Patched Spatial-Temporal Transformer Network (MSP-STTN), to incorporate rich and unified context modeling via a self-attention mechanism and global memory learning via a cross-attention mechanism for short- and long-term grid-based crowd flow prediction. In particular, a multisize patched spatial-temporal self-attention Transformer is designed to capture cross-space-time and cross-size contextual dependence of crowd data. The same structured cross-attention Transformer is developed to adaptively learn a global memory for long-term prediction in a responding-to-a-query style without error accumulation. In addition, a categorized space-time expectation is proposed as a unified regional encoding with temporal and external factors and is used as a base prediction for stable training. Furthermore, auxiliary tasks are introduced for promoting feature encoding and leveraging feature consistency to assist in the main prediction task. The experimental results reveal that MSP-STTN is competitive with the state of the art for one-step and multi-step short-term prediction within several hours and achieves practical long-term crowd flow prediction within one day on real-world grid-based crowd data sets TaxiBJ, BikeNYC, and CrowdDensityBJ. Our code and data are available at https://github.com/xieyulai/MSP-STTN. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 31
C2  - CCF:B期刊; FMS:B; 
LB  - Xie2022Multisize
ER  -

TY  - JOUR
AU  - Xiao, Y.
AU  - Quan, P.
AU  - Lei, M.
AU  - Niu, L.
TI  - Latent neighborhood-based heterogeneous graph representation
PY  - 2022
T2  - Neural Networks
VL  - 154
SP  - 413
EP  - 424
DO  - 10.1016/j.neunet.2022.07.028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135716712&doi=10.1016%2fj.neunet.2022.07.028&partnerID=40&md5=26258934ab5ff22d16d827ab703a6606
AB  - Graph, as a powerful data structure, has shown superior capability on modeling complex systems. Since real-world objects and their interactions are often multi-modal and multi-typed, compared with traditional homogeneous graphs, heterogeneous graphs can represent real-world objects more effectively. Meanwhile, rich semantic information brings great challenges for learning heterogeneous graph representation (HGR). Most existing HGR methods are based on the concept of meta-path, which is constructed based on direct neighbors and define composite semantic relations in heterogeneous graph. However, when the direct neighbor information is inadequate, which always happens due to insufficient observation, the quality of meta-paths cannot be guaranteed. Therefore, we propose a novel HGR framework based on latent direct neighbors. Specifically, random walks are first utilized to discover the potential candidates from indirect neighbors. Then HodgeRank is introduced to determine the latent direct neighbors according to their importance to the target. After that, neighborhood relationships are augmented with the selected latent direct neighbors, and the adjacency tensor of the heterogeneous graph is refactored correspondingly. Finally, Graph Transformer Network is adopted to construct semantic meta-paths automatically and generate HGR. Numerical experiments on different real-world heterogeneous networks show that our new approach can produce more meta-path instances and introduce more complex and diverse semantic information, and consequently achieves more accurate predictions compared with several state-of-the-art baselines. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, X.
AU  - Jia, M.
AU  - Wang, Q.
AU  - Zhang, J.
TI  - A Simple Visual-Textual Baseline for Pedestrian Attribute Recognition
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 10
SP  - 6994
EP  - 7004
DO  - 10.1109/TCSVT.2022.3178144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139747968&doi=10.1109%2fTCSVT.2022.3178144&partnerID=40&md5=6451504df414a4cfc4678ac9c2b3aad3
AB  - Pedestrian attribute recognition (PAR), which aims to identify attributes of the pedestrians captured in video surveillance, is a challenging task due to the poor quality of images and diverse spatial distribution among attributes. Existing methods usually model PAR as a multi-label classification problem and manually map attributes to an ordered list corresponding to the outputs of classifiers or sequential models. However, the inherent textual information among attribute annotations is largely neglected in these visual-only methods. In this paper, we first alleviate this issue by proposing a novel visual-textual baseline (VTB) for PAR which introduces an additional textual modality to explore the textual semantic correlations from attribute annotations by pre-trained textual encoders instead of human definitions. VTB encodes pedestrian images and attribute annotations into visual and textual features respectively, interacts with information across modalities, and predicts recognition results independently to remove the influence of attribute orders. Furthermore, we introduce transformer encoder as the cross-modal fusion module in VTB for sufficient intra-modal and cross-modal correlations exploration. Our method achieves superior performance over most existing visual-only methods on two widely used datasets including RAP and PA-100K, demonstrating the effectiveness of utilizing textual modality to PAR. Our method is expected to serve as a multimodal PAR baseline and inspire new insights for multimodal fusion in future PAR research. Our code is available at https://github.com/cxh0519/VTB.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Lu, J.
AU  - Cai, Y.
AU  - Wang, C.
AU  - He, G.
TI  - Exploring Contextual Relationships in 3D Cloud Points by Semantic Knowledge Mining
PY  - 2022
T2  - Computer Graphics Forum
VL  - 41
IS  - 7
SP  - 75
EP  - 86
DO  - 10.1111/cgf.14658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150679431&doi=10.1111%2fcgf.14658&partnerID=40&md5=16526612470a7a67c844da74fb209727
AB  - 3D scene graph generation (SGG) aims to predict the class of objects and predicates simultaneously in one 3D point cloud scene with instance segmentation. Since the underlying semantic of 3D point clouds is spatial information, recent ideas of the 3D SGG task usually face difficulties in understanding global contextual semantic relationships and neglect the intrinsic 3D visual structures. To build the global scope of semantic relationships, we first propose two types of Semantic Clue (SC) from entity level and path level, respectively. SC can be extracted from the training set and modeled as the co-occurrence probability between entities. Then a novel Semantic Clue aware Graph Convolution Network (SC-GCN) is designed to explicitly model each SC of which the message is passed in their specific neighbor pattern. For constructing the interactions between the 3D visual and semantic modalities, a visual-language transformer (VLT) module is proposed to jointly learn the correlation between 3D visual features and class label embeddings. Systematic experiments on the 3D semantic scene graph (3DSSG) dataset show that our full method achieves state-of-the-art performance. © 2022 The Author(s) Computer Graphics Forum © 2022 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jing, T.
AU  - Zheng, P.
AU  - Xia, L.
AU  - Liu, T.
TI  - Transformer-based hierarchical latent space VAE for interpretable remaining useful life prediction
PY  - 2022
T2  - Advanced Engineering Informatics
VL  - 54
C7  - 101781
DO  - 10.1016/j.aei.2022.101781
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141265417&doi=10.1016%2fj.aei.2022.101781&partnerID=40&md5=23fcedc8324e961e71368349f9cdce30
AB  - Data-driven prediction of remaining useful life (RUL) has emerged as one of the most sought-after research in prognostics and health management (PHM). Nevertheless, most RUL prediction methods based on deep learning are black-box models that lack a visual interpretation to understand the RUL degradation process. To remedy the deficiency, we propose an intrinsically interpretable RUL prediction method based on three main modules: a temporal fusion separable convolutional network (TF-SCN), a hierarchical latent space variational auto-encoder (HLS-VAE), and a regressor. TF-SCN is used to extract the local feature information of the temporal signal. HLS-VAE is based on a transformer backbone that mines long-term temporal dependencies and compresses features into a hierarchical latent space. To enhance the streaming representation of the latent space, the temporal degradation information, i.e., health indicators (HI), is incorporated into the latent space in the form of inductive bias by using intermediate latent variables. The latent space can be used as a visual representation with self-interpretation to evaluate RUL degradation patterns visually. Experiments based on turbine engines show that the proposed approach achieves the same high-quality RUL prediction as black-box models while providing a latent space in which degradation rate can be captured to provide the interpretable evaluation. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Yan, H.
AU  - Ma, X.
AU  - Pu, Z.
TI  - Learning Dynamic and Hierarchical Traffic Spatiotemporal Features with Transformer
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 11
SP  - 22386
EP  - 22399
DO  - 10.1109/TITS.2021.3102983
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113308926&doi=10.1109%2fTITS.2021.3102983&partnerID=40&md5=522c9bc398a5cde89af88b3b9c8101e2
AB  - Traffic forecasting has attracted considerable attention due to its importance in proactive urban traffic control and management. Scholars and engineers have exerted considerable efforts in improving the performance of traffic forecasting algorithms in terms of accuracy, reliability, and efficiency. Spatial feature representation of traffic flow is a core component that greatly influences traffic forecasting performance. In previous studies, several spatial attributes of traffic flow are ignored due to the following issues: a) traffic flow propagation does not comply with the road network, b) the spatial pattern of traffic flow varies over time, and c) single adjacent matrix cannot handle the complex and hierarchical urban traffic flow. To address the abovementioned issues, this study proposes a novel traffic forecasting algorithm called traffic transformer, which achieves great success in natural language processing. The multihead attention mechanism and stacking layers enable the transformer to learn dynamic and hierarchical features in sequential data. Two components, namely, global encoder and global-local decoder, are proposed to extract and fuse the spatial patterns globally and locally. Experimental results indicate that the proposed traffic transformer outperforms state-of-the-art methods. The learned dynamic and hierarchical features of traffic flow can help achieve a better understanding of spatial dependency of traffic flow for effective and efficient traffic control and management strategies.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 125
C2  - CCF:B期刊; FMS:B; 
LB  - Yan2022Learning
ER  -

TY  - JOUR
AU  - Chen, Z.
AU  - Chen, H.
AU  - Gong, L.
AU  - Yan, X.
AU  - Wang, J.
AU  - Guo, Y.
AU  - Qin, J.
AU  - Wei, M.
TI  - UTOPIC: Uncertainty-aware Overlap Prediction Network for Partial Point Cloud Registration
PY  - 2022
T2  - Computer Graphics Forum
VL  - 41
IS  - 7
SP  - 87
EP  - 98
DO  - 10.1111/cgf.14659
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150684046&doi=10.1111%2fcgf.14659&partnerID=40&md5=126b3e37cedbf3ea2728d7fc9ae63bed
AB  - High-confidence overlap prediction and accurate correspondences are critical for cutting-edge models to align paired point clouds in a partial-to-partial manner. However, there inherently exists uncertainty between the overlapping and non-overlapping regions, which has always been neglected and significantly affects the registration performance. Beyond the current wisdom, we propose a novel uncertainty-aware overlap prediction network, dubbed UTOPIC, to tackle the ambiguous overlap prediction problem; to our knowledge, this is the first to explicitly introduce overlap uncertainty to point cloud registration. Moreover, we induce the feature extractor to implicitly perceive the shape knowledge through a completion decoder, and present a geometric relation embedding for Transformer to obtain transformation-invariant geometry-aware feature representations. With the merits of more reliable overlap scores and more precise dense correspondences, UTOPIC can achieve stable and accurate registration results, even for the inputs with limited overlapping areas. Extensive quantitative and qualitative experiments on synthetic and real benchmarks demonstrate the superiority of our approach over state-of-the-art methods. © 2022 The Author(s) Computer Graphics Forum © 2022 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Efendiev, Y.
AU  - Leung, W.T.
AU  - Lin, G.
AU  - Zhang, Z.
TI  - Efficient hybrid explicit-implicit learning for multiscale problems
PY  - 2022
T2  - Journal of Computational Physics
VL  - 467
C7  - 111326
DO  - 10.1016/j.jcp.2022.111326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133854495&doi=10.1016%2fj.jcp.2022.111326&partnerID=40&md5=5a580b90f8074acb08821d804dd2762c
AB  - Splitting method is a powerful method to handle application problems by splitting physics, scales, domain, and so on. Many splitting algorithms have been designed for efficient temporal discretization. In this paper, our goal is to use temporal splitting concepts in designing machine learning algorithms and, at the same time, help splitting algorithms by incorporating data and speeding them up. We propose a machine learning assisted splitting scheme which improves the efficiency of the scheme meanwhile preserves the accuracy. We consider a recently introduced multiscale splitting algorithms, where the multiscale problem is solved on a coarse grid. To approximate the dynamics, only a few degrees of freedom are solved implicitly, while others explicitly. This splitting concept allows identifying degrees of freedom that need implicit treatment. In this paper, we use this splitting concept in machine learning and propose several strategies. First, the implicit part of the solution can be learned as it is more difficult to solve, while the explicit part can be computed. This provides a speed-up and data incorporation for splitting approaches. Secondly, one can design a hybrid neural network architecture because handling explicit parts requires much fewer communications among neurons and can be done efficiently. Thirdly, one can solve the coarse grid component via PDEs or other approximation methods and construct simpler neural networks for the explicit part of the solutions. We discuss these options and implement one of them by interpreting it as a machine translation task. This interpretation of the splitting scheme successfully enables us using the Transformer since it can perform model reduction for multiple time series and learn the connection between them. We also find that the splitting scheme is a great platform to predict the coarse solution with insufficient information of the target model: the target problem is partially given and we need to solve it through a known problem which approximates the target. Our machine learning model can incorporate and encode the given information from two different problems and then solve the target problems. We conduct four numerical examples and the results show that our method is stable and accurate. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Bhatia, S.
AU  - Richie, R.
TI  - Transformer Networks of Human Conceptual Knowledge
PY  - 2022
T2  - Psychological Review
VL  - 131
IS  - 1
SP  - 271
EP  - 306
DO  - 10.1037/rev0000319
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142275891&doi=10.1037%2frev0000319&partnerID=40&md5=a49c26cdd25435d9a12793a5fe6c2e12
AB  - We present a computational model capable of simulating aspects of human knowledge for thousands of real-world concepts. Our approach involves a pretrained transformer network that is further fine-tuned on large data sets of participant-generated feature norms. We show that such a model can successfully extrapolate from its training data, and predict human knowledge for new concepts and features. We apply our model to stimuli from 25 previous experiments in semantic cognition research and show that it reproduces many findings on semantic verification, concept typicality, feature distribution, and semantic similarity. We also compare our model against several variants, and by doing so, establish the model properties that are necessary for good prediction. The success of our approach shows how a combination of language data and (laboratory-based) psychological data can be used to build models with rich world knowledge. Such models can be used in the service of new psychological applications, such as the modeling of naturalistic semantic verification and knowledge retrieval, as well as the modeling of real-world categorization, decision-making, and reasoning. © 2022 American Psychological Association
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - AJG:4; zdy:4; 
LB  - Bhatia2022Transformer
ER  -

TY  - JOUR
AU  - Aizenshtein-Gazit, S.
AU  - Orenstein, Y.
TI  - DeepZF: Improved DNA-binding prediction of C2H2-zinc-finger proteins by deep transfer learning
PY  - 2022
T2  - Bioinformatics
VL  - 38
SP  - II62
EP  - II67
DO  - 10.1093/bioinformatics/btac469
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138200337&doi=10.1093%2fbioinformatics%2fbtac469&partnerID=40&md5=55b12c97c3647c0a2000b0f18efdf450
AB  - Motivation: Cys2His2 zinc-finger (C2H2-ZF) proteins are the largest class of human transcription factors and hence play central roles in gene regulation and cell function. C2H2-ZF proteins are characterized by a DNA-binding domain containing multiple ZFs. A subset of the ZFs bind diverse DNA triplets. Despite their central roles, little is known about which of their ZFs are binding and how the DNA-binding preferences are encoded in the amino acid sequence of each ZF. Results: We present DeepZF, a deep-learning-based pipeline for predicting binding ZFs and their DNA-binding preferences given only the amino acid sequence of a C2H2-ZF protein. To the best of our knowledge, we compiled the first in vivo dataset of binding and non-binding ZFs for training the first ZF-binding classifier. Our classifier, which is based on a novel protein transformer, achieved an average AUROC of 0.71. Moreover, we took advantage of both in vivo and in vitro datasets to learn the recognition code of ZF-DNA binding through transfer learning. Our newly developed model, which is the first to utilize deep learning for the task, achieved an average Pearson correlation greater than 0.94 over each of the three DNA binding positions. Together, DeepZF outperformed extant methods in the task of C2H2-ZF protein DNA-binding preferences prediction: it achieved an average Pearson correlation of 0.42 in motif similarity compared with an average correlation smaller than 0.1 achieved by extant methods. By applying established interpretability techniques, we show that DeepZF inferred biologically relevant binding principles, such as the effect of amino acid residue positions on ZF DNA-binding potential. © 2022 The Author(s). Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, S.
AU  - Wang, Y.
AU  - Deng, Y.
AU  - He, L.
AU  - Shao, B.
AU  - Yin, J.
AU  - Zheng, N.
AU  - Liu, T.-Y.
AU  - Wang, T.
TI  - Improved drug-target interaction prediction with intermolecular graph transformer
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 5
C7  - bbac162
DO  - 10.1093/bib/bbac162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138492926&doi=10.1093%2fbib%2fbbac162&partnerID=40&md5=dbd589ff96d0b74089b3a6152239aa9a
AB  - The identification of active binding drugs for target proteins (referred to as drug-target interaction prediction) is the key challenge in virtual screening, which plays an essential role in drug discovery. Although recent deep learning-based approaches achieve better performance than molecular docking, existing models often neglect topological or spatial of intermolecular information, hindering prediction performance. We recognize this problem and propose a novel approach called the Intermolecular Graph Transformer (IGT) that employs a dedicated attention mechanism to model intermolecular information with a three-way Transformer-based architecture. IGT outperforms state-of-the-art (SoTA) approaches by 9.1% and 20.5% over the second best option for binding activity and binding pose prediction, respectively, and exhibits superior generalization ability to unseen receptor proteins than SoTA approaches. Furthermore, IGT exhibits promising drug screening ability against severe acute respiratory syndrome coronavirus 2 by identifying 83.1% active drugs that have been validated by wet-lab experiments with near-native predicted binding poses. Source code and datasets are available at https://github.com/microsoft/IGT-Intermolecular-Graph-Transformer. © 2022 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Zhang, H.
AU  - Zhao, F.
AU  - Hu, Y.
AU  - Tan, C.
AU  - Yang, J.
TI  - Intention-Aware Vehicle Trajectory Prediction Based on Spatial-Temporal Dynamic Attention Network for Internet of Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
SP  - 19471
EP  - 19483
DO  - 10.1109/TITS.2022.3170551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129432452&doi=10.1109%2fTITS.2022.3170551&partnerID=40&md5=de48ab115b1b3760ee0888cb31e1895a
AB  - Vehicle trajectory prediction is a keystone for the application of the internet of vehicles (IoV). With the help of deep learning and big data, it is possible to understand the between-vehicle interaction pattern hidden in the complex traffic environment. In this paper, we propose a novel spatial-temporal dynamic attention network for vehicle trajectory prediction, which can comprehensively capture temporal and social patterns in a hierarchical manner. The social relation between vehicles is captured at each timestamp and thus retains the dynamic variation of interaction. The temporal correlation in terms of individual motion state as well as social interaction is captured by different sequential models. Furthermore, a driving intention-specific feature fusion mechanism is proposed such that the extracted temporal and social features can be integrated adaptively for the maneuver-based multi-modal trajectory prediction. Experimental results on two real-world datasets show that compared with the state-of-the-art algorithms, our proposal achieves comparable prediction performance for short-term prediction, however, works much better for long-term prediction. Additionally, various ablation analysis is provided to evaluate the effectiveness of our proposed network components. The code will be available at https://xbchen82.github.io/resource/.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 89
C2  - CCF:B期刊; FMS:B; 
LB  - Chen2022Intention-Aware
ER  -

TY  - JOUR
AU  - Kriebel, J.
AU  - Stitz, L.
TI  - Credit default prediction from user-generated text in peer-to-peer lending using deep learning
PY  - 2022
T2  - European Journal of Operational Research
VL  - 302
IS  - 1
SP  - 309
EP  - 323
DO  - 10.1016/j.ejor.2021.12.024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123016411&doi=10.1016%2fj.ejor.2021.12.024&partnerID=40&md5=83a66e0239624d936757e138fadbb49a
AB  - Digital technologies produce vast amounts of unstructured data that can be stored and accessed by traditional banks and fintech companies. We employ deep learning and several other techniques to extract credit-relevant information from user-generated text on Lending Club. Our results show that even short pieces of user-generated text can improve credit default predictions significantly. The importance of text is further supported by an information fusion analysis. Compared with other approaches that use text, deep learning outperforms them in almost all cases. However, machine learning models combined with word frequencies or topic models also extract substantial credit-relevant information. A comparison of six deep neural network architectures, including state-of-the-art transformer models, finds that the architectures mostly provide similar performance. This means that simpler methods (such as average embedding neural networks) offer performance comparable to more complex methods (such as the transformer networks BERT and RoBERTa) in this credit scoring setting. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 46
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Kriebel2022Credit
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Wan, Y.
AU  - Qin, J.
AU  - Fu, W.
AU  - Kang, Y.
TI  - A Deep RL-Based Algorithm for Coordinated Charging of Electric Vehicles
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
SP  - 18774
EP  - 18784
DO  - 10.1109/TITS.2022.3170000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129441475&doi=10.1109%2fTITS.2022.3170000&partnerID=40&md5=c7f57e67f67cce8e34aae1e38d285188
AB  - The development of electric vehicle (EV) industry is facing a series of issues, among which the efficient charging of multiple EVs needs solving desperately. This paper investigates the coordinated charging of multiple EVs with the aim of reducing the charging cost, ensuring a high battery state of charge (SoC), and avoiding the transformer overload. To this end, we first formulate the EV coordinated charging problem with the above multiple objectives as a Markov Decision Process (MDP) and then propose a multi-agent deep reinforcement learning (DRL)-based algorithm. In the proposed algorithm, a novel interaction model, i.e., communication neural network (CommNet) model, is adopted to realize the distributed computation of global information (namely the electricity price, the transformer load, and the total charging cost of multiple EVs). Moreover, different from the most existing works which make specific constraints on the size, the location, or the topology of the distribution network, what we need in the proposed method is only the transformer load. Besides, due to the use of long and short-term memory (LSTM) for price prediction, the proposed algorithm can flexibly deal with various uncertain price mechanisms. Finally, simulations are presented to verify the effectiveness and practicability of the proposed algorithm in a residential charging area.  © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2022Deep
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Han, H.
AU  - Wang, L.
AU  - Li, X.
AU  - Zhou, L.
TI  - Automated Radiographic Report Generation Purely on Transformer: A Multicriteria Supervised Approach
PY  - 2022
T2  - IEEE Transactions on Medical Imaging
VL  - 41
IS  - 10
SP  - 2803
EP  - 2813
DO  - 10.1109/TMI.2022.3171661
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129657020&doi=10.1109%2fTMI.2022.3171661&partnerID=40&md5=8a2f13daf798e37568acebc2f2992649
AB  - Automated radiographic report generation is challenging in at least two aspects. First, medical images are very similar to each other and the visual differences of clinic importance are often fine-grained. Second, the disease-related words may be submerged by many similar sentences describing the common content of the images, causing the abnormal to be misinterpreted as the normal in the worst case. To tackle these challenges, this paper proposes a pure transformer-based framework to jointly enforce better visual-textual alignment, multi-label diagnostic classification, and word importance weighting, to facilitate report generation. To the best of our knowledge, this is the first pure transformer-based framework for medical report generation, which enjoys the capacity of transformer in learning long range dependencies for both image regions and sentence words. Specifically, for the first challenge, we design a novel mechanism to embed an auxiliary image-text matching objective into the transformer's encoder-decoder structure, so that better correlated image and text features could be learned to help a report to discriminate similar images. For the second challenge, we integrate an additional multi-label classification task into our framework to guide the model in making correct diagnostic predictions. Also, a term-weighting scheme is proposed to reflect the importance of words for training so that our model would not miss key discriminative information. Our work achieves promising performance over the state-of-the-arts on two benchmark datasets, including the largest dataset MIMIC-CXR.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Sun, H.
AU  - Rao, Y.
AU  - Zhou, J.
AU  - Lu, J.
TI  - Video Saliency Forecasting Transformer
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 10
SP  - 6850
EP  - 6862
DO  - 10.1109/TCSVT.2022.3172971
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132525914&doi=10.1109%2fTCSVT.2022.3172971&partnerID=40&md5=e1f7c3fbbdc5cf9adf0be5803da0ffa4
AB  - Video saliency prediction (VSP) aims to imitate eye fixations of humans. However, the potential of this task has not been fully exploited since existing VSP methods only focus on modeling visual saliency of the input previous frames. In this paper, we present the first attempt to extend this task to video saliency forecasting (VSF) by forecasting attention regions of consecutive future frames. To tackle this problem, we propose a video saliency forecasting transformer (VSFT) network built on a new encoder-decoder architecture. Different from existing VSP methods, our VSFT is the first pure-transformer based architecture in the VSP field and is freed from the dependency of the pretrained S3D model. In VSFT, the attention mechanism is exploited to capture spatial-temporal dependencies between the input past frames and the target future frame. We propose cross-attention guidance blocks (CAGB) to aggregate multi-level representation features to provide sufficient guidance for forecasting. We conduct comprehensive experiments on two benchmark datasets, DHF1K and Hollywoods-2. We investigate the saliency forecasting and predicting abilities of existing VSP methods by modifying the supervision signals. Experimental results demonstrate that our method achieves superior performance on both VSF and VSP tasks.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 37
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Liu, Y.
AU  - Li, B.
AU  - Feng, B.
AU  - Wu, K.
AU  - Peng, C.
AU  - Hu, W.
TI  - SDTP: Semantic-Aware Decoupled Transformer Pyramid for Dense Image Prediction
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 9
SP  - 6160
EP  - 6173
DO  - 10.1109/TCSVT.2022.3162069
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137663197&doi=10.1109%2fTCSVT.2022.3162069&partnerID=40&md5=8d6a65408a41af9f0b2c71ca9a802519
AB  - Although transformer has achieved great progress on computer vision tasks, the scale variation in dense image prediction is still the key challenge. Few effective multi-scale techniques are applied in transformer and there are two main limitations in the current methods. On the one hand, self-Attention module in vanilla transformer fails to sufficiently exploit the diversity of semantic information because of its rigid mechanism. On the other hand, it is difficult to build attention and interaction among different levels due to the heavy computational burden. To alleviate this problem, we first revisit multi-scale problem in dense prediction, verifying the significance of diverse semantic representation and multi-scale interaction, and exploring the adaptation of transformer to pyramidal structure. Inspired by these findings, we propose a novel Semantic-Aware Decoupled Transformer Pyramid (SDTP) for dense image prediction, consisting of Intra-level Semantic Promotion (ISP), Cross-level Decoupled Interaction (CDI) and Attention Refinement Function (ARF). ISP explores the semantic diversity in different receptive space through more flexible self-Attention strategy. CDI builds the global attention and interaction among different levels in decoupled space which also solves the problem of heavy computation. Besides, ARF is further added to refine the attention in transformer. Experimental results demonstrate the validity and generality of the proposed method, which outperforms the state-of-The-Art by a significant margin in dense image prediction tasks. Furthermore, the proposed components are all plug-And-play, which can be embedded in other methods.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shu, H.
AU  - Ding, F.
AU  - Zhou, J.
AU  - Xue, Y.
AU  - Zhao, D.
AU  - Zeng, J.
AU  - Ma, J.
TI  - Boosting single-cell gene regulatory network reconstruction via bulk-cell transcriptomic data
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 5
C7  - bbac389
DO  - 10.1093/bib/bbac389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138492950&doi=10.1093%2fbib%2fbbac389&partnerID=40&md5=d44e86eef0cdb12b9b8b351ab0463d41
AB  - Computational recovery of gene regulatory network (GRN) has recently undergone a great shift from bulk-cell towards designing algorithms targeting single-cell data. In this work, we investigate whether the widely available bulk-cell data could be leveraged to assist the GRN predictions for single cells. We infer cell-type-specific GRNs from both the single-cell RNA sequencing data and the generic GRN derived from the bulk cells by constructing a weakly supervised learning framework based on the axial transformer. We verify our assumption that the bulk-cell transcriptomic data are a valuable resource, which could improve the prediction of single-cell GRN by conducting extensive experiments. Our GRN-transformer achieves the state-of-the-art prediction accuracy in comparison to existing supervised and unsupervised approaches. In addition, we show that our method can identify important transcription factors and potential regulations for Alzheimer's disease risk genes by using the predicted GRN. Availability: The implementation of GRN-transformer is available at https://github.com/HantaoShu/GRN-Transformer.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Latifi, S.
AU  - Jannach, D.
AU  - Ferraro, A.
TI  - Sequential recommendation: A study on transformers, nearest neighbors and sampled metrics
PY  - 2022
T2  - Information Sciences
VL  - 609
SP  - 660
EP  - 678
DO  - 10.1016/j.ins.2022.07.079
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134888073&doi=10.1016%2fj.ins.2022.07.079&partnerID=40&md5=c72309eccbc12981d0be587c95ea7bea
AB  - Sequential recommendation problems have received increased research interest in recent years. In such scenarios, the task is to suggest items to users to consume next, given their past interaction history, e.g., the next movie to watch or the next item to place in the shopping cart. A number of machine learning models were proposed recently for the task of sequential recommendation, with the latest ones based on deep learning techniques, in particular on Transformers. Given the often surprisingly competitive performance of simpler nearest-neighbor methods for the related problem of session-based recommendation, we investigate the use of nearest-neighbor methods for sequential recommendation problems. Our analysis on four datasets shows that nearest-neighbor methods achieve comparable or better performance than the recent Transformer-based BERT4REC method on two of them. However, the deep learning method outperforms the simple methods for the two larger datasets, confirming previous hypotheses that neural methods work best when more data is available. As a further result of our experiments, we found additional evidence that sampled metrics must be used with care, as they may not be predictive of an algorithm ranking that would be observed with the non-sampled, full evaluation. © 2022 The Author(s)
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; FMS:B; 
LB  - Latifi2022Sequential
ER  -

TY  - JOUR
AU  - Hu, J.
AU  - Gao, J.
AU  - Fang, X.
AU  - Liu, Z.
AU  - Wang, F.
AU  - Huang, W.
AU  - Wu, H.
AU  - Zhao, G.
TI  - DTSyn: A dual-transformer-based neural network to predict synergistic drug combinations
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 5
C7  - bbac302
DO  - 10.1093/bib/bbac302
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138495300&doi=10.1093%2fbib%2fbbac302&partnerID=40&md5=eaabb69b20daac1217f9a7ca349ebb01
AB  - Drug combination therapies are superior to monotherapy for cancer treatment in many ways. Identifying novel drug combinations by screening is challenging for the wet-lab experiments due to the time-consuming process of the enormous search space of possible drug pairs. Thus, computational methods have been developed to predict drug pairs with potential synergistic functions. Notwithstanding the success of current models, understanding the mechanism of drug synergy from a chemical-gene-tissue interaction perspective lacks study, hindering current algorithms from drug mechanism study. Here, we proposed a deep neural network model termed DTSyn (Dual Transformer encoder model for drug pair Synergy prediction) based on a multi-head attention mechanism to identify novel drug combinations. We designed a fine-granularity transformer encoder to capture chemical substructure-gene and gene-gene associations and a coarse-granularity transformer encoder to extract chemical-chemical and chemical-cell line interactions. DTSyn achieved the highest receiver operating characteristic area under the curve of 0.73, 0.78. 0.82 and 0.81 on four different cross-validation tasks, outperforming all competing methods. Further, DTSyn achieved the best True Positive Rate (TPR) over five independent data sets. The ablation study showed that both transformer encoder blocks contributed to the performance of DTSyn. In addition, DTSyn can extract interactions among chemicals and cell lines, representing the potential mechanisms of drug action. By leveraging the attention mechanism and pretrained gene embeddings, DTSyn shows improved interpretability ability. Thus, we envision our model as a valuable tool to prioritize synergistic drug pairs with chemical and cell line gene expression profile. © 2022 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Zhu, G.
AU  - Li, K.
AU  - Li, F.
AU  - Huang, L.
AU  - Duan, M.
AU  - Zhou, F.
TI  - HLAB: Learning the BiLSTM features from the ProtBert-encoded proteins for the class i HLA-peptide binding prediction
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 5
C7  - bbac173
DO  - 10.1093/bib/bbac173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138492272&doi=10.1093%2fbib%2fbbac173&partnerID=40&md5=c815d44b402f50316a742cda7000447e
AB  - Human Leukocyte Antigen (HLA) is a type of molecule residing on the surfaces of most human cells and exerts an essential role in the immune system responding to the invasive items. The T cell antigen receptors may recognize the HLA-peptide complexes on the surfaces of cancer cells and destroy these cancer cells through toxic T lymphocytes. The computational determination of HLA-binding peptides will facilitate the rapid development of cancer immunotherapies. This study hypothesized that the natural language processing-encoded peptide features may be further enriched by another deep neural network. The hypothesis was tested with the Bi-directional Long Short-Term Memory-extracted features from the pretrained Protein Bidirectional Encoder Representations from Transformers-encoded features of the class I HLA (HLA-I)-binding peptides. The experimental data showed that our proposed HLAB feature engineering algorithm outperformed the existing ones in detecting the HLA-I-binding peptides. The extensive evaluation data show that the proposed HLAB algorithm outperforms all the seven existing studies on predicting the peptides binding to the HLA-A∗01:01 allele in AUC and achieves the best average AUC values on the six out of the seven k-mers (k=8,9,...,14, respectively represent the prediction task of a polypeptide consisting of k amino acids) except for the 9-mer prediction tasks. The source code and the fine-tuned feature extraction models are available at http://www.healthinformaticslab.org/supp/resources.php. © 2022 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Abdelraouf, A.
AU  - Abdel-Aty, M.
AU  - Wu, Y.
TI  - Using Vision Transformers for Spatial-Context-Aware Rain and Road Surface Condition Detection on Freeways
PY  - 2022
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
SP  - 18546
EP  - 18556
DO  - 10.1109/TITS.2022.3150715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125353337&doi=10.1109%2fTITS.2022.3150715&partnerID=40&md5=30f9b01002133721f58d893cf71913c6
AB  - Inclement weather conditions, particularly heavy rain and the consequent wet road surface, have an unfavorable effect on driving conditions, traffic infrastructure, and operational plans. To mitigate the potentially detrimental ramifications of turbulent weather, it must be continuously monitored in real time and with high geospatial granularity. Traditionally, road weather conditions are monitored using weather forecasts or Roadside Weather Information Systems (RWIS). However, these methods are either ill-equipped or too expensive to provide the required fine-grained observations. Alternatively, roadside traffic CCTV cameras are ubiquitously deployed on US freeways and can serve as inexpensive sensors to surveil weather. In this paper, a novel vision-based methodology is proposed to detect rain and road surface conditions from roadside traffic cameras. Vision Transformers were utilized for image-based classification. They demonstrated superior results compared to convolution-based approaches. Furthermore, the geographical distribution of roadside cameras was leveraged to add spatial context awareness to the detection model. A Spatial Self-Attention network was proposed to model the relationship between the detection results of adjacent images as a sequence-to-sequence detection task. The results indicate that the addition of the sequential detection module improved the accuracy of the stand-alone Vision Transformer as measured by the F1-score. The boost in performance enhanced the F1-scores of the stand-alone Vision Transformer by 5.61% and 5.97% for the rain and road surface condition detection tasks, respectively, raising the total F1-score to 96.71% and 98.07%. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 35
C2  - CCF:B期刊; FMS:B; 
LB  - Abdelraouf2022Using
ER  -

TY  - JOUR
AU  - Zeng, Y.
AU  - Wei, Z.
AU  - Yu, W.
AU  - Yin, R.
AU  - Yuan, Y.
AU  - Li, B.
AU  - Tang, Z.
AU  - Lu, Y.
AU  - Yang, Y.
TI  - Spatial transcriptomics prediction from histology jointly through Transformer and graph neural networks
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 5
C7  - bbac297
DO  - 10.1093/bib/bbac297
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137757070&doi=10.1093%2fbib%2fbbac297&partnerID=40&md5=e258ade05fd8cbd433c5373dea316ade
AB  - The rapid development of spatial transcriptomics allows the measurement of RNA abundance at a high spatial resolution, making it possible to simultaneously profile gene expression, spatial locations of cells or spots, and the corresponding hematoxylin and eosin-stained histology images. It turns promising to predict gene expression from histology images that are relatively easy and cheap to obtain. For this purpose, several methods are devised, but they have not fully captured the internal relations of the 2D vision features or spatial dependency between spots. Here, we developed Hist2ST, a deep learning-based model to predict RNA-seq expression from histology images. Around each sequenced spot, the corresponding histology image is cropped into an image patch and fed into a convolutional module to extract 2D vision features. Meanwhile, the spatial relations with the whole image and neighbored patches are captured through Transformer and graph neural network modules, respectively. These learned features are then used to predict the gene expression by following the zero-inflated negative binomial distribution. To alleviate the impact by the small spatial transcriptomics data, a self-distillation mechanism is employed for efficient learning of the model. By comprehensive tests on cancer and normal datasets, Hist2ST was shown to outperform existing methods in terms of both gene expression prediction and spatial region identification. Further pathway analyses indicated that our model could reserve biological information. Thus, Hist2ST enables generating spatial transcriptomics data from histology images for elucidating molecular signatures of tissues. © 2022 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 48
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Polignano, M.
AU  - Basile, V.
AU  - Basile, P.
AU  - Gabrieli, G.
AU  - Vassallo, M.
AU  - Bosco, C.
TI  - A hybrid lexicon-based and neural approach for explainable polarity detection
PY  - 2022
T2  - Information Processing and Management
VL  - 59
IS  - 5
C7  - 103058
DO  - 10.1016/j.ipm.2022.103058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136626031&doi=10.1016%2fj.ipm.2022.103058&partnerID=40&md5=433ed017f34988a79c2a4e319a1362ec
AB  - In this work, we propose BERT-WMAL, a hybrid model that brings together information coming from data through the recent transformer deep learning model and those obtained from a polarized lexicon. The result is a model for sentence polarity that manages to have performances comparable with those at the state-of-the-art, but with the advantage of being able to provide the end-user with an explanation regarding the most important terms involved with the provided prediction. The model has been evaluated on three polarity detection Italian dataset, i.e., SENTIPOLC, AGRITREND and ABSITA. While the first contains 7,410 tweets released for training and 2,000 for testing, the second and the third respectively include 1,000 tweets without splitting, and 2,365 reviews for training, 1,171 for testing. The use of lexicon-based information proves to be effective in terms of the F1 measure since it shows an improvement of F1 score on all the observed dataset: from 0.664 to 0.669 (i.e, 0.772%) on AGRITREND, from 0.728 to 0.734 (i.e., 0.854%) on SENTIPOLC and from 0.904 to 0.921 (i.e, 1.873%) on ABSITA. The usefulness of this model not only depends on its effectiveness in terms of the F1 measure, but also on its ability to generate predictions that are more explainable and especially convincing for the end-users. We evaluated this aspect through a user study involving four native Italian speakers, each evaluating 64 sentences with associated explanations. The results demonstrate the validity of this approach based on a combination of weights of attention extracted from the deep learning model and the linguistic knowledge stored in the WMAL lexicon. These considerations allow us to regard the approach provided in this paper as a promising starting point for further works in this research area. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Yu, L.
AU  - Ding, X.
AU  - Liao, X.
AU  - Wang, L.
TI  - Lymph Node Metastasis Prediction From Whole Slide Images With Transformer-Guided Multiinstance Learning and Knowledge Transfer
PY  - 2022
T2  - IEEE Transactions on Medical Imaging
VL  - 41
IS  - 10
SP  - 2777
EP  - 2787
DO  - 10.1109/TMI.2022.3171418
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129671583&doi=10.1109%2fTMI.2022.3171418&partnerID=40&md5=77bf956bd7c3ee59c7205b6779796ba0
AB  - The gold standard for diagnosing lymph node metastasis of papillary thyroid carcinoma is to analyze the whole slide histopathological images (WSIs). Due to the large size of WSIs, recent computer-aided diagnosis approaches adopt the multi-instance learning (MIL) strategy and the key part is how to effectively aggregate the information of different instances (patches). In this paper, a novel transformer-guided framework is proposed to predict lymph node metastasis from WSIs, where we incorporate the transformer mechanism to improve the accuracy from three different aspects. First, we propose an effective transformer-based module for discriminative patch feature extraction, including a lightweight feature extractor with a pruned transformer (Tiny-ViT) and a clustering-based instance selection scheme. Next, we propose a new Transformer-MIL module to capture the relationship of different discriminative patches with sparse distribution on WSIs and better nonlinearly aggregate patch-level features into the slide-level prediction. Considering that the slide-level annotation is relatively limited to training a robust Transformer-MIL, we utilize the pathological relationship between the primary tumor and its lymph node metastasis and develop an effective attention-based mutual knowledge distillation (AMKD) paradigm. Experimental results on our collected WSI dataset demonstrate the efficiency of the proposed Transformer-MIL and attention-based knowledge distillation. Our method outperforms the state-of-the-art methods by over 2.72% in AUC (area under the curve).  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jahanbakht, M.
AU  - Xiang, W.
AU  - Azghadi, M.R.
TI  - Sediment Prediction in the Great Barrier Reef using Vision Transformer with finite element analysis
PY  - 2022
T2  - Neural Networks
VL  - 152
SP  - 311
EP  - 321
DO  - 10.1016/j.neunet.2022.04.022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130079892&doi=10.1016%2fj.neunet.2022.04.022&partnerID=40&md5=c3f7a89a1c59b3c1f80df0eea077be02
AB  - Suspended sediment is a significant threat to the Great Barrier Reef (GBR) ecosystem. This catchment pollutant stems primarily from terrestrial soil erosion. Bulk masses of sediments have potential to propagate from river plumes into the mid-shelf and outer-shelf regions. Existing sediment forecasting methods suffer from the problem of low-resolution predictions, making them unsuitable for wide area coverage. In this paper, a novel sediment distribution prediction model is proposed to augment existing water quality management programs for the GBR. This model is based on the state-of-the-art Transformer network in conjunction with the well-known finite element analysis. For model training, the emerging physics-informed neural network is employed to incorporate both simulated and measured sediment data. Our proposed Finite Element Transformer (FE-Transformer) model offers accurate predictions of sediment across the entire GBR. It provides unblurred outputs, which cannot be achieved with previous next-frame prediction models. This paves a way for accurate forecasting of sediment, which in turn may lead to improved water quality management for the GBR. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bittar, T.
AU  - Carpentier, P.
AU  - Chancelier, J.-P.
AU  - Lonchampt, J.
TI  - A decomposition method by interaction prediction for the optimization of maintenance scheduling
PY  - 2022
T2  - Annals of Operations Research
VL  - 316
IS  - 1
SP  - 229
EP  - 267
DO  - 10.1007/s10479-021-04460-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122866825&doi=10.1007%2fs10479-021-04460-y&partnerID=40&md5=9ff0bd3e93aecd4e3f33f1b70f98eec4
AB  - Optimizing maintenance scheduling is a major issue to improve the performance of hydropower plants. We study a system of several physical components of the same family: either a set of turbines, a set of transformers or a set of generators. The components share a common stock of spare parts and experience random failures that occur according to known failure distributions. We seek a deterministic preventive maintenance strategy that minimizes an expected cost depending on maintenance and forced outages of the system. The Auxiliary Problem Principle is used to decompose the original large-scale optimization problem into a sequence of independent subproblems of smaller dimension while ensuring their coordination. Each subproblem consists in optimizing the maintenance on a single component. Decomposition-coordination techniques are based on variational techniques but the maintenance optimization problem is a mixed-integer problem. Therefore, we relax the dynamics and the cost functions of the system. The resulting algorithm iteratively solves the subproblems on the relaxed system with a blackbox method and coordinates the components. Relaxation parameters have an important influence on the optimization and must be appropriately chosen. An admissible maintenance strategy is then derived from the resolution of the relaxed problem. We apply the decomposition algorithm on a system with 80 components. It outperforms the reference blackbox method applied directly on the original problem. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Bittar2022decomposition
ER  -

TY  - JOUR
AU  - Nawaz, H.S.
AU  - Shi, Z.
AU  - Gan, Y.
AU  - Hirpa, A.
AU  - Dong, J.
AU  - Zheng, H.
TI  - Temporal Moment Localization via Natural Language by Utilizing Video Question Answers as a Special Variant and Bypassing NLP for Corpora
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 9
SP  - 6174
EP  - 6185
DO  - 10.1109/TCSVT.2022.3162650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127486069&doi=10.1109%2fTCSVT.2022.3162650&partnerID=40&md5=99e1d6c107fba7c5784e8460a371a368
AB  - Temporal moment localization using natural language (TMLNL) is an emerging issue in computer vision for localizing a specific moment inside a long, untrimmed video. The goal of TMLNL is to obtain the video's output moment, which is related to the input query in a substantial way. Previous research focused on the visual portion of TMLNL, such as objects, backdrops, and other visual attributes, but natural language processing (NLP) techniques were largely used for the textual portion. A long query requires sufficient context to properly localize moments within a long untrimmed video. Thus, as a consequence of not completely understanding how to handle queries, performances deteriorated, especially when the query was longer. In this paper, we treat the TMLNL challenge as a unique variation of VQA, which equally considers the visual elements by using our proposed VQA joint visual-Textual framework (JVTF). However, we also manage complex and long input queries without employing natural language processing (NLP) by improving poorly graded to finely graded distinct granularity representations. Our suggested BCPN searches for insufficient context for long input queries using an approach called query handler (QH) and helps the JVTF find the most relevant moment. Previously, a recurrence of words was caused by increasing the number of encoding layers in transformers, LSTMs, and other NLP techniques; however, our QH ensured that repetition of word locations was reduced. The output of BCPN is combined with JVTF's guided attention to further improve the end outcome. Therefore, we propose a novel bidirectional context predictor network (BCPN), in addition to a VQA joint visual-Textual framework (JVTF), to address the equal importance of videos and queries. Through extensive experiments on three benchmark datasets, we show that the proposed BCPN outperforms the state-of-The-Art methods by IoU = 0.3 (2.65%) IoU = 0.5 (2.49) , and IoU = 0.7 (2.06%). © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zhang, F.
AU  - Yu, X.
AU  - Keung, J.
AU  - Li, F.
AU  - Xie, Z.
AU  - Yang, Z.
AU  - Ma, C.
AU  - Zhang, Z.
TI  - Improving Stack Overflow question title generation with copying enhanced CodeBERT model and bi-modal information
PY  - 2022
T2  - Information and Software Technology
VL  - 148
C7  - 106922
DO  - 10.1016/j.infsof.2022.106922
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129387733&doi=10.1016%2fj.infsof.2022.106922&partnerID=40&md5=e90c3528ae58e4ceba29cae65f7891b8
AB  - Context: Stack Overflow is very helpful for software developers who are seeking answers to programming problems. Previous studies have shown that a growing number of questions are of low quality and thus obtain less attention from potential answerers. Gao et al. proposed an LSTM-based model (i.e., BiLSTM-CC) to automatically generate question titles from the code snippets to improve the question quality. However, only using the code snippets in the question body cannot provide sufficient information for title generation, and LSTMs cannot capture the long-range dependencies between tokens. Objective: This paper proposes CCBERT, a deep learning based novel model to enhance the performance of question title generation by making full use of the bi-modal information of the entire question body. Method: CCBERT follows the encoder–decoder paradigm and uses CodeBERT to encode the question body into hidden representations, a stacked Transformer decoder to generate predicted tokens, and an additional copy attention layer to refine the output distribution. Both the encoder and decoder perform the multi-head self-attention operation to better capture the long-range dependencies. This paper builds a dataset containing around 200,000 high-quality questions filtered from the data officially published by Stack Overflow to verify the effectiveness of the CCBERT model. Results: CCBERT outperforms all the baseline models on the dataset. Experiments on both code-only and low-resource datasets show the superiority of CCBERT with less performance degradation. The human evaluation also shows the excellent performance of CCBERT concerning both readability and correlation criteria. Conclusion: CCBERT is capable of automatically capturing the bi-modal semantic information from the entire question body and parsing the long-range dependencies to achieve better performance. Therefore, CCBERT is an effective approach for generating Stack Overflow question titles. © 2022 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; FMS:B; 
LB  - Zhang2022Improving
ER  -

TY  - JOUR
AU  - Wu, Y.
AU  - Liu, Q.
AU  - Qiu, Y.
AU  - Xie, L.
TI  - Deep learning prediction of chemical-induced dose-dependent and context-specific multiplex phenotype responses and its application to personalized alzheimer’s disease drug repurposing
PY  - 2022
T2  - PLoS Computational Biology
VL  - 18
IS  - 8
C7  - e1010367
DO  - 10.1371/journal.pcbi.1010367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137124233&doi=10.1371%2fjournal.pcbi.1010367&partnerID=40&md5=1196afe5d3b41b3f51c12876ace46f60
AB  - Predictive modeling of drug-induced gene expressions is a powerful tool for phenotype-based compound screening and drug repurposing. State-of-the-art machine learning methods use a small number of fixed cell lines as a surrogate for predicting actual expressions in a new cell type or tissue, although it is well known that drug responses depend on a cellular context. Thus, the existing approach has limitations when applied to personalized medicine, especially for many understudied diseases whose molecular profiles are dramatically different from those characterized in the training data. Besides the gene expression, dose-dependent cell viability is another important phenotype readout and is more informative than conventional summary statistics (e.g., IC50) for characterizing clinical drug efficacy and toxicity. However, few computational methods can reliably predict the dose-dependent cell viability. To address the challenges mentioned above, we designed a new deep learning model, MultiDCP, to predict cellular context-dependent gene expressions and cell viability on a specific dosage. The novelties of MultiDCP include a knowledge-driven gene expression profile transformer that enables context-specific phenotypic response predictions of novel cells or tissues, integration of multiple diverse labeled and unlabeled omics data, the joint training of the multiple prediction tasks, and a teacher-student training procedure that allows us to utilize unreliable data effectively. Comprehensive benchmark studies suggest that MultiDCP outperforms state-of-the-art methods with unseen cell lines that are dissimilar from the cell lines in the supervised training in terms of gene expressions. The predicted drug-induced gene expressions demonstrate a stronger predictive power than noisy experimental data for downstream tasks. Thus, MultiDCP is a useful tool for transcriptomics-based drug repurposing and compound screening that currently rely on noisy high-throughput experimental data. We applied MultiDCP to repurpose individualized drugs for Alzheimer’s disease in terms of efficacy and toxicity, suggesting that MultiDCP is a potentially powerful tool for personalized drug discovery. © 2022 Wu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 9
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Atanasova, P.
AU  - Simonsen, J.G.
AU  - Lioma, C.
AU  - Augenstein, I.
TI  - Fact Checking with Insufficient Evidence
PY  - 2022
T2  - Transactions of the Association for Computational Linguistics
VL  - 10
SP  - 746
EP  - 763
DO  - 10.1162/tacl_a_00486
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130111577&doi=10.1162%2ftacl_a_00486&partnerID=40&md5=c62c32c419bac80b762596f0ceedbef0
AB  - Automating the fact checking (FC) process relies on information obtained from external sources. In this work, we posit that it is crucial for FC models to make veracity predictions only when there is sufficient evidence and otherwise indicate when it is not enough. To this end, we are the first to study what information FC models consider sufficient by introducing a novel task and advancing it with three main contributions. First, we conduct an in-depth empirical analysis of the task with a new fluency-preserving method for omitting information from the evidence at the constituent and sentence level. We identify when models consider the remaining evidence (in)sufficient for FC, based on three trained models with different Transformer architectures and three FC datasets. Second, we ask annotators whether the omitted evidence was important for FC, resulting in a novel diagnostic dataset, Suffi-cientFacts1, for FC with omitted evidence. We find that models are least successful in detecting missing evidence when adverbial modifiers are omitted (21% accuracy), whereas it is easiest for omitted date modifiers (63% accuracy). Finally, we propose a novel data augmentation strategy for contrastive self-learning of missing evidence by employing the proposed omission method combined with tri-training. It improves performance for Evidence Sufficiency Prediction by up to 17.8 F1 score, which in turn improves FC performance by up to 2.6 F1 score. © MIT Press Journals. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Jin, J.
AU  - Zou, Q.
AU  - Nakai, K.
AU  - Wei, L.
TI  - Predicting protein-peptide binding residues via interpretable deep learning
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 13
SP  - 3351
EP  - 3360
DO  - 10.1093/bioinformatics/btac352
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133958077&doi=10.1093%2fbioinformatics%2fbtac352&partnerID=40&md5=acf53bd877e04791fe6295da46078834
AB  - Summary: Identifying the protein-peptide binding residues is fundamentally important to understand the mechanisms of protein functions and explore drug discovery. Although several computational methods have been developed, most of them highly rely on third-party tools or complex data preprocessing for feature design, easily resulting in low computational efficacy and suffering from low predictive performance. To address the limitations, we propose PepBCL, a novel BERT (Bidirectional Encoder Representation from Transformers) -based contrastive learning framework to predict the protein-peptide binding residues based on protein sequences only. PepBCL is an end-to-end predictive model that is independent of feature engineering. Specifically, we introduce a well pre-trained protein language model that can automatically extract and learn high-latent representations of protein sequences relevant for protein structures and functions. Further, we design a novel contrastive learning module to optimize the feature representations of binding residues underlying the imbalanced dataset. We demonstrate that our proposed method significantly outperforms the state-of-the-art methods under benchmarking comparison, and achieves more robust performance. Moreover, we found that we further improve the performance via the integration of traditional features and our learnt features. Interestingly, the interpretable analysis of our model highlights the flexibility and adaptability of deep learning-based protein language model to capture both conserved and non-conserved sequential characteristics of peptide-binding residues. Finally, to facilitate the use of our method, we establish an online predictive platform as the implementation of the proposed PepBCL, which is now available at http://server.wei-group.net/PepBCL/.  © 2022 The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 38
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Guo, Z.
AU  - Zhang, X.
AU  - Liu, C.
AU  - Ji, X.
AU  - Jiao, J.
AU  - Ye, Q.
TI  - Convex-Hull Feature Adaptation for Oriented and Densely Packed Object Detection
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 8
SP  - 5252
EP  - 5265
DO  - 10.1109/TCSVT.2022.3140248
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122596589&doi=10.1109%2fTCSVT.2022.3140248&partnerID=40&md5=2a16a94e291da823c46d4535f18c9ecc
AB  - Detecting oriented and densely packed objects is a challenging problem considering that the receptive field intersection between objects causes spatial feature aliasing. In this paper, we propose a convex-hull feature adaptation (CFA) approach, with the aim to configure convolutional features in accordance with irregular object layouts. CFA roots in the convex-hull feature representation, which defines a set of dynamically sampled feature points guided by the convex intersection over union (CIoU) to bound object extent. CFA pursues optimal feature assignment by constructing convex-hull sets and iteratively splitting positive or negative convex-hulls. By simultaneously considering overlapping convex-hulls and objects and penalizing convex-hulls shared by multiple objects, CFA defines a systematic way to adapt convolutional features on regular grids to objects of irregular shapes. Experiments on DOTA and SKU110K-R datasets show that CFA achieved new state-of-The-Art performance for detecting oriented and densely packed objects. CFA also sets a solid baseline for convex polygon prediction on the MS COCO dataset defined for general object detection. Code is available at https://github.com/SDL-GuoZonghao/BeyondBoundingBox.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 26
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Amezaga Hechavarria, A.
AU  - Shafiq, M.O.
TI  - A modified attention mechanism powered by Bayesian Network for user activity analysis and prediction
PY  - 2022
T2  - Data and Knowledge Engineering
VL  - 140
C7  - 102034
DO  - 10.1016/j.datak.2022.102034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132317172&doi=10.1016%2fj.datak.2022.102034&partnerID=40&md5=57e161ab1a04be40054e9f26a8b8178c
AB  - Analyzing and predicting user activity is important in the current digital era with a lot of use-cases and applications. In this paper, we present an approach that facilitates a modification of the attention mechanism in a Transformer model. This work enables to improve the predictive capacity of a forecasting model which is progressively fed by somewhat erratic and small data generated by the early stages of online activity. The key element of the work is to use a Bayesian Network (BN) as a tool for feature engineering that helps to modify the attention mechanism in the Transformer model in that scenario. The model predicts the next activity on a sequence of online activities that the user will engage in while interacting with a Learning Management System (LMS). Click-stream data refers to a detailed log of how participants navigate through an online platform during a working session. The main application of our work is to improve the Predictor module of a smart hybrid-classifier for an LMS. Several configurations and architectures for the RNN-powered predictor, are tested and assessed. The results of the improved predictive capacity of this work can be useful to users in an online learning environment where early assistance in quasi-real time is required. This research answers the questions of how click-stream data can assist in refining the tasks of the Attention mechanism to improve the quality of the prediction. Performance is measured by the accuracy, right-content and first-state accuracy scores for the incoming sequence and compared across alternative models. The method also provides systematic customization of the attention mechanism in Transformers that can be applied to a range of problems involving click-stream data. © 2022
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, B.
AU  - Tang, X.
AU  - Qi, X.
AU  - Chen, Y.
AU  - Li, C.-G.
AU  - Xiao, R.
TI  - EMU: Effective Multi-Hot Encoding Net for Lightweight Scene Text Recognition with a Large Character Set
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 8
SP  - 5374
EP  - 5385
DO  - 10.1109/TCSVT.2022.3146240
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123737740&doi=10.1109%2fTCSVT.2022.3146240&partnerID=40&md5=72520b8d23674fa0de62e3b3626dbec4
AB  - Deploying a lightweight deep model for scene text recognition task on mobile devices has great commercial value. However, the conventional softmax-based one-hot classification module becomes a cumbersome obstacle when handling multi-languages or languages with large character set (e.g., Chinese) due to the rapid expansion of model parameters with the number of classes. To this end, we propose an Effective Multi-hot encoding and classification modUle (EMU) for scene text recognition in the scenario of multi-languages or languages with large character set. Specifically, EMU generates a binary multi-hot label for each class with a real-valued sub-network in training stage and produces the prediction by calculating the inner product between the multi-hot code and the multi-hot label. Compared to the softmax-based one-hot classifier, EMU reduces the storage requirement and the time cost in inference stage significantly, retaining similar performance. Furthermore, we design a convolution feature based Lightweight TransFormer to learn the effective features for EMU and consequently develop a lightweight scene text recognition framework, termed Light-Former-EMU. We conduct extensive experiments on seven public English benchmarks and two real-world Chinese challenge benchmarks. Experimental results verify the effectiveness of the proposed EMU and demonstrate the promising performance of the proposed Light-Former-EMU.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pezze, D.D.
AU  - Masiero, C.
AU  - Tosato, D.
AU  - Beghi, A.
AU  - Susto, G.A.
TI  - FORMULA: A Deep Learning Approach for Rare Alarms Predictions in Industrial Equipment
PY  - 2022
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 19
IS  - 3
SP  - 1491
EP  - 1502
DO  - 10.1109/TASE.2021.3127995
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120861604&doi=10.1109%2fTASE.2021.3127995&partnerID=40&md5=bbe644eed7cfb821a398c9df0cda1c5c
AB  - Predictive Maintenance technologies are particularly appealing for Industrial Equipment producers, as they pave the way to the selling of high added-value services and customized maintenance plans. However, standard Predictive Maintenance approaches assume the availability of sensor measurements, and the costs associated with adding sensors or remotely accessing sensor readings may discourage the development of such technologies. In this context, Alarm Forecasting can be very useful as it represents a low-cost alternative or helpful support to sensor-based Predictive Maintenance. In this work, we propose a new formulation for the Alarm Forecasting problem, framed as a multi-label classification task. We present a novel deep learning-based approach called FORMULA (alarm FORecasting in MUlti-LAbel setting). FORMULA leverages Transformer, a popular Neural Network architecture in the field of Natural Language Processing. To cope with alarm imbalance, we draw inspiration from Segmentation and Object Detection. Thus, FORMULA is trained by minimizing the Weighted Focal Loss, which turns out to be very effective in predicting rare alarms. These alarms, even if they are difficult to predict by nature, often are business-critical. We assess the proposed approach on a representative real-world problem from the packaging industry. In particular, we show that it outperforms not only classic multilabel techniques but also models based on recurrent neural networks. As regards the latter, the proposed approach also exhibits a lower computational burden, both in terms of training time and model size. To foster research in the field and reproducibility, we also publicly share the alarm logs dataset and the code used to perform the experiments.  © 2004-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shang, J.
AU  - Tang, X.
AU  - Guo, R.
AU  - Sun, Y.
TI  - Accurate identification of bacteriophages from metagenomic data using Transformer
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 4
C7  - bbac258
DO  - 10.1093/bib/bbac258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134720898&doi=10.1093%2fbib%2fbbac258&partnerID=40&md5=3c8fcdd052edd09e94e46c9e245d23ca
AB  - Motivation: Bacteriophages are viruses infecting bacteria. Being key players in microbial communities, they can regulate the composition/function of microbiome by infecting their bacterial hosts and mediating gene transfer. Recently, metagenomic , which can sequence all genetic materials from various microbiome, has become a popular means for new phage discovery. However, accurate and comprehensive detection of phages from the metagenomic data remains difficult. High diversity/abundance, and limited reference genomes pose major challenges for recruiting phage fragments from metagenomic data. Existing alignment-based or learning-based models have either low recall or precision on metagenomic data. Results: In this work, we adopt the state-of-The-Art language model, Transformer, to conduct contextual embedding for phage contigs. By constructing a protein-cluster vocabulary, we can feed both the protein composition and the proteins' positions from each contig into the Transformer. The Transformer can learn the protein organization and associations using the self-Attention mechanism and predicts the label for test contigs. We rigorously tested our developed tool named PhaMer on multiple datasets with increasing difficulty, including quality RefSeq genomes, short contigs, simulated metagenomic data, mock metagenomic data and the public IMG/VR dataset. All the experimental results show that PhaMer outperforms the state-of-The-Art tools. In the real metagenomic data experiment, PhaMer improves the F1-score of phage detection by 27%.  © 2022 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, F.
AU  - Zhang, Z.
AU  - Guan, J.
AU  - Zhou, S.
TI  - Effective drug-target interaction prediction with mutual interaction neural network
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 14
SP  - 3582
EP  - 3589
DO  - 10.1093/bioinformatics/btac377
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134999503&doi=10.1093%2fbioinformatics%2fbtac377&partnerID=40&md5=98bf159ced90da8f6bcdc36e951ae6a1
AB  - Motivation: Accurately predicting drug-target interaction (DTI) is a crucial step to drug discovery. Recently, deep learning techniques have been widely used for DTI prediction and achieved significant performance improvement. One challenge in building deep learning models for DTI prediction is how to appropriately represent drugs and targets. Target distance map and molecular graph are low dimensional and informative representations, which however have not been jointly used in DTI prediction. Another challenge is how to effectively model the mutual impact between drugs and targets. Though attention mechanism has been used to capture the one-way impact of targets on drugs or vice versa, the mutual impact between drugs and targets has not yet been explored, which is very important in predicting their interactions. Results: Therefore, in this article we propose MINN-DTI, a new model for DTI prediction. MINN-DTI combines an interacting-transformer module (called Interformer) with an improved Communicative Message Passing Neural Network (CMPNN) (called Inter-CMPNN) to better capture the two-way impact between drugs and targets, which are represented by molecular graph and distance map, respectively. The proposed method obtains better performance than the state-of-the-art methods on three benchmark datasets: DUD-E, human and BindingDB. MINN-DTI also provides good interpretability by assigning larger weights to the amino acids and atoms that contribute more to the interactions between drugs and targets.  © 2022 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 53
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Lin, J.
AU  - Luo, S.
TI  - Deep learning for the dynamic prediction of multivariate longitudinal and survival data
PY  - 2022
T2  - Statistics in Medicine
VL  - 41
IS  - 15
SP  - 2894
EP  - 2907
DO  - 10.1002/sim.9392
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127264287&doi=10.1002%2fsim.9392&partnerID=40&md5=2f6b5dcdf120789343b090de576b394f
AB  - The joint model for longitudinal and survival data improves time-to-event predictions by including longitudinal outcome variables in addition to baseline covariates. However, in practice, joint models may be limited by parametric assumptions in both the longitudinal and survival submodels. In addition, computational difficulties arise when considering multiple longitudinal outcomes due to the large number of random effects to be integrated out in the full likelihood. In this article, we discuss several recent machine learning methods for incorporating multivariate longitudinal data for time-to-event prediction. The presented methods use functional data analysis or convolutional neural networks to model the longitudinal data, both of which scale well to multiple longitudinal outcomes. In addition, we propose a novel architecture based on the transformer neural network, named TransformerJM, which jointly models longitudinal and time-to-event data. The prognostic abilities of each model are assessed and compared through both simulation and real data analysis on Alzheimer's disease datasets. Specifically, the models were evaluated based on their ability to dynamically update predictions as new longitudinal data becomes available. We showed that TransformerJM improves upon the predictive performance of existing methods across different scenarios. © 2022 John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - FMS:C; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kurata, H.
AU  - Tsukiyama, S.
AU  - Manavalan, B.
TI  - IACVP: Markedly enhanced identification of anti-coronavirus peptides using a dataset-specific word2vec model
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 4
C7  - bbac265
DO  - 10.1093/bib/bbac265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134721597&doi=10.1093%2fbib%2fbbac265&partnerID=40&md5=c8be70c71aab5da08fb216553ae36e23
AB  - The COVID-19 pandemic caused several million deaths worldwide. Development of anti-coronavirus drugs is thus urgent. Unlike conventional non-peptide drugs, antiviral peptide drugs are highly specific, easy to synthesize and modify, and not highly susceptible to drug resistance. To reduce the time and expense involved in screening thousands of peptides and assaying their antiviral activity, computational predictors for identifying anti-coronavirus peptides (ACVPs) are needed. However, few experimentally verified ACVP samples are available, even though a relatively large number of antiviral peptides (AVPs) have been discovered. In this study, we attempted to predict ACVPs using an AVP dataset and a small collection of ACVPs. Using conventional features, a binary profile and a word-embedding word2vec (W2V), we systematically explored five different machine learning methods: Transformer, Convolutional Neural Network, bidirectional Long Short-Term Memory, Random Forest (RF) and Support Vector Machine. Via exhaustive searches, we found that the RF classifier with W2V consistently achieved better performance on different datasets. The two main controlling factors were: (i) the dataset-specific W2V dictionary was generated from the training and independent test datasets instead of the widely used general UniProt proteome and (ii) a systematic search was conducted and determined the optimal k-mer value in W2V, which provides greater discrimination between positive and negative samples. Therefore, our proposed method, named iACVP, consistently provides better prediction performance compared with existing state-of-The-Art methods. To assist experimentalists in identifying putative ACVPs, we implemented our model as a web server accessible via the following link: http://kurata35.bio.kyutech.ac.jp/iACVP.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journa ls.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tipirneni, S.
AU  - Reddy, C.K.
TI  - Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series
PY  - 2022
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 16
IS  - 6
C7  - 105
DO  - 10.1145/3516367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141150179&doi=10.1145%2f3516367&partnerID=40&md5=48d2524eb134572c41e98fb0a637a63f
AB  - Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at https://github.com/sindhura97/STraTS. © 2022 Copyright held by the owner/author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 49
C2  - CCF:B期刊; FMS:B; 
LB  - Tipirneni2022Self-Supervised
ER  -

TY  - JOUR
AU  - Guo, S.
AU  - Rigall, E.
AU  - Ju, Y.
AU  - Dong, J.
TI  - 3D Hand Pose Estimation from Monocular RGB with Feature Interaction Module
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 8
SP  - 5293
EP  - 5306
DO  - 10.1109/TCSVT.2022.3142787
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123294692&doi=10.1109%2fTCSVT.2022.3142787&partnerID=40&md5=76332b1caaeea33ed62893665082e5c5
AB  - 3D hand pose estimation from a monocular RGB image is a highly challenging task due to self-occlusion, diverse appearances, and inherent depth ambiguities within monocular images. Most of the previous methods first employ deep neural networks to fit 2D joint location maps, then combines them with implicit or explicit pose-Aware features to directly regress 3D hand joints positions using their designed network structure. However, the skeleton positions and corresponding skeleton-Aware content information located in the latent space are invariably ignored. These skeleton-Aware contents effectively bridge the gap between hand joint and hand skeleton information by associating the relationship between different hand joints features and the hand skeleton positions distribution in 2D space. To address this issue, we propose a simple yet efficient deep neural network to directly recover reliable 3D hand pose from monocular RGB images with faster estimation process. Our purpose is the reduction of the model computational complexity while maintaining high precision performance. Therefore, we design a novel Feature Chat Block (FCB) to complete feature boosting, which enables the intuitively enhanced interaction between joint and skeleton features. First, this FCB module updates joint features effectively based on semantic graph convolutional neural network and multi-head self-Attention mechanism. The GCN-based structure focuses on the physical hand joints included in a binary adjacency matrix and the self-Attention part pays attention to hand joints located in a complementary matrix. Then, the FCB module employs query and key mechanisms respectively representing joint and skeleton features to further implement feature interaction. After a set of FCB modules, our model updates the fused features in a coarse-To-fine manner and finally outputs a predicted 3D hand pose. We conducted a comprehensive set of ablation experiments on the InterHand2.6M dataset to validate the effectiveness and significance of the proposed method. Additionally, experimental results on Rendered Hand Dataset, Stereo Hand Datasets, First-Person Hand Action Dataset and FreiHAND Dataset show our model surpasses the state-of-The-Art methods with faster inference speed.  © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 17
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Fradkin, P.
AU  - Young, A.
AU  - Atanackovic, L.
AU  - Frey, B.
AU  - Lee, L.J.
AU  - Wang, B.
TI  - A graph neural network approach for molecule carcinogenicity prediction
PY  - 2022
T2  - Bioinformatics
VL  - 38
SP  - I84
EP  - I91
DO  - 10.1093/bioinformatics/btac266
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132950207&doi=10.1093%2fbioinformatics%2fbtac266&partnerID=40&md5=1c75fde96777e241609715499959864a
AB  - Motivation: Molecular carcinogenicity is a preventable cause of cancer, but systematically identifying carcinogenic compounds, which involves performing experiments on animal models, is expensive, time consuming and low throughput. As a result, carcinogenicity information is limited and building data-driven models with good prediction accuracy remains a major challenge. Results: In this work, we propose CONCERTO, a deep learning model that uses a graph transformer in conjunction with a molecular fingerprint representation for carcinogenicity prediction from molecular structure. Special efforts have been made to overcome the data size constraint, such as multi-round pre-Training on related but lower quality mutagenicity data, and transfer learning from a large self-supervised model. Extensive experiments demonstrate that our model performs well and can generalize to external validation sets. CONCERTO could be useful for guiding future carcinogenicity experiments and provide insight into the molecular basis of carcinogenicity.  © 2022 The Author(s) 2022. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Hao, B.
AU  - Hu, Y.
AU  - Sotudian, S.
AU  - Zad, Z.
AU  - Adams, W.G.
AU  - Assoumou, S.A.
AU  - Hsu, H.
AU  - Mishuris, R.G.
AU  - Paschalidis, I.C.
TI  - Development and validation of predictive models for COVID-19 outcomes in a safety-net hospital population
PY  - 2022
T2  - Journal of the American Medical Informatics Association
VL  - 29
IS  - 7
SP  - 1253
EP  - 1262
DO  - 10.1093/jamia/ocac062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132049977&doi=10.1093%2fjamia%2focac062&partnerID=40&md5=4b7288a944d145c8c775c1f0d1cb53f0
AB  - Objective: To develop predictive models of coronavirus disease 2019 (COVID-19) outcomes, elucidate the influence of socioeconomic factors, and assess algorithmic racial fairness using a racially diverse patient population with high social needs. Materials and Methods: Data included 7,102 patients with positive (RT-PCR) severe acute respiratory syndrome coronavirus 2 test at a safety-net system in Massachusetts. Linear and nonlinear classification methods were applied. A score based on a recurrent neural network and a transformer architecture was developed to capture the dynamic evolution of vital signs. Combined with patient characteristics, clinical variables, and hospital occupancy measures, this dynamic vital score was used to train predictive models. Results: Hospitalizations can be predicted with an area under the receiver-operating characteristic curve (AUC) of 92% using symptoms, hospital occupancy, and patient characteristics, including social determinants of health. Parsimonious models to predict intensive care, mechanical ventilation, and mortality that used the most recent labs and vitals exhibited AUCs of 92.7%, 91.2%, and 94%, respectively. Early predictive models, using labs and vital signs closer to admission had AUCs of 81.1%, 84.9%, and 92%, respectively. Discussion: The most accurate models exhibit racial bias, being more likely to falsely predict that Black patients will be hospitalized. Models that are only based on the dynamic vital score exhibited accuracies close to the best parsimonious models, although the latter also used laboratories. Conclusions: This large study demonstrates that COVID-19 severity may accurately be predicted using a score that accounts for the dynamic evolution of vital signs. Further, race, social determinants of health, and hospital occupancy play an important role. © The Author(s) 2022. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Jiang, L.
AU  - Jiang, C.
AU  - Yu, X.
AU  - Fu, R.
AU  - Jin, S.
AU  - Liu, X.
TI  - DeepTTA: a transformer-based model for predicting cancer drug response
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 3
C7  - bbac100
DO  - 10.1093/bib/bbac100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130766775&doi=10.1093%2fbib%2fbbac100&partnerID=40&md5=a66abbf798a64cf9c6b797a43745daf6
AB  - Identifying new lead molecules to treat cancer requires more than a decade of dedicated effort. Before selected drug candidates are used in the clinic, their anti-cancer activity is generally validated by in vitro cellular experiments. Therefore, accurate prediction of cancer drug response is a critical and challenging task for anti-cancer drugs design and precision medicine. With the development of pharmacogenomics, the combination of efficient drug feature extraction methods and omics data has made it possible to use computational models to assist in drug response prediction. In this study, we propose DeepTTA, a novel end-to-end deep learning model that utilizes transformer for drug representation learning and a multilayer neural network for transcriptomic data prediction of the anti-cancer drug responses. Specifically, DeepTTA uses transcriptomic gene expression data and chemical substructures of drugs for drug response prediction. Compared to existing methods, DeepTTA achieved higher performance in terms of root mean square error, Pearson correlation coefficient and Spearman’s rank correlation coefficient on multiple test sets. Moreover, we discovered that anti-cancer drugs bortezomib and dactinomycin provide a potential therapeutic option with multiple clinical indications. With its excellent performance, DeepTTA is expected to be an effective method in cancer drug design. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Parnow, K.
AU  - Zhao, H.
TI  - Incorporating rich syntax information in Grammatical Error Correction
PY  - 2022
T2  - Information Processing and Management
VL  - 59
IS  - 3
C7  - 102891
DO  - 10.1016/j.ipm.2022.102891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127828989&doi=10.1016%2fj.ipm.2022.102891&partnerID=40&md5=51e4f8db6de4f92905e51f958fa150f2
AB  - Syntax parse trees are a method of representing sentence structure and are often used to provide models with syntax information and enhance downstream task performance. Because grammar and syntax are inherently linked, the incorporation of syntax parse trees in GEC is a natural solution. In this work, we present a method of incorporating syntax parse trees for Grammatical Error Correction (GEC). Building off a strong sequence-to-sequence Transformer baseline, we present a unified parse integration method for GEC that allows for the use of both dependency and constituency parse trees, as well as their combination - a syntactic graph. Specifically, on the sentence encoder, we propose a graph encoder that can encode dependency trees and constituent trees at the same time, yielding two representations for terminal nodes (i.e., the token of the sentence) and non-terminal nodes. We next use two cross-attentions (NT-Cross-Attention and T-Cross-Attention) to aggregate these source syntactic representations to the target side for final corrections prediction. In addition to evaluating our models on the popular CoNLL-2014 Shared Task and JFLEG GEC benchmarks, we affirm the effectiveness of our proposed method by testing both varying levels of parsing quality and exploring the use of both parsing formalisms. With further empirical exploration and analysis to identify the source of improvement, we found that rich syntax information provided clear clues for GEC; a syntactic graph composed of multiple syntactic parse trees can effectively compensate for the limited quality and insufficient error correction capability of a single syntactic parse tree. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 23
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Sarwar, S.M.
AU  - Zlatkova, D.
AU  - Hardalov, M.
AU  - Dinkov, Y.
AU  - Augenstein, I.
AU  - Nakov, P.
TI  - A Neighborhood Framework for Resource-Lean Content Flagging
PY  - 2022
T2  - Transactions of the Association for Computational Linguistics
VL  - 10
SP  - 484
EP  - 502
DO  - 10.1162/tacl_a_00472
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125809351&doi=10.1162%2ftacl_a_00472&partnerID=40&md5=0fc623234d2add84fb4fedc41f9ee646
AB  - We propose a novel framework for cross-lingual content flagging with limited target-language data, which significantly outperforms prior work in terms of predictive performance. The framework is based on a nearest-neighbor architecture. It is a modern instantiation of the vanilla k-nearest neighbor model, as we use Transformer representations in all its components. Our framework can adapt to new source-language instances, without the need to be retrained from scratch. Unlike prior work on neighborhood-based approaches, we encode the neighborhood information based on query– neighbor interactions. We propose two encoding schemes and we show their effectiveness using both qualitative and quantitative analysis. Our evaluation results on eight languages from two different datasets for abusive language detection show sizable improvements of up to 9.5 F1 points absolute (for Italian) over strong baselines. On average, we achieve 3.6 absolute F1 points of improvement for the three languages in the Jigsaw Multilingual dataset and 2.14 points for the WUL dataset. © 2022 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zheng, C.
AU  - Xu, L.
AU  - Fan, X.
AU  - Yang, J.
AU  - Fan, J.
AU  - Huang, X.
TI  - Dual-path transformer-based network with equalization-generation components prediction for flexible vibrational sensor speech enhancement in the time domain
PY  - 2022
T2  - Journal of the Acoustical Society of America
VL  - 151
IS  - 5
SP  - 2814
EP  - 2825
DO  - 10.1121/10.0010316
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129138066&doi=10.1121%2f10.0010316&partnerID=40&md5=59174e928b1e7c0cd8d6360e8b1d0c0d
AB  - The flexible vibrational sensor (FVS) has the potential to become a popular wearable communication device because of its natural noise shielding characteristics and soft materials. However, FVS speech faces a severe loss of frequency components. To improve speech quality, a time-domain neural network model based on the dual-path transformer combined with equalization-generation components prediction (DPT-EGNet) is proposed. More specifically, the DPT-EGNet consists of five modules, namely the pre-processing module, dual-path transformer module, equalization module, generation module, and post-processing module. The dual-path transformer module is leveraged to extract the local and global contextual relationship of long-term speech sequences, which is extremely beneficial for inferring the missing components. The equalization and generation modules are designed according to the characteristics of FVS speech, which further improve the speech quality by simulating the inversion process of the speech distortion. The experimental results demonstrate that the proposed model effectively improves the quality of FVS speech; the average perceptual evaluation of speech quality (PESQ), short-time objective intelligibility (STOI), and composite measure for overall speech quality (COVL) scores of three males and three females are relatively increased by 64.19%, 29.63%, and 101.37%, which is superior to other baseline models developed in different domains. The proposed model also has significantly lower complexity than the others.  © 2022 Acoustical Society of America.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, F.
AU  - Wei, L.
TI  - Multi-scale deep learning for the imbalanced multi-label protein subcellular localization prediction based on immunohistochemistry images
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 9
SP  - 2602
EP  - 2611
DO  - 10.1093/bioinformatics/btac123
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130017000&doi=10.1093%2fbioinformatics%2fbtac123&partnerID=40&md5=7e3876238db2f168d49b8292723487fe
AB  - Motivation: The development of microscopic imaging techniques enables us to study protein subcellular locations from the tissue level down to the cell level, contributing to the rapid development of image-based protein subcellular location prediction approaches. However, existing methods suffer from intrinsic limitations, such as poor feature representation ability, data imbalanced issue, and multi-label classification problem, greatly impacting the model performance and generalization. Results: In this study, we propose MSTLoc, a novel multi-scale end-to-end deep learning model to identify protein subcellular locations in the imbalanced multi-label immunohistochemistry (IHC) images dataset. In our MSTLoc, we deploy a deep convolution neural network to extract multi-scale features from the IHC images, aggregate the high-level features and low-level features via feature fusion to sufficiently exploit the dependencies amongst various subcellular locations, and utilize Vision Transformer (ViT) to model the relationship amongst the features and enhance the feature representation ability. We demonstrate that the proposed MSTLoc achieves better performance than current state-of-the-art models in multi-label subcellular location prediction. Through feature visualization and interpretation analysis, we demonstrate that as compared with the hand-crafted features, the multi-scale deep features learnt from our model exhibit better ability in capturing discriminative patterns underlying protein subcellular locations, and the features from different scales are complementary for the improvement in performance. Finally, case study results indicate that our MSTLoc can successfully identify some biomarkers from proteins that are closely involved with cancer development. © 2022 The Author(s). Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Kumar, P.
AU  - Raman, B.
TI  - A BERT based dual-channel explainable text emotion recognition system
PY  - 2022
T2  - Neural Networks
VL  - 150
SP  - 392
EP  - 407
DO  - 10.1016/j.neunet.2022.03.017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127180477&doi=10.1016%2fj.neunet.2022.03.017&partnerID=40&md5=38e979ca06a990982ab5b4dc7c5804d4
AB  - In this paper, a novel dual-channel system for multi-class text emotion recognition has been proposed, and a novel technique to explain its training & predictions has been developed. The architecture of the proposed system contains the embedding module, dual-channel module, emotion classification module, and explainability module. The embedding module extracts the textual features from the input sentences in the form of embedding vectors using the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model. Then the embedding vectors are fed as the inputs to the dual-channel network containing two network channels made up of convolutional neural network (CNN) and bidirectional long short term memory (BiLSTM) network. The intuition behind using CNN and BiLSTM in both the channels was to harness the goodness of the convolutional layer for feature extraction and the BiLSTM layer to extract text's order and sequence-related information. The outputs of both channels are in the form of embedding vectors which are concatenated and fed to the emotion classification module. The proposed system's architecture has been determined by thorough ablation studies, and a framework has been developed to discuss its computational cost. The emotion classification module learns and projects the emotion embeddings on a hyperplane in the form of clusters. The proposed explainability technique explains the training and predictions of the proposed system by analyzing the inter & intra-cluster distances and the intersection of these clusters. The proposed approach's consistent accuracy, precision, recall, and F1 score results for ISEAR, Aman, AffectiveText, and EmotionLines datasets, ensure its applicability to diverse texts. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 55
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Villegas-Morcillo, A.
AU  - Gomez, A.M.
AU  - Sanchez, V.
TI  - An analysis of protein language model embeddings for fold prediction
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 3
C7  - bbac142
DO  - 10.1093/bib/bbac142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130767646&doi=10.1093%2fbib%2fbbac142&partnerID=40&md5=f176f0ba53ea1674d955e82c412295bf
AB  - The identification of the protein fold class is a challenging problem in structural biology. Recent computational methods for fold prediction leverage deep learning techniques to extract protein fold-representative embeddings mainly using evolutionary information in the form of multiple sequence alignment (MSA) as input source. In contrast, protein language models (LM) have reshaped the field thanks to their ability to learn efficient protein representations (protein-LM embeddings) from purely sequential information in a self-supervised manner. In this paper, we analyze a framework for protein fold prediction using pre-trained protein-LM embeddings as input to several fine-tuning neural network models, which are supervisedly trained with fold labels. In particular, we compare the performance of six protein-LM embeddings: the long short-term memory-based UniRep and SeqVec, and the transformer-based ESM-1b, ESM-MSA, ProtBERT and ProtT5; as well as three neural networks: Multi-Layer Perceptron, ResCNN-BGRU (RBG) and Light-Attention (LAT). We separately evaluated the pairwise fold recognition (PFR) and direct fold classification (DFC) tasks on well-known benchmark datasets. The results indicate that the combination of transformer-based embeddings, particularly those obtained at amino acid level, with the RBG and LAT fine-tuning models performs remarkably well in both tasks. To further increase prediction accuracy, we propose several ensemble strategies for PFR and DFC, which provide a significant performance boost over the current state-of-the-art results. All this suggests that moving from traditional protein representations to protein-LM embeddings is a very promising approach to protein fold-related tasks. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, J.
AU  - Liu, J.
AU  - Kuang, H.
AU  - Wang, J.
TI  - A Fully Automated Multimodal MRI-Based Multi-Task Learning for Glioma Segmentation and IDH Genotyping
PY  - 2022
T2  - IEEE Transactions on Medical Imaging
VL  - 41
IS  - 6
SP  - 1520
EP  - 1532
DO  - 10.1109/TMI.2022.3142321
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122872096&doi=10.1109%2fTMI.2022.3142321&partnerID=40&md5=24097422fc15d3ff84a7ba6aaf399d5e
AB  - The accurate prediction of isocitrate dehydrogenase (IDH) mutation and glioma segmentation are important tasks for computer-Aided diagnosis using preoperative multimodal magnetic resonance imaging (MRI). The two tasks are ongoing challenges due to the significant inter-Tumor and intra-Tumor heterogeneity. The existing methods to address them are mostly based on single-Task approaches without considering the correlation between the two tasks. In addition, the acquisition of IDH genetic labels is expensive and costly, resulting in a limited number of IDH mutation data for modeling. To comprehensively address these problems, we propose a fully automated multimodal MRI-based multi-Task learning framework for simultaneous glioma segmentation and IDH genotyping. Specifically, the task correlation and heterogeneity are tackled with a hybrid CNN-Transformer encoder that consists of a convolutional neural network and a transformer to extract the shared spatial and global information learned from a decoder for glioma segmentation and a multi-scale classifier for IDH genotyping. Then, a multi-Task learning loss is designed to balance the two tasks by combining the segmentation and classification loss functions with uncertain weights. Finally, an uncertainty-Aware pseudo-label selection is proposed to generate IDH pseudo-labels from larger unlabeled data for improving the accuracy of IDH genotyping by using semi-supervised learning. We evaluate our method on a multi-institutional public dataset. Experimental results show that our proposed multi-Task network achieves promising performance and outperforms the single-Task learning counterparts and other existing state-of-The-Art methods. With the introduction of unlabeled data, the semi-supervised multi-Task learning framework further improves the performance of glioma segmentation and IDH genotyping. The source codes of our framework are publicly available at https://github.com/miacsu/MTTU-Net.git. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 90
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Colasanto, F.
AU  - Grilli, L.
AU  - Santoro, D.
AU  - Villani, G.
TI  - AlBERTino for stock price prediction: a Gibbs sampling approach
PY  - 2022
T2  - Information Sciences
VL  - 597
SP  - 341
EP  - 357
DO  - 10.1016/j.ins.2022.03.051
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126917852&doi=10.1016%2fj.ins.2022.03.051&partnerID=40&md5=d27998ccfe54d02247aebb87e06a8658
AB  - BERT (Bidirectional Encoder Representations from Transformers) is one of the most popular models in Natural Language Processing (NLP) for Sentiment Analysis. The main goal is to classify sentences (or entire texts) and to obtain a score in relation to their polarity: positive, negative or neutral. Recently, a Transformer-based architecture, the fine-tuned AlBERTo (Polignano et al. (2019)), has been introduced to determine a sentiment score in the financial sector through a specialized corpus of sentences. In this paper, we use the sentiment (polarity) score to improve the stocks forecasting. We apply the BERT model to determine the score associated to various events (both positive and negative) that have affected some stocks in the market. The sentences used to determine the scores are newspaper articles published on MilanoFinanza. We compute both the average sentiment score and the polarity, and we use a Monte Carlo method to generate (starting from the day the article was released) a series of possible paths for the next trading days, exploiting the Bayesian inference to determine a new series of bounded drift and volatility values on the basis of the score; thus, returning an exact “directed” price as a result. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; FMS:B; 
LB  - Colasanto2022AlBERTino
ER  -

TY  - JOUR
AU  - Nie, L.
AU  - Quan, L.
AU  - Wu, T.
AU  - He, R.
AU  - Lyu, Q.
TI  - TransPPMP: Predicting pathogenicity of frameshift and non-sense mutations by a Transformer based on protein features
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 10
SP  - 2705
EP  - 2711
DO  - 10.1093/bioinformatics/btac188
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132342010&doi=10.1093%2fbioinformatics%2fbtac188&partnerID=40&md5=e779aff1d82d6f1e46f927059216e308
AB  - Motivation: Protein structure can be severely disrupted by frameshift and non-sense mutations at specific positions in the protein sequence. Frameshift and non-sense mutation cases can also be found in healthy individuals. A method to distinguish neutral and potentially disease-associated frameshift and non-sense mutations is of practical and fundamental importance. It would allow researchers to rapidly screen out the potentially pathogenic sites from a large number of mutated genes and then use these sites as drug targets to speed up diagnosis and improve access to treatment. The problem of how to distinguish between neutral and potentially disease-associated frameshift and non-sense mutations remains under-researched. Results: We built a Transformer-based neural network model to predict the pathogenicity of frameshift and non-sense mutations on protein features and named it TransPPMP. The feature matrix of contextual sequences computed by the ESM pre-training model, type of mutation residue and the auxiliary features, including structure and function information, are combined as input features, and the focal loss function is designed to solve the sample imbalance problem during the training. In 10-fold cross-validation and independent blind test set, TransPPMP showed good robust performance and absolute advantages in all evaluation metrics compared with four other advanced methods, namely, ENTPRISE-X, VEST-indel, DDIG-in and CADD. In addition, we demonstrate the usefulness of the multi-head attention mechanism in Transformer to predict the pathogenicity of mutations-not only can multiple self-attention heads learn local and global interactions but also functional sites with a large influence on the mutated residue can be captured by attention focus. These could offer useful clues to study the pathogenicity mechanism of human complex diseases for which traditional machine learning methods fall short.  © 2022 The Author(s). Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Zhang, R.
AU  - Ghosh, S.
AU  - Pal, R.
TI  - Predicting binding affinities of emerging variants of SARS-CoV-2 using spike protein sequencing data: observations, caveats and recommendations
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 3
C7  - bbac128
DO  - 10.1093/bib/bbac128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130768084&doi=10.1093%2fbib%2fbbac128&partnerID=40&md5=9d1e538fcd306f4a03e4d0f8d9ff17b6
AB  - Predicting protein properties from amino acid sequences is an important problem in biology and pharmacology. Protein–protein interactions among SARS-CoV-2 spike protein, human receptors and antibodies are key determinants of the potency of this virus and its ability to evade the human immune response. As a rapidly evolving virus, SARS-CoV-2 has already developed into many variants with considerable variation in virulence among these variants. Utilizing the proteomic data of SARS-CoV-2 to predict its viral characteristics will, therefore, greatly aid in disease control and prevention. In this paper, we review and compare recent successful prediction methods based on long short-term memory (LSTM), transformer, convolutional neural network (CNN) and a similarity-based topological regression (TR) model and offer recommendations about appropriate predictive methodology depending on the similarity between training and test datasets. We compare the effectiveness of these models in predicting the binding affinity and expression of SARS-CoV-2 spike protein sequences. We also explore how effective these predictive methods are when trained on laboratory-created data and are tasked with predicting the binding affinity of the in-the-wild SARS-CoV-2 spike protein sequences obtained from the GISAID datasets. We observe that TR is a better method when the sample size is small and test protein sequences are sufficiently similar to the training sequence. However, when the training sample size is sufficiently large and prediction requires extrapolation, LSTM embedding and CNN-based predictive model show superior performance. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Singh, J.
AU  - Litfin, T.
AU  - Singh, J.
AU  - Paliwal, K.
AU  - Zhou, Y.
TI  - SPOT-Contact-LM: Improving single-sequence-based prediction of protein contact map using a transformer language model
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 7
SP  - 1888
EP  - 1894
DO  - 10.1093/bioinformatics/btac053
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127961392&doi=10.1093%2fbioinformatics%2fbtac053&partnerID=40&md5=14b2fe0c8f664b3baf22683e4d8a67e9
AB  - Motivation: Accurate prediction of protein contact-map is essential for accurate protein structure and function prediction. As a result, many methods have been developed for protein contact map prediction. However, most methods rely on protein-sequence-evolutionary information, which may not exist for many proteins due to lack of naturally occurring homologous sequences. Moreover, generating evolutionary profiles is computationally intensive. Here, we developed a contact-map predictor utilizing the output of a pre-trained language model ESM-1b as an input along with a large training set and an ensemble of residual neural networks. Results: We showed that the proposed method makes a significant improvement over a single-sequence-based predictor SSCpred with 15% improvement in the F1-score for the independent CASP14-FM test set. It also outperforms evolutionary-profile-based methods trRosetta and SPOT-Contact with 48.7% and 48.5% respective improvement in the F1-score on the proteins without homologs (Neff = 1) in the independent SPOT-2018 set. The new method provides a much faster and reasonably accurate alternative to evolution-based methods, useful for large-scale prediction.  © 2022 The Author(s) 2022. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Huang, F.
AU  - Yi, P.
AU  - Wang, J.
AU  - Li, M.
AU  - Peng, J.
AU  - Xiong, X.
TI  - A dynamical spatial-temporal graph neural network for traffic demand prediction
PY  - 2022
T2  - Information Sciences
VL  - 594
SP  - 286
EP  - 304
DO  - 10.1016/j.ins.2022.02.031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125283635&doi=10.1016%2fj.ins.2022.02.031&partnerID=40&md5=fc98108695adc286c0e6d587a89892a9
AB  - Traffic demand prediction is significant and practical in the resource scheduling of transportation application systems. Meanwhile, it remains a challenging topic due to the complexities of contextual effects and the highly dynamic nature of demand. Many works based on graph neural network (GNN) have recently been proposed to cope with this task. However, most previous studies treat the spatial dependence as a static graph, and their inference mechanism lacks interpretability. To address the issues, a Dynamical Spatial-Temporal Graph Neural Network model (DSTGNN) is proposed in this paper. DSTGNN has two critical phases: (1) Creating a spatial dependence graph. To capture the dynamical relationship, we propose building a spatial graph based on the stability of node's spatial dependence. (2) Inferring intensity. We model the changing demand process using the inhomogeneous Poisson process, which addresses the interpretability issue, and build a spatial-temporal embedding network to infer the intensity. Specifically, the spatial-temporal embedding network integrates the diffusion convolution neural network (DCNN) and a modified transformer. Extensive experiments are carried out on two real data sets, and the experimental results demonstrate that the performance of DSTGNN outperforms the state-of-the-art models on traffic demand prediction. © 2022 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 77
C2  - CCF:B期刊; FMS:B; 
LB  - Huang2022dynamical
ER  -

TY  - JOUR
AU  - Qiao, Y.
AU  - Shi, Y.
TI  - Unsupervised Deep Learning for FOD-Based Susceptibility Distortion Correction in Diffusion MRI
PY  - 2022
T2  - IEEE Transactions on Medical Imaging
VL  - 41
IS  - 5
SP  - 1165
EP  - 1175
DO  - 10.1109/TMI.2021.3134496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121395346&doi=10.1109%2fTMI.2021.3134496&partnerID=40&md5=a69ce3b5f21616ea5fdd02638df42d9a
AB  - Susceptibility induced distortion is a major artifact that affects the diffusion MRI (dMRI) data analysis. In the Human Connectome Project (HCP), the state-of-the-art method adopted to correct this kind of distortion is to exploit the displacement field from the B0 image in the reversed phase encoding images. However, both the traditional and learning-based approaches have limitations in achieving high correction accuracy in certain brain regions, such as brainstem. By utilizing the fiber orientation distribution (FOD) computed from the dMRI, we propose a novel deep learning framework named DistoRtion Correction Net (DrC-Net), which consists of the U-Net to capture the latent information from the 4D FOD images and the spatial transformer network to propagate the displacement field and back propagate the losses between the deformed FOD images. The experiments are performed on two datasets acquired with different phase encoding (PE) directions including the HCP and the Human Connectome Low Vision (HCLV) dataset. Compared to two traditional methods topup and FODReg and two deep learning methods S-Net and flow-net, the proposed method achieves significant improvements in terms of the mean squared difference (MSD) of fractional anisotropy (FA) images and minimum angular difference between two PEs in white matter and also brainstem regions. In the meantime, the proposed DrC-Net takes only several seconds to predict a displacement field, which is much faster than the FODReg method.  © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Karthikeyan, S.
AU  - De Herrera, A.G.S.
AU  - Doctor, F.
AU  - Mirza, A.
TI  - An OCR Post-Correction Approach Using Deep Learning for Processing Medical Reports
PY  - 2022
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 32
IS  - 5
SP  - 2574
EP  - 2581
DO  - 10.1109/TCSVT.2021.3087641
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111072335&doi=10.1109%2fTCSVT.2021.3087641&partnerID=40&md5=f635a297117eb0e5cd41b0e310822c5f
AB  - According to a recent Deloitte study, the COVID-19 pandemic continues to place a huge strain on the global health care sector. Covid-19 has also catalysed digital transformation across the sector for improving operational efficiencies. As a result, the amount of digitally stored patient data such as discharge letters, scan images, test results or free text entries by doctors has grown significantly. In 2020, 2314 exabytes of medical data was generated globally. This medical data does not conform to a generic structure and is mostly in the form of unstructured digitally generated or scanned paper documents stored as part of a patient's medical reports. This unstructured data is digitised using Optical Character Recognition (OCR) process. A key challenge here is that the accuracy of the OCR process varies due to the inability of current OCR engines to correctly transcribe scanned or handwritten documents in which text may be skewed, obscured or illegible. This is compounded by the fact that processed text is comprised of specific medical terminologies that do not necessarily form part of general language lexicons. The proposed work uses a deep neural network based self-supervised pre-Training technique: Robustly Optimized Bidirectional Encoder Representations from Transformers (RoBERTa) that can learn to predict hidden (masked) sections of text to fill in the gaps of non-Transcribable parts of the documents being processed. Evaluating the proposed method on domain-specific datasets which include real medical documents, shows a significantly reduced word error rate demonstrating the effectiveness of the approach. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cantini, R.
AU  - Marozzo, F.
AU  - Bruno, G.
AU  - Trunfio, P.
TI  - Learning Sentence-to-Hashtags Semantic Mapping for Hashtag Recommendation on Microblogs
PY  - 2022
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 16
IS  - 2
C7  - 32
DO  - 10.1145/3466876
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114988746&doi=10.1145%2f3466876&partnerID=40&md5=a402694ecfd00ce39fa4f688514f43da
AB  - The growing use of microblogging platforms is generating a huge amount of posts that need effective methods to be classified and searched. In Twitter and other social media platforms, hashtags are exploited by users to facilitate the search, categorization, and spread of posts. Choosing the appropriate hashtags for a post is not always easy for users, and therefore posts are often published without hashtags or with hashtags not well defined. To deal with this issue, we propose a new model, called HASHET (HAshtag recommendation using Sentence-to-Hashtag Embedding Translation), aimed at suggesting a relevant set of hashtags for a given post. HASHET is based on two independent latent spaces for embedding the text of a post and the hashtags it contains. A mapping process based on a multi-layer perceptron is then used for learning a translation from the semantic features of the text to the latent representation of its hashtags. We evaluated the effectiveness of two language representation models for sentence embedding and tested different search strategies for semantic expansion, finding out that the combined use of BERT (Bidirectional Encoder Representation from Transformer) and a global expansion strategy leads to the best recommendation results. HASHET has been evaluated on two real-world case studies related to the 2016 United States presidential election and COVID-19 pandemic. The results reveal the effectiveness of HASHET in predicting one or more correct hashtags, with an average F-score up to 0.82 and a recommendation hit-rate up to 0.92. Our approach has been compared to the most relevant techniques used in the literature (generative models, unsupervised models, and attention-based supervised models) by achieving up to 15% improvement in F-score for the hashtag recommendation task and 9% for the topic discovery task. © 2021 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; FMS:B; 
LB  - Cantini2022Learning
ER  -

TY  - JOUR
AU  - Ieremie, I.
AU  - Ewing, R.M.
AU  - Niranjan, M.
TI  - TransformerGO: predicting protein-protein interactions by modelling the attention between sets of gene ontology terms
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 8
SP  - 2269
EP  - 2277
DO  - 10.1093/bioinformatics/btac104
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128307321&doi=10.1093%2fbioinformatics%2fbtac104&partnerID=40&md5=cfa337f8aee1546756a8df9c3c208ba5
AB  - Motivation: Protein-protein interactions (PPIs) play a key role in diverse biological processes but only a small subset of the interactions has been experimentally identified. Additionally, high-throughput experimental techniques that detect PPIs are known to suffer various limitations, such as exaggerated false positives and negatives rates. The semantic similarity derived from the Gene Ontology (GO) annotation is regarded as one of the most powerful indicators for protein interactions. However, while computational approaches for prediction of PPIs have gained popularity in recent years, most methods fail to capture the specificity of GO terms. Results: We propose TransformerGO, a model that is capable of capturing the semantic similarity between GO sets dynamically using an attention mechanism. We generate dense graph embeddings for GO terms using an algorithmic framework for learning continuous representations of nodes in networks called node2vec. TransformerGO learns deep semantic relations between annotated terms and can distinguish between negative and positive interactions with high accuracy. TransformerGO outperforms classic semantic similarity measures on gold standard PPI datasets and state-of-the-art machine-learning-based approaches on large datasets from Saccharomyces cerevisiae and Homo sapiens. We show how the neural attention mechanism embedded in the transformer architecture detects relevant functional terms when predicting interactions. © 2022 The Author(s) 2022. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yuan, Q.
AU  - Chen, S.
AU  - Rao, J.
AU  - Zheng, S.
AU  - Zhao, H.
AU  - Yang, Y.
TI  - AlphaFold2-aware protein-DNA binding site prediction using graph transformer
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 2
C7  - bbab564
DO  - 10.1093/bib/bbab564
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127499599&doi=10.1093%2fbib%2fbbab564&partnerID=40&md5=7864b6010bf6eabc2d65bf2abe4072e2
AB  - Protein-DNA interactions play crucial roles in the biological systems, and identifying protein-DNA binding sites is the first step for mechanistic understanding of various biological activities (such as transcription and repair) and designing novel drugs. How to accurately identify DNA-binding residues from only protein sequence remains a challenging task. Currently, most existing sequence-based methods only consider contextual features of the sequential neighbors, which are limited to capture spatial information. Based on the recent breakthrough in protein structure prediction by AlphaFold2, we propose an accurate predictor, GraphSite, for identifying DNA-binding residues based on the structural models predicted by AlphaFold2. Here, we convert the binding site prediction problem into a graph node classification task and employ a transformer-based variant model to take the protein structural information into account. By leveraging predicted protein structures and graph transformer, GraphSite substantially improves over the latest sequence-based and structure-based methods. The algorithm is further confirmed on the independent test set of 181 proteins, where GraphSite surpasses the state-of-the-art structure-based method by 16.4% in area under the precision-recall curve and 11.2% in Matthews correlation coefficient, respectively. We provide the datasets, the predicted structures and the source codes along with the pre-trained models of GraphSite at https://github.com/biomed-AI/GraphSite. The GraphSite web server is freely available at https://biomed.nscc-gz.cn/apps/GraphSite.  © 2022 The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shao, T.
AU  - Cai, F.
AU  - Chen, W.
AU  - Chen, H.
TI  - Self-supervised clarification question generation for ambiguous multi-turn conversation
PY  - 2022
T2  - Information Sciences
VL  - 587
SP  - 626
EP  - 641
DO  - 10.1016/j.ins.2021.12.040
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121925778&doi=10.1016%2fj.ins.2021.12.040&partnerID=40&md5=7ed9ea2d87e44fb0ae3b4c4d0777a62a
AB  - Clarification Question Generation (CQG) aims to automatically generate clarification questions to avoid misunderstanding. In this paper, we focus on generating clarification questions in the scenario of ambiguous multi-turn conversation, which can be well applied to the interactive systems, e.g., dialogue systems and conversational recommendation systems. As a novel direction, limited manual-annotated samples are available for CQG. Moreover, existing approaches mainly ignore the representation of ambiguous semantics and cannot deal with the Out-of-Vocabulary (OOV) problem in a good manner. To address the above issues, we propose a Self-supervised Hierarchical Pointer-generator model (SHiP) for this task. In detail, similar to the backbone Coarse-to-fine process of CQG, we first formulate two self-supervised learning pretext tasks, i.e., Dialogue History Prediction and Entity Name Prediction. Then, we incorporate a hierarchical Transformer mechanism and a pointer-generator mechanism to understand the ambiguous multi-turn conversations and solve the OOV problem. Finally, we propose an end-to-end co-training paradigm to train the pretext tasks and downstream tasks. We quantify the improvements of SHiP against the competitive baselines on a publicly available dataset CLAQUA, showing a general improvement of 6.75% and 3.91% over state-of-the-art baseline in terms of BLEU and ROUGE-L, respectively. © 2021 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - CCF:B期刊; FMS:B; 
LB  - Shao2022Self-supervised
ER  -

TY  - JOUR
AU  - Qiao, Y.
AU  - Zhu, X.
AU  - Gong, H.
TI  - BERT-Kcr: prediction of lysine crotonylation sites by a transfer learning method with pre-trained BERT models
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 3
SP  - 648
EP  - 654
DO  - 10.1093/bioinformatics/btab712
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120426670&doi=10.1093%2fbioinformatics%2fbtab712&partnerID=40&md5=30cf661061ab136b96021825d66f94c0
AB  - Motivation: As one of the most important post-translational modifications (PTMs), protein lysine crotonylation (Kcr) has attracted wide attention, which involves in important physiological activities, such as cell differentiation and metabolism. However, experimental methods are expensive and time-consuming for Kcr identification. Instead, computational methods can predict Kcr sites in silico with high efficiency and low cost. Results: In this study, we proposed a novel predictor, BERT-Kcr, for protein Kcr sites prediction, which was developed by using a transfer learning method with pre-trained bidirectional encoder representations from transformers (BERT) models. These models were originally used for natural language processing (NLP) tasks, such as sentence classification. Here, we transferred each amino acid into a word as the input information to the pre-trained BERT model. The features encoded by BERT were extracted and then fed to a BiLSTM network to build our final model. Compared with the models built by other machine learning and deep learning classifiers, BERT-Kcr achieved the best performance with AUROC of 0.983 for 10-fold cross validation. Further evaluation on the independent test set indicates that BERT-Kcr outperforms the state-of-the-art model Deep-Kcr with an improvement of about 5% for AUROC. The results of our experiment indicate that the direct use of sequence information and advanced pre-trained models of NLP could be an effective way for identifying PTM sites of proteins. © 2022 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 55
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Thumuluri, V.
AU  - Martiny, H.-M.
AU  - Almagro Armenteros, J.J.
AU  - Salomon, J.
AU  - Nielsen, H.
AU  - Johansen, A.R.
TI  - NetSolP: predicting protein solubility in Escherichia coli using language models
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 4
SP  - 941
EP  - 946
DO  - 10.1093/bioinformatics/btab801
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123905288&doi=10.1093%2fbioinformatics%2fbtab801&partnerID=40&md5=54e7c6306f60e8192822dd0d18f39cfa
AB  - Motivation: Solubility and expression levels of proteins can be a limiting factor for large-scale studies and industrial production. By determining the solubility and expression directly from the protein sequence, the success rate of wet-lab experiments can be increased. Results: In this study, we focus on predicting the solubility and usability for purification of proteins expressed in Escherichia coli directly from the sequence. Our model NetSolP is based on deep learning protein language models called transformers and we show that it achieves state-of-the-art performance and improves extrapolation across datasets. As we find current methods are built on biased datasets, we curate existing datasets by using strict sequence-identity partitioning and ensure that there is minimal bias in the sequences. © 2022 Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Chen, K.
AU  - Zhao, H.
AU  - Yang, Y.
TI  - Capturing large genomic contexts for accurately predicting enhancer-promoter interactions
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 2
C7  - bbab577
DO  - 10.1093/bib/bbab577
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127499795&doi=10.1093%2fbib%2fbbab577&partnerID=40&md5=a5fa3212652f6c5aeb7700b2700794d5
AB  - Enhancer-promoter interaction (EPI) is a key mechanism underlying gene regulation. EPI prediction has always been a challenging task because enhancers could regulate promoters of distant target genes. Although many machine learning models have been developed, they leverage only the features in enhancers and promoters, or simply add the average genomic signals in the regions between enhancers and promoters, without utilizing detailed features between or outside enhancers and promoters. Due to a lack of large-scale features, existing methods could achieve only moderate performance, especially for predicting EPIs in different cell types. Here, we present a Transformer-based model, TransEPI, for EPI prediction by capturing large genomic contexts. TransEPI was developed based on EPI datasets derived from Hi-C or ChIA-PET data in six cell lines. To avoid over-fitting, we evaluated the TransEPI model by testing it on independent test datasets where the cell line and chromosome are different from the training data. TransEPI not only achieved consistent performance across the cross-validation and test datasets from different cell types but also outperformed the state-of-the-art machine learning and deep learning models. In addition, we found that the improved performance of TransEPI was attributed to the integration of large genomic contexts. Lastly, TransEPI was extended to study the non-coding mutations associated with brain disorders or neural diseases, and we found that TransEPI was also useful for predicting the target genes of non-coding mutations. © The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chang, Y.-C.
AU  - Ku, C.-H.
AU  - Nguyen, D.-D.L.
TI  - Predicting aspect-based sentiment using deep learning and information visualization: The impact of COVID-19 on the airline industry
PY  - 2022
T2  - Information and Management
VL  - 59
IS  - 2
C7  - 103587
DO  - 10.1016/j.im.2021.103587
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122150763&doi=10.1016%2fj.im.2021.103587&partnerID=40&md5=2e168c1b473d76696a8d3708c689f01b
AB  - This study investigates customer satisfaction through aspect-level sentiment analysis and visual analytics. We collected and examined the flight reviews on TripAdvisor from January 2016 to August 2020 to gauge the impact of COVID-19 on passenger travel sentiment in several aspects. Till now, information systems, management, and tourism research have paid little attention to the use of deep learning and word embedding techniques, such as bidirectional encoder representations from transformers, especially for aspect-level sentiment analysis. This paper aims to identify perceived aspect-based sentiments and predict unrated sentiments for various categories to address this research gap. Ultimately, this study complements existing sentiment analysis methods and extends the use of data-driven and visual analytics approaches to better understand customer satisfaction in the airline industry and within the context of the COVID-19. Our proposed method outperforms baseline comparisons and therefore contributes to the theoretical and managerial literature. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - CCF:C期刊; AJG:3; ZUFE:1A; zdy:3; 
LB  - Chang2022Predicting
ER  -

TY  - JOUR
AU  - Raad, J.
AU  - Bugnon, L.A.
AU  - Milone, D.H.
AU  - Stegmayer, G.
TI  - MiRe2e: A full end-to-end deep model based on transformers for prediction of pre-miRNAs
PY  - 2022
T2  - Bioinformatics
VL  - 38
IS  - 5
SP  - 1191
EP  - 1197
DO  - 10.1093/bioinformatics/btab823
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125483106&doi=10.1093%2fbioinformatics%2fbtab823&partnerID=40&md5=50016b14ceea2edd3707065273413e1e
AB  - Motivation: MicroRNAs (miRNAs) are small RNA sequences with key roles in the regulation of gene expression at post-transcriptional level in different species. Accurate prediction of novel miRNAs is needed due to their importance in many biological processes and their associations with complicated diseases in humans. Many machine learning approaches were proposed in the last decade for this purpose, but requiring handcrafted features extraction to identify possible de novo miRNAs. More recently, the emergence of deep learning (DL) has allowed the automatic feature extraction, learning relevant representations by themselves. However, the state-of-art deep models require complex pre-processing of the input sequences and prediction of their secondary structure to reach an acceptable performance. Results: In this work, we present miRe2e, the first full end-to-end DL model for pre-miRNA prediction. This model is based on Transformers, a neural architecture that uses attention mechanisms to infer global dependencies between inputs and outputs. It is capable of receiving the raw genome-wide data as input, without any pre-processing nor feature engineering. After a training stage with known pre-miRNAs, hairpin and non-harpin sequences, it can identify all the pre-miRNA sequences within a genome. The model has been validated through several experimental setups using the human genome, and it was compared with state-of-the-art algorithms obtaining 10 times better performance.  © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 16
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Le, T.
AU  - Nguyen, K.
AU  - Phung, D.
TI  - Improving kernel online learning with a snapshot memory
PY  - 2022
T2  - Machine Learning
VL  - 111
IS  - 3
SP  - 997
EP  - 1018
DO  - 10.1007/s10994-021-06075-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122303537&doi=10.1007%2fs10994-021-06075-7&partnerID=40&md5=bdf3a9caf0f10dc1e003d625f0a7f620
AB  - We propose in this paper the Stochastic Variance-reduced Gradient Descent for Kernel Online Learning (DualSVRG), which obtains the ε-approximate linear convergence rate and is not vulnerable to the curse of kernelization. Our approach uses a variance reduction technique to reduce the variance when estimating full gradient, and further exploits recent work in dual space gradient descent for online learning to achieve model optimality. This is achieved by introducing the concept of an instant memory, which is a snapshot storing the most recent incoming data instances and proposing three transformer oracles, namely budget, coverage, and always-move oracles. We further develop rigorous theoretical analysis to demonstrate that our proposed approach can obtain the ε-approximate linear convergence rate, while maintaining model sparsity, hence encourages fast training. We conduct extensive experiments on several benchmark datasets to compare our DualSVRG with state-of-the-art baselines in both batch and online settings. The experimental results show that our DualSVRG yields superior predictive performance, while spending comparable training time with baselines. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, S.
AU  - Huang, Y.
AU  - Bu, Y.
AU  - Lu, W.
AU  - Qian, J.
AU  - Wang, D.
TI  - Fine-grained citation count prediction via a transformer-based model with among-attention mechanism
PY  - 2022
T2  - Information Processing and Management
VL  - 59
IS  - 2
C7  - 102799
DO  - 10.1016/j.ipm.2021.102799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118854228&doi=10.1016%2fj.ipm.2021.102799&partnerID=40&md5=2660db52e6fbb1a60069525b41c4be25
AB  - Previous studies have confirmed that citation mention and location reveal different contributions of the cited articles, and that both are significant in scientific research evaluation. However, traditional citation count prediction only focuses on predicting citation frequency. In this paper, we propose a novel fine-grained citation count prediction task (FGCCP), which aims to predict in-text citation count from each structural function of a paper separately. Specifically, we treated this task as a “sequence to sequence” issue and a multi-task learning job, in which both the inputs and the outputs are based on the sequence pattern of citations from different structural functions. To fulfill FGCCP, we proposed a transformer-based model (i.e. MTAT) in which a novel among-attention mechanism is employed. Based on an empirical study of full-text documents from PubMed Central Open Access Subset, our model achieves satisfactory prediction accuracy, and surpasses common machine learning and deep learning models on FGCCP. Moreover, we also discuss the potential role of the among-attention mechanism and the reason why our proposed model outperforms state-of-the-art strategies. FGCCP may provide more detailed decision-making evidence and evaluation basis for researchers in scientific research evaluation. In addition, MTAT is a general model which can be easily deployed in other multi-task learning jobs. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Lin, S.-Y.
AU  - Kung, Y.-C.
AU  - Leu, F.-Y.
TI  - Predictive intelligence in harmful news identification by BERT-based ensemble learning model with text sentiment analysis
PY  - 2022
T2  - Information Processing and Management
VL  - 59
IS  - 2
C7  - 102872
DO  - 10.1016/j.ipm.2022.102872
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123396510&doi=10.1016%2fj.ipm.2022.102872&partnerID=40&md5=43abf0375839b109e1371462a4363aa3
AB  - In an environment full of disordered information, the media spreads fake or harmful information into the public arena with a speed which is faster than ever before. A news report should ideally be neutral and factual. Excessive personal emotions or viewpoints should not be included. News articles ought not to be intentionally or maliciously written or create a media framing. A harmful news is defined as those explicit or implicit harmful speech in news text that harms people or affects readers’ perception. However, in the current situation, it is difficult to effectively identify and predict fake or harmful news in advance, especially harmful news. Therefore, in this study, we propose a Bidirectional Encoder Representation from Transformers (BERT) based model which applies ensemble learning methods with a text sentiment analysis to identify harmful news, aiming to provide readers with a way to identify harmful news content so as to help them to judge whether the information provided is in a more neutral manner. The working model of the proposed system has two phases. The first phase is collecting harmful news and establishing a development model for analyzing the correlation between text sentiment and harmful news. The second phase is identifying harmful news by analyzing text sentiment with an ensemble learning technique and the BERT model. The purpose is to determine whether the news has harmful intentions. Our experimental results show that the F1-score of the proposed model reaches 66.3%, an increase of 7.8% compared with that of the previous term frequency-inverse document frequency approach which adopts a Lagrangian Support Vector Machine (LSVM) model without using a text sentiment. Moreover, the proposed method achieves a better performance in recognizing various cases of information disorder. © 2022 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 64
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Izadi, M.
AU  - Akbari, K.
AU  - Heydarnoori, A.
TI  - Predicting the objective and priority of issue reports in software repositories
PY  - 2022
T2  - Empirical Software Engineering
VL  - 27
IS  - 2
C7  - 50
DO  - 10.1007/s10664-021-10085-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123988141&doi=10.1007%2fs10664-021-10085-3&partnerID=40&md5=89f291da12a6d15be97029f2bd0a03be
AB  - Software repositories such as GitHub host a large number of software entities. Developers collaboratively discuss, implement, use, and share these entities. Proper documentation plays an important role in successful software management and maintenance. Users exploit Issue Tracking Systems, a facility of software repositories, to keep track of issue reports, to manage the workload and processes, and finally, to document the highlight of their team’s effort. An issue report is a rich source of collaboratively-curated software knowledge, and can contain a reported problem, a request for new features, or merely a question about the software product. As the number of these issues increases, it becomes harder to manage them manually. GitHub provides labels for tagging issues, as a means of issue management. However, about half of the issues in GitHub’s top 1000 repositories do not have any labels. In this work, we aim at automating the process of managing issue reports for software teams. We propose a two-stage approach to predict both the objective behind opening an issue and its priority level using feature engineering methods and state-of-the-art text classifiers. To the best of our knowledge, we are the first to fine-tune a Transformer for issue classification. We train and evaluate our models in both project-based and cross-project settings. The latter approach provides a generic prediction model applicable for any unseen software project or projects with little historical data. Our proposed approach can successfully predict the objective and priority level of issue reports with 82 % (fine-tuned RoBERTa) and 75 % (Random Forest) accuracy, respectively. Moreover, we conducted human labeling and evaluation on unlabeled issues from six unseen GitHub projects to assess the performance of the cross-project model on new data. The model achieves 90 % accuracy on the sample set. We measure inter-rater reliability and obtain an average Percent Agreement of 85.3 % and Randolph’s free-marginal Kappa of 0.71 that translate to a substantial agreement among labelers. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 43
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chang, T.A.
AU  - Bergen, B.K.
TI  - Word Acquisition in Neural Language Models
PY  - 2022
T2  - Transactions of the Association for Computational Linguistics
VL  - 10
SP  - 1
EP  - 16
DO  - 10.1162/tacl_a_00444
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123827455&doi=10.1162%2ftacl_a_00444&partnerID=40&md5=f5117713bc1568bc92794f915645273e
AB  - We investigate how neural language models acquire individual words during training, extracting learning curves and ages of acquisition for over 600 words on the MacArthur-Bates Communicative Development Inventory (Fenson et al., 2007). Drawing on studies of word acquisition in children, we evaluate multiple predictors for words’ ages of acquisition in LSTMs, BERT, and GPT-2. We find that the effects of concreteness, word length, and lexical class are pointedly different in children and language models, reinforcing the importance of interaction and sensorimotor experience in child language acquisition. Language models rely far more on word frequency than children, but, like children, they exhibit slower learning of words in longer utterances. Interestingly, models follow consistent patterns during training for both unidirectional and bidirectional models, and for both LSTM and Transformer architectures. Models predict based on unigram token frequencies early in training, before transitioning loosely to bigram probabilities, eventually converging on more nuanced predictions. These results shed light on the role of distributional learning mechanisms in children, while also providing insights for more human-like language acquisition in language models. © 2022 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 24
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Geneva, N.
AU  - Zabaras, N.
TI  - Transformers for modeling physical systems
PY  - 2022
T2  - Neural Networks
VL  - 146
SP  - 272
EP  - 289
DO  - 10.1016/j.neunet.2021.11.022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121150805&doi=10.1016%2fj.neunet.2021.11.022&partnerID=40&md5=84f133f2a757b18e315749d192648af3
AB  - Transformers are widely used in natural language processing due to their ability to model longer-term dependencies in text. Although these models achieve state-of-the-art performance for many language related tasks, their applicability outside of the natural language processing field has been minimal. In this work, we propose the use of transformer models for the prediction of dynamical systems representative of physical phenomena. The use of Koopman based embeddings provides a unique and powerful method for projecting any dynamical system into a vector representation which can then be predicted by a transformer. The proposed model is able to accurately predict various dynamical systems and outperform classical methods that are commonly used in the scientific machine learning literature.1 © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 81
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, X.
AU  - Dong, M.
AU  - Li, J.
AU  - Guo, X.
TI  - A 3-D-Swin Transformer-Based Hierarchical Contrastive Learning Method for Hyperspectral Image Classification
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5411415
DO  - 10.1109/TGRS.2022.3202036
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137545168&doi=10.1109%2fTGRS.2022.3202036&partnerID=40&md5=5c08f8d65d36adaeed8a63450babd2e1
AB  - Deep convolutional neural networks have been dominating in the field of hyperspectral image (HSI) classification. However, single convolutional kernel can limit the receptive field and fail to capture the sequential properties of data. The self-attention-based Transformer can build global sequence information, among which the Swin Transformer (SwinT) integrates sequence modeling capability and prior information of the visual signals (e.g., locality and translation invariance). Based on SwinT, we propose a 3-D SwinT (3DSwinT) to accommodate the 3-D properties of HSI and capture the rich spatial-spectral information of HSI. Currently, supervised learning is still the most commonly used method for remote sensing image interpretation. However, pixel-by-pixel HSI classification demands a large number of high-quality labeled samples that are time-consuming and costly to collect. As unsupervised learning, self-supervised learning (SSL), especially contrastive learning, can learn semantic representations from unlabeled data and, hence, is becoming a potential alternative to supervised learning. On the other hand, current contrastive learning methods are all single level or single scale, which do not consider complex and variable multiscale features of objects. Therefore, this article proposes a novel 3DSwinT-based hierarchical contrastive learning (3DSwinT-HCL) method, which can fully exploit multiscale semantic representations of images. Besides, we propose a multiscale local contrastive learning (MS-LCL) module to mine the pixel-level representations in order to adapt to downstream dense prediction tasks. A series of experiments verify the great potential and superiority of 3DSwinT-HCL.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 71
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, R.
AU  - An, L.
AU  - Li, G.
AU  - Yu, C.
TI  - Predicting social media rumours in the context of public health emergencies
PY  - 2022
T2  - Journal of Information Science
DO  - 10.1177/01655515221137879
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142854837&doi=10.1177%2f01655515221137879&partnerID=40&md5=a1523905782f7a382764e7b04e24cc7d
AB  - The spread of rumours on social media in the context of public health emergencies often distorts perceptions of public events and obstructs crisis management. Microblog entries about 28 rumour cases are collected on Sina Weibo during the COVID-19 outbreak. The Modality–Agency–Interactivity–Navigability model is used to identify the key factors of rumour prediction. To investigate the relationship among information modality, information content, information source and rumour identification, the binary logistic regression model is established based on the features of users and microblog entries. In addition, we propose a multi-feature rumour prediction model based on the Bidirectional Encoder Representations from Transformers (BERT) and Extreme Gradient Boosting (XGBoost) models. The proposed rumour prediction model has the best performance compared with other models. The feature importance is then calculated by the SHapley Additive exPlanations (SHAP), which can also explain the XGBoost results. It is shown that the likelihood that microblog entries are rumours decreases as the values of variables such as user influence and the positive sentiment of comments rise. Microblog entries posted on Thursdays or at noon are more probably to be rumours than those posted at other time. The proposed model can assist emergency management departments in establishing a feasible rumour prediction mechanism to guide public opinion against rumours. © The Author(s) 2022.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Sun2022Predicting
ER  -

TY  - JOUR
AU  - Dong, X.
AU  - Zhao, Z.
AU  - Wang, Y.
AU  - Wang, J.
AU  - Hu, C.
TI  - Motion-Guided Global-Local Aggregation Transformer Network for Precipitation Nowcasting
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5119816
DO  - 10.1109/TGRS.2022.3217639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141519323&doi=10.1109%2fTGRS.2022.3217639&partnerID=40&md5=1b1a80d8643173509bfc0e9b39f1efba
AB  - Nowadays deep learning-based weather radar echo extrapolation methods have competently improved nowcasting quality. Current pure convolutional or convolutional recurrent neural network-based extrapolation pipelines inherently struggle in capturing both global and local spatiotemporal interactions simultaneously, thereby limiting nowcasting performances, e.g., they not only tend to underestimate heavy rainfalls' spatial coverage and intensity but also fail to precisely predict nonlinear motion patterns. Furthermore, the usually adopted pixel-wise objective functions lead to blurry predictions. To this end, we propose a novel motion-guided global-local aggregation Transformer network for effectively combining spatiotemporal cues at different time scales, thereby strengthening global-local spatiotemporal aggregation urgently required by the extrapolation task. First, we divide existing observations into both short- and long-term sequences to represent echo dynamics at different time scales. Then, to introduce reasonable motion guidance to Transformer, we customize an end-to-end module for jointly extracting motion representation of short- and long-term echo sequences (MRS, MRL), while estimating optical flow. Subsequently, based on Transformer architecture, MRS is used as queries to retrospect the most useful information from MRL for an effective aggregation of global long-term and local short-term cues. Finally, the fused feature is employed for future echo prediction. Additionally, for the blurry prediction problem, predictions from our model trained with an adversarial regularization achieve superior performances not only in nowcasting skill scores but also in precipitation details and image clarity over existing methods. Extensive experiments on two challenging radar echo datasets demonstrate the effectiveness of our proposed method.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Thayaparan, M.
AU  - Valentino, M.
AU  - Ferreira, D.
AU  - Rozanova, J.
AU  - Freitas, A.
TI  - Diff-Explainer: Differentiable Convex Optimization for Explainable Multi-hop Inference
PY  - 2022
T2  - Transactions of the Association for Computational Linguistics
VL  - 10
SP  - 1103
EP  - 1119
DO  - 10.1162/tacl_a_00508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138732560&doi=10.1162%2ftacl_a_00508&partnerID=40&md5=5f24a0d53ef21bd5c39fdbec7e5d4eb3
AB  - This paper presents Diff-Explainer, the first hybrid framework for explainable multi-hop inference that integrates explicit constraints with neural architectures through differentiable convex optimization. Specifically, DiffExplainer allows for the fine-tuning of neural representations within a constrained optimization framework to answer and explain multi-hop questions in natural language. To demonstrate the efficacy of the hybrid framework, we combine existing ILP-based solvers for multi-hop Question Answering (QA) with Transformer-based representations. An extensive empirical evaluation on scientific and commonsense QA tasks demonstrates that the integration of explicit constraints in a end-to-end differentiable framework can significantly improve the performance of nondifferentiable ILP solvers (8.91%–13.3%). Moreover, additional analysis reveals that Diff-Explainer is able to achieve strong performance when compared to standalone Transformers and previous multi-hop approaches while still providing structured explanations in support of its predictions. © 2022 Association for Computational Linguistics.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 6
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, M.
AU  - Shi, Q.
AU  - Li, J.
AU  - Chai, Z.
TI  - Learning Token-Aligned Representations with Multimodel Transformers for Different-Resolution Change Detection
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 4413013
DO  - 10.1109/TGRS.2022.3200684
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137572006&doi=10.1109%2fTGRS.2022.3200684&partnerID=40&md5=78216b2da6266e90ac143c01c50372f8
AB  - Different-resolution change detection (DRCD) is now becoming an urgent problem to be solved, which is of great potential in rapid monitoring, such as disaster assessment and urban expansion. In DRCD tasks, bitemporal inputs are given in the form of different resolutions, and thus, conventional change detection (CD) methods cannot be applied directly. Previous studies have attempted to deal with this problem by reconstructing the low-resolution (LR) image into a high-resolution (HR) one, including interpolation and super-resolution (SR). However, these solutions are limited by the availability of training data, making it hard to meet different kinds of needs. Besides, these image-level strategies have also ignored the interaction and alignment of high-level features. Therefore, we propose a new approach based on multimodel Transformers (MM-Trans), which solves the resolution gaps of bitemporal inputs in DRCD tasks from the perspective of feature alignment. In the MM-Trans, a weight-unshared feature extractor is first utilized to precisely capture the features of the different-resolution inputs. Then, a spatial-aligned Transformer (sp-Trans) is introduced to align the LR-image features to the same size of the HR-image ones, which can be optimized in a learnable way by an auxiliary token loss. After that, a semantic-aligned Transformer (se-Trans) is adopted, in which the bitemporal features can be further interacted and aligned semantically. Finally, a prediction head is employed to obtain fine-grained change results. Experiments conducted on three common CD datasets, CDD, S2Looking, and HTCD dataset, have shown the advancement of the MM-Trans and fully demonstrated its potential in DSCD tasks.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Jin, P.
AU  - Mou, L.
AU  - Xia, G.-S.
AU  - Zhu, X.X.
TI  - Anomaly Detection in Aerial Videos With Transformers
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5628213
DO  - 10.1109/TGRS.2022.3198130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136717906&doi=10.1109%2fTGRS.2022.3198130&partnerID=40&md5=9dd9675cb106b2aa1e0dcdadc8fe161c
AB  - Unmanned aerial vehicles (UAVs) are widely applied for purposes of inspection, search, and rescue operations by the virtue of low-cost, large-coverage, real-time, and high-resolution data acquisition capacities. Massive volumes of aerial videos are produced in these processes, in which normal events often account for an overwhelming proportion. It is extremely difficult to localize and extract abnormal events containing potentially valuable information from long video streams manually. Therefore, we are dedicated to developing anomaly detection methods to solve this issue. In this article, we create a new dataset, named Drone-Anomaly, for anomaly detection in aerial videos. This dataset provides 37 training video sequences and 22 testing video sequences from seven different realistic scenes with various anomalous events. There are 87488 color video frames (51635 for training and 35853 for testing) with the size of 640 ×640 at 30 frames/s. Based on this dataset, we evaluate existing methods and offer a benchmark for this task. Furthermore, we present a new baseline model, anomaly detection with Transformers (ANDTs), which treats consecutive video frames as a sequence of tubelets, utilizes a Transformer encoder to learn feature representations from the sequence, and leverages a decoder to predict the next frame. Our network models normality in the training phase and identifies an event with unpredictable temporal dynamics as an anomaly in the test phase. Moreover, to comprehensively evaluate the performance of our proposed method, we use not only our Drone-Anomaly dataset but also another dataset. We will make our dataset and code publicly available. A demo video is available at https://youtu.be/ancczYryOBY. We make our dataset and code publicly available (https://gitlab.lrz.de/ai4eo/reasoning/drone-anomaly https://github.com/Jin-Pu/Drone-Anomaly). © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 29
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Feng, Y.
AU  - Xu, H.
AU  - Jiang, J.
AU  - Liu, H.
AU  - Zheng, J.
TI  - ICIF-Net: Intra-Scale Cross-Interaction and Inter-Scale Feature Fusion Network for Bitemporal Remote Sensing Images Change Detection
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 4410213
DO  - 10.1109/TGRS.2022.3168331
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128693596&doi=10.1109%2fTGRS.2022.3168331&partnerID=40&md5=438db22e25b8f191c40a0f72edc0c00e
AB  - Change detection (CD) of remote sensing (RS) images has enjoyed remarkable success by virtue of convolutional neural networks (CNNs) with promising discriminative capabilities. However, CNNs lack the capability of modeling long-range dependencies in bitemporal image pairs, resulting in inferior identifiability against the same semantic targets yet with varying features. The recently thriving Transformer, on the contrary, is warranted, for practice, with global receptive fields. To jointly harvest the local-global features and circumvent the misalignment issues caused by step-by-step downsampling operations in traditional backbone networks, we propose an intra-scale cross-interaction and inter-scale feature fusion network (ICIF-Net), explicitly tapping the potential of integrating CNN and Transformer. In particular, the local features and global features, respectively, extracted by CNN and Transformer, are interactively communicated at the same spatial resolution using a linearized Conv Attention module, which motivates the counterpart to glimpse the representation of another branch while preserving its own features. In addition, with the introduction of two attention-based inter-scale fusion schemes, including mask-based aggregation and spatial alignment (SA), information integration is enforced at different resolutions. Finally, the integrated features are fed into a conventional change prediction head to generate the output. Extensive experiments conducted on four CD datasets of bitemporal (RS) images demonstrate that our ICIF-Net surpasses the other state-of-the-art (SOTA) approaches. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 157
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pi, Z.
AU  - Jiao, L.
AU  - Liu, F.
AU  - Liu, X.
AU  - Li, L.
AU  - Hou, B.
AU  - Yang, S.
TI  - Very Low-Resolution Moving Vehicle Detection in Satellite Videos
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5624517
DO  - 10.1109/TGRS.2022.3179502
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131733647&doi=10.1109%2fTGRS.2022.3179502&partnerID=40&md5=6dc38a35ca11104327d58bca94524930
AB  - This article proposes a practical end-to-end neural network framework to detect tiny moving vehicles in satellite videos with low imaging quality. Some instability factors, such as illumination changes, motion blurs, and low contrast to the cluttered background, make it difficult to distinguish true objects from noise and other point-shaped distractors. Moving vehicle detection in satellite videos can be carried out based on background subtraction or frame differencing. However, these methods are prone to produce lots of false alarms and miss many positive targets. Appearance-based detection can be an alternative but is not well-suited since classifier models are of weak discriminative power for the vehicles in top view at such low resolution. This article addresses these issues by integrating motion information from adjacent frames to facilitate the extraction of semantic features and incorporating the transformer to refine the features for key points estimation and scale prediction. Our proposed model can well identify the actual moving targets and suppress interference from stationary targets or background. The experiments and evaluations using satellite videos show that the proposed approach can accurately locate the targets under weak feature attributes and improve the detection performance in complex scenarios. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bai, J.
AU  - Wen, Z.
AU  - Xiao, Z.
AU  - Ye, F.
AU  - Zhu, Y.
AU  - Alazab, M.
AU  - Jiao, L.
TI  - Hyperspectral Image Classification Based on Multibranch Attention Transformer Networks
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5535317
DO  - 10.1109/TGRS.2022.3196661
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135745459&doi=10.1109%2fTGRS.2022.3196661&partnerID=40&md5=00587a41f2d0ac6baef5b57250564320
AB  - Deep learning (DL) has become a mainstream method of hyperspectral image (HSI) classification. Many DL-based methods exploit spatial-spectral features to achieve better classification results. However, due to the complex backgrounds in HSIs, existing methods usually show unsatisfactory performance for the class pixels located on the land-cover category boundary area. In large part, this is because the network is susceptible to interference by the irrelevant information around the target pixel in the training stage, resulting in inaccurate feature extraction. In this article, a new multibranch transformer architecture (spectral spatial transformer (SST)-M) that assembles spatial attention and extracts spectral features is proposed to address this problem. The transformer model has a global receptive field and thus can integrate global spatial position information in the HSI cube. Meanwhile, we design a spatial sequence attention model to enhance the useful spatial location features and weaken invalid information. Considering that HSIs contain considerable spectral information, a spectral feature extraction model is designed to extract discriminative spectral features, replacing the widely used principal component analysis (PCA) method and obtaining better classification results than it. Finally, inspired by semantic segmentation, a mask prediction model is designed to classify all of the pixels in the HSI cube; this guides the neural network to learn precise pixel characteristics and spatial distributions. To verify the effectiveness of our algorithm (SST-M), quantitative experiments were conducted in three well-known datasets, namely, Indian Pines (IP), University of Pavia (PU), and Kennedy Space Center (KSC). The experimental results demonstrate that the proposed model achieves better performance than the other state-of-the-art methods.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 46
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Li, C.
AU  - Yang, H.
AU  - Sun, J.
TI  - Intention-Interaction Graph Based Hierarchical Reasoning Networks for Human Trajectory Prediction
PY  - 2022
T2  - IEEE Transactions on Multimedia
SP  - 1
EP  - 12
DO  - 10.1109/TMM.2022.3182151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132746523&doi=10.1109%2fTMM.2022.3182151&partnerID=40&md5=12e901ca70ab1ffdb6e5359a81652bbd
AB  - Understanding crowd motion dynamics and forecasting the future pedestrian trajectories are critical to various applications, e.g. autonomous driving and surveillance system. This task is challenging because when pedestrians plan the future paths in real crowd scenes, they will distinguish the priorities of following their predetermined destinations and responding to the motion behaviors of neighboring pedestrians. However, most of the existing methods ignore the problem of intention-interaction trade-off. In this paper, we tackle this problem by a hierarchical network, which achieves dynamically reasoning predetermined destinations and future trajectories. A novel graph structure called Intention-Interaction Graph (IIG) is designed to jointly model the self intentions and social interactions. To aggregate information in IIG, Interaction Gated Graph Attention Networks (IGGAN) consisting of a gate mechanism and an attention mechanism is proposed, thus achieving reasoning the influence degree of neighboring pedestrians and destinations. Experimental results on multiple widely used pedestrian trajectory prediction datasets, including two datasets in ETH and three datasets in UCY, demonstrate the effectiveness of the proposed model. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Bazi, Y.
AU  - Rahhal, M.M.A.
AU  - Mekhalfi, M.L.
AU  - Zuair, M.A.A.
AU  - Melgani, F.
TI  - Bi-Modal Transformer-Based Approach for Visual Question Answering in Remote Sensing Imagery
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 4708011
DO  - 10.1109/TGRS.2022.3192460
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135211976&doi=10.1109%2fTGRS.2022.3192460&partnerID=40&md5=c4a5ead71b5ee737809a1bb3effda51f
AB  - Recently, vision-language models based on transformers are gaining popularity for joint modeling of visual and textual modalities. In particular, they show impressive results when transferred to several downstream tasks such as zero and few-shot classification. In this article, we propose a visual question answering (VQA) approach for remote sensing images based on these models. The VQA task attempts to provide answers to image-related questions. In contrast, VQA has gained popularity in computer vision, in remote sensing, it is not widespread. First, we use the contrastive language image pretraining (CLIP) network for embedding the image patches and question words into a sequence of visual and textual representations. Then, we learn attention mechanisms to capture the intradependencies and interdependencies within and between these representations. Afterward, we generate the final answer by averaging the predictions of two classifiers mounted on the top of the resulting contextual representations. In the experiments, we study the performance of the proposed approach on two datasets acquired with Sentinel-2 and aerial sensors. In particular, we demonstrate that our approach can achieve better results with reduced training size compared with the recent state-of-the-art.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 34
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Katayama, S.
AU  - Aoki, S.
AU  - Yonezawa, T.
AU  - Okoshi, T.
AU  - Nakazawa, J.
AU  - Kawaguchi, N.
TI  - ER-Chat: A Text-to-Text Open-Domain Dialogue Framework for Emotion Regulation
PY  - 2022
T2  - IEEE Transactions on Affective Computing
VL  - 13
IS  - 4
SP  - 2229
EP  - 2237
DO  - 10.1109/TAFFC.2022.3191973
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135206164&doi=10.1109%2fTAFFC.2022.3191973&partnerID=40&md5=9d17a5e391747ca62492d0a75a4f93ae
AB  - Emotions are essential for constructing social relationships between humans and interactive systems. Although emotional and empathetic dialogue generation methods have been proposed for dialogue systems, appropriate dialogue involves not only mirroring emotions and always being empathetic but also complex factors such as context. This paper proposes Emotion Regulation Chat (ER-Chat) as an end-to-end dialogue framework for emotion regulation. Emotion regulation is concerned with actions to approach appropriate emotional states. Learning appropriate emotion and intent when responding on the basis of the context of the dialogue enables the generation of more human-like dialogue. We conducted automatic and human evaluations to demonstrate the superiority of ER-Chat over the baseline system. The results show that inclusion of emotion and intent prediction mechanisms enable generation of dialogues with greater fluency, diversity, emotion awareness, and emotion appropriateness, which are greatly preferred by humans. © 2010-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 11
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wei, S.
AU  - Zeng, X.
AU  - Zhang, H.
AU  - Zhou, Z.
AU  - Shi, J.
AU  - Zhang, X.
TI  - LFG-Net: Low-Level Feature Guided Network for Precise Ship Instance Segmentation in SAR Images
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5231017
DO  - 10.1109/TGRS.2022.3188677
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134260643&doi=10.1109%2fTGRS.2022.3188677&partnerID=40&md5=7f2e6b1a030fd3ee23d8c320c7a0602f
AB  - Ship instance segmentation of high-resolution (HR) synthetic aperture radar (SAR) images is a valuable and challenging task due to the complex scattering and noise properties. In this article, we pioneered the construction of the low-level feature to discriminate the ships and complemented the super-resolution (SR) denoising techniques in the network modules, termed low-level feature guided network (LFG-Net), for precise ship instance segmentation in SAR images. LFG-Net consists of the low-level feature concerned pyramid (LFCP), the high-resolution feature interaction module (HR-FIM), and the compression recovery segmentation branch (CRSB). LFCP extends the vanilla feature pyramid network (FPN) with the P1 layer and complements SR techniques to capture the regional and texture information at the image level for small object segmentation. HR-FIM interacts with the bounding box region of interest (RoI) feature and mask RoI feature at the instance level with HR techniques to enhance the mask RoI feature. CRSB aims at recovering the HR mask predictions to improve the ship segmentation performance. Comprehensive experiments on high-resolution SAR images dataset (HRSID), polygon segmentation SAR ship detection dataset (PSeg-SSDD), and AirSARShip indicate that LFG-Net∗ achieves 11.7%, 6.3%, and 12.7% AP increments compared with the Mask R-CNN baseline, respectively. Besides, it receives 9.5%, 4.9%, and 7.3% AP increments compared with the state-of-the-art method, which bridges the gap of instance segmentation precision in SAR images. In terms of the visualized instance segmentation results, LFG-Net∗ is capable of segmenting the complex scenes, e.g., the adjacent distributed ships and ships with strong reflection noise interference, in SAR images. The code is available at: https://github.com/Evarray/LFG-Net. © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ren, M.
AU  - Huang, X.
AU  - Li, W.
AU  - Song, D.
AU  - Nie, W.
TI  - LR-GCN: Latent Relation-Aware Graph Convolutional Network for Conversational Emotion Recognition
PY  - 2022
T2  - IEEE Transactions on Multimedia
VL  - 24
SP  - 4422
EP  - 4432
DO  - 10.1109/TMM.2021.3117062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118620378&doi=10.1109%2fTMM.2021.3117062&partnerID=40&md5=75823dc1c7f43ca915ada0693c11c545
AB  - As an intersection of artificial intelligence and human communication analysis, Emotion Recognition in Conversation (ERC) has attracted much research attention in recent years. Existing studies, however, are limited in adequately exploiting latent relations among the constituent utterances. In this paper, we address this issue by proposing a novel approach named Latent Relation-Aware Graph Convolutional Network (LR-GCN), where both speaker dependency of the interlocutors is leveraged and latent correlations among the utterances are captured for ERC. Specifically, we first establish a graph model to incorporate the context information and speaker dependency of the conversation. Afterward, the multi-head attention mechanism is introduced to explore the latent correlations among the utterances and generate a set of all-linked graphs. Here, aiming to simultaneously exploit the original modeled speaker dependency and the explored correlation information, we introduce a dense connection layer to capture more structural information of the generated graphs. Through a multi-branch graph network, we achieve a unified representation of each utterance for final prediction. Detailed evaluations on two benchmark datasets demonstrate LR-GCN outperforms the state-of-the-art approaches. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Du, S.
AU  - Liu, C.
AU  - Cao, Z.
TI  - Interior Attention-Aware Network for Infrared Small Target Detection
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
C7  - 5002013
DO  - 10.1109/TGRS.2022.3163410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127500371&doi=10.1109%2fTGRS.2022.3163410&partnerID=40&md5=f3228fb17e07895c3faf4c16dffe6c3e
AB  - Infrared small target detection plays an important role in target warning, ground monitoring, and flight guidance. Existing methods typically utilize local-contrast information of each pixel to detect infrared small targets, neglecting the interior relation between target pixels or background pixels. The mere use of the local information of one pixel, however, is not sufficient for accurate detection, which may lead to missing detection and false alarms. As a harmonious whole, information between pixels are necessary to determine if a pixel belongs to the target or the background. Motivated by the fact that pixels from targets or backgrounds are correlated with each other, we propose a coarse-to-fine interior attention-aware network (IAANet) for infrared small target detection. Specifically, a region proposal network (RPN) is first applied to obtain coarse target regions and filter out backgrounds. Then, we leverage a transformer encoder to model the attention between pixels in coarse target regions, outputting attention-aware features. Finally, predictions are obtained by feeding attention-aware features to a classification head. Extensive experiments show that our approach is capable of detecting targets precisely, of suppressing a variety of false alarm sources, and works effectively in various background environments and target appearances. We show that our IAANet outperforms the state-of-the-art methods by a large margin. Code will be made available at: https://github.com/kwwcv/iaanet.  © 2022 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 140
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ma, C.
AU  - Zhang, Y.
AU  - Guo, J.
AU  - Hu, Y.
AU  - Geng, X.
AU  - Li, F.
AU  - Lei, B.
AU  - Ding, C.
TI  - End-to-End Method with Transformer for 3-D Detection of Oil Tank from Single SAR Image
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
DO  - 10.1109/TGRS.2021.3127986
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125468332&doi=10.1109%2fTGRS.2021.3127986&partnerID=40&md5=b4504cb09610be3b226f3ddd22bd3e45
AB  - In recent years, deep learning has been successfully applied in the field of synthetic aperture radar (SAR) image object detection. However, unlike ships and tanks targets, the oil tank targets in SAR image are usually dense and compact with more overlaps and discrete scattering centers, which greatly increases the difficulty of extracting location and structural parameters. Most of the existing methods transfer the methods suitable for natural image to the SAR image field, without considering the unique characteristics of SAR image. Therefore, in this article, we propose an improved model based on the end-to-end transformer network, which is the first model introducing transformer network to 3-D detection of oil tank targets from single SAR image. We input the incidence angle into the transformer model as a priori token. Then, we propose a feature description operator (FDO) based on the scattering centers that are used as an aid to improve the precision of predictions. In addition, we also propose a cylinder IOU as a more suitable evaluation metric for 3-D detection of oil tank. Finally, we evaluate our model on an SAR image dataset that contains SAR images from RADARSAT-2, TerraSAR-X, and GF-3 with different incidence angles. Our experiments demonstrate that our proposed model achieves the AP of 77.6% compared with 60.8% of baseline, which proves the effectiveness of the introduction of observation conditions, cylinder IOU loss (CI Loss), and the FDO based on the scattering centers in our model and is appealing for 3-D detection of oil tank.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Metzger, N.
AU  - Turkoglu, M.O.
AU  - D'Aronco, S.
AU  - Wegner, J.D.
AU  - Schindler, K.
TI  - Crop Classification under Varying Cloud Cover with Neural Ordinary Differential Equations
PY  - 2022
T2  - IEEE Transactions on Geoscience and Remote Sensing
VL  - 60
DO  - 10.1109/TGRS.2021.3101965
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114596863&doi=10.1109%2fTGRS.2021.3101965&partnerID=40&md5=4581ac88b194a361fc3ae09dd9de29fc
AB  - Optical satellite sensors cannot see the earth's surface through clouds. Despite the periodic revisit cycle, image sequences acquired by earth observation satellites are, therefore, irregularly sampled in time. State-of-the-art methods for crop classification (and other time-series analysis tasks) rely on techniques that implicitly assume regular temporal spacing between observations, such as recurrent neural networks (RNNs). We propose to use neural ordinary differential equations (NODEs) in combination with RNNs to classify crop types in irregularly spaced image sequences. The resulting ODE-RNN models consist of two steps: an update step, where a recurrent unit assimilates new input data into the model's hidden state, and a prediction step, in which NODE propagates the hidden state until the next observation arrives. The prediction step is based on a continuous representation of the latent dynamics, which has several advantages. At the conceptual level, it is a more natural way to describe the mechanisms that govern the phenological cycle. From a practical point of view, it makes it possible to sample the system state at arbitrary points in time such that one can integrate observations whenever they are available and extrapolate beyond the last observation. Our experiments show that ODE-RNN, indeed, improves classification accuracy over common baselines, such as LSTM, GRU, temporal convolutional network, and transformer. The gains are most prominent in the challenging scenario where only few observations are available (i.e., frequent cloud cover). Moreover, we show that the ability to extrapolate translates to better classification performance early in the season, which is important for forecasting.  © 1980-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 21
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Lin, S.
AU  - Wang, Y.
AU  - Zhang, L.
AU  - Chu, Y.
AU  - Liu, Y.
AU  - Fang, Y.
AU  - Jiang, M.
AU  - Wang, Q.
AU  - Zhao, B.
AU  - Xiong, Y.
AU  - Wei, D.-Q.
TI  - MDF-SA-DDI: Predicting drug-drug interaction events based on multi-source drug fusion, multi-source feature fusion and transformer self-attention mechanism
PY  - 2022
T2  - Briefings in Bioinformatics
VL  - 23
IS  - 1
C7  - bbab421
DO  - 10.1093/bib/bbab421
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125234053&doi=10.1093%2fbib%2fbbab421&partnerID=40&md5=f5f739d21c6a79a975da4a9bc4dab329
AB  - One of the main problems with the joint use of multiple drugs is that it may cause adverse drug interactions and side effects that damage the body. Therefore, it is important to predict potential drug interactions. However, most of the available prediction methods can only predict whether two drugs interact or not, whereas few methods can predict interaction events between two drugs. Accurately predicting interaction events of two drugs is more useful for researchers to study the mechanism of the interaction of two drugs. In the present study, we propose a novel method, MDF-SA-DDI, which predicts drug-drug interaction (DDI) events based on multi-source drug fusion, multi-source feature fusion and transformer self-attention mechanism. MDF-SA-DDI is mainly composed of two parts: multi-source drug fusion and multi-source feature fusion. First, we combine two drugs in four different ways and input the combined drug feature representation into four different drug fusion networks (Siamese network, convolutional neural network and two auto-encoders) to obtain the latent feature vectors of the drug pairs, in which the two auto-encoders have the same structure, and their main difference is the number of neurons in the input layer of the two auto-encoders. Then, we use transformer blocks that include self-attention mechanism to perform latent feature fusion. We conducted experiments on three different tasks with two datasets. On the small dataset, the area under the precision-recall-curve (AUPR) and F1 scores of our method on task 1 reached 0.9737 and 0.8878, respectively, which were better than the state-of-the-art method. On the large dataset, the AUPR and F1 scores of our method on task 1 reached 0.9773 and 0.9117, respectively. In task 2 and task 3 of two datasets, our method also achieved the same or better performance as the state-of-the-art method. More importantly, the case studies on five DDI events are conducted and achieved satisfactory performance. The source codes and data are available at https://github.com/ShenggengLin/MDF-SA-DDI.  © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 91
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Unke, O.T.
AU  - Chmiela, S.
AU  - Gastegger, M.
AU  - Schütt, K.T.
AU  - Sauceda, H.E.
AU  - Müller, K.-R.
TI  - SpookyNet: Learning force fields with electronic degrees of freedom and nonlocal effects
PY  - 2021
T2  - Nature Communications
VL  - 12
IS  - 1
C7  - 7273
DO  - 10.1038/s41467-021-27504-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121316968&doi=10.1038%2fs41467-021-27504-0&partnerID=40&md5=d2722e636a366d9715e8ec62eb697b3f
AB  - Machine-learned force fields combine the accuracy of ab initio methods with the efficiency of conventional force fields. However, current machine-learned force fields typically ignore electronic degrees of freedom, such as the total charge or spin state, and assume chemical locality, which is problematic when molecules have inconsistent electronic states, or when nonlocal effects play a significant role. This work introduces SpookyNet, a deep neural network for constructing machine-learned force fields with explicit treatment of electronic degrees of freedom and nonlocality, modeled via self-attention in a transformer architecture. Chemically meaningful inductive biases and analytical corrections built into the network architecture allow it to properly model physical limits. SpookyNet improves upon the current state-of-the-art (or achieves similar performance) on popular quantum chemistry data sets. Notably, it is able to generalize across chemical and conformational space and can leverage the learned chemical insights, e.g. by predicting unknown spin states, thus helping to close a further important remaining gap for today’s machine learning models in quantum chemistry. © 2021, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 166
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Yamaguchi, H.
AU  - Saito, Y.
TI  - Evotuning protocols for Transformer-based variant effect prediction on multi-domain proteins
PY  - 2021
T2  - Briefings in Bioinformatics
VL  - 22
IS  - 6
C7  - bbab234
DO  - 10.1093/bib/bbab234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121951026&doi=10.1093%2fbib%2fbbab234&partnerID=40&md5=a19e74f84cb3466bb9431f7a6a46c650
AB  - Accurate variant effect prediction has broad impacts on protein engineering. Recent machine learning approaches toward this end are based on representation learning, by which feature vectors are learned and generated from unlabeled sequences. However, it is unclear how to effectively learn evolutionary properties of an engineering target protein from homologous sequences, taking into account the protein's sequence-level structure called domain architecture (DA). Additionally, no optimal protocols are established for incorporating such properties into Transformer, the neural network well-known to perform the best in natural language processing research. This article proposes DA-aware evolutionary fine-tuning, or 'evotuning', protocols for Transformer-based variant effect prediction, considering various combinations of homology search, fine-tuning and sequence vectorization strategies. We exhaustively evaluated our protocols on diverse proteins with different functions and DAs. The results indicated that our protocols achieved significantly better performances than previous DA-unaware ones. The visualizations of attention maps suggested that the structural information was incorporated by evotuning without direct supervision, possibly leading to better prediction accuracy.  © 2021 The Author(s). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 8
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kovács, D.P.
AU  - McCorkindale, W.
AU  - Lee, A.A.
TI  - Quantitative interpretation explains machine learning models for chemical reaction prediction and uncovers bias
PY  - 2021
T2  - Nature Communications
VL  - 12
IS  - 1
C7  - 1695
DO  - 10.1038/s41467-021-21895-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102683306&doi=10.1038%2fs41467-021-21895-w&partnerID=40&md5=3c35ac224a3a59653b43ca20e005ad8d
AB  - Organic synthesis remains a major challenge in drug discovery. Although a plethora of machine learning models have been proposed as solutions in the literature, they suffer from being opaque black-boxes. It is neither clear if the models are making correct predictions because they inferred the salient chemistry, nor is it clear which training data they are relying on to reach a prediction. This opaqueness hinders both model developers and users. In this paper, we quantitatively interpret the Molecular Transformer, the state-of-the-art model for reaction prediction. We develop a framework to attribute predicted reaction outcomes both to specific parts of reactants, and to reactions in the training set. Furthermore, we demonstrate how to retrieve evidence for predicted reaction outcomes, and understand counterintuitive predictions by scrutinising the data. Additionally, we identify Clever Hans predictions where the correct prediction is reached for the wrong reason due to dataset bias. We present a new debiased dataset that provides a more realistic assessment of model performance, which we propose as the new standard benchmark for comparing reaction prediction models. © 2021, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 58
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Vaucher, A.C.
AU  - Schwaller, P.
AU  - Geluykens, J.
AU  - Nair, V.H.
AU  - Iuliano, A.
AU  - Laino, T.
TI  - Inferring experimental procedures from text-based representations of chemical reactions
PY  - 2021
T2  - Nature Communications
VL  - 12
IS  - 1
C7  - 2573
DO  - 10.1038/s41467-021-22951-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105527305&doi=10.1038%2fs41467-021-22951-1&partnerID=40&md5=5957558d46b5fc2b6ac9419f615e3d5c
AB  - The experimental execution of chemical reactions is a context-dependent and time-consuming process, often solved using the experience collected over multiple decades of laboratory work or searching similar, already executed, experimental protocols. Although data-driven schemes, such as retrosynthetic models, are becoming established technologies in synthetic organic chemistry, the conversion of proposed synthetic routes to experimental procedures remains a burden on the shoulder of domain experts. In this work, we present data-driven models for predicting the entire sequence of synthesis steps starting from a textual representation of a chemical equation, for application in batch organic chemistry. We generated a data set of 693,517 chemical equations and associated action sequences by extracting and processing experimental procedure text from patents, using state-of-the-art natural language models. We used the attained data set to train three different models: a nearest-neighbor model based on recently-introduced reaction fingerprints, and two deep-learning sequence-to-sequence models based on the Transformer and BART architectures. An analysis by a trained chemist revealed that the predicted action sequences are adequate for execution without human intervention in more than 50% of the cases. © 2021, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 54
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Gao, L.
AU  - Chen, T.
AU  - Li, X.
AU  - Zeng, P.
AU  - Zhao, L.
AU  - Li, Y.-F.
TI  - Generalized pyramid co-attention with learnable aggregation net for video question answering
PY  - 2021
T2  - Pattern Recognition
VL  - 120
C7  - 108145
DO  - 10.1016/j.patcog.2021.108145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111048135&doi=10.1016%2fj.patcog.2021.108145&partnerID=40&md5=2d73e6013e6e81d6b389c7931d3f9699
AB  - Video based visual question answering (V-VQA) remains challenging at the intersection of vision and language. In this paper, we propose a novel architecture, namely Generalized Pyramid Co-attention with Learnable Aggregation Net (GPC) to address two central problems: 1) how to deploy co-attention to V-VQA task considering the complex and diverse content of videos; and 2) how to aggregate the frame-level features (or word-level features) without destroying the feature distributions and temporal information. To solve the first problem, we propose a Generalized Pyramid Co-attention structure with a novel diversity learning module to explicitly encourage attention accuracy and diversity. And we first instantiate it into a Multi-path Pyramid Co-attention (MPC) to capture diverse feature. Then we find each attention branch of original co-attention mechanism does not interact with the others, which results in coarse attention maps. So we extend the MPC structure to a Cascaded Pyramid Transformer Co-attention (CPTC) module in which we replace co-attention with transformer co-attention. To solve the second problem, we propose a new learnable aggregation method with a set of evidence gates. It automatically aggregates adaptively-weighted frame-level features (or word-level features) to extract rich video (or question) context semantic information. With evidence gates, it then further chooses the most related signals representing the evidence information to predict the answer. Extensive validations on the two V-VQA datasets, TGIF-QA and TVQA show that both our proposed MPC and CPTC achieve the state-of-the-art performance and CPTC performs better under various settings and metrics. Code and model have been released at:https://github.com/lixiangpengcs/LAD-Net-for-VideoQA. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Cheng, J.
AU  - Bendjama, K.
AU  - Rittner, K.
AU  - Malone, B.
TI  - BERTMHC: improved MHC-peptide class II interaction prediction with transformer and multiple instance learning
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 22
SP  - 4172
EP  - 4179
DO  - 10.1093/bioinformatics/btab422
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133522381&doi=10.1093%2fbioinformatics%2fbtab422&partnerID=40&md5=03a8921a0c5ca971637a8f1cf7305225
AB  - Motivation: Increasingly comprehensive characterization of cancer-associated genetic alterations has paved the way for the development of highly specific therapeutic vaccines. Predicting precisely the binding and presentation of peptides to major histocompatibility complex (MHC) alleles is an important step toward such therapies. Recent data suggest that presentation of both class I and II epitopes are critical for the induction of a sustained effective immune response. However, the prediction performance for MHC class II has been limited compared to class I. Results: We present a transformer neural network model which leverages self-supervised pretraining from a large corpus of protein sequences. We also propose a multiple instance learning (MIL) framework to deconvolve mass spectrometry data where multiple potential MHC alleles may have presented each peptide. We show that pretraining boosted the performance for these tasks. Combining pretraining and the novel MIL approach, our model outperforms state-of-the-art models based on peptide and MHC sequence only for both binding and cell surface presentation predictions.  © 2021 The Author(s). Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Chen, D.
AU  - Gao, K.
AU  - Nguyen, D.D.
AU  - Chen, X.
AU  - Jiang, Y.
AU  - Wei, G.-W.
AU  - Pan, F.
TI  - Algebraic graph-assisted bidirectional transformers for molecular property prediction
PY  - 2021
T2  - Nature Communications
VL  - 12
IS  - 1
C7  - 3521
DO  - 10.1038/s41467-021-23720-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107590051&doi=10.1038%2fs41467-021-23720-w&partnerID=40&md5=b9ebff0822474ffff915c8f404f31c4b
AB  - The ability of molecular property prediction is of great significance to drug discovery, human health, and environmental protection. Despite considerable efforts, quantitative prediction of various molecular properties remains a challenge. Although some machine learning models, such as bidirectional encoder from transformer, can incorporate massive unlabeled molecular data into molecular representations via a self-supervised learning strategy, it neglects three-dimensional (3D) stereochemical information. Algebraic graph, specifically, element-specific multiscale weighted colored algebraic graph, embeds complementary 3D molecular information into graph invariants. We propose an algebraic graph-assisted bidirectional transformer (AGBT) framework by fusing representations generated by algebraic graph and bidirectional transformer, as well as a variety of machine learning algorithms, including decision trees, multitask learning, and deep neural networks. We validate the proposed AGBT framework on eight molecular datasets, involving quantitative toxicity, physical chemistry, and physiology datasets. Extensive numerical experiments have shown that AGBT is a state-of-the-art framework for molecular property prediction. © 2021, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 111
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Yang, Y.
AU  - Li, K.
AU  - Li, W.
AU  - Li, F.
AU  - Peng, S.
TI  - BioERP: Biomedical heterogeneous network-based self-supervised representation learning approach for entity relationship predictions
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 24
SP  - 4793
EP  - 4800
DO  - 10.1093/bioinformatics/btab565
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121719324&doi=10.1093%2fbioinformatics%2fbtab565&partnerID=40&md5=b618a5b2951be95c4318575f05e9c7a4
AB  - Motivation: Predicting entity relationship can greatly benefit important biomedical problems. Recently, a large amount of biomedical heterogeneous networks (BioHNs) are generated and offer opportunities for developing network-based learning approaches to predict relationships among entities. However, current researches slightly explored BioHNs-based self-supervised representation learning methods, and are hard to simultaneously capturing local- and global-level association information among entities. Results: In this study, we propose a BioHN-based self-supervised representation learning approach for entity relationship predictions, termed BioERP. A self-supervised meta path detection mechanism is proposed to train a deep Transformer encoder model that can capture the global structure and semantic feature in BioHNs. Meanwhile, a biomedical entity mask learning strategy is designed to reflect local associations of vertices. Finally, the representations from different task models are concatenated to generate two-level representation vectors for predicting relationships among entities. The results on eight datasets show BioERP outperforms 30 state-of-the-art methods. In particular, BioERP reveals great performance with results close to 1 in terms of AUC and AUPR on the drug-target interaction predictions. In summary, BioERP is a promising bio-entity relationship prediction approach.  © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Stevenson, M.
AU  - Mues, C.
AU  - Bravo, C.
TI  - The value of text for small business default prediction: A Deep Learning approach
PY  - 2021
T2  - European Journal of Operational Research
VL  - 295
IS  - 2
SP  - 758
EP  - 771
DO  - 10.1016/j.ejor.2021.03.008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103544993&doi=10.1016%2fj.ejor.2021.03.008&partnerID=40&md5=672fbd733353a8b301ba93614f30a408
AB  - Compared to consumer lending, Micro, Small and Medium Enterprise (mSME) credit risk modelling is particularly challenging, as, often, the same sources of information are not available. Therefore, it is standard policy for a loan officer to provide a textual loan assessment to mitigate limited data availability. In turn, this statement is analysed by a credit expert alongside any available standard credit data. In our paper, we exploit recent advances from the field of Deep Learning and Natural Language Processing (NLP), including the BERT (Bidirectional Encoder Representations from Transformers) model, to extract information from 60,000 textual assessments provided by a lender. We consider the performance in terms of the AUC (Area Under the receiver operating characteristic Curve) and Brier Score metrics and find that the text alone is surprisingly effective for predicting default. However, when combined with traditional data, it yields no additional predictive capability, with performance dependent on the text's length. Our proposed Deep Learning model does, however, appear to be robust to the quality of the text and therefore suitable for partly automating the mSME lending process. We also demonstrate how the content of loan assessments influences performance, leading us to a series of recommendations on a new strategy for collecting future mSME loan assessments. © 2021 Elsevier B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 56
C2  - FMS:A; AJG:4; ZUFE:1A; zdy:4; 
LB  - Stevenson2021value
ER  -

TY  - JOUR
AU  - Miftahutdinov, Z.
AU  - Kadurin, A.
AU  - Kudrin, R.
AU  - Tutubalina, E.
TI  - Medical concept normalization in clinical trials with drug and disease representation learning
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 21
SP  - 3856
EP  - 3864
DO  - 10.1093/bioinformatics/btab474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121339307&doi=10.1093%2fbioinformatics%2fbtab474&partnerID=40&md5=3196dcb211542f6e0ffbba60c90cbce4
AB  - Motivation: Clinical trials are the essential stage of every drug development program for the treatment to become available to patients. Despite the importance of well-structured clinical trial databases and their tremendous value for drug discovery and development such instances are very rare. Presently large-scale information on clinical trials is stored in clinical trial registers which are relatively structured, but the mappings to external databases of drugs and diseases are increasingly lacking. The precise production of such links would enable us to interrogate richer harmonized datasets for invaluable insights. Results: We present a neural approach for medical concept normalization of diseases and drugs. Our two-stage approach is based on Bidirectional Encoder Representations from Transformers (BERT). In the training stage, we optimize the relative similarity of mentions and concept names from a terminology via triplet loss. In the inference stage, we obtain the closest concept name representation in a common embedding space to a given mention representation. We performed a set of experiments on a dataset of abstracts and a real-world dataset of trial records with interventions and conditions mapped to drug and disease terminologies. The latter includes mentions associated with one or more concepts (in-KB) or zero (out-of-KB, nil prediction). Experiments show that our approach significantly outperforms baseline and state-of-the-art architectures. Moreover, we demonstrate that our approach is effective in knowledge transfer from the scientific literature to clinical trial data.  © 2021 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 20
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Pamuksuz, U.
AU  - Yun, J.T.
AU  - Humphreys, A.
TI  - A Brand-New Look at You: Predicting Brand Personality in Social Media Networks with Machine Learning
PY  - 2021
T2  - Journal of Interactive Marketing
VL  - 56
SP  - 55
EP  - 69
DO  - 10.1016/j.intmar.2021.05.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110120421&doi=10.1016%2fj.intmar.2021.05.001&partnerID=40&md5=2b4b64f0510709deb3c6ba221d4cfc13
AB  - Tools for analyzing social media text data to gain marketing insight have recently emerged. While a wealth of research has focused on automated human personality assessment, little research has focused on advancing methods for obtaining brand personality from social media content. Brand personality is a nuanced aspect of brands that has a consistent set of traits aside from its functional benefits. In this study, we introduce a novel, automated, and generalizable data analytics approach to extract near real-time estimates of brand personalities in social media networks. This method can be used to track attempts to change brand personality over time, measure brand personality of competitors, and assess congruence in brand personality. Applied to consumer data, firms can assess how consumers perceive brand personality and study the effects of brand–consumer congruence in personality. Our approach develops a novel hybrid machine learning algorithmic design (LDA2Vec), which bypasses often extensive manual coding tasks, thus providing an adaptable and scalable tool that can be used for a range of management studies. Our approach enhances the theoretical understanding of channeled and perceived brand personality as it is represented in social media networks and provides practitioners with the ability to foster branding strategies by using big data resources. © 2021
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Pamuksuz2021Brand-New
ER  -

TY  - JOUR
AU  - Puranam, D.
AU  - Kadiyali, V.
AU  - Narayan, V.
TI  - The impact of increase in minimum wages on consumer perceptions of service: a transformer model of online restaurant reviews
PY  - 2021
T2  - Marketing Science
VL  - 40
IS  - 5
SP  - 985
EP  - 1004
DO  - 10.1287/mksc.2021.1294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118220280&doi=10.1287%2fmksc.2021.1294&partnerID=40&md5=162ae33122d2e30988c252ade6470a07
AB  - We study the impact of a mandated increase in minimum wages on consumer perceptions of multiple dimensions of service quality in the restaurant industry. When faced with higher minimum wages, firms might reduce the number of employees, resulting in poorer consumer service. Alternatively, higher-paid workers might be more motivated to improve consumer service. Using a combination of human annotation and several transformer models, we estimate the incidence of discussion of several service quality attributes (and their valence) in a textual data set of 97,242 online reviews of 1,752 restaurants posted over two years. We exploit a natural experiment in the County of Santa Clara, California, wherein only the city of San Jose legislated a 25% minimum wage increase in 2013. By comparing restaurant reviews in San Jose with those of synthetic controls, we find an improvement in the perceived service quality of San Jose restaurants. Specifically, we find reduced negative discussion of the courtesy and friendliness of workers. This decrease is present in independent restaurants and not in chains. This finding appears to be consistent with agency theory–based predictions of greater incentives to improve service in independent restaurants. We discuss alternative mechanisms for our results. We also discuss implications for consumers, restaurants, and policy makers. © 2021 INFORMS.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 13
C2  - FMS:A; AJG:5; ZUFE:TOP; zdy:5; 
LB  - Puranam2021impact
ER  -

TY  - JOUR
AU  - Ji, Y.
AU  - Zhou, Z.
AU  - Liu, H.
AU  - Davuluri, R.V.
TI  - DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 15
SP  - 2112
EP  - 2120
DO  - 10.1093/bioinformatics/btab083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143590314&doi=10.1093%2fbioinformatics%2fbtab083&partnerID=40&md5=7a7410ded147496a86711edd4fde5d50
AB  - Motivation: Deciphering the language of non-coding DNA is one of the fundamental problems in genome research. Gene regulatory code is highly complex due to the existence of polysemy and distant semantic relationship, which previous informatics methods often fail to capture especially in data-scarce scenarios. Results: To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, to capture global and transferrable understanding of genomic DNA sequences based on up and downstream nucleotide contexts. We compared DNABERT to the most widely used programs for genome-wide regulatory elements prediction and demonstrate its ease of use, accuracy and efficiency. We show that the single pre-trained transformers model can simultaneously achieve state-of-the-art performance on prediction of promoters, splice sites and transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, DNABERT enables direct visualization of nucleotide-level importance and semantic relationship within input sequences for better interpretability and accurate identification of conserved sequence motifs and functional genetic variant candidates. Finally, we demonstrate that pre-trained DNABERT with human genome can even be readily applied to other organisms with exceptional performance. We anticipate that the pre-trained DNABERT model can be fined tuned to many other sequence analyses tasks. VC The Author(s) 2021. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 355
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Charoenkwan, P.
AU  - Nantasenamat, C.
AU  - Hasan, M.M.
AU  - Manavalan, B.
AU  - Shoombuatong, W.
TI  - BERT4Bitter: A bidirectional encoder representations from transformers (BERT)-based model for improving the prediction of bitter peptides
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 17
SP  - 2556
EP  - 2562
DO  - 10.1093/bioinformatics/btab133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102066790&doi=10.1093%2fbioinformatics%2fbtab133&partnerID=40&md5=c3f08f12ba40f93476d5b3cda6764730
AB  - Motivation: The identification of bitter peptides through experimental approaches is an expensive and timeconsuming endeavor. Due to the huge number of newly available peptide sequences in the post-genomic era, the development of automated computational models for the identification of novel bitter peptides is highly desirable. Results: In this work, we present BERT4Bitter, a bidirectional encoder representation from transformers (BERT)- based model for predicting bitter peptides directly from their amino acid sequence without using any structural information. To the best of our knowledge, this is the first time a BERT-based model has been employed to identify bitter peptides. Compared to widely used machine learning models, BERT4Bitter achieved the best performance with an accuracy of 0.861 and 0.922 for cross-validation and independent tests, respectively. Furthermore, extensive empirical benchmarking experiments on the independent dataset demonstrated that BERT4Bitter clearly outperformed the existing method with improvements of 8.0% accuracy and 16.0% Matthews coefficient correlation, highlighting the effectiveness and robustness of BERT4Bitter. We believe that the BERT4Bitter method proposed herein will be a useful tool for rapidly screening and identifying novel bitter peptides for drug development and nutritional research.  © The Author(s) 2021. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 114
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Nieuwazny, J.
AU  - Nowakowski, K.
AU  - Ptaszynski, M.
AU  - Masui, F.
TI  - Can you fool AI by doing a 180? — A case study on authorship analysis of texts by Arata Osada
PY  - 2021
T2  - Information Processing and Management
VL  - 58
IS  - 5
C7  - 102644
DO  - 10.1016/j.ipm.2021.102644
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107623122&doi=10.1016%2fj.ipm.2021.102644&partnerID=40&md5=ddfbb7461e71cd6ba7810a27bd397cee
AB  - This paper is our attempt at answering a twofold question covering the areas of ethics and authorship analysis solutions. Firstly, since the methods used for performing authorship analysis imply that an author can be recognized by the content he or she creates, we were interested in finding out whether it would be possible for an author identification system to correctly attribute works to authors if in the course of years they have undergone a major psychological transition. Secondly – and from the point of view of the evolution of an author's ethical values – we checked what it would mean if the authorship attribution system encounters difficulties in detecting single authorship. We set out to answer those questions through performing a binary authorship analysis task using a text classifier based on a pre-trained transformer model and a baseline method relying on conventional similarity metrics. For the test set, we chose several works of Arata Osada, a Japanese educator and specialist in the history of education, with half of them being books written before the Second World War and another half in the 1950s, in between which the author underwent a transformation in terms of political opinions. As a result, we were able to confirm that in the case of texts authored by Arata Osada in a time span of more than 10 years, while the classification accuracy drops by a large margin and is substantially lower than for texts by other non-fiction writers, confidence scores of the predictions remain at a similar level as in the case of a shorter time span, indicating that the classifier was in many instances tricked into deciding that texts written by Arata Osada over a time span of multiple years were actually written by two different people, which in turn leads us to believe that such a change can affect authorship analysis, and that historical events have great impact on a person's ethical outlook as expressed in their writings. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Pan, J.
AU  - Wang, S.
AU  - Bai, J.
AU  - Dai, J.
TI  - Diverse Dance Synthesis via Keyframes with Transformer Controllers
PY  - 2021
T2  - Computer Graphics Forum
VL  - 40
IS  - 7
SP  - 71
EP  - 83
DO  - 10.1111/cgf.14402
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119993447&doi=10.1111%2fcgf.14402&partnerID=40&md5=f23ef6d79c93b8cf245a6c00ae76d8dc
AB  - Existing keyframe-based motion synthesis mainly focuses on the generation of cyclic actions or short-term motion, such as walking, running, and transitions between close postures. However, these methods will significantly degrade the naturalness and diversity of the synthesized motion when dealing with complex and impromptu movements, e.g., dance performance and martial arts. In addition, current research lacks fine-grained control over the generated motion, which is essential for intelligent human-computer interaction and animation creation. In this paper, we propose a novel keyframe-based motion generation network based on multiple constraints, which can achieve diverse dance synthesis via learned knowledge. Specifically, the algorithm is mainly formulated based on the recurrent neural network (RNN) and the Transformer architecture. The backbone of our network is a hierarchical RNN module composed of two long short-term memory (LSTM) units, in which the first LSTM is utilized to embed the posture information of the historical frames into a latent space, and the second one is employed to predict the human posture for the next frame. Moreover, our framework contains two Transformer-based controllers, which are used to model the constraints of the root trajectory and the velocity factor respectively, so as to better utilize the temporal context of the frames and achieve fine-grained motion control. We verify the proposed approach on a dance dataset containing a wide range of contemporary dance. The results of three quantitative analyses validate the superiority of our algorithm. The video and qualitative experimental results demonstrate that the complex motion sequences generated by our algorithm can achieve diverse and smooth motion transitions between keyframes, even for long-term synthesis. © 2021 The Author(s) Computer Graphics Forum © 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 5
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Le, N.Q.K.
AU  - Ho, Q.-T.
AU  - Nguyen, T.-T.-D.
AU  - Ou, Y.-Y.
TI  - A transformer architecture based on BERT and 2D convolutional neural network to identify DNA enhancers from sequence information
PY  - 2021
T2  - Briefings in Bioinformatics
VL  - 22
IS  - 5
C7  - bbab005
DO  - 10.1093/bib/bbab005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102657808&doi=10.1093%2fbib%2fbbab005&partnerID=40&md5=35bdaeb9eff0777ae2b29b9bebd2500b
AB  - Recently, language representation models have drawn a lot of attention in the natural language processing field due to their remarkable results. Among them, bidirectional encoder representations from transformers (BERT) has proven to be a simple, yet powerful language model that achieved novel state-of-The-Art performance. BERT adopted the concept of contextualized word embedding to capture the semantics and context of the words in which they appeared. In this study, we present a novel technique by incorporating BERT-based multilingual model in bioinformatics to represent the information of DNA sequences. We treated DNA sequences as natural sentences and then used BERT models to transform them into fixed-length numerical matrices. As a case study, we applied our method to DNA enhancer prediction, which is a well-known and challenging problem in this field. We then observed that our BERT-based features improved more than 5-10% in terms of sensitivity, specificity, accuracy and Matthews correlation coefficient compared to the current state-of-The-Art features in bioinformatics. Moreover, advanced experiments show that deep learning (as represented by 2D convolutional neural networks; CNN) holds potential in learning BERT features better than other traditional machine learning techniques. In conclusion, we suggest that BERT and 2D CNNs could open a new avenue in biological modeling using sequence information.  © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 119
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ayoub, J.
AU  - Yang, X.J.
AU  - Zhou, F.
TI  - Combat COVID-19 infodemic using explainable natural language processing models
PY  - 2021
T2  - Information Processing and Management
VL  - 58
IS  - 4
C7  - 102569
DO  - 10.1016/j.ipm.2021.102569
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102851698&doi=10.1016%2fj.ipm.2021.102569&partnerID=40&md5=947a43e0ab4d3fcfbca3b0d3245f8461
AB  - Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high. Thus, it is critical to detect and combat such misinformation. Recently, deep learning models using natural language processing techniques, such as BERT (Bidirectional Encoder Representations from Transformers), have achieved great successes in detecting misinformation. In this paper, we proposed an explainable natural language processing model based on DistilBERT and SHAP (Shapley Additive exPlanations) to combat misinformation about COVID-19 due to their efficiency and effectiveness. First, we collected a dataset of 984 claims about COVID-19 with fact-checking. By augmenting the data using back-translation, we doubled the sample size of the dataset and the DistilBERT model was able to obtain good performance (accuracy: 0.972; areas under the curve: 0.993) in detecting misinformation about COVID-19. Our model was also tested on a larger dataset for AAAI2021 — COVID-19 Fake News Detection Shared Task and obtained good performance (accuracy: 0.938; areas under the curve: 0.985). The performance on both datasets was better than traditional machine learning models. Second, in order to boost public trust in model prediction, we employed SHAP to improve model explainability, which was further evaluated using a between-subjects experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE). The participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition. Our results provided good implications for detecting misinformation about COVID-19 and improving public trust. © 2021 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 101
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Sawhney, R.
AU  - Joshi, H.
AU  - Gandhi, S.
AU  - Jin, D.
AU  - Shah, R.R.
TI  - Robust suicide risk assessment on social media via deep adversarial learning
PY  - 2021
T2  - Journal of the American Medical Informatics Association
VL  - 28
IS  - 7
SP  - 1497
EP  - 1506
DO  - 10.1093/jamia/ocab031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112125142&doi=10.1093%2fjamia%2focab031&partnerID=40&md5=a86e54d7607b8112c0fcc06fa868c0ef
AB  - Objective: The prevalence of social media for sharing personal thoughts makes it a viable platform for the assessment of suicide risk. However, deep learning models are not able to capture the diverse nature of linguistic choices and temporal patterns that can be exhibited by a suicidal user on social media and end up overfitting on specific cues that are not generally applicable. We propose Adversarial Suicide assessment Hierarchical Attention (ASHA), a hierarchical attention model that employs adversarial learning for improving the generalization ability of the model. Material and Methods: We assess the suicide risk of a social media user across 5 levels of increasing severity of risk. ASHA leverages a transformer-based architecture to learn the semantic nature of social media posts and a temporal attention-based long short-term memory architecture for the sequential modeling of a user's historical posts. We dynamically generate adversarial examples by adding perturbations to actual examples that can simulate the stochasticity in historical posts, thereby making the model robust. Results: Through extensive experiments, we establish the face-value of ASHA and show that it significantly outperforms existing baselines, with the F1 score of 64%. This is a 2% and a 4% increase over the ContextBERT and ContextCNN baselines, respectively. Finally, we discuss the practical applicability and ethical aspects of our work pertaining to ASHA, as a human-in-the-loop framework. Discussion and Conclusions: Adversarial samples can be helpful in capturing the diverse nature of suicidal ideation. Through ASHA, we hope to form a component in a larger human-in-the-loop infrastructure for suicide risk assessment on social media. © 2021 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Han, F.
AU  - Wang, C.
AU  - Du, H.
AU  - Liao, J.
TI  - Deep Portrait Lighting Enhancement with 3D Guidance
PY  - 2021
T2  - Computer Graphics Forum
VL  - 40
IS  - 4
SP  - 177
EP  - 188
DO  - 10.1111/cgf.14350
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109830472&doi=10.1111%2fcgf.14350&partnerID=40&md5=a2efc22fcdda2b446e699338fe61afdc
AB  - Despite recent breakthroughs in deep learning methods for image lighting enhancement, they are inferior when applied to portraits because 3D facial information is ignored in their models. To address this, we present a novel deep learning framework for portrait lighting enhancement based on 3D facial guidance. Our framework consists of two stages. In the first stage, corrected lighting parameters are predicted by a network from the input bad lighting image, with the assistance of a 3D morphable model and a differentiable renderer. Given the predicted lighting parameter, the differentiable renderer renders a face image with corrected shading and texture, which serves as the 3D guidance for learning image lighting enhancement in the second stage. To better exploit the long-range correlations between the input and the guidance, in the second stage, we design an image-to-image translation network with a novel transformer architecture, which automatically produces a lighting-enhanced result. Experimental results on the FFHQ dataset and in-the-wild images show that the proposed method outperforms state-of-the-art methods in terms of both quantitative metrics and visual quality. © 2021 The Author(s) Computer Graphics Forum © 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Zainab, K.
AU  - Srivastava, G.
AU  - Mago, V.
TI  - Identifying health related occupations of Twitter users through word embedding and deep neural networks
PY  - 2021
T2  - BMC Bioinformatics
VL  - 22
C7  - 630
DO  - 10.1186/s12859-022-04933-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138973298&doi=10.1186%2fs12859-022-04933-2&partnerID=40&md5=f7405edf2b09c3ab038afb95114e3c8a
AB  - Background: Twitter is a popular social networking site where short messages or “tweets” of users have been used extensively for research purposes. However, not much research has been done in mining the medical professions, such as detecting the occupations of users from their biographical contents. Mining such professions can be used to build efficient recommender systems for cost-effective targeted advertisements. Moreover, it is highly important to develop effective methods to identify the occupation of users since conventional classification methods rely on features developed by human intelligence. Although, the result may be favorable for the classification problem. However, it is still extremely challenging for traditional classifiers to predict the medical occupations accurately since it involves predicting multiple occupations. Hence this study emphasizes predicting the medical occupational class of users through their public biographical (“Bio”) content. We have conducted our analysis by annotating the bio content of Twitter users. In this paper, we propose a method of combining word embedding with state-of-art neural network models that include: Long Short Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit, Bidirectional Encoder Representations from Transformers, and A lite BERT. Moreover, we have also observed that by composing the word embedding with the neural network models there is no need to construct any particular attribute or feature. By using word embedding, the bio contents are formatted as dense vectors which are fed as input into the neural network models as a sequence of vectors. Result: Performance metrics that include accuracy, precision, recall, and F1-score have shown a significant difference between our method of combining word embedding with neural network models than with the traditional methods. The scores have proved that our proposed approach has outperformed the traditional machine learning techniques for detecting medical occupations among users. ALBERT has performed the best among the deep learning networks with an F1 score of 0.90. Conclusion: In this study, we have presented a novel method of detecting the occupations of Twitter users engaged in the medical domain by merging word embedding with state-of-art neural networks. The outcomes of our approach have demonstrated that our method can further advance the process of analyzing corpora of social media without going through the trouble of developing computationally expensive features. © 2022, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 2
C2  - CCF:C期刊; ZUFE:1A; 
LB  - Zainab2021Identifying
ER  -

TY  - JOUR
AU  - Lee, W.
AU  - Shi, Y.
AU  - Sun, H.
AU  - Cheng, L.
AU  - Zhang, K.
AU  - Wang, X.
AU  - Chen, Z.
TI  - MSIPA: Multi-Scale Interval Pattern-Aware Network for ICU Transfer Prediction
PY  - 2021
T2  - ACM Transactions on Knowledge Discovery from Data
VL  - 16
IS  - 1
C7  - 3458284
DO  - 10.1145/3458284
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111168496&doi=10.1145%2f3458284&partnerID=40&md5=6f83d0754be368697289639223ab8dc9
AB  - Accurate prediction of patients' ICU transfer events is of great significance for improving ICU treatment efficiency. ICU transition prediction task based on Electronic Health Records (EHR) is a temporal mining task like many other health informatics mining tasks. In the EHR-based temporal mining task, existing approaches are usually unable to mine and exploit patterns used to improve model performance. This article proposes a network based on Interval Pattern-Aware, Multi-Scale Interval Pattern-Aware (MSIPA) network. MSIPA mines different interval patterns in temporal EHR data according to the short, medium, and long intervals. MSIPA utilizes the Scaled Dot-Product Attention mechanism to query the contexts corresponding to the three scale patterns. Furthermore, Transformer will use all three types of contextual information simultaneously for ICU transfer prediction. Extensive experiments on real-world data demonstrate that an MSIPA network outperforms state-of-The-Art methods. © 2021 Association for Computing Machinery.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - CCF:B期刊; FMS:B; 
LB  - Lee2021MSIPA
ER  -

TY  - JOUR
AU  - Yogatama, D.
AU  - D’autume, C.M.
AU  - Kong, L.
TI  - Adaptive semiparametric language models
PY  - 2021
T2  - Transactions of the Association for Computational Linguistics
VL  - 9
SP  - 362
EP  - 373
DO  - 10.1162/tacl_a_00371
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101804387&doi=10.1162%2ftacl_a_00371&partnerID=40&md5=aba13515a8f06b59fe4b6331fc5d4965
AB  - We present a language model that combines a large parametric neural network (i.e., a transformer) with a non-parametric episodic memory component in an integrated architecture. Our model uses extended short-term context by caching local hidden states—similar to transformer-XL—and global long-term memory by retrieving a set of nearest neighbor tokens at each timestep. We design a gating function to adaptively combine multiple information sources to make a prediction. This mechanism allows the model to use either local context, short-term memory, or long-term memory (or any combination of them) on an ad hoc basis depending on the context. Experiments on word-based and character-based language modeling datasets demonstrate the efficacy of our proposed method compared to strong baselines. © 2021, MIT Press Journals. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 60
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, K.
AU  - Xiao, C.
AU  - Glass, L.M.
AU  - Sun, J.
TI  - MolTrans: Molecular Interaction Transformer for drug-target interaction prediction
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 6
SP  - 830
EP  - 836
DO  - 10.1093/bioinformatics/btaa880
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106068794&doi=10.1093%2fbioinformatics%2fbtaa880&partnerID=40&md5=728addce4d602405fd8448d2c355d81c
AB  - Motivation: Drug-target interaction (DTI) prediction is a foundational task for in-silico drug discovery, which is costly and time-consuming due to the need of experimental search over large drug compound space. Recent years have witnessed promising progress for deep learning in DTI predictions. However, the following challenges are still open: (i) existing molecular representation learning approaches ignore the sub-structural nature of DTI, thus produce results that are less accurate and difficult to explain and (ii) existing methods focus on limited labeled data while ignoring the value of massive unlabeled molecular data. Results: We propose a Molecular Interaction Transformer (MolTrans) to address these limitations via: (i) knowledge inspired sub-structural pattern mining algorithm and interaction modeling module for more accurate and interpretable DTI prediction and (ii) an augmented transformer encoder to better extract and capture the semantic relations among sub-structures extracted from massive unlabeled biomedical data. We evaluate MolTrans on real-world data and show it improved DTI prediction performance compared to state-of-the-art baselines. © 2020 The Author(s) 2020. Published by Oxford University Press.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 252
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, Q.
AU  - Xie, L.
TI  - TranSynergy: Mechanism-driven interpretable deep neural network for the synergistic prediction and pathway deconvolution of drug combinations
PY  - 2021
T2  - PLoS Computational Biology
VL  - 17
IS  - 2
C7  - e1008653
DO  - 10.1371/JOURNAL.PCBI.1008653
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102394442&doi=10.1371%2fJOURNAL.PCBI.1008653&partnerID=40&md5=91bb65b1f428f400419d123ec3227ee2
AB  - Drug combinations have demonstrated great potential in cancer treatments. They alleviate drug resistance and improve therapeutic efficacy. The fast-growing number of anti-cancer drugs has caused the experimental investigation of all drug combinations to become costly and time-consuming. Computational techniques can improve the efficiency of drug combination screening. Despite recent advances in applying machine learning to synergistic drug combination prediction, several challenges remain. First, the performance of existing methods is suboptimal. There is still much space for improvement. Second, biological knowledge has not been fully incorporated into the model. Finally, many models are lack interpretability, limiting their clinical applications. To address these challenges, we have developed a knowledge-enabled and self-attention transformer boosted deep learning model, TranSynergy, which improves the performance and interpretability of synergistic drug combination prediction. TranSynergy is designed so that the cellular effect of drug actions can be explicitly modeled through cell-line gene dependency, gene-gene interaction, and genome-wide drug-target interaction. A novel Shapley Additive Gene Set Enrichment Analysis (SA-GSEA) method has been developed to deconvolute genes that contribute to the synergistic drug combination and improve model interpretability. Extensive benchmark studies demonstrate that TranSynergy outperforms the state-of-the-art method, suggesting the potential of mechanism-driven machine learning. Novel pathways that are associated with the synergistic combinations are revealed and supported by experimental evidences. They may provide new insights into identifying biomarkers for precision medicine and discovering new anticancer therapies. Several new synergistic drug combinations have been predicted with high confidence for ovarian cancer which has few treatment options. The code is available at https://github.com/qiaoliuhub/drug_combination. Copyright: © 2021 Liu, Xie. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 94
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Sun, J.
AU  - Wang, S.
AU  - Zhang, J.
AU  - Zong, C.
TI  - Neural Encoding and Decoding with Distributed Sentence Representations
PY  - 2021
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 32
IS  - 2
C7  - 9223750
SP  - 589
EP  - 603
DO  - 10.1109/TNNLS.2020.3027595
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092892485&doi=10.1109%2fTNNLS.2020.3027595&partnerID=40&md5=766814997d203acf3487b6a7a3fcf492
AB  - Building computational models to account for the cortical representation of language plays an important role in understanding the human linguistic system. Recent progress in distributed semantic models (DSMs), especially transformer-based methods, has driven advances in many language understanding tasks, making DSM a promising methodology to probe brain language processing. DSMs have been shown to reliably explain cortical responses to word stimuli. However, characterizing the brain activities for sentence processing is much less exhaustively explored with DSMs, especially the deep neural network-based methods. What is the relationship between cortical sentence representations against DSMs? What linguistic features that a DSM catches better explain its correlation with the brain activities aroused by sentence stimuli? Could distributed sentence representations help to reveal the semantic selectivity of different brain areas? We address these questions through the lens of neural encoding and decoding, fueled by the latest developments in natural language representation learning. We begin by evaluating the ability of a wide range of 12 DSMs to predict and decipher the functional magnetic resonance imaging (fMRI) images from humans reading sentences. Most models deliver high accuracy in the left middle temporal gyrus (LMTG) and left occipital complex (LOC). Notably, encoders trained with transformer-based DSMs consistently outperform other unsupervised structured models and all the unstructured baselines. With probing and ablation tasks, we further find that differences in the performance of the DSMs in modeling brain activities can be at least partially explained by the granularity of their semantic representations. We also illustrate the DSM's selectivity for concept categories and show that the topics are represented by spatially overlapping and distributed cortical patterns. Our results corroborate and extend previous findings in understanding the relation between DSMs and neural activation patterns and contribute to building solid brain-machine interfaces with deep neural network representations.  © 2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - You, R.
AU  - Liu, Y.
AU  - Mamitsuka, H.
AU  - Zhu, S.
TI  - BERTMeSH: Deep contextual representation learning for large-scale high-performance MeSH indexing with full text
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 5
SP  - 684
EP  - 692
DO  - 10.1093/bioinformatics/btaa837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097784994&doi=10.1093%2fbioinformatics%2fbtaa837&partnerID=40&md5=e6077307706052b76acf66df747a5b22
AB  - Motivation: With the rapid increase of biomedical articles, large-scale automatic Medical Subject Headings (MeSH) indexing has become increasingly important. FullMeSH, the only method for large-scale MeSH indexing with full text, suffers from three major drawbacks: FullMeSH (i) uses Learning To Rank, which is time-consuming, (ii) can capture some pre-defined sections only in full text and (iii) ignores the whole MEDLINE database. Results: We propose a computationally lighter, full text and deep-learning-based MeSH indexing method, BERTMeSH, which is flexible for section organization in full text. BERTMeSH has two technologies: (i) the state-of-the-art pre-trained deep contextual representation, Bidirectional Encoder Representations from Transformers (BERT), which makes BERTMeSH capture deep semantics of full text. (ii) A transfer learning strategy for using both full text in PubMed Central (PMC) and title and abstract (only and no full text) in MEDLINE, to take advantages of both. In our experiments, BERTMeSH was pre-trained with 3 million MEDLINE citations and trained on ∼1.5 million full texts in PMC. BERTMeSH outperformed various cutting-edge baselines. For example, for 20 K test articles of PMC, BERTMeSH achieved a Micro F-measure of 69.2%, which was 6.3% higher than FullMeSH with the difference being statistically significant. Also prediction of 20 K test articles needed 5 min by BERTMeSH, while it took more than 10 h by FullMeSH, proving the computational efficiency of BERTMeSH.  © 2020 The Author(s) 2020. Published by Oxford University Press. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 27
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Warikoo, N.
AU  - Chang, Y.-C.
AU  - Hsu, W.-L.
TI  - LBERT: Lexically aware Transformer-based Bidirectional Encoder Representation model for learning universal bio-entity relations
PY  - 2021
T2  - Bioinformatics
VL  - 37
IS  - 3
SP  - 404
EP  - 412
DO  - 10.1093/bioinformatics/btaa721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105695026&doi=10.1093%2fbioinformatics%2fbtaa721&partnerID=40&md5=8861d7643a5833f5f7e892a5b8a8077d
AB  - Motivation: Natural Language Processing techniques are constantly being advanced to accommodate the influx of data as well as to provide exhaustive and structured knowledge dissemination. Within the biomedical domain, relation detection between bio-entities known as the Bio-Entity Relation Extraction (BRE) task has a critical function in knowledge structuring. Although recent advances in deep learning-based biomedical domain embedding have improved BRE predictive analytics, these works are often task selective or use external knowledge-based pre-/post-processing. In addition, deep learning-based models do not account for local syntactic contexts, which have improved data representation in many kernel classifier-based models. In this study, we propose a universal BRE model, i.e. LBERT, which is a Lexically aware Transformer-based Bidirectional Encoder Representation model, and which explores both local and global contexts representations for sentence-level classification tasks. Results: This article presents one of the most exhaustive BRE studies ever conducted over five different bio-entity relation types. Our model outperforms state-of-the-art deep learning models in protein-protein interaction (PPI), drug-drug interaction and protein-bio-entity relation classification tasks by 0.02%, 11.2% and 41.4%, respectively. LBERT representations show a statistically significant improvement over BioBERT in detecting true bio-entity relation for large corpora like PPI. Our ablation studies clearly indicate the contribution of the lexical features and distance-adjusted attention in improving prediction performance by learning additional local semantic context along with bi-directionally learned global context.  © 2020 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Tetko, I.V.
AU  - Karpov, P.
AU  - Van Deursen, R.
AU  - Godin, G.
TI  - State-of-the-art augmented NLP transformer models for direct and single-step retrosynthesis
PY  - 2020
T2  - Nature Communications
VL  - 11
IS  - 1
C7  - 5575
DO  - 10.1038/s41467-020-19266-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094958315&doi=10.1038%2fs41467-020-19266-y&partnerID=40&md5=64b1504cb0a28b6395d5327a68eafe72
AB  - We investigated the effect of different training scenarios on predicting the (retro)synthesis of chemical compounds using text-like representation of chemical reactions (SMILES) and Natural Language Processing (NLP) neural network Transformer architecture. We showed that data augmentation, which is a powerful method used in image processing, eliminated the effect of data memorization by neural networks and improved their performance for prediction of new sequences. This effect was observed when augmentation was used simultaneously for input and the target data simultaneously. The top-5 accuracy was 84.8% for the prediction of the largest fragment (thus identifying principal transformation for classical retro-synthesis) for the USPTO-50k test dataset, and was achieved by a combination of SMILES augmentation and a beam search algorithm. The same approach provided significantly better results for the prediction of direct reactions from the single-step USPTO-MIT test set. Our model achieved 90.6% top-1 and 96.1% top-5 accuracy for its challenging mixed set and 97% top-5 accuracy for the USPTO-MIT separated set. It also significantly improved results for USPTO-full set single-step retrosynthesis for both top-1 and top-10 accuracies. The appearance frequency of the most abundantly generated SMILES was well correlated with the prediction outcome and can be used as a measure of the quality of reaction prediction. © 2020, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 228
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Jiang, D.
AU  - Sahli, H.
TI  - Transformer Encoder with Multi-Modal Multi-Head Attention for Continuous Affect Recognition
PY  - 2021
T2  - IEEE Transactions on Multimedia
VL  - 23
SP  - 4171
EP  - 4183
DO  - 10.1109/TMM.2020.3037496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098799979&doi=10.1109%2fTMM.2020.3037496&partnerID=40&md5=70e54a2896964d94ad131ebdf94cd42e
AB  - Continuous affect recognition is becoming an increasingly attractive research topic in affective computing. Previous works mainly focused on modelling the temporal dependency within a sensor modality, or adopting early or late fusion for multi-modal affective state recognition. However, early fusion suffers from the curse of dimensionality, and late fusion ignores the complementarity and redundancy between multiple modal streams. In this paper, we first introduce the transformer-encoder with a self-attention mechanism and propose a Convolutional Neural Network-Transformer Encoder (CNN-TE) framework to model the temporal dependency for single modal affect recognition. Further, to effectively consider the complementarity and redundancy between multiple streams we propose a Transformer Encoder with Multi-modal Multi-head Attention (TEMMA) for multi-modal affect recognition. TEMMA allows to progressively and simultaneously refine the inter-modality interactions and intra-modality temporal dependency. The learned multi-modal representations are fed to an Inference Sub-network with fully connected layers to estimate the affective state. The proposed framework is trained in a nutshell and demonstrates its effectiveness on the AVEC2016 and AVEC2019 datasets. Compared to state-of-the-art models, our approach obtains remarkable improvements on both arousal and valence in terms of concordance correlation coefficient (CCC) reaching 0.583 for arousal and 0.564 for valence on the AVEC2019 test set. © 1999-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 66
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Pesciullesi, G.
AU  - Schwaller, P.
AU  - Laino, T.
AU  - Reymond, J.-L.
TI  - Transfer learning enables the molecular transformer to predict regio- and stereoselective reactions on carbohydrates
PY  - 2020
T2  - Nature Communications
VL  - 11
IS  - 1
C7  - 4874
DO  - 10.1038/s41467-020-18671-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091589871&doi=10.1038%2fs41467-020-18671-7&partnerID=40&md5=80e95263ae41d6ba34ac33c357d5849c
AB  - Organic synthesis methodology enables the synthesis of complex molecules and materials used in all fields of science and technology and represents a vast body of accumulated knowledge optimally suited for deep learning. While most organic reactions involve distinct functional groups and can readily be learned by deep learning models and chemists alike, regio- and stereoselective transformations are more challenging because their outcome also depends on functional group surroundings. Here, we challenge the Molecular Transformer model to predict reactions on carbohydrates where regio- and stereoselectivity are notoriously difficult to predict. We show that transfer learning of the general patent reaction model with a small set of carbohydrate reactions produces a specialized model returning predictions for carbohydrate reactions with remarkable accuracy. We validate these predictions experimentally with the synthesis of a lipid-linked oligosaccharide involving regioselective protections and stereoselective glycosylations. The transfer learning approach should be applicable to any reaction class of interest. © 2020, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 108
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Peng, W.
AU  - Yu, S.
AU  - Handler, A.M.
AU  - Tu, Z.
AU  - Saccone, G.
AU  - Xi, Z.
AU  - Zhang, H.
TI  - miRNA-1-3p is an early embryonic male sex-determining factor in the Oriental fruit fly Bactrocera dorsalis
PY  - 2020
T2  - Nature Communications
VL  - 11
IS  - 1
C7  - 932
DO  - 10.1038/s41467-020-14622-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079778806&doi=10.1038%2fs41467-020-14622-4&partnerID=40&md5=e3dfd0d27b33e0dd37481ccae8932db7
AB  - Regulation of male sexual differentiation by a Y chromosome-linked male determining factor (M-factor) is one of a diverse array of sex determination mechanisms found in insects. By deep sequencing of small RNAs from Bactrocera dorsalis early embryos, we identified an autosomal-derived microRNA, miR-1-3p, that has predicted target sites in the transformer gene (Bdtra) required for female sex determination. We further demonstrate by both in vitro and in vivo tests that miR-1-3p suppresses Bdtra expression. Injection of a miR-1-3p mimic in early embryos results in 87–92% phenotypic males, whereas knockdown of miR-1-3p by an inhibitor results in 67–77% phenotypic females. Finally, CRISPR/Cas9-mediated knockout of miR-1-3p results in the expression of female-specific splice variants of Bdtra and doublesex (Bddsx), and induced sex reversal of XY individuals into phenotypic females. These results indicate that miR-1-3p is required for male sex determination in early embryogenesis in B. dorsalis as an intermediate male determiner. © 2020, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 42
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Vaucher, A.C.
AU  - Zipoli, F.
AU  - Geluykens, J.
AU  - Nair, V.H.
AU  - Schwaller, P.
AU  - Laino, T.
TI  - Automated extraction of chemical synthesis actions from experimental procedures
PY  - 2020
T2  - Nature Communications
VL  - 11
IS  - 1
C7  - 3601
DO  - 10.1038/s41467-020-17266-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088152489&doi=10.1038%2fs41467-020-17266-6&partnerID=40&md5=5c94207c883248ebe1fea8e357ba337c
AB  - Experimental procedures for chemical synthesis are commonly reported in prose in patents or in the scientific literature. The extraction of the details necessary to reproduce and validate a synthesis in a chemical laboratory is often a tedious task requiring extensive human intervention. We present a method to convert unstructured experimental procedures written in English to structured synthetic steps (action sequences) reflecting all the operations needed to successfully conduct the corresponding chemical reactions. To achieve this, we design a set of synthesis actions with predefined properties and a deep-learning sequence to sequence model based on the transformer architecture to convert experimental procedures to action sequences. The model is pretrained on vast amounts of data generated automatically with a custom rule-based natural language processing approach and refined on manually annotated samples. Predictions on our test set result in a perfect (100%) match of the action sequence for 60.8% of sentences, a 90% match for 71.3% of sentences, and a 75% match for 82.4% of sentences. © 2020, The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 119
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Roy, S.
AU  - Menapace, W.
AU  - Oei, S.
AU  - Luijten, B.
AU  - Fini, E.
AU  - Saltori, C.
AU  - Huijben, I.
AU  - Chennakeshava, N.
AU  - Mento, F.
AU  - Sentelli, A.
AU  - Peschiera, E.
AU  - Trevisan, R.
AU  - Maschietto, G.
AU  - Torri, E.
AU  - Inchingolo, R.
AU  - Smargiassi, A.
AU  - Soldati, G.
AU  - Rota, P.
AU  - Passerini, A.
AU  - Van Sloun, R.J.G.
AU  - Ricci, E.
AU  - Demi, L.
TI  - Deep Learning for Classification and Localization of COVID-19 Markers in Point-of-Care Lung Ultrasound
PY  - 2020
T2  - IEEE Transactions on Medical Imaging
VL  - 39
IS  - 8
C7  - 9093068
SP  - 2676
EP  - 2687
DO  - 10.1109/TMI.2020.2994459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087653114&doi=10.1109%2fTMI.2020.2994459&partnerID=40&md5=ec353d97c074ec004c953108c02345b0
AB  - Deep learning (DL) has proved successful in medical imaging and, in the wake of the recent COVID-19 pandemic, some works have started to investigate DL-based solutions for the assisted diagnosis of lung diseases. While existing works focus on CT scans, this paper studies the application of DL techniques for the analysis of lung ultrasonography (LUS) images. Specifically, we present a novel fully-annotated dataset of LUS images collected from several Italian hospitals, with labels indicating the degree of disease severity at a frame-level, video-level, and pixel-level (segmentation masks). Leveraging these data, we introduce several deep models that address relevant tasks for the automatic analysis of LUS images. In particular, we present a novel deep network, derived from Spatial Transformer Networks, which simultaneously predicts the disease severity score associated to a input frame and provides localization of pathological artefacts in a weakly-supervised way. Furthermore, we introduce a new method based on uninorms for effective frame score aggregation at a video-level. Finally, we benchmark state of the art deep models for estimating pixel-level segmentations of COVID-19 imaging biomarkers. Experiments on the proposed dataset demonstrate satisfactory results on all the considered tasks, paving the way to future research on DL for the assisted diagnosis of COVID-19 from LUS data. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 460
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, G.
AU  - Wang, Q.
AU  - Ma, J.
TI  - OPUS-TASS: A protein backbone torsion angles and secondary structure predictor based on ensemble neural networks
PY  - 2020
T2  - Bioinformatics
VL  - 36
IS  - 20
SP  - 5021
EP  - 5026
DO  - 10.1093/bioinformatics/btaa629
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095734031&doi=10.1093%2fbioinformatics%2fbtaa629&partnerID=40&md5=5fc973ade92eb0ecae74d2c30ed92546
AB  - Motivation: Predictions of protein backbone torsion angles (φ and ψ) and secondary structure from sequence are crucial subproblems in protein structure prediction. With the development of deep learning approaches, their accuracies have been significantly improved. To capture the long-range interactions, most studies integrate bidirectional recurrent neural networks into their models. In this study, we introduce and modify a recently proposed architecture named Transformer to capture the interactions between the two residues theoretically with arbitrary distance. Moreover, we take advantage of multitask learning to improve the generalization of neural network by introducing related tasks into the training process. Similar to many previous studies, OPUS-TASS uses an ensemble of models and achieves better results. Results: OPUS-TASS uses the same training and validation sets as SPOT-1D. We compare the performance of OPUS-TASS and SPOT-1D on TEST2016 (1213 proteins) and TEST2018 (250 proteins) proposed in the SPOT-1D paper, CASP12 (55 proteins), CASP13 (32 proteins) and CASP-FM (56 proteins) proposed in the SAINT paper, and a recently released PDB structure collection from CAMEO (93 proteins) named as CAMEO93. On these six test sets, OPUS-TASS achieves consistent improvements in both backbone torsion angles prediction and secondary structure prediction. On CAMEO93, SPOT-1D achieves the mean absolute errors of 16.89 and 23.02 for φ and ψ predictions, respectively, and the accuracies for 3- and 8-state secondary structure predictions are 87.72 and 77.15%, respectively. In comparison, OPUS-TASS achieves 16.56 and 22.56 for φ and ψ predictions, and 89.06 and 78.87% for 3- and 8-state secondary structure predictions, respectively. In particular, after using our torsion angles refinement method OPUS-Refine as the post-processing procedure for OPUS-TASS, the mean absolute errors for final φ and ψ predictions are further decreased to 16.28 and 21.98, respectively. © 2020 The Author(s).
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 41
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Fish, N.
AU  - Zhang, R.
AU  - Perry, L.
AU  - Cohen-Or, D.
AU  - Shechtman, E.
AU  - Barnes, C.
TI  - Image Morphing With Perceptual Constraints and STN Alignment
PY  - 2020
T2  - Computer Graphics Forum
VL  - 39
IS  - 6
SP  - 303
EP  - 313
DO  - 10.1111/cgf.14027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085697531&doi=10.1111%2fcgf.14027&partnerID=40&md5=ec07f553493a64a17a45232f086c2000
AB  - In image morphing, a sequence of plausible frames are synthesized and composited together to form a smooth transformation between given instances. Intermediates must remain faithful to the input, stand on their own as members of the set and maintain a well-paced visual transition from one to the next. In this paper, we propose a conditional generative adversarial network (GAN) morphing framework operating on a pair of input images. The network is trained to synthesize frames corresponding to temporal samples along the transformation, and learns a proper shape prior that enhances the plausibility of intermediate frames. While individual frame plausibility is boosted by the adversarial setup, a special training protocol producing sequences of frames, combined with a perceptual similarity loss, promote smooth transformation over time. Explicit stating of correspondences is replaced with a grid-based freeform deformation spatial transformer that predicts the geometric warp between the inputs, instituting the smooth geometric effect by bringing the shapes into an initial alignment. We provide comparisons to classic as well as latent space morphing techniques, and demonstrate that, given a set of images for self-supervision, our network learns to generate visually pleasing morphing effects featuring believable in-betweens, with robustness to changes in shape and texture, requiring no correspondence annotation. © 2020 The Authors Computer Graphics Forum © 2020 Eurographics - The European Association for Computer Graphics and John Wiley & Sons Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Xu, D.
AU  - Gopale, M.
AU  - Zhang, J.
AU  - Brown, K.
AU  - Begoli, E.
AU  - Bethard, S.
TI  - Unified medical language system resources improve sieve-based generation and bidirectional encoder representations from transformers (BERT)–based ranking for concept normalization
PY  - 2020
T2  - Journal of the American Medical Informatics Association
VL  - 27
IS  - 10
SP  - 1510
EP  - 1519
DO  - 10.1093/jamia/ocaa080
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093539184&doi=10.1093%2fjamia%2focaa080&partnerID=40&md5=7cc010fce56a2c58d56bb8618925a383
AB  - Objective: Concept normalization, the task of linking phrases in text to concepts in an ontology, is useful for many downstream tasks including relation extraction, information retrieval, etc. We present a generate-and-rank concept normalization system based on our participation in the 2019 National NLP Clinical Challenges Shared Task Track 3 Concept Normalization. Materials and Methods: The shared task provided 13 609 concept mentions drawn from 100 discharge summaries. We first design a sieve-based system that uses Lucene indices over the training data, Unified Medical Language System (UMLS) preferred terms, and UMLS synonyms to generate a list of possible concepts for each mention. We then design a listwise classifier based on the BERT (Bidirectional Encoder Representations from Transformers) neural network to rank the candidate concepts, integrating UMLS semantic types through a regularizer. Results: Our generate-and-rank system was third of 33 in the competition, outperforming the candidate generator alone (81.66% vs 79.44%) and the previous state of the art (76.35%). During postevaluation, the model’s accuracy was increased to 83.56% via improvements to how training data are generated from UMLS and incorporation of our UMLS semantic type regularizer. Discussion: Analysis of the model shows that prioritizing UMLS preferred terms yields better performance, that the UMLS semantic type regularizer results in qualitatively better concept predictions, and that the model performs well even on concepts not seen during training. Conclusions: Our generate-and-rank framework for UMLS concept normalization integrates key UMLS features like preferred terms and semantic types with a neural network–based ranking model to accurately link phrases in text to UMLS concepts. © The Author(s) 2020.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 15
C2  - CCF:B期刊; FMS:C; 
ER  -

TY  - JOUR
AU  - Chen, L.
AU  - Tan, X.
AU  - Wang, D.
AU  - Zhong, F.
AU  - Liu, X.
AU  - Yang, T.
AU  - Luo, X.
AU  - Chen, K.
AU  - Jiang, H.
AU  - Zheng, M.
TI  - TransformerCPI: Improving compound-protein interaction prediction by sequence-based deep learning with self-attention mechanism and label reversal experiments
PY  - 2020
T2  - Bioinformatics
VL  - 36
IS  - 16
SP  - 4406
EP  - 4414
DO  - 10.1093/bioinformatics/btaa524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094222071&doi=10.1093%2fbioinformatics%2fbtaa524&partnerID=40&md5=54080bbe1c0384489150e96505a0e5fb
AB  - Motivation: Identifying compound-protein interaction (CPI) is a crucial task in drug discovery and chemogenomics studies, and proteins without three-dimensional structure account for a large part of potential biological targets, which requires developing methods using only protein sequence information to predict CPI. However, sequence-based CPI models may face some specific pitfalls, including using inappropriate datasets, hidden ligand bias and splitting datasets inappropriately, resulting in overestimation of their prediction performance. Results: To address these issues, we here constructed new datasets specific for CPI prediction, proposed a novel transformer neural network named TransformerCPI, and introduced a more rigorous label reversal experiment to test whether a model learns true interaction features. TransformerCPI achieved much improved performance on the new experiments, and it can be deconvolved to highlight important interacting regions of protein sequences and compound atoms, which may contribute chemical biology studies with useful guidance for further ligand structural optimization. © 2020 The Author(s) 2020. Published by Oxford University Press. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 260
C2  - CCF:B期刊; ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Liu, Y.
AU  - Yuan, H.
AU  - Wang, Z.
AU  - Ji, S.
TI  - Global Pixel Transformers for Virtual Staining of Microscopy Images
PY  - 2020
T2  - IEEE Transactions on Medical Imaging
VL  - 39
IS  - 6
C7  - 8964264
SP  - 2256
EP  - 2266
DO  - 10.1109/TMI.2020.2968504
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084367444&doi=10.1109%2fTMI.2020.2968504&partnerID=40&md5=41ba1b946d897ba8afdacb7a5e91f87a
AB  - Visualizing the details of different cellular structures is of great importance to elucidate cellular functions. However, it is challenging to obtain high quality images of different structures directly due to complex cellular environments. Fluorescence staining is a popular technique to label different structures but has several drawbacks. In particular, label staining is time consuming and may affect cell morphology, and simultaneous labels are inherently limited. This raises the need of building computational models to learn relationships between unlabeled microscopy images and labeled fluorescence images, and to infer fluorescence labels of other microscopy images excluding the physical staining process. We propose to develop a novel deep model for virtual staining of unlabeled microscopy images. We first propose a novel network layer, known as the global pixel transformer layer, that fuses global information from inputs effectively. The proposed global pixel transformer layer can generate outputs with arbitrary dimensions, and can be employed for all the regular, down-sampling, and up-sampling operators. We then incorporate our proposed global pixel transformer layers and dense blocks to build an U-Net like network. We believe such a design can promote feature reusing between layers. In addition, we propose a multi-scale input strategy to encourage networks to capture features at different scales. We conduct evaluations across various fluorescence image prediction tasks to demonstrate the effectiveness of our approach. Both quantitative and qualitative results show that our method outperforms the state-of-the-art approach significantly. It is also shown that our proposed global pixel transformer layer is useful to improve the fluorescence image prediction results. © 1982-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 25
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Tófoli, M.F.
AU  - Soler, E.M.
AU  - Balbo, A.R.
AU  - Baptista, E.C.
AU  - Nepomuceno, L.
TI  - Interior/exterior-point methods with inertia correction strategy for solving optimal reactive power flow problems with discrete variables
PY  - 2020
T2  - Annals of Operations Research
VL  - 286
IS  - 1-2
SP  - 243
EP  - 263
DO  - 10.1007/s10479-018-3012-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052641341&doi=10.1007%2fs10479-018-3012-y&partnerID=40&md5=bfbc6591ed2f6c6a84c8661cd3f7f631
AB  - Interior/exterior-point methods have been widely used for solving Optimal Reactive Power Flow problems (ORPF). However, the utilization of such methods becomes difficult when transformer taps and/or capacitor/reactor banks are more rigorously represented in the problem formulation by means of discrete control variables. This work investigates the solution of the ORPF problem when transformer tap ratios are modeled as discrete variables. The solution method proposed handles discrete variables by means of sinusoidal penalty function, while the penalized problems are solved by an exterior-point method. An inertia correction strategy is proposed in order to assure that only local minima are obtained for the penalized problems. New search directions are also investigated that combine predictor and corrector directions. Numerical simulations are performed involving the IEEE 14, 30 and 57 bus systems. The results show the efficiency of the proposed inertia correction strategy and also reveals that the proposed exterior-point method outperforms traditional interior-point methods in terms of the number of iterations and computation times. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - FMS:B; AJG:3; ZUFE:1A; zdy:3; 
LB  - Tófoli2020Interior/exterior-point
ER  -

TY  - JOUR
AU  - Hupkes, D.
AU  - Dankers, V.
AU  - Mul, M.
AU  - Bruni, E.
TI  - Compositionality Decomposed: How do Neural Networks Generalise?
PY  - 2020
T2  - Journal of Artificial Intelligence Research
VL  - 67
SP  - 757
EP  - 795
DO  - 10.1613/JAIR.1.11674
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089811968&doi=10.1613%2fJAIR.1.11674&partnerID=40&md5=3d09a13051b4278d66e320174ee8728b
AB  - Despite a multitude of empirical studies, little consensus exists on whether neural networks are able to generalise compositionally, a controversy that, in part, stems from a lack of agreement about what it means for a neural model to be compositional. As a response to this controversy, we present a set of tests that provide a bridge between, on the one hand, the vast amount of linguistic and philosophical theory about compositionality of language and, on the other, the successful neural models of language. We collect different interpretations of compositionality and translate them into five theoretically grounded tests for models that are formulated on a task-independent level. In particular, we provide tests to investigate (i) if models systematically recombine known parts and rules (ii) if models can extend their predictions beyond the length they have seen in the training data (iii) if models’ composition operations are local or global (iv) if models’ predictions are robust to synonym substitutions and (v) if models favour rules or exceptions during training. To demonstrate the usefulness of this evaluation paradigm, we instantiate these five tests on a highly compositional data set which we dub PCFG SET and apply the resulting tests to three popular sequence-to-sequence models: a recurrent, a convolution-based and a transformer model. We provide an in-depth analysis of the results, which uncover the strengths and weaknesses of these three architectures and point to potential areas of improvement. ©2020 AI Access Foundation. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 151
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Chen, Y.
AU  - Wang, J.
AU  - Zhu, B.
AU  - Tang, M.
AU  - Lu, H.
TI  - Pixelwise Deep Sequence Learning for Moving Object Detection
PY  - 2019
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 29
IS  - 9
C7  - 8097419
SP  - 2568
EP  - 2579
DO  - 10.1109/TCSVT.2017.2770319
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033677329&doi=10.1109%2fTCSVT.2017.2770319&partnerID=40&md5=5f319df8f5d0ed22716da45e0450ace1
AB  - Moving object detection is an essential, well-studied but still open problem in computer vision and plays a fundamental role in many applications. Traditional approaches usually reconstruct background images with hand-crafted visual features, such as color, texture, and edge. Due to lack of prior knowledge or semantic information, it is difficult to deal with complicated and rapid changing scenes. To exploit the temporal structure of the pixel-level semantic information, in this paper, we propose an end-to-end deep sequence learning architecture for moving object detection. First, the video sequences are input into a deep convolutional encoder-decoder network for extracting pixel-wise semantic features. Then, to exploit the temporal context, we propose a novel attention long short-term memory (Attention ConvLSTM) to model pixelwise changes over time. A spatial transformer network and a conditional random field layer are finally appended to reduce the sensitivity to camera motion and smooth the foreground boundaries. A multi-task loss is proposed to jointly optimization for frame-based classification and temporal prediction in an end-to-end network. Experimental results on CDnet 2014 and LASIESTA show 12.15% and 16.71% improvement to the state of the art, respectively. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 78
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, J.
AU  - Wang, W.
AU  - Gao, W.
TI  - Predicting Diverse Future Frames With Local Transformation-Guided Masking
PY  - 2019
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 29
IS  - 12
C7  - 8540055
SP  - 3531
EP  - 3543
DO  - 10.1109/TCSVT.2018.2882061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056717266&doi=10.1109%2fTCSVT.2018.2882061&partnerID=40&md5=3c7c990c094403acdf13284b4484c70c
AB  - Video prediction is the challenging task of generating the future frames of a video given a sequence of previously observed frames. This task involves the construction of an internal representation that accurately models the frame evolutions, including contents and dynamics. Video prediction is considered difficult due to the inherent compounding of errors in recursive pixel level prediction. In this paper, we present a novel video prediction system that focuses on regions of interest (ROIs) rather than on entire frames and learns frame evolutions at the transformation level rather than at the pixel level. We provide two strategies to generate high-quality ROIs that contains potential moving visual cues. The frame evolutions are modeled with a transformation generator that produces transformers and masks simultaneously, which are then combined to generate the future frame in a transformation-guided masking procedure. Compared with recent approaches, our system is able to generate more accurate predictions by modeling the visual evolutions at the transformation level rather than at the pixel level. Focusing on ROIs avoids a heavy computational burden and enables our system to generate high-quality long-term future frames without severely amplified signal loss. Moreover, our system is able to generate diverse plausible future frames, which is important in many real-world scenarios. Furthermore, we enable our system to perform video prediction conditioned on a single frame by revising the transformation generator to produce motion-centric transformers. We test our system on four datasets with different experimental settings and demonstrate its advantages over recent methods, both quantitatively and qualitatively. © 1991-2012 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 10
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Alletto, S.
AU  - Abati, D.
AU  - Calderara, S.
AU  - Cucchiara, R.
AU  - Rigazio, L.
TI  - Self-Supervised Optical Flow Estimation by Projective Bootstrap
PY  - 2019
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 20
IS  - 9
C7  - 8506466
SP  - 3294
EP  - 3302
DO  - 10.1109/TITS.2018.2873980
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055709752&doi=10.1109%2fTITS.2018.2873980&partnerID=40&md5=07220224952912e0afa84681fe76fa48
AB  - Dense optical flow estimation is complex and time consuming, with state-of-the-art methods relying either on large synthetic data sets or on pipelines requiring up to a few minutes per frame pair. In this paper, we address the problem of optical flow estimation in the automotive scenario in a self-supervised manner. We argue that optical flow can be cast as a geometrical warping between two successive video frames and devise a deep architecture to estimate such transformation in two stages. First, a dense pixel-level flow is computed with a projective bootstrap on rigid surfaces. We show how such global transformation can be approximated with a homography and extend spatial transformer layers so that they can be employed to compute the flow field implied by such transformation. Subsequently, we refine the prediction by feeding a second, deeper network that accounts for moving objects. A final reconstruction loss compares the warping of frame Xt with the subsequent frame Xt+1 and guides both estimates. The model has the speed advantages of end-to-end deep architectures while achieving competitive performances, both outperforming recent unsupervised methods and showing good generalization capabilities on new automotive data sets. © 2000-2011 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 7
C2  - CCF:B期刊; FMS:B; 
LB  - Alletto2019Self-Supervised
ER  -

TY  - JOUR
AU  - Zhou, L.
AU  - Zhang, J.
AU  - Zong, C.
TI  - Synchronous Bidirectional Neural Machine Translation
PY  - 2019
T2  - Transactions of the Association for Computational Linguistics
VL  - 7
SP  - 91
EP  - 105
DO  - 10.1162/tacl_a_00256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682943&doi=10.1162%2ftacl_a_00256&partnerID=40&md5=a413a6975dd8f4bee3e587bdd44dd660
AB  - Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right. However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs. In this paper, we introduce a synchronous bidirectional–neural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time. Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model. Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on large-scale NIST Chinese-English, WMT14 English-German, and WMT18 Russian-English translation tasks. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art per formance on Chinese-English and English-German translation tasks. © 2019 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 90
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Huang, L.
AU  - Huang, Y.
AU  - Ouyang, W.
AU  - Wang, L.
TI  - Part-aligned pose-guided recurrent network for action recognition
PY  - 2019
T2  - Pattern Recognition
VL  - 92
SP  - 165
EP  - 176
DO  - 10.1016/j.patcog.2019.03.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063593519&doi=10.1016%2fj.patcog.2019.03.010&partnerID=40&md5=371e9631a14096551b01db76ede08b33
AB  - Action recognition using pose information has drawn much attention recently. However, most previous approaches treat human pose as a whole or just use pose to extract robust features. Actually, human body parts play an important role in action, and so modeling spatio-temporal information of body parts can effectively assist in classifying actions. In this paper, we propose a Part-aligned Pose-guided Recurrent Network (P                             2                             RN) for action recognition. The model mainly consists of two modules, i.e., part alignment module and part pooling module, which are used for part representation learning and part-related feature fusion, respectively. The part-alignment module incorporates an auto-transformer attention, aiming to capture spatial configuration of body parts and predict pose attention maps. While the part pooling module exploits both symmetry and complementarity of body parts to produce fused body representation. The whole network is a recurrent network which can exploit the body representation and simultaneously model spatio-temporal evolutions of human body parts. Experiments on two publicly available benchmark datasets show the state-of-the-art performance and demonstrate the power of the two proposed modules.                          © 2019 Elsevier Ltd
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 19
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Liu, Q.
AU  - He, D.
AU  - Xie, L.
TI  - Prediction of off-target specificity and cells-pecific fitness of CRISPR-Cas system using attention boosted deep learning and network-based gene feature
PY  - 2019
T2  - PLoS Computational Biology
VL  - 15
IS  - 10
C7  - e1007480
DO  - 10.1371/journal.pcbi.1007480
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074673437&doi=10.1371%2fjournal.pcbi.1007480&partnerID=40&md5=f814a3c76617d7d638423f563dc85a97
AB  - CRISPR-Cas is a powerful genome editing technology and has a great potential for in vivo gene therapy. Successful translational application of CRISPR-Cas to biomedicine still faces many safety concerns, including off-target side effect, cell fitness problem after CRISPRCas treatment, and on-target genome editing side effect in undesired tissues. To solve these issues, it is needed to design sgRNA with high cell-specific efficacy and specificity. Existing single-guide RNA (sgRNA) design tools mainly depend on a sgRNA sequence and the local information of the targeted genome, thus are not sufficient to account for the difference in the cellular response of the same gene in different cell types. To incorporate cellspecific information into the sgRNA design, we develop novel interpretable machine learning models, which integrate features learned from advanced transformer-based deep neural network with cell-specific gene property derived from biological network and gene expression profile, for the prediction of CRISPR-Cas9 and CRISPR-Cas12a efficacy and specificity. In benchmark studies, our models significantly outperform state-of-the-art algorithms. Furthermore, we find that the network-based gene property is critical for the prediction of cell-specific post-treatment cellular response. Our results suggest that the design of efficient and safe CRISPR-Cas needs to consider cell-specific information of genes. Our findings may bolster developing more accurate predictive models of CRISPR-Cas across a broad spectrum of biological conditions as well as provide new insight into developing efficient and safe CRISPR-based gene therapy. © 2019 Liu et al.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 44
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Große-Stoltenberg, A.
AU  - Hellmann, C.
AU  - Thiele, J.
AU  - Werner, C.
AU  - Oldeland, J.
TI  - Early detection of GPP-related regime shifts after plant invasion by integrating imaging spectroscopy with airborne LiDAR
PY  - 2018
T2  - Remote Sensing of Environment
VL  - 209
SP  - 780
EP  - 792
DO  - 10.1016/j.rse.2018.02.038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043506509&doi=10.1016%2fj.rse.2018.02.038&partnerID=40&md5=d7cc35aa9ced7e4c7fb904e18f13b908
AB  - Invasive plant species can have high, self-reinforcing impacts on ecosystem structure and functioning that induce permanent changes of ecosystem properties. Therefore, early detection and timely management is required to alleviate ecosystem consequences of invasion. Integrating airborne hyperspectral imagery with LiDAR data can deliver spatially explicit information on invader occurrence and ecosystem transformations even at early stages of invasion. However, relevant “model invaders” and well-characterized ecosystems need to be identified to both increase predictive power of invasion theory and prioritize management. In addition, there is still a knowledge gap regarding sensor-based approaches that are valid in space and time to assess the impact of invasive engineers on ecosystem functioning as well as the potential to induce regime shifts. In this study, occurrence and spatio-temporal impact of the invasive N2-fixing shrub, Acacia longifolia, was assessed in a heterogeneous, Mediterranean dune ecosystem. The invader was mapped using vegetation indices derived from airborne hyperspectral images as well as airborne LiDAR data using Random Forest classification with a Sensitivity of 0.79, a Positive Predicted Value (PPV) of 0.81, and Cohen's Kappa of 0.77. Invaded sites varied between early stages with low cover, where isolated patches were detected, to heavily infested A. longifolia thickets. Analysis of historical images showed that the invader could establish under the harsh conditions of open dune plains, possibly triggered by human interference. The recently developed Near-Infrared Vegetation Index (NIRV), which is related to Gross Primary Production (GPP), increased linearly and significantly with increasing invader cover. This indicated a GPP-related regime shift induced by the invader, changing ecosystem productivity representative of open shrublands to that of forests. Such a shift could even be identified at early stages of invasion. Thus, the NIRV index may provide an appropriate sensor-based “model metric” to assess impacts of invasive engineers. This offers the opportunity to predict and anticipate regime shifts as a basis for timely management. © 2018 Elsevier Inc.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 28
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Casavola, A.
AU  - Tedesco, F.
AU  - Vizza, M.
TI  - Command Governor Strategies for the Online Management of Reactive Power in Smart Grids with Distributed Generation
PY  - 2017
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 14
IS  - 2
C7  - 7851056
SP  - 449
EP  - 460
DO  - 10.1109/TASE.2017.2655460
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012992049&doi=10.1109%2fTASE.2017.2655460&partnerID=40&md5=106cc44e04f5b912e31ae18205038764
AB  - High penetration of distributed generation (DG) in medium voltage (MV) power grids may easily lead to abrupt voltage raises in the presence of either low demand conditions or high power production from renewable sources. In order to cope with the possibly occurring voltage limit violation, the active power injected by the distributed generators is typically curtailed, being, however, such an approach suboptimal from an economical point of view and presenting several other disadvantages. To address this issue, the online management and coordination of the reactive power injected/absorbed by the distributed generators acting on the grid are proposed here. The approach is based on command governor ideas that are used here to optimally solve constrained voltage control problems in both centralized and distributed ways. The approach foresees an active coordination between some controllable devices of the grid, e.g., distributed generators and MV/high voltage transformers, in order to maintain relevant system variables within prescribed operative constraints in response to unexpected adverse conditions. Simulation results show that the proposed approach is more effective than approaches suggested by the current Italian norms on DGs connection. © 2017 IEEE.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 14
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Cao, Y.
TI  - Predicting power consumption of GPUs with fuzzy wavelet neural networks
PY  - 2015
T2  - Parallel Computing
VL  - 44
SP  - 18
EP  - 36
DO  - 10.1016/j.parco.2015.02.002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924353663&doi=10.1016%2fj.parco.2015.02.002&partnerID=40&md5=cb5521dd5a6873e83d054d99565262f8
AB  - Prediction and optimization of power consumption have become an essential issue in the field of General-purpose computing on graphic processing units (GPUs) because of the increasing prevalence of GPUs and the constraints of energy consumption. However, previous approaches to build power models need to extract program features related to power consumption from the performance counter or GPU emulators. These approaches are unable to estimate power consumption of applications for software designers owing to the lack of information about detailed GPUs architecture or the supporting of emulators. In this study, we explore a novel method to model GPU power consumption of applications in computing process. By using program slicing, we decompose the source code of applications into slices and extract the power-related static program features. The slicing is used as a basic unit to train a power model based on fuzzy wavelet artificial neural networks. This step allows programmers to investigate the power profile of their applications and identify the code areas with higher energy consumption. To improve prediction accuracy, we further divide the GPUs applications by the branch structure into two categories: sparseness-branch and denseness-branch. The power model is proposed for sparseness-branch programs based on slicing. For denseness-branch programs, probabilistic slicing is utilized to reduce the invalid slices in order to improve accuracy. The models are empirically validated by using typical GPU benchmarks and the results are compared with the measured power. Overall, the average error of our power models is less than 6%. © 2015 Elsevier B.V. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ravicz, M.E.
AU  - Rosowski, J.J.
TI  - Inner-ear sound pressures near the base of the cochlea in chinchilla: Further investigation
PY  - 2013
T2  - Journal of the Acoustical Society of America
VL  - 133
IS  - 4
SP  - 2208
EP  - 2223
DO  - 10.1121/1.4792139
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876156699&doi=10.1121%2f1.4792139&partnerID=40&md5=46d8577761bd18fef8ebb257e989e19d
AB  - The middle-ear pressure gain GMEP, the ratio of sound pressure in the cochlear vestibule PV to sound pressure at the tympanic membrane PTM, is a descriptor of middle-ear sound transfer and the cochlear input for a given stimulus in the ear canal. GMEP and the cochlear partition differential pressure near the cochlear base ΔP CP, which determines the stimulus for cochlear partition motion and has been linked to hearing ability, were computed from simultaneous measurements of PV, PTM, and the sound pressure in scala tympani near the round window PST in chinchilla. GMEP magnitude was approximately 30 dB between 0.1 and 10 kHz and decreased sharply above 20 kHz, which is not consistent with an ideal transformer or a lossless transmission line. The GMEP phase was consistent with a roughly 50-μs delay between PV and PTM. GMEP was little affected by the inner-ear modifications necessary to measure PST. G MEP is a good predictor of ΔPCP at low and moderate frequencies where PV ≫ PST but overestimates ΔPCP above a few kilohertz where PV ≈ P ST. The ratio of PST to PV provides insight into the distribution of sound pressure within the cochlear scalae. © 2013 Acoustical Society of America.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 18
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Hong, Y.
AU  - Meeker, W.Q.
AU  - McCalley, J.D.
TI  - Prediction of remaining life of power transformers based on left truncated and right censored lifetime data
PY  - 2009
T2  - Annals of Applied Statistics
VL  - 3
IS  - 2
SP  - 857
EP  - 879
DO  - 10.1214/00-AOAS231
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954789389&doi=10.1214%2f00-AOAS231&partnerID=40&md5=c041b3abdc53d68fe8c6dddd27791a7b
AB  - Prediction of the remaining life of high-voltage power transformers is an important issue for energy companies because of the need for planning maintenance and capital expenditures. Lifetime data for such transformers are complicated because transformer lifetimes can extend over many decades and transformer designs and manufacturing practices have evolved. We were asked to develop statistically-based predictions for the lifetimes of an energy company's fleet of high-voltage transmission and distribution transformers. The company's data records begin in 1980, providing information on installation and failure dates of transformers. Although the dataset contains many units that were installed before 1980, there is no information about units that were installed and failed before 1980. Thus, the data are left truncated and right censored. We use a parametric lifetime model to describe the lifetime distribution of individual transformers. We develop a statistical procedure, based on age-adjusted life distributions, for computing a prediction interval for remaining life for individual transformers now in service. We then extend these ideas to provide predictions and prediction intervals for the cumulative number of failures, over a range of time, for the overall fleet of transformers. © Institute of Mathematical Statistics, 2009.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 131
C2  - FMS:B; AJG:2; ZUFE:1A; zdy:2; 
LB  - Hong2009Prediction
ER  -

TY  - JOUR
AU  - Vinay Kumar, K.
AU  - Ravi, V.
AU  - Carr, M.
AU  - Raj Kiran, N.
TI  - Software development cost estimation using wavelet neural networks
PY  - 2008
T2  - Journal of Systems and Software
VL  - 81
IS  - 11
SP  - 1853
EP  - 1867
DO  - 10.1016/j.jss.2007.12.793
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-52049116923&doi=10.1016%2fj.jss.2007.12.793&partnerID=40&md5=5be776d64d38b6b802b10711c41100fe
AB  - Software development has become an essential investment for many organizations. Software engineering practitioners have become more and more concerned about accurately predicting the cost and quality of software product under development. Accurate estimates are desired but no model has proved to be successful at effectively and consistently predicting software development cost. In this paper, we propose the use of wavelet neural network (WNN) to forecast the software development effort. We used two types of WNN with Morlet function and Gaussian function as transfer function and also proposed threshold acceptance training algorithm for wavelet neural network (TAWNN). The effectiveness of the WNN variants is compared with other techniques such as multilayer perceptron (MLP), radial basis function network (RBFN), multiple linear regression (MLR), dynamic evolving neuro-fuzzy inference system (DENFIS) and support vector machine (SVM) in terms of the error measure which is mean magnitude relative error (MMRE) obtained on Canadian financial (CF) dataset and IBM data processing services (IBMDPS) dataset. Based on the experiments conducted, it is observed that the WNN-Morlet for CF dataset and WNN-Gaussian for IBMDPS outperformed all the other techniques. Also, TAWNN outperformed all other techniques except WNN. © 2008 Elsevier Inc. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 121
C2  - CCF:B期刊; AJG:2; zdy:2; 
ER  -

TY  - JOUR
AU  - Barrios, E.
TI  - Soil biota, ecosystem services and land productivity
PY  - 2007
T2  - Ecological Economics
VL  - 64
IS  - 2
SP  - 269
EP  - 285
DO  - 10.1016/j.ecolecon.2007.03.004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-36549064652&doi=10.1016%2fj.ecolecon.2007.03.004&partnerID=40&md5=be13442afa1ff3720627db3fe90bd659
AB  - The soil environment is likely the most complex biological community. Soil organisms are extremely diverse and contribute to a wide range of ecosystem services that are essential to the sustainable function of natural and managed ecosystems. The soil organism community can have direct and indirect impacts on land productivity. Direct impacts are those where specific organisms affect crop yield immediately. Indirect effects include those provided by soil organisms participating in carbon and nutrient cycles, soil structure modification and food web interactions that generate ecosystem services that ultimately affect productivity. Recognizing the great biological and functional diversity in the soil and the complexity of ecological interactions it becomes necessary to focus in this paper on soil biota that have a strong linkage to functions which underpin 'soil based' ecosystem services. Selected organisms from different functional groups (i.e. microsymbionts, decomposers, elemental transformers, soil ecosystem engineers, soil-borne pest and diseases, and microregulators) are used to illustrate the linkages of soil biota and ecosystem services essential to life on earth as well as with those associated with the provision of goods and the regulation of ecosystem processes. These services are not only essential to ecosystem function but also a critical resource for the sustainable management of agricultural ecosystems. Research opportunities and gaps related to methodological, experimental and conceptual approaches that may be helpful to address the challenge of linking soil biodiversity and function to the provision of ecosystem services and land productivity are discussed. These include: 1) integration of spatial variability research in soil ecology and a focus on 'hot spots' of biological activity, 2) using a selective functional group approach to study soil biota and function, 3) combining new and existing methodological approaches that link selected soil organisms, the temporal and spatial dynamics of their function, and their contribution to the provision of selected 'soil based' ecosystem services, 4) using understanding about hierarchical relationships to manage soil biota and function in cropping systems, 5) using local knowledge about plants as indicators of soil quality, remote sensing and GIS technologies, and plant-soil biota interactions to help understand the impacts of soil biota at landscape scale, and 6) developing land quality monitoring systems that inform land users about their land's ecosystem service performance, improve capacities to predict and adapt to environmental changes, and support policy and decision-making. © 2007 Elsevier B.V. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 684
C2  - FMS:A; AJG:3; zdy:3; 
LB  - Barrios2007Soil
ER  -

TY  - JOUR
AU  - Anex, R.P.
AU  - Englehardt, J.D.
TI  - Application of a predictive Bayesian model to environmental accounting
PY  - 2001
T2  - Journal of Hazardous Materials
VL  - 82
IS  - 2
SP  - 99
EP  - 112
DO  - 10.1016/S0304-3894(00)00348-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035970950&doi=10.1016%2fS0304-3894%2800%2900348-4&partnerID=40&md5=a2b060b80f7006b3751bd83a8193d3dd
AB  - Environmental accounting techniques are intended to capture important environmental costs and benefits that are often overlooked in standard accounting practices. Environmental accounting methods themselves often ignore or inadequately represent large but highly uncertain environmental costs and costs conditioned by specific prior events. Use of a predictive Bayesian model is demonstrated for the assessment of such highly uncertain environmental and contingent costs. The predictive Bayesian approach presented generates probability distributions for the quantity of interest (rather than parameters thereof). A spreadsheet implementation of a previously proposed predictive Bayesian model, extended to represent contingent costs, is described and used to evaluate whether a firm should undertake an accelerated phase-out of its PCB containing transformers. Variability and uncertainty (due to lack of information) in transformer accident frequency and severity are assessed simultaneously using a combination of historical accident data, engineering model-based cost estimates, and subjective judgement. Model results are compared using several different risk measures. Use of the model for incorporation of environmental risk management into a company's overall risk management strategy is discussed. Copyright © 2001 Elsevier Science B.V.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 4
C2  - ZUFE:1A; 
ER  -

TY  - JOUR
AU  - Hemdal, J.F.
TI  - One-dimensional digital processing of images for straight-line detection
PY  - 1998
T2  - Pattern Recognition
VL  - 31
IS  - 11
SP  - 1687
EP  - 1690
DO  - 10.1016/S0031-3203(98)00046-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032215143&doi=10.1016%2fS0031-3203%2898%2900046-6&partnerID=40&md5=61a80a38b16bd5d87449a52e00e1ef62
AB  - The detection of straight lines in images is a common requirement in the recognition of some patterns. Several approaches have been in the use for many years but are computationally intensive. This paper presents a simple algorithm which can make use of the fast fourier transformer (FFT) for rapid computation and has the added feature of being able to detect straight lines of a specified length. The method herein suggests that simply unlacing the image raster before matched filtering can reduce the search range because of the restricted periodicities in the one-dimensional unlaced signal. These matched filters can be applied in the frequency domain through the use of the FFT. This note discusses the algorithm and presents example results.; The detection of straight lines in images is a common requirement in the recognition of some patterns. Several approaches have been in the use for many years but are computationally intensive. This paper presents a simple algorithm which can make use of the Fast Fourier Transformer (FFT) for rapid computation and has the added feature of being able to detect straight lines of a specified length. The method herein suggests that simply unlacing the image raster before matched filtering can reduce the search range because of the restricted periodicities in the one-dimensional unlaced signal. These matched filters can be applied in the frequency domain through the use of the FFT. This note discusses the algorithm and presents example results.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Masaki, T.
AU  - Morimoto, Y.
AU  - Onoye, T.
AU  - Shirakawa, I.
TI  - VLSI Implementation of Inverse Discrete Cosine Transformer and Motion Compensator for MPEG2 HDTV Video Decoding
PY  - 1995
T2  - IEEE Transactions on Circuits and Systems for Video Technology
VL  - 5
IS  - 5
SP  - 387
EP  - 395
DO  - 10.1109/76.473552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029388046&doi=10.1109%2f76.473552&partnerID=40&md5=fc1d47ddab70e9e77fe2f6def21357e5
AB  - An MPEG2 video decoder core dedicated to MP@HL (Main Profile at High Level) images is described with the main theme focused on an inverse discrete cosine transformer and a motion compensator. By means of various novel architectures, the inverse discrete cosine transformer achieves a high throughput, and the motion compensator performs different types of picture prediction modes employed by the MPEG2 algorithm. The decoder core, implemented in the total chip area of 22.0 mm2 by a 0.6-µm triple-metal CMOS technology, processes a macroblock within 3.84 µs, and therefore is capable of decoding HDTV (1920 x 1152 pels) images in real time. © 1995 IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 32
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Kraszewski, R.J.
AU  - Sigelmann, R.A.
AU  - Herbertz, J.
AU  - Lee, M.
TI  - A chain matrix model for an acoustically coupled, lead zirconate titanate core, electrical transformer
PY  - 1991
T2  - Journal of the Acoustical Society of America
VL  - 90
IS  - 5
SP  - 2763
EP  - 2768
DO  - 10.1121/1.401872
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025718666&doi=10.1121%2f1.401872&partnerID=40&md5=cf546c12be07e7b30b9fa3544950c9e7
AB  - Chain matrices are used to generate a functional description of the electrical impedance parameters of a device comprised of three layers of piezoelectric rings and implemented as a two port network. It is shown that this device can be used as a piezoelectric core, acoustically coupled electrical transformer (PT). A circuit representation of the PT is derived and comparisons are made between it and the magnetic transformer (MT). The impedance parameters of a PT, made from three lead zirconate titanate rings, were measured and compared with their corresponding theoretical values. While the approach predicts, in this case, the center frequency of the device with an error of 4.5%, it provides a highly accurate description of its qualitative behavior. The error in the center frequency is attributed to the presence of coupled modes that are ignored by the model. In particular, the tested device did not strictly satisfy the thinness constraints that are imposed by the approximations used. Power transfer calculations predict an efficiency around the resonance frequency in excess of 0.90 for loads ranging from 0.1 to 13 kH. © 1991, Acoustical Society of America. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 1
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Shepard, S.W.
AU  - Cunefare, K.A.
TI  - Active control of extended acoustic sources in a half-space
PY  - 1994
T2  - Journal of the Acoustical Society of America
VL  - 96
IS  - 4
SP  - 2262
EP  - 2271
DO  - 10.1121/1.410098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027937740&doi=10.1121%2f1.410098&partnerID=40&md5=f148b3d93737ca89c7daed945cc9ef00
AB  - Many noise sources, such as an electronic transformer, are located on or near an acoustically rigid planar surface, such as a concrete floor. Thus far, however, most of the active noise control research has been based on the free-field assumption. The work presented here investigates the effect the presence of a rigid plane has on the active noise control of an acoustic source with characteristic dimensions comparable to the acoustic wavelength at the frequency of interest. It is shown that when the source is located a distance of one wavelength or more from the plane, the presence of the plane may be neglected. However, the minimum radiated power computed using a free space active analysis can be significantly greater than that predicted using a half space active analysis for distances less than one wavelength. As a result, using the simpler free space analysis techniques leads to less effective control for distances less than one wavelength. © 1994, Acoustical Society of America. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 12
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Beaulieu, N.C.
AU  - Abu-Dayya, A.A.
TI  - The Evaluation of Error Probabilities for Low-Frequency Attenuation Channels
PY  - 1994
T2  - IEEE Transactions on Communications
VL  - 42
IS  - 9
SP  - 2676
EP  - 2683
DO  - 10.1109/26.317408
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028496508&doi=10.1109%2f26.317408&partnerID=40&md5=b8162a619c8670abe0ac175a79093654
AB  - Currently, channels having large low-frequency attenuation are of much interest. Low-frequency removal may result from transformer or capacitor coupling. Examples include ISDN loop transmission (transformer coupling) and wireless systems (capacitor coupled amplifiers). Despite this interest, Few works have explicitly examined the problem of calculating the average probability of error for these systems, in which the intersymbol interference from a single pulse may extend over hundreds or even thousands of symbols. Efficient series techniques for evaluation of the error probabilities of multilevel pulse amplitude modulations and multilevel duobinary signaling are derived. The method is applicable to any additive noise possessing an even probability density function. The Gaussian noise case is examined in detail. Examples of Nyquist I signaling and suboptimal detection of nonreturn-to-zero pulse codes are considered. The results are compared to previous published results. It is seen that an often cited upper bound, though within a factor of about ten in error probability for small to medium intersymbol interference conditions, may significantly overestimate the system degradation due to low-frequency attenuation when the intersymbol interference is large. © 1994 IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 3
C2  - CCF:B期刊; 
ER  -

TY  - JOUR
AU  - Ling, F.
AU  - Qureshi, S.U.H.
TI  - Convergence and Steady-State Behavior of a Phase-Splitting Fractionally Spaced Equalizer
PY  - 1990
T2  - IEEE Transactions on Communications
VL  - 38
IS  - 4
SP  - 418
EP  - 425
DO  - 10.1109/26.52651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025414333&doi=10.1109%2f26.52651&partnerID=40&md5=7d9f1f06387c09c6175fc2861152024c
AB  - The eigenstructure, the initial convergence, and the steady-state behavior of a phase-splitting fractionally spaced equalizer (PS-FSE) [1] are analyzed in this paper. It is shown that the initial convergence rate of a T/3 or, in general, a T/M, PS-FSE employing the least mean-square (LMS) stochastic gradient adaptive algorithm is half that of a symbol rate equalizer (SRE) or a complex fractionally spaced equalizer (CFSE ) [2]-[7] with the same time span. We also show that the LMS adaptive PS-FSE with symbol rate update converges to a Hilbert transformer followed by a matched filter in cascade with an optimal SRE, and thus forms an optimal receiver structure. The LMS PS-FSE is computationally more efficient and introduced less system delay than the CFSE. © 1990 IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 12 January 2025; Cited By: 22
C2  - CCF:B期刊; 
ER  -
